{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Nov-2016", "title": "Extensions and Limitations of the Neural GPU", "abstract": "The Neural GPU is a recent model that can learn algorithms such as multi-digit binary addition and binary multiplication in a way that generalizes to inputs of arbitrary length. We show that there are two simple ways of improving the performance of the Neural GPU: by carefully designing a curriculum, and by increasing model size. The latter requires careful memory management, as a naive implementation of the Neural GPU is memory intensive. We find that these techniques to increase the set of algorithmic problems that can be solved by the Neural GPU: we have been able to learn to perform all the arithmetic operations (and generalize to arbitrarily long numbers) when the arguments are given in the decimal representation (which, surprisingly, has not been possible before). We have also been able to train the Neural GPU to evaluate long arithmetic expressions with multiple operands that require respecting the precedence order of the operands, although these have succeeded only in their binary representation, and not with 100\\% accuracy.", "histories": [["v1", "Wed, 2 Nov 2016 19:18:17 GMT  (1804kb,D)", "http://arxiv.org/abs/1611.00736v1", null], ["v2", "Fri, 4 Nov 2016 20:46:40 GMT  (2731kb,D)", "http://arxiv.org/abs/1611.00736v2", null]], "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["eric price", "wojciech zaremba", "ilya sutskever"], "accepted": false, "id": "1611.00736"}
