{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Nov-2015", "title": "Interpretable Two-level Boolean Rule Learning for Classification", "abstract": "This paper proposes algorithms for learning two-level Boolean rules in Conjunctive Normal Form (CNF, i.e. AND-of-ORs) or Disjunctive Normal Form (DNF, i.e. OR-of-ANDs) as a type of human-interpretable classification model, aiming for a favorable trade-off between the classification accuracy and the simplicity of the rule. Two formulations are proposed. The first is an integer program whose objective function is a combination of the total number of errors and the total number of features used in the rule. We generalize a previously proposed linear programming (LP) relaxation from one-level to two-level rules. The second formulation replaces the 0-1 classification error with the Hamming distance from the current two-level rule to the closest rule that correctly classifies a sample. Based on this second formulation, block coordinate descent and alternating minimization algorithms are developed. Experiments show that the two-level rules can yield noticeably better performance than one-level rules due to their dramatically larger modeling capacity, and the two algorithms based on the Hamming distance formulation are generally superior to the other two-level rule learning methods in our comparison. A proposed approach to binarize any fractional values in the optimal solutions of LP relaxations is also shown to be effective.", "histories": [["v1", "Mon, 23 Nov 2015 18:52:21 GMT  (64kb)", "http://arxiv.org/abs/1511.07361v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["guolong su", "dennis wei", "kush r varshney", "dmitry m malioutov"], "accepted": false, "id": "1511.07361"}
