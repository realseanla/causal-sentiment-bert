{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Dec-2016", "title": "Summary - TerpreT: A Probabilistic Programming Language for Program Induction", "abstract": "We study machine learning formulations of inductive program synthesis; that is, given input-output examples, synthesize source code that maps inputs to corresponding outputs. Our key contribution is TerpreT, a domain-specific language for expressing program synthesis problems. A TerpreT model is composed of a specification of a program representation and an interpreter that describes how programs map inputs to outputs. The inference task is to observe a set of input-output examples and infer the underlying program. From a TerpreT model we automatically perform inference using four different back-ends: gradient descent (thus each TerpreT model can be seen as defining a differentiable interpreter), linear program (LP) relaxations for graphical models, discrete satisfiability solving, and the Sketch program synthesis system. TerpreT has two main benefits. First, it enables rapid exploration of a range of domains, program representations, and interpreter models. Second, it separates the model specification from the inference algorithm, allowing proper comparisons between different approaches to inference.", "histories": [["v1", "Fri, 2 Dec 2016 20:08:22 GMT  (6053kb,D)", "http://arxiv.org/abs/1612.00817v1", "7 pages, 2 figures, 4 tables in 1st Workshop on Neural Abstract Machines &amp; Program Induction (NAMPI), @NIPS 2016"]], "COMMENTS": "7 pages, 2 figures, 4 tables in 1st Workshop on Neural Abstract Machines &amp; Program Induction (NAMPI), @NIPS 2016", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.NE", "authors": ["alexander l gaunt", "marc brockschmidt", "rishabh singh", "nate kushman", "pushmeet kohli", "jonathan taylor", "daniel tarlow"], "accepted": false, "id": "1612.00817"}
