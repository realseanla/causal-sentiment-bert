{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2016", "title": "Learning Multiagent Communication with Backpropagation", "abstract": "Many tasks in AI require the collaboration of multiple agents. Typically, the communication protocol between agents is manually specified and not altered during training. In this paper we explore a simple neural model, called CommNN, that uses continuous communication for fully cooperative tasks. The model consists of multiple agents and the communication between them is learned alongside their policy. We apply this model to a diverse set of tasks, demonstrating the ability of the agents to learn to communicate amongst themselves, yielding improved performance over non-communicative agents and baselines. In some cases, it is possible to interpret the language devised by the agents, revealing simple but effective strategies for solving the task at hand.", "histories": [["v1", "Wed, 25 May 2016 05:33:21 GMT  (1955kb,D)", "http://arxiv.org/abs/1605.07736v1", null], ["v2", "Mon, 31 Oct 2016 17:29:58 GMT  (2132kb,D)", "http://arxiv.org/abs/1605.07736v2", "Accepted to NIPS 2016"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["sainbayar sukhbaatar", "arthur szlam", "rob fergus"], "accepted": true, "id": "1605.07736"}
