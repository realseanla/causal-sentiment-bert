{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2013", "title": "Theory Refinement on Bayesian Networks", "abstract": "Theory refinement is the task of updating a domain theory in the light of new cases, to be done automatically or with some expert assistance. The problem of theory refinement under uncertainty is reviewed here in the context of Bayesian statistics, a theory of belief revision. The problem is reduced to an incremental learning task as follows: the learning system is initially primed with a partial theory supplied by a domain expert, and thereafter maintains its own internal representation of alternative theories which is able to be interrogated by the domain expert and able to be incrementally refined from data. Algorithms for refinement of Bayesian networks are presented to illustrate what is meant by \"partial theory\", \"alternative theory representation\", etc. The algorithms are an incremental variant of batch learning algorithms from the literature so can work well in batch and incremental mode.", "histories": [["v1", "Wed, 20 Mar 2013 15:29:57 GMT  (476kb)", "http://arxiv.org/abs/1303.5709v1", "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)"]], "COMMENTS": "Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI1991)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["wray l buntine"], "accepted": false, "id": "1303.5709"}
