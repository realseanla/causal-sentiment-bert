{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2017", "title": "Strongly-Typed Agents are Guaranteed to Interact Safely", "abstract": "As artificial agents proliferate, it is becoming increasingly important to ensure that their interactions with one another are well-behaved. In this paper, we formalize a common-sense notion of when algorithms are well-behaved: an algorithm is safe if it does no harm. Motivated by recent progress in deep learning, we focus on the specific case where agents update their actions according to gradient descent. The first result is that gradient descent converges to a Nash equilibrium in safe games.", "histories": [["v1", "Fri, 24 Feb 2017 02:30:15 GMT  (360kb,D)", "http://arxiv.org/abs/1702.07450v1", "13 pages"]], "COMMENTS": "13 pages", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.GT", "authors": ["david balduzzi"], "accepted": true, "id": "1702.07450"}
