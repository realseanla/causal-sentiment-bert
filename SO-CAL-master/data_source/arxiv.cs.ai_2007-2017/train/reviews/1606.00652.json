{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2016", "title": "Death and Suicide in Universal Artificial Intelligence", "abstract": "Reinforcement learning (RL) is a general paradigm for studying intelligent behaviour, with applications ranging from artificial intelligence to psychology and economics. AIXI is a universal solution to the RL problem; it can learn any computable environment. A technical subtlety of AIXI is that it is defined using a mixture over semimeasures that need not sum to 1, rather than over proper probability measures. In this work we argue that the shortfall of a semimeasure can naturally be interpreted as the agent's estimate of the probability of its death. We formally define death for generally intelligent agents like AIXI, and prove a number of related theorems about their behaviour. Notable discoveries include that agent behaviour can change radically under positive linear transformations of the reward signal (from suicidal to dogmatically self-preserving), and that the agent's posterior belief that it will survive increases over time.", "histories": [["v1", "Thu, 2 Jun 2016 12:48:39 GMT  (21kb)", "http://arxiv.org/abs/1606.00652v1", "Conference: Artificial General Intelligence (AGI) 2016 13 pages, 2 figures"]], "COMMENTS": "Conference: Artificial General Intelligence (AGI) 2016 13 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jarryd martin", "tom everitt", "marcus hutter"], "accepted": false, "id": "1606.00652"}
