{"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2016", "title": "A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks", "abstract": "Transfer and multi-task learning have traditionally focused on either a single source-target pair or very few, similar tasks. Ideally, the linguistic levels of morphology, syntax and semantics would benefit each other by being trained in a single model. We introduce such a joint many-task model together with a strategy for successively growing its depth to solve increasingly complex tasks. All layers include shortcut connections to both word representations and lower-level task predictions. We use a simple regularization term to allow for optimizing all model weights to improve one task's loss without exhibiting catastrophic interference of the other tasks. Our single end-to-end trainable model obtains state-of-the-art results on chunking, dependency parsing, semantic relatedness and textual entailment. It also performs competitively on POS tagging. Our dependency parsing layer relies only on a single feed-forward pass and does not require a beam search.", "histories": [["v1", "Sat, 5 Nov 2016 01:59:29 GMT  (729kb,D)", "http://arxiv.org/abs/1611.01587v1", "Under review as a conference paper at ICLR 2017"], ["v2", "Fri, 11 Nov 2016 01:16:07 GMT  (731kb,D)", "http://arxiv.org/abs/1611.01587v2", "Under review as a conference paper at ICLR 2017 (Expanded Appendix for further explanation and analysis)"], ["v3", "Sat, 19 Nov 2016 00:20:12 GMT  (731kb,D)", "http://arxiv.org/abs/1611.01587v3", "Under review as a conference paper at ICLR 2017 (Expanded Appendix for further explanation and analysis; Expanded ablation analysis in Section 6.3)"], ["v4", "Sun, 16 Apr 2017 22:38:21 GMT  (73kb,D)", "http://arxiv.org/abs/1611.01587v4", "Expanded Appendix for further explanation and analysis; Reported additional results"], ["v5", "Mon, 24 Jul 2017 14:41:16 GMT  (79kb,D)", "http://arxiv.org/abs/1611.01587v5", "Accepted as a full paper at the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP 2017)"]], "COMMENTS": "Under review as a conference paper at ICLR 2017", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["kazuma hashimoto", "caiming xiong", "yoshimasa tsuruoka", "richard socher"], "accepted": true, "id": "1611.01587"}
