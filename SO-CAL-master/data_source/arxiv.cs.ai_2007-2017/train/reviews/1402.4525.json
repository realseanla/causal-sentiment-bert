{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Feb-2014", "title": "Off-Policy General Value Functions to Represent Dynamic Role Assignments in RoboCup 3D Soccer Simulation", "abstract": "Collecting and maintaining accurate world knowledge in a dynamic, complex, adversarial, and stochastic environment such as the RoboCup 3D Soccer Simulation is a challenging task. Knowledge should be learned in real-time with time constraints. We use recently introduced Off-Policy Gradient Descent algorithms within Reinforcement Learning that illustrate learnable knowledge representations for dynamic role assignments. The results show that the agents have learned competitive policies against the top teams from the RoboCup 2012 competitions for three vs three, five vs five, and seven vs seven agents. We have explicitly used subsets of agents to identify the dynamics and the semantics for which the agents learn to maximize their performance measures, and to gather knowledge about different objectives, so that all agents participate effectively and efficiently within the group.", "histories": [["v1", "Tue, 18 Feb 2014 23:01:13 GMT  (1220kb,D)", "http://arxiv.org/abs/1402.4525v1", "18 pages, 8 figures"]], "COMMENTS": "18 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["saminda abeyruwan", "andreas seekircher", "ubbo visser"], "accepted": false, "id": "1402.4525"}
