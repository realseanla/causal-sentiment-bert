{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Apr-2017", "title": "Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder Based Speech Recognition", "abstract": "End-to-end training of deep learning-based models allows for implicit learning of intermediate representations based on the final task loss. However, the end-to-end approach ignores the useful domain knowledge encoded in explicit intermediate-level supervision. We hypothesize that using intermediate representations as auxiliary supervision at lower levels of deep networks may be a good way of combining the advantages of end-to-end training and more traditional pipeline approaches. We present experiments on conversational speech recognition where we use lower-level tasks, such as phoneme recognition, in a multitask training approach with an encoder-decoder model for direct character transcription. We compare multiple types of lower-level tasks and analyze the effects of the auxiliary tasks. Our results on the Switchboard corpus show that this approach improves recognition accuracy over a standard encoder-decoder model on the Eval2000 test set.", "histories": [["v1", "Wed, 5 Apr 2017 19:44:23 GMT  (109kb,D)", "http://arxiv.org/abs/1704.01631v1", null], ["v2", "Wed, 19 Apr 2017 16:01:53 GMT  (109kb,D)", "http://arxiv.org/abs/1704.01631v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["shubham toshniwal", "hao tang", "liang lu", "karen livescu"], "accepted": false, "id": "1704.01631"}
