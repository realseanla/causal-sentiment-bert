{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2016", "title": "Natural Language Generation as Planning under Uncertainty Using Reinforcement Learning", "abstract": "We present and evaluate a new model for Natural Language Generation (NLG) in Spoken Dialogue Systems, based on statistical planning, given noisy feedback from the current generation context (e.g. a user and a surface realiser). We study its use in a standard NLG problem: how to present information (in this case a set of search results) to users, given the complex trade- offs between utterance length, amount of information conveyed, and cognitive load. We set these trade-offs by analysing existing MATCH data. We then train a NLG pol- icy using Reinforcement Learning (RL), which adapts its behaviour to noisy feed- back from the current generation context. This policy is compared to several base- lines derived from previous work in this area. The learned policy significantly out- performs all the prior approaches.", "histories": [["v1", "Wed, 15 Jun 2016 09:05:56 GMT  (55kb,D)", "http://arxiv.org/abs/1606.04686v1", "published EACL 2009"]], "COMMENTS": "published EACL 2009", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["verena rieser", "oliver lemon"], "accepted": false, "id": "1606.04686"}
