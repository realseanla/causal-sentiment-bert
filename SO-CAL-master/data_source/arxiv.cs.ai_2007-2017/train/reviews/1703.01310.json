{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2017", "title": "Count-Based Exploration with Neural Density Models", "abstract": "Bellemare et al. (2016) introduced the notion of a pseudo-count to generalize count-based exploration to non-tabular reinforcement learning. This pseudo-count is derived from a density model which effectively replaces the count table used in the tabular setting. Using an exploration bonus based on this pseudo-count and a mixed Monte Carlo update applied to a DQN agent was sufficient to achieve state-of-the-art on the Atari 2600 game Montezuma's Revenge.", "histories": [["v1", "Fri, 3 Mar 2017 19:07:53 GMT  (2260kb,D)", "http://arxiv.org/abs/1703.01310v1", null], ["v2", "Wed, 14 Jun 2017 13:56:28 GMT  (2253kb,D)", "http://arxiv.org/abs/1703.01310v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["georg ostrovski", "marc g bellemare", "a\u00e4ron van den oord", "r\u00e9mi munos"], "accepted": true, "id": "1703.01310"}
