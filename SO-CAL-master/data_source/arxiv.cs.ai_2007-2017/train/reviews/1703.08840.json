{"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2017", "title": "Inferring The Latent Structure of Human Decision-Making from Raw Visual Inputs", "abstract": "The goal of imitation learning is to match example expert behavior, without access to a reinforcement signal. Expert demonstrations provided by humans, however, often show significant variability due to latent factors that are not explicitly modeled. We introduce an extension to the Generative Adversarial Imitation Learning method that can infer the latent structure of human decision-making in an unsupervised way. Our method can not only imitate complex behaviors, but also learn interpretable and meaningful representations. We demonstrate that the approach is applicable to high-dimensional environments including raw visual inputs. In the highway driving domain, we show that a model learned from demonstrations is able to both produce different styles of human-like driving behaviors and accurately anticipate human actions. Our method surpasses various baselines in terms of performance and functionality.", "histories": [["v1", "Sun, 26 Mar 2017 16:20:36 GMT  (8149kb,D)", "http://arxiv.org/abs/1703.08840v1", "10 pages, 6 figures"]], "COMMENTS": "10 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV", "authors": ["yunzhu li", "jiaming song", "stefano ermon"], "accepted": true, "id": "1703.08840"}
