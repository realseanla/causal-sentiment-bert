{"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Unsupervised Image-to-Image Translation Networks", "abstract": "Most of the existing image-to-image translation frameworks---mapping an image in one domain to a corresponding image in another---are based on supervised learning, i.e., pairs of corresponding images in two domains are required for learning the translation function. This largely limits their applications, because capturing corresponding images in two different domains is often a difficult task. To address the issue, we propose the UNsupervised Image-to-image Translation (UNIT) framework, which is based on variational autoencoders and generative adversarial networks. The proposed framework can learn the translation function without any corresponding images in two domains. We enable this learning capability by combining a weight-sharing constraint and an adversarial training objective. Through visualization results from various unsupervised image translation tasks, we verify the effectiveness of the proposed framework. An ablation study further reveals the critical design choices. Moreover, we apply the UNIT framework to the unsupervised domain adaptation task and achieve better results than competing algorithms do in benchmark datasets.", "histories": [["v1", "Thu, 2 Mar 2017 16:29:30 GMT  (3274kb,D)", "http://arxiv.org/abs/1703.00848v1", "19 pages, 19 figures"], ["v2", "Tue, 3 Oct 2017 17:55:21 GMT  (4519kb,D)", "http://arxiv.org/abs/1703.00848v2", "11 pages, 6 figures"], ["v3", "Fri, 6 Oct 2017 03:14:21 GMT  (4519kb,D)", "http://arxiv.org/abs/1703.00848v3", "11 pages, 6 figures, The paper will be published in NIPS 2017"], ["v4", "Mon, 9 Oct 2017 18:14:27 GMT  (4642kb,D)", "http://arxiv.org/abs/1703.00848v4", "NIPS 2017, 11 pages, 6 figures"]], "COMMENTS": "19 pages, 19 figures", "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["ming-yu liu", "thomas breuel", "jan kautz"], "accepted": true, "id": "1703.00848"}
