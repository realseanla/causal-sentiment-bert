{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2010", "title": "Less Regret via Online Conditioning", "abstract": "We analyze and evaluate an online gradient descent algorithm with adaptive per-coordinate adjustment of learning rates. Our algorithm can be thought of as an online version of batch gradient descent with a diagonal preconditioner. This approach leads to regret bounds that are stronger than those of standard online gradient descent for general online convex optimization problems. Experimentally, we show that our algorithm is competitive with state-of-the-art algorithms for large scale machine learning problems.", "histories": [["v1", "Thu, 25 Feb 2010 20:31:05 GMT  (15kb)", "http://arxiv.org/abs/1002.4862v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["matthew streeter", "h brendan mcmahan"], "accepted": false, "id": "1002.4862"}
