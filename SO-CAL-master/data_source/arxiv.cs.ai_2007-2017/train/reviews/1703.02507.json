{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Mar-2017", "title": "Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features", "abstract": "The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, and on many tasks even beats supervised models, highlighting the robustness of the produced sentence embeddings.", "histories": [["v1", "Tue, 7 Mar 2017 18:19:11 GMT  (91kb,D)", "http://arxiv.org/abs/1703.02507v1", null], ["v2", "Mon, 10 Jul 2017 18:05:48 GMT  (108kb,D)", "http://arxiv.org/abs/1703.02507v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.IR", "authors": ["matteo pagliardini", "prakhar gupta", "martin jaggi"], "accepted": false, "id": "1703.02507"}
