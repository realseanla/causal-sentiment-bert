{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Mar-2017", "title": "Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability", "abstract": "Many real-world tasks involve multiple agents with partial observability and limited communication. Learning is challenging in these settings due to local viewpoints of agents, which perceive the world as non-stationary due to concurrently-exploring teammates. Approaches that learn specialized policies for individual tasks face major problems when applied to the real world: not only do agents have to learn and store a distinct policy for each task, but in practice the identity of the task is often non-observable, making these algorithms inapplicable. This paper formalizes and addresses the problem of multi-task multi-agent reinforcement learning under partial observability. We introduce a decentralized single-task learning approach that is robust to concurrent interactions of teammates, and present an approach for distilling single-task policies into a unified policy that performs well across multiple related tasks, without explicit provision of task identity.", "histories": [["v1", "Fri, 17 Mar 2017 19:32:38 GMT  (5933kb,D)", "https://arxiv.org/abs/1703.06182v1", null], ["v2", "Sat, 25 Mar 2017 15:54:36 GMT  (5933kb,D)", "http://arxiv.org/abs/1703.06182v2", null], ["v3", "Wed, 14 Jun 2017 16:09:39 GMT  (6467kb,D)", "http://arxiv.org/abs/1703.06182v3", null], ["v4", "Thu, 13 Jul 2017 17:34:34 GMT  (6467kb,D)", "http://arxiv.org/abs/1703.06182v4", "Accepted to ICML 2017"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.MA", "authors": ["shayegan omidshafiei", "jason pazis", "christopher amato", "jonathan p how", "john vian"], "accepted": true, "id": "1703.06182"}
