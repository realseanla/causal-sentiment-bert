{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2013", "title": "A Method for Speeding Up Value Iteration in Partially Observable Markov Decision Processes", "abstract": "We present a technique for speeding up the convergence of value iteration for partially observable Markov decisions processes (POMDPs). The underlying idea is similar to that behind modified policy iteration for fully observable Markov decision processes (MDPs). The technique can be easily incorporated into any existing POMDP value iteration algorithms. Experiments have been conducted on several test problems with one POMDP value iteration algorithm called incremental pruning. We find that the technique can make incremental pruning run several orders of magnitude faster.", "histories": [["v1", "Wed, 23 Jan 2013 16:01:45 GMT  (292kb)", "http://arxiv.org/abs/1301.6751v1", "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)"]], "COMMENTS": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI1999)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["nevin lianwen zhang", "stephen s lee", "weihong zhang"], "accepted": false, "id": "1301.6751"}
