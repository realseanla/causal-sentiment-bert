{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2016", "title": "Playing SNES in the Retro Learning Environment", "abstract": "Mastering a video game requires skill, tactics and strategy. While these attributes may be acquired naturally by human players, teaching them to a computer program is a far more challenging task. In recent years, extensive research was carried out in the field of reinforcement learning and numerous algorithms were introduced, aiming to learn how to perform human tasks such as playing video games. As a results, the Arcade Learning Environment (ALE) has become a commonly used benchmark environment allowing algorithms to train on various Atari 2600 games. Most Atari games no longer pose a challenge to state-of-the-art algorithms. In this paper we introduce a new learning environment, the Retro Learning Environment --- RLE, based on the Super Nintendo Entertainment System (SNES). The environment is expandable, allowing for more video games and consoles to be easily added to the environment, while maintaining the same interface as ALE. Moreover, RLE is compatible with Python and Torch. SNES games pose a significant challenge to current algorithms due to their higher level of complexity and versatility. To overcome these challenges, we introduce a novel training method based on training two agents against each other.", "histories": [["v1", "Mon, 7 Nov 2016 18:33:38 GMT  (1316kb,D)", "http://arxiv.org/abs/1611.02205v1", null], ["v2", "Tue, 7 Feb 2017 18:50:50 GMT  (1308kb,D)", "http://arxiv.org/abs/1611.02205v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["nadav bhonker", "shai rozenberg", "itay hubara"], "accepted": false, "id": "1611.02205"}
