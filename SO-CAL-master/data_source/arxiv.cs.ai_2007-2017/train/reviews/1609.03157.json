{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2016", "title": "A centralized reinforcement learning method for multi-agent job scheduling in Grid", "abstract": "One of the main challenges in Grid systems is designing an adaptive, scalable, and model-independent method for job scheduling to achieve a desirable degree of load balancing and system efficiency. Centralized job scheduling methods have some drawbacks, such as single point of failure and lack of scalability. Moreover, decentralized methods require a coordination mechanism with limited communications. In this paper, we propose a multi-agent approach to job scheduling in Grid, named Centralized Learning Distributed Scheduling (CLDS), by utilizing the reinforcement learning framework. The CLDS is a model free approach that uses the information of jobs and their completion time to estimate the efficiency of resources. In this method, there are a learner agent and several scheduler agents that perform the task of learning and job scheduling with the use of a coordination strategy that maintains the communication cost at a limited level. We evaluated the efficiency of the CLDS method by designing and performing a set of experiments on a simulated Grid system under different system scales and loads. The results show that the CLDS can effectively balance the load of system even in large scale and heavy loaded Grids, while maintains its adaptive performance and scalability.", "histories": [["v1", "Sun, 11 Sep 2016 13:03:21 GMT  (558kb)", "http://arxiv.org/abs/1609.03157v1", null]], "reviews": [], "SUBJECTS": "cs.DC cs.AI", "authors": ["milad moradi"], "accepted": false, "id": "1609.03157"}
