{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Aug-2016", "title": "On Context-Dependent Clustering of Bandits", "abstract": "We investigate two context-dependent clustering techniques for content recommendation based on exploration-exploitation strategies in contextual multi-armed bandit settings. Our algorithms dynamically group users based on the items under consideration and, possibly, group items based on the similarity of the clusterings induced over the users. The resulting algorithm thus takes advantage of preference patterns in the data in a way akin to collaborative filtering methods. We provide an empirical analysis on extensive real-world datasets, showing scalability and increased prediction performance over state-of-the-art methods for clustering bandits. For one of the two algorithms we also give a regret analysis within a standard linear stochastic noise setting.", "histories": [["v1", "Sat, 6 Aug 2016 14:13:28 GMT  (1733kb)", "https://arxiv.org/abs/1608.03544v1", "This is a copy ofarXiv:1502.03473v3. It is necessary because the original file was overwritten with another paper. arXiv admin note: substantial text overlap witharXiv:1510.03164"], ["v2", "Mon, 27 Feb 2017 17:16:22 GMT  (214kb,D)", "http://arxiv.org/abs/1608.03544v2", null]], "COMMENTS": "This is a copy ofarXiv:1502.03473v3. It is necessary because the original file was overwritten with another paper. arXiv admin note: substantial text overlap witharXiv:1510.03164", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.IR stat.ML", "authors": ["claudio gentile", "shuai li", "purushottam kar", "alexandros karatzoglou", "giovanni zappella", "evans etrue"], "accepted": true, "id": "1608.03544"}
