{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jan-2016", "title": "Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis", "abstract": "An important problem for both graphics and vision is to synthesize novel views of a 3D object from a single image. This is particularly challenging due to the partial observability inherent in projecting a 3D object onto the image space, and the ill-posedness of inferring object shape and pose. However, we can train a neural network to address the problem if we restrict our attention to specific object categories (in our case faces and chairs) for which we can gather ample training data. In this paper, we propose a novel recurrent convolutional encoder-decoder network that is trained end-to-end on the task of rendering rotated objects starting from a single image. The recurrent structure allows our model to capture long-term dependencies along a sequence of transformations. We demonstrate the quality of its predictions for human faces on the Multi-PIE dataset and for a dataset of 3D chair models, and also show its ability to disentangle latent factors of variation (e.g., identity and pose) without using full supervision.", "histories": [["v1", "Tue, 5 Jan 2016 00:08:09 GMT  (6511kb,D)", "http://arxiv.org/abs/1601.00706v1", "This was published in NIPS 2015 conference"]], "COMMENTS": "This was published in NIPS 2015 conference", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV", "authors": ["jimei yang", "scott e reed", "ming-hsuan yang 0001", "honglak lee"], "accepted": true, "id": "1601.00706"}
