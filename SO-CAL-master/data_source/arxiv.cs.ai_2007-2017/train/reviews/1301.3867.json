{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Fast Planning in Stochastic Games", "abstract": "Stochastic games generalize Markov decision processes (MDPs) to a multiagent setting by allowing the state transitions to depend jointly on all player actions, and having rewards determined by multiplayer matrix games at each state. We consider the problem of computing Nash equilibria in stochastic games, the analogue of planning in MDPs. We begin by providing a generalization of finite-horizon value iteration that computes a Nash strategy for each player in generalsum stochastic games. The algorithm takes an arbitrary Nash selection function as input, which allows the translation of local choices between multiple Nash equilibria into the selection of a single global Nash equilibrium.", "histories": [["v1", "Wed, 16 Jan 2013 15:50:58 GMT  (278kb)", "http://arxiv.org/abs/1301.3867v1", "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)"]], "COMMENTS": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)", "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["michael kearns", "yishay mansour", "satinder singh"], "accepted": false, "id": "1301.3867"}
