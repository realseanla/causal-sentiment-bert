{"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Mar-2017", "title": "Towards Generalization and Simplicity in Continuous Control", "abstract": "This work shows that policies with simple linear and RBF parameterizations can be trained to solve a variety of continuous control tasks, including the OpenAI gym benchmarks. The performance of these trained policies are competitive with state of the art results, obtained with more elaborate parameterizations such as fully connected neural networks. Furthermore, existing training and testing scenarios are shown to be very limited and prone to over-fitting, thus giving rise to only trajectory-centric policies. Training with a diverse initial state distribution is shown to produce more global policies with better generalization. This allows for interactive control scenarios where the system recovers from large on-line perturbations; as shown in the supplementary video.", "histories": [["v1", "Wed, 8 Mar 2017 01:33:51 GMT  (1379kb,D)", "http://arxiv.org/abs/1703.02660v1", "Project page:this https URL"]], "COMMENTS": "Project page:this https URL", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.RO cs.SY", "authors": ["aravind rajeswaran", "kendall lowrey", "emanuel todorov", "sham kakade"], "accepted": true, "id": "1703.02660"}
