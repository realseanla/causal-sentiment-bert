{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Feb-2017", "title": "Stacked Thompson Bandits", "abstract": "We introduce Stacked Thompson Bandits (STB) for efficiently generating plans that are likely to satisfy a given bounded temporal logic requirement. STB uses a simulation for evaluation of plans, and takes a Bayesian approach to using the resulting information to guide its search. In particular, we show that stacking multiarmed bandits and using Thompson sampling to guide the action selection process for each bandit enables STB to generate plans that satisfy requirements with a high probability while only searching a fraction of the search space.", "histories": [["v1", "Tue, 28 Feb 2017 10:19:30 GMT  (621kb,D)", "http://arxiv.org/abs/1702.08726v1", "Accepted at SEsCPS @ ICSE 2017"]], "COMMENTS": "Accepted at SEsCPS @ ICSE 2017", "reviews": [], "SUBJECTS": "cs.SE cs.AI cs.SY", "authors": ["lenz belzner", "thomas gabor"], "accepted": false, "id": "1702.08726"}
