{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Nov-2016", "title": "Options Discovery with Budgeted Reinforcement Learning", "abstract": "We consider the problem of learning hierarchical policies for Reinforcement Learning able to discover options, an option corresponding to a sub-policy over a set of primitive actions. Different models have been proposed during the last decade that usually rely on a predefined set of options. We specifically address the problem of automatically discovering options in decision processes. We describe a new RL learning framework called Bi-POMDP, and a new learning model called Budgeted Option Neural Network (BONN) able to discover options based on a budgeted learning objective. Since Bi-POMDP are more general than POMDP, our model can also be used to discover options for classical RL tasks. The BONN model is evaluated on different classical RL problems, demonstrating both quantitative and qualitative interesting results.", "histories": [["v1", "Mon, 21 Nov 2016 15:05:55 GMT  (225kb,D)", "http://arxiv.org/abs/1611.06824v1", "Under review as a conference paper at ICLR 2017"], ["v2", "Tue, 24 Jan 2017 17:06:24 GMT  (273kb,D)", "http://arxiv.org/abs/1611.06824v2", "Under review as a conference paper at ICLR 2017"], ["v3", "Wed, 22 Feb 2017 13:12:33 GMT  (567kb,D)", "http://arxiv.org/abs/1611.06824v3", "Under review as a conference paper at IJCAI 2017"]], "COMMENTS": "Under review as a conference paper at ICLR 2017", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["aur\\'elia l\\'eon", "ludovic denoyer"], "accepted": false, "id": "1611.06824"}
