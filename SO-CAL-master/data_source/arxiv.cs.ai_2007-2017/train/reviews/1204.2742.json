{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Apr-2012", "title": "Video In Sentences Out", "abstract": "We present a system that produces sentential descriptions of video: who did what to whom, and where and how they did it. Action class is rendered as a verb, participant objects as noun phrases, properties of those objects as adjectival modifiers in those noun phrases,spatial relations between those participants as prepositional phrases, and characteristics of the event as prepositional-phrase adjuncts and adverbial modifiers. Extracting the information needed to render these linguistic entities requires an approach to event recognition that recovers object tracks, the track-to-role assignments, and changing body posture.", "histories": [["v1", "Thu, 12 Apr 2012 14:47:44 GMT  (4210kb,D)", "http://arxiv.org/abs/1204.2742v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["andrei barbu", "alexander bridge", "zachary burchill", "dan coroian", "sven dickinson", "sanja fidler", "aaron michaux", "sam mussman", "siddharth narayanaswamy", "dhaval salvi", "lara schmidt", "jiangnan shangguan", "jeffrey mark siskind", "jarrell waggoner", "song wang", "jinlian wei", "yifan yin", "zhiqi zhang"], "accepted": false, "id": "1204.2742"}
