{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2017", "title": "Autonomous Quadrotor Landing using Deep Reinforcement Learning", "abstract": "Landing an unmanned aerial vehicle on a ground marker is an open problem despite the effort of the research community. Previous attempts mostly focused on the analysis of hand-crafted geometric features and the use of external sensors in order to allow the vehicle to approach the land-pad. In this article, we propose a method based on deep reinforcement learning which only requires low-resolution images taken from a down-looking camera in order to identify the position of the marker and land the quadrotor on it. The proposed approach is based on a hierarchy of Deep Q-Networks (DQNs) which are used as high-level control policy for the navigation toward the marker. We implemented different technical solutions, such as the combination of vanilla and double DQNs trained using a form of prioritized buffer replay which separates experiences in multiple containers. Learning is achieved without any human supervision, giving to the agent an high-level feedback. The results show that the quadrotor can autonomously accomplish landing on a large variety of simulated environments and with relevant noise. In some conditions the DQN outperformed human pilots tested in the same environment.", "histories": [["v1", "Mon, 11 Sep 2017 11:39:47 GMT  (6173kb,D)", "http://arxiv.org/abs/1709.03339v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.RO", "authors": ["riccardo polvara", "massimiliano patacchiola", "sanjay sharma", "jian wan", "rew manning", "robert sutton", "angelo cangelosi"], "accepted": false, "id": "1709.03339"}
