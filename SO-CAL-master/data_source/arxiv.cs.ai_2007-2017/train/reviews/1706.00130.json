{"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2017", "title": "Teaching Machines to Describe Images via Natural Language Feedback", "abstract": "Robots will eventually be part of every household. It is thus critical to enable algorithms to learn from and be guided by non-expert users. In this paper, we bring a human in the loop, and enable a human teacher to give feedback to a learning agent in the form of natural language. We argue that a descriptive sentence can provide a much stronger learning signal than a numeric reward in that it can easily point to where the mistakes are and how to correct them. We focus on the problem of image captioning in which the quality of the output can easily be judged by non-experts. We propose a hierarchical phrase-based captioning model trained with policy gradients, and design a feedback network that provides reward to the learner by conditioning on the human-provided feedback. We show that by exploiting descriptive feedback our model learns to perform better than when given independently written human captions.", "histories": [["v1", "Thu, 1 Jun 2017 00:24:55 GMT  (3938kb,D)", "https://arxiv.org/abs/1706.00130v1", "13 pages"], ["v2", "Mon, 5 Jun 2017 16:47:40 GMT  (3938kb,D)", "http://arxiv.org/abs/1706.00130v2", "13 pages"]], "COMMENTS": "13 pages", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.CV cs.HC", "authors": ["huan ling", "sanja fidler"], "accepted": true, "id": "1706.00130"}
