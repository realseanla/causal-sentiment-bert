{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Oct-2016", "title": "Surprisal-Driven Zoneout", "abstract": "We propose a novel method of regularization for recurrent neural networks called suprisal-driven zoneout. In this method, states \\textit{zoneout} (maintain their previous value rather than updating), when the \\textit{suprisal} (discrepancy between the last state's prediction and target) is small. Thus regularization is adaptive and input-driven on a per-neuron basis. We demonstrate the effectiveness of this idea by achieving state-of-the-art bits per character of 1.32 on the Hutter Prize Wikipedia dataset, significantly reducing the gap to the best known highly-engineered compression methods.", "histories": [["v1", "Mon, 24 Oct 2016 22:38:52 GMT  (1234kb,D)", "http://arxiv.org/abs/1610.07675v1", "Submitted to Continual Learning and Deep Networks Workshop NIPS 2016"], ["v2", "Fri, 28 Oct 2016 19:55:16 GMT  (1234kb,D)", "http://arxiv.org/abs/1610.07675v2", "Submitted to Continual Learning and Deep Networks Workshop NIPS 2016"], ["v3", "Mon, 31 Oct 2016 15:18:11 GMT  (1234kb,D)", "http://arxiv.org/abs/1610.07675v3", "Submitted to Continual Learning and Deep Networks Workshop NIPS 2016"], ["v4", "Thu, 3 Nov 2016 17:09:23 GMT  (1234kb,D)", "http://arxiv.org/abs/1610.07675v4", "Submitted to Continual Learning and Deep Networks Workshop NIPS 2016"], ["v5", "Thu, 24 Nov 2016 06:40:26 GMT  (1242kb,D)", "http://arxiv.org/abs/1610.07675v5", "To be published at the Continual Learning and Deep Networks Workshop NIPS 2016"], ["v6", "Tue, 13 Dec 2016 23:32:24 GMT  (1242kb,D)", "http://arxiv.org/abs/1610.07675v6", "Published at the Continual Learning and Deep Networks Workshop; NIPS 2016"]], "COMMENTS": "Submitted to Continual Learning and Deep Networks Workshop NIPS 2016", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.NE", "authors": ["kamil rocki", "tomasz kornuta", "tegan maharaj"], "accepted": false, "id": "1610.07675"}
