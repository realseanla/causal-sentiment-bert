{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Feb-2012", "title": "Extended Mixture of MLP Experts by Hybrid of Conjugate Gradient Method and Modified Cuckoo Search", "abstract": "This paper investigates a new method for improving the learning algorithm of Mixture of Experts (ME) model using a hybrid of Modified Cuckoo Search (MCS) and Conjugate Gradient (CG) as a second order optimization technique. The CG technique is combined with Back-Propagation (BP) algorithm to yield a much more efficient learning algorithm for ME structure. In addition, the experts and gating networks in enhanced model are replaced by CG based Multi-Layer Perceptrons (MLPs) to provide faster and more accurate learning. The CG is considerably depends on initial weights of connections of Artificial Neural Network (ANN), so, a metaheuristic algorithm, the so-called Modified Cuckoo Search is applied in order to select the optimal weights. The performance of proposed method is compared with Gradient Decent Based ME (GDME) and Conjugate Gradient Based ME (CGME) in classification and regression problems. The experimental results show that hybrid MSC and CG based ME (MCS-CGME) has faster convergence and better performance in utilized benchmark data sets.", "histories": [["v1", "Fri, 17 Feb 2012 11:49:56 GMT  (205kb)", "http://arxiv.org/abs/1202.3887v1", "13 pages, 2 figures"]], "COMMENTS": "13 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["hamid salimi", "davar giveki", "mohammad ali soltanshahi", "javad hatami"], "accepted": false, "id": "1202.3887"}
