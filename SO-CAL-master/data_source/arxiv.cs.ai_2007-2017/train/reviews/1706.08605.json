{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Jun-2017", "title": "Developing Bug-Free Machine Learning Systems With Formal Mathematics", "abstract": "Noisy data, non-convex objectives, model misspecification, and numerical instability can all cause undesired behaviors in machine learning systems. As a result, detecting actual implementation errors can be extremely difficult. We demonstrate a methodology in which developers use an interactive proof assistant to both implement their system and to state a formal theorem defining what it means for their system to be correct. The process of proving this theorem interactively in the proof assistant exposes all implementation errors since any error in the program would cause the proof to fail. As a case study, we implement a new system, Certigrad, for optimizing over stochastic computation graphs, and we generate a formal (i.e. machine-checkable) proof that the gradients sampled by the system are unbiased estimates of the true mathematical gradients. We train a variational autoencoder using Certigrad and find the performance comparable to training the same model in TensorFlow.", "histories": [["v1", "Mon, 26 Jun 2017 21:30:02 GMT  (93kb,D)", "http://arxiv.org/abs/1706.08605v1", "To appear at the Thirty-fourth International Conference on Machine Learning (ICML) 2017"]], "COMMENTS": "To appear at the Thirty-fourth International Conference on Machine Learning (ICML) 2017", "reviews": [], "SUBJECTS": "cs.SE cs.AI", "authors": ["daniel selsam", "percy liang", "david l dill"], "accepted": true, "id": "1706.08605"}
