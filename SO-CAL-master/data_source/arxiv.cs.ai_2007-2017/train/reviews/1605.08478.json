{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2016", "title": "Model-Free Imitation Learning with Policy Optimization", "abstract": "In imitation learning, an agent learns how to behave in an environment with an unknown cost function by mimicking expert demonstrations. Existing imitation learning algorithms typically involve solving a sequence of planning or reinforcement learning problems. Such algorithms are therefore not directly applicable to large, high-dimensional environments, and their performance can significantly degrade if the planning problems are not solved to optimality. Under the apprenticeship learning formalism, we develop alternative model-free algorithms for finding a parameterized stochastic policy that performs at least as well as an expert policy on an unknown cost function, based on sample trajectories from the expert. Our approach, based on policy gradients, scales to large continuous environments with guaranteed convergence to local minima.", "histories": [["v1", "Thu, 26 May 2016 23:43:32 GMT  (459kb,D)", "http://arxiv.org/abs/1605.08478v1", "In Proceedings of the 33rd International Conference on Machine Learning, 2016"]], "COMMENTS": "In Proceedings of the 33rd International Conference on Machine Learning, 2016", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["jonathan ho", "jayesh k gupta", "stefano ermon"], "accepted": true, "id": "1605.08478"}
