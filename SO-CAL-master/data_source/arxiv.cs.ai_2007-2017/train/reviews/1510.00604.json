{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Oct-2015", "title": "Online Vision- and Action-Based Object Classification Using Both Symbolic and Subsymbolic Knowledge Representations", "abstract": "If a robot is supposed to roam an environment and interact with objects, it is often necessary to know all possible objects in advance, so that a database with models of all objects can be generated for visual identification. However, this constraint cannot always be fulfilled. Due to that reason, a model based object recognition cannot be used to guide the robot's interactions. Therefore, this paper proposes a system that analyzes features of encountered objects and then uses these features to compare unknown objects to already known ones. From the resulting similarity appropriate actions can be derived. Moreover, the system enables the robot to learn object categories by grouping similar objects or by splitting existing categories. To represent the knowledge a hybrid form is used, consisting of both symbolic and subsymbolic representations.", "histories": [["v1", "Fri, 2 Oct 2015 14:08:36 GMT  (267kb,D)", "http://arxiv.org/abs/1510.00604v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["laura steinert", "jens hoefinghoff", "josef pauli"], "accepted": false, "id": "1510.00604"}
