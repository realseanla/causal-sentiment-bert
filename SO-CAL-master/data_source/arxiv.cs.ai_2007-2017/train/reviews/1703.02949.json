{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Mar-2017", "title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where two agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of \"analogy making\", or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "histories": [["v1", "Wed, 8 Mar 2017 18:09:32 GMT  (1041kb,D)", "http://arxiv.org/abs/1703.02949v1", "Published as a conference paper at ICLR 2017"]], "COMMENTS": "Published as a conference paper at ICLR 2017", "reviews": [], "SUBJECTS": "cs.AI cs.RO", "authors": ["abhishek gupta", "coline devin", "yuxuan liu", "pieter abbeel", "sergey levine"], "accepted": true, "id": "1703.02949"}
