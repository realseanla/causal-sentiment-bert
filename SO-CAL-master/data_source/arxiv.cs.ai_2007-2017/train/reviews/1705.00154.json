{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Apr-2017", "title": "Classical Planning in Deep Latent Space: Bridging the Subsymbolic-Symbolic Boundary", "abstract": "Current domain-independent, classical planners require symbolic models of the problem domain and instance as input, resulting in a knowledge acquisition bottleneck. Meanwhile, although recent work in deep learning has achieved impressive results in many fields, the knowledge is encoded in a subsymbolic representation which cannot be directly used by symbolic systems such as planners. We propose LatPlan, an integrated architecture combining deep learning and a classical planner. Given a set of unlabeled training image pairs showing allowed actions in the problem domain, and a pair of images representing the start and goal states, LatPlan uses a Variational Autoencoder to generate a discrete latent vector from the images, based on which a PDDL model can be constructed and then solved by an off-the-shelf planner. We evaluate LatPlan using image-based versions of 3 planning domains: 8-puzzle, LightsOut, and Towers of Hanoi.", "histories": [["v1", "Sat, 29 Apr 2017 08:22:29 GMT  (1768kb,D)", "http://arxiv.org/abs/1705.00154v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["masataro asai", "alex fukunaga"], "accepted": false, "id": "1705.00154"}
