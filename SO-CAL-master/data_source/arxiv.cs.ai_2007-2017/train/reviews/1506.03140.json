{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2015", "title": "On-the-Job Learning with Bayesian Decision Theory", "abstract": "How can we deploy a high-accuracy system starting with zero training examples? We consider an \"on-the-job\" setting, where as inputs arrive, we use crowdsourcing to resolve uncertainty where needed and output our prediction when confident. As the model improves over time, the reliance on crowdsourcing queries decreases. We cast our setting as a stochastic game based on Bayesian decision theory, which allows us to balance latency, cost, and accuracy objectives in a principled way. Computing the optimal policy is intractable, so we develop an approximation based on Monte Carlo Tree Search. We tested our approach across three datasets---named-entity recognition, sentiment classification, and image classification. On the NER task we obtained a 6--7 fold reduction in cost compared to full human annotation. We also achieve a 17% F$_1$ improvement over having a single human label the whole set, and a 28% F$_1$ improvement over online learning.", "histories": [["v1", "Wed, 10 Jun 2015 00:40:34 GMT  (2894kb,D)", "https://arxiv.org/abs/1506.03140v1", null], ["v2", "Mon, 7 Dec 2015 21:44:07 GMT  (1717kb,D)", "http://arxiv.org/abs/1506.03140v2", "As appearing in NIPS 2015"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["keenon werling", "arun tejasvi chaganty", "percy liang", "christopher d manning"], "accepted": true, "id": "1506.03140"}
