{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Apr-2016", "title": "Planning with Information-Processing Constraints and Model Uncertainty in Markov Decision Processes", "abstract": "Information-theoretic principles for learning and acting have been proposed to solve particular classes of Markov Decision Problems. Mathematically, such approaches are governed by a variational free energy principle and allow solving MDP planning problems with information-processing constraints expressed in terms of a Kullback-Leibler divergence with respect to a reference distribution. Here we consider a generalization of such MDP planners by taking model uncertainty into account. As model uncertainty can also be formalized as an information-processing constraint, we can derive a unified solution from a single generalized variational principle. We provide a generalized value iteration scheme together with a convergence proof. As limit cases, this generalized scheme includes standard value iteration with a known model, Bayesian MDP planning, and robust planning. We demonstrate the benefits of this approach in a grid world simulation.", "histories": [["v1", "Thu, 7 Apr 2016 17:12:07 GMT  (276kb,D)", "http://arxiv.org/abs/1604.02080v1", "16 pages, 3 figures"]], "COMMENTS": "16 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.AI cs.SY", "authors": ["jordi grau-moya", "felix leibfried", "tim genewein", "daniel a braun"], "accepted": false, "id": "1604.02080"}
