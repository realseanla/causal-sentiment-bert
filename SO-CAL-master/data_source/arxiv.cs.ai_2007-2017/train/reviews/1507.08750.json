{"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Jul-2015", "title": "Action-Conditional Video Prediction using Deep Networks in Atari Games", "abstract": "Motivated by vision-based reinforcement learning (RL) problems, in particular Atari games from the recent benchmark Aracade Learning Environment (ALE), we consider spatio-temporal prediction problems where future (image-)frames are dependent on control variables or actions as well as previous frames. While not composed of natural scenes, frames in Atari games are high-dimensional in size, can involve tens of objects with one or more objects being controlled by the actions directly and many other objects being influenced indirectly, can involve entry and departure of objects, and can involve deep partial observability. We propose and evaluate two deep neural network architectures that consist of encoding, action-conditional transformation, and decoding layers based on convolutional neural networks and recurrent neural networks. Experimental results show that the proposed architectures are able to generate visually-realistic frames that are also useful for control over approximately 100-step action-conditional futures in some games. To the best of our knowledge, this paper is the first to make and evaluate long-term predictions on high-dimensional video conditioned by control inputs.", "histories": [["v1", "Fri, 31 Jul 2015 04:43:30 GMT  (4950kb,D)", "http://arxiv.org/abs/1507.08750v1", "9 pages (main) and 33 pages (supplementary material)"], ["v2", "Tue, 22 Dec 2015 04:26:54 GMT  (5705kb,D)", "http://arxiv.org/abs/1507.08750v2", "Published at NIPS 2015 (Advances in Neural Information Processing Systems 28)"]], "COMMENTS": "9 pages (main) and 33 pages (supplementary material)", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV", "authors": ["junhyuk oh", "xiaoxiao guo", "honglak lee", "richard l lewis", "satinder p singh"], "accepted": true, "id": "1507.08750"}
