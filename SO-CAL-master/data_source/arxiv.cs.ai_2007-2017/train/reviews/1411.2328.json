{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Nov-2014", "title": "Modeling Word Relatedness in Latent Dirichlet Allocation", "abstract": "Standard LDA model suffers the problem that the topic assignment of each word is independent and word correlation hence is neglected. To address this problem, in this paper, we propose a model called Word Related Latent Dirichlet Allocation (WR-LDA) by incorporating word correlation into LDA topic models. This leads to new capabilities that standard LDA model does not have such as estimating infrequently occurring words or multi-language topic modeling. Experimental results demonstrate the effectiveness of our model compared with standard LDA.", "histories": [["v1", "Mon, 10 Nov 2014 05:24:41 GMT  (1135kb,D)", "http://arxiv.org/abs/1411.2328v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["xun wang"], "accepted": false, "id": "1411.2328"}
