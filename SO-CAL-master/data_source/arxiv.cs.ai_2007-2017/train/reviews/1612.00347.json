{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2016", "title": "Bootstrapping incremental dialogue systems: using linguistic knowledge to learn from minimal data", "abstract": "We present a method for inducing new dialogue systems from very small amounts of unannotated dialogue data, showing how word-level exploration using Reinforcement Learning (RL), combined with an incremental and semantic grammar - Dynamic Syntax (DS) - allows systems to discover, generate, and understand many new dialogue variants. The method avoids the use of expensive and time-consuming dialogue act annotations, and supports more natural (incremental) dialogues than turn-based systems. Here, language generation and dialogue management are treated as a joint decision/optimisation problem, and the MDP model for RL is constructed automatically. With an implemented system, we show that this method enables a wide range of dialogue variations to be automatically captured, even when the system is trained from only a single dialogue. The variants include question-answer pairs, over- and under-answering, self- and other-corrections, clarification interaction, split-utterances, and ellipsis. This generalisation property results from the structural knowledge and constraints present within the DS grammar, and highlights some limitations of recent systems built using machine learning techniques only.", "histories": [["v1", "Thu, 1 Dec 2016 16:49:04 GMT  (488kb,D)", "http://arxiv.org/abs/1612.00347v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.HC", "authors": ["dimitrios kalatzis", "arash eshghi", "oliver lemon"], "accepted": false, "id": "1612.00347"}
