{"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Feb-2016", "title": "Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks", "abstract": "This paper presents to the best of our knowledge the first end-to-end object tracking approach which directly maps from raw sensor input to object tracks in sensor space without requiring any feature engineering or system identification in the form of plant or sensor models. Specifically, our system accepts a stream of raw sensor data at one end and, in real-time, produces an estimate of the entire environment state at the output including even occluded objects. We achieve this by framing the problem as a deep learning task and exploit sequence models in the form of recurrent neural networks to learn a mapping from sensor measurements to object tracks. In particular, we propose a learning method based on a form of input dropout which allows learning in an unsupervised manner, only based on raw, occluded sensor data without access to ground-truth annotations. We demonstrate our approach using a synthetic dataset designed to mimic the task of tracking objects in 2D laser data -- as commonly encountered in robotics applications -- and show that it learns to track many dynamic objects despite occlusions and the presence of sensor noise.", "histories": [["v1", "Tue, 2 Feb 2016 16:10:16 GMT  (379kb,D)", "http://arxiv.org/abs/1602.00991v1", "Published in The Thirtieth AAAI Conference on Artificial Intelligence (AAAI-16) Video:this https URLCode:this http URL"], ["v2", "Tue, 8 Mar 2016 22:09:05 GMT  (379kb,D)", "http://arxiv.org/abs/1602.00991v2", "Published in The Thirtieth AAAI Conference on Artificial Intelligence (AAAI-16), Video:this https URL, Code:this http URL"]], "COMMENTS": "Published in The Thirtieth AAAI Conference on Artificial Intelligence (AAAI-16) Video:this https URLCode:this http URL", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV cs.NE cs.RO", "authors": ["peter ondruska", "ingmar posner"], "accepted": true, "id": "1602.00991"}
