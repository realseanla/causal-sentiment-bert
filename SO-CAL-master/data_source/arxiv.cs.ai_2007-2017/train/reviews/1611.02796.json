{"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2016", "title": "Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control", "abstract": "Sequence models can be trained using supervised learning and a next-step prediction objective. This approach, however, suffers from known failure modes. For example, it is notoriously difficult to ensure multi-step generated sequences have coherent global structure. Motivated by the fact that reinforcement learning (RL) can be used to impose arbitrary properties on generated data by choosing appropriate reward functions, in this paper we propose a novel approach for sequence training which combines Maximum Likelihood (ML) and RL training. We refine a sequence predictor by optimizing for some imposed reward functions, while maintaining good predictive properties learned from data. We propose efficient ways to solve this by augmenting deep Q-learning with a cross-entropy reward and deriving novel off-policy methods for RNNs from stochastic optimal control (SOC). We explore the usefulness of our approach in the context of music generation. An LSTM is trained on a large corpus of songs to predict the next note in a musical sequence. This Note-RNN is then refined using RL, where the reward function is a combination of rewards based on rules of music theory, as well as the output of another trained Note-RNN. We show that by combining ML and RL, this RL Tuner method can not only produce more pleasing melodies, but that it can significantly reduce unwanted behaviors and failure modes of the RNN.", "histories": [["v1", "Wed, 9 Nov 2016 01:46:32 GMT  (406kb,D)", "http://arxiv.org/abs/1611.02796v1", null], ["v2", "Thu, 10 Nov 2016 18:54:17 GMT  (406kb,D)", "http://arxiv.org/abs/1611.02796v2", "Update affiliations"], ["v3", "Wed, 7 Dec 2016 14:42:30 GMT  (405kb,D)", "http://arxiv.org/abs/1611.02796v3", "Update acknowledgements"], ["v4", "Thu, 12 Jan 2017 02:18:20 GMT  (409kb,D)", "http://arxiv.org/abs/1611.02796v4", "Update acknowledgements"], ["v5", "Mon, 27 Feb 2017 20:38:06 GMT  (404kb,D)", "http://arxiv.org/abs/1611.02796v5", "Complete rewrite; new results on computational molecular generation"], ["v6", "Sat, 4 Mar 2017 19:38:01 GMT  (405kb,D)", "http://arxiv.org/abs/1611.02796v6", "Add citation for related work"], ["v7", "Thu, 6 Apr 2017 15:02:04 GMT  (405kb,D)", "http://arxiv.org/abs/1611.02796v7", "Add citation for related work"], ["v8", "Thu, 4 May 2017 17:11:45 GMT  (405kb,D)", "http://arxiv.org/abs/1611.02796v8", "Add citation for related work"], ["v9", "Mon, 16 Oct 2017 21:31:31 GMT  (429kb,D)", "http://arxiv.org/abs/1611.02796v9", "Add supplementary material"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["natasha jaques", "shixiang gu", "dzmitry bahdanau", "jos\u00e9 miguel hern\u00e1ndez-lobato", "richard e turner", "douglas eck"], "accepted": true, "id": "1611.02796"}
