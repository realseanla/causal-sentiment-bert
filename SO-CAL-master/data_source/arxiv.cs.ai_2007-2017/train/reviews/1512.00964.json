{"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Dec-2015", "title": "Modeling Human Understanding of Complex Intentional Action with a Bayesian Nonparametric Subgoal Model", "abstract": "Most human behaviors consist of multiple parts, steps, or subtasks. These structures guide our action planning and execution, but when we observe others, the latent structure of their actions is typically unobservable, and must be inferred in order to learn new skills by demonstration, or to assist others in completing their tasks. For example, an assistant who has learned the subgoal structure of a colleague's task can more rapidly recognize and support their actions as they unfold. Here we model how humans infer subgoals from observations of complex action sequences using a nonparametric Bayesian model, which assumes that observed actions are generated by approximately rational planning over unknown subgoal sequences. We test this model with a behavioral experiment in which humans observed different series of goal-directed actions, and inferred both the number and composition of the subgoal sequences associated with each goal. The Bayesian model predicts human subgoal inferences with high accuracy, and significantly better than several alternative models and straightforward heuristics. Motivated by this result, we simulate how learning and inference of subgoals can improve performance in an artificial user assistance task. The Bayesian model learns the correct subgoals from fewer observations, and better assists users by more rapidly and accurately inferring the goal of their actions than alternative approaches.", "histories": [["v1", "Thu, 3 Dec 2015 06:44:35 GMT  (635kb,D)", "http://arxiv.org/abs/1512.00964v1", "Accepted at AAAI 16"]], "COMMENTS": "Accepted at AAAI 16", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ryo nakahashi", "chris l baker", "joshua b tenenbaum"], "accepted": true, "id": "1512.00964"}
