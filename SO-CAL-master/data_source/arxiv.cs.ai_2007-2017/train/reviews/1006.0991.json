{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jun-2010", "title": "Variational Program Inference", "abstract": "We introduce a framework for representing a variety of interesting problems as inference over the execution of probabilistic model programs. We represent a \"solution\" to such a problem as a guide program which runs alongside the model program and influences the model program's random choices, leading the model program to sample from a different distribution than from its priors. Ideally the guide program influences the model program to sample from the posteriors given the evidence. We show how the KL- divergence between the true posterior distribution and the distribution induced by the guided model program can be efficiently estimated (up to an additive constant) by sampling multiple executions of the guided model program. In addition, we show how to use the guide program as a proposal distribution in importance sampling to statistically prove lower bounds on the probability of the evidence and on the probability of a hypothesis and the evidence. We can use the quotient of these two bounds as an estimate of the conditional probability of the hypothesis given the evidence. We thus turn the inference problem into a heuristic search for better guide programs.", "histories": [["v1", "Fri, 4 Jun 2010 20:55:04 GMT  (192kb)", "http://arxiv.org/abs/1006.0991v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["georges harik", "noam shazeer"], "accepted": false, "id": "1006.0991"}
