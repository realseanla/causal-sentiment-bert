{
  "name" : "1611.06134.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Team–maxmin equilibrium: efficiency bounds and algorithms",
    "authors" : [ "Nicola Basilico", "Andrea Celli", "Giuseppe De Nittis", "Nicola Gatti" ],
    "emails" : [ "nicola.basilico@unimi.it", "nicola.gatti}@polimi.it" ],
    "sections" : [ {
      "heading" : "Introduction",
      "text" : "The computational study of game–theoretic solutions concepts is among the most important challenges addressed in the last decade of Computer Science (Deng, Papadimitriou, and Safra 2002). These problems acquired particular relevance in Artificial Intelligence, where the goal is to design physical or software agents that must behave optimally in strategic situations. In addition to the well– known Nash equilibrium (Nash 1951), other solution concepts received attention in the Artificial Intelligence literature thanks to their application in security domains. Examples include Maxmin equilibrium for zero–sum games under various forms of constraints over the actions of the players (Jain et al. 2010) and Stackelberg (a.k.a. leader–follower) equilibrium (Conitzer and Sandholm 2006).\nWhile a large part of the literature focuses on 2–player games, few results are known about games with more players—except for games with a very specific structure, e.g., congestion games (Nisan et al. 2007). In this paper, we focus on the Team–maxmin equilibrium proposed by (von\nCopyright c© 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nStengel and Koller 1997). It applies to zero–sum games between a team and an adversary. The team is defined as a set of players with the same utility function UT and without the capability of synchronizing their actions. The adversary is a single player with utility function ´UT . These games can model many realistic security scenarios, for example those where multiple non–coordinating agents share the common objective of defending an environment against a malicious attacker. In (Jiang et al. 2013), a security setting of such type is studied and an analysis of the price of mis– coordination in the specific proposed security games is conducted. The Team–maxmin equilibrium plays a crucial role also in infinitely repeated games and role assignment problems (Moon and Conitzer 2016), where it is necessary to compute threat points. The current approach to tackle these problems, in games with more than two players, is considering the correlated threat point (Kontogiannis and Spirakis 2008) or employing approximating algorithms that avoid the use of linear programming (Andersen and Conitzer 2013). Our techniques allow the computation punishment strategies (leading to the threat points) in the general scenario in which players, other than the defector, cannot coordinate strategy execution.\nThe study of Team–maxmin equilibrium is almost completely unexplored. It is known that it always exists, it is unique except for degeneracies, and it is the best Nash equilibrium for the team, but, to the best of our knowledge, only two computational works deal with this solution concept. (Borgs et al. 2010) show that the Minmax value (equivalently the Team–maxmin value) is inapproximable in additive sense within 3m2 even in 3–player games with m actions per player and binary payoffs (but nothing is known about the membership to APX class or some super class); (Hansen et al. 2008) strengthen the previous complexity result and provide a quasi–polynomial time –approximation (in additive sense) algorithm. Only (Lim 1997; Alpern and Lim 1998) deal with the mathematical derivation for a specific class of games with an adversary, i.e., rendezvous– evasion games. Instead, a number of works deal with team games without adversary. We just cite a few for the sake of completeness. Team games were first proposed in (Palfrey and Rosenthal 1983) as voting games, then studied in repeated and absorbing games to understand the interaction among the players (Bornstein, Erev, and Goren 1994; ar X iv :1\n61 1.\n06 13\n4v 1\n[ cs\n.A I]\n1 8\nN ov\n2 01\n6\nBornstein, Winter, and Goren 1996; Bornstein, Budescu, and Zamir 1997; Solan 2000) and more recently in Markov games with noisy payoffs (Wang and Sandholm 2002).\nOriginal contributions We provide two main contributions. First, we study the relationship, in terms of efficiency for the team, between Nash equilibrium (i.e., when players are not teammates), Team–maxmin equilibrium, and Correlated–team maxmin equilibrium (i.e., the Maxmin equilibrium when all the team members can play in correlated strategies and then can synchronize the execution of their actions). We show that, even in the same instances with binary payoffs, the worst Nash equilibrium may be arbitrarily worse than the Team–maxmin equilibrium that, in its turn, may be arbitrarily worse (in this case only asymptotically) than the Correlated–team maxmin equilibrium. We provide exact bounds for the inefficiency and we design an algorithm that, given a correlated strategy of the team, returns in polynomial time a mixed strategy of the team minimizing the worst–case ratio between the utility given by the correlated strategy and the utility given by the mixed strategy. Second, we provide some algorithms to find and/or approximate the Team–maxmin equilibrium, we discuss their theoretical guarantees and evaluate them in practice by means of a standard testbed (Nudelman et al. 2004). We also identify the limits of such algorithms and discuss which ones are the best to be adopted depending on the instance to be solved. For the sake of presentation, the proofs of the theorems are presented in the Appendices."
    }, {
      "heading" : "Preliminaries",
      "text" : "A normal–form game is a tuple pN,A,Uq where: N “ t1, 2, . . . , nu is the set of players; A “ Ś\niPN Ai is the set of player i’s actions, where Ai “ ta1, a2, . . . , amiu; U “ tU1, U2, . . . , Unu is the utility function of player i, where Ui : A Ñ R. A strategy profile is defined as s “ ps1, s2, . . . , snq, where si P ∆pAiq is player i’s mixed strategy and ∆pAiq is the set of all the probability distributions over Ai. As customary, ´i denotes the set containing all the players except player i. We study games in which the set of players T “ t1, 2, . . . , n ´ 1u constitutes a team whose members have the same utility function UT . Player n is an adversary of the team and her utility function is ´UT .\nWhen the teammates cannot coordinate at all and therefore no player can communicate with the others, and each player takes decisions independently, the appropriate solution concept is the Nash equilibrium, which prescribes a strategy profile where each player i’s strategy si is a best response to s´i. In 2–player zero–sum games, a Nash equilibrium is a pair of Maxmin/Minmax strategies and can be computed in polynomial time. In arbitrary games, the computation of a Nash equilibrium is PPAD–complete even when the number of players is fixed (Daskalakis, Goldberg, and Papadimitriou 2009). Instead, when the teammates can coordinate themselves, we distinguish two forms of coordinations: correlated, in which a correlating device decides a joint action (i.e., an action profile specifying one action per teammate) and then communicates each teammate her action, and non–correlated, in which each player plays independently from the others.\nWhen the coordination is non–correlated, players are subject to the inability of correlating their actions, and their strategy si is mixed, as defined above for a generic normal– form game. In other words, teammates can jointly decide their strategies, but they cannot synchronize their actions, which must then be drawn independently. The appropriate solution concept for such setting is the Team–maxmin equilibrium.\nA Team–maxmin equilibrium is a Nash equilibrium with the properties of being unique (except for degeneracies) and the best one for the team. These property are very appealing in real–world settings, since they allow to avoid the equilibrium selection problem which affects the Nash equilibrium. In security applications, for instance, the equilibrium uniqueness allows to perfectly forecast the behavior of the attacker (adversary). When the number of players is given, finding a Team–maxmin equilibrium is FNP– hard and the Team–maxmin value is inapproximable in additive sense even when the payoffs are binary (Hansen et al. 2008). 1 In (Hansen et al. 2008), the authors provide a quasi–polynomial–time –approximation (in additive sense) algorithm. Furthermore, a Team–maxmin equilibrium may contain irrational probabilities even with 2 teammates and 3 different values of payoffs.2 It is not known any experimental evaluation of algorithms for finding the Team–maxmin equilibrium.\nWhen players can synchronize their actions, the team strategy is said to be correlated. Given the set of team action profiles defined as AT “ Ś\niPT Ai, a correlated team strategy is defined as p P ∆pAT q. In other words, teammates can jointly decide and execute their strategy. The team is then equivalent to a single player whose actions are joint team action profiles. In such case, the appropriate solution concept for the team and the adversary is a pair of Maxmin/Minmax strategies that, for the sake of clarity, we call in this paper Correlated–team maxmin equilibrium. This equilibrium can be found by means of linear programming since it can be formulated as a maxmin problem in which the max player’s action space is given by the Cartesian product of the action space of each teammate. Notice that the size of the input is exponential in the number of teammates and therefore approximation algorithms for games with many team members are necessary in practice.\nFurthermore, it is not known the price—in terms of inefficiency—paid by a team due to the inability of synchronizing the execution of their actions. This would allow to understand how the Team–maxmin equilibrium is inefficient w.r.t. the Correlated–team maxmin equilibrium, or equivalently, how well the Team-maxmin equilibrium approximates the Correlated-team maxmin equilibrium. Another open problem is studying the gain a set of players shar-\n1Rigorously speaking, (Hansen et al. 2008) studies Minmax strategy when there is a single max player and multiple min players. The problem of finding the Team–maxmin equilibrium in zero– sum adversarial team games can be formulated as the problem of finding such Minmax strategy and vice versa.\n2The proof, provided in (Hansen et al. 2008), contains a minor flaw. In the Appendices, we provide a correct revision of the proof with all the calculations, omitted in the original proof.\ning the same goal would have in forming a team and coordinating their mixed strategies (i.e., how is the Nash equilibrium inefficient w.r.t. the Team-maxmin equilibrium, or equivalently, how well the Nash equilibrium approximates the Team-maxmin equilibrium).\nNash, Team-maxmin, and Correlated–team maxmin equilibria\nWe study the relationships between Nash equilibrium and Team–maxmin equilibrium in terms of efficiency for the team. In our analysis, we resort to the concept of Price of Anarchy (POA), showing that Nash equilibrium—precisely, the worst case Nash equilibrium—may be arbitrarily inefficient w.r.t. the Team–maxmin equilibrium—corresponding to the best Nash equilibrium for the team. In this case the POA provides a measure about the inefficiency that a group of players with the same goal would have if they do not form a team. To have coherent results with the definition of POA, we consider games with payoffs in the range r0, 1s. We observe that our results will hold without loss of generality since, given any arbitrary game, we can produce an equivalent game in which the payoffs are in such a range by using an affine transformation. Furthermore, for the sake of presentation, we consider only games in which m1 “ . . . “ mn “ m. The generalization of our results when players may have a different number of actions is straightforward.\nTheorem 1 The Price of Anarchy (POA) of the Nash equilibrium w.r.t. the Team–maxmin equilibrium may be POA“ 8 even in games with 3 players (2 teammates), 2 actions per player, and binary payoffs.\nIn order to evaluate the inefficiency of the Team–maxmin equilibrium w.r.t. the Correlated–team maxmin equilibrium, we introduce a new index similar to the mediation value proposed in (Ashlagi, Monderer, and Tennenholtz 2008) and following the same rationale of the POA. We call such an index Price of Uncorrelation (POU) and we define it as the ratio between the team’s utility provided by the Correlated– team maxmin equilibrium and that one provided by the Team–maxmin equilibrium. POU provides a measure of the inefficiency due to the impossibility, for the teammates, of synchronizing the execution of their strategies.\nDefinition 1 Let us consider an n–player game. The Price of Uncorrelation (POU) is defined as POU “ v\nteam C vteamM\ně 1 where vteamC is Correlated–team maxmin value of the team and vteamM is Team–maxmin value of the team.\nWe initially provide a lower bound over the worst–case POU.\nTheorem 2 The POU of the Team–maxmin equilibrium w.r.t. the Correlated–team maxmin equilibrium may be POU“ mn´2 even in games with binary payoffs.\nNow, we provide an upper bound over the worst–case POU.\nTheorem 3 Given any n–player game and a Correlated– team maxmin equilibrium with a utility of v for the team, it is always possible to find in polynomial time a mixed strategy profile for the team providing a utility of at least vmn´2 to the team and therefore POU is never larger than mn´2.\nWe observe that Theorem 7 shows that the upper bound of POU is at least mn´2, while Theorem 8 shows that POU cannot be larger than mn´2. Therefore, POU is arbitrarily large only asymptotically. In other words, POU “ 8 only when m or n go to 8.3 More importantly, the proof of Theorem 8 provides a polynomial–time algorithm to find a mixed strategy of the team given a correlated strategy and this algorithm is the best possible algorithm in terms of worst–case minimization of POU. The algorithm is simple and computes mixed strategies for the team members as follows. Given the Correlated–team maxmin equilibrium p P ∆pA1ˆ . . .ˆAn´1q, the mixed strategy of player 1 ps1q is such that each action a1 is played with the probability that a1 is chosen in p, that is s1pa1q “ ř\na´1PA´1 ppa1, a´1q. Every other team member i P Nzt1, nu plays uniformly over the actions she plays with strictly positive probability in p. Since the computation of a Correlated–team maxmin equilibrium can be done in polynomial time, such an algorithm is a polynomial–time approximation algorithm for the Team–maxmin equilibrium.\nFurthermore, notice that POU rises polynomially in the number of actions m and exponentially in the number of players n. Interestingly, the instances used in the proof of Theorem 7 generalize the instances used in the proof of Theorem 6. Indeed, it can be observed that the POA of the Nash equilibrium w.r.t. the Team–maxmin equilibrium is8 in the instances used in the proof of Theorem 7. Therefore, there are instances in which the worst Nash equilibrium is arbitrarily worse than the Team–maxmin equilibrium and, in its turn, the Team–maxmin equilibrium is arbitrarily worse (in this case only asymptotically) than the Correlated–team maxmin equilibrium.\nFor the sake of completeness, we state the following result, showing the lower bound of POU.\nTheorem 4 The POU of the Team–maxmin equilibrium w.r.t. the Correlated–team maxmin equilibrium may be POU“ 1 even in games with binary payoffs.\nAlgorithms to find and/or approximate a Team-maxmin equilibrium\nIn the following, we describe four algorithms to find/approximate the Team–maxmin equilibrium.\nGlobal optimization The problem of finding the Team– maxmin equilibrium can be formulated as a non–linear non– convex mathematical program as follows:\n3A more accurate bound can be obtained by substituting m with the size of the equilibrium support, showing that the inefficiency increases as the equilibrium support increases.\nAlgorithm 1 SupportEnumeration 1: v˚ “ `8 2: for all i P T do 3: Pi “ tpV 1i ,m1i q, pV 2i ,m2i q, . . . | @j, V ji Ď Ai, ř\naPVi mji paq “ Γu\n4: C “ŚiPT Pi 5: for all ` pV1,m1q, pV2,m2q, . . . , pVn´1,mn´1q ˘\nP C do 6: for all i P T do\n7: sipaiq “\n$\n&\n%\nmipaiq Γ , if ai P Vi 0 otherwise\n8: v˚ “ maxtv˚,min sn UT ps1, s2, . . . , sn´1qu 9: return v˚\nmax v,si v\ns.t. v ´ ÿ\naT PAT\nUT paT , anq ź\niPT sipaiq ď 0 @an P An\nÿ\naiPAi\nsipaiq “ 1 @i P T\nsipaiq ě 0 @i P T, ai P Ai\nIn order to find an exact (within a given accuracy) Team– maxmin equilibrium, we resort to global optimization tools. Global optimization obviously requires exponential time. In particular, we use BARON (Tawarmalani and Sahinidis 2005) solver, since it is the best performing solver for completely continuous problems among all the existing global optimization solvers (Neumaier et al. 2005). Most importantly, BARON, if terminated prematurely, returns a lower bound, corresponding to the value of the best solution found so far, and an upper bound, corresponding to the tightest upper bound over the Team–maxmin value found so far.\nReconstruction from correlated strategies We approximate the Team–maxmin equilibrium by using a simple variation of the algorithm described previously to find a mixed strategy from a correlated one. First, the algorithm finds a Correlated–team maxmin by means of linear programming. Second, we derive the mixed strategy. The algorithm can be parametrized by exchanging player 1 with each player of the team. This leads to n ´ 1 different mixed strategies from the same correlated strategy. The algorithm returns the best one for the team. Since the Correlated–team maxmin equilibrium is always better than the Team–maxmin equilibrium, this algorithm assures an approximation factor of at least 1mn´2 showing that the problem is in Poly–APX when n is given.\nSupport enumeration In (Hansen et al. 2008), the authors show how in n–players finite strategic games the minmax value of a player can be approximated (from above) within an arbitrary additive error ą 0. The algorithmic approach to guarantee such approximation leverages the concept of simple strategies as introduced in (Lipton and Young 1994) and can be exploited to approximate the Team–maxmin value, as we fully report in Algorithm 1.\nAlgorithm 2 IteratedLP 1: @i P T , scuri Ð ŝi 2: repeat 3: for all i P T do\n4:\nv˚i “ max vi vi ď ř\naT PAT xaiUT paT , anq\nś jPT ztiu scurj pajq @an P An\nř\naiPAi xai “ 1 @ai P Ai :\nxai ě 0\n5: i1 “ arg max iPT v˚i\n6: scuri paiq “\n$\n&\n%\nx˚ai if i “ i1\nscuri paiq otherwise 7: until convergence or timeout 8: return scur\nThe algorithm enumerates joint action multi–sets (specifying, for each player i, a subset of actions that can contain duplicate elements) of cardinality Γ “\nP ln |Ai| 2 2 T\n. The strategy for each player is then obtained from an uniform distribution over the considered multi–set (for example, if action ai has k duplicates it will be selected with probability k{Γ). The adversary’s best response and the corresponding value for the team is then computed. The algorithm returns the joint support maximizing the value of the team. With a slight adaptation of the analysis made in (Hansen et al. 2008), it can be easily shown that Algorithm 1 approximates the Team–maxmin value with additive error of at most with a number of iterations equal to `\nm`Γ´1 Γ ˘n´1 .\nIn the table below we report, for some m, the number of iterations required by the algorithm to assure a given approximation with additive error not larger than .\nm 5 5 5 10 10 10 0.9 0.5 0.1 0.9 0.5 0.1 iterations ą 24 ą 212 ą 241 ą 211 ą 221 ą 287\nAs it can be seen, the algorithm can provide only a coarse guarantee (in additive sense) in small games, requiring however a large number of iterations.\nIterating linear programming In Algorithm 2 we propose a method we call IteratedLP based on solving iteratively a Maxmin problem between 2 players (a member of the team and the adversary) by linear programming.\nIt works by maintaining a current solution scur which specifies a strategy for each team member. It is initialized (Line 1) with a starting solution ŝ which, in principle, can prescribe an arbitrary set of strategies for the team (e.g., uniform randomizations). Then for each team member i (Line 3), we instantiate and solve the specified linear program (Line 4). The decision variables of this LP are vi and, for each action ai of player i, xai . We maximize vi subject to the upper bound given by the first constraint, where we assumed that the strategy of player i (relabeled with x to distinguish it) is a variable while the strategies of the other team members are constants, set to the associated value specified by the current solution. (Notice that, in the LP, aj is the action that team member j plays in the team action profile aT ). The optimal solution of the LP is given by v˚i and x ˚, rep-\nresenting the Maxmin strategy of team member i once the strategies of teammates have been fixed to the current solution. Once the LP has been solved for each i, the algorithm updates the current solution in the following way (Line 6): the strategy of the team member that obtained the best LP optimal solution is replaced with the corresponding strategy from the LP. This process continuously iterates until convergence or until some timeout is met. At each iteration of the algorithm, the value of the game increases (non–strictly) monotonically. We run it using multiple random restarts, i.e., generating a set of different initial assignments ŝ (Line 1). Once convergence is achieved, we pass to the next random restart generating a new strategy profile for the team.\nA crucial question is whether there are initializations that are better or worse than others. We can prove the following.\nTheorem 5 When the algorithm is initialized with a uniform strategy for every player, the worst–case approximation factor of Algorithm 2 is at least 1mn´1 and at most 1 mn´2 . When instead the algorithm is initialized with a pure strategy, the worst–case approximation factor is 0.\nWe leave open the problem of studying how the worst– case approximation factor varies for other initializations."
    }, {
      "heading" : "Experimental evaluation",
      "text" : ""
    }, {
      "heading" : "Experimental setting",
      "text" : "Our experimental setting is based on instances of RandomGames class generated by GAMUT (Nudelman et al. 2004). Specifically, once a game instance is generated, we extract the utility function of player 1 and assign it to all the team members. Furthermore, in each generated game instance, the payoffs are between 0 and 1. We use 100 game instances for each combination of n andmwhere n P t3, 4, 5u and m is as follows:\nm “\n$\n’ ’ ’ ’ ’ &\n’ ’ ’ ’ ’ % 5 to 40, step “ 5, n “ 3 50 to 150, step “ 10, n “ 3 5 to 50, step “ 5, n “ 4 5 to 30, step “ 5, n “ 5 .\nAlgorithms are implemented in Python 2.7.6, adopting GUROBI 6.5.0 (Gurobi Optimization 2015) for linear mathematical programs, AMPL 20160310 (Fourer, Gay, and Kernighan 1989) and BARON 14.4.0 (Tawarmalani and Sahinidis 2005; Sahinidis 2014) for global optimization programs. We set a timeout of 60 minutes for the resolution of each instance. All the algorithms are executed on a UNIX computer with 2.33GHz CPU and 128 GB RAM."
    }, {
      "heading" : "Experimental results",
      "text" : "Global optimization The average quality of the solutions is reported in Fig. 1 in terms of ratio between the lower (a.k.a. primal) bound and the upper (a.k.a. dual) bound returned by BARON once terminated. When BARON finds the optimal solution (up to an accuracy of 10´9), the lower bound equals the upper bound achieving a ratio of 1. This happens with n “ 3 up to m “ 15 (except for some outliers), with n P t4, 5u and m “ 5. For larger instances with\nn “ 3 up to m “ 130, with n “ 4 up to m “ 45 and with n “ 5 up to m “ 20, BARON returns an approximate solution with a ratio always larger than 0.7. With n “ 3 and m P t140, 150u, BARON returns a very high upper bound such that the ratio is close to zero. With larger instances, BARON does not run due to memory limits. Hence, BARON demonstrates to be an excellent tool to approximate the Team–maxmin equilibrium especially with n “ 3 (note that, with n “ 3 and m “ 130, the number of outcomes is larger than 2 millions).\nOther algorithms We report in Fig. 2 the average performance of the other three algorithms described in the previous section in terms of ratio between team value of the strategy returned by each single algorithm and the lower bound returned by BARON. A ratio smaller than 1 means that the given algorithm provides a solution with a quality worse than the solution returned by BARON.\nLet us focus on the reconstruction from correlated strategies. This algorithm solves all the instances of our experimental settings, including also the instances that BARON does not solve due to memory limits. However, the quality of the solutions is always worse than the solutions returned by BARON. More precisely, we notice that the ratio is always larger than 0.6 and, with n “ 3, it is larger than 0.8. Hence, the quality of the solutions w.r.t. the upper bound of BARON is always larger than 0.5, thus achieving at least 1{2 of the Team–maxmin value. As expected, the quality decreases as the number of players increases. Instead, surprisingly, the quality increases as the number of actions per player increases (we provide a motivation for that below).\nLet us focus on the support enumeration algorithm. We report the performance of the algorithm for P t0.10, 0.25, 0.50, 0.75, 1.00u. As expected, the algorithm does not scale. Indeed, when is set ă 1, the algorithm terminates only for m ď 20 with n “ 3, and only for m “ 5 with n P t4, 5u. This shows that the algorithm can be practically applied only when “ 1, but this corresponds not providing any theoretical bound (indeed, since all the payoffs are between 0 and 1, any strategy profile has an additive gap no larger than 1). However, even when “ 1, the algorithm terminates only for m ď 50 with n “ 3, for m ď 15 with n “ 4, and for m “ 5 with n “ 5, that is a strictly smaller\nsubset of instances than the subset solved by BARON. The quality of the solutions returned by the algorithm is rather good, but it is always worse than the solutions returned by BARON. Finally, notice that, differently from the previous algorithm, in the case of n “ 3, the quality of the solution decreases as the number of action increases.\nLet us focus on the iterated linear programming. We report the performance of the algorithm for a number of random restarts in t1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100u. This algorithm solves all the instances of our experimental settings, including also the instances that BARON does not solve due to memory limits. Also in this case, the quality of the solutions is always worse than the solutions returned by BARON. Notice that the ratio is very high and very close to 1 for n “ 3. Interestingly, the number of restarts affects the solution quality essentially only when m is small. Obviously, when m is large, the number of restarts performed by the algorithm reduces, but, surprisingly, the solution quality increases and it is almost the same for every number of restarts. We observe that the number of restarts performed with the largest instances is 30 with n P t3, 4u and 10 with n “ 5. This algorithm provides the best approximation w.r.t. the previous two algorithms.\nSummary Global optimization (BARON) provides the best approximate solutions, but it does not solve all the instances of the experimental setting due to memory limits. The algorithm iterating linear programming allows one to solve larger instances with a relatively small loss in terms of utility. Furthermore, approximating the Team–maxmin equilibrium gets easier as the number of actions per player increases. We observe that this may happen because, as the number of actions per player increases, the probability that the Team–maxmin equilibrium has a small support increases and small supported equilibria should be easier to be found.\nPrice of Uncorrelation Finally, we empirically evaluate POU in our experimental setting. We do that by calculating the ratio between the value of the Correlated–team maxmin equilibrium—computed exactly—and the lower bound retuned by BARON, which is the algorithm returning always the best approximation of the Team–maxmin equilibrium. This ratio is obviously an upper bound of the actual POU. In Fig. 3, we report the average ratio and the corresponding box plot. Surprisingly, the ratio is very close to 1 even for n “ 5, while, we recall, the worst–case ratio is mn´2. It can be observed that the ratio is monotonically increasing in n, while the dependency on m is not monotone: there is\na maximum small values of m and then the ratio decreases as m increases. For instance, in 3–players games, the ratio goes asymptotically to about 1.15, showing that the loss is very small empirically. Unexpectedly, this shows that, on average, the loss due to the inability for a team of correlating their strategies is rather small.\nSpecific game classes Our Appendices includes additional experiments assessing, analogously to what done in this section with RandomGames, empirical approximation performances and Price of Uncorrelation.\nThese additional results substantially confirm global optimization as the best approach for games of small size, while IteratedLP keeps providing an approximation ratio close to the optimum even with complex game instances. Moreover, by generating random games from specific classes, it is possible to observe an interesting set of worst–case instances from the class Travelers Dilemma. For those games BARON, although keeping to be the best among the other algorithms, provided low empirical approximation factors suggesting how Team–maxmin could be hard to approximate for such class. The Price of Uncorrelation shows a similar trend of that of Fig. 3 for all classes but Bertrand Oligopoly. For these games, results seem to suggest that correlation becomes more and more critical as the number of players’ actions increases."
    }, {
      "heading" : "Conclusions",
      "text" : "The Team–maxmin equilibrium is an important solution concept requiring deep algorithmic studies. In this work, we studied its efficiency w.r.t. Nash equilibrium and the Maxmin equilibrium with correlated team strategies. Moreover, we proposed algorithms to compute/approximate it, deriving theoretical guarantees and empirical evaluations.\nIn future, we will deal with Team–maxmin equilibrium in specific games like polymatrix games and congestion games."
    }, {
      "heading" : "Appendices Proofs of the Theorems",
      "text" : "Theorem 6 The Price of Anarchy (POA) of the Nash equilibrium w.r.t. the Team–maxmin equilibrium may be POA“ 8 even in games with 3 players (2 teammates), 2 actions per player, and binary payoffs for the team.\nProof. Consider the following game instance with 3 players (2 teammates), 2 actions per player, and binary payoffs for the team:\n2 a3 a4\n1 a1 1 0 a2 0 0\n2 a3 a4\n1 a1 0 0 a2 0 1\na5 a6\n3\nTeam–maxmin equilibrium. Consider the strategy profile in which:\ns1 “ \" a1 0.5\na2 0.5 , s2 “\n\"\na3 0.5 a4 0.5 , s3 “\n\"\na5 0.5 a6 0.5 .\nIt is a Nash equilibrium providing each teammate a utility of 0.25. Indeed, player 1 is indifferent between playing actions a1 and a2, each action providing a utility of 0.25. The same holds for the other two players: player 2 is indifferent between playing actions a3 and a4, each action providing a utility of 0.25, and player 3 is indifferent between playing actions a5 and a6, each action providing a utility of ´0.25.\nWorst Nash equilibrium. Consider the action profiles pa2, a4, a5q and pa1, a3, a6q. They are Nash equilibria providing the team a utility of 0. Indeed, consider pa2, a4, a5q, player 1 would gain 0 from unilateral deviations and the same for player 2, while player 3 would lose utility (from 1 to 0) from unilateral deviations.\nPOA. As a result, the ratio between the value of the team provided by the Team–maxmin equilibrium and the worst Nash equilibrium is POA“ 0.250 “ 8. l\nTheorem 7 The Price of Uncorrelation (POU) of the Team– maxmin equilibrium w.r.t. the Correlated–team maxmin equilibrium may be POU“ mn´2 even in games with binary payoffs for the team.\nProof. Consider the game instances with n players (n ´ 1 teammates) and m actions per player in which the utility of the team is:\nUT pa1, . . . , anq “ \" 1 a1 “ a2 “ . . . “ an 0 otherwise ,\nCorrelated–team maxmin equilibrium. The equilibrium strategy profile prescribes the team plays all the join actions of the form a1 “ a2 “ . . . “ an´1, each action played with a probability of 1m . The utility for the team is 1 m . First, we observe that the team cannot improve its utility by playing with strictly positive probability the other joint actions. This easily follows from the fact that all the other actions provide\na utility of zero to the team for every action of the adversary, resulting thus weakly dominated. Second, we observe that all the joint actions of the form a1 “ a2 “ . . . “ an´1 must be played with strictly positive probability. Indeed, suppose that the team plays with zero probability a joint action of the form a1 “ a2 “ . . . “ an´1 “ a. Then, if the adversary plays a, the team receives a utility of 0. Finally, given that all the joint actions of the form a1 “ a2 “ . . . “ an´1 are played with strictly positive probability, the probability over them is uniform by symmetry.\nTeam maxmin equilibrium. The equilibrium strategy profile prescribes each player to play every action with a probability of 1m . The utility of the team is 1 mn´1 . Initially, we observe that if some player does not play with strictly positive probability at least an action, say a, then the utility of the team is zero. Indeed, in such a case, if the adversary plays a, the utility of the team is zero. Finally, given that every player plays with strictly positive probability all the actions, the probability over them is uniform by symmetry.\nPOU. As a result, the ratio between the value of the team provided by the Correlated–team maxmin equilibrium and Team–maxmin equilibrium is POU“ 1{m1{mn´1 “ m n´2. l\nTheorem 8 Given any n–player game and a Correlated– team maxmin equilibrium with a utility of v for the team, it is always possible to find in polynomial time a mixed strategy profile for the team providing a utility of at least vmn´2 to the team.\nProof. Consider the following simple algorithm. Call p the correlated strategy of the team at the Correlated–team maxmin equilibrium—generically, p is a function p P ∆pA1 ˆ . . . ˆ An´1q where ∆pSq is the set of all probability distributions over set S. The mixed strategy si with i P Nztnu is obtained as follows: • for every a1 P A1, we set\ns1pa1q “ ÿ\npa2,...an´1qPA2ˆ...ˆAn´1\nppa1, a2, . . . , an´1q.\nNotice that the strategy is well defined, summing to 1 since ř\naPA1ˆ...An´1 ppaq “ 1;\n• for every i P Nzt1, nu and for every ai P Ai, we set\nsipaiq “ \" 0 Ea´n : ai P a´n and ppa´nq ą 0 1{|suppi| otherwise ;\nwhere |suppi| is the number of actions of i played with strictly positive probability by p. Notice that also in this case the strategy is well defined, summing to 1.\nIn words, the mixed strategy si is built such that: s1 plays each action a1 with the probability that a1 is chosen by p, while si with i P Nzt1, nu plays action ai with a probability of 1 divided by the number of actions of i played by strictly positive probability by p if a is played by p and with a probability of 0 otherwise. We show that the strategy profile ps1, . . . , s´nq always assures (against an adversary) the team to receive at least vmn´2 where v is the utility given by\nthe Correlated–team maxmin equilibrium. For the sake of the presentation, we distinguish some cases.\nCase 1: for every team member i, each action ai is played with positive strictly probability in p and there is only one joint action of the team played with strictly positive probability that contains ai. In this case, once an opportune re– labeling of the actions is performed, the correlated strategy p puts strictly positive probability only to joint actions of the form a1 “ a2 “ . . . “ an´1 and to all such joint actions. First, we show that our s plays each joint action a1 “ a2 “ . . . “ an´1 such that ppa1, . . . , a´nq ą 0 with ppa1, . . . , a´nq{mn´2. This is because s1pa1q “ ppa1, . . . , a´nq, while s2pa2q “ . . . “ sn´1pan´1q “ 1m . Second, the worst case, which minimizes the utility of the team when a mixed strategy is used, is when the payoffs of all the outcomes achievable with the joint actions played with zero probability by p are zero. This means that the only joint actions providing strictly positive expected utility to the team are those played with strictly positive probability by p. Strategy s prescribes over such joint actions the same probability of p divided by mn´2. Therefore, the strategy of the adversary does not change and the utility for the team provided by the mixed strategy s is 1{mn´2 multiplied by the utility given by the Correlated–team maxmin equilibrium. When the payoffs of the outcomes achievable by the joint actions played with zero probability by p have strictly positive values, the expected utility for the team given by s is obviously larger than 1{mn´2 multiplied by the utility given by the Correlated–team maxmin equilibrium. This completes the proof of the theorem for this case.\nCase 2: for every team member i, each action ai is played with positive strictly probability in p and there may be more than one joint action of the team played with strictly positive probability that contains ai. In this case, the proof is exactly the same of the previous case except we notice that the probability with which a joint action pa1, . . . , a´nq with ppa1, . . . , a´nq ą 0 is played by s is strictly larger than ppa1,...,a´nq\nmn´2 . We provide a simple example. Suppose that action a1 belongs to 2 joint actions played with strictly positive probability by p, say a1 and a2. The, s1pa1q “ ppa1q`ppp2q. Therefore, the probability with joint action a1 is played by s is ppa\n1q`ppa2q mn´2 ą ppa1q mn´2 . Therefore, the utility given to the\nteam by s is, except degeneracies, strictly larger than 1mn´2 multiplied by the utility of the Correlated–team maxmin equilibrium.\nCase 3: no restriction. In this case, the proof is exactly the same of the previous case except that the probability with which a joint action pa1, . . . , a´nq with ppa1, . . . , a´nq ą 0 is played by s is strictly larger than ppa1,...,a´nqmn´2 . This follows from the fact that the strategy of team members i with i ą 1 may prescribe to play actions ai with a probability larger than 1{m, since |suppi| may be smaller than m. This completes the proof. l\nTheorem 9 The POU of the Team–maxmin equilibrium w.r.t. the Correlated–team maxmin equilibrium may be POU“ 1 even in games with binary payoffs.\nProof. To find a suitable example, it suffices to consider a game instance with an equilibrium in pure strategies. Consider, for example, the following game instance with 3 players (2 teammates), 2 actions per player, and binary payoffs for the team:\n2 a3 a4\n1 a1 1 0 a2 0 1\n2 a3 a4\n1 a1 1 0 a2 0 1\na5 a6\n3\nConsider any strategy profile where players 1 and 2 play with probability 1 actions a1 and a3, respectively. For any strategy of player 3 this is an equilibrium profile that yields to the team a probability of 1 independently from the availability of correlation between them. l\nTheorem 10 When the algorithm is initialized with a uniform strategy for every player, the worst–case approximation factor of Algorithm 2 is at least 1mn´1 and at most 1 mn´2 . When instead the algorithm is initialized with a pure strategy, the worst–case approximation factor is 0.\nProof. We prove that, when every team player plays a uniform strategy, the value of the team is almost 1mn´1 of the value of the Team–maxmin equilibrium. Consider initially the worst case in which the Team–maxmin equilibrium is pure giving a value v to the team. When a uniform strategy is used by every player, each outcome is played with a probability of at least 1mn´1 , including the equilibrium outcome. In the worst case, all the outcomes except the equilibrium provide a utility of zero to the team, and therefore the team receives a utility of vmn´1 . In the case in which the Team– maxmin equilibrium is mixed, the proof is similar.\nNow, we prove that there is some case in which the algorithm returns an approximation of 1mn´2 . Consider a team game where the team is composed by n ´ 1 members and each player has m actions, while the adversary has only one action. The team utility is defined as UT pa1, a2, . . . , an´1q “ 1 when a1 “ a2 “ . . . “ an´1 and 0 otherwise. Let us consider, in Line 1 of Algorithm 2, a uniform ŝ prescribing to each team member to play each action with probability 1m . The resolution of the LP of Line 4, once fixed the strategy of one team member to such uniform distribution, would output the same uniform distribution for the other one. In other words, ŝ is a local maximum for our algorithm. Thus, the algorithm would return a strategy profile guaranteeing the team a payoff of mmn´1 “ 1 mn´2 whereas the team–maxmin value amounts to 1 and can be clearly obtained by any team profile in which both team members play the same action in pure strategies. So the approximation factor achieved by the algorithm would be exactly 1mn´2 .\nConsider the case in which the initialization is pure. Consider the game instance used in the proof of Theorem 1. If the initialization is ŝ1 “ a2 and ŝ2 “ a4, the algorithm returns 0, while the optimal value is 0.25. l"
    }, {
      "heading" : "Team–maxmin value irrationality",
      "text" : "In (Hansen et al. 2008), the authors consider the following 3–player game (we report only the utility of player 3):\n2 a3 a4\n1 a1 1 0 a2 0 0\na5\n2 a3 a4\n1 a1 0 0 a2 0 2\na6\n3\nand look for the minmax strategy of players 1 and 2 against player 3. The authors claim that such a strategy is to play actions a1 and a3 with probability 2´ ? 2, giving player 3 with\na utility of 6´4 ?\n2. This is not true, since, if players 1 and 2 play actions pa1, a4q or pa2, a3q, player 3 gains 0. Therefore, the minmax strategy of players 1 and 2 against player 3 is to play pa1, a4q or pa2, a3q.\nIn order to fix the proof, it is sufficient to change the sign of the payoffs. Once the sign has been changed, the example works for both the minmax strategy of players 1 and 2 against player 3 and the team–maxmin equilibrium where players 1 and 2 compose the team. We report here all the calculations—omitted in (Hansen et al. 2008)—for the case of the team–maxmin equilibrium. To compute the team– maxmin strategy of the team we need to solve the following optimization problem:\nmax s1pa1q,s2pa3q v s.t. v ď s1pa1qs2pa3q v ď 2p1´ s1pa1qqp1´ s2pa3qq s1pa1q P r0, 1s s2pa3q P r0, 1s\nHere, the maximum value is achieved when both inequalities hold as equalities. Thus, we can write:\ns1pa1qs2pa3q “ 2p1´ s1pa1qqp1´ s2pa3qq\nfrom which it follows:\ns1pa1q “ 2s2pa3q ´ 2 s2pa3q ´ 2 .\nNow we write:\nv “ s2pa3qp2s2pa3q ´ 2q s2pa3q ´ 2 .\nThis expression is maximized for s2pa3q “ 2 ?\n2 and the corresponding value is 6´ 4 ? 2."
    }, {
      "heading" : "Additional experimental results",
      "text" : "In this section we report additional experimental results we obtained with specific classes of GAMUT games (Nudelman et al. 2004). We considered 3–Players games from the following classes: Bertrand Oligopoly, Dispersion Game, Minimum Effort Game, and TravelersDilemma. In the following we report the average approximation factor, over 20 random instances for each data point, obtained with BARON and the ratio between BARON’s lower bound (corresponding to the best feasible solution returned) and the utility value returned by other algorithms. For Iterating LP we also display what obtained with different numbers of restarts."
    }, {
      "heading" : "40 60 80 100",
      "text" : ""
    }, {
      "heading" : "40 60 80 100",
      "text" : ""
    } ],
    "references" : [ {
      "title" : "W",
      "author" : [ "S. Alpern", "Lim" ],
      "venue" : "S.",
      "citeRegEx" : "Alpern and Lim 1998",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "and Conitzer",
      "author" : [ "G. Andersen" ],
      "venue" : "V.",
      "citeRegEx" : "Andersen and Conitzer 2013",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "On the value of correlation",
      "author" : [ "Monderer Ashlagi", "I. Tennenholtz 2008] Ashlagi", "D. Monderer", "M. Tennenholtz" ],
      "venue" : "Journal of Artificial Intelligence Research",
      "citeRegEx" : "Ashlagi et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Ashlagi et al\\.",
      "year" : 2008
    }, {
      "title" : "C",
      "author" : [ "C. Borgs", "J.T. Chayes", "N. Immorlica", "A.T. Kalai", "V.S. Mirrokni", "Papadimitriou" ],
      "venue" : "H.",
      "citeRegEx" : "Borgs et al. 2010",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Cooperation in intergroup, n-person, and two-person games of chicken",
      "author" : [ "Budescu Bornstein", "G. Zamir 1997] Bornstein", "D. Budescu", "S. Zamir" ],
      "venue" : "Journal of Conflict Resolution",
      "citeRegEx" : "Bornstein et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Bornstein et al\\.",
      "year" : 1997
    }, {
      "title" : "The effect of repeated play in the ipg and ipd team games. Journal of Conflict resolution 38(4):690–707",
      "author" : [ "Erev Bornstein", "G. Goren 1994] Bornstein", "I. Erev", "H. Goren" ],
      "venue" : null,
      "citeRegEx" : "Bornstein et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Bornstein et al\\.",
      "year" : 1994
    }, {
      "title" : "Experimental study of repeated team-games",
      "author" : [ "Winter Bornstein", "G. Goren 1996] Bornstein", "E. Winter", "H. Goren" ],
      "venue" : "European Journal of Political Economy",
      "citeRegEx" : "Bornstein et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Bornstein et al\\.",
      "year" : 1996
    }, {
      "title" : "and Sandholm",
      "author" : [ "V. Conitzer" ],
      "venue" : "T.",
      "citeRegEx" : "Conitzer and Sandholm 2006",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "C",
      "author" : [ "C. Daskalakis", "P.W. Goldberg", "Papadimitriou" ],
      "venue" : "H.",
      "citeRegEx" : "Daskalakis. Goldberg. and Papadimitriou 2009",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "On the complexity of equilibria",
      "author" : [ "Papadimitriou Deng", "X. Safra 2002] Deng", "C. Papadimitriou", "S. Safra" ],
      "venue" : "In Proceedings of the thiry-fourth annual ACM symposium on Theory of computing,",
      "citeRegEx" : "Deng et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Deng et al\\.",
      "year" : 2002
    }, {
      "title" : "D",
      "author" : [ "Fourer, R.", "Gay" ],
      "venue" : "M.; and Kernighan, B.",
      "citeRegEx" : "Fourer. Gay. and Kernighan 1989",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "T",
      "author" : [ "K.A. Hansen", "T.D. Hansen", "P.B. Miltersen", "Sørensen" ],
      "venue" : "B.",
      "citeRegEx" : "Hansen et al. 2008",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Security games with arbitrary schedules: A branch and price approach",
      "author" : [ "Jain" ],
      "venue" : null,
      "citeRegEx" : "Jain,? \\Q2010\\E",
      "shortCiteRegEx" : "Jain",
      "year" : 2010
    }, {
      "title" : "A",
      "author" : [ "Jiang, A.X.", "Procaccia" ],
      "venue" : "D.; Qian, Y.; N.; and Tambe, M.",
      "citeRegEx" : "Jiang et al. 2013",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "P",
      "author" : [ "S.C. Kontogiannis", "Spirakis" ],
      "venue" : "G.",
      "citeRegEx" : "Kontogiannis and Spirakis 2008",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "W",
      "author" : [ "Lim" ],
      "venue" : "S.",
      "citeRegEx" : "Lim 1997",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "N",
      "author" : [ "R.J. Lipton", "Young" ],
      "venue" : "E.",
      "citeRegEx" : "Lipton and Young 1994",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "and Conitzer",
      "author" : [ "C. Moon" ],
      "venue" : "V.",
      "citeRegEx" : "Moon and Conitzer 2016",
      "shortCiteRegEx" : null,
      "year" : 2016
    }, {
      "title" : "A comparison of complete global optimization solvers. Mathematical programming 103(2):335–356",
      "author" : [ "Neumaier" ],
      "venue" : null,
      "citeRegEx" : "Neumaier,? \\Q2005\\E",
      "shortCiteRegEx" : "Neumaier",
      "year" : 2005
    }, {
      "title" : "V",
      "author" : [ "N. Nisan", "T. Roughgarden", "E. Tardos", "Vazirani" ],
      "venue" : "V.",
      "citeRegEx" : "Nisan et al. 2007",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Run the gamut: A comprehensive approach to evaluating game-theoretic algorithms",
      "author" : [ "Nudelman" ],
      "venue" : "In Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent",
      "citeRegEx" : "Nudelman,? \\Q2004\\E",
      "shortCiteRegEx" : "Nudelman",
      "year" : 2004
    }, {
      "title" : "and Rosenthal",
      "author" : [ "T.R. Palfrey" ],
      "venue" : "H.",
      "citeRegEx" : "Palfrey and Rosenthal 1983",
      "shortCiteRegEx" : null,
      "year" : 1983
    }, {
      "title" : "N",
      "author" : [ "Sahinidis" ],
      "venue" : "V.",
      "citeRegEx" : "Sahinidis 2014",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "N",
      "author" : [ "M. Tawarmalani", "Sahinidis" ],
      "venue" : "V.",
      "citeRegEx" : "Tawarmalani and Sahinidis 2005",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Team-maxmin equilibria. Games and Economic Behavior 21(1):309–321",
      "author" : [ "von Stengel", "B. Koller 1997] von Stengel", "D. Koller" ],
      "venue" : null,
      "citeRegEx" : "Stengel et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Stengel et al\\.",
      "year" : 1997
    }, {
      "title" : "and Sandholm",
      "author" : [ "X. Wang" ],
      "venue" : "T.",
      "citeRegEx" : "Wang and Sandholm 2002",
      "shortCiteRegEx" : null,
      "year" : 2002
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "The Team-maxmin equilibrium prescribes the optimal strategies for a team of rational players sharing the same goal and without the capability of correlating their strategies in strategic games against an adversary. This solution concept can capture situations in which an agent controls multiple resources—corresponding to the team members—that cannot communicate. It is known that such equilibrium always exists and it is unique (unless degeneracy) and these properties make it a credible solution concept to be used in real–world applications, especially in security scenarios. Nevertheless, to the best of our knowledge, the Team–maxmin equilibrium is almost completely unexplored in the literature. In this paper, we investigate bounds of (in)efficiency of the Team– maxmin equilibrium w.r.t. the Nash equilibria and w.r.t. the Maxmin equilibrium when the team members can play correlated strategies. Furthermore, we study a number of algorithms to find and/or approximate an equilibrium, discussing their theoretical guarantees and evaluating their performance by using a standard testbed of game instances. Introduction The computational study of game–theoretic solutions concepts is among the most important challenges addressed in the last decade of Computer Science (Deng, Papadimitriou, and Safra 2002). These problems acquired particular relevance in Artificial Intelligence, where the goal is to design physical or software agents that must behave optimally in strategic situations. In addition to the well– known Nash equilibrium (Nash 1951), other solution concepts received attention in the Artificial Intelligence literature thanks to their application in security domains. Examples include Maxmin equilibrium for zero–sum games under various forms of constraints over the actions of the players (Jain et al. 2010) and Stackelberg (a.k.a. leader–follower) equilibrium (Conitzer and Sandholm 2006). While a large part of the literature focuses on 2–player games, few results are known about games with more players—except for games with a very specific structure, e.g., congestion games (Nisan et al. 2007). In this paper, we focus on the Team–maxmin equilibrium proposed by (von Copyright c © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Stengel and Koller 1997). It applies to zero–sum games between a team and an adversary. The team is defined as a set of players with the same utility function UT and without the capability of synchronizing their actions. The adversary is a single player with utility function ́UT . These games can model many realistic security scenarios, for example those where multiple non–coordinating agents share the common objective of defending an environment against a malicious attacker. In (Jiang et al. 2013), a security setting of such type is studied and an analysis of the price of mis– coordination in the specific proposed security games is conducted. The Team–maxmin equilibrium plays a crucial role also in infinitely repeated games and role assignment problems (Moon and Conitzer 2016), where it is necessary to compute threat points. The current approach to tackle these problems, in games with more than two players, is considering the correlated threat point (Kontogiannis and Spirakis 2008) or employing approximating algorithms that avoid the use of linear programming (Andersen and Conitzer 2013). Our techniques allow the computation punishment strategies (leading to the threat points) in the general scenario in which players, other than the defector, cannot coordinate strategy execution. The study of Team–maxmin equilibrium is almost completely unexplored. It is known that it always exists, it is unique except for degeneracies, and it is the best Nash equilibrium for the team, but, to the best of our knowledge, only two computational works deal with this solution concept. (Borgs et al. 2010) show that the Minmax value (equivalently the Team–maxmin value) is inapproximable in additive sense within 3 m2 even in 3–player games with m actions per player and binary payoffs (but nothing is known about the membership to APX class or some super class); (Hansen et al. 2008) strengthen the previous complexity result and provide a quasi–polynomial time –approximation (in additive sense) algorithm. Only (Lim 1997; Alpern and Lim 1998) deal with the mathematical derivation for a specific class of games with an adversary, i.e., rendezvous– evasion games. Instead, a number of works deal with team games without adversary. We just cite a few for the sake of completeness. Team games were first proposed in (Palfrey and Rosenthal 1983) as voting games, then studied in repeated and absorbing games to understand the interaction among the players (Bornstein, Erev, and Goren 1994; ar X iv :1 61 1. 06 13 4v 1 [ cs .A I] 1 8 N ov 2 01 6 Bornstein, Winter, and Goren 1996; Bornstein, Budescu, and Zamir 1997; Solan 2000) and more recently in Markov games with noisy payoffs (Wang and Sandholm 2002). Original contributions We provide two main contributions. First, we study the relationship, in terms of efficiency for the team, between Nash equilibrium (i.e., when players are not teammates), Team–maxmin equilibrium, and Correlated–team maxmin equilibrium (i.e., the Maxmin equilibrium when all the team members can play in correlated strategies and then can synchronize the execution of their actions). We show that, even in the same instances with binary payoffs, the worst Nash equilibrium may be arbitrarily worse than the Team–maxmin equilibrium that, in its turn, may be arbitrarily worse (in this case only asymptotically) than the Correlated–team maxmin equilibrium. We provide exact bounds for the inefficiency and we design an algorithm that, given a correlated strategy of the team, returns in polynomial time a mixed strategy of the team minimizing the worst–case ratio between the utility given by the correlated strategy and the utility given by the mixed strategy. Second, we provide some algorithms to find and/or approximate the Team–maxmin equilibrium, we discuss their theoretical guarantees and evaluate them in practice by means of a standard testbed (Nudelman et al. 2004). We also identify the limits of such algorithms and discuss which ones are the best to be adopted depending on the instance to be solved. For the sake of presentation, the proofs of the theorems are presented in the Appendices. Preliminaries A normal–form game is a tuple pN,A,Uq where: N “ t1, 2, . . . , nu is the set of players; A “ Ś iPN Ai is the set of player i’s actions, where Ai “ ta1, a2, . . . , amiu; U “ tU1, U2, . . . , Unu is the utility function of player i, where Ui : A Ñ R. A strategy profile is defined as s “ ps1, s2, . . . , snq, where si P ∆pAiq is player i’s mixed strategy and ∆pAiq is the set of all the probability distributions over Ai. As customary,  ́i denotes the set containing all the players except player i. We study games in which the set of players T “ t1, 2, . . . , n  ́ 1u constitutes a team whose members have the same utility function UT . Player n is an adversary of the team and her utility function is ́UT . When the teammates cannot coordinate at all and therefore no player can communicate with the others, and each player takes decisions independently, the appropriate solution concept is the Nash equilibrium, which prescribes a strategy profile where each player i’s strategy si is a best response to s ́i. In 2–player zero–sum games, a Nash equilibrium is a pair of Maxmin/Minmax strategies and can be computed in polynomial time. In arbitrary games, the computation of a Nash equilibrium is PPAD–complete even when the number of players is fixed (Daskalakis, Goldberg, and Papadimitriou 2009). Instead, when the teammates can coordinate themselves, we distinguish two forms of coordinations: correlated, in which a correlating device decides a joint action (i.e., an action profile specifying one action per teammate) and then communicates each teammate her action, and non–correlated, in which each player plays independently from the others. When the coordination is non–correlated, players are subject to the inability of correlating their actions, and their strategy si is mixed, as defined above for a generic normal– form game. In other words, teammates can jointly decide their strategies, but they cannot synchronize their actions, which must then be drawn independently. The appropriate solution concept for such setting is the Team–maxmin equilibrium. A Team–maxmin equilibrium is a Nash equilibrium with the properties of being unique (except for degeneracies) and the best one for the team. These property are very appealing in real–world settings, since they allow to avoid the equilibrium selection problem which affects the Nash equilibrium. In security applications, for instance, the equilibrium uniqueness allows to perfectly forecast the behavior of the attacker (adversary). When the number of players is given, finding a Team–maxmin equilibrium is FNP– hard and the Team–maxmin value is inapproximable in additive sense even when the payoffs are binary (Hansen et al. 2008). 1 In (Hansen et al. 2008), the authors provide a quasi–polynomial–time –approximation (in additive sense) algorithm. Furthermore, a Team–maxmin equilibrium may contain irrational probabilities even with 2 teammates and 3 different values of payoffs.2 It is not known any experimental evaluation of algorithms for finding the Team–maxmin equilibrium. When players can synchronize their actions, the team strategy is said to be correlated. Given the set of team action profiles defined as AT “ Ś iPT Ai, a correlated team strategy is defined as p P ∆pAT q. In other words, teammates can jointly decide and execute their strategy. The team is then equivalent to a single player whose actions are joint team action profiles. In such case, the appropriate solution concept for the team and the adversary is a pair of Maxmin/Minmax strategies that, for the sake of clarity, we call in this paper Correlated–team maxmin equilibrium. This equilibrium can be found by means of linear programming since it can be formulated as a maxmin problem in which the max player’s action space is given by the Cartesian product of the action space of each teammate. Notice that the size of the input is exponential in the number of teammates and therefore approximation algorithms for games with many team members are necessary in practice. Furthermore, it is not known the price—in terms of inefficiency—paid by a team due to the inability of synchronizing the execution of their actions. This would allow to understand how the Team–maxmin equilibrium is inefficient w.r.t. the Correlated–team maxmin equilibrium, or equivalently, how well the Team-maxmin equilibrium approximates the Correlated-team maxmin equilibrium. Another open problem is studying the gain a set of players sharRigorously speaking, (Hansen et al. 2008) studies Minmax strategy when there is a single max player and multiple min players. The problem of finding the Team–maxmin equilibrium in zero– sum adversarial team games can be formulated as the problem of finding such Minmax strategy and vice versa. The proof, provided in (Hansen et al. 2008), contains a minor flaw. In the Appendices, we provide a correct revision of the proof with all the calculations, omitted in the original proof. ing the same goal would have in forming a team and coordinating their mixed strategies (i.e., how is the Nash equilibrium inefficient w.r.t. the Team-maxmin equilibrium, or equivalently, how well the Nash equilibrium approximates the Team-maxmin equilibrium). Nash, Team-maxmin, and Correlated–team maxmin equilibria We study the relationships between Nash equilibrium and Team–maxmin equilibrium in terms of efficiency for the team. In our analysis, we resort to the concept of Price of Anarchy (POA), showing that Nash equilibrium—precisely, the worst case Nash equilibrium—may be arbitrarily inefficient w.r.t. the Team–maxmin equilibrium—corresponding to the best Nash equilibrium for the team. In this case the POA provides a measure about the inefficiency that a group of players with the same goal would have if they do not form a team. To have coherent results with the definition of POA, we consider games with payoffs in the range r0, 1s. We observe that our results will hold without loss of generality since, given any arbitrary game, we can produce an equivalent game in which the payoffs are in such a range by using an affine transformation. Furthermore, for the sake of presentation, we consider only games in which m1 “ . . . “ mn “ m. The generalization of our results when players may have a different number of actions is straightforward. Theorem 1 The Price of Anarchy (POA) of the Nash equilibrium w.r.t. the Team–maxmin equilibrium may be POA“ 8 even in games with 3 players (2 teammates), 2 actions per player, and binary payoffs. In order to evaluate the inefficiency of the Team–maxmin equilibrium w.r.t. the Correlated–team maxmin equilibrium, we introduce a new index similar to the mediation value proposed in (Ashlagi, Monderer, and Tennenholtz 2008) and following the same rationale of the POA. We call such an index Price of Uncorrelation (POU) and we define it as the ratio between the team’s utility provided by the Correlated– team maxmin equilibrium and that one provided by the Team–maxmin equilibrium. POU provides a measure of the inefficiency due to the impossibility, for the teammates, of synchronizing the execution of their strategies. Definition 1 Let us consider an n–player game. The Price of Uncorrelation (POU) is defined as POU “ v team C vteam M ě 1 where vteam C is Correlated–team maxmin value of the team and vteam M is Team–maxmin value of the team. We initially provide a lower bound over the worst–case POU. Theorem 2 The POU of the Team–maxmin equilibrium w.r.t. the Correlated–team maxmin equilibrium may be POU“ mn ́2 even in games with binary payoffs. Now, we provide an upper bound over the worst–case POU. Theorem 3 Given any n–player game and a Correlated– team maxmin equilibrium with a utility of v for the team, it is always possible to find in polynomial time a mixed strategy profile for the team providing a utility of at least v mn ́2 to the team and therefore POU is never larger than mn ́2. We observe that Theorem 7 shows that the upper bound of POU is at least mn ́2, while Theorem 8 shows that POU cannot be larger than mn ́2. Therefore, POU is arbitrarily large only asymptotically. In other words, POU “ 8 only when m or n go to 8.3 More importantly, the proof of Theorem 8 provides a polynomial–time algorithm to find a mixed strategy of the team given a correlated strategy and this algorithm is the best possible algorithm in terms of worst–case minimization of POU. The algorithm is simple and computes mixed strategies for the team members as follows. Given the Correlated–team maxmin equilibrium p P ∆pA1ˆ . . .ˆAn ́1q, the mixed strategy of player 1 ps1q is such that each action a1 is played with the probability that a1 is chosen in p, that is s1pa1q “ ř a ́1PA ́1 ppa1, a ́1q. Every other team member i P Nzt1, nu plays uniformly over the actions she plays with strictly positive probability in p. Since the computation of a Correlated–team maxmin equilibrium can be done in polynomial time, such an algorithm is a polynomial–time approximation algorithm for the Team–maxmin equilibrium. Furthermore, notice that POU rises polynomially in the number of actions m and exponentially in the number of players n. Interestingly, the instances used in the proof of Theorem 7 generalize the instances used in the proof of Theorem 6. Indeed, it can be observed that the POA of the Nash equilibrium w.r.t. the Team–maxmin equilibrium is8 in the instances used in the proof of Theorem 7. Therefore, there are instances in which the worst Nash equilibrium is arbitrarily worse than the Team–maxmin equilibrium and, in its turn, the Team–maxmin equilibrium is arbitrarily worse (in this case only asymptotically) than the Correlated–team maxmin equilibrium. For the sake of completeness, we state the following result, showing the lower bound of POU. Theorem 4 The POU of the Team–maxmin equilibrium w.r.t. the Correlated–team maxmin equilibrium may be POU“ 1 even in games with binary payoffs. Algorithms to find and/or approximate a Team-maxmin equilibrium In the following, we describe four algorithms to find/approximate the Team–maxmin equilibrium. Global optimization The problem of finding the Team– maxmin equilibrium can be formulated as a non–linear non– convex mathematical program as follows: A more accurate bound can be obtained by substituting m with the size of the equilibrium support, showing that the inefficiency increases as the equilibrium support increases. Algorithm 1 SupportEnumeration 1: v ̊ “ `8 2: for all i P T do 3: Pi “ tpV 1 i ,m1i q, pV 2 i ,m2i q, . . . | @j, V j i Ď Ai, ř",
    "creator" : "LaTeX with hyperref package"
  }
}