{
  "name" : "1505.05063.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Necessary and Sufficient Conditions for Surrogate Functions of Pareto Frontiers and Their Synthesis Using Gaussian Processes",
    "authors" : [ "Conrado S. Miranda", "Fernando J. Von Zuben" ],
    "emails" : [ "contact@conradomiranda.com,", "vonzuben@dca.fee.unicamp.br" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 5.\n05 06\n3v 3\n[ cs\n.A I]\n1 8\nD ec\n2 01\n5 1\nIndex Terms—Gaussian processes; Necessary and sufficient conditions; Non-dominated frontier; Surrogate functions.\nI. INTRODUCTION\nMULTI-OBJECTIVE optimization (MOO), also calledmultiple criteria optimization [1], is an extension of the standard single-objective optimization, where the objectives may be conflicting with each other [2], [3]. When a conflict exists, we are no more looking for a single optimal solution but for a set of solutions, each one providing a trade-off on the objectives and none being better than the others. This solution set is called the Pareto set and its counterpart in the objective space is denoted the Pareto frontier.\nThe Pareto frontier is at the core of MOO algorithms, being the foundation of many methods devoted to evaluating the performance and comparing the solutions to each other [4]. However, the frontier is defined by the objectives, which can be expensive to compute [5], [6], [7]. This leads to a variety of surrogate methods that try to approximate the objectives, e.g. [8], [9], thus saving computational resources.\nAmong the surrogates that directly or indirectly estimate the Pareto frontier, one introduced by Yun et al. [10] is the closest to the surrogate described in this paper. They used a one-class SVM to define a function over the objective space whose null\nC. S. Miranda and F. J. Von Zuben are with the School of Electrical and Computer Engineering, University of Campinas (Unicamp), Brazil. E-mail: contact@conradomiranda.com, vonzuben@dca.fee.unicamp.br\nspace describes an approximation of the Pareto frontier. This function is used to select individuals, since its value increases as its argument becomes more distant from the frontier, which are then used for crossover in a genetic algorithm.\nLoshchilov et al. [11] presented a similar SVM approach, but the function learnt is defined over the decision space, which allows direct comparison with the Pareto frontier approximation without requiring evaluation of the objectives. This direct comparison can also be achieved with estimates built over the objective space by integrating surrogates for the objectives. However, contrary to the one-class SVM that learns a model to fit all samples on one side of the approximate frontier, the proposed SVM is also able to consider points that dominate the frontier being approximated, allowing approximation of multiple Pareto frontiers, each defined by a class of points in non-dominated sorting [12].\nIn a different approach, Loshchilov et al. [13] approximated the Pareto dominance instead of the Pareto frontier by using a rank-based SVM. In this case, instead of providing only the data points, the algorithm is also informed about the preference for an arbitrary number of sample pairs and tries to find a function where higher evaluation represents higher preference. Using the Pareto dominance to establish the preference between points and learning directly from the decision space, candidate solutions can be compared in dominance using the learnt function. However, both [11] and [13] try to estimate the Pareto frontier using generic function approximation models, which do not take into account the particularities of the Pareto frontier.\nIt is possible to guarantee that the Pareto frontier’s estimate is valid by building conservative estimates. For instance, using a binary random field over the objective space to model the boundary between dominated and non-dominated regions, Da Fonseca and Fonseca [14] described a theory that can be used to assess the statistical performance of a stochastic optimization algorithm and compare different algorithms. The attainment function described in the paper defines the probability that a run of the stochastic algorithm will dominate the function’s arguments. Although the attainment function is hard to compute, it can be approximated by multiple runs of the underlying algorithm, which makes it a good candidate for analyzing the performance statistics of the optimization algorithm and for performing hypothesis testing between MOO algorithms.\nIf a single run is considered, then the approximate attainment function describes a valid estimate of the Pareto frontier\n2 and it is defined as the border of the region dominated by the points provided. Although valid, this estimate is very conservative and does not interpolate between the points provided, which means it cannot provide a good idea of the frontier’s shape and any evaluation of new points could be performed using only dominance comparison with the provided points.\nIn this paper, we develop a theory that defines necessary and sufficient conditions for a functional description of a Pareto frontier. Based on this theory, the search for approximations for the Pareto frontier using surrogate functions should be constrained to, or at least focused on, the ones that satisfy the results. If not, the resulting manifold obtained from the function may have any shape, possibly with many dominated points, which could result in reduced performance.\nMoreover, the theory is developed on the objective space, allowing either accurate or approximate objective evaluations to be used, without restricting the format of the objectives’ surrogates. If parametric surrogate objectives are used, their association with the Pareto frontier surrogate can provide feedback on how to adjust their parameters so that the approximation is closer to the real objectives.\nAs an example of how to integrate the theoretical conditions in a surrogate design, we show how to introduce the theoretical conditions as soft constraints in Gaussian processes [15], which are nonparametric models, thus being able to adjust to variable number of samples, and whose hyper-parameters can be easily optimized.\nTo validate the hypothesis that surrogate methods that do not consider this theory may define invalid Pareto frontier approximations, the constrained Gaussian process is compared to a regular Gaussian process and to an existing SVM-based surrogate [10] and results show that the soft constrained Gaussian process finds good approximations maximally obeying the constraints according to the degree of flexibility of the model. On the other hand, the models that do not take into account the theory can violate greatly and arbitrarily the conditions for a valid Pareto frontier.\nThis paper is organized as follows. Section II introduces the notation and principles of multi-objective optimization used in this paper. Section III shows the conditions that a function must satisfy to define a Pareto frontier. These conditions are then used in Section IV to build a function to approximate a frontier given some points on it and the approximation is compared to an existing surrogate. Finally, Section V summarizes the findings and points out future directions for research."
    }, {
      "heading" : "II. MULTI-OBJECTIVE OPTIMIZATION",
      "text" : "A multi-objective optimization (MOO) problem is defined by a decision space X and a set of objective functions gi(x) : X → Yi, i ∈ {1, . . . ,M}, where Yi ⊆ R [16]. Since the framework is the same for maximization or minimization, we will consider that minimization is desired in all objectives. For a given point x in the decision space, the point defined by its evaluation using the objectives y = (g1(x), . . . , gM (x)) is its counterpart in the objective space Y = Y1 × · · · × YM .\nAlthough the objective space usually only makes sense when coupled with the decision space and objectives, which\nallows for its infeasible region and Pareto frontier to be defined, we will work only with the objective space in this paper, which means that the results hold for any problem. We will also consider that Y = RM , since any restriction for a specific problem is defined by means of the objectives and decision space constraints, and are handled transparently.\nFurthermore, we assume that the optimal solutions describe a set of M−1 manifolds on RM , which correspond to curves in the 2D case and surfaces in the 3D case. Most multi-objective optimization problems have solutions with this property, with noticeable exceptions, such as: i) problems where some of the objectives do not conflict, so that only one of them should be used in the MOO problem with the other conflicting objectives, while the optimality of the ignored objectives is guaranteed because they were redundant; and ii) some problems with less decision variables D than objectives M , such as the Viennet function [17].\nSince we are dealing with an optimization problem, we must define operators to compare solutions, like the operators < and ≤ are used in the mono-objective case. In MOO, this operator is the dominance.\nDefinition 1 (Dominance). Let y and y′ be points in RM , the objective space. Then y dominates y′, denoted y y′, if yi ≤ y ′ i for all i.\nThe definition of dominance used in this paper is the same provided in [4], which allows a point to dominate itself. This relation is usually called weak dominance, but we call it “dominance” for simplicity, since it is the main dominance relation used in this paper. Another common definition is to require that yi < y′i for at least one i, and both definitions are consistent with the theory developed in this paper.\nDefinition 2 (Strong Dominance). Let y and y′ be points in RM , the objective space. Then y strongly dominates y′, denoted y ≺ y′, if yi < y′i for all i.\nOnce defined the comparison operator, we can divide the space Y in three sets: an estimated Pareto frontier, the set of points strongly dominated by the estimated frontier, and the set of points not strongly dominated by the estimated frontier.\nDefinition 3 (Estimated Pareto Frontier). A path-connected set of points F ⊂ RM is said to be an estimated Pareto frontier if no point in it strongly dominates another point also in F , that is, ∀y ∈ F, ∄y′ ∈ F : y′ ≺ y, and every point in the objective space except for F either strongly dominates or is strongly dominated by a point in F , that is, ∀y ∈ RM − F, ∃y′ ∈ F : y ≺ y′ ∨ y′ ≺ y.\nA set S is path-connected if there is a path joining any two points x and y in S and a path is defined by a continuous function p : [0, 1] → S with p(0) = x and p(1) = y. Therefore, if there is a continuous path of points in S that gets from any x ∈ S to y ∈ S, then S is path-connected. Based on this definition, an estimated Pareto frontier F divides the objective space RM in three disjoint sets: points strongly dominated by points in F , points that strongly dominates points in F , and F itself.\n3 −2 −1.8 −1.6 −1.4 −1.2 −1 −0.8 −0.6 −0.4 −0.2 0 0 0.5 1 1.5 2 2.5 3 y 1\ny2\nD D Fs F\nFigure 1: Example of the definitions for a particular multiobjective problem. The estimated strict Pareto frontier Fs is shown in a solid blue line, the estimated Pareto frontier F includes the solid and dashed blue lines, the dominated region D is shown on the top right red area, and the non-dominated region D is shown on the bottom left green area.\nDefinition 4 (Estimated Strict Pareto Frontier). A set of points Fs ⊂ RM is said to be an estimated strict Pareto frontier if no point in it dominates another point also in Fs, that is, ∀y ∈ Fs, ∄y′ ∈ Fs, y′ 6= y : y′ y, and every point in the objective space except for Fs either dominates or is dominated by a point in Fs, that is, ∀y ∈ RM − Fs, ∃y′ ∈ Fs : y y′ ∨ y′ y.\nDefinition 5 (True Pareto Frontier). An estimated strict Pareto frontier F ∗ is a true Pareto frontier if and only if, for all points in F ∗, there is no other feasible point in the objective space that dominates the point in the frontier, that is, ∀y ∈ F ∗, ∄x ∈ X , g(x) 6= y : g(x) y. Moreover, for a given problem, the true Pareto frontier is unique.\nThe estimated Pareto frontier of Definition 3 is a generalization and an approximation of the true Pareto frontier in two ways: i) if the true Pareto frontier is discontinuous, then dominated points are added so that the estimated Pareto frontier F is path-connected while also guaranteeing that no point in it strongly dominates any other; and ii) the estimated Pareto frontier is simply a set of points that divide the space into dominated and non-dominated regions, without stating anything about the optimality of its points.\nConsider, for instance, a problem where one of the objectives is given by\ng1(x) =\n{\nx+ 1, x > 1\nx, otherwise,\nand the other is given by g2(x) = −x. Then the true Pareto frontier F ∗ is given by\nF ∗ ={(x+ 1,−x) | x ∈ R, x > 1}\n∪ {(x,−x) | x ∈ R, x ≤ 1},\nwhich clearly is not path-connected. However, if we add the set of points F̂ = {(y,−1) | y ∈ (1, 2]} to F ∗, then the resulting\npath-connected set F = F ∗ ∪ F̂ satisfies Definition 3, despite the fact that every point in F̂ is dominated by (1, 1) ∈ F ∗, but not strongly dominated by it.\nFigure 1 shows an estimated strict Pareto frontier Fs, which coincides with the true Pareto frontier F ∗ in this example, and the path-connected estimated Pareto frontier F for this problem. This makes it clear that the estimated Pareto frontier F can contain the true Pareto frontier F ∗, i.e. F ∗ ⊆ F , while providing a path-connected 1D manifold that splits the whole objective space R2. Of course, these properties of the estimated Pareto frontier are extensible to M > 2 objectives.\nWith the definition of an estimated Pareto frontier, the objective space is divided into two sets, named dominated and non-dominated sets, also shown in Fig. 1.\nDefinition 6 (Dominated Set). The dominated set D for an estimated Pareto frontier F is the set of all points in RM where, for each one of them, there is at least one point in F that strongly dominates it, that is, D = {y ∈ RM | ∃y′ ∈ F : y′ ≺ y}.\nDefinition 7 (Non-Dominated Set). The non-dominated set D for an estimated Pareto frontier F is the set of all points that are not in F or D. This implies that D = {y ∈ RM | ∃y′ ∈ F : y ≺ y′}.\nNote that, from the definition of strong dominance, both D and D are open and unbounded sets, with boundaries defined by the estimated Pareto frontier F . Furthermore, if F contains the true Pareto frontier, then the points in D are not achievable due to the objectives’ definitions.\nFrom the partition of the objective space in three sets, one estimated Pareto frontier, one dominated and one nondominated set, we can define a score function similarly to [11], [13].\nDefinition 8 (Score Function). A score function f(y) : RM → R for a given estimated Pareto frontier F is a function that satisfies\nf(y) = 0, ∀y ∈ F,\nf(y) > 0, ∀y ∈ D,\nf(y) < 0, ∀y ∈ D.\nTherefore, a score function provides a single value that places its argument in relation to the estimated frontier. Moreover, for a given estimated Pareto frontier F , there are many possible choices of score functions f(y) that satisfy the definition and all of them uniquely define F based on their solution set f(y) = 0. This allows a score function to work as a surrogate for the estimated Pareto frontier."
    }, {
      "heading" : "III. NECESSARY AND SUFFICIENT CONDITIONS FOR SURROGATE SCORE FUNCTIONS",
      "text" : "In this section, we will show how a score function f(y) can induce an estimated Pareto frontier F and the conditions it must satisfy so that the set it defines is indeed an estimated Pareto frontier, that is, no point in it strongly dominates any other point in it.\n4 The main theory developed is based on the most general notion of a function f , but the conditions may be hard to evaluate for a general case. Therefore, we will also provide corollaries that prove the results for functions with additional constraints, like continuous derivatives. Since some of these results depend on Taylor approximations and the first derivative at the required points may be zero, we must define a generalized gradient.\nDefinition 9 (Generalized Gradient). Let h ∈ Ck, where Ck is the class of functions where the first k derivatives exist and are continuous, with k ≥ 1. Let k∗(h) be the first non-zero derivative of h evaluated at 0, that is,\nk∗(h) = arg min 1≤i≤k\n(\ndih dxi\n∣ ∣ ∣ ∣\nx=0\n6= 0\n)\n,\nwhere k∗(h) is not defined if h is a constant function or no i satisfies the inequality. Then\n∆(h) =\n\n \n \n0, ∃a ∈ R, ∀x : h(x) = a\n1\nk∗(h)!\ndk ∗(h)h\ndxk∗(h)\n∣ ∣ ∣ ∣ ∣\nx=0\n, otherwise\nis the generalized gradient operator, which is undefined if there is no i that satisfies the inequality.\nThe role of the generalized gradient in the theory to be presented is to avoid issues with functions that may have null derivative at the points being evaluated but that are also increasing. Consider, for instance, the function f(x) = x3, whose gradient is null at x = 0. This function is strictly increasing, but the first-order approximation using Taylor series is a constant. In order to consider small changes in the function’s argument, we must use first non-null derivative, which is the generalized gradient, as it will dominate the approximation.\nThe generalized gradient can be used in the Taylor approximation as h(δ) = h(0)+ δ′∆(h)+O(δ′′), where 0 < δ ≪ 1, δ′ = δk ∗(h), δ′′ = δk ∗(h)+1, and O(·) is the big-O notation. Since the result is based on δ being a small value, the exact power used to compute δ′ is not important for the approximation and the term O(δ′′) is dominated by the other factors.\nThe extensions to continuous functions f rely on the generalized gradient of a single-parameter continuous function f̂ , derived from the original f , having different signs for opposite directions. However, it does not hold for functions where k∗(·) is even.\nFor example, consider h(x) = x2, which has k∗(h) = 2. The Taylor approximation is given by h(δ) ≈ δ2∆(h(x)) = 2δ2 = δ2∆(h(−x)) ≈ h(−δ), which does not give different signs to different directions of x. Therefore, the two constraints on ∆(f̂ ) defined in the corollaries that follow can be viewed as a single constraint on ∆(f̂) plus the constraint that k∗(f̂) is odd."
    }, {
      "heading" : "A. Necessary Conditions",
      "text" : "The necessary conditions derived are direct applications of the estimated Pareto frontier’s definition and establish the basic\nground on how to define a function f from a given estimated frontier.\nLemma 1 (General Necessity). Let F be an estimated Pareto frontier. Let f(y) : RM → R be a score function for F . Then f(y+ δu) > 0 and f(y− δu) < 0 for all y ∈ F , u ∈ (0, 1]M , and δ ∈ R, δ > 0.\nProof. Assume there are y, u, and δ > 0 such that f(y+δu) ≤ 0. Let y′ = y + δu, so that y ≺ y′.\nIf f(y′) < 0, then from the definition of a score function there is some y∗ ∈ F such that y′ ≺ y∗. From the transitivity of dominance, we have that y ≺ y′ ≺ y∗, which is a contradiction, since the point y∗ in the frontier cannot strongly dominate the point y also in the frontier. Then we must have f(y′) = 0, which means y′ ∈ F and also creates a contradiction.\nAssume that f(y− δu) ≥ 0, and let y′′ = y− δu. Then we can similarly prove that it also creates a contradiction.\nTherefore, there are no such y, u, and δ with f(y+δu) ≤ 0 or f(y − δu) ≥ 0.\nThis result is intuitive, since moving δ in direction u from y we enter either D or D. If the function has the required derivatives, then the following result holds.\nCorollary 1 (Differentiable Necessity). Let F be an estimated Pareto frontier. Let f(y) : RM → R be a score function for F . Let f̂+y,u(x) = f(y + xu) and f̂ − y,u(x) = f(y − xu), with x ∈ [0,∞). Let ∆(f̂+y,u) and ∆(f̂ − y,u) be defined for all y ∈ F and u ∈ (0, 1]M . Then ∆(f̂+y,u) > 0 and ∆(f̂ − y,u) < 0 for all y ∈ F and u ∈ (0, 1]M .\nProof. Since f satisfies all conditions from Lemma 1, we have that f(y+ δu) > 0 and f(y− δu) < 0 for all y, u, and δ > 0.\nIn particular, let δ ≪ 1. Approximating using Taylor series, we have that f(y + δu) ≈ f(y) + δ′∆(f̂+y,u) > 0 and f(y − δu) ≈ f(y) + δ′∆(f̂−y,u) < 0, where δ\n′ is the appropriate power of δ for the expansion. Since f(y) = 0 and δ′ > 0, then ∆(f̂+y,u) > 0 and ∆(f̂ − y,u) < 0 must hold.\nAlthough this corollary may appear to provide weaker guarantees on f , its proof shows that the inequality constraints on the generalized gradient is equivalent to the direct inequalities on the function defined in the previous lemma."
    }, {
      "heading" : "B. Sufficient Conditions",
      "text" : "Once defined how the estimated Pareto frontier relates to a given score function, we will show that a function that satisfies the results of the previous lemma and corollary in fact uniquely defines an estimated Pareto frontier F .\nLemma 2 (General Sufficiency). Let f(y) : RM → R be a function. Let F = {y ∈ RM | f(y) = 0} be a path-connected set. Let f(y + δu) > 0 and f(y − δu) < 0 for all y ∈ F , u ∈ (0, 1]M , and δ ∈ R, δ > 0. Then F is an estimated Pareto frontier.\nProof. For F to be an estimated Pareto frontier, we have to prove that for any y, y′ ∈ F, y 6= y′ we have y ⊀ y′. Assume there are y and y′ in F such that y ≺ y′.\n5 Let u = y′ − y and δ = 1. Then we have f(y + δu) = f(y′) = 0, which violates the first inequality on f(·). Alternatively, we have f(y′ − δu) = f(y) = 0, which violates the second inequality.\nTherefore, there are no y and y′ in F such that y ≺ y′, and F is an estimated Pareto frontier.\nThe restrictions on f(y ± δu) may be hard to verify in general, since they must be valid for all δ. However, if the function has the appropriate derivatives, then it becomes easier to check if it satisfies the requirements.\nCorollary 2 (Differentiable Sufficiency). Let f(y) : RM → R be a function. Let F = {y ∈ RM | f(y) = 0} be a pathconnected set. Let f̂+y,u(x) = f(y+ xu) and f̂ − y,u(x) = f(y− xu), with x ∈ [0,∞). Let ∆(f̂+y,u) > 0 and ∆(f̂ − y,u) < 0 for all y ∈ F and u ∈ (0, 1]M . Then F is an estimated Pareto frontier.\nProof. To use Lemma 2, we must prove that f(y+δu) > 0 and f(y − δu) < 0 for all y ∈ F , u ∈ (0, 1]M , and δ ∈ R, δ > 0.\nSuppose there is some y, u, and δ in the domain such that f(y + δu) = 0. Moreover, let δ be the smallest value for which this happens for a given y and u. Let 0 < ǫ ≪ 1 and ǫ < δ. Then f(y + ǫu) ≈ f(y) + ǫ′∆(f̂+y,u) > 0 and f((y+δu)−ǫu) ≈ f(y+δu)+ǫ′∆(f̂−y,u) < 0, where ǫ\n′ is the appropriate power of ǫ for the approximation. However, f(·) cannot go from positive to negative without passing through 0 due to its continuity. Then there must be some δ′ < δ such that f(y + δ′u) = 0, which contradicts the definition of δ.\nTherefore, the first inequality on Lemma 2 holds. We can use a similar method to prove the second inequality, and then use the lemma.\nAgain, this corollary shows the equivalence between the inequalities on the function and on the generalized gradient."
    }, {
      "heading" : "C. Necessary and Sufficient Conditions",
      "text" : "Since the symmetry between Lemmas 1 and 2 is clear, we can build a theorem to merge those two and provide necessary and sufficient conditions for defining an estimated Pareto frontier F from a score function f(y).\nTheorem 1 (General Score Function). Let f(y) : RM → R be a function. Let F = {y ∈ RM | f(y) = 0} be a pathconnected set. Let D = {y ∈ RM | ∃y′ ∈ F : y′ ≺ y} and D = RM\\(F ∪ D). Let f(y) > 0, ∀y ∈ D, and f(y) < 0, ∀y ∈ D. Then F is an estimated Pareto frontier if and only if f(y+δu) > 0 and f(y−δu) < 0 for all y ∈ F , u ∈ (0, 1]M , and δ ∈ R, δ > 0.\nProof. Assume that the constraints on f are valid. Then, from Lemma 2, we have that F is an estimated Pareto frontier. Now assume that F is an estimated Pareto frontier. Then, from Lemma 1, we have that the constraints on f are valid.\nInstead of requiring knowledge of the sign of f(y) over the sets, we can use a more strict definition, requiring continuity, to guarantee that the result holds.\nCorollary 3 (Continuous Score Function). Let f(y) : RM → R be a continuous function where there are points v+ and v− such that f(v+) > 0, f(v−) < 0, and v− ≺ v+. Let F = {y ∈ RM | f(y) = 0} be a path-connected set. Then F is an estimated Pareto frontier if and only if f(y+δu) > 0 and f(y − δu) < 0 for all y ∈ F , u ∈ (0, 1]M , and δ ∈ R, δ > 0.\nProof. Assume that F is an estimated Pareto frontier. Assume that there are y, y′ ∈ D = {y ∈ RM | ∃y′ ∈ F : y′ ≺ y} such that f(y) > 0 and f(y′) < 0. From the continuity of f , we have that there is some z ∈ D such that f(z) = 0. However, since f(z) = 0, it is in F . From the definition of D, there is some z′ ∈ F such that z′ ≺ z, which violates the assumption that F is an estimated Pareto frontier. Therefore, all points in D have the same sign over f . The same can be shown for D.\nSince v− ≺ v+, we have that v+ ∈ D and v− ∈ D. Then f satisfies all conditions from Theorem 1.\nAgain, we can replace the constraints on f(y ± δu) by the constraint on the generalized gradient.\nCorollary 4 (Differentiable Score Function). Let f(y) : RM → R be a function where there are points v+ and v− such that f(v+) > 0, f(v−) < 0, and v− ≺ v+. Let F = {y ∈ RM | f(y) = 0} be a path-connected set. Let f̂+y,u(x) = f(y + xu) and f̂ − y,u(x) = f(y − xu). Let ∆(f̂ + y,u) and ∆(f̂−y,u) be defined for all y ∈ F and u ∈ (0, 1] M . Then F is an estimated Pareto frontier if and only if ∆(f̂+y,u) > 0 and ∆(f̂−y,u) < 0 for all y ∈ F and u ∈ (0, 1] M .\nProof. We can use Corollary 3 to show that the restrictions on f(y± δu) must hold. From Corollaries 1 and 2, we know that the restrictions on ∆(f̂±y,u) are the same as the restrictions on f(y ± δu), so this corollary is valid."
    }, {
      "heading" : "IV. LEARNING SURROGATE FUNCTIONS FROM SAMPLES",
      "text" : "After showing what conditions the function f must satisfy, one could ask how to build such function for a given problem and specially how to learn one from a given set of nondominated points. This can be a hard question to answer in general, but we can provide an additional lemma that can help in many cases.\nLemma 3 (Strictly Increasing Sufficiency). Let f(y) : RM → R be a strictly increasing function on each coordinate. Let F = {y ∈ RM | f(y) = 0}. Then F is an estimated Pareto frontier.\nProof. For F to be an estimated Pareto frontier, we have to prove that for any y, y′ ∈ F, y 6= y′ we have y ⊀ y′. Assume there are y and y′ in F such that y ≺ y′.\nLet P = (p0 = y, p1, . . . , pM−1, pM = y′) be a path between y and y′ that increments only one coordinate at a time. Since f is strictly increasing, we have that f(pi) < f(pi+1). Thus f(y) < f(y′), which contradicts the premise that f(y) = f(y′) = 0 because they are both in the frontier.\nTherefore, there are no y and y′ in F where y ≺ y′ and F is an estimated Pareto frontier.\nNote that, because f is strictly increasing, there is no point in F that even dominates another point in F , which was\n6 allowed in Definition 3. This restriction can be relaxed to be only monotonically non-decreasing if one can guarantee that f(y) = 0 is only a manifold, and not a subspace with volume. If f(y) = 0 is a subspace, then we can find two points in it where one dominates the other, which violates the basic definition of an estimated Pareto frontier. For instance, a function that is monotonically non-decreasing and is constant in at most one dimension at a time does not create a subspace on f(y) = 0.\nNonetheless, this lemma can be used as a guide on how to build a function for the general case. We will build a model that tries to approximate an estimated Pareto frontier from a few of its samples using an approximated monotonically increasing function based on Gaussian processes."
    }, {
      "heading" : "A. Gaussian Process As a Function Approximation Problem",
      "text" : "Since the model should have enough flexibility to fit the given samples, an appropriate choice for a surrogate function is a Gaussian process, which always has enough capacity to fit the data. Before describing how a Gaussian process is used to approximate the Pareto frontier, we provide the reader with an overview of how they work. For a more detailed description, we refer the reader to [15].\nA Gaussian process (GP) is a generalization of the multivariate normal distribution to infinite dimensions and can be used to solve a regression problem. A GP defines a probability distribution over functions, such that the outputs are jointly normally distributed.\nTo better understand this concept, consider an infinite column vector y ∈ R∞ and an infinite matrix x ∈ R∞×D . Then a function f : RD → R can be described by associating the row indexes, such that f(xi) = yi. The GP relies on the fact that the relationship between x and y can be written as:\ny ∼ N (µ(x),K(x)), (1)\nwhich states that all dimensions of y are distributed according to a multivariate normal distribution with mean µ(x) and covariance K(x). Moreover, the mean for a given dimension is given by E[yi] = µ(xi) and the covariance is given by Cov(yi, yj) = k(xi, xj), where k(·, ·) is a positive semidefinite kernel function.\nAlthough continuous functions, and thus Gaussian processes, are defined for an infinite number of points, which caused the vectors x and y to have infinite dimensions, only a finite number of observations are actually made in practice. Let N be such number of observations. Then, by the marginalization property of the multivariate normal distribution, we only have to consider N observed dimensions of x and y. Furthermore, the finite-dimension version of y is still normally distributed according to Eq. (1) when considering only the observed dimensions.\nUsual choices for the mean and covariance functions are the null mean [15], such that µ(x) = 0, and the squared exponential kernel, defined by:\nk(x, x′) = η2 exp\n(\n− 1\n2\nD ∑\ni=1\n(xi − x′i) 2\nρ2i\n)\n, (2)\nwhere η, ρi > 0 and ρi are the scale parameters, which define a representative scale for the smoothness of the function.\nThe choice of the kernel function establishes the shape and smoothness of the functions defined by the GP, with the squared exponential kernel defining infinitely differentiable functions. Other choices of kernel are possible and provide different compromises regarding the shape of the function being approximated, such as faster changes and periodicity of values. However, in order to use the monotonicity constraints introduced in Section IV-B, the kernel has to be at least twice differentiable, which limits the kernels that can be used.\nFigure 2a shows the prior distribution over functions using the squared exponential kernel with η = 1, ρ = 0.5, D = 1, and the zero mean. This highlights the fact that the GP defines a distribution over functions, not a unique function. Three sample functions from this GP are also shown in the same figure. Note that the functions are not shown as continuous, which would require an infinite number of points, but as finite approximations.\nTo use the GP to make predictions, the observed values of x are split into a training set X , whose output Y is known, and a test set X∗, whose output Y∗ we want to predict. Since all observations are jointly normally distributed, we have that the posterior distribution is given by:\nY∗|X∗, X, Y ∼ N (µ∗,Σ∗) (3a) µ∗ = K(X∗, X)K(X,X) −1Y (3b)\nΣ∗ = K(X∗, X∗)−K(X∗, X)K(X,X) −1K(X,X∗), (3c)\nwhere K(·, ·) are matrices built by computing the kernel function for each combination of the arguments values.\nThe posterior distribution for the previous GP, after four observations marked as black dots, is shown in Fig. 2b. Note that the uncertainty around the observed points is reduced due to the observation themselves, and the mean function passes over the points, as expected. Again, three functions are sampled from the posterior, and all agree on the value the function must assume over the observations.\nIn order to avoid some numerical issues and to consider noisy observations, we can assume that the covariance has a noisy term. Assuming that yi = f(xi) + ǫi, where ǫi is normally distributed with zero mean and variance σ2, then the covariance of the observations is given by Cov(yi, yj) = k(xi, xj) + σ\n2δij . The noiseless value li = f(xi) can then be estimated by:\nL∗|X∗, X, Y ∼ N (µ∗,Σ∗) (4a)\nµ∗ = K(X∗, X)ΩY (4b)\nΣ∗ = K(X∗, X∗)−K(X∗, X)ΩK(X,X∗) (4c)\nΩ = [ K(X,X) + σ2I ]−1 , (4d)\nwhich is similar to Eq. (3), except for the added term in Ω corresponding to the noise."
    }, {
      "heading" : "B. Gaussian Processes with Monotonicity Soft Constraint as Surrogates",
      "text" : "Just like in the previous section, we consider the null mean function µ(x) = 0 and the squared exponential kernel defined\n7 −2 −1.5 −1 −0.5 0 0.5 1 1.5 2 −2 −1.5 −1 −0.5 0 0.5 1 1.5 2\nx\nf (x )\n(a) Before observations\n−2 −1.5 −1 −0.5 0 0.5 1 1.5 2 −4\n−3\n−2\n−1\n0\n1\n2\n3\n4\nx\nf (x )\n(b) After observations\nFigure 2: Function distribution using a Gaussian process. Before the observations, the distribution is the same over all the space. After the observations, the distribution adapts to constraint the possible functions. The distribution mean is given by the black line and the 95% confidence interval is given by the shadowed region. Three function samples are also provided for each case.\nin Eq. (2). Since we are mapping from the objective space RM to a value in R, according to Definition 8, the input values are the objectives y and the outputs the scores z.\nLet Y ∈ RN×M be a set of N input points and Z ∈ RN their desired targets for training. We define the latent variable L between the two, such that\nL|X ∼ N (0,K(Y, Y )),\nwhere K(Y, Y )i,j = k(yi, yj). The latent variable then produces the observed values Z through\nZ|L ∼ N (L, σ2I),\nwhere I is the identity matrix. This model is the same as the one described in Section IV-A. However, only the mean prediction will be used in this paper to describe the estimated Pareto frontier. Moreover, we will show how changing the allowed noise level σ affects the Pareto frontier approximation.\nBesides the observations of f(y) at the desired points, the GP framework also accepts observations of its derivative, since differentiation is a linear operator [18], [19], that is, the derivative of a GP is also a Gaussian process. However, since we do not know the desired value of the gradient, only that it should be positive, from Corollary 4 and Lemma 3, forcing an arbitrary value may lead to reduced performance.\nAnother option is to introduce a probability distribution over the gradient in order to favor positive values, introducing monotonicity information [20]. This new distribution can be viewed as adding constraints to the Gaussian process, making it feasible to include the monotonicity information to the existing framework.\nIdeally, the probability distribution over the gradient is the step function, which provides a probability of zero if the gradient is negative and the same probability for all positive\ngradients. However, the step function defines a hard threshold and does not allow small errors, which can cause some problems for the optimization. Therefore, a smooth function that approximates the step is used to define a soft constraint over the gradient.\nLet m(i)di be the indication that the i-th sample is monotonic in the direction di. Then the following probability distribution can be used to approximate the step function:\np\n(\nm (i) di\n∣ ∣ ∣ ∣ ∂l(i)\n∂ydi\n)\n= Φ\n(\n∂l(i)\n∂ydi\n1\nν\n)\n(5a)\nΦ(v) =\n∫ v\n−∞\nN (t|0, 1)dt, (5b)\nwhere we assume the probit function Φ(·) as the derivative probability. Since the probit is a cumulative distribution function, its value ranges from 0 to 1 and it is monotonically increasing, which makes it a good approximation for the step function. The parameter ν allows us to define how strict the distribution should be, with ν → 0 approximating the step function or a hard constraint. In this paper, following the suggestion of [20], we use ν = 10−6.\nSince the monotonicity probability is not normal, it has to be approximated by a normal distribution to be used in the GP framework. To understand this, first consider the problem without the monotonicity constraints, which is given by Eq. (4). The probability distribution of the observation is given by:\np(L∗|X∗, X, Y ) =\n∫\np(L∗|X∗, X, L)p(L|X,Y )dL, (6)\nwhere L is the latent variable for the training data, whose\n8 −0.8 −0 .8 −0.6 −0.4 −0.4 −0.2 −0.2 0 0 0.2 0.2\n−0.5 0 0.5 1 1.5 −0.5\n0\n0.5\n1\n1.5\ny1\ny 2\n(a) Concave, β → ∞\n−0.2\n−0.2\n0\n0\n0.2\n0.2\n0.4 0.4 0.6 0. 8\n0.8\n−0.5 0 0.5 1 1.5 −0.5\n0\n0.5\n1\n1.5\ny1\ny 2\n(b) Convex, β → ∞\n−1\n−0.8\n−0.6\n−0.6\n−0.4\n−0.4\n−0.2\n−0.2\n0\n0\n0.2\n0.2\n0.2 0.4\n0.4\n0.6\n0.6\n−0.5 0 0.5 1 1.5 −0.5\n0\n0.5\n1\n1.5\ny1\ny 2\n(c) Concave, β = 0.1\n−0.6\n−0.4\n−0 .4\n−0.2\n−0.2\n−0.2\n0\n0\n0.2\n0.2\n0.4\n0.4\n0.6\n0.6\n0.8\n1\n−0.5 0 0.5 1 1.5 −0.5\n0\n0.5\n1\n1.5\ny1\ny 2\n(d) Convex, β = 0.1\n−1.4\n−1.2\n−1\n−0.8 −0.6\n−0.6\n−0.4\n−0.4\n− 0.2\n−0.2\n0\n0\n0\n0.2\n0.2 0.2\n0.4\n0.4\n0. 4\n0.6\n0. 6\n0.8\n0.8\n−0.5 0 0.5 1 1.5 −0.5\n0\n0.5\n1\n1.5\ny1\ny 2\n(e) Concave, β → 0\n−0.8\n−0 .8\n−0 .6\n−0.6\n−0 .4\n−0.4\n−0.4\n− 0.2\n−0.2\n−0.2\n0\n0\n0\n0.2\n0.2\n0.4\n0.4\n0.6\n0.6\n0.8\n0.8\n1\n1.2\n1.4\n1.6\n−0.5 0 0.5 1 1.5 −0.5\n0\n0.5\n1\n1.5\ny1\ny 2\n(f) Convex, β → 0\nFigure 3: Contours for the f(y) learned using a Gaussian process with derivative constraint. The black dots are the frontier points provided.\n9 −0.8\n−0.6\n−0 .6\n−0.4\n−0 .4\n−0.2\n−0 .2\n−0 .2\n0\n0 0\n0\n−0.5 0 0.5 1 1.5 −0.5\n0\n0.5\n1\n1.5\ny1\ny 2\n(a) Concave, β = 0.1\n0\n0 0 0\n0. 2\n0. 2\n0.2\n0.4\n0.4\n0. 6\n0.60.8\n−0.5 0 0.5 1 1.5 −0.5\n0\n0.5\n1\n1.5\ny1\ny 2\n(b) Convex, β = 0.1\nFigure 4: Contours for the f(y) learned using standard Gaussian process. The black dots are the frontier points provided.\nprobability distribution, computed by the Bayes’ rule, is\np(L|X,Y ) = p(Y |L)p(L|X)\np(Y |X)\np(Y |X) =\n∫\np(Y |L)p(L|X)dL.\nAccording to the model, the prior p(L|X) and the likelihoods p(Y |L) and p(L∗|X∗, X, L) are normal distributions, which makes all integrals tractable and all other distributions defined in the closed form presented in Eq. 4.\nNow, considering the monotonicity constraints, let M be the monotonicity constraints and L′ be the random variable associated with the derivative of the latent variables L. Then the probability distribution in Eq. (5) can be written as p(M|L′). Rewriting the posterior distribution over the latent variables, we get:\np(L|X,Y,M) = p(M|L′)p(Y |L)p(L,L′|X)\np(Y,M|X) (7a)\np(Y,M|X) =\n∫\np(M|L′)p(Y |L)p(L,L′|X)dLdL′. (7b)\nBecause the distribution p(M|L′) is not normal and every other distribution in Eq. (7) is normal, the integrals defined in Eqs. (6) and (7b) are intractable. Therefore, the distribution p(M|L′) must be approximated by a normal distribution, which can be achieved using the expectation propagation algorithm [21], with the update equations described in [20]. The expectation propagation algorithm iteratively adjusts an unnormalized normal distribution to locally approximate the distribution defined by the soft constraints, such that p(M|L′) ≈ Z̃N (L′|µ̃, Σ̃), where Z̃ is a normalization constant, µ̃ is a mean vector with one value for each monotonicity constraint, and Σ̃ is a diagonal covariance matrix.\nBesides this monotonicity constraint, we also would like that the errors between the provided values for the points z and their latent values l are small, so that the estimated shape of the Pareto frontier is closer to the true one. This can be\nachieved by placing a prior inverse-gamma distribution over σ2, whose density is given by:\np(x;α, β) = βα\nΓ(α) x−α−1 exp\n(\n− β\nx\n)\n,\nwhere Γ(·) is the gamma function. As β → ∞, this prior is ignored, while β → 0 indicates that there is no noise. In the results shown, we fix α = 3 and vary β.\nWe define f(y) as the final expected value E[l∗|y∗, Z, Y, θ], and the parameters θ are optimized to maximize the full likelihood, including gradient probability and σ2 prior, of the training data Y and Z . We also add the monotonicity constraint on all training data for all directions, but it should be noted that we can also add only monotonicity constraint at a point without defining its desired value. This allows us to find points that have f(y) = 0 but negative gradient and add the constraint on them, which in turn could improve the estimation.\nTo test the GP’s performance as a surrogate, we consider the two test frontiers whose samples are given by P1 = [(0, 1), (ǫ, ǫ), (1, 0)], which is a convex frontier, and P2 = [(0, 1), (1− ǫ, 1− ǫ), (1, 0)], which is a concave frontier, both with ǫ = 10−3. Note that the points were purposely selected to test the ability to model very sharp frontiers. However, using only the points defined by P1 and P2 leads to a solution where f(y) is almost 0 everywhere. To avoid this problem, we add a point (1, 1), with target value 1, to P1 and a point (0, 0), with target value −1, to P2. The parameters for the Gaussian process are found using gradient ascent in the samples likelihood.\nFigure 3 shows the resulting curves for different values of β. The first thing we notice is that, although β → ∞ does not place any restriction on σ, which allows the observed points in the frontier to be far from their latent values that actually define the frontier, the resulting curve is still able to fit the general shape defined by the points provided.\nAs we reduce the value of β, the observed variance σ2 is required to be smaller and the frontier shape gets better and better. Ideally, with β = 0, the latent points would be the same\n10\nas the observed points, but this causes numeric problems due to the monotonicity information and can make it harder to satisfy the monotonicity constraint, due to the smoothness of the GP.\nWhen we reduce the value to β = 0.01 and beyond, the resulting frontier is not valid anymore, with noticeable points with negative derivative. However, the largest difference in the concave problem is between points (0.82, 1.055) and (0.2, 0.985), with a total reduction in y2 of just 0.07, and a similar result is obtained for the convex case. Therefore, this approximation is still close to the correct frontier and could be used to evaluate proposed solutions because it was built with the theoretical developments of this paper in mind and tries to approximate them, which most likely provides better frontier estimates than methods that use traditional regression solutions, such as [10], [11], [13], where the manifold f(y) = 0 can have any shape.\nTo evaluate the effect of using the gradient constraint, Fig. 4 shows a similar GP but without any information on the gradients. Although the expected Pareto frontier is correctly identified, there are also many points that do not belong to the frontier and where f(y) = 0. Since the unconstrained GP had better frontier estimates for the extreme points than the constrained GP, as all points between them and the knee satisfy the conditions, it appears that not every point benefits from the gradient constraint.\nEven though both GP models failed to fully satisfy the theoretical conditions, we consider that the GP with derivative restriction performed better, both because there are some parameter sets that are able to satisfy the frontier conditions and because it does not violate the restrictions as much. Moreover, if the variance, which is not shown but is higher for points far from the inputs provided, is taken into account, then the violations of the GP with derivatives occur in a region with higher uncertainty than the violations of the pure GP.\nTherefore, despite the minor violations of the GP with derivative constraints, this approximation is still close to the correct frontier and could be used to evaluate the proposed solutions."
    }, {
      "heading" : "C. Comparison to Existing SVM Surrogate",
      "text" : "The surrogate method introduced in [10], like the method proposed in this paper, is based on approximating the frontier directly from values in the objective space. This makes it a good candidate for comparison and validating the conjecture that existing methods may arbitrarily violate the conditions described in this paper.\nThe one-class SVM used in [10] is defined by the following optimization problem:\nmin w,ξi,ρ\n‖w‖2\n2 +\n1\nνN\nN ∑\ni=1\nξi − ρ\ns.t. wTφ(xi) ≥ ρ− ξi ξi ≥ 0, i ∈ {1, . . . , N},\nwhere v ∈ (0, 1] and the feature-extraction function φ(x) is defined implicitly by the kernel\nK(x, y) = exp(−γ‖x− y‖2),\nwhich is similar to the kernel used for the GP. One important difference between training an SVM and a GP is that the GP has a natural way to optimize its hyper-parameters by maximizing the data likelihood, which automatically defines a trade-off between fitting the data and model complexity. For the SVM, we must use cross-validation [22], which reduces the number of points available to fit the model, since the data must be divided in the training and validation sets.\nTo compare the surrogate methods, we use one test problem from [3], which is also used in [10] to show the behavior of the proposed SVM surrogate. The problem is given by:\nmin f1(x1, x2) = x1 min f2(x1, x2) = 1 + x 2 2 − x1 − 0.2 sin(3πx1)\ns.t. x1 ∈ [0, 1], x2 ∈ [−2, 2].\nWe chose this problem because its true Pareto frontier is discontinuous, which creates sharp changes in its associated estimated Pareto frontier, just like in Fig. 1, and makes it harder to approximate.\nWe chose ν = 10−3 so that the samples provided should be almost perfectly classified and we constraint the scales ρi in Eq. 2 to be equal, so that both methods can use the same features from the samples. The data set provided is composed of a grid with step 0.05 for both variables, which includes some points in the Pareto frontier. The full grid is used to fit the SVM because it provided better results than using just the non-dominated points, while only the non-dominated points are required for the GP.\nFigure 5 shows the resulting approximations of the Pareto frontier using a GP with parameters learnt through gradient ascent in the data likelihood, like in Section IV-B, and an SVM with different values of γ. The GP learns an appropriate shape from the samples provided despite the discontinuity in the frontier, but also slightly violates the constraints during the gap in f1 ∈ [0.3, 0.5]. Moreover, in the absence of any information about the shape in the interval f1 ∈ (0.9, 1], because no point was provided there, the GP extrapolates a valid shape for the Pareto frontier.\nThe SVM is highly dependent on the parameter γ. When it is small, the shape learnt is very conservative and does not follow the shape defined by the points in the frontier. On the other hand, when it is large, the surrogate fits the points in the frontier better but also may define a function that violates greatly the conditions to be a valid Pareto frontier. The best value for γ that does not violate the constraints in the interval f1 ∈ [0, 0.9] is γ = 5. However, for this value the GP provides a better approximation of the Pareto frontier, as shown in Fig. 5b. Increasing γ provides a better approximation, achieving a quality comparable to the GP, but also creates regions that violate the conditions to be a valid Pareto frontier more than the GP. Furthermore, γ = 6 defines a region that the SVM believes is part of the Pareto frontier but actually is very distant from it and inside the dominated region, as shown in Fig. 5c.\nBesides these issues, the SVM also does not extrapolate well to the region f1 ∈ (0.9, 1]. Close inspection shows that\n11\nthe dominated region defined by the SVM is finite, that is, it is described by a region in the objective space that is surrounded by an infinite region that the SVM believes is not dominated. This behavior shows that the learnt model carries no concept of the problem it is solving, which is to approximate a Pareto frontier, but describes a generic function approximation. The results in Fig. 5 provide evidence for the conjecture that existing methods proposed in the literature may arbitrarily violate the conditions described in this paper.\nFurthermore, if only the points at the Pareto frontier were provided for learning, then the region defined by the SVM would enclose only these points and would ignore the dominated region. Thus the SVM method requires data in the dominated region while the GP method only requires the points at the frontier."
    }, {
      "heading" : "V. CONCLUSION",
      "text" : "In this paper, we have introduced the necessary and sufficient conditions that functions must satisfy so that their solution space describes an estimated Pareto frontier. These conditions follow from the definition of an estimated Pareto frontier and are extended for differentiable functions, which allows easier verification of the conditions.\nBased on these conditions, a Gaussian process (GP) was tested on toy problems with very sharp Pareto frontiers. The GP was extended to include the theoretical conditions as soft probabilistic constraints and a regularization term was added to avoid large deviations between the points and their latent values. The mean latent value is used as surrogate for the Pareto frontier, and some values of the regularization constant allowed a correct frontier estimate to be found.\nHowever, when the regularization becomes too strong, the surrogate violates the constraints that define a valid estimated Pareto frontier on some points, but this occurs far from the given inputs and the deviation is small. This suggests that, even under these conditions, the proposed function could be used to provide insight on the shape of the true Pareto frontier, and possibly provide more realistic estimates than other methods that do not take the restrictions into consideration during their design.\nTo validate this hypothesis and the conjecture that existing surrogate methods may violate the conditions described in this paper, we compared the proposed GP with a one-class SVM used in [10] on one of the test problems described in the same paper. We showed that the GP again violates the constraints by small values and provide a good estimate for the Pareto\n12\nfrontier, while the SVM defined a worse estimate or violated the conditions more than the GP. Furthermore, the dominated region defined by the SVM is bounded by what it represents as the non-dominated region, while the GP correctly divides the space in two infinite areas.\nBesides being a better surrogate for the Pareto frontier, the GP has the data likelihood as an innate measure that can be used to optimize its hyper-parameters and only requires data at the frontier. On the other hand, the SVM must use some method, like cross-validation [22], to optimize its hyperparameters and it requires data in the dominated region to define better approximations.\nWe highlight that, although GP were used together with the theory on this paper to approximate the Pareto frontier, the theory is general and does not depend on the specific choice of the function descriptor. Therefore, other models that are able to deal with the constraints imposed by the theory, in either a soft or hard way, should be able to learn the desired shape of the Pareto frontier too. Nonetheless, we are not aware of any other method to create the score function in which the constraints are as easy to include as in the GP. Additionally, a GP provides robustness to changing the number of points used in the estimation.\nFurther investigations involve studying the behavior of the GP to approximate the Pareto frontier with real benchmarks and using some multi-objective optimization algorithm, such as NSGA-II [23], to provide the points. Since the objectives tend to be smoother than in the example frontier provided [24], we expect the estimated Pareto frontier described by a GP to fit the true Pareto frontier even better in these problems. If this is the case, we will investigate the possibility of integrating the frontier surrogate with other surrogate models for the objectives, so that all of them are learned directly and the number of function evaluations could be reduced.\nMoreover, since the only requirement for the surrogate is that the Pareto frontier is approximated by the null space and the exact value on other parts of the objective space are not relevant, the GP could be used to fit a regression model on the individuals of a population where the target value is monotonically increasing in the objective space. Standard performance measures in multi-objective optimization, such as the class in non-dominated sorting [23] and the dominance count [25], satisfy this property and can be used as targets of the regression. In this case, the GP would not only define the Pareto frontier, but would also define a measure of the distance between a given point and the approximated Pareto frontier.\nAnother interesting line of research is to evaluate when the derivative constraints on the points provided is beneficial, since in some points it avoids incorrect association of other points with the frontier, like around the knee in the unconstrained GP shown in this paper, and in others it may make the estimated shape not satisfy the constraints, like the points in the constrained GP also shown in this paper. This could not only provide better fit, but may also increase the fitting speed, since less constraints need to be evaluated, which reduces the size of the GP and the number of expectation propagation steps required. Therefore an iterative algorithm that adds the constraints as needed should be pursued."
    }, {
      "heading" : "ACKNOWLEDGMENT",
      "text" : "The authors would like to thank CNPq for the financial support."
    } ],
    "references" : [ {
      "title" : "Multiple Criteria Optimization: State of the Art Annotated Bibliographic Surveys, ser",
      "author" : [ "X. Gandibleux" ],
      "venue" : "International Series in Operations Research & Management Science. Springer US,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2006
    }, {
      "title" : "Nonlinear Multiobjective Optimization",
      "author" : [ "K. Miettinen" ],
      "venue" : "Springer US,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1999
    }, {
      "title" : "Multi-Objective Optimization Using Evolutionary Algorithms",
      "author" : [ "K. Deb" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2001
    }, {
      "title" : "Performance Assessment of Multiobjective Optimizers: An Analysis and Review",
      "author" : [ "E. Zitzler", "L. Thiele", "M. Laumanns", "C.M. Fonseca", "V.G. Da Fonseca" ],
      "venue" : "Evolutionary Computation, IEEE Transactions on, vol. 7, no. 2, pp. 117–132, 2003.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "A Comprehensive Survey of Fitness Approximation in Evolutionary Computation",
      "author" : [ "Y. Jin" ],
      "venue" : "Soft computing, vol. 9, no. 1, pp. 3–12, 2005.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Meta-Modeling in Multiobjective Optimization",
      "author" : [ "J. Knowles", "H. Nakayama" ],
      "venue" : "Multiobjective Optimization. Springer, 2008, pp. 245–284.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Multi-objective Optimization Using Surrogates",
      "author" : [ "I. Voutchkov", "A. Keane" ],
      "venue" : "Computational Intelligence in Optimization. Springer, 2010, pp. 155–175.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A Gaussian process surrogate model assisted evolutionary algorithm for medium scale expensive optimization problems",
      "author" : [ "B. Liu", "Q. Zhang", "G. Gielen" ],
      "venue" : "Evolutionary Computation, IEEE Transactions on, vol. 18, no. 2, pp. 180–192, 2014.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Multiobjective estimation of distribution algorithm based on joint modeling of objectives and variables",
      "author" : [ "H. Karshenas", "R. Santana", "C. Bielza", "P. Larranaga" ],
      "venue" : "Evolutionary Computation, IEEE Transactions on, vol. 18, no. 4, pp. 519–542, 2014.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Generation of Pareto frontiers using support vector machine",
      "author" : [ "Y. Yun", "H. Nakayama", "M. Arakava" ],
      "venue" : "International Conference on Multiple Criteria Decision Making, 2004.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "A Mono Surrogate for Multiobjective Optimization",
      "author" : [ "I. Loshchilov", "M. Schoenauer", "M. Sebag" ],
      "venue" : "Proceedings of the 12th Annual Conference on Genetic and Evolutionary Computation. ACM, 2010, pp. 471–478.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "An efficient approach to nondominated sorting for evolutionary multiobjective optimization",
      "author" : [ "X. Zhang", "Y. Tian", "R. Cheng", "Y. Jin" ],
      "venue" : "Evolutionary Computation, IEEE Transactions on, vol. 19, no. 2, pp. 201–213, 2015.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Dominance-Based Pareto- Surrogate for Multi-Objective Optimization",
      "author" : [ "I. Loshchilov", "M. Schoenauer", "M. Sebag" ],
      "venue" : "Simulated Evolution and Learning. Springer, 2010, pp. 230–239.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "The attainment-function approach to stochastic multiobjective optimizer assessment and comparison",
      "author" : [ "V.G. da Fonseca", "C.M. Fonseca" ],
      "venue" : "Experimental methods for the analysis of optimization algorithms. Springer, 2010, pp. 103–130.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Gaussian Process for Machine Learning",
      "author" : [ "C.E. Rasmussen", "C.K.I. Williams" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2006
    }, {
      "title" : "Multi-objective optimization",
      "author" : [ "K. Deb" ],
      "venue" : "Search methodologies. Springer, 2014, pp. 403–449.",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Some Bayesian numerical analysis",
      "author" : [ "A. O’Hagan" ],
      "venue" : "Bayesian statistics, vol. 4, pp. 345–363, 1992.",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "Gaussian processes to speed up hybrid Monte Carlo for expensive Bayesian integrals",
      "author" : [ "C.E. Rasmussen", "J.M. Bernardo", "M.J. Bayarri", "J. Berger", "A.P. Dawid", "D. Heckerman", "A.F.M. Smith", "M. West" ],
      "venue" : "Bayesian Statistics 7, 2003, pp. 651–659.",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Gaussian processes with monotonicity information",
      "author" : [ "J. Riihimäki", "A. Vehtari" ],
      "venue" : "International Conference on Artificial Intelligence and Statistics, 2010, pp. 645–652.",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Expectation propagation for approximate Bayesian inference",
      "author" : [ "T.P. Minka" ],
      "venue" : "Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence. Morgan Kaufmann Publishers Inc., 2001, pp. 362–369.",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "A fast and elitist multiobjective genetic algorithm: NSGA-II",
      "author" : [ "K. Deb", "A. Pratap", "S. Agarwal", "T.A.M.T. Meyarivan" ],
      "venue" : "Evolutionary Computation, IEEE Transactions on, vol. 6, no. 2, pp. 182–197, 2002.  13",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "A review of multiobjective test problems and a scalable test problem toolkit",
      "author" : [ "S. Huband", "P. Hingston", "L. Barone", "L. While" ],
      "venue" : "Evolutionary Computation, IEEE Transactions on, vol. 10, no. 5, pp. 477–506, 2006.",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "MULTI-OBJECTIVE optimization (MOO), also called multiple criteria optimization [1], is an extension of the standard single-objective optimization, where the objectives may be conflicting with each other [2], [3].",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 1,
      "context" : "MULTI-OBJECTIVE optimization (MOO), also called multiple criteria optimization [1], is an extension of the standard single-objective optimization, where the objectives may be conflicting with each other [2], [3].",
      "startOffset" : 203,
      "endOffset" : 206
    }, {
      "referenceID" : 2,
      "context" : "MULTI-OBJECTIVE optimization (MOO), also called multiple criteria optimization [1], is an extension of the standard single-objective optimization, where the objectives may be conflicting with each other [2], [3].",
      "startOffset" : 208,
      "endOffset" : 211
    }, {
      "referenceID" : 3,
      "context" : "The Pareto frontier is at the core of MOO algorithms, being the foundation of many methods devoted to evaluating the performance and comparing the solutions to each other [4].",
      "startOffset" : 171,
      "endOffset" : 174
    }, {
      "referenceID" : 4,
      "context" : "However, the frontier is defined by the objectives, which can be expensive to compute [5], [6], [7].",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 5,
      "context" : "However, the frontier is defined by the objectives, which can be expensive to compute [5], [6], [7].",
      "startOffset" : 91,
      "endOffset" : 94
    }, {
      "referenceID" : 6,
      "context" : "However, the frontier is defined by the objectives, which can be expensive to compute [5], [6], [7].",
      "startOffset" : 96,
      "endOffset" : 99
    }, {
      "referenceID" : 7,
      "context" : "[8], [9], thus saving computational resources.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "[8], [9], thus saving computational resources.",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 9,
      "context" : "[10] is the closest to the surrogate described in this paper.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11] presented a similar SVM approach, but the function learnt is defined over the decision space, which allows direct comparison with the Pareto frontier approximation without requiring evaluation of the objectives.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "However, contrary to the one-class SVM that learns a model to fit all samples on one side of the approximate frontier, the proposed SVM is also able to consider points that dominate the frontier being approximated, allowing approximation of multiple Pareto frontiers, each defined by a class of points in non-dominated sorting [12].",
      "startOffset" : 327,
      "endOffset" : 331
    }, {
      "referenceID" : 12,
      "context" : "[13] approximated the Pareto dominance instead of the Pareto frontier by using a rank-based SVM.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "However, both [11] and [13] try to estimate the Pareto frontier using generic function approximation models, which do not take into account the particularities of the Pareto frontier.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 12,
      "context" : "However, both [11] and [13] try to estimate the Pareto frontier using generic function approximation models, which do not take into account the particularities of the Pareto frontier.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 13,
      "context" : "For instance, using a binary random field over the objective space to model the boundary between dominated and non-dominated regions, Da Fonseca and Fonseca [14] described a theory that can be used to assess the statistical performance of a stochastic optimization algorithm and compare different algorithms.",
      "startOffset" : 157,
      "endOffset" : 161
    }, {
      "referenceID" : 14,
      "context" : "As an example of how to integrate the theoretical conditions in a surrogate design, we show how to introduce the theoretical conditions as soft constraints in Gaussian processes [15], which are nonparametric models, thus being able to adjust to variable number of samples, and whose hyper-parameters can be easily optimized.",
      "startOffset" : 178,
      "endOffset" : 182
    }, {
      "referenceID" : 9,
      "context" : "To validate the hypothesis that surrogate methods that do not consider this theory may define invalid Pareto frontier approximations, the constrained Gaussian process is compared to a regular Gaussian process and to an existing SVM-based surrogate [10] and results show that the soft constrained Gaussian process finds good approximations maximally obeying the constraints according to the degree of flexibility of the model.",
      "startOffset" : 248,
      "endOffset" : 252
    }, {
      "referenceID" : 15,
      "context" : ",M}, where Yi ⊆ R [16].",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 3,
      "context" : "The definition of dominance used in this paper is the same provided in [4], which allows a point to dominate itself.",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 0,
      "context" : "A set S is path-connected if there is a path joining any two points x and y in S and a path is defined by a continuous function p : [0, 1] → S with p(0) = x and p(1) = y.",
      "startOffset" : 132,
      "endOffset" : 138
    }, {
      "referenceID" : 10,
      "context" : "From the partition of the objective space in three sets, one estimated Pareto frontier, one dominated and one nondominated set, we can define a score function similarly to [11], [13].",
      "startOffset" : 172,
      "endOffset" : 176
    }, {
      "referenceID" : 12,
      "context" : "From the partition of the objective space in three sets, one estimated Pareto frontier, one dominated and one nondominated set, we can define a score function similarly to [11], [13].",
      "startOffset" : 178,
      "endOffset" : 182
    }, {
      "referenceID" : 14,
      "context" : "For a more detailed description, we refer the reader to [15].",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 14,
      "context" : "Usual choices for the mean and covariance functions are the null mean [15], such that μ(x) = 0, and the squared exponential kernel, defined by:",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 16,
      "context" : "Besides the observations of f(y) at the desired points, the GP framework also accepts observations of its derivative, since differentiation is a linear operator [18], [19], that is, the derivative of a GP is also a Gaussian process.",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 17,
      "context" : "Besides the observations of f(y) at the desired points, the GP framework also accepts observations of its derivative, since differentiation is a linear operator [18], [19], that is, the derivative of a GP is also a Gaussian process.",
      "startOffset" : 167,
      "endOffset" : 171
    }, {
      "referenceID" : 18,
      "context" : "Another option is to introduce a probability distribution over the gradient in order to favor positive values, introducing monotonicity information [20].",
      "startOffset" : 148,
      "endOffset" : 152
    }, {
      "referenceID" : 18,
      "context" : "In this paper, following the suggestion of [20], we use ν = 10.",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 19,
      "context" : "Therefore, the distribution p(M|L) must be approximated by a normal distribution, which can be achieved using the expectation propagation algorithm [21], with the update equations described in [20].",
      "startOffset" : 148,
      "endOffset" : 152
    }, {
      "referenceID" : 18,
      "context" : "Therefore, the distribution p(M|L) must be approximated by a normal distribution, which can be achieved using the expectation propagation algorithm [21], with the update equations described in [20].",
      "startOffset" : 193,
      "endOffset" : 197
    }, {
      "referenceID" : 9,
      "context" : "Therefore, this approximation is still close to the correct frontier and could be used to evaluate proposed solutions because it was built with the theoretical developments of this paper in mind and tries to approximate them, which most likely provides better frontier estimates than methods that use traditional regression solutions, such as [10], [11], [13], where the manifold f(y) = 0 can have any shape.",
      "startOffset" : 343,
      "endOffset" : 347
    }, {
      "referenceID" : 10,
      "context" : "Therefore, this approximation is still close to the correct frontier and could be used to evaluate proposed solutions because it was built with the theoretical developments of this paper in mind and tries to approximate them, which most likely provides better frontier estimates than methods that use traditional regression solutions, such as [10], [11], [13], where the manifold f(y) = 0 can have any shape.",
      "startOffset" : 349,
      "endOffset" : 353
    }, {
      "referenceID" : 12,
      "context" : "Therefore, this approximation is still close to the correct frontier and could be used to evaluate proposed solutions because it was built with the theoretical developments of this paper in mind and tries to approximate them, which most likely provides better frontier estimates than methods that use traditional regression solutions, such as [10], [11], [13], where the manifold f(y) = 0 can have any shape.",
      "startOffset" : 355,
      "endOffset" : 359
    }, {
      "referenceID" : 9,
      "context" : "Comparison to Existing SVM Surrogate The surrogate method introduced in [10], like the method proposed in this paper, is based on approximating the frontier directly from values in the objective space.",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 9,
      "context" : "The one-class SVM used in [10] is defined by the following optimization problem:",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 2,
      "context" : "To compare the surrogate methods, we use one test problem from [3], which is also used in [10] to show the behavior of the proposed SVM surrogate.",
      "startOffset" : 63,
      "endOffset" : 66
    }, {
      "referenceID" : 9,
      "context" : "To compare the surrogate methods, we use one test problem from [3], which is also used in [10] to show the behavior of the proposed SVM surrogate.",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : "x1 ∈ [0, 1], x2 ∈ [−2, 2].",
      "startOffset" : 5,
      "endOffset" : 11
    }, {
      "referenceID" : 9,
      "context" : "To validate this hypothesis and the conjecture that existing surrogate methods may violate the conditions described in this paper, we compared the proposed GP with a one-class SVM used in [10] on one of the test problems described in the same paper.",
      "startOffset" : 188,
      "endOffset" : 192
    }, {
      "referenceID" : 20,
      "context" : "Further investigations involve studying the behavior of the GP to approximate the Pareto frontier with real benchmarks and using some multi-objective optimization algorithm, such as NSGA-II [23], to provide the points.",
      "startOffset" : 190,
      "endOffset" : 194
    }, {
      "referenceID" : 21,
      "context" : "Since the objectives tend to be smoother than in the example frontier provided [24], we expect the estimated Pareto frontier described by a GP to fit the true Pareto frontier even better in these problems.",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 20,
      "context" : "Standard performance measures in multi-objective optimization, such as the class in non-dominated sorting [23] and the dominance count [25], satisfy this property and can be used as targets of the regression.",
      "startOffset" : 106,
      "endOffset" : 110
    } ],
    "year" : 2015,
    "abstractText" : "This paper introduces the necessary and sufficient conditions that surrogate functions must satisfy to properly define frontiers of non-dominated solutions in multi-objective optimization problems. These new conditions work directly on the objective space, thus being agnostic about how the solutions are evaluated. Therefore, real objectives or user-designed objectives’ surrogates are allowed, opening the possibility of linking independent objective surrogates. To illustrate the practical consequences of adopting the proposed conditions, we use Gaussian processes as surrogates endowed with monotonicity soft constraints and with an adjustable degree of flexibility, and compare them to regular Gaussian processes and to a frontier surrogate method in the literature that is the closest to the method proposed in this paper. Results show that the necessary and sufficient conditions proposed here are finely managed by the constrained Gaussian process, guiding to high-quality surrogates capable of suitably synthesizing an approximation to the Pareto frontier in challenging instances of multi-objective optimization, while an existing approach that does not take the theory proposed in consideration defines surrogates which greatly violate the conditions to describe a valid frontier.",
    "creator" : "LaTeX with hyperref package"
  }
}