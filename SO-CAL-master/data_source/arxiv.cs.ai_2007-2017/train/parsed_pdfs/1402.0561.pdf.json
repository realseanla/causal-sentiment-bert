{
  "name" : "1402.0561.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Irrelevant and Independent Natural Extension for Sets of Desirable Gambles",
    "authors" : [ "Gert de Cooman", "Enrique Miranda" ],
    "emails" : [ "gert.decooman@ugent.be", "mirandaenrique@uniovi.es" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "In reasoning and decision making under uncertainty, there is little doubt that probabilities play the leading part. Imprecise probability models provide a well-founded extension to probabilistic reasoning, that allow us to deal with incomplete probability assessments, indecision and robustness issues.1\nEarly imprecise probability models (going back to, amongst others, Bernoulli, 1713; Boole, 1952, 1961; Koopman, 1940) centered on lower and upper probabilities for events or propositions. In later stages (see for instance Smith, 1961; Williams, 1975b and, for the clearest statement, Walley, 1991, Section 2.7), it became apparent that the language of events and lower probabilities is lacking in power of expression, and that a much more expressive theory can be built using random variables and lower previsions (or lower expectations), instead.2 However, even though it has been quite successful, and is by now quite well developed, there are a number of problems with the lower prevision approach. Its mathematical complexity is fairly high, especially when conditioning and independence\n1. To get a good idea of what the field of imprecise probabilities is about, and how it is evolving, browse through the online proceedings of the biennial ISIPTA conferences, to be found on the web site (www. sipta.org) of the Society for Imprecise Probability: Theories and Applications. 2. In contrast, for precise probability models, the expressive power of probabilities and expectations is the same: a linear prevision or expectation on the set of all (bounded) real-valued maps is uniquely determined by its restriction to events (a finitely additive probability), and vice versa.\nc©2012 AI Access Foundation. All rights reserved.\nenter the picture. Also, the coherence requirements, which specify basic rules for proper inference using (conditional) lower previsions, are quite cumbersome, and rather harder to chop down into intuitive elementary building blocks than their precise-probabilistic counterparts, even though the latter turn out to be special instances of the former. Finally, as is the case with many other approaches to probability, and as we will see further on, the theory of coherent lower previsions has issues with conditioning on sets of probability zero.\nA very attractive solution to these problems was offered by Walley (2000), in the form of sets of desirable gambles. Walley’s work was inspired by earlier ideas by Smith (1961) and Williams (1975b), but previous work along these lines was also done by Seidenfeld, Schervish, and Kadane (1995). On this approach, the primitive notions are not probabilities of events, nor expectations of random variables. Rather, the starting point is the question whether a gamble, or a risky transaction, is desirable to a subject, i.e. strictly preferred to the zero transaction, or status quo. A basic belief model is then not a probability measure, nor a lower prevision, but a set of desirable gambles.\nLet us briefly summarise here why we believe working with sets of desirable gambles as basic belief models deserves more attention in the AI community:\nPrimo, as a number of examples in the literature have shown (Couso & Moral, 2011; De Cooman & Quaeghebeur, 2012; Moral, 2005), and as we shall see further on (look for instance at Examples 1 and 2), working with and making inferences using a set of desirable gambles as a subject’s uncertainty model is more general and more expressive. It is also arguably simpler and more elegant from a mathematical point of view, and it has a very intuitive geometrical interpretation (Quaeghebeur, 2012b).\nSecundo, we shall see in Sections 4 and 5 that the approach to coherent marginalisation and conditioning is especially straightforward, and there are no issues with conditioning on sets of probability zero.\nTertio, as we will argue in Section 2.3, because of the similarity between accepting a gamble on the one hand, and accepting a proposition to be true on the other, working with sets of desirable gambles leads to an account of probabilistic inference with a very ‘logical’ flavour; see the work by Moral and Wilson (1995) for an early discussion of this idea.\nQuarto, working with sets of desirable gambles encompasses and subsumes as special cases both classical (or ‘precise’) probabilistic inference and inference in classical propositional logic; see Sections 2 and 5.\nAnd finally, quinto, as will be made clear by the discussion throughout, sets of desirable gambles are eminently suited for dealing with partial probability assessments, in situations where experts express their beliefs, preferences or behavioural dispositions using finitely many assessments that need not determine a unique probability measure. In particular, we will discuss the connection with partial preferences in Section 2.1.\nLet us try and present a preliminary defense of these sweeping claims with a few examples. One particular perceived disadvantage of working with lower previsions—or with previsions and probabilities for that matter—is that conditioning a lower prevision need not lead to uniquely coherent results when the conditioning event has lower or upper probability zero; see for instance the work of Walley (1991, Section 6.4). For precise probabilities, this difficulty can be circumvented by using full conditional measures (Dubins, 1975). As we have already mentioned, in an imprecise-probabilities context, working with the more informative coherent sets of desirable gambles rather than with lower previsions provides a very\nelegant and intuitively appealing way out of this problem, as it has already been suggested by Walley (1991, Section 3.8.6 and Appendix F), and argued in much more detail in his later work (Walley, 2000). The connection between full conditional measures and maximal coherent sets of desirable gambles was recently explored by Couso and Moral (2011): the latter are still more general and expressive.\nThe work by De Cooman and Quaeghebeur (2012) has shown that working with sets of desirable gambles is especially illuminating in the context of modelling exchangeability assessments: it exposes the simple geometrical meaning of the notion of exchangeability, and leads to a simple and particularly elegant proof of a significant generalisation to de Finetti’s representation theorem for exchangeable random variables (de Finetti, 1931).\nExchangeability is a structural assessment, and so is independence, quite common in the context of probabilistic graphical models, such as Bayesian (Pearl, 1985) or credal networks (Cozman, 2000). Conditioning and independence are, of course, closely related. In a recent paper (De Cooman, Miranda, & Zaffalon, 2011), we investigated the notions of epistemic independence of finite-valued variables using coherent lower previsions, thus adding to the literature where assessments of epistemic irrelevance and independence are studied for graphical models (De Cooman, Hermans, Antonucci, & Zaffalon, 2010; Destercke & De Cooman, 2008), as an alternative to the more often used notion of strong independence. The above-mentioned problems with conditioning, and the fact that the coherence requirements for conditional lower previsions are, to be honest, quite cumbersome to work with, have turned this into a quite complicated exercise. This is the reason why, in the present paper, we intend to show that looking at independence using sets of desirable gambles leads to a more elegant theory that avoids some of the complexity pitfalls of working with coherent lower previsions. In doing this, we build on the strong pioneering work on epistemic irrelevance by Moral (2005). While we focus here on the symmetrised notion of epistemic independence, much of what we do can be seen as an application and continuation of his ideas.\nOur goal in this paper is to show how local models for some variables, together with independence assessments, can be combined in order to produce a joint model. This joint model can then be used to draw inferences, as is done for instance in the context of Bayesian or credal networks (Antonucci, de Campos, & Zaffalon, 2012; Cozman, 2000; Pearl, 1985). One of the core ideas of such probabilistic graphical models is to provide a representation of this joint model that is less taxing from a computational point of view.\nThere are three main novelties to our approach: the first is that we allow for imprecision in the local models—although precise models are a particular case; the second is that we model local probability assessments by means of sets of desirable gambles, because of the above-mentioned advantages they possess over coherent lower previsions; and the third is that we stress epistemic irrelevance and independence rather than the more common assessment strong independence, for reasons that will become clear further on—although we also discuss strong independence.\nWith the results in this paper we are adding useful tools to the growing toolbox for reasoning with partial probability assessments that sets of desirable gambles constitute, something already started in our work on exchangeability (De Cooman & Quaeghebeur, 2012) and the work on epistemic irrelevance and credal networks by Moral (2005). In this regard, it is also interesting to mention that algorithms for making inferences with sets\nof desirable gambles have been recently established (Couso & Moral, 2011; Quaeghebeur, 2012a). Having such a set of tools that are easily implemented in computer programs is clearly beneficial to a field like AI, which should surely be interested in coherent reasoning under uncertainty with general and robust uncertainty models that require no full specification. This paper constitutes a further step in that direction, and it also allows us to see more clearly which are the main difficulties faced when working with sets of desirable gambles. There remain, however, a number of important situations to be dealt with, and future lines of research are discussed in a number of places in the paper, as well as in the Conclusion.\nIn Section 2 we summarise relevant results in the existing theory of sets of desirable gambles. After mentioning useful notational conventions in Section 3, we recall the basic marginalisation, conditioning and extension operations for sets of desirable gambles in Sections 4 and 5. We use these to combine a number of marginal sets of desirable gambles into a joint satisfying epistemic irrelevance (Section 6), and epistemic independence (Section 7). In Section 8, we study the particular case of maximal coherent sets of desirable gambles, and derive the concept of a strong product. Section 9 deals with conditional independence assessments."
    }, {
      "heading" : "2. Coherent Sets of Desirable Gambles and Natural Extension",
      "text" : "Let us begin by explaining what our basic uncertainty models, coherent sets of desirable gambles, are about (more details can be found in Augustin, Coolen, De Cooman, & Troffaes, 2012; Couso & Moral, 2011; De Cooman & Quaeghebeur, 2012; Moral, 2005; Walley, 2000).\nConsider a variable X taking values in some possibility space X , which we assume in this paper to be finite.3 We model information about X by means of sets of desirable gambles. A gamble is a real-valued function on X , and we denote the set of all gambles on X by G(X). It is a linear space under point-wise addition of gambles, and point-wise multiplication of gambles with real numbers. For any subset A of G(X), we denote by posi(A) the set of all positive linear combinations of gambles in A:\nposi(A) :=\n{ n ∑\nk=1\nλkfk : fk ∈ A, λk > 0, n > 0\n}\n.\nWe call A a convex cone if it is closed under positive linear combinations, meaning that posi(A) = A.\nFor any two gambles f and g on X , we write ‘f ≥ g’ if (∀x ∈ X)f(x) ≥ g(x), and ‘f > g’ if f ≥ g and f 6= g. A gamble f > 0 is called positive. A gamble g ≤ 0 is called non-positive. G(X)6=0 denotes the set of all non-zero gambles, G(X)>0 the convex cone of all positive gambles, and G(X)≤0 the convex cone of all non-positive gambles.\n3. All the results in this section remain valid when working with more general, possibly infinite, possibility spaces, and in that case gambles are assumed to be bounded real-valued functions. We make this finiteness assumption here to avoid having to deal with the controversial issue of conglomerability (Miranda, Zaffalon, & De Cooman, 2012; Walley, 1991), because it will make the discussion of independence in later sections significantly easier, and because most practically implementable inference systems in AI are finitary in any case."
    }, {
      "heading" : "2.1 Coherence and Avoiding Non-positivity",
      "text" : "Definition 1 (Avoiding non-positivity and coherence). We say that a set of desirable gambles D ⊆ G(X) avoids non-positivity if f 6≤ 0 for all gambles f in posi(D), or in other words if G(X)≤0 ∩ posi(D) = ∅. It is called coherent if it satisfies the following requirements:"
    }, {
      "heading" : "D1. 0 /∈ D;",
      "text" : "D2. G(X)>0 ⊆ D;\nD3. D = posi(D).\nWe denote by D(X) the set of all coherent sets of desirable gambles on X.\nRequirement D3 turns D into a convex cone. Due to D2, it includes G(X)>0; due to D1–D3, it excludes G(X)≤0, and therefore avoids non-positivity:\nD4. if f ≤ 0 then f /∈ D, or equivalently G(X)≤0 ∩ D = ∅.\nThe set G(X)>0 is coherent, and it is the smallest such subset of G(X). This set represents minimal commitments on the part of the subject, in the sense that if he knows nothing about the likelihood of the different outcomes he will only prefer to zero those gambles which are sure to never decrease his wealth and have a possibility of increasing it. Hence, it is usually taken to model complete ignorance, and it is called the vacuous model.\nOne interesting feature of coherent sets of desirable gambles is that they are linked to the field of decision making with incomplete preferences (Aumann, 1962; Dubra, Maccheroni, & Ok, 2004; Shapley & Baucells, 1998), because they are formally equivalent to the strict versions of partial preference orderings (Buehler, 1976; Giron & Rios, 1980). Given a coherent set of desirable gambles D, we can define a strict preference relation ≻ between gambles by\nf ≻ g ⇔ f − g ∈ D for any gambles f and g in G(X).\nIndeed, due to the linearity of the utility scale, exchanging a gamble g for a gamble f is a transaction with reward function f − g, and strictly preferring f over g means that this exchange should be strictly preferred to the status quo (zero). The relation ≻ satisfies the following conditions:\nSP1. f ⊁ f for all f ∈ G(X) [irreflexivity]\nSP2. f > g ⇒ f ≻ g for all f, g ∈ G(X) [monotonicity]\nSP3. f ≻ g and g ≻ h ⇒ f ≻ h for all f, g, h ∈ G(X) [transitivity]\nSP4. f ≻ g ⇔ µf + (1− µ)h ≻ µg + (1− µ)h for all µ ∈ (0, 1] and f, g, h ∈ G(X) [mixture independence]\nConversely, any preference relation satisfying the above axioms determines a coherent set of desirable gambles. Partial preference orderings provide a foundation for a general decision theory with imprecise probabilities and imprecise utilities (Fishburn, 1975; Seidenfeld et al., 1995; Seidenfeld, Schervish, & Kadane, 2010). See also the work by Moral and Wilson (1995), Walley (1991, 2000) and Quaeghebeur (2012b, Section 2.4) for more information."
    }, {
      "heading" : "2.2 Natural Extension",
      "text" : "If we consider any non-empty family of coherent sets of desirable gambles Di, i ∈ I, then their intersection ⋂\ni∈I Di is still coherent. This is the idea behind the following result, which brings to the fore a notion of coherent inference. If a subject gives us an assessment, a set A ⊆ G(X) of gambles on X that he finds desirable, then it tells us exactly when this assessment can be extended to a coherent set of desirable gambles, and how to construct the smallest such set.\nTheorem 1 (De Cooman & Quaeghebeur, 2012). Consider A ⊆ G(X), and define its natural extension by:4\nE(A) := ⋂ {D ∈ D(X) : A ⊆ D} .\nThen the following statements are equivalent:\n(i) A avoids non-positivity;\n(ii) A is included in some coherent set of desirable gambles;\n(iii) E(A) 6= G(X);\n(iv) the set of desirable gambles E(A) is coherent;\n(v) E(A) is the smallest coherent set of desirable gambles that includes A.\nWhen any (and hence all) of these equivalent statements hold, then\nE(A) = posi ( G(X)>0 ∪ A ) .\nThis shows that if we have an assessment A with a finite description, we can represent its natural extension on a computer by storing a finite description of its extreme rays. Although in general our assessments A need not have a finite description (for instance those considered in Eq. (3) further on can but need not have one), they will be of interest in a vast range of practical situations. For a description of the many cases where partial probability assessments can be given a finite description, and for efficient algorithms for verifying the coherence or computing the natural extension of a set of gambles, we refer to the work by Couso and Moral (2011) and Quaeghebeur (2012a)."
    }, {
      "heading" : "2.3 Connection with Classical Propositional Logic",
      "text" : "The definition of a coherent set of desirable gambles, and Theorem 1, make clear that inference with desirable gambles bears a formal resemblance to deduction in classical proposition logic: D3 is a production axiom that states that positive linear combinations of desirable gambles are again desirable. The exact correspondences are listed in the following table:\nClassical propositional logic Sets of desirable gambles logical consistency avoiding non-positivity deductively closed coherent deductive closure natural extension\n4. As usual, in this expression, we let ⋂ ∅ = G(X).\nWe shall see that this inference with sets of desirable gambles has (precise-)probabilistic inference, and in particular Bayes’s Rule, as a special case. But it is easy to see that it also generalises (includes as a special case) classical propositional logic: a proposition p can be identified with a subset Ap of the Stone space X , and accepting a proposition p corresponds to judging the gamble IAp − 1 + ǫ to be desirable for all ǫ > 0.\n5 Here IAp is the so-called indicator (gamble) of Ap, assuming the value 1 on Ap and 0 elsewhere. See the work by De Cooman (2005) for a more detailed discussion."
    }, {
      "heading" : "2.4 Helpful Lemmas",
      "text" : "In order to prove a number of results in this paper, we need the following lemmas, one of which is convenient version of the separating hyperplane theorem. They rely heavily on the assumption of a finite space X , and are not easily extended to a more general case.\nLemma 2. Assume that X is finite, and consider a finite subset A of G(X). Then 0 /∈ posi(G(X)>0∪A) if and only if there is some probability mass function p such that p(x) > 0 for all x ∈ X and ∑\nx∈X p(x)f(x) > 0 for all f ∈ A.\nProof. It clearly suffices to prove necessity. Since 0 /∈ posi(G(X)>0 ∪ A), we infer from a version of the separating hyperplane theorem (Walley, 1991, Appendix E.1) that there is a linear functional Λ on G(X) such that\n(∀x ∈ X)Λ(I{x}) > 0 and (∀f ∈ A)Λ(f) > 0.\nThen Λ(X) = ∑\nx∈X Λ(I{x}) > 0, and if we let p(x) := Λ(I{x})/Λ(X) > 0 for all x ∈ X , then p is a probability mass function on X for which Λ(f)/Λ(X) = ∑\nx∈X p(x)f(x) > 0 for all f ∈ A.\nOur second lemma implies that if we consider a coherent set of desirable gambles that does not include a gamble nor its opposite, we can always find a coherent superset that includes one of the two:\nLemma 3. Consider a convex cone A of gambles on X such that max f > 0 for all f ∈ A. Consider any non-zero gamble g on X. If g /∈ A then 0 /∈ posi(A ∪ {−g}).\nProof. Consider a non-zero gamble g /∈ A, and assume ex absurdo that 0 ∈ posi(A∪{−g}). Then it follows from the assumptions that there are f ∈ A and µ > 0 such that 0 = f + µ(−g). Hence g ∈ A, a contradiction."
    }, {
      "heading" : "2.5 Maximal Coherent Sets of Desirable Gambles",
      "text" : "An element D of D(X) is called maximal if it is not strictly included in any other element of D(X), or in other words, if adding any gamble f to D makes sure we can no longer extend the set D ∪ {f} to a set that is still coherent:\n(∀D′ ∈ D(X))(D ⊆ D′ ⇒ D = D′).\n5. This is not equivalent to judging the gamble IAp − 1 to be desirable, as in that case we do not obtain a coherent set of desirable gambles; the gamble IAp − 1 is only almost-desirable in the sense of Walley (1991, Section 3.7.3).\nM(X) denotes the set of all maximal elements of D(X). The following proposition provides a useful characterisation of such maximal elements.\nProposition 4 (De Cooman & Quaeghebeur, 2012). Consider any D ∈ D(X). It is a maximal coherent set of desirable gambles if and only if\n(∀f ∈ G(X)6=0)(f /∈ D ⇒ −f ∈ D).\nAs is the case for classical propositional logic (see, for instance, De Cooman, 2005), coherence and inference can be described completely in terms of such maximal elements. This is the essence of the following important result, which continues to hold for infinite X , but for which a constructive proof can be given in case X is finite, based on the argument suggested by Couso and Moral (2011).\nTheorem 5 (Couso & Moral, 2011; De Cooman & Quaeghebeur, 2012). A set A avoids non-positivity if and only if there is some maximal M ∈ M(X) such that A ⊆ M. Moreover\nE(A) = ⋂ m(A),\nwhere we let m(A) := {M ∈ M(X) : A ⊆ M} . (1)\nThis shows that (coherent) sets of desirable gambles are instances of the so-called strong belief structures described and studied in detail by De Cooman (2005), into which the strong belief structures of classical propositional logic can be embedded. This guarantees amongst other things that an AGM-like (De Cooman, 2005; Gärdenfors, 1988) account of belief expansion and revision is possible for these objects."
    }, {
      "heading" : "2.6 Coherent Lower Previsions",
      "text" : "We conclude this section by shedding some light on the connection between coherent sets of desirable gambles, coherent lower previsions, and probabilities.\nGiven a coherent set of desirable gambles D, the functional P defined on G(X) by\nP (f) := sup {µ : f − µ ∈ D} (2)\nis a coherent lower prevision (Walley, 1991, Thm. 3.8.1), that is, it corresponds to taking the lower envelope of the expectations associated with a set of finitely additive probabilities. The conjugate upper prevision P is defined by P (f) := inf {µ : µ− f ∈ D} = −P (−f).\nMany different coherent sets of desirable gambles induce the same coherent lower prevision P , and they typically differ only in their boundaries. In this sense, we can say that sets of desirable gambles are more informative than coherent lower previsions: although a gamble with positive lower prevision is always desirable and one with a negative lower prevision is not desirable, a lower prevision does not generally provide information about the desirability of a gamble whose lower prevision equal to zero. This is the reason why we need to consider the sets of desirable gambles if we want to have this additional information. To see this more clearly, consider the following adaptation of an example by Moral (2005, Example 1):\nExample 1. Consider X1 = X2 = {a, b}, and let P be the coherent lower prevision on G(X1 × X2) given by\nP (f) := min\n{\nf(b, a) + f(b, b) 2 , f(b, a) + 3f(b, b) 4\n}\nfor all gambles f on X1 × X2.\nThis coherent lower prevision is induced by each of the following coherent sets of desirable gambles by means of Eq. (2):\nD := {f : f > 0 or P (f) > 0}\nD′ := D ∪ {f : f(b, a) = f(b, b) = 0 and f(a, a) + f(a, b) > 0} .\nHowever, these two sets encode different preferences, as the gamble g given by g(a, a) = 2, g(a, b) = −1, g(b, a) = g(b, b) = 0, with P (g) = 0, is considered desirable for D′ but not for D. This is because coherent lower previsions are not able to distinguish between preferences and weak preferences, while sets of desirable gambles can. We shall see in Section 5 that these differences come into play when considering conditioning.\nThe smallest set of desirable gambles that induces a given coherent lower prevision—an open cone—is called the associated set of strictly desirable gambles, and is given by\nD := {f ∈ G(X) : f > 0 or P (f) > 0} . (3)\nThis is for instance the case of the set D in Example 1. Sets of strictly desirable gambles are in a one-to-one relationship with coherent lower previsions, and as such they suffer from the same problems when conditioning on sets of (lower) probability zero, in the sense that in the conditional models they determine in that case—by means of Eqs. (8) and (10) in Section 5—are always vacuous (Zaffalon & Miranda, 2012; Quaeghebeur, 2012b). This is one of the reasons why in this paper we are considering the more general model of coherent sets of (not necessarily strictly) desirable gambles. For additional discussion about why sets of desirable gambles are more informative than coherent lower previsions, we refer to Walley (2000) and Quaeghebeur (2012b).\nWhen the lower and the upper prevision coincide on all gambles, then the functional P defined on G(X) by P(f) := P (f) = P (f) for all f ∈ G(X) is a linear prevision, i.e., it corresponds to the expectation operator with respect to a finitely additive probability. This happens in particular if D is a maximal coherent set of desirable gambles M:\nP (f) = sup {µ : f − µ ∈ M} = inf {µ : f − µ /∈ M} = inf {µ : µ− f ∈ M} = P (f);\nto see why the second equality holds, observe that if f − µ ∈ M then also f − µ′ ∈ M for all µ′ < µ, and as a consequence the set {µ : f − µ ∈ M} is an interval that is unbounded below. The third equality follows from Proposition 4. Thus, up to boundary behaviour, precise probability models correspond to a maximal coherent sets of desirable gambles; see the work by Couso and Moral (2011, Section 5), Miranda and Zaffalon (2010, Proposition 6) and Williams (1975a) for more information. Moreover, any coherent lower prevision P is the lower envelope of the credal set M(P ) it induces, given by\nM(P ) := {P linear prevision : (∀f ∈ G(X))P(f) ≥ P (f)} .\nWe can conclude at this point that at least in its basic representational aspects, models involving coherent sets of desirable gambles generalise both classical propositional logic and precise probability in its finitary approach championed by de Finetti (1937, 1975)."
    }, {
      "heading" : "3. Basic Notation",
      "text" : "Now that we have highlighted the basic facts about this more general approach to uncertainty modelling, we are ready to turn to independence. In order to talk about this, we need to be able to deal with models involving more than one variable. In the present section, we introduce the notational devices we will use to make this discussion as elegant as possible.\nFrom now on, we consider a number of variables Xn, n ∈ N , taking values in the respective finite sets Xn. Here N is some finite non-empty index set. 6\nFor every subset R of N , we denote by XR the tuple of variables (with one component for each r ∈ R) that takes values in the Cartesian product XR := ×r∈RXr. This Cartesian product is the set of all maps xR from R to ⋃\nr∈R Xr such that xr := xR(r) ∈ Xr for all r ∈ R. Elements of XR are generically denoted by xR or zR, with corresponding components xr := xR(r) or zr := zR(r), r ∈ R.\nWe will assume that the variables Xn are logically independent, which means that for each subset R of N , XR may assume all values in XR.\nWe denote by G(XR) the set of gambles defined on XR. We will frequently resort to the simplifying device of identifying a gamble on XR with a gamble on XN , namely its cylindrical extension. To give an example, if K ⊆ G(XN ), this trick allows us to consider K∩G(XR) as the set of those gambles in K that depend only on the variable XR. As another example, this device allows us to identify the gambles I{xR} and I{xR}×XN\\R , and therefore also the events {xR} and {xR} × XN\\R. More generally, for any event A ⊆ XR, we can identify the gambles IA and IA×XN\\R , and therefore also the events A and A× XN\\R.\nWe must pay particular attention to the case R = ∅. By definition, X∅ is the set of all maps from ∅ to ⋃\nr∈∅Xr = ∅. It contains only one element x∅: the empty map. This means that there is no uncertainty about the value of the variable X∅: it can assume only one value (the empty map). Moreover IX∅ = I{x∅} = 1. Also, we can identify G(X∅) with the set of real numbers R. There is only one coherent set of desirable gambles on X∅: the set R>0 of positive real numbers.\nOne final notational convention that is very handy and will be used throughout: if n is an index, then we identify n and {n}. So we take X{n}, G(X{n}), D{n} to also refer to Xn, G(Xn) and Dn, respectively. This trick, amongst other things, allows us to consider two disjoint index sets N1 and N2, and consider each of these sets to constitute an index in themselves, leading to a new index set {N1, N2}. The variables XN1 and XN2 can then be combined into a joint variable X{N1,N2}, which can of course be identified with the variable XN1∪N2 : joint variables can be considered as single variables, and combined to constitute new joint variables."
    }, {
      "heading" : "4. Marginalisation and Cylindrical Extension",
      "text" : "Suppose that we have a set DN ⊆ G(XN ) of desirable gambles modelling a subject’s information about the uncertain variable XN .\n6. The assumption of finiteness of the spaces Xn is essential for the proofs of some of the results established later on, such as Theorem 13 and Proposition 18. It also allows us to simplify some of the expressions of the sets of gambles derived by an assumption of epistemic irrelevance or independence, from which we derive for instance Lemma 11 and Proposition 14.\nWe are interested in modelling the information about the variable XO, where O is some subset of N . This can be done using the set of desirable gambles that belong to DN but only depend on the variable XO:\nmargO(DN ) := {g ∈ G(XO) : g ∈ DN} = DN ∩ G(XO). (4)\nObserve that if DN is coherent we obtain marg∅(DN ) = G(X∅)>0, which can be identified with the set of positive real numbers R>0. Also, with O1 ⊆ O2 ⊆ N :\nmargO1(margO2(DN )) = { g ∈ G(XO1) : g ∈ margO2(DN ) }\n= {g ∈ G(XO1) : g ∈ G(XO2) ∩ DN} = {g ∈ G(XO1) : g ∈ DN} = margO1(DN ). (5)\nCoherence is trivially preserved under marginalisation.\nProposition 6. Let DN be a set of desirable gambles on XN , and consider any subset O of N .\n(i) If DN avoids non-positivity, then so does margO(DN ).\n(ii) If DN is coherent, then margO(DN ) is a coherent set of desirable gambles on XO.\nWe now look for a kind of inverse operation to marginalisation. Suppose we have a coherent set of desirable gambles DO ⊆ G(XO) modelling a subject’s information about the uncertain variable XO, and we want to extend this to a coherent set of desirable gambles on XN , representing the same information. So we are looking for a coherent set of desirable gambles DN ⊆ G(XN ) such that margO(DN ) = DO and that is as small as possible: the most conservative coherent set of desirable gambles on XN that marginalises to DO. It turns out that such a set always exists and is not difficult to find.\nProposition 7. Let O be a subset of N and let DO ∈ D(XO). Then the most conservative (smallest) coherent set of desirable gambles on XN that marginalises to DO is given by\nextN (DO) := posi(G(XN )>0 ∪ DO). (6)\nIt is called the cylindrical extension of DO to a set of desirable gambles on XN , and clearly satisfies\nmargO(extN (DO)) = DO. (7)\nThis extension is called weak extension by Moral (2005, Section 2.1).7\nProof. It is clear from the coherence requirements and Eq. (4) that any coherent set of desirable gambles that marginalises to DO must include G(XN )>0 and DO, and therefore also posi(G(XN )>0∪DO) = extN (DO). It therefore suffices to prove that posi(G(XN )>0∪DO) is coherent, and that it marginalises to DO.\n7. The main difference between our result and Moral’s is that we are excluding the zero gamble from any coherent set of desirable gambles, while Moral is including it.\nTo prove coherence, it suffices to prove that DO avoids non-positivity, by Theorem 1. But this is obvious because DO is a coherent set of desirable gambles on XO.\nWe are left to prove that margO(extN (DO)) = DO. Since for any g ∈ DO it is obvious that both g ∈ extN (DO) and g ∈ G(XO), we see immediately that DO ⊆ margO(extN (DO)), so we concentrate on proving the converse inclusion. Consider f ∈ margO(extN (DO)), meaning that both f ∈ G(XO) and f ∈ extN (DO). The latter means that there are g ∈ DO, h ∈ G(XN )>0, and non-negative λ and µ such that max{λ, µ} > 0 for which f = λg + µh. Since we need to prove that f ∈ DO, we can assume without loss of generality that µ > 0. But then h = (f −λg)/µ ∈ G(XO) and therefore also h ∈ G(XO)>0, whence indeed f ∈ DO, by coherence of DO."
    }, {
      "heading" : "5. Conditioning",
      "text" : "Suppose that we have a set DN ⊆ G(XN ) of desirable gambles modelling a subject’s information about the uncertain variable XN .\nConsider a subset I of N , and assume we want to update the model DN with the information that XI = xI . This leads to an updated, or conditioned, set of desirable gambles:\nDN |xI := { f ∈ G(XN ) : f > 0 or I{xI}f ∈ DN } . (8)\nFor technical reasons, and mainly in order to streamline the proofs as much as possible, we also allow the admittedly pathological case that I = ∅. Since I{x∅} = 1, this amounts to not conditioning at all.\nEq. (8) introduces the conditioning operator ‘|’ essentially used by Walley (2000) and Moral (2005). We prefer the slightly modified version ‘⌋’, introduced by De Cooman and Quaeghebeur (2012). Since I{xI}f = I{xI}f(xI , ·), we can characterise the updated model DN |xI through the set\nDN⌋xI := { g ∈ G(XN\\I) : I{xI}g ∈ DN } ⊆ G(XN\\I),\nin the specific sense that for all g ∈ G(XN\\I):\ng ∈ DN⌋xI ⇔ I{xI}g ∈ DN ⇔ I{xI}g ∈ DN |xI , (9)\nand for all f ∈ G(XN ):\nf ∈ DN |xI ⇔ (f > 0 or f(xI , ·) ∈ DN⌋xI).\nAs the above equation shows, there is a one-to-one correspondence between DN |xI and DN⌋xI . We prefer this second operator because we find it more intuitive that conditioning a gamble on some xI ∈ XI produces a gamble that depends only on the remaining N \\ I variables. This will be useful for instance when combining conditional sets of gambles, as in Proposition 24 later on.\nIt is immediate to prove that conditioning preserves coherence:\nProposition 8. Let DN be a coherent set of desirable gambles on XN , and consider any subset I of N . Then DN⌋xI is a coherent set of desirable gambles on XN\\I .\nThe order of marginalisation and conditioning can be reversed, under some conditions:\nProposition 9. Let DN be a coherent set of desirable gambles on XN , and consider any disjoint subsets I and O of N . Then for all xI ∈ XI :\nmargO(DN⌋xI) = margI∪O(DN )⌋xI .\nProof. Consider any h ∈ G(XN ) and observe the following chain of equivalences:\nh ∈ margO(DN⌋xI) ⇔ h ∈ G(XO) and h ∈ DN⌋xI\n⇔ h ∈ G(XO) and I{xI}h ∈ DN ⇔ h ∈ G(XO) and I{xI}h ∈ margI∪O(DN ) ⇔ h ∈ G(XO) and h ∈ margI∪O(DN )⌋xI ⇔ h ∈ margI∪O(DN )⌋xI .\nTo end this section, let us briefly look at the consequences of this type of updating for the coherent lower previsions associated with coherent sets of desirable gambles. This will allow us to further back our claim that standard probability theory can be recovered as a special case of the theory of coherent sets of desirable gambles, as it also allows us to derive Bayes’s Rule.\nLet us denote by PN the lower prevision induced by the joint model DN , and by P (·|xI) the conditional lower prevision on G(XN\\I) induced by the updated set DN⌋xI . Then for any gamble g on XN\\I :\nP (g|xI) = sup {µ : g − µ ∈ DN⌋xI} = sup { µ : I{xI}[g − µ] ∈ DN } . (10)\nThis allows us to clarify further that sets of desirable gambles are indeed more informative than coherent lower previsions, again using the example by Moral (2005):\nExample 2. Consider again the lower prevision P and the coherent sets of desirable gambles D and D′ from Example 1. Consider the event that X1 = a, which has (upper) probability zero in both D and D′. When conditioning on this event, we obtain two different updated sets: on the one hand,\nD⌋(X1 = a) = {g ∈ G(X2) : g > 0} = G(X2)>0\nwhereas D′⌋(X1 = a) = {g ∈ G(X2) : g(a) + g(b) > 0} .\nThis means that there sets represent different information when conditioning on the event of probability zero X1 = a. Indeed, if we apply Eq. (10) we see that the first one induces the vacuous lower prevision P (g|X1 = a) = min{g(a), g(b)} for any gamble g on X2, while the second one induces the uniform linear prevision: P (g|X1 = a) = g(a)+g(b)\n2 .\nThe lower previsions PN and P (·|xI) then satisfy a condition called the Generalised Bayes Rule (this follows from Williams, 1975b and Miranda & Zaffalon, 2010, Thm. 8):\nPN (I{xI}[g − P (g|xI)]) = 0. (11)\nWe refer to the work by Walley (1991, 2000) for more information about this rule. It leads to Bayes’s Rule in the special case that the joint model DN induces a precise prevision PN . Indeed, if we let g = I{xN\\I} and generically denote probability mass by p, we infer from Eq. (11) and the linearity of PN that PN (I{xI}I{xN\\I}) = P (I{xN\\I}|xI)PN (I{xI}), or in other words that p(xN ) = p(xN\\I |xI)p(xI). See Section 2.6 for more details on the relationship between coherent lower (and linear) previsions and sets of desirable gambles.\nRemark 1. A lower prevision P is also in a one-to-one correspondence with a so-called set of almost desirable gambles, namely\nD := {f : P (f) ≥ 0} .\nThis set corresponds to the uniform closure of any coherent set of desirable gambles D that induces P by means of Eq. (2). Although sets of almost-desirable gambles are interesting, and allow us work with non-strict preference relations (Walley, 1991, Section 3.7.6), we have opted for considering the more general model of coherent sets of desirable gambles for two (admittedly related) reasons. Like sets of strictly desirable gambles, sets of almost-desirable gambles do not permit to elicit boundary behaviour, which may be important when updating, as we have discussed in Example 2. Moreover, conditioning a set of almost desirable gambles may produce incoherent models when sets of probability zero are involved (Miranda & Zaffalon, 2010, Proposition 5 and Example 2): if we take for instance X1 = X2 = {0, 1} and the linear prevision P with mass function p(0, ·) = 0 and p(·, 1) = 12 , then its associated set of almost desirable gambles is:\nD = {f : f(1, 0) + f(1, 1) ≥ 0} ,\nand if we use Eq. (8) to condition this set D on X1 = 0, we get G(X1,2), which is an incoherent set. This means that for such sets of almost desirable gambles, and more generally for sets of gambles associated with non-strict preferences, the conditioning operation must be modified in order to avoid producing incoherences. It turns out there is no unique way of doing this; see the work by Hermans (2012) for more details."
    }, {
      "heading" : "6. Irrelevant Natural Extension",
      "text" : "We are now ready to look at the simplest type of irrelevance judgement.\nDefinition 2. Consider two disjoint subsets I and O of N . We say that XI is epistemically irrelevant to XO when learning the value of XI does not influence or change our subject’s beliefs about XO.\nWhen does a set DN of desirable gambles on XN capture this type of epistemic irrelevance? Observing that XI = xI turns DN into the updated set DN⌋xI of desirable gambles on XN\\I , we come to the following definition:\nDefinition 3. A set DN of desirable gambles on XN is said to satisfy epistemic irrelevance of XI to XO when\nmargO(DN⌋xI) = margO(DN ) for all xI ∈ XI . (12)\nAs before, for technical reasons we also allow I and O to be empty. It is clear from the definition above that the ‘variable’ X∅, about whose constant value we are certain, is epistemically irrelevant to any variable XO. Similarly, we see that any variable XI is epistemically irrelevant to the ‘variable’ X∅. This seems to be in accordance with intuition. We refer to Levi (1980) and Walley (1982, 1991) for related notions in terms of coherent lower previsions or credal sets.\nThe epistemic irrelevance condition can be reformulated trivially in an interesting and slightly different manner.\nProposition 10. Let DN be a coherent set of desirable gambles on XN , and let I and O be any disjoint subsets of N . Then the following statements are equivalent:\n(i) margO(DN⌋xI) = margO(DN ) for all xI ∈ XI ;\n(ii) for all f ∈ G(XO) and all xI ∈ XI : f ∈ DN ⇔ I{xI}f ∈ DN .\nProof. It suffices to take into account that f ∈ margO(DN ) if and only if f ∈ DN and f ∈ G(XO), while f ∈ margO(DN⌋xI) if and only if f ∈ G(XO) and I{xI}f ∈ DN .\nIrrelevance assessments are most useful in constructing sets of desirable gambles from other ones. Suppose we have a coherent set DO of desirable gambles on XO, and an assessment that XI is epistemically irrelevant to XO, where I and O are disjoint index sets. Then how can we combine DO and this structural irrelevance assessment into a coherent set of desirable gambles on XI∪O, or more generally, on XN , where N ⊇ I ∪ O? To see how this can be done in a way that is as conservative as possible, we introduce the following sets\nAirrI→O := posi ({ I{xI}g : g ∈ DO and xI ∈ XI })\n(13)\n= {h ∈ G(XI∪O)6=0 : (∀xI ∈ XI)h(xI , ·) ∈ DO ∪ {0}} . (14)\nClearly, and this will be quite important in streamlining proofs, Airr∅→O = DO and A irr I→∅ = G(XI)>0. The intuition behind Eq. (13) is to consider the cylindrical extensions of the gambles in DO to the space XI∪O, and to take the natural extension of the resulting set. The alternative expression (14) shows that this is equivalent to selecting a gamble in DO for a finite number of xI in XI , and to derive from them a gamble on XI∪O.\nLet us give two important properties of these sets:\nLemma 11. Consider disjoint subsets I and O of N , and a coherent set DO of desirable gambles on XO. Then A irr I→O is a coherent set of desirable gambles on XI∪O.\nProof. D1. Assume ex absurdo that there are n > 0, real λk > 0 and fk ∈ A irr I→O such that ∑n\nk=1 λkfk = 0. It follows from the assumptions that there are ℓ ∈ {1, . . . , n} and xI ∈ XI such that fℓ(xI , ·) 6= 0. This implies that in the sum ∑n k=1 λkfk(xI , ·) = 0 not all the gambles λkfk(xI , ·) are zero. Since the non-zero ones belong to DO, this contradicts the coherence of DO.\nD2. Consider any h ∈ G(XI∪O)>0. Then clearly h(xI , ·) ≥ 0 and therefore h(xI , ·) ∈ DO ∪ {0} for all xI ∈ XI . Since h 6= 0, it follows that indeed h ∈ A irr I→O.\nD3. Trivial, using that posi(posi(D)) = posi(D) for any set of desirable gambles D.\nLemma 12. Consider disjoint subsets I and O of N , and a coherent set DO of desirable gambles on XO. Then margO(A irr I→O) = DO.\nProof. It is obvious from Eq. (14) that indeed:\nmargO(A irr I→O) = A irr I→O ∩ G(XO) = {h ∈ G(XO)6=0 : (∀xI ∈ XI)h ∈ DO ∪ {0}}\n= {h ∈ G(XO)6=0 : h ∈ DO ∪ {0}} = DO.\nTheorem 13. Consider disjoint subsets I and O of N , and a coherent set DO of desirable gambles on XO. Then the smallest coherent set of desirable gambles on XN that marginalises to DO and satisfies the epistemic irrelevance condition (12) of XI to XO is given by extN (A irr I→O) = posi(G(XN )>0 ∪ A irr I→O).\nProof. Consider any coherent set DN of desirable gambles on XN that marginalises to DO and satisfies the irrelevance condition (12). This implies that margO(DN⌋xI) = DO for any xI ∈ XI , so g ∈ DN⌋xI , and therefore I{xI}g ∈ DN for any g ∈ DO, by Eq. (9). So we infer by coherence that AirrI→O ⊆ DN , and therefore also that posi(G(XN )>0 ∪ A irr I→O) ⊆ DN . As a consequence, it suffices to prove that (i) extN (A irr I→O) is coherent, (ii) marginalises to DO, and (iii) satisfies the epistemic irrelevance condition (12). This is what we now set out to do.\n(i). By Lemma 11, AirrI→O is a coherent set of desirable gambles on XI∪O, so Proposition 7 implies that posi(G(XN )>0 ∪ A irr I→O) = extN (A irr I→O) is a coherent set of desirable gambles on XN . (ii). Marginalisation leads to:\nmargO(extN (A irr I→O)) = margO(margI∪O(extN (A irr I→O))) = margO(A irr I→O) = DO,\nwhere the first equality follows from Eq. (5), the second from Eq. (7), and the third from Lemma 12.\n(iii). It follows from Proposition 9 and Eq. (7) that\nmargO(extN (A irr I→O)⌋xI) = margI∪O(extN (A irr I→O))⌋xI = A irr I→O⌋xI ,\nand we have just shown in (ii) that margO(extN (A irr I→O)) = DO, so proving the equality margO(extN (A irr I→O)⌋xI) = margO(extN (A irr I→O)) amounts to proving that A irr I→O⌋xI = DO. It is obvious from the definition of AirrI→O that DO ⊆ A irr I→O⌋xI , so we concentrate on the converse inclusion. Consider any h ∈ AirrI→O⌋xI ; then I{xI}h ∈ A irr I→O, so we infer from Eq. (14) that in particular h ∈ DO ∪{0}. But since A irr I→O is coherent by Lemma 11, we see that h 6= 0 and therefore indeed h ∈ DO.\nTheorem 13 is mentioned briefly, with only a hint at the proof, by Moral (2005, Section 2.4). We believe the result is not so trivial and have therefore decided to include our version of the proof here. Our notion of epistemic irrelevance is called weak epistemic irrelevance by Moral. For his version of epistemic irrelevance he requires in addition that DN should be equal to the irrelevant natural extension of DO, and therefore be the smallest model that satisfies the (weak) epistemic irrelevance condition (12). While we feel comfortable with\nhis reasons for doing so, we have decided not to follow his lead in this. Our main reason for not doing so is tied up with the philosophy behind partial assessments (or probability specifications). Each such assessment, be it local (e.g. stating that all gambles in some set A are desirable) or structural (e.g. imposing symmetry or irrelevance), serves to further restrict the possible models, and at each stage the most conservative (smallest possible) model is considered to be the one to be used, and possibly further refined by additional assessments. Only calling a model irrelevant when it is the smallest weakly irrelevant model would, we believe, conflict with approach: larger models obtained later on by adding, say, further symmetry assessments, would no longer deserve to be called irrelevant (but would still satisfy all the relevant conditions).\nWe infer from Theorem 13 and Eq. (13) that extreme rays of the irrelevant natural extension have the form I{xI}g, where g is some extreme ray of DO, so representing or finding this extension on a computer has a computational complexity that is linear in the number of extreme rays of DO and linear in the number of elements of the product set XI— and therefore essentially exponential in the number |I| of irrelevant variablesXi, i ∈ I. More generally, this will also be the case in the fairly general situation where DO is generated by a finite number of so-called ‘generalised’ extreme rays, as described in detail in by Couso and Moral (2011, Section 4) and Quaeghebeur (2012a, Section 3)."
    }, {
      "heading" : "7. Independent Natural Extension",
      "text" : "We now turn to independence assessments, which constitute a symmetrisation of irrelevance assessments.\nDefinition 4. We say that the variables Xn, n ∈ N are epistemically independent when learning the values of any number of them does not influence or change our beliefs about the remaining ones: for any two disjoint subsets I and O of N , XI is epistemically irrelevant to XO.\nWhen does a set DN of desirable gambles on XN capture this type of epistemic independence?\nDefinition 5. A coherent set DN of desirable gambles on XN is called independent if\nmargO(DN⌋xI) = margO(DN ) for all disjoint subsets I and O of N , and all xI ∈ XI .\nIn this definition, we allow I and O to be empty too, but doing so does not lead to any substantive requirement, because the condition margO(DN⌋xI) = margO(DN ) is trivially satisfied when I or O are empty.\nIndependent sets have an interesting factorisation property, which means that a product of two desirable gambles that depend on different variables should again be desirable, provided one of the gambles is positive; we refer to the work by De Cooman et al. (2011) for another paper where factorisation is considered in this somewhat unusual form. Factorisation follows from the characterisation of epistemic irrelevance we have given in Proposition 10 and the properties of coherence.\nProposition 14 (Factorisation of independent sets). Let DN be an independent coherent set of desirable gambles on XN . Then for all disjoint subsets I and O of N and for all f ∈ G(XO):\nf ∈ DN ⇔ (∀g ∈ G(XI)>0)(fg ∈ DN ). (15)\nProof. Fix arbitrary disjoint subsets I and O of N and any f ∈ G(XO); we show that Eq. (15) holds. The ‘⇐’ part is trivial. For the ‘⇒’ part, assume that f ∈ DN and consider any g ∈ G(XI)>0. We have to show that fg ∈ DN . Since g = ∑\nxI∈XI I{xI}g(xI), we see\nthat fg = ∑\nxI∈XI g(xI)I{xI}f . Now since f ∈ margO(DN ), we infer from the independence\nof DN and Proposition 10 that f ∈ DN⌋xI and therefore I{xI}f ∈ DN for all xI ∈ XI . We conclude that fg is a positive linear combination of elements I{xI}f of DN , and therefore belongs to DN by coherence.\nIndependence assessments are useful in constructing joint sets of desirable gambles from marginal ones. Suppose we have coherent sets Dn of desirable gambles on Xn, for each n ∈ N and an assessment that the variables Xn, n ∈ N are epistemically independent. Then how can we combine the Dn and this structural independence assessment into a coherent set of desirable gambles on XN in a way that is as conservative as possible? If we call independent product of the Dn any independent DN ∈ D(XN ) that marginalises to the Dn for all n ∈ N , this means we are looking for the smallest such independent product.\nFurther on, we are going to prove that such a smallest independent product always exists. Before we can do this elegantly, however, we need to do some preparatory work involving particular sets of desirable gambles that can be constructed from the Dn. Consider, as a special case of Eq. (14), for any subset I of N and any o ∈ N \\ I:\nAirrI→{o} := posi ({ I{xI}g : g ∈ Do and xI ∈ XI })\n(16)\n= { h ∈ G(XI∪{o})6=0 : (∀xI ∈ XI)h(xI , ·) ∈ Do ∪ {0} } , (17)\nand use these sets to construct the following set of gambles on XN :\n⊗n∈NDn := posi\n(\nG(XN )>0 ∪ ⋃\nn∈N\nAirrN\\{n}→{n}\n)\n= posi\n(\n⋃\nn∈N\nAirrN\\{n}→{n}\n)\n, (18)\nwhere the second equality holds because the set G(XN )>0 is included inA irr N\\{n}→{n} for every n ∈ N . The set ⊗n∈NDn gathers the subsets of G(XN ) we can derive from the different Dn by means of an assumption of epistemic irrelevance, and considers the natural extension of their union, which is the minimal coherent superset (we shall show that it is indeed coherent in Proposition 15 below). Observe that, quite trivially, Airr{n}\\{n}→{n} = Dn and therefore ⊗m∈{n}Dm = Dn. We now prove a number of important properties for ⊗n∈NDn.\nProposition 15 (Coherence). Let Dn be coherent sets of desirable gambles on Xn, n ∈ N . Then ⊗n∈NDn is a coherent set of desirable gambles on XN .\nProof. Let, for ease of notation, AN := ⋃ n∈N A irr N\\{n}→{n}. It follows from Theorem 1 that we have to prove that AN avoids non-positivity. So consider any f ∈ posi(AN ), and assume ex absurdo that f ≤ 0. Then there are λn ≥ 0 and fn ∈ A irr N\\{n}→{n} such that\nf = ∑ n∈N λnfn and maxn∈N λn > 0 [recall that the A irr N\\{n}→{n} are convex cones, by Lemma 11]. Fix arbitrary m ∈ N . Let\nANm := { fm(xN\\{m}, ·) : xN\\{m} ∈ XN\\{m}, fm(xN\\{m}, ·) 6= 0 } ,\nthen it follows from Eq. (17) that ANm is a finite non-empty subset of Dm, so the coherence of Dm, Theorem 1 and Lemma 2 imply that there is some mass function pm on Xm with expectation operator Em such that (∀xm ∈ Xm)pm(xm) > 0 and\n(∀xN\\{m} ∈ XN\\{m})(fm(xN\\{m}, ·) 6= 0 ⇒ Em(fm(xN\\{m}, ·)) > 0).\nSo if we define the gamble gN\\{m} on XN\\{m} by letting\ngN\\{m}(xN\\{m}) := Em(fm(xN\\{m}, ·))\nfor all xN\\{m} ∈ XN\\{m}, then gN\\{m} > 0. Since we can do this for all m ∈ N , we can define the mass function pN on XN by letting pN (xN ) := ∏\nm∈N pm(xm) > 0 for all xN ∈ XN . The corresponding expectation operator EN is of course the product operator of the marginals Em. But then it follows from the reasoning and assumptions above that EN (f) = ∑ m∈N λmEN (fm) = ∑\nm∈N λmEN (gm) > 0, whereas f ≤ 0 leads us to conclude that EN (f) ≤ 0, a contradiction.\nLemma 16. Consider any disjoint subsets I, R and any o ∈ N \\ (I ∪R). Then f(xR, ·) ∈ Airr\nI→{o} ∪ {0} for all f ∈ A irr I∪R→{o} and all xR ∈ XR.\nProof. Fix f ∈ Airr I∪R→{o} and xR ∈ XR and consider the gamble g := f(xR, ·) on XI∪{o}. It follows from the assumptions that for all xI ∈ XI :\ng(xI , ·) = f(xR, xI , ·) ∈ Do ∪ {0},\nwhence indeed g ∈ Airr I→{o} ∪ {0}.\nProposition 17 (Marginalisation). Consider coherent marginal sets of desirable gambles Dn for all n ∈ N . Let R be any subset of N , then margR(⊗n∈NDn) = ⊗r∈RDr.\nProof. Since we are interpreting gambles on XR as special gambles on XN , it is clear from Eq. (17) that for any r ∈ R, Airr\nR\\{r}→{r} ⊆ A irr N\\{r}→{r}. Eqs. (6) and (18) now tell us that\nextN (⊗r∈RDr) ⊆ ⊗n∈NDn. If we invoke Eq. (7), this leads to\n⊗r∈RDr = margR(extN (⊗r∈RDr)) ⊆ margR(⊗n∈NDn),\nso we can concentrate on the converse inequality. Consider therefore any f ∈ margR(⊗n∈NDn) = (⊗n∈NDn) ∩ G(XR), and assume ex absurdo that f /∈ ⊗r∈RDr. It follows from the coherence of ⊗n∈NDn that f 6= 0 [see Proposition 15]. Since f ∈ ⊗n∈NDn, there are S ⊆ N , fs ∈ A irr N\\{s}→{s}, s ∈ S and g ∈ G(XN ) with g ≥ 0 such that f = g + ∑\ns∈S fs. Clearly S \\ R 6= ∅, because S \\ R = ∅ would imply that, with xN\\R any\nelement of XN\\R, f = f(xN\\R, ·) = g(xN\\R, ·) + ∑\ns∈S∩R fs(xN\\R, ·) ∈ ⊗r∈RDr, since we infer from Lemma 16 that fs(xN\\R, ·) ∈ A irr R\\{s}→{s} ∪ {0} for all s ∈ S ∩R.\nIt follows from the coherence of ⊗r∈RDr [Proposition 15], f /∈ ⊗r∈RDr and Lemma 3 that 0 /∈ posi({−f} ∪ ⊗r∈RDr). Let, for ease of notation,\nANS∩R := { fs(zN\\R, ·) : s ∈ S ∩R, zN\\R ∈ XN\\R, fs(zN\\R, ·) 6= 0 } .\nThen ANS∩R is clearly a finite subset of ⊗r∈RDr [to see this, use a similar argument as above, involving Lemma 16], so we infer from Lemma 2 that there is some mass function pR on XR with associated expectation operator ER such that\n\n \n \n(∀xR ∈ XR)pR(xR) > 0\n(∀s ∈ S ∩R)(∀zN\\R ∈ XN\\R)ER(fs(zN\\R, ·)) ≥ 0\nER(f) < 0.\nWe then infer from f = f(zN\\R, ·) = g(zN\\R, ·) + ∑ s∈S∩R fs(zN\\R, ·) + ∑\ns∈S\\R fs(zN\\R, ·) that for all zN\\R in XN\\R:\n0 > ER(f)− ER(g(zN\\R, ·))− ∑\ns∈S∩R\nER(fs(zN\\R, ·))\n= ∑\ns∈S\\R\nER(fs(zN\\R, ·)) = ∑\ns∈S\\R\n∑\nxR∈XR\npR(xR)fs(zN\\R, xR).\nThe gambles fs(·, xR) on XN\\R [where xR ∈ XR and s ∈ S \\R] can clearly not all be zero. The non-zero ones all belong to ⊗s∈N\\RDs for all s ∈ N \\R and all xR ∈ XR, by Lemma 16, so the coherence of the set of desirable gambles ⊗s∈N\\RDs [Proposition 15] guarantees that their positive linear combination h := ∑\ns∈S\\R\n∑\nxR∈XR pR(xR)fs(·, xR) also belongs to\n⊗s∈N\\RDs. This contradicts h ≤ 0. Hence indeed f ∈ ⊗r∈RDr.\nProposition 18 (Conditioning). Consider coherent marginal sets of desirable gambles Dn for all n ∈ N , and define ⊗n∈NDn by means of Eq. (18). Then ⊗n∈NDn is independent: for all disjoint subsets I and O of N , and all xI ∈ XI ,\nmargO(⊗n∈NDn⌋xI) = margO(⊗n∈NDn) = ⊗o∈ODo.\nThis could probably be proved indirectly using the ‘semi-graphoid’ properties of conditional epistemic irrelevance, proved by Moral (2005); it appears we need reverse weak union, reverse decomposition, and contraction. Here we give a direct proof. Proposition 17 can also be seen as a special case of the present result for I = ∅.\nProof. Fix arbitrary disjoint subsets I and O of N , and arbitrary xI ∈ XI . The second equality follows from Proposition 17, so we concentrate on proving that margO(⊗n∈NDn⌋xI) coincides with ⊗o∈ODo. The proof is similar to that of Proposition 17.\nWe first show that ⊗o∈ODo ⊆ ⊗n∈NDn⌋xI . Consider any gamble f ∈ ⊗o∈ODo, then we have to show that I{xI}f ∈ ⊗n∈NDn. By assumption, there are non-negative reals λo and µ, gambles fo ∈ A irr O\\{o}→{o} for all o ∈ O and g ∈ G(XO)>0 such that f = µg + ∑ o∈O λofo\nand max{µ,maxo∈O λo} > 0. Fix o ∈ O and let f ′ o := I{xI}fo ∈ G(XN ). Then it follows from the definition of Airr O\\{o}→{o} that f ′ o(zN\\{o}, ·) = I{xI}(zI)fo(zO\\{o}, ·) ∈ Do∪{0} for all zN\\{o} ∈ XN\\{o}. Since f ′ o 6= 0, the definition of A irr N\\{o}→{o} tells us that f ′ o ∈ A irr N\\{o}→{o}. Similarly, if we let g′ := I{xI}g ∈ G(XN ), then g ′ > 0. So it follows from Eq. (18) that indeed I{xI}f = µg ′ + ∑ o∈O λof ′ o ∈ ⊗n∈NDn.\nWe now turn to the converse inclusion, ⊗n∈NDn⌋xI ⊆ ⊗o∈ODo. Consider any gamble f ∈ G(XO) such that I{xI}f belongs to ⊗n∈NDn and assume ex absurdo that f /∈ ⊗o∈ODo. Let, for the sake of notational simplicity, C := N \\ (I ∪O).\nIt follows from the coherence of ⊗n∈NDn that f 6= 0 [see Proposition 15]. Since I{xI}f ∈ ⊗n∈NDn, there are S ⊆ N , fs ∈ A irr N\\{s}→{s}, s ∈ S and g ∈ G(XN ) with g ≥ 0 such that I{xI}f = g+ ∑\ns∈S fs. Clearly S \\O 6= ∅, because S \\O = ∅ would imply that, with xC any element of XC , f = g(xI , xC , ·) + ∑\ns∈S∩O fs(xI , xC , ·) ∈ ⊗o∈ODo, since Lemma 16 shows that fs(xI , xC , ·) ∈ A irr O\\{s}→{s} for all s ∈ S ∩O.\nIt follows from the coherence of ⊗o∈ODo [Proposition 15], f /∈ ⊗o∈ODo and Lemma 3 that 0 /∈ posi({−f} ∪ ⊗o∈ODo). Let, for ease of notation,\nANS∩O := {fs(xI , zC , ·) : s ∈ S ∩O, zC ∈ XC , fs(xI , zC , ·) 6= 0} .\nThen ANS∩O is clearly a finite subset of ⊗o∈ODo [to see this, use a similar argument as above, involving Lemma 16], so we infer from Lemma 2 that there is some mass function pO on XO with associated expectation operator EO such that\n\n \n \n(∀xO ∈ XO)pO(xO) > 0\n(∀s ∈ S ∩O)(∀zC ∈ XC)EO(fs(xI , zC , ·)) ≥ 0\nEO(f) < 0.\nSince f = g(xI , zC , ·)+ ∑ s∈S∩O fs(xI , zC , ·)+ ∑\ns∈S\\O fs(xI , zC , ·) for any choice of zC ∈ XC , we see that:\n0 > EO(f)−EO(g(xI , zC , ·)) − ∑\ns∈S∩O\nEO(fs(xI , zC , ·))\n= ∑\ns∈S\\O\nEO(fs(xI , zC , ·)) = ∑\ns∈S\\O\n∑\nxO∈XO\npO(xO)fs(xI , zC , xO)).\nSimilarly, for any zC ∈ XC and any zI ∈ XI \\ {xI} we then infer from 0 = g(zI , zC , ·) + ∑\ns∈S∩O fs(zI , zC , ·) + ∑ s∈S\\O fs(zI , zC , ·) that:\n0 ≥ −EO(g(zI , zC , ·)) − ∑\ns∈S∩O\nEO(fs(zI , zC , ·))\n= ∑\ns∈S\\O\nEO(fs(zI , zC , ·)) = ∑\ns∈S\\O\n∑\nxO∈XO\npO(xO)fs(zI , zC , xO)).\nHence\nh := ∑\ns∈S\\O\n∑\nxO∈XO\npO(xO)fs(·, ·, xO) ≤ 0.\nThe gambles fs(·, ·, xO) on XI∪C [where xO ∈ XO and s ∈ S \\ O] can clearly not all be zero. The non-zero ones all belong to ⊗s∈I∪CDs, by Lemma 16. But then the coherence of the set of desirable gambles ⊗s∈I∪CDs [Proposition 15] guarantees that their positive linear combination h is an element of ⊗c∈CDc for which h ≤ 0, a contradiction. Hence indeed f ∈ ⊗o∈ODo.\nTheorem 19 (Independent natural extension). Consider the coherent sets Dn of desirable gambles on Xn, n ∈ N . Then ⊗n∈NDn is the smallest coherent set of desirable gambles on XN that is an independent product of the coherent sets of desirable gambles Dn, n ∈ N .\nWe call ⊗n∈NDn the independent natural extension of the marginals Dn.\nProof. It follows from Propositions 15, 17 and 18 that ⊗n∈NDn is an independent product DN of the Dn. To prove that it is the smallest one, consider any independent product DN of the Dn. Fix n ∈ N . If we consider any xN\\{n} ∈ XN\\{n}, then margn(DN⌋xN\\{n}) = Dn, by assumption. If we therefore consider any g ∈ Dn, this in turn implies that g ∈ DN⌋xN\\{n}, and therefore I{xN\\{n}}g ∈ DN , by Eq. (9). So we infer by coherence that A irr N\\{n}→{n} ⊆ DN , and therefore also that ⊗n∈NDn ⊆ DN .\nOne of the most useful properties of the independent natural extension, is its associativity: it allows us to construct the extension in a modular fashion.\nTheorem 20 (Associativity of independent natural extension). Let N1 and N2 be disjoint non-empty index sets, and consider Dnk ∈ D(Xnk), nk ∈ Nk, k = 1, 2. Then given DN1 := ⊗n1∈N1Dn1 and DN2 := ⊗n2∈N2Dn2 , it holds that\nDN1 ⊗DN2 = ⊗n∈N1∪N2Dn.\nProof. We first prove that DN1 ⊗ DN2 ⊆ ⊗n∈N1∪N2Dn. Fix any gamble h ∈ A irr {N1}→{N2} and any xN1 ∈ XN1 , so h(xN1 , ·) ∈ DN2 ∪ {0} by Eq. (17). It follows from Eq. (18) that there are gambles hn2xN1 ∈ Airr N2\\{n2}→{n2} ∪ {0} for all n2 ∈ N2 such that\nh(xN1 , ·) ≥ ∑\nn2∈N2\nhn2xN1 .\nDefine, for any n2 ∈ N2, the gamble gn2 on XN by letting gn2(xN\\{n2}, ·) := h n2 xN1 (xN2\\{n2}, ·) for all xN ∈ XN . Then it follows from Eq. (17) that gn2(xN\\{n2}, ·) ∈ Dn2 ∪ {0} for all xN ∈ XN , and therefore gn2 ∈ A irr N\\{n2}→{n2} ∪ {0}. Moreover,\nh = ∑\nxN1∈XN1\nI{xN1} h(xN1 , ·)\n≥ ∑\nxN1∈XN1\nI{xN1}\n∑\nn2∈N2\nhn2xN1 =\n∑\nn2∈N2\n∑\nxN1∈XN1\nI{xN1} hn2xN1\n= ∑\nn2∈N2\ngn2 ,\nIt therefore follows from Eq. (18) that h ∈ ⊗n∈N1∪N2Dn, since clearly h 6= 0 because of Eq. (17). We conclude that Airr{N1}→{N2} ⊆ ⊗n∈N1∪N2Dn. Similarly, we can prove the\ninclusion Airr{N2}→{N1} ⊆ ⊗n∈N1∪N2Dn, and therefore also DN1 ⊗DN2 ⊆ ⊗n∈N1∪N2Dn, again by Eq. (18). Next, we prove the converse inclusion ⊗n∈N1∪N2Dn ⊆ DN1 ⊗DN2 . Consider any gamble h ∈ ⊗n∈N1∪N2Dn, then by Eq. (18) there are hn ∈ A irr N1∪N2\\{n}→{n}\n∪{0} for all n ∈ N1∪N2 such that\nh ≥ ∑\nn∈N\nhn = h1 + h2, where h1 := ∑\nn1∈N1\nhn1 and h2 := ∑\nn2∈N2\nhn2 .\nFix any xN1 ∈ XN1 . For any n2 ∈ N2, hn2 ∈ A irr N1∪N2\\{n2}→{n2} ∪ {0} implies that hn2(xN1 , ·) ∈ A irr N2\\{n2}→{n2} ∪{0} by Lemma 16. Hence h2(xN1 , ·) ∈ DN2 ∪{0} by Eq. (18), and therefore h2 ∈ A irr {N1}→{N2} ∪ {0} by Eq. (17). Similarly, h1 ∈ A irr {N2}→{N1} ∪ {0}, and therefore h ∈ DN1 ⊗DN2 by Eq. (18), since clearly h 6= 0.\nTo conclude this section, we establish a connection between independent natural extension for sets of desirable gambles and the eponymous notion for coherent lower previsions, studied in detail by De Cooman et al. (2011). Given coherent lower previsions Pn on G(Xn), n ∈ N , their independent natural extension is the coherent lower prevision given by\nEN (f) := sup hn∈G(XN )\nn∈N\nmin zN∈XN\n[\nf(zN )− ∑\nn∈N\n[hn(zN )− Pn(hn(·, zN\\{n}))]\n]\n(19)\nfor all gambles f on XN . It is the point-wise smallest (most conservative) joint lower prevision that satisfies the property of coherence by Walley (1991, ch. 7) with the marginals Pn given an assessment of epistemic independence of the variables Xn, n ∈ N .\nThe correspondence between coherent lower previsions and sets of desirable gambles has been mentioned in Section 2.6; we show next that if we have such a correspondence between the marginals, it also holds between their associated independent natural extensions.\nTheorem 21. Let Dn be coherent sets of desirable gambles on Xn for n ∈ N , and let ⊗n∈NDn be their independent natural extension. Consider the coherent lower previsions Pn on G(Xn) given by Pn(fn) := sup {µ ∈ R : fn − µ ∈ Dn} for all fn ∈ G(Xn). Then the independent natural extension EN of the marginal lower previsions Pn, n ∈ N satisfies\nEN (f) = sup {µ ∈ R : f − µ ∈ ⊗n∈NDn} for all f ∈ G(XN ).\nProof. Fix any gamble f in G(XN ). First, consider any real number µ < EN (f), then it follows from Eq. (19) that there are δ > 0 and hn ∈ G(XN ), n ∈ N such that f − µ ≥ ∑\nn∈N gn, where we defined the gambles gn on XN by gn(zN ) := hn(zN )−Pn(hn(zN\\{n}, ·))+ δ for all zN ∈ XN . But it follows from the definition of Pn that\ngn(zN\\{n}, ·) = hn(zN\\{n}, ·)− Pn(hn(zN\\{n}, ·)) + δ ∈ Dn for all zN\\{n} ∈ XN\\{n}.\nSince clearly gn 6= 0, Eq. (17) then tells us that gn ∈ A irr N\\{n}→{n}, and we infer from Eq. (18) that ∑\nn∈N gn ∈ ⊗n∈NDn, and therefore also f − µ ∈ ⊗n∈NDn. This guarantees that EN (f) ≤ sup {µ ∈ R : f − µ ∈ ⊗n∈NDn}.\nTo prove the converse inequality, consider any real number µ such that f−µ ∈ ⊗n∈NDn. We infer using Eq. (18) that there are gambles hn ∈ A irr N\\{n}→{n}, n ∈ N such that f − µ ≥ ∑\nn∈N hn. For all n ∈ N and zN\\{n} ∈ XN\\{n}, it follows from Eq. (17) that hn(zN\\{n}, ·) ∈ Dn ∪ {0}, and therefore Pn(hn(zN\\{n}, ·)) ≥ 0, whence\n∑\nn∈N\n[ hn(zN )− Pn(hn(zN\\{n}, ·)) ] ≤ ∑\nn∈N\nhn(zN ) ≤ f(zN )− µ.\nWe then infer from Eq. (19) that EN (f) ≥ µ and so we find that indeed also EN (f) ≥ sup {µ ∈ R : f − µ ∈ ⊗n∈NDn}.\nIn a similar way as for the irrelevant natural extension, we infer from Eqs. (16) and (18) that the computational complexity of finding or representing the independent natural extension of a number of marginal models Dn is linear in the number of extreme rays of the Dn, and linear in the number of elements of the sets XN\\{n}—and therefore essentially exponential in the number |N | of independent variables Xn, n ∈ N . Similar results will hold in the more general case that the marginal sets of desirable gambles can be characterised using a finite number of ‘generalised’ extreme rays, as described by Couso and Moral (2011) and Quaeghebeur (2012a)."
    }, {
      "heading" : "8. Maximal Coherent Sets of Desirable Gambles and Strong Products",
      "text" : "We have seen that for any collection Dn, n ∈ N of marginal coherent sets of desirable gambles, there always is a smallest independent product, which we have called the independent natural extension ⊗n∈NDn. We have proceeded in this way because we had no way of excluding that there may be other, larger, independent products. Indeed, we show in this section that such is the case. Using the notions of independent natural extension and maximal coherent sets of desirable gambles, we can consistently define a specific independent product that typically strictly includes the independent natural extension. We call it the strong product, because it is very close in spirit to the strong product used in coherent lower prevision theory (Couso, Moral, & Walley, 2000; Cozman, 2000, 2005; De Cooman et al., 2011), as we shall see in Theorem 28."
    }, {
      "heading" : "8.1 Independent Products of Maximal Coherent Sets of Desirable Gambles",
      "text" : "We begin by mentioning a number of interesting facts about maximal coherent sets of desirable gambles, and their independent products. The following result was already (essentially) proved by Couso and Moral (2011): updating a coherent set of desirable gambles preserves its maximality.\nProposition 22. Let MN ∈ M(XN ), and consider any disjoint subsets I and O of N . Then margO(MN⌋xI) ∈ M(XO) for all xI ∈ XI .\nProof. Suppose there is some xI in XI for which margO(MN⌋xI) is not maximal. This means that there is some f ∈ G(XO) for which neither f nor −f belong to MN⌋xI , which in turn implies that neither I{xI}f nor −I{xI}f belong to MN . But this contradicts the maximality of MN .\nOn the other hand, taking the independent natural extension does not necessarily preserve maximality: if Mn ∈ M(Xn) for all n ∈ N , then it does not necessarily hold that ⊗n∈NMn ∈ M(XN ), as the counterexample in Section A.1 shows. Interestingly, that example does not present an isolated case: when we consider two binary variables, the independent natural extension of two maximal coherent sets of desirable gambles is never maximal, as we can see in our next proposition. It is an open problem whether this negative result can be extended to any finite set of (not necessarily binary) variables.\nAn intuitive explanation of this result is that each of the maximal sets of gambles is a half-space where we are excluding one of the two rays determining its boundary, so as not to have the zero gamble as desirable; and when we apply the notion of independent natural extension we end up missing three of the four parts of the boundary of the set of gambles in the product space, preventing this product from being maximal.\nProposition 23. Consider X1 = X2 = {0, 1}, and let M1 and M2 be any maximal coherent sets of desirable gambles on X1 and X2, respectively. Then their independent natural extension M1 ⊗M2 is not a maximal coherent set of desirable gambles.\nProof. Let pk be the mass function of the linear prevision Pk determined by Mk, k = 1, 2. We deduce from Theorem 21 that the lower prevision determined by M1 ⊗M2 is the independent natural extension of the linear previsions P1 and P2, and therefore equal to the independent product P{1,2} of these linear previsions [see Proposition 25 in De Cooman et al., 2011]. This is the linear prevision on G(X{1,2}) with mass function defined by p{1,2}(x1, x2) := p1(x1)p2(x2) for all (x1, x2) ∈ X{1,2}.\nBefore we really get the proof on the tracks, we make a useful observation. Any maximal Mk is a semi-plane through the origin that excludes the origin, includes its boundary on one side of the origin, and excludes the boundary on the other side. This means that there is unique element ak of Xk where all the elements fk of the included boundary—those elements fk of Mk for which Pk(fk) is zero—are positive fk(ak) > 0. We denote the single other element of Xk by bk. In other words, if we express\nMk = {fk : Pk(fk) > 0} ∪ {fk : Pk(fk) = 0, fk ∈ Mk},\nand consider fk ∈ Mk with Pk(fk) = pk(ak)fk(ak) + pk(bk)fk(bk) = 0, then if fk(ak) > 0 there cannot be any gk ∈ Mk with Pk(gk) = 0 and gk(bk) > 0: otherwise, the zero gamble would be a convex combination of fk and gk [it would be 0 = fk− fk(bk) gk(bk)\ngk] and it would thus belong to Mk, a contradiction with its coherence. Note that in this reasoning we assume implicitly that pk(ak) ∈ (0, 1); otherwise, if for instance pk(ak) = 0, a gamble fk satisfies Pk(fk) = 0 if and only if fk(bk) = 0, and then fk can only belong to Mk if fk(ak) > 0.\nWe are now ready to turn to the proof. There are a number of possibilities.\nFirst, assume that both pk(ak) > 0 and pk(bk) > 0 for k = 1, 2. Consider any gamble h on X{1,2} such that h(a1, a2) = h(b1, b2) = 0, minh < 0, maxh > 0 and\nP{1,2}(h) = p1(a1)p2(b2)h(a1, b2) + p1(b1)p2(a2)h(b1, a2) = 0.\nOf course, there always is such a gamble, and we are going to show that it does not belong to M1 ⊗M2.\nAssume ex absurdo that it does, meaning that there are h1 ∈ A irr {2}→{1} and h2 ∈ Airr{1}→{2} such that h ≥ h1 + h2. By definition, h1(·, x2) ∈ M1 ∪ {0} and therefore P1(h1(·, x2)) ≥ 0 for all x2 ∈ X2. Similarly, P2(h2(x1, ·)) ≥ 0 for all x1 ∈ X1. Hence 0 = P{1,2}(h) ≥ P{1,2}(h1) + P{1,2}(h2) ≥ 0, taking into account that\nP{1,2}(h1) = ∑\nx2∈X2\np2(x2)P1(h1(·, x2)) ≥ 0 and P{1,2}(h2) = ∑\nx1∈X1\np1(x1)P2(h2(x1, ·)) ≥ 0.\nAs a consequence, P{1,2}(h1) = P{1,2}(h2) = 0. But this in turn implies that P1(h1(·, x2)) = 0 for all x2 ∈ X2 and that P2(h2(x1, ·)) = 0 for all x1 ∈ X1. Given the observations made at the start of the proof, we therefore come to the conclusion that h1(a1, x2) ≥ 0 for all x2 ∈ X2 and h2(x1, a2) ≥ 0 for all x1 ∈ X1. But then h(a1, a2) = 0 implies that h1(a1, a2) = h2(a1, a2) = 0, which in turn implies that h1(b1, a2) = h2(a1, b2) = 0, because both 0 = P1(h1(·, a2)) = p1(a1)h1(a1, a2) + p1(b1)h1(b1, a2) and 0 = P2(h2(a1, ·)) = p2(a1)h1(a1, a2) + p2(b1)h1(a1, b2). So we eventually find that\nh(b1, a2) ≥ h1(b1, a2) + h2(b1, a2) ≥ 0 and h(a1, b2) ≥ h1(a1, b2) + h2(a1, b2) ≥ 0,\nwhich contradicts minh < 0. Now, if any non-zero h such that h(a1, a2) = h(b1, b2) = 0 = P{1,2}(h) with minh < 0 and maxh > 0 does not belong toM1⊗M2, neither does −h, and this means thatM1⊗M2 is not maximal.\nNext we consider the cases where one of the marginal linear previsions are degenerate. Assume for instance that p1(a1) = 0 and p2(a2) ∈ (0, 1) [the other cases where only one of the marginals is degenerate are similar]. Consider a non-zero gamble h2 /∈ M2 such that P2(h2) = 0 [always possible]. Then −h2 ∈ M2 and it follows from the observations made in the beginning of this proof that h2(a2) < 0. Now consider the gamble h defined by\nh(b1, a2) := h2(a2) < 0, h(b1, b2) := h2(b2) ≥ 0, h(a1, a2) = h(a1, a2) := 1.\nIt follows that P{1,2}(h) = P2(h2) = 0. To see that h /∈ M1 ⊗ M2, assume that there are f1 ∈ A irr {2}→{1} and f2 ∈ A irr {1}→{2} such that h ≥ f1 + f2. But then 0 = P{1,2}(h) ≥ P{1,2}(f1) +P{1,2}(f2) ≥ 0 and therefore 0 = P{1,2}(f1) = p2(a2)f1(b1, a2) + p2(b2)f1(b1, b2). On the other hand, f1 ∈ A irr {2}→{1} also implies that P1(f1(·, x2)) ≥ 0 for all x2 ∈ X2, and therefore f1(b1, a2) ≥ 0 and f1(b1, b2) ≥ 0. Hence f1(b1, ·) = 0, and therefore f2(b1, ·) ≤ h(b1, ·) = h2 and since h2 /∈ M2, it follows that f2(b1, ·) /∈ M2. Because we must have by definition that f2(b1, ·) ∈ M2 ∪ {0}, this can only mean that f2(b1, ·) = 0, whence h2 ≥ 0, contradicting h2(a2) < 0. This implies that h cannot belong to M1 ⊗M2.\nSimilarly, if −h belongs to M1 ⊗ M2, then there must be g1 ∈ A irr {2}→{1} and g2 ∈ Airr{1}→{2} such that −h ≥ g1 + g2. But then 0 = P{1,2}(−h) ≥ P{1,2}(g1) + P{1,2}(g2) ≥ 0, whence 0 = P{1,2}(g1) = p2(a2)g1(b1, a2) + p2(b2)g1(b1, b2). But g1 ∈ A irr {2}→{1} also implies that P1(g1(·, x2)) ≥ 0 for all x2 ∈ X2, and therefore g1(b1, a2) ≥ 0 and g1(b1, b2) ≥ 0. Hence g1(b1, ·) = 0, and therefore we find that g1(a1, a2) ≥ 0 and g1(a1, b2) ≥ 0 [if, say, g1(a1, a2) < 0 then g1(·, a2) < 0 because also g1(b1, a2) = 0, which contradicts that g1(·, a2) ∈ M1 ∪ {0}, a consequence of g1 ∈ A irr {2}→{1}]. Since, moreover, g2 ∈ A irr {1}→{2} implies that 0 ≤ P2(g2(a1, ·)) = p2(a2)g2(a1, a2) + p2(b2)g2(a1, b2) and therefore also that\ng2(a1, a2) ≥ 0 or g2(a1, b2) ≥ 0, it follows that −h(a1, a2) ≥ 0 or −h(a1, b2) ≥ 0, which contradicts −h(a1, a2) = −h(a1, b2) = −1 < 0. Hence, −h does not belong to M1 ⊗ M2 either, so M1 ⊗M2 is not maximal.\nFinally, we turn to the cases where all marginals are degenerate. Assume for instance that p1(a1) = p2(a2) = 0 [the other cases where both marginals are degenerate, are similar]. Consider the gamble h given by\nh(a1, a2) = h(b1, b2) = 0, h(b1, a2) = 1, h(a1, b2) = −1,\nthen P{1,2}(h) = p1(b1)p2(b2)h(b1, b2) = 0. To see that h /∈ M1 ⊗M2, assume ex absurdo that there are u1 ∈ A irr {2}→{1} and u2 ∈ A irr {1}→{2} such that h ≥ u1+u2. Then u1 ∈ A irr {2}→{1} implies that\nu1(b1, b2) = P1(u1(·, b2)) ≥ 0 and u1(b1, a2) = P1(u1(·, a2)) ≥ 0,\nand similarly u2 ∈ A irr {1}→{2} implies that u2(b1, b2) = P2(u2(b1, ·)) ≥ 0 and u2(a1, b2) = P2(u2(a1, ·)) ≥ 0. Now it also follows from P{1,2}(h) = 0, P{1,2}(u1) ≥ 0 and P{1,2}(u2) ≥ 0 that u1(b1, b2) = P{1,2}(u1) = 0 and u2(b1, b2) = P{1,2}(u2) = 0, and as a consequence we find that u1(a1, b2) ≥ 0 and u2(b1, a2) ≥ 0 [if, say, u1(a1, b2) < 0 then u1(·, b2) < 0 because also u1(b1, b2) = 0, which contradicts u1(·, b2) ∈ M1∪{0}, a consequence of u1 ∈ A irr {2}→{1}]. As a consequence, −1 = h(a1, b2) ≥ u1(a1, b2) + u2(a1, b2) ≥ 0, a contradiction. Hence indeed, h does not belong to M1 ⊗M2.\nFinally, assume ex absurdo that there are v1 ∈ A irr {2}→{1} and v2 ∈ A irr {1}→{2} such that\n−h ≥ v1 + v2. Then v1 ∈ A irr {2}→{1} implies that\nv1(b1, b2) = P1(v1(·, b2)) ≥ 0 and v1(b1, a2) = P1(v1(·, a2)) ≥ 0,\nand similarly v2 ∈ A irr {1}→{2} implies that v2(b1, b2) = P2(v2(b1, ·)) ≥ 0 and v2(a1, b2) = P2(v2(a1, ·)) ≥ 0. Now it also follows from P{1,2}(−h) = 0, P{1,2}(v1) ≥ 0 and P{1,2}(v1) ≥ 0 that v1(b1, b2) = P{1,2}(v1) = 0 and v2(b1, b2) = P{1,2}(v2) = 0, and as a consequence we find that v1(a1, b2) ≥ 0 and v2(b1, a2) ≥ 0 [if, say, v1(a1, b2) < 0 then v1(·, b2) < 0 because also v1(b1, b2) = 0, which contradicts v1(·, b2) ∈ M1 ∪ {0}, a consequence of v1 ∈ A irr {2}→{1}]. As a consequence, −1 = −h(b1, a2) ≥ v1(b1, a2) + v2(b1, a2) ≥ 0, a contradiction. This shows that −h does not belong to M1 ⊗M2 either, and therefore this set is not maximal.\nOn the other hand, the Example A.2 in the Appendix shows that there are independent products of maximal coherent sets of desirable gambles that are maximal; hence, the independent natural extension of maximal coherent sets is not their only independent product. Indeed, we can establish the following result:\nProposition 24. Consider maximal coherent sets of desirable gambles M1 ∈ M(X1) and M2 ∈ M(X2).\n(i) Let D{1,2} be any coherent set of desirable gambles on X{1,2} such that M1 ⊗M2 ⊆ D{1,2}. Then D{1,2} is independent with marginals M1 and M2.\n(ii) As a consequence, a maximal set of gambles M{1,2} is an independent product of its marginals if and only if M{1,2}⌋x2 is the same for all x2 ∈ X2 and M{1,2}⌋x1 is the same for all x1 ∈ X1.\nProof. (i). We have for every x1 ∈ X1 that M2 = (M1 ⊗ M2)⌋x1 ⊆ D{1,2}⌋x1, where the equality follows from Proposition 18. Since M2 is maximal, this implies that M2 = D{1,2}⌋x1 for all x1 ∈ X1, and a similar argument shows that M1 = D{1,2}⌋x2 for all x2 ∈ X2. On the other hand, it follows from Proposition 17 that M2 = marg2(M1⊗M2) ⊆ marg2(D{1,2}). Since M2 is maximal, this implies that M2 = marg2(D{1,2}), and a similar argument shows that M1 = marg1(D{1,2}). In summary, we see that marg1(D{1,2}) = D{1,2}⌋x2 for all x2 ∈ X2, and marg2(D{1,2}) = D{1,2}⌋x1 for all x1 ∈ X1, showing that D{1,2} is indeed independent.\n(ii). It follows from the definition of an independent product that it is necessary that M{1,2}⌋x2 and M{1,2}⌋x1 should be the same for all x2 and x1, respectively. To see that this is also a sufficient condition for M{1,2} to be an independent product, note that in that case M{1,2}⌋x1⊗M{1,2}⌋x2 ⊆ M{1,2}, and that the sets M{1,2}⌋x1 and M{1,2}⌋x2 are maximal, by Proposition 22. On the other hand, Proposition 17 implies that\nmarg1(M{1,2}⌋x1 ⊗M{1,2}⌋x2) = M{1,2}⌋x1 ⊆ marg1(M{1,2}),\nso both sets are equal. Similarly, we deduce that\nmarg2(M{1,2}⌋x1 ⊗M{1,2}⌋x2) = M{1,2}⌋x2 ⊆ marg2(M{1,2}),\nand therefore marg1(M{1,2}) ⊗ marg2(M{1,2}) ⊆ M{1,2}. Invoking the first part of the proposition, we find that M{1,2} is an independent product of its marginals.\nThe first part of this proposition provides us with a simple characterisation of the independent products of two maximal sets: they are simply those coherent supersets of the independent natural extension; in particular, this means that any maximal superset of this independent natural extension will be an independent product, so two maximal sets always have maximal products (although these will differ from the independent natural extension). The second part implies that if the sets of conditional gambles coincide for all the conditioning events, then they automatically agree with the marginal sets of gambles, and as a consequence the set is an independent product."
    }, {
      "heading" : "8.2 The Strong Product and Its Properties",
      "text" : "Now consider the case where we have coherent marginal sets of desirable gambles Dn for all n ∈ N . We define their strong product ⊠n∈NDn as the set of desirable gambles on the product space XN given by: 8\n⊠n∈NDn := ⋂ {⊗n∈NMn : Mn ∈ m(Dn), n ∈ N} ,\nwhere m(Dn) is given by Eq. (1). This strong product corresponds is the set of desirable gambles determined by a notion of independence that is more restrictive than those of epistemic irrelevance and independence considered so far: that of strong independence (Couso et al., 2000; Cozman, 2012), sometimes called type-3 independence (de Campos & Moral,\n8. As this paper focusses on independent natural extension, because that has a much more direct behavioural justification, we will forgo discussing the complexity of computing this strong product, which, on the face of it, appears to be significantly higher than that for independent natural extension.\n1995). Strong independence means that the associated joint credal set is the convex hull of the set of linear previsions that are the stochastic independent products of linear previsions that dominate the marginals; or, equivalently, that the associated lower prevision is the lower envelope of the products of the linear previsions that dominate the marginals. This will be clearer after Theorem 28.\nFor maximal coherent sets of desirable gambles Mn ∈ M(Xn), n ∈ N the strong product and the independent natural extension coincide: ⊠n∈NMn = ⊗n∈NMn, as clearly m(Mn) = {Mn}. Taking into account Proposition 23, we deduce that the strong product of maximal coherent sets of desirable gambles is not necessarily maximal; Example A.2 in the Appendix shows that there are other independent products that may strictly include the strong product.\nThe marginalisation properties of the strong product follow directly from those of the independent natural extension.\nProposition 25 (Marginalisation). Consider coherent sets of desirable gambles Dn for all n ∈ N . Let R be any subset of N , then margR(⊠n∈NDn) = ⊠r∈RDr.\nProof. Consider any f ∈ G(XR) and observe the following chain of equivalences:\nf ∈ ⊠n∈NDn ⇔ (∀Mn ∈ m(Dn), n ∈ N)f ∈ ⊗n∈NMn\n⇔ (∀Mn ∈ m(Dn), n ∈ N)f ∈ ⊗r∈RMr\n⇔ (∀Mr ∈ m(Dr), r ∈ R)f ∈ ⊗r∈RMr\n⇔ f ∈ ⊠r∈RDr,\nwhere the second equivalence follows from Proposition 17.\nNext, we show that the strong product of some coherent marginal sets of desirable gambles Dn is an independent product of these marginals. In order to do so, we first establish the following simple yet powerful result:\nProposition 26. Let DjN , j ∈ J be any non-empty family of independent coherent sets of desirable gambles on XN . Then their intersection DN := ⋂ j∈J D j N is an independent coherent set of desirable gambles on XN .\nProof. Consider any disjoint subsets I and O of N , and any xI ∈ XI . Then\nh ∈ margO(DN⌋xI) ⇔ (∀j ∈ J)h ∈ margO(D j N⌋xI)\n⇔ (∀j ∈ J)h ∈ margO(D j N ) ⇔ h ∈ margO(DN ).\nProposition 27. Consider coherent marginal sets of desirable gambles Dn for all n ∈ N . Then their strong product ⊠n∈NDn is an independent product of these marginals.\nProof. Taking into account Proposition 26, all we need to show is that the sets Dn are the marginals of the strong product ⊠n∈NDn. This is an immediate consequence of Proposition 25.\nThe strong product may strictly include the independent natural extension, as we can see from the example in Section A.3. It is an open question whether, like the independent natural extension, the strong product is associative. Although we have not been able to prove associativity in general, it is not difficult to show that it suffices to establish it for maximal sets of desirable gambles, and that one of the inclusions, namely ⊠n∈N1∪N2Mn ⊆ (⊠n∈N1Mn) ⊠ (⊠n∈N2Mn) holds because the strong product always includes the independent natural extension. We suspect, but have not been able to prove, that the converse inclusion also holds, and that the strong product is associative, taking into account that in its definition we are taking the intersection of sets of gambles determined by an associative operator (the independent natural extension).\nTo conclude this section, we establish a connection between the strong product of sets of desirable gambles and the eponymous notion for coherent lower previsions, studied for instance by De Cooman et al. (2011) (see also Cozman, 2012 for comments on the corresponding notion in terms of credal sets, which is sometimes called the strong extension). Given coherent lower previsions Pn on G(Xn), n ∈ N , their strong product is the coherent lower prevision defined by\nSN (f) := inf {×n∈NPn(f) : (∀n ∈ N)Pn ∈ M(Pn)}\nfor all gambles f on XN ; the intuition behind this notion, taking into account the correspondence between coherent lower previsions and sets of desirable gambles discussed in Section 2.6, is that the intersection of a family of sets of desirable gambles is closely related to taking the lower envelope of the associated family of coherent lower previsions.\nIf we start from linear previsions Pn on G(Xn), their strong product corresponds to their linear product ×n∈NPn, and it coincides also with their independent natural extension EN . If we begin with coherent lower previsions Pn on G(Xn), their strong product SN is the lower envelope of the set of strong products determined by the dominating linear previsions.\nTheorem 28. Let Dn be coherent sets of desirable gambles in G(Xn) for all n ∈ N , and let ⊠n∈NDn be their strong product. Consider the coherent lower previsions Pn on G(Xn) given by Pn(f) := sup {µ ∈ R : f − µ ∈ Dn}. Then the strong product SN of the marginal lower previsions Pn, n ∈ N satisfies\nSN (f) = sup {µ ∈ R : f − µ ∈ ⊠n∈NDn} .\nProof. Assume first of all that Dn is a maximal coherent set of desirable gambles for all n in N . Then it follows that Pn is a linear prevision, which we denote by Pn, for all n ∈ N . The strong product of the linear previsions Pn, n ∈ N coincides with their linear independent product ×n∈NPn, which is also their independent natural extension (use Proposition 10 from De Cooman et al., 2011). Since we have proved in Theorem 21 that this is the coherent lower prevision associated with ⊗n∈NDn = ⊠n∈NDn, we conclude that the strong product ⊠n∈NDn is associated with the strong product of the linear previsions Pn.\nWe move next to the general case. Fix any gamble f on XN . Consider any real number µ < SN (f). For any n ∈ N , consider any maximal coherent set of desirable gambles Mn ∈ m(Dn), and the associated linear prevision Pn, then clearly Pn ∈ M(P n). Hence ×n∈NPn(f) ≥ SN (f) > µ, and we infer from the arguments above that then necessarily\nf − µ ∈ ⊗n∈NMn. Hence f − µ ∈ ⊠n∈NDn. This leads to the conclusion that SN (f) ≤ sup {µ ∈ R : f − µ ∈ ⊠n∈NDn}.\nConversely, consider any real number µ such that f − µ ∈ ⊠n∈NDn. Consider arbitrary Pn ∈ M(P n), n ∈ N , then there are maximal coherent sets of desirable gambles Mn ∈ m(Dn) inducing them: let Dn be the set of strictly desirable gambles that induces Pn, given by Eq. (3). This set is coherent by Walley (1991, Thm. 3.8.1). Consider the set Dn∪Dn, and let us show that it is coherent. Condition D2 holds trivially because it is satisfied by Dn. To see that D3 holds, taking into account that both Dn and Dn are coherent sets of gambles, and in particular cones, it suffices to show that for any gamble f ∈ Dn and any g ∈ Dn, their sum f+g belongs to Dn∪Dn. Consider thus such gambles f, g. If f ∈ G(Xn)>0, then it also belongs to Dn and as a consequence f + g ∈ Dn; on the other hand, if f ∈ Dn \\ G(Xn)>0, it follows that Pn(f) > 0, whence Pn(f + g) = Pn(f) + Pn(g) ≥ Pn(f) + Pn(g) > 0, and therefore f + g ∈ Dn. Since both Dn and Dn are coherent, we deduce from this that condition D1 also holds, and as a consequence the set Dn ∪ Dn is indeed coherent.\nNow, Theorem 5 implies that there is some maximal coherent set of desirable gambles Mn ∈ m(Dn ∪ Dn) ⊆ m(Dn), and from Walley (1991, Thm. 3.8.3) we deduce that Dn and Mn induce the same Pn by means of Eq. (2). But then f − µ ∈ ⊗n∈NMn, and therefore ×n∈NPn(f) ≥ µ, using the argumentation above. Hence SN (f) ≥ µ, and therefore SN (f) ≥ sup {µ ∈ R : f − µ ∈ ⊠n∈NDn}.\nTogether with Theorem 21 and the fact that the strong product of lower previsions may strictly dominate their independent natural extension (see Example 9.3.4 in Walley, 1991), this also shows that the strong product of marginal sets of desirable gambles may strictly include their independent natural extension. An explicit example will be given in Appendix A.3."
    }, {
      "heading" : "9. Conditional Irrelevance and Independence",
      "text" : "The final step we take in this paper, consists in extending our results from irrelevance and independence to a simple but common form of conditional irrelevance and independence. Next to the variables XN in XN , we now also consider another variable Y assuming values in a finite set Y.\nConsider two disjoint subsets I and O of N . We say that XI is epistemically irrelevant to XO when, conditional on Y , learning the value of XI does not influence or change our beliefs about XO.\nWhen does a set D of desirable gambles on XN × Y capture this type of conditional epistemic irrelevance? Clearly, we should require that:\nmargO(D⌋xI , y) = margO(D⌋y) for all xI ∈ XI and all y ∈ Y .\nAs before, for technical reasons we also allow I and O to be empty. It is clear from the definition above that the ‘variable’ X∅, about whose constant value we are certain, is conditionally epistemically irrelevant to any variable XO. Similarly, we see that any variable XI is conditionally epistemically irrelevant to the ‘variable’ X∅. This seems to be in accordance with intuition.\nAlso, if Y is a singleton, then there is no uncertainty about Y and conditioning on Y amounts to not conditioning at all: epistemic irrelevance can be seen as a special case of conditional epistemic irrelevance.\nWe now want to argue that, conversely, there is a very specific and definite way in which conditional epistemic irrelevance statements can be reduced to simple epistemic irrelevance statements. The crucial results that allow us to establish this, are the following conceptually very simple theorem and its corollary.\nTheorem 29 (Sequential updating). Consider any subset R of N , and any coherent set D of desirable gambles on XN × Y. Then\n(D⌋y)⌋xR = (D⌋xR)⌋y = D⌋xR, y for all xR ∈ XR and y ∈ Y. (20)\nProof. Fix any xR in XR and any y ∈ Y. Clearly, all three sets in Eq. (20) are subsets of G(XN\\R). So take any gamble f on XN\\R, and consider the following chains of equivalences:\nI{y}I{xR}f ∈ D ⇔ I{xR}f ∈ D⌋y ⇔ f ∈ (D⌋y)⌋xR I{y}I{xR}f ∈ D ⇔ I{y}f ∈ D⌋xR ⇔ f ∈ (D⌋xR)⌋y I{y}I{xR}f ∈ D ⇔ f ∈ D⌋xR, y.\nCorollary 30 (Reduction). Consider any disjoint subsets I and O of N , and any coherent set D of desirable gambles on XN × Y. Then the following statements are equivalent:\n(i) margO(D⌋xI , y) = margO(D⌋y) for all xI ∈ XI and all y ∈ Y;\n(ii) margO((D⌋y)⌋xI ) = margO(D⌋y) for all xI ∈ XI and y ∈ Y.\nThis tells us that a model D about (XN , Y ) represents epistemic irrelevance of XI to XO, conditional on Y if and only if for each possible value y ∈ Y of Y , the model D⌋y about XN represents epistemic irrelevance of XI to XO.\nNow suppose we have marginal conditional models Dn⌋Y on Xn, n ∈ N . The notation Dn⌋Y is a concise way of representing the family of conditional models Dn⌋y, y ∈ Y. Then if we combine Corollary 30 and Theorem 19, we obtain the following:\nCorollary 31. The smallest conditionally independent product D⌋Y of the marginal models Dn⌋Y is given by ⊗n∈N (Dn⌋Y ), meaning that for each y ∈ Y, D⌋y = ⊗n∈N(Dn⌋y).\nThis also shows that calculating the conditionally independent natural extension has, in comparison with independent natural extension, an additional factor in the computational complexity that its simply linear in the number of possible values for the conditioning variable Y ."
    }, {
      "heading" : "10. Conclusions",
      "text" : "Sets of desirable gambles are more informative than coherent lower previsions, as we have shown in Section 2.6, and they are helpful in avoiding problems involving zero probabilities. Moreover, they have a simple axiomatic definition, as we have seen in Section 2.1. They\nhave been overlooked for much of the development of the theory of imprecise probabilities, and it is only in the last five or six years that more effort is being devoted to bringing this simplifying and unifying notion to the fore.\nWorking with sets of desirable gambles allows us to show that the computational complexity of checking whether a gamble belongs to the independent natural extension compares favourably to that of computing the strong product, which has a complexity that is exponential in the number of variables.\nOur results here also show that we can model assessments of epistemic independence easily using sets of desirable gambles, and that we can derive from them existing results for lower previsions.\nMoreover, the results in Section 7 indicate that constructing global joint models (i.e. coherent sets of desirable gambles) from local ones is something that can be easily and efficiently done for the some types of credal networks (Cozman, 2000, 2005). The interpretation of the graphical structure in credal networks is usually taken to be the following: for any node (variable), conditional on its parents, the non-parent non-descendants are strongly independent of it (Cozman, 2000, 2005). But we can replace the assumption of strong independence with the weaker one of epistemic irrelevance, as in the work by De Cooman et al. (2010), and this tends to produce more conservative independent products.9\nIf we consider a credal network made up of n unconnected nodes X1, . . . ,Xn, their interpretation is then very simple: for any variable Xk, the remaining variables X1, . . . , Xk−1, Xk+1, . . .Xn are epistemically irrelevant to it. The expression (18) for the independent natural extension ⊗nk=1Dk, and the reasoning behind it in Section 7, show that ⊗ n k=1Dk is the smallest (most conservative) coherent joint set of desirable gambles that expresses the epistemic irrelevancies in the graph.\nInterestingly, we can make the network slightly more complicated by looking at the developments in Section 9, which tell us that the conditionally independent natural extension ⊗nk=1Xk⌋Y is the most conservative (conditional) joint model that reflects the independence conditions embedded in the following graphical structure:\nY\nX1 X2\n. . . Xn−1 Xn\nfor any variable Xk, the remaining variables X1, . . . , Xk−1, Xk+1, . . .Xn are epistemically irrelevant to Xk, conditional on Y .\nNow, any tree can be built up recursively using simple networks like the one above as building blocks: similarly to what is done by De Cooman et al. (2010, Section 4), we can use recursion from the leaves to the root, so that at any step we have a conditional model that we put together into a joint one using the epistemic irrelevance/independence assessments and the marginal extension theorem (Miranda & De Cooman, 2007), that allows us to combine hierarchical information. This suggests that the developments in this paper\n9. See also Section 8 for more details about strong independence; we surmise that the computational complexity of dealing with strong products is worse than that for computing the independent natural extension.\ncan be used to good advantage in finding efficient algorithms for inference in credal trees under epistemic irrelevance, using sets of desirable gambles as uncertainty models. This approach could build on the ideas proposed by De Cooman et al. (2010) and Destercke and De Cooman (2008) in the context of credal trees with lower previsions as local uncertainty models, but make them more general and also more directly amenable to simple assessment and elicitation for the local models. This would have interesting applications in dealing with hidden Markov models with imprecise transition and emission models, which are, of course, special credal trees.\nWe expect that generalising those algorithms towards more general credal networks (polytrees, . . . ) will be more difficult, and will have to rely heavily on the pioneering work of Moral (2005) on graphoid properties for epistemic irrelevance. In this sense, it would be interesting to model other assumptions of independence between variables using sets of desirable gambles, for instance intermediate assumptions between epistemic irrelevance and independence (that is, epistemic irrelevance for some pairs of sets of variables only). Moreover, algorithms for computing the irrelevant and the independent natural extension, as well as the strong product, need to be devised.\nOther open problems would be to generalise our work to infinite sequences of random variables, which would allow us to deal with unbounded trees, and, as we have already discussed in the paper, to establish the associativity of the strong product and to extend our results to variables taking values on infinite spaces."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was supported by SBO project 060043 of the IWT-Vlaanderen, and by project MTM2010-17844. We would like to thank the reviewers for their helpful comments."
    }, {
      "heading" : "Appendix A. Examples",
      "text" : "In this appendix, we have gathered a number of examples and counterexamples.\nA.1 Independent Natural Extension Need Not Preserve Maximality\nLet X = {0, 1} and let M be the subset of G(X) given by\nM := {f ∈ G(X) : f(0) + f(1) > 0 or f(0) = −f(1) > 0} .\n0\n1\nM Then it is easy to see that M is a coherent set of desirable gambles. It is moreover maximal: if some non-zero f /∈ M, then either f(0) + f(1) < 0, whence −f(0) − f(1) > 0 and then −f > 0, or f(0) = −f(1) < 0 and then −f(0) = f(1) > 0, which means that −f ∈ M.\nLet N = {1, 2}, X1 = X2 = X and M1 = M2 = M. The independent natural extension of M1 and M2 is given by\nM1 ⊗M2 := posi ( G(X{1,2})>0 ∪A irr {1}→{2} ∪A irr {2}→{1} )\n= {\nh1 + h2 : h1 ∈ A irr {1}→{2} ∪ {0}, h2 ∈ A irr {2}→{1} ∪ {0}\n}\n\\ {0},\ntaking into account that all non-negative gambles belong to both Airr{1}→{2} and A irr {2}→{1} and thatAirr{1}→{2}∪{0} andA irr {2}→{1}∪{0} are convex cones. Recall that h1 ∈ A irr {1}→{2}∪{0} iff h1(0, ·) ∈ M ∪ {0} and h1(1, ·) ∈ M ∪ {0}, and similarly that h2 ∈ A irr {2}→{1} ∪ {0} iff h2(·, 0) ∈ M ∪ {0} and h2(·, 1) ∈ M ∪ {0}. This means that any gamble h in M1 ⊗M2 can be expressed as\nh(0, 0) = α+ ǫ, h(0, 1) = β + µ, h(1, 0) = γ + λ, h(1, 1) = δ + η,\nwhere α, . . . , η are real numbers satisfying the following constraints:\nα+ β > 0 or α = −β ≥ 0\nγ + δ > 0 or γ = −δ ≥ 0\nǫ+ λ > 0 or ǫ = −λ ≥ 0\nµ+ η > 0 or µ = −η ≥ 0\nmax{α, γ, ǫ, µ} > 0.\nThen the gamble h given by h(0, 0) = h(1, 1) = −1 and h(0, 1) = h(1, 0) = 1 does not belong to M1 ⊗ M2: since h(0, 0) + h(0, 1) + h(1, 0) + h(1, 1) = 0, we should have α = −β ≥ 0, γ = −δ ≥ 0, ǫ = −λ ≥ 0 and µ = −η ≥ 0, and this implies that h(0, 0) ≥ 0, a contradiction. But −h does not belong to M1⊗M2 either, because h(0, 0)+h(0, 1)+h(1, 0)+h(1, 1) = 0 similarly implies that −h(1, 1) ≤ 0. Hence, the independent natural extension of M1 and M2 is not maximal.\nA.2 A Maximal Independent Product of Maximal Sets\nNext, we construct an example of an independent product of maximal sets that is again maximal.\nConsider the spaces X1 and X2, and the maximal marginal coherent sets of desirable gambles M1 and M2 as in Section A.1. Now consider the set of desirable gambles M ′ defined by\nM′ := {h ∈ G(XN ) : h(0, 0) + h(0, 1) + h(1, 0) + h(1, 1) > 0}\n∪ {h ∈ G(XN ) : h(0, 0) + h(0, 1) + h(1, 0) + h(1, 1) = 0 and\n[h(0, 0) > 0 or h(0, 0) = 0, h(0, 1) > 0 or h(0, 0) = h(0, 1) = 0, h(1, 0) > 0]}.\nWe first show that M1⊗M2 ⊆ M ′. According to the discussion in Section A.1, any gamble h in M1⊗M2 satisfies h(0, 0) = α+ ǫ, h(0, 1) = β+µ, h(1, 0) = γ+λ, and h(1, 1) = δ+ η, where in particular\nmin{α+ β, γ + δ, ǫ+ λ, µ + η} ≥ 0,\nwhence\nh(0, 0) + h(0, 1) + h(1, 0) + h(1, 1) = (α+ ǫ) + (β + µ) + (γ + λ) + (µ + η)\n= (α+ β) + (γ + δ) + (ǫ+ λ) + (µ + η) ≥ 0.\nIf h(0, 0)+h(0, 1)+h(1, 0)+h(1, 1) = 0, this implies that α+β = γ+δ = ǫ+λ = µ+η = 0, and therefore, again looking at the characterisation of M1 ⊗ M2 in Section A.1, that\nα = −β ≥ 0, γ = −δ ≥ 0, ǫ = −λ ≥ 0 and µ = −η ≥ 0 This implies in particular that h(0, 0) = α + ǫ ≥ 0. So we see that either h(0, 0) > 0, and in that case h ∈ M′, or h(0, 0) = 0. But this implies that α = ǫ = β = λ = 0. And then h(0, 1) = µ ≥ 0, so again we have either h(0, 1) > 0, in which case h ∈ M′, or h(0, 1) = µ = δ = 0. But now it follows from the conditions imposed on the α, . . . , η in Section A.1 that h(1, 0) = γ > 0, which again means that h belongs to M′. So, indeed, M1 ⊗M2 ⊆ M\n′. We now show that M′ is a maximal coherent set of desirable gambles. It is easy to see that M′ is coherent. To show that it is maximal, consider any non-zero gamble h in G(X{1,2}); then there are three possibilities. If h(0, 0) + h(1, 0) + h(0, 1) + h(1, 1) > 0, then h ∈ M′ and −h /∈ M′. If h(0, 0)+h(1, 0)+h(0, 1)+h(1, 1) < 0, then −h ∈ M′ and h /∈ M′. And if h(0, 0) + h(1, 0) + h(0, 1) + h(1, 1) = 0, then exactly one of h,−h belongs to M′.\nTo conclude, note that M′ is an independent product of M1 and M2 because of Proposition 24.\nA.3 The Strong Product May Strictly Include The Independent Natural Extension\nThe following is an adaptation of an example by Walley (1991, Example 9.3.4). Consider X = {0, 1} and let P be the coherent lower prevision determined by P ({0}) = 2/5 and P (1) = 1/2, so we have for all f ∈ G(X) that:\nP (f) = min\n{\n1 2 f(0) + 1 2 f(1), 2 5 f(0) + 3 5 f(1)\n}\n.\nWith P we can associate the coherent set of (strictly) desirable gambles by Eq. (3):\nD := {f : f > 0 or P (f) > 0} .\nNow let N = {1, 2}, X1 = X2 = X and D1 = D2 = D. Consider the gamble h on X{1,2} determined by\nh(0, 0) = h(1, 1) = 51\n100 , h(0, 1) = h(1, 0) = −\n49\n100 .\nTo see that D1⊗D2 is strictly included in D1⊠D2, we will show that h belongs to D1⊠D2 but not to D1 ⊗D2.\nFor the latter claim, consider any gambles h1 ∈ A irr {1}→{2} and h2 ∈ A irr {2}→{1}, and assume ex absurdo that h ≥ h1+h2. Then we see that (h1+h2)(0, 0) = α+ǫ, (h1+h2)(0, 1) = β+µ, (h1 + h2)(1, 0) = γ + λ and (h1 + h2)(1, 1) = δ + η, where the real numbers α, . . . , η must satisfy the following constraints:\nmax{α, β} > 0 and min\n{\n1 2 α+ 1 2 β, 2 5 α+ 3 5 β\n}\n≥ 0\nmax{γ, δ} > 0 and min\n{\n1 2 γ + 1 2 δ, 2 5 γ + 3 5 δ\n}\n≥ 0\nmax{ǫ, λ} > 0 and min\n{\n1 2 ǫ+ 1 2 λ, 2 5 ǫ+ 3 5 λ\n}\n≥ 0\nmax{µ, η} > 0 and min\n{\n1 2 µ+ 1 2 η, 2 5 µ+ 3 5 η\n}\n≥ 0.\nAs a consequence,\n2 5 (α+ ǫ) + 3 5 (β + γ + δ + µ+ λ+ η)\n= ( 2\n5 α+\n3 5 β) + ( 2 5 ǫ+ 3 5 λ) + 6 5 ( 1 2 γ + 1 2 δ) + 6 5 ( 1 2 µ+ 1 2 η) ≥ 0,\nbut on the other hand\n2 5 (α+ ǫ) + 3 5 (β + γ + δ + µ+ λ+ η)\n≤ 2\n5 h(0, 0) +\n3 5 (h(0, 1) + h(1, 0) + h(1, 1)) = − 39 500 ,\na contradiction. This implies that h does not belong to D1 ⊗D2. For the former claim, consider arbitrary maximal coherent set of desirable gambles M1 ∈ m(D1) and M2 ∈ m(D2). Then it follows from the discussion in Section 2.6 that M1 induces a linear prevision P1 ≥ P 1, and that M2 induces a linear prevision P2 ≥ P 2. But then it follows from the discussion in Example 9.3.4 by Walley (1991) that\n(P1 × P2)(h) ≥ 1\n100 > 0,\nwhich tells us that h belongs to the set of strictly desirable gambles that induces P1 × P2, because of Eq. (3). Since that is the smallest coherent set of desirable gambles that induces P1 × P2, and since M1 ⊗ M2 is another such set, by Theorem 28, we deduce that h ∈ M1 ⊗M2. It follows that indeed h ∈ D1 ⊠D2."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2012,
    "abstractText" : "The results in this paper add useful tools to the theory of sets of desirable gambles, a growing toolbox for reasoning with partial probability assessments. We investigate how to combine a number of marginal coherent sets of desirable gambles into a joint set using the properties of epistemic irrelevance and independence. We provide formulas for the smallest such joint, called their independent natural extension, and study its main properties. The independent natural extension of maximal coherent sets of desirable gambles allows us to define the strong product of sets of desirable gambles. Finally, we explore an easy way to generalise these results to also apply for the conditional versions of epistemic irrelevance and independence. Having such a set of tools that are easily implemented in computer programs is clearly beneficial to fields, like AI, with a clear interest in coherent reasoning under uncertainty using general and robust uncertainty models that require no full specification.",
    "creator" : "dvips(k) 5.98 Copyright 2009 Radical Eye Software"
  }
}