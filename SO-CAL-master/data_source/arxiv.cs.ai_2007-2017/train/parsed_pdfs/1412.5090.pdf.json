{
  "name" : "1412.5090.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Jan van Eijck", "Bryan Renne" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n41 2.\n50 90\nv2 [\ncs .L\nO ]\n1 7\nD ec\n2 01"
    }, {
      "heading" : "1 Introduction",
      "text" : "De Finetti [dF51, dF37] proposed the following axiomatization of qualitative probabilistic comparison (presented here based on [Sco64]): for sets X , Y , and Z coming from the powerset ℘(W ) of a nonempty finite set W , we have\n1. W ∅,\n2. ∅ X ,\n3. X Y or Y X ,\n∗Funded by an Innovational Research Incentives Scheme Veni grant from the Netherlands Organisation for Scientific Research (NWO).\n4. X Y Z implies X Z, and\n5. X Y if and only if X ∪ Z Y ∪ Z for Z disjoint from X and Y .\nDe Finetti conjectured that any binary relation on ℘(W ) that satisfies these conditions is realizable by a probability measure P on ℘(W ), which means that we have X Y if and only if P (X) ≤ P (Y ). While every probability measure realizing a binary relation on ℘(W ) satisfies de Finetti’s conditions, these conditions do not in general guarantee the existence of a realizing probability measure: it was shown by Kraft, Pratt, and Seidenberg [KPS59] (presented here as in [Seg71]) that for W = {a, b, c, d, e}, the relations\n{c} ≺ {a, b}, {b, d} ≺ {a, c},\n{a, e} ≺ {b, c}, {a, b, c} ≺ {d, e}\nmay be extended to a binary relation over ℘(W ) that satisfies de Finetti’s conditions and yet has no realizing probability measure. Kraft, Pratt, and Seidenberg (“KPS”) also determined what was missing from de Finetti’s axiomatization; Scott [Sco64] later presented the KPS conditions in a linear algebraic form.\nTheorem 1.1 ([Sco64, Theorem 4.1] reformulated with ℘(W ) instead of a general Boolean algebra). Let W be a nonempty finite set. Given X ∈ ℘(W ), let ι : W → {0, 1} be the characteristic function of X (i.e., ι(X)(w) = 1 if w ∈ X , and ι(X)(w) = 0 if w /∈ X). Construe functions x : W → R as vectors: x(w) indicates the real-number value of vector x at coordinate w. Addition and negation of these vectors is taken component-wise: (x + y)(w) := x(w) + y(w) and (−x)(w) := −(x(w)). A binary relation on ℘(W ) is realizable by a probability measure if and only if it satisfies each of the following: for each m ∈ Z+ and X, Y,X1, . . . , Xm, Y1, . . . , Ym ∈ ℘(W ), we have\n1. ∅ ≺ W ;\n2. ∅ X;\n3. X Y or Y X; and\n4. if Xi Yi for each i ≤ m and ∑m i=1 ι(Xi) = ∑m j=1 ι(Yj), then Yj Xj for each j ≤ m.\nScott’s fourth condition is the most difficult. The algebraic component ∑m\ni=1 ι(Xi) = ∑m j=1 ι(Yj) (1)\nof this condition says: for each coordinate w ∈ W , the number of Xi’s that contain w is equal to the number of Yj’s that contain w. Intuitively, Scott’s forth condition tells us that if two length-m sequences of coordinate sets are related component-wise by the relation “is no more probable than” and the occurrence multiplicity of any given world is the same in each of the sequences, then the sets are also related component-wise by the relation “has the same probability.”\nUsing Scott’s theorem to prove completeness, Segerberg [Seg71] studied a modal logic of qualitative probability. Segerberg’s logic has a binary operator expressing qualitative probabilistic\ncomparison and a unary operator ✷ expressing necessity. Gärdenfors [Gär75] considered a simplified version of Segerberg’s logic that, among other differences, eliminated the necessity operator in lieu of the abbreviation ✷ϕ := (1 ϕ), which has the semantic meaning that ϕ has probability 1 (and implies that ϕ is true at all outcomes with nonzero probability). Both Gärdenfors and Segerberg express the algebraic component (1) of Scott’s fourth condition using Segerberg’s notation\n(ϕ1, . . . , ϕmEψ1, . . . , ψm) ,\nwhich we sometimes shorten to (ϕiEψi)mi=1. This expression abbreviates the formula\n✷(F0 ∨ · · · ∨ Fm) ,\nwhere each Fi is the disjunction of all conjunctions\nd1ϕ1 ∧ · · · ∧ dmϕm ∧ e1ψ1 ∧ · · · ∧ emψm∧\nsatisfying the property that exactly i of the dk’s are the empty string, exactly i of the ek’s are the empty string, and the rest of the dk’s and ek’s are the negation sign ¬. Intuitively, Fi says that i of the ϕk’s are true and i of the ψk’s are true; F0 ∨ · · · ∨ Fm says that the number of true ϕk’s is the same as the number of true ψk’s; and (ϕiEψi)mi=1 := ✷(F0 ∨ · · · ∨ Fm) says that at every outcome with nonzero probability, the number of true ϕk’s is the same as the number of true ψk’s. Using this notation, it is possible to express the fourth condition of Scott’s theorem and thereby obtain completeness for the probabilistic interpretation.\nIn the present paper, we follow this tradition of studying probability from a qualitative (i.e., non-numerical) point of view using modal logic. However, our focus shall not be on the binary relation of qualitative probabilistic comparison but instead on the unary notions of certainty (i.e., having probability 1) and “high” probability (i.e., having a probability greater than some fixed rational-number threshold c ≥ 1\n2 ). That is, our interest is in unary modal logics of high\nprobability. For convenience in this study, we shall identify epistemic notions with probabilistic assignment, which suggests a connection with subjective probability [Jef04]. In particular, we identify knowledge with probabilistic certainty (i.e., probability 1) and belief with probability greater than some fixed rational-number threshold c ≥ 1\n2 . Therefore, instead of the unary operator ✷, we shall\nuse the unary operator K and assign this operator an epistemic reading: Kϕ says that the agent knows ϕ, which means she assigns ϕ subjective probability 1. We shall use the unary modal operator B to express belief: Bϕ says that the agent believes ϕ, which means she assigns ϕ a subjective probability exceeding the threshold c (which will always be a fixed value within a given context or theory). Though our readings of these formulas are epistemic and doxastic, we stress that our technical results are independent of this reading, so someone who disagrees with subjective probability or our epistemic/doxastic readings is encouraged to think of our work purely in terms of high probability: Kϕ says P (ϕ) = 1, and Bϕ says P (ϕ) > c for some fixed c ∈ [1\n2 , 1)∩Q. That is, the\ntechnical results of our work are in no way dependent on our use of epistemic/doxastic notions or on the philosophy of subjective probability.\nLenzen [Len03, Len80] is to our knowledge the first to consider a modal logic of high probability for the threshold c = 1\n2 . Actually, his perspective is slightly different than the one we adopt here.\nFirst, his reading of formulas is different (though not in any deep way): he identifies “the agent is convinced of ϕ” with P (ϕ) = 1 and “ψ is believed” by P (ψ) > 1\n2 . More substantially, Lenzen’s\nconviction (German: Überzeuging) does not imply truth. Technically, this amounts to permitting the possibility that there are outcomes having probability zero. For reasons of personal preference, we forbid this in our study here, though this difference is non-essential, as it is completely trivial from the technical perspective to change our setting to allow zero-probability outcomes or to change Lenzen’s setting to forbid them. Therefore, we credit Lenzen’s work [Len80] as the first to provide a proof of probabilistic completeness for c = 1\n2 . As with Segerberg’s and Gärdenfors’\nprobabilistic completeness results, Lenzen’s proof made crucial use of Scott’s work. In more recent work, Herzig [Her03] considered a logic of belief and action in which belief in ϕ is identified with P (ϕ) > P (¬ϕ). This is equivalent to Lenzen’s notion, though Herzig does not study completeness. Another recent work by Kyberg and Teng [KT12] investigated a notion of “acceptance” in which ϕ is accepted whenever the probability of ¬ϕ is at most some small ǫ. This gives rise to the minimal modal logic EMN, which is different than Lenzen’s logic.\nWe herein consider belief à la Lenzen not only for the case c = 1 2 but also for the case c > 1 2 . As it turns out, the logics for these cases are different, though our focus will be on the logic for c = 1\n2 because this is the only threshold for which a probability completeness result is known. In\nparticular, probability completeness for c > 1 2 is still open. Thresholds c < 1 2 permit simultaneous belief of ϕ and ¬ϕ while avoiding belief of any self-contradictory sentence such as the propositional constant ⊥ for falsehood. This might suggest some connection with paraconsistent logic. However, we leave these logics of low probability for future work, though we shall say a few words more about them later in this paper.\nIn Section 2, we identify a Kripke-style semantics for probability logic similar to [EoS14, Hal03] (and no doubt to many others). We require that all worlds are probabilistically possible but not necessarily epistemically so, and we provide some examples of how this semantics works. In particular, we demonstrate that our requirement is not problematic: world v can be made to have probability zero relative to world w if we cut the epistemic accessibility relation between these worlds.\nIn Section 3, we define our modal notions of certain knowledge and of belief exceeding threshold c, explain the motto “belief is willingness to bet,” and prove a number of properties of certain knowledge and this “betting” belief. For instance, we show that knowledge is S5 and belief is not normal. We show a number of other threshold-specific properties of betting belief as well. In particular, we see that the belief modality extends the minimal modal logic EMND45 + ¬B⊥ by way of certain schemes relating knowledge and belief.\nWe then introduce a formal modal language in Section 4, relate this language to the probabilistic notions of belief and knowledge, and introduce an epistemic neighborhood semantics for the language. We study the relationship between the neighborhood and probabilistic semantics. In particular, we introduce a notion of “agreement” between epistemic probability models and epistemic neighborhood models, the key component of which is this: an event X is a neighborhood of a world w if and only if the probability measure Pw at w satisfies Pw(X) > c. We use one of Scott’s theorems to prove that epistemic neighborhood models satisfying certain properties give rise to agreeing epistemic probability models for the threshold c = 1\n2 . This result we credit\nto Lenzen; however, we prove this result anew in a modern, streamlined form that we hope will make it more accessible. The main remaining open problem is to prove the analogous result for thresholds c 6= 1\n2 (i.e., find the additional sufficient conditions on epistemic neighborhood models\nwe need to impose so as to guarantee the existence of an agreeing epistemic probability model for threshold c 6= 1\n2 ). Finally, we prove that epistemic probability models always give rise to agreeing\nepistemic neighborhood models. In Section 5, we introduce a basic modal theory KB that is probabilistically sound. We adapt an example due to Walley and Fine [WF79] that shows KB is probabilistically incomplete. This leads us to add additional principles to KB, thereby producing the modal theory KB.5, our name for our modern reformulation of Lenzen’s modal theory of knowledge and belief (or, in Lenzen’s terminology, his theory of “acceptance” and belief). Using the results from Section 4, we prove that this logic is sound and complete for epistemic probability models using threshold c = 1\n2 .\nRegarding the semantics based on our epistemic neighborhood models, we prove that KB is sound and complete for the full class of these models and that KB.5 is sound and complete for the smaller class that satisfies the additional Lenzen-derivative properties needed to guarantee the existence of an agreeing probability measure for threshold c = 1\n2 .\nStated in an analogy: KB is to de Finetti’s axiomatization as KB.5 is to the KPS/Scott axiomatization. However, do not be misled: de Finetti, KPS, and Scott considered qualitative probabilistic comparison, which is a binary notion based on a binary operator . See also [HI13] for a revival of this tradition. We, on the other hand, consider high probability, which is a unary notion based on unary operators we denote as K and B.\nAnother version of our main open question can be restated in the following syntactic form: given a threshold c 6= 1\n2 , find the additional principles that must be added to our probabilistically\nsound but incomplete base logic KB in order to obtain a probabilistically sound and complete logic for threshold c. In our conclusion, we present some additional sound principles that might come up in this work, but we have not been able to find the probabilistically sound and complete axiomatization for thresholds c 6= 1\n2 .\nGiven the link between epistemic neighborhood models and epistemic probability models, our results may be viewed as a contribution to the study connecting two schools of rational decision making: the probabilist (e.g., [Kör08]) and the AI-based (e.g., [KT12]). We also hope that it will be of some use in future work on qualitative probability."
    }, {
      "heading" : "2 Epistemic Probability Models",
      "text" : "Definition 2.1. We fix a set P of propositional letters. An epistemic probability model is a structure M = (W,R, V, P ) satisfying the following.\n• (W,R, V ) is a finite single-agent S5 Kripke model:\n– W is a finite nonempty set of “worlds” or “outcomes.” An event is a set X ⊆ W of worlds. When convenient, we identify a world w with the singleton event {w}.\n– R ⊆ W ×W is an equivalence relation R on W . We let\n[w] := {v ∈ W | wRv}\ndenote the equivalence class of world w. This is the set of worlds that agent cannot distinguish from w.\n– V : W → ℘(P) assigns a set V (w) of propositional letters to each world w ∈ W .\n• P : ℘(W ) → [0, 1] is a probability measure over the finite algebra ℘(W ) satisfying the property of full support: P (w) 6= 0 for each w ∈ W .\nA pointed epistemic probability model is a pair (M, w) consisting of an epistemic probability model M = (W,R, V, P ) and world w ∈ W called the point.\nThe agent’s uncertainty as to which world is the actual world is given by the equivalence relation R. If w is the actual world, then the probability the agent assigns to an event X at w is given by\nPw(X) := P (X ∩ [w])\nP ([w]) . (2)\nIn words: the probability the agent assigns to event X at world w is the probability she assigns to X conditional on her knowledge at w. Slogan: subjective probability is always conditioned, and the most general condition is given by the knowledge of the agent. This makes sense because the right side of (2) is just P (X|[w]), the probability of X conditional on [w]. Note that Pw(X) is always well-defined: we have w ∈ [w] by the reflexivity of R and hence 0 < P (w) ≤ P ([w]) by full support, so the denominator on the right side of (2) is nonzero.\nExample 2.2 (Horse racing). Three horses compete in a race. For each i ∈ {1, 2, 3}, horse hi wins the race in world wi. The agent can distinguish between these three possibilities, and she assigns the horses winning chances of 3:2:1. We represent this situation in the form of an epistemic probability model M2.2 pictured as follows:\nh1\nw1\nh2\nw2\nh3\nw3\nP = {w1 : 3 6 , w2 : 2 6 , w3 : 1 6 }\nM2.2\nWhen we picture epistemic probability models, the arrows of the agent are to be closed under reflexivity and transitivity. With this convention in place, it is not difficult to verify that Pw1({w1, w3}) = 2 3 ; that is, at w1, the assigns probability 23 to the event that the winner is horse 1 or horse 3.\nThe property of full support says that each world is probabilistically possible. Therefore, in order to represent a situation in which the agent is certain that horse 3 can never win, we simply make the h3-worlds inaccessible via R.\nExample 2.3 (Certainty of impossibility). We modify Example 2.2 by eliminating the arrow between worlds w2 and w3.\nh1\nw1\nh2\nw2\nh3\nw3\nP = {w1 : 3 6 , w2 : 2 6 , w3 : 1 6 }\nM2.3\nAt world w1 in this picture, there is no accessible world at which horse 3 wins. Therefore, at world w1, the agent assigns probability 0 to the event that horse 3 wins: Pw1(w3) = 0.\nWe define a language L for reasoning about epistemic probability models.\nDefinition 2.4. The language L of (single-agent) probability logic is defined by the following grammar.\nϕ ::= ⊤ | p | ¬ϕ | ϕ ∧ ϕ | t ≥ 0\nt ::= q | q · P (ϕ) | t+ t\np ∈ P, q ∈ Q\nWe adopt the usual abbreviations for Boolean connectives. We define the relational symbols ≤, >, <, and = in terms of ≥ as usual. For example, t = s abbreviates (t ≥ s) ∧ (s ≥ t). We also use the obvious abbreviations for writing linear inequalities. For example, P (p) ≤ 1 − q abbreviates 1 + (−q) + (−1) · P (p) ≥ 0.\nDefinition 2.5. Let M = (W,R, V, P ) be an epistemic probability model. We define a binary truth relation |=p between a pointed epistemic probability model (M, w) and L-formulas as follows.\nM, w |=p ⊤\nM, w |=p p iff p ∈ V (w)\nM, w |=p ¬ϕ iff M, w 6|=p ϕ\nM, w |=p ϕ ∧ ψ iff M, w |=p ϕ and M, w |=p ψ\nM, w |=p t ≥ 0 iff JtKw ≥ 0\nJϕKp := {u ∈ W | M, u |=p ϕ}\nPw(X) := P (X ∩ [w])\nP ([w])\nJqKw := q\nJq · P (ϕ)Kw := q · Pw(JϕKp)\nJt + t′Kw := JtKw + Jt ′Kw\nValidity of ϕ ∈ L in epistemic probability model M, written M |=p ϕ, means that M, w |=p ϕ for each world w ∈ W . Validity of ϕ ∈ L, written |=p ϕ, means that M |=p ϕ for each epistemic probability model M."
    }, {
      "heading" : "3 Certainty and Belief",
      "text" : "[Eij13] formulates and proves a “certainty theorem” relating certainty in epistemic probability models to knowledge in a version of these models in which the probabilistic information is removed. This motivates the following definition.\nDefinition 3.1 (Knowledge as Certainty). We adopt the following abbreviations.\n• Kϕ abbreviates P (ϕ) = 1.\nWe read Kϕ as “the agent knows ϕ.”\n• Ǩϕ abbreviates ¬K¬ϕ.\nWe read Ǩϕ as “ϕ is consistent with the agent’s knowledge.”\nTheorem 3.2 ([Eij13]). K is an S5 modal operator:\n1. |=p ϕ for each L-instance ϕ of a scheme of classical propositional logic.\nAxioms of classical propositional logic are valid.\n2. |=p K(ϕ → ψ) → (Kϕ → Kψ)\nKnowledge is closed under logical consequence.\n3. |=p Kϕ → ϕ\nKnowledge is veridical.\n4. |=p Kϕ → KKϕ\nKnowledge is positive introspective: it is known what is known.\n5. |=p ¬Kϕ → K¬Kϕ\nKnowledge is negative introspective: it is known what is not known.\n6. |=p ϕ implies |=p Kϕ\nAll validities are known.\n7. |=p ϕ → ψ and |=p ϕ together imply |=p ψ.\nValidities are closed under the rule of Modus Ponens.\nWe define belief in a proposition ϕ as willingness to take bets on ϕ with the odds being better than some rational number c ∈ (0, 1) ∩ Q. This leads to a number of degrees of belief, one for each threshold c.\nDefinition 3.3 (Belief as Willingness to Bet). Fix a threshold c ∈ (0, 1) ∩Q.\n• Bcϕ abbreviates P (ϕ) > c.\nWe read Bcϕ as “the agent believes ϕ with threshold c.”\n• B̌cϕ abbreviates ¬Bc¬ϕ.\nWe read B̌ϕ as “ϕ is consistent with the agent’s threshold-c beliefs.”\nIf the threshold c is omitted (either in the notations Bcϕ and B̌cϕ or in the informal readings of these notations), it is assumed that c = 1\n2 .\nThis notion of belief comes from subjective probability [Jef04]. In particular, fix a threshold c = p/q ∈ (0, 1) ∩ Q. Suppose that the agent believes ϕ with threshold c = p/q; that is, P (ϕ) > p/q. If the agent wagers p dollars for a chance to win q dollars on a bet that ϕ is true, then she expects her net winnings to be\n[(q − p) · P (ϕ)]− [p · (1− P (ϕ))] = q · P (ϕ)− p\ndollars on this bet. This is a positive number of dollars if and only if q · P (ϕ) > p. But notice that the latter is guaranteed by the assumption P (ϕ) > p/q. Therefore, it is rational for the agent to take this bet. Said in the parlance of the subjective probability literature: “If the agent stakes p to win q in a bet on ϕ, then her winning expectation is positive in case she believes ϕ with threshold c = p/q.” Or in a short motto: “Belief is willingness to bet.”\nRemark 3.4. Belief based on threshold c = 0 or c = 1 is trivial to express in terms of negation, K, and falsehood ⊥. So we do not consider these thresholds here. Beliefs based on low-thresholds c ∈ (0, 1\n2 ) ∩ Q have unintuitive and unusual features. First, low-threshold beliefs unintuitively permit inconsistency of the kind that an agent can believe both ϕ and ¬ϕ while avoiding inconsistency of the kind that the agent can believe a self-contradictory formula such as ⊥. (This suggests some connection with paraconsistent logic.) Second, the dual of a low-threshold belief implies the belief at that threshold (i.e., B̌cϕ → Bcϕ), which is unusual if we assign the usual “consistency” reading to dual operators (i.e., “ϕ is consistent with the agent’s beliefs implies ϕ is believed” is unusual). Since low-threshold c ∈ (0, 1\n2 ) ∩ Q beliefs have these unintuitive and unusual features, we leave\ntheir study for future work, focusing instead on thresholds c ∈ [1 2 , 1) ∩Q.\nThe following lemma provides a useful characterization of the dual B̌cϕ.\nLemma 3.5. Let M = (W,R, V, P ) be an epistemic probability model.\n1. M, w |=p B̌cϕ iff M, w |=p P (ϕ) ≥ 1− c.\n2. M, w |=p B̌ 1 2ϕ iff M, w |=p P (ϕ) ≥ 12 .\nProof. For Item 1, we have the following:\nM, w |=p B̌cϕ\niff M, w |=p ¬Bc¬ϕ by definition of B̌cϕ\niff Pw(J¬ϕKp) 6> c by definition of Bcϕ and |=p\niff Pw(J¬ϕKp) ≤ c since Q is totally ordered\niff Pw(JϕKp) ≥ 1− c since J¬ϕKp = W − JϕKp\nFor Item 2, apply Item 1 with c = 1 2 .\nWe now consider a simple example.\nExample 3.6 (Non-normality). In this variation, all horses have equal chances of winning and the agent knows this.\nh1\nw1\nh2\nw2\nh3\nw3\nP = {w1 : 1 3 , w2 : 1 3 , w3 : 1 3 }\nM3.6\nRecalling that an omitted threshold c is implicitly assumed to be 1 2 , the following are readily verified.\n1. M3.6 |=p B(h1 ∨ h2 ∨ h3).\nThe agent believes the winning horse is among the three.\n(The agent is willing to bet that the winning horse is among the three.)\n2. M3.6 |=p B(h1 ∨ h2) ∧ B(h1 ∨ h3) ∧B(h2 ∨ h3).\nThe agent believes the winning horse is among any two.\n(The agent is willing to bet that the winning horse is among any two.)\n3. M3.6 |=p Ba¬h1 ∧ Ba¬h2 ∧Ba¬h3.\nThe agent believes the winning horse is not any particular one.\n(The agent is willing to bet that the winning horse is not any particular one.)\n4. M3.6 |=p ¬B(¬h1 ∧ ¬h2).\nThe agent does not believe that both horses 1 and 2 do not win.\n(The agent is not willing to bet that both horses 1 and 2 do not win.)\nIt follows from Items 3 and 4 of Example 3.6 that the present notion of belief is not closed under conjunction. This is discussed as part of the literature on the “Lottery Paradox” [Kyb61].1 However, there is no reason in general that it is paradoxical to assign a conjunction ϕ ∧ ψ a lower probability than either of its conjunctions. Indeed, if ϕ and ψ are independent, then the probability of their conjunction equals the product of their probabilities, so unless one of ϕ or ψ is certain or impossible, the probability of ϕ ∧ ψ will be less than the probability of ϕ and less than the probability of ψ.\nWe set aside philosophical arguments for or against closure of belief under conjunction and instead turn our attention to the study of the properties of the present notion of belief. One of these is a complicated but useful property due to Scott [Sco64] that makes use of notation due to Segerberg [Seg71].\nDefinition 3.7 (Segerberg notation; [Seg71]). Fix a positive integerm ∈ Z+ and formulasϕ1, . . . , ϕm and ψ1, . . . , ψm. The expression\n(ϕ1, . . . , ϕmIψ1, . . . , ψm) (3)\nabbreviates the formula K(F0 ∨ F1 ∨ F2 ∨ · · · ∨ Fm) ,\nwhere Fi is the disjunction of all conjunctions\nd1ϕ1 ∧ · · · ∧ dmϕm ∧ e1ψ1 ∧ · · · ∧ emψm\nsatisfying the property that exactly i of the dk’s are the empty string, at least i of the ek’s are the empty string, and the rest of the dk’s and ek’s are the negation sign ¬. We may write (ϕiIψi)mi=1 as an abbreviation for (3). Finally, let\n(ϕiEψi) m i=1 abbreviate (ϕiIψi) m i=1 ∧ (ψiIϕi) m i=1 .\nWe also allow the use of E in a notation similar to (3).\nThe formula (ϕiIψi)mi=1 says that the agent knows that the number of true ϕi’s is less than or equal to the number of true ψi’s. Put another way, (ϕiIψi)mi=1 is true if and only if every one of the agent’s epistemically accessible worlds satisfies at least as many ψi’s as ϕi’s. The formula (ϕiEψi)mi=1 says that every one of the agent’s epistemically accessible worlds satisfies exactly as many ψi’s as ϕi’s.\nDefinition 3.8 (Scott scheme; [Sco64]). We define the following scheme:\n[(ϕiIψi)mi=1 ∧ B cϕ1 ∧ ∧m i=2 B̌ cϕi] → ∨m i=1B cψi (Scott)\nIf m = 1, then ∧m\ni=2 B̌ cϕi is ⊤. Note that (Scott) is meant to encompass the indicated scheme for\neach positive integer m ∈ Z+.\n1The usual formulation of the Lottery Paradox: it is paradoxical for an agent to believe that one of n lottery tickets will be a winner (i.e., “some ticket is a winner”) without believing of any particular ticket that it is the winner (i.e., “for each i ∈ {1, . . . , n}, ticket i is not a winner”).\n(Scott) says that if the agent knows the number of true ϕi’s is less than or equal to the number of true ψi’s, she believes ϕ1 with threshold c, and the remaining ϕi’s are each consistent with her threshold-c beliefs, then she believes one of the ψi’s with threshold c. Adapting a proof of Segerberg [Seg71], we show that belief with threshold c = 1\n2 satisfies (Scott).\nWe report this result along with a number of other properties in the following proposition.\nTheorem 3.9 (Properties of Belief). For c ∈ (0, 1) ∩Q, we have:\n1. 6|=p Bc(ϕ → ψ) → (Bcϕ → Bcψ).\nBelief is not closed under logical consequence.\n(So Bc is not a normal modal operator.)\n2. 6|=p Bcϕ → ϕ.\nBelief is not veridical.\n3. |=p Kϕ → Bcϕ.\nWhat is known is believed.\n4. |=p ¬Bc⊥.\nThe propositional constant ⊥ for falsehood is not believed.\n5. |=p Bc⊤.\nThe propositional constant ⊤ for truth is believed.\n6. |=p Bcϕ → KBcϕ.\nWhat is believed is known to be believed.\n7. |=p ¬Bcϕ → K¬Bcϕ.\nWhat is not believed is known to be not believed.\n8. |=p K(ϕ → ψ) → (Bcϕ → Bcψ).\nBelief is closed under known logical consequence.\n9. If c ∈ [1 2 , 1), then |=p Bcϕ → B̌cϕ.\nHigh-threshold belief is consistent: belief in ϕ implies disbelief in ¬ϕ.\n10. |=p B̌ 1 2ϕ ∧ Ǩ(¬ϕ ∧ ψ) → B 1 2 (ϕ ∨ ψ).\nFor mid-threshold belief, if ϕ is consistent with the agent’s beliefs and ¬ϕ ∧ ψ is consistent with her knowledge, then she believes ϕ ∨ ψ.\n11. |=p [(ϕiIψi)mi=1 ∧ B 1 2ϕ1 ∧ ∧m i=2 B̌ 1 2ϕi] → ∨m i=1B 1 2ψi.\nMid-threshold belief satisfies (Scott).\nProof. We consider each item in turn.\n1. Given c ∈ (0, 1)∩Q and integers p and q such that p/q = c, we define M as the modification of the model M3.6 of Example 3.6 obtained by changing P as follows:\nP :=\n{\nw1 : q − p\n2q , w2 :\np q , w3 : q − p 2q\n}\n.\nSince 0 < p < q, it follows that\nPw1(J¬h1 → h2Kp) = Pw1({w1, w2}) = q + p\n2q >\n2p 2q = p q ,\nPw1(J¬h1Kp) = Pw1({w2, w3}) = q + p\n2q >\n2p 2q = p q , and\nPw1(Jh2Kp) = Pw1(w2) = p\nq .\nTherefore, we have\nM, w1 |=p B c(¬h1 → h2) ∧B c¬h1 ∧ ¬B ch2 .\n2. For M defined in the proof of Item 1, we have\nM, w1 |=p h1 ∧B c¬h1 .\n3. M, w |=p Kϕ implies Pw(JϕKp) = 1 > c. Hence M, w |=p Bcϕ.\n4. Pw(J⊥Kp) = 0 < c. Hence M, w |= ¬Bc⊥.\n5. Pw(J⊤Kp) = 1 > c. Hence M, w |=p Bc⊤.\n6. M, w |=p Bcϕ implies Pw(JϕKp) > c. To show that M, w |=p KBcϕ, we must prove that\nPw(JB cϕKp) =\nP (JBcϕKp ∩ [w])\nP ([w]) = 1 .\nTo show this, we prove that JBcϕKp ∩ [w] = [w]. So choose u ∈ [w]. Since R is an equivalence relation, we have\nPu(JϕKp) = P (JϕKp ∩ [u])\nP ([u]) =\nP (JϕKp ∩ [w])\nP ([w]) = Pw(JϕKp) > c ,\nwhich implies u ∈ JBcϕKp. The result follows.\n7. The argument is similar to that for Item 6, though we note that M, w |=p ¬Bcϕ implies Pw(JϕKp) ≤ c.\n8. We assume that M, w |=p K(ϕ → ψ) and M, w |=p Bcϕ. This means thatPw(Jϕ → ψKp) = 1 and Pw(JϕKp) > c. But then it follows that Pw(JψKp) > c as well, which is what it means to have M, w |=p Bcψ.\n9. Assume c ∈ [1 2 , 1)∩Q and M, w |=p Bcϕ. Then Pw(JϕKp) > c ≥ 1−c. So Pw(JϕKp) ≥ 1−c.\nThe result therefore follows by Lemma 3.5.\n10. We prove something more general. Assume c ∈ (0, 1 2 ] ∩ Q and M, w |=p B̌cϕ. By\nLemma 3.5, it follows that Pw(JϕKp) ≥ c. Let us assume further that M, w |=p Ǩ(¬ϕ ∧ ψ). This means\n1 6= Pw(J¬(¬ϕ ∧ ψ)Kp) = P (J¬(¬ϕ ∧ ψ)Kp ∩ [w])\nP ([w]) ,\nwhich implies there exists v ∈ J¬ϕ ∧ ψKp ∩ [w]. Since P (v) > 0 by full support, it follows that\nPw(Jϕ ∨ ψKp) = P (Jϕ ∨ ψKp ∩ [w])\nP ([w])\n= P (JϕKp ∩ [w])\nP ([w]) +\nP (J¬ϕ ∧ ψKp ∩ [w])\nP ([w])\n≥ P (JϕKp ∩ [w])\nP ([w]) +\nP (v)\nP ([w])\n= Pw(JϕKp) + P (v)\nP ([w])\n≥ c+ P (v)\nP ([w]) > c .\nThat is, M, w |=p Bc(ϕ ∨ ψ).\n11. Again, we prove something more general. We assume c ∈ (0, 1 2 ] ∩Q plus the following:\nM, w |=p (ϕiIψi) m i=1 (4) M, w |=p B cϕ1 (5) M, w |=p ∧m i=2 B̌ cϕi (6)\nWe recall the meaning of (4): for each v ∈ [w], the number of ϕi’s true at v is less than or equal to the number of ψk’s true at v. It therefore follows from (4) that\nPw(Jϕ1Kp) + · · ·+ Pw(JϕmKp) ≤ Pw(Jψ1Kp) + · · ·+ Pw(JψmKp) . (7)\nOutlining an argument due to Segerberg [Seg71, pp. 344–346], the reason for this is as follows: we think of each world v ∈ [w] as being assigned a “weight” Pw(v). A member Pw(JϕiKp) of the sum on the left of (7) is just a total of the weight of every v ∈ [w] that satisfies ϕi; that is,\nPw(JϕiKp) = ∑ {Pw(v) | v ∈ JϕiKp ∩ [w]} .\nAssumption (4) tells us that for each v ∈ [w], the number of totals Pw(JϕiKp) on the left of (7) to which v contributes its weight is less than or equal to the number of totals Pw(JψkKp) on the right of (7) to which v contributes its weight. But then the sum of totals on the left must be less than or equal to the sum of totals on the right. Hence (7) follows.\nHaving established (7), we now proceed further with the overall proof. By (5), we have Pw(Jϕ1Kp) > c. Applying (6) and Lemma 3.5, we have Pw(ϕi) ≥ c for each i ∈ {2, . . . , m}. Hence\nPw(Jψ1Kp) + · · ·+ Pw(JψmKp) ≥ Pw(Jϕ1Kp) + · · ·+ Pw(JϕmKp) > mc .\nThat is, the sum of the Pw(JψkKp)’s must exceed mc. Since each member of this m-member sum is non-negative, it follows that at least one member must exceed c. That is, there exists j ∈ {1, . . . , m} such that Pw(JψjKp) > c. Hence M, w |=p ∨m j=1B cψj ."
    }, {
      "heading" : "4 Epistemic Neighborhood Models",
      "text" : "The modal formulas Kϕ and Bcϕ were taken as abbreviations in the language L of probability logic. We wish to consider a propositional modal language that has knowledge and belief operators as primitives.\nDefinition 4.1. The language LKB of (single-agent) knowledge and belief is defined by the following grammar.\nϕ ::= ⊤ | p | ¬ϕ | ϕ ∧ ϕ | Kϕ | Bϕ\np ∈ P\nWe adopt the usual abbreviations for other Boolean connectives and define the dual operators Ǩ := ¬K¬ and B̌ := ¬B¬. Finally, the LKB-formula\n(ϕ1, . . . , ϕmIψ1, . . . , ψm)\nand its abbreviation (ϕiIψi)mi=1 are given as in Definition 3.7 except that all formulas are taken from the language LKB.\nOur goal will be to develop a possible worlds semantics for LKB that links with the probabilistic setting by making the following translation truth-preserving.\nDefinition 4.2 (Translation). For c ∈ (0, 1) ∩Q, we define c : LKB → L as follows.\n⊤c := ⊤\npc := p\n(¬ϕ)c := ¬ϕc\n(ϕ ∧ ψ)c := ϕc ∧ ψc\n(Kϕ)c := P (ϕc) = 1 (= Kϕc in L)\n(Bϕ)c := P (ϕc) > c (= Bcϕc in L)\nSince we have seen that the probabilistic belief operator Bc is not a normal modal operator (Theorem 3.9(1)), we opt for a neighborhood semantics for LKB [Che80, Ch. 7] with an epistemic twist.\nDefinition 4.3. An epistemic neighborhood model is a structure\nM = (W,R, V,N)\nsatisfying the following.\n• (W,R, V ) is a finite single-agent S5 Kripke model (as in Definition 2.1). As before, we let\n[w] := {v ∈ W | wRv}\ndenote the equivalence class of world w. This is the set of worlds the agent cannot distinguish from w.\n• N : W → ℘(℘(W )) is a neighborhood function that assigns to each world w ∈ W a collection N(w) of sets of worlds—each such set called a neighborhood of w—subject to the following conditions.\n(kbc) ∀X ∈ N(w) : X ⊆ [w].\n(kbf) ∅ /∈ N(w).\n(n) [w] ∈ N(w).\n(a) ∀v ∈ [w] : N(v) = N(w).\n(kbm) ∀X ⊆ Y ⊆ [w] : if X ∈ N(w), then Y ∈ N(w).\nA pointed epistemic neighborhood model is a pair (M, w) consisting of an epistemic neighborhood model M and a world w in M .\nAn epistemic neighborhood model is a variation of a neighborhood model that includes an epistemic component R. Intuitively, [w] is the set of worlds the agent knows to be possible at w and each X ∈ N(w) represents a proposition that the agent believes at w. The condition that R be an equivalence relation ensures that knowledge is closed under logical consequence, veridical (i.e., only true things can be known), positive introspective (i.e., the agent knows what she knows), and negative introspective (i.e., the agent knows what she does not know).\nProperty (kbc) ensures that the agent does not believe a proposition X ⊆ W that she knows to be false: if X contains a world in w′ ∈ (W − [w]) that the agent knows is not possible with respect to the actual world w, then she knows that X cannot be the case and hence she does not believe X . Property (kbf) ensures that no logical falsehood is believed, while Property (n) ensures that every logical truth is believed. Property (a) ensures that X is believed if and only if it is known that X is believed. Property (kbm) says that belief is monotonic: if an agent believes X , then she believes all propositions Y ⊇ X that follow from X .\nWe now turn to the definition of truth for the language LKB.\nDefinition 4.4. Let M = (W,R, V,N) be an epistemic neighborhood model. We define a binary truth relation |=n between a pointed epistemic neighborhood model (M, w) and LKB-formulas and a function J·KMn : LKB → ℘(W ) as follows.\nJϕKMn := {v ∈ W | M, v |=n ϕ}\nM, w |=n p iff p ∈ V (w)\nM, w |=n ¬ϕ iff M, w 6|=n ϕ\nM, w |=n ϕ ∧ ψ iff M, w |=n ϕ and M, w |=n ψ\nM, w |=n Kϕ iff [w] ⊆ JϕK M n M, w |=n Bϕ iff [w] ∩ JϕK M n ∈ N(w)\nValidity of ϕ ∈ LKB in an epistemic neighborhood model M, written M |=n ϕ, means that M, w |=n ϕ for each world w ∈ W . Validity of ϕ ∈ LKB, written |=n ϕ, means that M |=n ϕ for each epistemic neighborhood model M. For a class C of epistemic neighborhood models, we write C |=n ϕ to mean that M |=n ϕ for each M ∈ C.\nIntuitively, Kϕ is true at w iff ϕ holds at all worlds epistemically possible with respect to w, and Bϕ holds at w iff the epistemically possible ϕ-worlds make up a neighborhood of w. Note that it follows from this definition that the dual for belief B̌ϕ is true at w iff [w]∩ J¬ϕKMn /∈ N(w). The latter says that the epistemically possible ¬ϕ-worlds do not make up a neighborhood of w."
    }, {
      "heading" : "4.1 Neighborhood and Probability Model Agreement",
      "text" : "Epistemic neighborhood models describe agent knowledge and belief. Epistemic probability models can be used for the same purpose along the lines we have discussed above once we establish a belief threshold c ∈ (0, 1) ∩Q. This gives rise to a natural question: is there some sense in which these two models for knowledge and belief can be seen to agree?\nDefinition 4.5 (Model Agreement). Let M = (W,R, V,N) be an epistemic neighborhood model. For a threshold c ∈ (0, 1) ∩ Q, to say that a probability measure P : ℘(W ) → [0, 1] agrees with M for threshold c means we have the following:\n• P satisfies full support (i.e., P (w) 6= 0 for each w ∈ W ); and\n• for each w ∈ W and X ⊆ [w], we have\nX ∈ N(w) iff Pw(X) := P (X|[w]) > c .\nTo say that an epistemic probability model M′ = (W ′, R′, V ′, P ′) agrees with M for threshold c means that (W ′, R′, V ′) = (W,R, V ) and P ′ agrees with M for threshold c. If the threshold c is not mentioned, it is assumed that c = 1\n2 .\nAgreement for threshold c between an epistemic neighborhood model and an epistemic probability model makes the translation c : LKB → L (Definition 4.2) truth-preserving.\nTheorem 4.6 (Agreement). Fix c ∈ (0, 1) ∩ Q, an epistemic neighborhood model M, and an epistemic probability model M′. If M and M′ agree for threshold c, then we have for each ϕ ∈ LKB that\nM, w |=n ϕ iff M ′, w |=p ϕ c .\nProof. Induction on the structure of ϕ ∈ LKB. The non-modal cases are obvious. We first consider knowledge formulas. Assume M, w |=n Kψ. This means [w] ⊆ JψKMn . Applying the induction hypothesis, this is equivalent to [w] ⊆ JψcKM ′\np . By full support, the latter holds if and only if\nPw(Jψ cKM\n′ p ) = P (JψcKM\n′\np ∩ [w])\nP ([w]) = 1 ,\nwhich is what it means to have M′, w |=p P (ψc) = 1. Since P (ψc) = 1 is what is abbreviated by (Kψ)c, the result follows.\nNow we move to belief formulas. Assume M, w |=n Bψ. This means that [w]∩JψKMn ∈ N(w). Since M′ agrees with M, the latter holds iff Pw([w] ∩ JψcKM ′\np ) > c. But this is equivalent to Pw(Jψ cKM ′ p ) > c, which is what it means to have M ′, w |=p P (ψc) > c. Since P (ψc) > c is what is abbreviated by (Bψ)c, the result follows."
    }, {
      "heading" : "4.2 Probability Measures on Epistemic Neighborhood Models",
      "text" : "In this subsection, we take up the question of agreement between epistemic probability models and epistemic neighborhood models from the point of view of the latter: given an epistemic neighborhood model and a threshold c, can we find an agreeing epistemic probability model for this threshold? As we will see, we have a full answer only for the case c = 1\n2 . The case for c 6= 1 2 is\nopen, though we will have some comments on this in the conclusion of the paper. To begin, we adapt an example due to Walley and Fine [WF79] to show that not every epistemic neighborhood model gives rise to an agreeing probability measure.\nTheorem 4.7 ([WF79]). There exists an epistemic neighborhood model M that has no agreeing probability measure for any threshold c ∈ (0, 1) ∩Q.\nProof. We adapt Example 2 from [WF79, pp. 344-345] to the present setting. Fix c ∈ (0, 1) ∩ Q. Let P := {a, b, c, d, e, f, g}. Define:\nX := {efg, abg, adf, bde, ace, cdg, bcf} ,\nY := {abcd, cdef, bceg, acfg, bdfg, abef, adeg} .\nNotation: in the above sets, xyz denotes {x, y, z}, and wxyz denotes {w, x, y, z}. Now define\nN := {X ′ | ∃X ∈ X : X ⊆ X ′ ⊆ P} .\nLet M := (W,R, V,N) be defined by W := P, R := W ×W , V (w) := {w} for each w ∈ P, and N(w) := N for each w ∈ W . It is straightforward to verify that M is an epistemic neighborhood model and that Y ∩ N = ∅.\nToward a contradiction, suppose there exists a probability measure P that agrees with M. Since each letter p ∈ W occurs in exactly three of the seven members of X , we have:\n∑\nX∈X\nP (X) = ∑\np∈W\n3 · P ({p}) .\nSince each letter p ∈ W occurs in exactly four of the seven members of Y , we have:\n∑\nY ∈Y\nP (Y ) = ∑\np∈W\n4 · P ({p}) > ∑\nX∈X\nP (X) .\nOn the other hand, since Y ∩ N = ∅, no member of Y is a neighborhood of M and therefore it follows by the agreement of P with M that we have P (Y ) ≤ c < P (X) for each Y ∈ Y and X ∈ X . But then ∑\nY ∈Y\nP (Y ) < ∑\nX∈X\nP (X) ,\nand we have reached a contradiction. Conclusion: no such P exists.\nQuestion: what are the additional restrictions on the neighborhood function that one must impose in order to guarantee the existence of an agreeing probability measure for a given threshold c ∈ (0, 1) ∩Q? For c = 1\n2 , the restrictions are known. For thresholds c 6= 1 2 , the question is open.\nThe restrictions needed for c = 1 2 were studied first in the form of a purely probabilistic semantics (i.e., something like epistemic probability models and not something like our epistemic neighborhood models). To our knowledge, Lenzen’s [Len80] is the first complete study of the restrictions needed in such a purely probabilistic framework over a unary modal language similar to LKB. The conditions Lenzen proposed are targeted to satisfy the conditions of a theorem due to Scott, which is the key result that gives rise to a probability measure in the completeness proof for Lenzen’s logic. Here we state the required restrictions in the language of our epistemic neighborhood models. Later we will make the link with Lenzen’s axiomatic system when we consider axiomatic theories in the language LKB targeted to our epistemic neighborhood models.\nDefinition 4.8 (Extra Properties for “Mid-Threshold” Models). Let M = (W,R, V,N) be an epistemic neighborhood model. For m ∈ Z+ and sets of worlds X1, . . . , Xm and Y1, . . . , Ym, we write\nX1, . . . , XmIY1, . . . , Ym (8)\nto mean that for each v ∈ W , the number of Xi’s containing v is less than or equal to the number of Yi’s containing v. This is the semantic counterpart of the formula from Definition 3.7. We may write (XiIYi)mi=1 as an abbreviation for (8). Also, we write (XiEYi) m i=1 to mean that both (XiIYi)mi=1 and (YiIXi) m i=1 hold, and we allow the notation with E to be used in a form as in (8). The following is a list of properties that M may satisfy.\n(d) ∀X ∈ N(w) : [w]−X /∈ N(w).\n(sc) ∀X, Y ⊆ [w]: if [w]−X /∈ N(w) and X ( Y , then Y ∈ N(w).\n(scott) ∀m ∈ Z+, ∀X1, . . . , Xm, Y1, . . . , Ym ⊆ [w] :\nif X1, . . . , XmIY1, . . . , Ym and\nX1 ∈ N(w) and\n∀i ∈ {2, . . . , m} : [w]−Xi /∈ N(w) ,\nthen ∃j ∈ {1, . . . , m} : Yj ∈ N(w) .\nTo say an epistemic neighborhood model is mid-threshold means it satisfies (d), (sc), and (scott). We may drop the word “epistemic” in referring to mid-threshold epistemic neighborhood models. Pointed versions of mid-threshold neighborhood models are defined in the obvious way.\nProperty (d) ensures that beliefs are consistent in the sense that the agent does not believe both X and its complement [w]−X . Property (sc) is a form of “strong commitment”: if the agent does not believe the complement [w] − X , then she must believe any strictly weaker Y implied by X . Property (scott) is a version of the syntactic scheme (Scott) from Definition 3.8.\nLet us return to the model M from the proof of Theorem 5.5. It is easy to see that for no Xi ∈ X do we have W −Xi ∈ N(a) = N . So, numbering the members of X as X1, . . . , X7 and the members of Y as Y1, . . . , Y7, we see that M satisfies\n(XiIYi) 7 i=1, X1 ∈ N(a), and ∀i ∈ {2, . . . , 7} : W −Xi /∈ N(a) ,\nwhich is the antecedent of property (scott) from Definition 4.8. However, M does not satisfy\n∃j ∈ {1, . . . , 7} : Yj ∈ N(a) ,\nwhich is the corresponding consequent of the indicated instance of (scott). So we see that if we were to restrict ourselves to the class of epistemic neighborhood models satisfying this property, we would no longer be able to use M as a counterexample to the claim that not every epistemic neighborhood model gives rise to an agreeing probability measure. Of course ruling out M as a counterexample to this claim does not prove the claim. However, utilizing (scott) in conjunction with (d) and (sc), we are able to prove the claim. This proof makes crucial use of a theorem due to Scott that is closely related to [Sco64, Theorem 4.1].\nIn preparation for the statement of Scott’s theorem, we recall some well-known notions from linear algebra. For a nonempty set S, let L(S) denote the S-dimensional real vector space whose vectors consist of functions x : S → R and whose operations of vector addition and scalar multiplication are defined coordinate-wise: given vectors x, y : S → R and a scalar real r ∈ R, the vector (x+ y) : S → R is defined by (x+ y)(s) := x(s) + y(s) for each coordinate s ∈ S and the vector (r ·x) : S → R is defined by (r ·x)(s) := r ·x(s) for each coordinate s ∈ S. Note that we have just used the usual notational overloading wherein the + or · symbol on one side of an equation refers to the vector operation, and yet the same symbol on the other side of the same equation refers to the operation in R. Other common notational abbreviations such as omission of ·’s and writing −x for (−1) ·x will be used. To say that a vector x : S → R is rational means that all of its coordinates (i.e., values) are rational numbers. To say a set X ⊆ L(S) of vectors is rational means that every\nvector in X is rational, and to say that X is symmetric means that X = −X := {−x | x ∈ X}. A linear functional on L(S) is a function f : L(S) → R satisfying the following property of linearity: for each r1, r2 ∈ R and x, y ∈ L(S), we have f(r1x+ r2y) = r1 · f(x) + r2 · f(y).\nTheorem 4.9 ([Sco64, Theorem 1.2]). Let S be a finite nonempty set and X be a finite, rational, symmetric subset of L(S). For each N ⊆ X , there exists a linear functional f on L(S) that realizes N , meaning\nN = {x ∈ X | f(x) ≥ 0} ,\nif and only if the following conditions are satisfied:\n• for each x ∈ X , we have x ∈ N or −x ∈ N ; and\n• for each integer n ≥ 0 and x0, . . . , xn ∈ N , we have\nn∑\ni=0\nxi = 0 ⇒ −x0 ∈ N .\nWe use this theorem to show that mid-threshold models always give rise to an agreeing probability measure. That is, the neighborhood function of mid-threshold models picks out exactly those neighborhoods that may be assigned a probability exceeding 1\n2 . Many of the key ideas of the proof\nof the following result are due to Lenzen [Len80]. However, the argument we present here has been rewritten in a streamlined, modern form and in the language of our epistemic neighborhood models. Despite this difference (and the necessary work we had to undertake to translate these results into this modern form), we are happy to credit Professor Lenzen for the following result.\nTheorem 4.10 ([Len80]). Let M = (W,R, V,N) be a mid-threshold epistemic neighborhood model. There exists a probability measure P : ℘(W ) → [0, 1] agreeing with M for threshold 1\n2 ;\nthat is,\n• P satisfies full support (i.e., P (w) 6= 0 for each w ∈ W ); and\n• for each w ∈ W and X ⊆ [w], we have\nX ∈ N(w) iff Pw(X) := P (X|[w]) > 12 .\nProof. We credit Lenzen [Len80] for this proof, though we herein provide an original reformulation of his work within the setting of the epistemic neighborhood models introduced in this paper. Proceeding, for w ∈ W , define Sw := [w]. For each X ⊆ Sw, define the relative complement X ′ := Sw −X and let ι(X) : Sw → {0, 1} be the characteristic function of X:\nι(X)(s) :=\n{\n1 if s ∈ X,\n0 otherwise.\nWe consider the following finite subsets of L(Sw):\nAw := {ι(X) | X ⊆ Sw} , Bw := {ι(X)− ι(X ′) | X ⊆ Sw & X ′ /∈ N(w)} ,\nNw := Aw ∪ Bw ,\nXw := Nw ∪ (−Nw) .\nIt is easy to see that Nw ⊆ Xw and that Xw is a finite, rational, and symmetric subset of L(Sw). We wish to show that Nw and Xw satisfy the conditions of Theorem 4.9. First, we note that x ∈ Xw implies x ∈ Nw or −x ∈ Nw by the definition of Xw.\nFor the second condition of Theorem 4.9, suppose we are given an integer n ≥ 0 such that x0, . . . , xn ∈ Nw and ∑n i=0 xi = 0. We wish to show that −x0 ∈ Nw. Proceeding, there exists an integer ℓ satisfying:\n0 ≤ i ≤ ℓ implies xi = ι(Xi)− ι(X ′ i) ∈ Bw , and ℓ < i ≤ n implies xi = ι(Xi) ∈ Aw .\nToward a contradiction, assume there exists i > ℓ with xi 6= 0. Then for x∗ := ∑n\ni=ℓ+1 xi, we have x∗(s) ≥ 0 for all s ∈ Sw, and there exists s∗ ∈ Sw with x∗(s∗) > 0. Hence\n∑ℓ i=0 xi = ∑ℓ i=0 ( ι(Xi)− ι(X ′i) ) = −x∗ ,\nwhere −x∗(s∗) < 0 and −x∗(s) ≤ 0 for all s ∈ Sw. So for each s ∈ Sw, the number of the sets in the list X ′0, . . . , X ′ ℓ containing s is greater than or equal to the number of the sets in the list X0, . . . , Xℓ containing s. Further, s∗ is a member of strictly more sets in the former list than those in the latter. By renumbering, we may assume that s∗ ∈ X ′0 −X0. Then we have\nX0 ∪ {s ∗}, X1, . . . , XℓIX ′ 0, X ′ 1, . . . , X ′ ℓ .\nSince X ′0, . . . , X ′ ℓ /∈ N(w), it follows by (scott) that X0 ∪ {s ∗} /∈ N(w). But X0 ( X0 ∪ {s∗} /∈ N(w) and X ′0 /∈ N(w), which violates (sc). Conclusion: i > ℓ implies xi = 0. But then we have∑n\ni=0 xi = ∑ℓ i=0 xi. Since xi = ι(Xi)− ι(X ′ i) for i ≤ ℓ, it follows that ∑ℓ i=0 ι(Xi) = ∑ℓ i=0 ι(X ′ i).\nBut the latter is what it means to have (XiEX ′i) ℓ i=0. Since X ′ i /∈ N(w) for i ≤ ℓ by the definition of Bw, it follows by (scott) that X0 /∈ N(w). But then ι(X ′0)− ι(X0) = −x0 ∈ Bw ⊆ Nw, as desired. So we may apply Theorem 4.9: there exists a linear functional fw on L(Sw) that realizes Nw. That is, Nw = {x ∈ Xw | fw(x) ≥ 0} .\nDefine gw : ℘(Sw) → R by the composition gw(X) := fw(ι(X)). This function satisfies a few important properties.\n1. X ∈ N(w) iff gw(X) > gw(X ′).\nSuppose X ∈ N(w). Then X ′ /∈ N(w) by (d). Hence ι(X)−ι(X ′) ∈ Bw and ι(X ′)−ι(X) /∈ Bw. Since Sw ∈ N(w) by (n), it follows that X 6= ∅ = S ′w. But then the coordinates of\nι(X ′)− ι(X) contain at least one 1 and at least one −1. Since every x ∈ Aw has coordinates that are 1’s or 0’s only, it follows that ι(X ′)− ι(X) /∈ Nw. As ι(X)− ι(X ′) ∈ Bw ⊆ Nw and fw is linear and realizes Nw, it follows that gw(X) ≥ gw(X ′) and gw(X ′) gw(X). That is, gw(X) > gw(X ′).\nConversely, suppose gw(X) > gw(X ′). Since fw is linear and realizes Nw, it follows that ι(X ′)− ι(X) /∈ Nw ⊇ Bw. Applying the definition of Bw, we have X ∈ N(w).\n2. gw(Sw) > gw(∅) = 0.\nWe have gw(∅) = fw(0) = 0 by the linearity of fw. Since Sw ∈ N(w) by (n), it follows that gw(Sw) > gw(∅) by property 1.\n3. If 0 ≤ gw(X) ≤ gw(Sw).\nSince ι(X) ∈ Aw ⊆ Nw and fw realizes Nw, we have gw(X) ≥ 0. So each X ⊆ Sw satisfies gw(X) ≥ 0. From this it follows by the linearity of fw that for each X ⊆ Sw, we have\ngw(X) = ∑ v∈X gw({v}) ≤ ∑ v∈Sw gw({v}) = gw(Sw) .\n4. If X, Y ⊆ Sw and X ∩ Y = ∅, then gw(X ∪ Y ) = gw(X) + gw(Y ).\nBy the linearity of fw.\n5. ∅ 6= X ⊆ Sw implies gw(X) > 0.\nSuppose ∅ 6= X ⊆ Sw. By property 2, it suffices to prove the result for X 6= Sw. Toward a contradiction, assume gw(X) = 0 for ∅ ( X ( Sw. By property 4, we have gw(Sw) = gw(X) + gw(X ′) = gw(X ′). Since fw is linear and realizes Nw and\nι(X ′)− ι(Sw) = −(ι(Sw)− ι(X ′)) = −ι(X) ∈ Xw ,\nwe obtain −ι(X) ∈ Nw. But ∅ ( X ( Sw implies that −ι(X) has coordinates containing at least one −1 and at least one 0. Since members of Aw have coordinates made up of 0’s and 1’s, members of Bw have coordinates made up of −1’s and 1’s, and Nw = Aw ∪ Bw, it cannot be the case that −ι(X) ∈ Nw. Contradiction. Conclusion: gw(X) > 0.\nNow take v ∈ [w]. Since N(v) = N(w) by (a), it follows that gw also realizes Nv. So, letting [W ] be the set {[w] | w ∈ W} of equivalence classes, let h : [W ] → W be a choice function that selects for each class [w] ∈ [W ] a representative h([w]) ∈ [w]. Using a notational overloading that ought to be harmless, we define a new function hw : ℘([w]) → R by setting hw(X) := gh([w])(X). Obviously, v ∈ [w] implies hv = hw. Finally, we define P : ℘(W ) → [0, 1] by\nP (X) := ∑\n[w]∈[W ]\nhw(X ∩ [w])\nhw([w]) .\nNote that by property 2, the denominator hw([w]) is always nonzero.\nWe prove that P is a probability measure on ℘(W ) satisfying full support. First, P satisfies the Kolmogorov axioms over the finite algebra ℘(W ): we have P (X) ≥ 0 by property 3, P (W ) = 1 by property 2 and the definition of P , and P (X ∪ Y ) = P (X) + P (Y ) for disjoint X and Y by property 4 and the definition of P . Second, full support follows by property 5.\nFinally, for X ⊆ [w], we have by property 1 that X ∈ N(w) iff hw(X) > hw(X ′). But the latter holds iff we have (making use of property 4) that\n2 · hw(X) > hw(X) + hw(X ′) = hw([w]) .\nBy property 2, the definition of P , and the fact that X ⊆ [w], the above inequality holds iff\nP (X) = hw(X)\nhw([w]) > 1 2 .\nCorollary 4.11. Let M = (W,R, V,N) be a mid-threshold epistemic neighborhood model. There exists an epistemic probability model N = (W,R, V, P ) that agrees with M for threshold 1\n2 .\nProof. Let P be the measure given by Theorem 4.10."
    }, {
      "heading" : "4.3 Epistemic Neighborhood Models from Probability Measures",
      "text" : "In the last subsection, we investigated the question of whether an epistemic neighborhood model gives rise to an agreeing epistemic probability model. In this section, we look at this question the other way around: given an epistemic probability model and a threshold c, is there an agreeing epistemic neighborhood model? As we will see, the answer is always “yes.”\nDefinition 4.12. Given an epistemic probability model M = (W,R, V, P ) and a threshold c ∈ [1 2 , 1) ∩Q, we define the structure Mc := (W,R, V,N c) by setting\nN c(w) := {X ⊆ [w] | Pw(X) > c} .\nIntuitively, the agent believes a proposition X at world w (i.e., X ∈ N c(w)) if and only if X is epistemically possible (i.e., X ⊆ [w]) and the probability she assigns to X at world w exceeds the threshold (i.e., Pw(X) > c).\nLemma 4.13 (Correctness). Fix c ∈ (0, 1) ∩Q. If M is an epistemic probability model, then Mc is an epistemic neighborhood model. Furthermore, M 1 2 is a mid-threshold neighborhood model.\nProof. We verify that N c satisfies the required properties.\n• For (kbc), X ∈ N c(w) implies X ⊆ [w] by definition.\n• For (kbf), Pw(∅) = 0 < c, so ∅ /∈ N c(w).\n• For (n), Pw([w]) = 1 > c, so [w] ∈ N c(w).\n• For (a), suppose X ∈ N c(w) and v ∈ [w]. Then Pw(X) > c. Since v ∈ [w] implies [w] = [v], we have\nPw(X) = P (X ∩ [w])\nP ([w]) =\nP (X ∩ [v])\nP ([v]) = Pv(X) .\nHence Pv(X) > c, so X ∈ N c(v).\n• For (kbm), suppose X ∈ N c(w). Then Pw(X) > c. Hence if Y satisfies X ⊆ Y ⊆ [w], we have Pw(Y ) > c and so Y ∈ N c(w).\nSo Mc is an epistemic neighborhood model. We now show that M 1\n2 satisfies the additional required properties.\n• For (d), assume c ∈ [1 2 , 1) ∩ Q and X ∈ N c(w). Then Pw(X) > c, and therefore Pw([w]−\nX) ≤ 1− c ≤ c. Hence [w]−X /∈ N c(w).\n• For (sc), assume X ′ := [Γ] − X /∈ N 1\n2 (w) and X ( Y ⊆ [Γ]. From the first assumption, we have Pw(X ′) ≤ 12 , and therefore that Pw(X) ≥ 1 2 . Applying the second assumption, Pw(Y ) > Pw(X) ≥ 1 2 , and hence X ∈ N 1 2 (w).\n• For (scott), we assume c ∈ (0, 1 2 ] ∩Q along with the following:\n(XiIYi) m i=1 (9) X1 ∈ N c(w) (10) ∀i ∈ {2, . . . , m} : [Γ]−Xi /∈ N c(w) (11)\nFrom (9) it follows that\nPw(X1) + · · ·+ Pw(Xm) ≤ Pw(Y1) + · · ·+ Pw(Ym) (12)\nThe argument for this is similar to an argument for (7) in proof of Theorem 3.9(11). From (10), we have Pw(X1) > c. From (11), we have for each i ∈ {2, . . . , m} that Pw([w]−Xi) ≤ c and therefore that Pw(Xi) ≥ 1 − c ≥ c since c ∈ (0, 12 ] ∩ Q. Hence the left side of (12) exceeds mc. Since every summand on the right side of the inequality is positive and mc > 0, it follows that at least one member of the right side of (12) must exceed c. That is, there exists j ∈ {1, . . . , m} such that Pw(Yj) > c and hence Yj ∈ N c(w).\nTheorem 4.14. Let c ∈ (0, 1)∩Q and M = (W,R, V, P ) be an epistemic probability model. The epistemic neighborhood model Mc = (W,R, V,N c) agrees with M for threshold c.\nProof. By definition of N c."
    }, {
      "heading" : "5 Calculi for Belief as Willingness to Bet",
      "text" : "We now consider an axiomatic link both with epistemic neighborhood models and with epistemic probability models. We study two calculi: the calculus KB of epistemic neighborhood models, and the calculus KB.5 of mid-threshold neighborhood models. Regarding the probability interpretation, KB is sound for every threshold but not complete for any threshold. KB.5 is both sound and complete for the probability interpretation with threshold c = 1\n2 .\nKB.5 is our modern reformulation of Lenzen’s [Len80] calculus for the logic of knowledge (i.e., Lenzen’s “acceptance”) as probabilistic certainty and belief as probability exceeding threshold 1\n2 . Lenzen’s intended semantic structures are something like epistemic probability models. Our intended semantic structures are our mid-threshold neighborhood models, though there is a natural link with epistemic probability models via Theorem 4.10. In fact, many of the main ideas of our proof of Theorem 4.10 are not doubt translations of Lenzen’s ideas into the language of our epistemic neighborhood models. Since we have rewritten all proofs using our own approach and modern modal notions, it is difficult to determine whether we have introduced novel mathematical results on top of Lenzen’s existing work, though we suspect that anything new we may have added along these lines (excluding of course epistemic neighborhood models themselves and all related results except Theorem 4.10) may be slight at best. Therefore, we are happy to credit Professor Lenzen for the probabilistic soundness and completeness of KB.5 and for Theorem 4.10. Nevertheless, we do think that it is worth our effort to provide this modern reformulation of his results. In particular, we believe that in using semantic structures more familiar to the modern modal logician, our modern reformulation of Lenzen’s results will make the mathematical details of Lenzen’s work more accessible to a modern English-language audience. We also hope that our use of the modal neighborhood structures will suggest directions for further study of qualitative probability via tools from modal logic.\nDefinition 5.1. We define the following theories in the language LKB.\n• KB is defined in Table 1.\n• KB.5 is obtained from KB by adding (D), (SC), and (Scott) from Table 2.\n• KB.5− is obtained from KB.5 by omitting (BF) and (KBM).\nWe will see later in Theorem 5.6 that KB.5 and KB.5− derive the same theorems."
    }, {
      "heading" : "5.1 Results for the Basic Calculus KB",
      "text" : "The following result shows that if we restrict attention to provable statements whose only modality is single-agent belief Bϕ, then KB is an extension of the minimal modal logic EMN45 + ¬B⊥ = EMN45+(BF) obtained by adding S5-knowledge and the knowledge-belief connection principles (Ap), (An), and (KBM).2 The modal theory KB.5, which we will see is equivalent to KB.5−, is a\n2EMN45+ (BF) is the logic of single-agent belief (without knowledge) having Schemes (CL) (Table 1), M (Theorem 5.2(2)), (N) (Table 1), 4 (Theorem 5.2(5)), 5 (Theorem 5.2(6)), and (BF) (Table 1) along with Rules (MP)\nknowledge-inclusive extension of EMND45+(Scott) that adds the additional connection principle (SC).3 In Section 5.2, we will show that KB.5 is the modal logic for probabilistic belief with threshold c = 1\n2 .\nTheorem 5.2 (KB Derivables). We have each of the following.\n1. KB ⊢ Kϕ → Bϕ.\n“Knowledge implies belief.”\n2. KB ⊢ B(ϕ ∧ ψ) → (Bϕ ∧Bψ).\nThis is “Scheme M” [Che80, Ch. 8].\n3. KB ⊢ Kϕ ∧ Bψ → B(ϕ ∧ ψ).\nIf the antecedent Kϕ were replaced by Bϕ, then we would obtain “Scheme C” [Che80, Ch. 8]. So we do not have Scheme C outright but instead a knowledge-weakened version:\n(Table 1) and RE (Theorem 5.2(12)). This is a “monotonic” system of modal logic satisfying positive and negative belief introspection (4 and 5) and the property (BF) that falsehood ⊥ is not believed. See [Che80, Ch. 8] for details on naming minimal modal logics.\n3EMND45+ (Scott) is EMN45+ (BF) minus Scheme (BF) plus Schemes (D) and (Scott) from Table 2.\nin order to conclude belief of a conjunction from belief of one of the conjuncts, the other conjunct must be known (and not merely believed, as is required by the stronger, non-KBprovable Scheme C).\n4. KB ⊢ K(ϕ → ψ) → (B̌ϕ → B̌ψ).\nThis is the dual version of our (KBM).\n5. KB ⊢ Bϕ → BBϕ.\nThis is “Scheme 4” for belief [Che80, Ch. 8].\n6. KB ⊢ ¬Bϕ → B¬Bϕ.\nThis is “Scheme 5” for belief [Che80, Ch. 8].\n7. KB ⊢ Bϕ ↔ KBϕ.\nThis says that belief and knowledge of belief are equivalent.\n8. KB ⊢ ¬Bϕ ↔ K¬Bϕ.\nThis says that non-belief and knowledge of non-belief are equivalent.\n9. KB ⊢ ϕ implies KB ⊢ Bϕ.\nThis is the rule of Modus Ponens (or Modal Necessitation), sometimes called “Rule RN” [Che80, Ch. 8].\n10. KB ⊢ ϕ → ψ implies KB ⊢ Bϕ → Bψ.\nThis is “Rule RM” [Che80, Ch. 8].\n11. KB ⊢ ϕ → ψ implies KB ⊢ B̌ϕ → B̌ψ.\nThis is the dual version of RM.\n12. KB ⊢ ϕ ↔ ψ implies KB ⊢ Bϕ ↔ Bψ.\nThis is “Rule RE” [Che80, Ch. 8].\n13. KB ⊢ ϕ → ⊥ implies KB ⊢ ¬Bϕ.\nThis says that no self-contradictory sentence is believed. This may be viewed as a certain generalization of (BF) (Table 1).\nProof. We reason in KB. For 1, we have Kϕ → K(⊤ → ϕ) by elementary modal reasoning. But then from this, B⊤ by (N), and K(⊤ → ϕ) → (B⊤ → Bϕ) by (KBM), it follows by classical reasoning that we have Kϕ → Bϕ.\nFor 2, we derive K((ϕ ∧ ψ) → ϕ) → (B(ϕ ∧ ψ) → Bϕ) (13)\nby (KBM), and the antecedent of (13) by (CL) and (MN). Therefore, the consequent of (13) is derivable by (MN). By a similar argument, B(ϕ ∧ ψ) → Bψ is derivable. By classical reasoning, 2 is derivable.\nFor 3, we derive\nKϕ → K(ψ → (ϕ ∧ ψ)) and (14)\nK(ψ → (ϕ ∧ ψ)) → (Bψ → B(ϕ ∧ ψ)) . (15)\n(14) follows by S5 reasoning. (15) follows by (KBM). Applying classical reasoning to (14) and (15), we obtain\nKϕ → (Bψ → B(ϕ ∧ ψ)) ,\nfrom which 3 follows by classical reasoning. For 4, we derive\nK(ϕ → ψ) → K(¬ψ → ¬ϕ) and (16)\nK(¬ψ → ¬ϕ) → (B¬ψ → B¬ϕ) . (17)\n(16) follows by S5 reasoning. (17) follows by (KBM). Applying classical reasoning to (16) and (17), we obtain\nK(ϕ → ψ) → (B¬ψ → B¬ϕ) ,\nfrom which 4 follows by classical reasoning (just contrapose the consequent). 5 follows by (Ap) and 1. 6 follows by (An) and 1. 7 follows by by (Ap) for the right-to-left and (KS5) for the left-to-right. 8 follows by (An) for the right-to-left and (KS5) for the left-to-right. 9 follows by (MN) and 1. 10 follows by (MN) and (KBM). 11 follows by contraposition, (MN), (KBM), and contraposition. 12 follows from 10 by classical reasoning.\nFor 13, we have K(ϕ → ⊥) → (Bϕ → B⊥) (18)\nby (KBM). Therefore, if ϕ → ⊥ is provable, it follows by (MN) that the antecedent of (18) is as well. By (MP), the consequent Bϕ → B⊥ is provable. Applying (BF) and classical reasoning, it follows by contraposition that ¬Bϕ is provable.\nTheorem 5.3 (KB Neighborhood Soundness and Completeness). KB is sound and complete with respect to the class C of epistemic neighborhood models:\n∀ϕ ∈ LKB : KB ⊢ ϕ ⇔ C |=n ϕ .\nProof. By induction on the length of derivation. We first verify soundness of the axioms.\n• Validity of (CL) immediate. Validity of (KS5) follows because the R’s are equivalence relations [BdRV01].\n• Scheme (BF) is valid: |=n ¬B⊥.\nJ⊥Kn = ∅ /∈ N(w) by (kbf). Hence M, w 6|=n B⊥.\n• Scheme (N) is valid: |=n B⊤.\nJ⊤Kn ∩ [w] = [w] ∈ N(w) by (n). Hence M, w |=n B⊤.\n• Scheme (Ap) is valid: |=n Bϕ → KBϕ.\nSuppose M, w |=n Bϕ. Then [w]∩ JϕKn ∈ N(w). Take v ∈ [w]. We have [v] = [w] because R is an equivalence relation, and we have N(v) = N(w) by (a). Hence [v] ∩ JϕKn ∈ N(v); that is, M, v |=n Bϕ. Since v ∈ [w] was chosen arbitrarily, we have shown that [w] ⊆ JBϕKn. Hence M, w |=n KBϕ.\n• Scheme (An) is valid: |=n ¬Bϕ → K¬Bϕ.\nReplace Bϕ by ¬Bϕ and ∈ by /∈ in the argument for the previous item.\n• Scheme (KBM) is valid: |=n K(ϕ → ψ) → (Bϕ → Bψ).\nSuppose M, w |=n K(ϕ → ψ) and M, w |=n Bϕ. This means [w] ⊆ Jϕ → ψKn and [w] ∩ JϕKn ∈ N(w). But then\n[w] ∩ JϕKn ⊆ [w] ∩ JϕKn ∩ Jϕ → ψKn ⊆ [w] ∩ JψKn .\nHence [w] ∩ JψKn ∈ N(w) by (kbm). That is, M, w |=n Bψ.\nThat validity is closed under applications of the rules MP and MN follows by the standard arguments [BdRV01]. This completes the proof of soundness.\nBefore we prove completeness, we first prove an important result that we will use tacitly throughout the completeness proof proper. Let M be the set of all LKB-formulas having one of the forms Kϕ, ¬Kϕ, Bϕ, or ¬Bϕ. We prove the following Modal-Assumption Deduction Theorem: for each finite F ⊆ M , we have\nF ⊢KB ϕ iff ⊢KB ( ∧ F ) → ϕ .\nThe right-to-left direction straightforward. The proof of the left-to-right direction is by induction on the length of derivation. All cases are standard except for the induction step in which (MN) is applied, so we focus on this case. Suppose F ⊢KB Kϕ is derived by (MP) from ϕ such that F ⊢KB ϕ. By the induction hypothesis, we have ⊢KB ( ∧\nχ∈F χ) → ϕ. By (MN) and K reasoning, we have ⊢KB ( ∧\nχ∈F Kχ) → Kϕ. However, it also follows by S5 reasoning (using schemes 4 and 5), scheme (Ap), scheme (An), and the fact that F ⊆ M that we have ⊢KB χ → Kχ for each χ ∈ F . Hence ⊢KB ( ∧ χ∈F χ) → ( ∧ χ∈F Kχ), where ( ∧ χ∈F χ) = ∧\nF . Conclusion: ⊢KB ( ∧ F ) → Kϕ.\nTo prove completeness, it suffices to show that KB 0 ¬θ implies θ is satisfiable at a pointed epistemic neighborhood model. For two sets F and F ′ of LKB-formulas, to say that F is maxcons in F ′ means that F ⊆ F ′, the set F is KB-consistent (i.e., for no finite G ⊆ F do we have ⊢KB ( ∧ G) → ⊥), and adding any formula ψ ∈ F ′ not already in F will produce a KB-inconsistent (i.e., not KB-consistent) set.\nFor a set F of LKB-formulas, we define the single-negation closure ±F of F and the modal closure MCl(F ) of F to be the sets\n±F := F ∪ {¬ϕ | ϕ ∈ F} ∪ {⊥,⊤} ,\nMCl(F ) := F ∪ {Xϕ | ϕ ∈ F and X ∈ {K,¬K,B,¬B}} .\nIn particular, MCl(F ) is obtained from F by adding for each formulaϕ ∈ F the additional formulas Kϕ, ¬Kϕ, Bϕ, and ¬Bϕ. We say the each of the latter four formulas is a modalization of ϕ.\nLet S be the set of subformulas of θ, including θ itself. Let C0 be the Boolean closure of S; that is, C0 is the smallest extension of S that contains the propositional constants ⊤ (truth) and ⊥ (falsehood), or their abbreviations in LKB if they are not primitive, and is closed under the Boolean connectives (e.g., negation, conjunction, implication, and disjunction) definable in the language. Finally, define C := MCl(C0).\nWe define the structure M = (W,R, V,N) as follows:\nW := {w ⊆ C | w is maxcons in C},\n[ϕ] := {w ∈ W | ϕ ∈ w} for ϕ ∈ C,\nR := {(w, v) ∈ W 2 | w ∩M = v ∩M},\nV (w) := P ∩ w,\nN(w) := {X ⊆ [w] | ∃ϕ ∈ C : (X = [ϕ] ∩ [w] and w ∩M ⊢KB Bϕ)}.\nWe make use (often tacitly) of the following In-class Identity Lemma: for each u, v ∈ W , if [u] = [v] and u ∩ ±S = v ∩ ±S, then u = v. So suppose [u] = [v] and u ∩ S ′ = v ∩ S ′. Given ϕ ∈ u, we wish to show that ϕ ∈ u. There are two cases to consider.\n• Case: ϕ ∈ u ∩ C0.\nϕ is a Boolean combination of members of S and is therefore KB-provably equivalent to a formula ϕ′ that is a disjunction of conjunctions of maxcons subsets of ±S. It follows by the maximal KB-consistency of u that ϕ′ ∈ u and hence one of the disjuncts ϕ′′ of ϕ′ is a member of u. Applying the maimal KB-consistency of u, it follows from ϕ′′ ∈ u that every conjunct of ϕ′′ is a member of u. But each conjunct of ϕ′′ is a member of ±S ⊆ S ′ and hence each conjunct of ϕ′′ is a member of v by our assumption u ∩ S ′ = v ∩ S ′. Applying the maximal KB-consistency of v, it follows that ϕ′′ ∈ v, hence ϕ′ ∈ v, and hence ϕ ∈ v.\n• Case: ϕ ∈ u ∩ (C − C0).\nϕ is a modalization Xψ of a Boolean combination of members of S. But Xψ ∈ M and our assumption [u] = [v] implies u ∩M = v ∩M . So Xψ ∈ v.\nThe converse is proved similarly. The In-class Identity Lemma gives rise to the following Identity Lemma: for each u, v ∈ W , if u ∩ MCl(±S) = v ∩MCl(±S), then u = v. Indeed, suppose u ∩ MCl(±S) = v ∩ MCl(±S). If [u] = [v], then it follows from ±S ⊆ MCl(±S) that we have u ∩ ±S = v ∩ ±S, and therefore u = v by the In-class Identity Lemma. So it suffices to prove that [u] = [v]; that is, we prove that\nu ∩M = v ∩M . Proceeding, take Xϕ ∈ u ∩M . If Xϕ ∈ C0, then we have Xϕ ∈ v ∩M by the argument in the first case of the In-class Identity Lemma. So suppose Xϕ ∈ C − C0 so that Xϕ is a modalization of ϕ ∈ C0. We have ⊢KB ϕ ↔ ϕ′, where ϕ′ is a disjunction of conjunctions of maxcons subsets of ±S. Applying (MN) and K reasoning, we obtain\n⊢KB Kϕ ↔ Kϕ ′ and ⊢KB ¬Kϕ ↔ ¬Kϕ ′ . (19)\nApplying (KBM) and classical reasoning to (19), it follows that\n⊢KB Bϕ ↔ Bϕ ′ and ⊢KB ¬Bϕ ↔ ¬Bϕ ′ . (20)\nSince Xϕ ∈ u, we have by (19), (20), and the maximal KB-consistency of u that Xϕ′ ∈ u ∩ MCl(±S). Since u ∩MCl(±S) = v ∩MCl(±S), it follows that Xϕ′ ∈ v, and hence Xϕ ∈ v by the maximal KB-consistency of v. The converse is proved similarly.\nWe may make use (often tacitly) of the following Definability Lemma: for each w ∈ W and each X ⊆ [w], defining\nXd := ∨\nv∈X\n∧ (v ∩ ±S) ,\nit follows that Xd ∈ C0 ⊆ C and [Xd] ∩ [w] = X . For the proof, first note that Xd ∈ C0 because C0 is closed under Boolean operations and ±S ⊆ C0 ⊆ C. So assume u ∈ [Xd] ∩ [w], which implies Xd ∈ u and [u] = [w]. Since u is maxcons in C ⊇ ±S, we have by the above definition of Xd as a disjunction over v ∈ X that there exists v ∈ X such that ∧ (v ∩ ±S) ∈ u and hence v∩±S ⊆ u. Since u is maxcons in C and hence maxcons in ±S and since ±S is closed under the operation ∼ : LKB → LKB defined by\n∼ϕ :=\n{\nψ if ϕ = ¬ψ\n¬ϕ otherwise,\nit follows that u ∩ ±S = v ∩ ±S. So since [u] = [v] and u ∩ ±S = v ∩ ±S, we have u = v ∈ X by the Identity Lemma. Conversely, suppose u ∈ X ⊆ [w]. By the definition of Xd, we have KB ⊢ ∧ (u ∩ ±S) → Xd and therefore Xd ∈ u because u is maxcons in C and ∧ (u ∩ ±S) ∈ u. Hence u ∈ [Xd] ∩ [w] because u ∈ X ⊆ [w]. Our definitions above specify the structure M = (W,R, V,N). W is nonempty because θ is consistent and so may be extended to a maxcons wθ ∈ W . Since MCl(±S) is finite, it follows by the Identity Lemma that W is finite. Further, R is an equivalence relation. So to conclude that M is an epistemic neighborhood model, all that remains is for us to show that N satisfies the neighborhood function properties.\n(kbc) X ∈ N(w) implies X ⊆ [w].\nBy definition.\n(bf) ∅ /∈ N(w).\nChoose ϕ ∈ C satisfying [ϕ] ∩ [w] = ∅. It follows that w ∩M ⊢KB ϕ → ⊥, since otherwise we could extend (w∩M)∪{ϕ} to some v ∈ [ϕ]∩ [w], which would contradict [ϕ]∩ [w] = ∅.\nSo by (MN), we have w∩M ⊢KB K(ϕ → ⊥) and hence w∩M ⊢KB Bϕ → B⊥ by (KBM). Since w ∩ M ⊢ ¬B⊥ by (BF), it follows that w ∩ M ⊢KB ¬Bϕ. So we have shown that w ∩ M ⊢KB ¬Bϕ for each ϕ ∈ C satisfying [ϕ] ∩ [w] = ∅. KB is consistent (just apply soundness to any epistemic neighborhood model), and therefore we have w ∩ M 0KB Bϕ for each ϕ ∈ C satisfying [ϕ] ∩ [w] = ∅. Conclusion: ∅ /∈ N(w).\n(n) [w] ∈ N(w).\nw ∩M ⊢KB B⊤ by (N). Hence [⊤] ∩ [w] = [w] ∈ N(w).\n(a) v ∈ [w] implies N(v) = N(w).\nv ∈ [w] implies [v] = [w] and v ∩M = w ∩M . Therefore for each X ⊆ [v] = [w], we have ϕ ∈ C satisfying X = [ϕ] ∩ [v] and v ∩M ⊢KB Bϕ iff X = [ϕ] ∩ [w] and w ∩M ⊢KB Bϕ. Hence N(v) = N(w).\n(kbm) If X ⊆ Y ⊆ [w] and X ∈ N(w), then Y ∈ N(w).\nSuppose X ⊆ Y ⊆ [w] and X ∈ N(w). Then there is ϕ ∈ C satisfying X = [ϕ] ∩ [w] and w ∩ M ⊢KB Bϕ. Since X ⊆ Y , it follows that [ϕ] ∩ [w] ⊆ [Y d] ∩ [w]. From this we obtain that w ∩ M ⊢KB ϕ → Y d, since otherwise we could extend (w ∩ M) ∪ {ϕ,¬Y d} to some v ∈ [ϕ] ∩ [¬Y d] ∩ [w], which would contradict [ϕ] ∩ [w] ⊆ [Y d] ∩ [w]. Hence w ∩ M ⊢KB K(ϕ → Y d) by (MN) and so w ∩ M ⊢KB Bϕ → BY d by (KBM). Since w ∩M ⊢KB Bϕ, we have w ∩M ⊢KB BY d. Hence Y ∈ N(w).\nSo M is indeed and epistemic neighborhood model. To complete our overall argument, it suffices to prove the Truth Lemma: for each ϕ ∈ C and w ∈ W , we have ϕ ∈ w iff M, w |=n ϕ. The argument is by induction on the construction of ϕ ∈ C. Boolean cases are straightforward, so we restrict our attention to the modal cases: formulas Bϕ and Kϕ in C. Note that by the definition of C as the Boolean closure of the set S of subformulas of θ, either of Bϕ ∈ C or Kϕ ∈ C implies ϕ ∈ C.\nSuppose Bϕ ∈ w. Then w ∩M ⊢KB Bϕ and hence [ϕ] ∩ [w] ∈ N(w) by the definition of N and the fact that ϕ ∈ C. Applying the induction hypothesis, [ϕ] = JϕKMn , so JϕK M n ∩ [w] ∈ N(w). But this is what it means to have M, w |=n Bϕ. Conversely, assume M, w |=n Bϕ for Bϕ ∈ C. This means JϕKMn ∩ [w] ∈ N(w). By the induction hypothesis and the fact that ϕ ∈ C, we have [ϕ] = JϕKMn , so [ϕ] ∩ [w] ∈ N(w). By the definition of N , there exists ψ ∈ C such that w ∩M ⊢KB Bψ and [ϕ] ∩ [w] = [ψ] ∩ [w]. But then w ∩M ⊢KB ψ → ϕ, for otherwise we could extend (w ∩M) ∪ {ψ,¬ϕ} to some v ∈ [w] such that v ∈ [ψ] ∩ [w] and v /∈ [ϕ] ∩ [w], contradicting [ϕ] ∩ [w] = [ψ] ∩ [w]. Applying (MN), we have w ∩M ⊢KB K(ψ → ϕ) and hence w ∩M ⊢KB Bψ → Bϕ by (KBM). Since w ∩M ⊢KB Bψ, it follows that w ∩M ⊢KB Bϕ. And since w is maxcons in C, we conclude that Bϕ ∈ w.\nNow suppose Kϕ ∈ w. Then for each v ∈ [w], we have that Kϕ ∈ v and therefore ϕ ∈ v by S5 reasoning (using scheme T) and the fact that v is maxcons in C. But then we have shown that [w] ⊆ [ϕ]. Since ϕ ∈ C, it follows by the induction hypothesis that [w] ⊆ JϕKMn , which is what it means to have M, w |=n Kϕ.\nConversely, assume M, w |=n Kϕ for Kϕ ∈ C. It follows that [w] ⊆ JϕKMn . By the induction hypothesis, [w] ⊆ [ϕ]. But then w ∩M ⊢KB ϕ, for otherwise we could extend (w ∩M) ∪ {¬ϕ} to some v ∈ [w] satisfying v /∈ [ϕ], contradicting [w] ⊆ [ϕ]. By (MN), we have w ∩M ⊢KB Kϕ. Since Kϕ ∈ C and w is maxcons in C, it follows that Kϕ ∈ w.\nSince KB is sound and complete with respect to the class of epistemic neighborhood models, we would expect that in light of Theorem 4.7 that KB is at most sound for the probability interpretation.\nTheorem 5.4 (KB Probability Soundness). KB is sound for any threshold c ∈ (0, 1) ∩ Q with respect to the class of epistemic probability models:\n∀c ∈ (0, 1) ∩Q, ∀ϕ ∈ LKB : KB ⊢ ϕ ⇒ |=p ϕc .\nProof. Theorems 3.2 and 3.9.\nTheorem 5.5 (KB Probability Incompleteness). KB is incomplete for all thresholds c ∈ (0, 1)∩Q with respect to the class of epistemic probability models:\n∃ϕ ∈ LKB, ∀c ∈ (0, 1) ∩Q : |=p ϕc and KB 0 ϕ .\nProof. Take M as in the proof of Theorem 4.7. Let σ be the modal formula describing (M, a): informally (and easily formalizable),\nσ := ab̄ · · · ḡ ∧KW ∧ ( ∧ Z∈N(a) BZ) ∧ ( ∧ Z′∈℘(W )−N(a) ¬BZ ′) .\nWe have M, w |=n σ so that 6|=n ¬σ and therefore KB 0 ¬σ by Theorem 5.3. By the proof of Theorem 4.7, there is no probability measure agreeing with M for any threshold. Hence |=p ¬σc. So ϕ := ¬σ gives us the desired formula.\n5.2 Results for the Mid-Threshold Calculus KB.5\nWe first show that the KB schemes (BF) and (KBM) are redundant in the theory KB.5.\nTheorem 5.6. KB.5− and KB.5 derive the same theorems:\n∀ϕ ∈ LKB : KB.5 − ⊢ ϕ ⇔ KB.5 ⊢ ϕ .\nProof. It suffices to prove that the schemes (BF) and (KBM) are derivable in KB.5−. For (KBM), we have by Definition 3.7 that the formula ϕIψ is just\nK ( (¬ϕ ∧ ¬ψ) ∨ (¬ϕ ∧ ψ) ︸ ︷︷ ︸\nF0\n∨ (ϕ ∧ ψ) ︸ ︷︷ ︸\nF1\n) , (21)\nwhere we have explicitly indicated the subformulasF0 and F1 used in the notation of Definition 3.7. Semantically, (21) says that in each of the agent’s accessible worlds, ψ is true whenever ϕ is true. Now reasoning within KB.5−, it follows that K(ϕ → ψ) is provably equivalent to ϕIψ. But then\nfrom K(ϕ → ψ) and Bϕ, we may derive ϕIψ and Bϕ, from which we may derive Bψ by (Scott). Hence (KBM) is derivable.\nWe now consider (BF). The formula ⊥ → ¬⊤ is a classical tautology and hence K(⊥ → ¬⊤) follows by (MN). Hence by an instance of (KBM), which can be defined away in terms of axioms other than (BF) as above, it follows that B⊥ → B¬⊤ and therefore that ¬B¬⊤ → ¬B⊥. Also by (N), (D), and (MP), we may derive ¬B¬⊤. That is, (BF) is derivable.\nTheorem 5.7 (KB.5 Neighborhood Soundness and Completeness). KB.5 is sound and complete with respect to the class C.5 of mid-threshold neighborhood models:\n∀ϕ ∈ LKB : KB.5 ⊢ ϕ ⇔ C .5 |=n ϕ .\nProof. Soundness is by induction on the length of derivation. Most cases are as in the proof of Theorem 5.3. We only need consider the remaining axiom schemes.\n• Scheme (D) is valid: |=n Bϕ → B̌ϕ.\nSuppose M, w |=n Bϕ. This means [w] ∩ JϕKn ∈ N(w). By (d),\n[w] ∩ J¬ψKn = [w]− JϕKn = [w]− ([w] ∩ JϕKn) /∈ N(w) .\nBut this is what it means to have M, w |=n B̌ϕ.\n• Scheme (SC) is valid: |=n B̌ϕ ∧ Ǩ(¬ϕ ∧ ψ) → B(ϕ ∨ ψ).\nSuppose M, w |=n B̌ϕ and M, w |=n Ǩ(¬ϕ ∧ ψ). It follows that\n[w]− ([w] ∩ JϕKn) = [w] ∩ J¬ϕKn /∈ N(w)\nand that there exists v ∈ [w] satisfying M, v |= ¬ϕ∧ψ. But then [w]∩Jϕ ∨ ψKn ) [w]∩JϕKn and therefore [w] ∩ Jϕ ∨ ψKn ∈ N(w) by (sc). Hence M, w |= B(ϕ ∨ ψ).\n• Scheme (Scott) is valid:\n|=n [(ϕiIψi)mi=1 ∧ Bϕ1 ∧ ∧m i=2 B̌ϕi] → ∨m i=1Bψi .\nSuppose (M, w) satisfies the antecedent of scheme (Scott). It follows that each v ∈ [w] satisfies at least as many ϕi’s as ψi’s, that [w]∩ Jψ1Kn ∈ N(w), and that [w]− JϕkKn /∈ N(w) for each k ∈ {2, . . . , m}. Hence\n[w] ∩ Jϕ1Kn, . . . , [w] ∩ JϕmKnI[w] ∩ Jψ1Kn, . . . , [w] ∩ JψmKn ,\nfrom which it follows by (scott) that [w] ∩ JψjKn ∈ N(w) for some j ∈ {1, . . . , m}. Hence M, w |=n Bψj , and thus M, w |=n ∨m i=1Bψi.\nSoundness has been proved. For completeness, it suffices to show that the model M defined as in the proof of Theorem 5.3—except that now derivability is always taken with respect to KB.5—is a mid-threshold neighborhood model; the rest of the argument is as in that proof, mutatis mutandis. Most of the properties of M are shown in that proof. What remains is for us to show that M also satisfies (d), (sc), and (scott).\n(d) X ∈ N(w) implies X ′ /∈ N(w), where X ′ := [w]−X .\nSuppose X ∈ N(w). Then we have ϕ ∈ C such that X = [ϕ] ∩ [w] and w ∩M ⊢KB.5 Bϕ. By (D), it follows that w ∩M ⊢KB.5 B̌ϕ. Choose ψ ∈ C satisfying X ′ = [ψ]∩ [w]. We have w ∩ M ⊢KB.5 ψ → ¬ϕ, since otherwise we could extend (w ∩ M) ∪ {ψ, ϕ} to a v ∈ [w] such that v ∈ [ψ] ∩ [w] = X ′ and v ∈ [ϕ] ∩ [w] = X , contradicting X ′ ∩X = ∅. By (MP), we have w ∩M ⊢KB.5 K(ψ → ¬ϕ) and therefore w ∩M ⊢KB.5 Bψ → B¬ϕ by (KBM). So since B̌ϕ = ¬B¬ϕ, it follows by classical reasoning that w ∩M ⊢KB.5 B̌ϕ → ¬Bψ. Since w ∩ M ⊢KB.5 B̌ϕ, it follows that w ∩ M ⊢KB.5 ¬Bψ. By the consistency of KB.5 (which follows by applying soundness to any mid-threshold epistemic neighborhood model), we have w ∩M 0KB Bψ. So we have shown that w ∩M 0KB.5 Bψ for each ψ ∈ C satisfying X ′ = [ψ] ∩ [w]. Conclusion: X ′ /∈ N(w).\n(sc) If X ′ /∈ N(w) and X ( Y ⊆ [w], then Y ∈ N(w).\nAssume X ′ /∈ N(w) and X ( Y ⊆ [w]. It follows from X ′ /∈ N(w) that we have w ∩ M 0KB.5 B(X ′)d. Since (X ′)d ∈ C0, it follows that B(X ′)d ∈ C = MCl(C0) and therefore ¬B(X ′)d ∈ w ∩ M because w is maxcons in C. Hence w ∩ M ⊢KB.5 ¬B(X ′)d. Now we have w∩M ⊢KB.5 ¬Xd → (X ′)d, for otherwise we could extend (w∩M)∪{¬Xd,¬(X ′)d} to some v ∈ [w] such that v ∈ [¬Xd]∩ [w] = X ′ and v ∈ [¬(X ′)d]∩ [w] = X , contradicting X ′∩X = ∅. By (MP), we have w∩M ⊢KB.5 K(¬Xd → (X ′)d) and therefore w∩M ⊢KB.5 B¬Xd → B(X ′)d by (KBM). Since w∩M ⊢KB.5 ¬B(X ′)d, it follows by classical reasoning that w ∩M ⊢KB.5 ¬B¬Xd. That is, w ∩M ⊢KB.5 B̌Xd.\nFurther, since X ( Y ⊆ [w], it follows that there exists y ∈ Y − X satisfying y ∈ [Y d] − [Xd] = [Y d ∧ ¬Xd]. Since ¬(Y d ∧ ¬Xd) ∈ C0, it follows that ¬K¬(Y d ∧ ¬Xd) ∈ C = MCl(C0). But then K¬(Y d ∧ ¬Xd) /∈ w, for otherwise it would follow from y ∈ [w] that w ∩ M = y ∩ M and hence K¬(Y d ∧ ¬Xd) ∈ y, from which it would follow by T and the fact that y is maxcons in C that ¬(Y d ∧ ¬Xd) ∈ y, contradicting y ∈ [Y d ∧ ¬Xd]. So since K¬(Y d ∧ ¬Xd) /∈ w, we have by the fact that ¬K¬(Y d ∧ ¬Xd) ∈ C and the maximal KB.5-consistency of w that ¬K¬(Y d ∧ ¬Xd) = Ǩ(Y d ∧ ¬Xd) ∈ w. Hence w ∩ M ⊢KB.5 Ǩ(Y d ∧ ¬Xd). As w ∩ M ⊢KB.5 B̌Xd as well, it follows by (SC) that w∩M ⊢KB.5 B(Y d ∨Xd). But [Y d ∨Xd] = Y by our assumption X ( Y and therefore we have shown that Y ∈ N(w).\n(scott) If X1, . . . , Xm, Y1, . . . , Ym ⊆ [w], (XiIYi)mi=1, X1 ∈ N(w), and X ′ i := [w]− Xi /∈ N(w)\nfor all i ∈ {2, . . . , m}, then there exists j ∈ {1, . . . , m} such that Yj ∈ N(w).\nAssume we have the above-stated antecedent of the (scott) property. It follows from X1 ∈ N(w) that w ∩ M ⊢KB.5 BXd1 . For i ∈ {2, . . . , m}, it follows from X ′ i /∈ N(w) by an argument as in the above proof for (sc) that w ∩ M ⊢ B̌Xdi . If we can prove that w ∩ M ⊢KB.5 (Xdi IY d i ) m i=1 as well, then we would have by (Scott) that w ∩M ⊢KB.5 ∨m j=1BY d j . But then since BY dj ∈ C for each j ∈ {1, . . . , m}, we would have BY d k ∈ w for some k ∈ {1, . . . , m} by the maximal KB.5-consistency of w, hence w ∩ M ⊢KB.5 BY dk , and hence Yk = [Y dk ] ∈ N(w).\nSo it suffices for us to prove that w ∩ M ⊢KB.5 (Xdi IY d i ) m i=1. Proceeding, we recall that (Xdi IY d i ) m i=1 abbreviates the formula K(F0 ∨ · · · ∨ Fm), where Fk is the disjunction of all conjunctions d1X d 1 ∧ · · · ∧ dmX d m ∧ e1Y d 1 ∧ · · · ∧ emY d m , (22)\nsatisfying the property that exactly k of the di’s are the empty string, at least k of the ei’s are the empty string, and the rest of the di’s and ei’s are the negation sign ¬. Since each of the Xi’s and Yi’s is a member of C0 and C0 is closed under Boolean operations, each conjunction (22) is a member of C0, and hence so is the disjunction F0 ∨ · · · ∨ Fm. But then K(F0 ∨ · · · ∨ Fm) ∈ C = MCl(C0). We make use of these facts tacitly in what follows. Now we have by our assumption (XiIYi)mi=1 and the fact that the Xi’s and Yi’s are subsets of [w] that every world in [w] is contained in at least as many of the Xi’s as in the Yi’s. Every world in [w] therefore contains at least one of the Fi’s, for otherwise it would follow by maximal KB.5-consistency that we could find a world v ∈ [w] that is not contained in at least as many of the Xi’s as in the Yi’s, a contradiction. By maximal KB.5-consistency, every world in [w] thereby contains the disjunction F0 ∨ · · · ∨ Fm. But then it follows by maximal KB.5-consistency and T-reasoning that K(F0 ∨ · · · ∨ Fm) ∈ w, and hence w ∩M ⊢KB.5 (Xdi IY d i ) m i=1.\nSince KB.5 is sound and complete with respect to mid-threshold neighborhood models, we would expect from Corollary 4.11 that KB.5 is sound and complete with respect to the probability interpretation for threshold c = 1\n2 .\nTheorem 5.8 (Due to [Len80]; KB.5 Probability Soundness and Completeness). KB.5 is sound and complete for threshold 1\n2 with respect to the class of epistemic probability models:\n∀ϕ ∈ LKB : KB.5 ⊢ ϕ ⇔ |=p ϕ 1 2 .\nProof. Soundness is by Theorems 3.2 and 3.9. Completeness is by Theorem 5.7 and Corollary 4.11."
    }, {
      "heading" : "6 Conclusion",
      "text" : "Summary We have provided a study of unary modal logics of high probability. We introduced epistemic neighborhood models and studied their connection to traditional epistemic probability models by way of a natural notion of “agreement.” We listed the Lenzen-derivative properties of epistemic neighborhood models that guarantee the existence of an agreeing probability measure for threshold c = 1\n2 . The list of properties required to guarantee the existence of an agreeing\nprobability measure for other thresholds is unknown. We also presented our study from a proof theoretic point of view by introducing a probabilistically sound but incomplete logic KB and our version of Lenzen’s probabilistically sound and complete logic KB.5 for threshold c = 1\n2 . It is\nopen as to the principles one must add to KB in order to obtain probabilistic completeness for other thresholds. We also proved soundness and completeness of KB and of KB.5 with respect to a corresponding class of epistemic neighborhood models. The result for KB.5 along with our\nTheorem 4.10, a theorem we credit to Lenzen, shows thatKB.5 is the logic of probabilistic certainty and of probability exceeding c = 1\n2 . It is our hope that our repackaging of Professor Lenzen’s result\nwill make his work more accessible to a broad audience of modern modal logicians. We also hope that the connection we have made with neighborhood semantics will prove useful in future work on modal logics of qualitative probability.\nOpen Questions for Future Work\n1. The main open question is the following: given a “high-threshold” c ∈ (1 2 , 1) ∩ Q, find the\nexact extension KBc of KB that is probabilistically sound and complete for threshold c with respect to the class of epistemic probability models, in the sense that we would have:\n∀ϕ ∈ LKB : KB c ⊢ ϕ ⇔ |=p ϕc .\nObserving that (SC) and (Scott) are not valid for high-thresholds c > 1 2 , we conjecture that what is required are threshold-specific variants of (SC) and (Scott) that will together guarantee probability soundness and completeness. Toward this end, we suggest the following schemes as a starting point:\n(SCs0) (Ǩϕ0 ∧ ∧s i=1 B̌ϕi ∧ ∧s i 6=j=0K(ϕi → ¬ϕj)) → B( ∨s i=0 ϕi) (SCs1) ( ∧s i=1 B̌ϕi ∧ ∧s i 6=j=1K(ϕi → ¬ϕj)) → B( ∨s i=1 ϕi) (WS) [(ϕiIψi)mi=1 ∧ ∧m i=1Bϕi] → ∨m i=1Bψi\nObserve that (SC) is just (SC10). Further, if we define s ′ := c/(1 − c) and s := ceiling(s′), then scheme (SCs0) is probabilistically sound if s = s ′ and scheme (SCs1) is probabilistically sound if s 6= s′. The reasoning for this is as follows: s′ tells us the number of (1 − c)’s that divide c. In particular, recall from Lemma 3.5 that the probabilistic interpretation of B̌ϕ is that ϕ is assigned probability at least 1 − c. Therefore, if we have s disjoint propositions that each have probability at least 1 − c, then the probability of their disjunction will have probability s ·(1−c) ≥ c. This inequality is strict if s 6= s′ and is in fact an equality if s = s′. Therefore, in the case s 6= s′, scheme (SCs1) is sound: s disjoint propositions each having probability 1− c together sum to a probability exceeding the threshold c. And in case s = s′, scheme (SCs0) is sound: s disjoint propositions each having probability 1 − c together sum to a probability that equals c, so adding some additional probability from another disjoint proposition ϕ0 will yield a disjunction whose probability again exceeds c. In either case, exceeding probability c is what we equate with belief, so soundness is proved. We note that scheme (WS) can be shown to be sound by adapting the proof Theorem 3.9(11). The epistemic neighborhood model versions of (SCs0), (SC s 1), and (WS) are:\n(scs0) ∀X1, . . . , Xs, Y ⊆ [w]: if [w] − X1, . . . , [w] − Xs /∈ N(w), the Xi’s are pairwise disjoint, and Y )\n⋃s i=1Xi, then Y ∈ N(w).\n(scs1) ∀X1, . . . , Xs ⊆ [w]: if [w] − X1, . . . , [w] − Xs /∈ N(w) and the Xi’s are pairwise disjoint, then\n⋃s i=1Xi ∈ N(w).\n(ws) ∀m ∈ Z+, ∀X1, . . . , Xm, Y1, . . . , Ym ⊆ [w] :\nif X1, . . . , XmIY1, . . . , Ym and\n∀i ∈ {1, . . . , m} : Xi ∈ N(w) ,\nthen ∃j ∈ {1, . . . , m} : Yj ∈ N(w) .\nIf M is an epistemic neighborhood model, then a slight modification of the proof of property (scott) in Lemma 4.13 shows that M c satisfies (ws). We presume that an adaptation of the proof for the proof of property (sc) in the same lemma will show that M c satisfies (scs0) if s = s′ and (scs1) if s 6= s ′.\nWe remark that (WS) is not threshold-specific, though it is sound for all high-thresholds c > 1 2 . We suspect that a threshold-specific variant may be required in order to adapt Lenzen’s proof of KB.5 probability soundness and completeness for threshold c = 1 2 (Theorem 4.10).\n2. Another open question is the exact relationship between Segerberg’s comparitive operator ϕ ψ (“ϕ is no more probable than ψ”) [Gär75, Seg71] and our unary operators K and B. The formula Bϕ is equivalent to ¬ϕ ≺ ϕ. However, it is not clear how the logics of these operators are related. Also, we suspect that a language with is strictly more expressive.\n3. Yet another direction is the extension of our work to Bayesian updating. Given a pointed epistemic probability model (M, w) satisfying ϕ, let\nM[ϕ] = (W [ϕ], R[ϕ], V [ϕ], P [ϕ])\nbe defined by\nW [ϕ] := JϕKMp R[ϕ] := R ∩ (W [ϕ]×W [ϕ])\nV [ϕ](w) := V (w) for w ∈ W [ϕ]\nP [ϕ](w) := P (w)\nP (JϕKMp )\nIt is not difficult to see that M[ϕ] is an epistemic probability model and\nP [ϕ](X) = P (X ∩ JϕKMp )\nP (JϕKMp ) = P [ϕ](X|JϕKMp ) ,\nwhere the value on the right is the probability of X conditional on JϕKMp . It would be interesting to investigate the analog of this operation in epistemic neighborhood models. The operation may also have a close relationship with the study of updates in Probabilistic Dynamic Epistemic Logic [vBGK09, BS08].\n4. Finally, we have only considered a single-agent version of our logics KB and KB.5. The reason for this is that obtaining completeness for KB.5 with respect to the class of finite mid-threshold neighborhood models requires us to construct a finite countermodel satisfying (sc), as we did in the completeness portion of the proof of Theorem 5.7. However, this property has an antecedent that includes the negative condition X ′ /∈ N(w) and from this and X ( Y ⊆ [w], we are to conclude the positive condition Y ∈ N(w). Referring the reader to the completeness portions of the proofs of Theorems 5.3 and 5.7 for definitions and terminology, the trick to making things work in the single-agent case is to prove the Definability Lemma using a particular closure construction that ensures every potential neighborhood X ⊆ [w] is definable by a formula Xd such that BXd is a member of the closure set C. This makes crucial use of the In-class Identity Lemma. However, our proof of this lemma depends on the assumption that maxcons sets u, v ∈ [w] differ only in non-modal formulas. In the straightforward multi-agent version of our setting, we would have an equivalence class [w]a consisting of all maxcons sets that agree on modal formulas Kaϕ and Baψ for a given agent a. But then two worlds u, v ∈ [w]a could disagree on modal formulas Kbϕ or Bbψ for some agent b 6= a, which leads to a breakdown in the current proof of the In-class Identity Lemma and therefore presents problems for guaranteeing definability of potential neighborhoods satisfying the desired membership property. Remedying this in a multi-agent version of a finite mid-threshold neighborhood model is not straightforward because it is difficult to simultaneously satisfy (sc), all other properties of finite mid-threshold neighborhood models, and the definability-with-membership property. We therefore leave for future work the matter of proving completeness of multi-agent KB.5 with respect to the class of finite multi-agent mid-threshold neighborhood models. We note that multi-agent KB.5 is obtained from our existing axiomatization by simply adding a subscript to all occurrences of a modal operator K or B in our present axiomatization. Multi-agent KB is obtained similarly, though completeness for multi-agent KB with respect to the full class of finite multi-agent epistemic neighborhood models can be shown without much difficulty because the problematic property (sc) need not be satisfied.\nAcknowledgements Thanks to Alexandru Baltag, Johan van Benthem, Jim Delgrande, Peter van Emde Boas, Andreas Herzig, Thomas Icard, Sonja Smets, and Rineke Verbrugge for helpful comments and pointers to the literature."
    } ],
    "references" : [ {
      "title" : "Modal Logic. Cambridge Tracts in Theoretical Computer Science",
      "author" : [ "P. Blackburn", "M. de Rijke", "Y. Venema" ],
      "venue" : null,
      "citeRegEx" : "Blackburn et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Blackburn et al\\.",
      "year" : 2001
    }, {
      "title" : "Probabilistic dynamic belief",
      "author" : [ "Alexandru Baltag", "Sonja Smets" ],
      "venue" : "revision. Synthese,",
      "citeRegEx" : "Baltag and Smets.,? \\Q2008\\E",
      "shortCiteRegEx" : "Baltag and Smets.",
      "year" : 2008
    }, {
      "title" : "Modal Logic: An Introduction",
      "author" : [ "B.F. Chellas" ],
      "venue" : null,
      "citeRegEx" : "Chellas.,? \\Q1980\\E",
      "shortCiteRegEx" : "Chellas.",
      "year" : 1980
    }, {
      "title" : "La prévision: ses lois logiques, ses sources subjectives",
      "author" : [ "Bruno de Finetti" ],
      "venue" : "Annals de l’Institut Henri Poincaré,",
      "citeRegEx" : "Finetti.,? \\Q1937\\E",
      "shortCiteRegEx" : "Finetti.",
      "year" : 1937
    }, {
      "title" : "La “logica del plausibile” secondo la concezione di polya",
      "author" : [ "Bruno de Finetti" ],
      "venue" : "In Atti della XLII Riunione, Societa Italiana per il Progresso delle Scienze,",
      "citeRegEx" : "Finetti.,? \\Q1951\\E",
      "shortCiteRegEx" : "Finetti.",
      "year" : 1951
    }, {
      "title" : "Learning about probability. available from http://homepages.cwi.nl: /jve/software/prodemo",
      "author" : [ "Jan van Eijck" ],
      "venue" : null,
      "citeRegEx" : "Eijck.,? \\Q2013\\E",
      "shortCiteRegEx" : "Eijck.",
      "year" : 2013
    }, {
      "title" : "Epistemic probability logic simplified",
      "author" : [ "Jan van Eijck", "Frano̧is Schwarzentruber" ],
      "venue" : "Advances in Modal Logic,",
      "citeRegEx" : "Eijck and Schwarzentruber.,? \\Q2014\\E",
      "shortCiteRegEx" : "Eijck and Schwarzentruber.",
      "year" : 2014
    }, {
      "title" : "Qualitative probability as an intensional logic",
      "author" : [ "Peter Gärdenfors" ],
      "venue" : "Journal of Philosophical Logic,",
      "citeRegEx" : "Gärdenfors.,? \\Q1975\\E",
      "shortCiteRegEx" : "Gärdenfors.",
      "year" : 1975
    }, {
      "title" : "Reasoning About Uncertainty",
      "author" : [ "J. Halpern" ],
      "venue" : null,
      "citeRegEx" : "Halpern.,? \\Q2003\\E",
      "shortCiteRegEx" : "Halpern.",
      "year" : 2003
    }, {
      "title" : "Modal probability, belief, and actions",
      "author" : [ "A. Herzig" ],
      "venue" : "Fundamenta Informaticae,",
      "citeRegEx" : "Herzig.,? \\Q2003\\E",
      "shortCiteRegEx" : "Herzig.",
      "year" : 2003
    }, {
      "title" : "Measure semantics and qualitative semantics for epistemic modals",
      "author" : [ "Wesley H. Holliday", "Thomas F. Icard" ],
      "venue" : "In Proceedings of SALT,",
      "citeRegEx" : "Holliday and Icard.,? \\Q2013\\E",
      "shortCiteRegEx" : "Holliday and Icard.",
      "year" : 2013
    }, {
      "title" : "Subjective Probability — The Real Thing",
      "author" : [ "Richard Jeffrey" ],
      "venue" : null,
      "citeRegEx" : "Jeffrey.,? \\Q2004\\E",
      "shortCiteRegEx" : "Jeffrey.",
      "year" : 2004
    }, {
      "title" : "Naive Decision Making: Mathematics Applied to the Social World",
      "author" : [ "T.W. Körner" ],
      "venue" : null,
      "citeRegEx" : "Körner.,? \\Q2008\\E",
      "shortCiteRegEx" : "Körner.",
      "year" : 2008
    }, {
      "title" : "Intuitive probability on finite sets",
      "author" : [ "Charles H. Kraft", "John W. Pratt", "A. Seidenberg" ],
      "venue" : "The Annals of Mathematical Statistics,",
      "citeRegEx" : "Kraft et al\\.,? \\Q1959\\E",
      "shortCiteRegEx" : "Kraft et al\\.",
      "year" : 1959
    }, {
      "title" : "The logic of risky knowledge, reprised",
      "author" : [ "Henry E. Kyburg", "Choh Man Teng" ],
      "venue" : "International Journal of Approximate Reasoning,",
      "citeRegEx" : "Kyburg and Teng.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kyburg and Teng.",
      "year" : 2012
    }, {
      "title" : "Probability and the Logic of Rational Belief",
      "author" : [ "H.E. Kyburg" ],
      "venue" : null,
      "citeRegEx" : "Kyburg.,? \\Q1961\\E",
      "shortCiteRegEx" : "Kyburg.",
      "year" : 1961
    }, {
      "title" : "Glauben, Wissen und Wahrscheinlichkeit — Systene der epistemischen Logik",
      "author" : [ "Wolfgang Lenzen" ],
      "venue" : null,
      "citeRegEx" : "Lenzen.,? \\Q1980\\E",
      "shortCiteRegEx" : "Lenzen.",
      "year" : 1980
    }, {
      "title" : "Knowledge, belief, and subjective probability — outlines of a unified theory of epistemic/doxastic logic",
      "author" : [ "Wolfgang Lenzen" ],
      "venue" : "Knowledge Contributors,",
      "citeRegEx" : "Lenzen.,? \\Q2003\\E",
      "shortCiteRegEx" : "Lenzen.",
      "year" : 2003
    }, {
      "title" : "Measurement structures and linear equalities",
      "author" : [ "Dana Scott" ],
      "venue" : "Journal of Mathematical Psychology,",
      "citeRegEx" : "Scott.,? \\Q1964\\E",
      "shortCiteRegEx" : "Scott.",
      "year" : 1964
    }, {
      "title" : "Qualitative probability in a modal setting",
      "author" : [ "K. Segerberg" ],
      "venue" : "Proceedings of the 2nd Scandinavian Logic Symposium,",
      "citeRegEx" : "Segerberg.,? \\Q1971\\E",
      "shortCiteRegEx" : "Segerberg.",
      "year" : 1971
    }, {
      "title" : "Dynamic update with probabilities",
      "author" : [ "Johan van Benthem", "Jelle Gerbrandy", "Barteld Kooi" ],
      "venue" : "Studia Logica,",
      "citeRegEx" : "Benthem et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Benthem et al\\.",
      "year" : 2009
    }, {
      "title" : "Varieties of modal (classificatory) and comparative",
      "author" : [ "P. Walley", "T.L. Fine" ],
      "venue" : "probability. Synthese,",
      "citeRegEx" : "Walley and Fine.,? \\Q1979\\E",
      "shortCiteRegEx" : "Walley and Fine.",
      "year" : 1979
    } ],
    "referenceMentions" : [ ],
    "year" : 2014,
    "abstractText" : "We investigate modal logics of high probability having two unary modal operators: an operator K expressing probabilistic certainty and an operator B expressing probability exceeding a fixed rational threshold c ≥ 1 2 . Identifying knowledge with the former and belief with the latter, we may think of c as the agent’s betting threshold, which leads to the motto “belief is willingness to bet.” The logic KB.5 for c = 12 has an S5 K modality along with a sub-normal B modality that extends the minimal modal logic EMND45 by way of four schemes relating K and B, one of which is a complex scheme arising out of a theorem due to Scott. Lenzen was the first to use Scott’s theorem to show that a version of this logic is sound and complete for the probability interpretation. We reformulate Lenzen’s results and present them here in a modern and accessible form. In addition, we introduce a new epistemic neighborhood semantics that will be more familiar to modern modal logicians. Using Scott’s theorem, we provide the Lenzen-derivative properties that must be imposed on finite epistemic neighborhood models so as to guarantee the existence of a probability measure respecting the neighborhood function in the appropriate way for threshold c = 12 . This yields a link between probabilistic and modal neighborhood semantics that we hope will be of use in future work on modal logics of qualitative probability. We leave open the question of which properties must be imposed on finite epistemic neighborhood models so as to guarantee existence of an appropriate probability measure for thresholds c 6= 12 .",
    "creator" : "LaTeX with hyperref package"
  }
}