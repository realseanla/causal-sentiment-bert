{
  "name" : "1605.07246.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Adaptive ADMM with Spectral Penalty Parameter Selection",
    "authors" : [ "Zheng Xu", "Mário A. T. Figueiredo", "Thomas Goldstein" ],
    "emails" : [ "1xuzh@cs.umd.edu,", "tomg@cs.umd.edu,", "2mario.figueiredo@tecnico.ulisboa.pt" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The alternating direction method of multipliers (ADMM) is an invaluable element of the modern optimization toolbox. ADMM decomposes complex optimization problems into sequences of simpler subproblems, often solvable in closed form; its simplicity, flexibility, and broad applicability, made ADMM a state-of-the-art solver in machine learning, signal processing, and many other areas [2].\nIt is well known that the efficiency of ADMM hinges on the careful selection of a penalty parameter, which is often manually tuned by users for their particular problem instances. For gradient descent and proximal-gradient methods, adaptive (i.e. automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].\nIn this paper, we propose to automate and speed up ADMM by using stepsize selection rules imported from the gradient descent literature, namely the Barzilai-Borwein “spectral” method for smooth unconstrained problems [1, 7]. Since ADMM handles multi-term objectives and linear constraints, it is not immediately obvious how to adopt such rules. The key to our approach is to analyze the dual of the ADMM problem, which can be written without constraints. To ensure reliability of the method, we develop a correlation criterion that safeguards it against inaccurate stepsize choices. The resulting adaptive ADMM (AADMM) is fully automated and fairly insensitive to the initial stepsize."
    }, {
      "heading" : "2 Background and Related Work",
      "text" : ""
    }, {
      "heading" : "2.1 Alternating Direction Method of Multipliers",
      "text" : "ADMM dates back to the 1970s [8, 10]. Its convergence was shown in the 1990s [4], and convergence rates have been the topic of much recent work (see [11, 14, 18] and references therein). In the last decade, ADMM became one of the tools of choice to handle a wide variety of optimization problems in machine learning, signal processing, and many other areas (for a comprehensive review, see [2]).\nADMM tackles problems in the form\nmin u∈Rn,v∈Rm H(u) +G(v), subject to Au+Bv = b, (1)\nar X\niv :1\n60 5.\n07 24\n6v 1\n[ cs\n.L G\n] 2\n4 M\nay 2\nwhere H : Rn → R̄ and G : Rm → R̄ are closed, proper, convex functions, A ∈ Rp×n, B ∈ Rp×m, and b ∈ Rp. With λ∈Rp denoting the dual variables (Lagrange multipliers), ADMM has the form\nuk+1 = arg min u H(u) + 〈λk,−Au〉+ τk 2 ‖b−Au−Bvk‖22 (2)\nvk+1 = arg min v G(v) + 〈λk,−Bv〉+ τk 2 ‖b−Auk+1 −Bv‖22 (3)\nλk+1 =λk + τk(b−Auk+1 −Bvk+1), (4) where the sequence of penalties τk is the only free choice, and has a high impact on the algorithm’s performance. Our goal is to automate this choice, by adaptively tuning τk for optimal performance.\nThe convergence of the algorithm can be monitored using primal and dual “residuals,” both of which approach zero as the iterates become more accurate, and which are defined as\nrk = b−Auk −Bvk, and dk = τkATB(vk − vk−1), (5) respectively [2]. The iteration is generally stopped when ‖rk‖2 ≤ tol max{‖Auk‖2, ‖Bvk‖2, ‖b‖2} and ‖dk‖2 ≤ tol‖ATλk‖2, where tol > 0 is the stopping tolerance (e.g., tol ≈ 10−3 )."
    }, {
      "heading" : "2.2 Parameter tuning and adaptation",
      "text" : "Relatively little work has been done on automating ADMM, i.e., on adaptively choosing τk. In the specific case where the objective is a strictly convex quadratic function, criteria for choosing an optimal constant penalty have been recently proposed [9, 19].\nResidual balancing (RB [2, 15]) is the only available adaptive method for general form problems (1). RB is based on the following observation: increasing τk strengthens the penalty term, resulting in smaller primal residuals but larger dual ones; conversely, decreasing τk leads to larger primal and smaller dual residuals. Since both residuals must be small at convergence, it makes sense to “balance” them, i.e., to tune τk to keep both residuals of similar magnitude. A simple scheme for this goal is\nτk+1 =  ητk if ‖dk‖2 > µ‖rk‖2 τk/η if ‖rk‖2 > µ‖dk‖2 τk otherwise,\n(6)\nfor parameters µ > 1 and η > 1 [2]. RB has recently been adapted to distributed optimization [22] and other primal-dual splitting methods [13]. ADMM with adaptive penalty is not guaranteed to converge, although convergence can be enforced by fixing τk = τ after a finite number of iterations [15].\nThe RB idea suffers from a fundamental flaw. The relative size of the residuals depends on the (arbitrary) scaling of the problem; for example, with the change of variable u ← 10u, problem (1) can be re-scaled so that ADMM produces an equivalent sequence of iterates with residuals of very different magnitudes. Consequently, RB criteria are arbitrary for some problems, and their performance varies wildly with different problem scalings (see Section 4.4). Furthermore, the penalty parameter may adapt slowly if the initial value is far from optimal. Finally, without a careful choice of η and µ, the penalty parameters may oscillate and the algorithm fails to converge before τk is fixed."
    }, {
      "heading" : "2.3 Dual interpretation of ADMM",
      "text" : "We now explain the close relationship between ADMM and Douglas-Rachdord Splitting (DRS) [4, 6, 11], which plays a central role in the proposed approach. The starting observation is that the dual of problem (1) has the form\nmin ζ∈Rp H∗(AT ζ)− 〈ζ, b〉︸ ︷︷ ︸ Ĥ(ζ) +G∗(BT ζ)︸ ︷︷ ︸ Ĝ(ζ) ; (7)\nwith F ∗ denoting the Fenchel conjugate of F , defined as F ∗(y) = supx〈x, y〉 − F (x) [20].\nThe DRS algorithm solves (7) by generating two sequences (ζk)k∈N and (ζ̂k)k∈N according to\n0 ∈ ζ̂k+1 − ζk τk + ∂Ĥ(ζ̂k+1) + ∂Ĝ(ζk) (8) 0 ∈ ζk+1 − ζk τk + ∂Ĥ(ζ̂k+1) + ∂Ĝ(ζk+1), (9)\nwhere we use the standard notation ∂F (x) for the subdifferential of F evaluated at x [20].\nReferring back to ADMM in (2)–(4), and defining λ̂k+1 = λk+τk(b−Auk+1−Bvk), the optimality condition for the minimization of (2) is\n0 ∈ ∂H(uk+1)−ATλk − τkAT (b−Auk+1 −Bvk) = ∂H(uk+1)−AT λ̂k+1, (10)\nwhich is equivalent to AT λ̂k+1 ∈ ∂H(uk+1), thus1 uk+1 ∈ ∂H∗(AT λ̂k+1). A similar argument using the optimality condition for (3) leads to vk+1 ∈ ∂G∗(BTλk+1). Recalling (7), we arrive at\nAuk+1 − b ∈ ∂Ĥ(λ̂k+1) and Bvk+1 ∈ ∂Ĝ(λk+1). (11) Using these identities, we finally have\nλ̂k+1 = λk + τk(b−Auk+1 −Bvk) ∈ λk − τk ( ∂Ĥ(λ̂k+1) + ∂Ĝ(λk) ) (12)\nλk+1 = λk + τk(b−Auk+1 −Bvk+1) ∈ λk − τk ( ∂Ĥ(λ̂k+1) + ∂Ĝ(λk+1) ) , (13)\nshowing that the sequences (λk)k∈N and (λ̂k)k∈N satisfy the same conditions (8) and (9) as (ζk)k∈N and (ζ̂k)k∈N, thus proving that ADMM for problem (1) is equivalent to DRS for its dual (7)."
    }, {
      "heading" : "2.4 Spectral (Barzilai-Borwein) stepsize selection",
      "text" : "The classical gradient descent step for unconstrained minimization of a smooth function F: Rn→ R has the form xk+1 = xk−τk∇F (xk). Spectral gradient methods, pioneered by Barzilai and Borwein (BB) [1], adaptively choose the stepsize τk to achieve fast convergence. In a nutshell, the standard (there are variants) BB method sets τk = 1/αk, with αk chosen such that αkI mimics the Hessian of F over the last step, seeking a quasi-Newton step. Using a least squares criterion yields\nαk = argmin α∈R ‖∇F (xk)−∇F (xk−1)− α(xk − xk−1)‖22, (14)\nwhich is an estimate of the curvature of F across the previous step of the algorithm. Spectral gradient methods dramatically outperform schemas with constant stepsize in many applications [7, 24] and have been generalized to handle non-differentiable problems via proximal gradient methods [23, 12]. Finally, notice that (14) is equivalent to modeling the gradient∇F (xk) as a linear function of xk,\n∇F (xk) ≈ ∇F (xk−1) + αk(xk − xk−1) = αk xk + ak, (15) where ak = ∇F (xk−1)− αk xk−1∈ Rn. The observation that a local linear approximation of the gradient has an optimal parameter equal to the inverse of the BB stepsize will play an important role below."
    }, {
      "heading" : "3 Spectral penalty parameters",
      "text" : "Inspired by the BB method [1], we propose a spectral penalty parameter selection method for ADMM. We first derive a spectral stepsize rule for DRS, and then adapt this rule to ADMM. Finally, we discuss safeguarding methods to prevent unexpected behavior when curvature estimates are inaccurate."
    }, {
      "heading" : "3.1 Spectral stepsize for Douglas-Rachford splitting",
      "text" : "Considering the dual problem (7), and following the observation in (15) about the BB method, we model/approximate ∂Ĥ(ζ̂) and ∂Ĝ(ζ) at iteration k as linear functions of their arguments,\n∂Ĥ(ζ̂) = αk ζ̂ + Ψk and ∂Ĝ(ζ) = βk ζ + Φk, (16)\nwhere αk > 0, βk > 0 are local curvature estimates of Ĥ and Ĝ, respectively, and Ψk,Φk ⊂ Rp. Once we obtain these curvature estimates, we will be able to exploit the following proposition. Proposition 1 (Spectral DRS). Suppose the DRS steps (8)–(9) are applied to problem (7), where (omitting the subscript k from αk, βk,Ψk,Φk to lighten the notation in what follows)\n∂Ĥ(ζ̂) = α ζ̂ + Ψ and ∂Ĝ(ζ) = β ζ + Φ.\nThen, the minimal residual of Ĥ(ζk+1) + Ĝ(ζk+1) is obtained by setting τk = 1/ √ αβ.\n1An important property relating F and F ∗ is that y ∈ ∂H(x) if and only if x ∈ ∂H∗(y) [20].\nProof. Inserting (16) into the DRS step (8)–(9), we have\n0 ∈ ζ̂k+1 − ζk τ + (α ζ̂k+1 + Ψ) + (β ζk + Φ) (17) 0 ∈ ζk+1 − ζk τ + (α ζ̂k+1 + Ψ) + (β ζk+1 + Φ). (18)\nFrom (17)–(18), we can explicitly get the update for ζ̂k+1 as\nζ̂k+1 = 1− β τ 1 + α τ ζk − aτ + bτ 1 + α τ , (19)\nwhere a ∈ Ψ and b ∈ Φ, and for ζk+1 as\nζk+1 = 1\n1 + β τ ζk −\nα τ\n1 + β τ ζ̂k+1 −\na τ + bτ 1 + β τ = (1 + αβ τ2)ζk − (a+ b)τ (1 + α τ)(1 + β τ) , (20)\nwhere the second equality results from using the expression for ζ̂k+1 from (19).\nThe residual rDR at ζk+1 is simply the magnitude of the subgradient (corresponding to elements a ∈ Ψ and b ∈ Φ) of the objective that is given by\nrDR = ‖(α+ β)ζk+1 + (a+ b)‖ = 1 + αβ τ2\n(1 + α τ)(1 + β τ) ‖(α+ β)ζk + (a+ b)‖, (21)\nwhere ζk+1 in (21) was substituted with (20). The optimal stepsize τk minimizes the residual\nτk = arg min τ rDR = arg max τ\n(1 + α τ)(1 + β τ)\n1 + αβ τ2 = arg max τ\n(α+ β)τ 1 + αβτ2 = 1/\n√ αβ.\nFinally (recovering the iteration subscript k), notice that τk = (α̂k β̂k)1/2, where α̂k = 1/αk and β̂k = 1/βk are the spectral gradient descent stepsizes for Ĥ and Ĝ, at ζ̂k and ζk, respectively."
    }, {
      "heading" : "3.2 Spectral stepsize estimation",
      "text" : "Proposition 1 shows how to adaptively choose the penalty parameters. We can begin by obtaining linear estimates of the subgradients of the terms in the dual objective (7). The geometric mean of the optimal gradient descent stepsizes for those two terms is then the optimal DRS stepsize, and also the optimal penalty parameter for ADMM, thanks to the equivalence presented in Subsection 2.3.\nWe now address the question of how to estimate α̂k = α−1k and β̂k = β −1 k for the components Ĝ(λ̂k) and Ĥ(λk) at the k-th iteration. The curvature parameters are estimated based on the results from iteration k and an older iteration k0 < k . Noting the identities (11), we define\n∆λ̂k := λ̂k − λ̂k0 and ∆Ĥk := ∂Ĥ(λ̂k)− ∂Ĥ(λ̂k0) = A(uk − uk0). (22)\nAssuming, as above, a linear model for ∂Ĥ , we expect ∆Ĥk ≈ α∆λ̂k + a. As is typical in the spectral stepsize literature [24], the curvature of Ĥ(λ) is estimated via one of the two least squares problems\nmin α ‖∆Ĥk − α∆λ̂k‖22 or min α ‖α−1∆Ĥk −∆λ̂k‖22. (23)\nThe closed form solutions for the corresponding spectral stepsizes α̂k = 1/αk are, respectively,\nα̂SDk = 〈∆λ̂k,∆λ̂k〉 〈∆Ĥk,∆λ̂k〉\nand α̂MGk = 〈∆Ĥk,∆λ̂k〉 〈∆Ĥk,∆Ĥk〉 , (24)\nwhere (following [24]) SD stands for steepest descent stepsize, and MG for minimum gradient stepsize. The Cauchy-Schwarz inequality can be used to show that α̂SDk ≥ α̂MGk . Rather than choosing one or the other, we suggest the hybrid stepsize rule proposed in [12, 24], defined as\nα̂k =\n{ α̂MGk if 2 α̂ MG k > α̂ SD k\nα̂SDk − α̂MGk /2 otherwise. (25)\nThe spectral stepsize β̂k = 1/βk of Ĝ(λk) is similarly estimated as,\nβ̂k =\n{ β̂MGk if 2 β̂ MG k > β̂ SD k\nβ̂SDk − β̂MGk /2 otherwise, (26)\nwhere β̂SDk = 〈∆λk,∆λk〉/〈∆Ĝk,∆λk〉, β̂MGk = 〈∆Ĝk,∆λk〉/〈∆Ĝk,∆Ĝk〉, ∆Ĝk = B(vk−vk0), and ∆λk = λk − λk0 . It is important to note that α̂k and β̂k are obtained from the iterates of ADMM alone, i.e., our scheme does not require the user to supply the dual problem."
    }, {
      "heading" : "3.3 Safeguarding: testing the quality of stepsize estimates",
      "text" : "On some iterations, the linear models for one or both subgradients that underly the spectral stepsize choice may be very inaccurate. When this occurs, the least squares procedure may produce ineffective stepsize values. The classical BB method for unconstrained problems uses a line search to safeguard against unstable stepsizes when curvature estimates are unreliable. For ADMM, however, there is no notion of “stable” stepsize (any constant stepsizes is stable), thus line search methods are not applicable. Rather, we propose to safeguard the method by assessing the quality of the curvature estimates, and only updating the stepsize if the curvature estimates satisfy a reliability criterion.\nThe linear model (16) assumes the change in dual gradient is linearly proportional to the change in the dual variables. To test the validity of this assumption, we measure the correlation between these quantities (equivalently, the cosine of their angle):\nαcorrk = 〈∆Ĥk,∆λ̂k〉 ‖∆Ĥk‖‖∆λ̂k‖\nand βcorrk = 〈∆Ĝk,∆λk〉 ‖∆Ĝk‖‖∆λk‖ . (27)\nThe correlations indicate whether the linear assumptions (16) are suitable to estimate the gradients, thus the spectral stepsizes α̂k and β̂k are utilized only if the correlations indicate the estimation is credible enough. Finally, the safeguarded spectral adaptive penalty parameter rule is\nτk+1 =  √ α̂kβ̂k if αcorrk > corr and βcorrk > corr α̂k if αcorrk > corr and βcorrk ≤ corr\nβ̂k if αcorrk ≤ corr and βcorrk > corr τk otherwise,\n(28)\nwhere corr is a quality threshold for the curvature estimates, while α̂k and β̂k are the spectral stepsizes given by (25) and (26). The proposed method falls back to constant penalty parameter when both curvature estimates are deemed inaccurate."
    }, {
      "heading" : "3.4 Adaptive ADMM with spectral penalty parameter",
      "text" : "The complete adaptive ADMM (AADMM) is shown in Algorithm 1. We suggest only updating the stepsize every Tf iterations. The overhead of the proposed adaptivity scheme is modest, requiring only a few inner products, plus the storage needed to hold one previous iterate. As noted in [15], convergence is guaranteed if the adaptivity is turned off after a finite number of iterations; however, we have found this to be unnecessary in practice."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Experimental setting",
      "text" : "We consider several applications to demonstrate the effectiveness of the proposed AADMM. We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2]. We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].\nFor comparison, we implemented vanilla ADMM, fast ADMM with a restart strategy [11], and ADMM with residual balancing [2, 15], using µ = 10 and η = 2 in (6), and turned off after 1000\nAlgorithm 1 Adaptive ADMM (AADMM) with spectral penalty parameter selection Input: initialize v0, λ0, τ0, k0 = 0, corr = 0.2, update frequency Tf = 2\n1: for k = 0, 1, 2, . . . ,maxiter do 2: uk+1 ← arg minuH(u) + 〈λk,−Au〉+ τk2 ‖b−Au−Bvk‖ 2 3: vk+1 ← arg minv G(v) + 〈λk,−Bv〉+ τk2 ‖b−Auk+1 −Bv‖ 2 4: λk+1 ← λk + τk(b−Auk+1 −Bvk+1) 5: if mod(k, Tf ) = 1 then 6: λ̂k+1 = λk + τk(b−Auk+1 −Bvk) 7: Compute spectral stepsizes α̂k, β̂k using (25) and (26) 8: Estimate correlations αcorrk , β corr k , as given in (27)\n9: Update τk+1 using (28) 10: k0 ← k 11: else 12: τk+1 ← τk 13: end if 14: end for\niterations to guarantee convergence. The proposed AADMM is implemented as shown in Algorithm 1, with fixed parameters corr = 0.2 and Tf = 2.\nWe set the stopping tolerance to tol = 10−5, 10−3, and 0.05 for small, medium, and large scale problems, respectively. The initial penalty τ0 = 1/10 is used for all problems except the general QP problem, where τ0 is set to the value proposed for quadratic problems in [19]."
    }, {
      "heading" : "4.2 Applications",
      "text" : "Linear regression with elastic net (EN) regularization. EN is a modification of the `1 (or LASSO) regularizer that helps preserving groups of highly correlated variables [11, 25], and requires solving\nmin x\n1 2 ‖Dx− c‖22 + ρ1‖x‖1 + ρ2 2 ‖x‖22, (29)\nwhere ‖ · ‖1 denotes the `1 norm, D is a data matrix, c contains measurements, and x is the regression coefficients. One way to apply ADMM to this problem is to rewrite it as\nmin u,v\n1 2 ‖Du− c‖22 + ρ1‖v‖1 + ρ2 2 ‖v‖22 subject to u− v = 0. (30)\nThe synthetic dataset introduced in [11, 25] and realistic dataset introduced in [5, 25] are investigated. Typical parameters ρ1 = ρ2 = 1 are used in all experiments.\nSupport vector machine (SVM) and QP. The dual of the SVM learning problem is a QP\nmin z\n1 2 zTQz − eT z subject to cT z = 0 and 0 ≤ z ≤ C, (31)\nwhere z is the SVM dual variable, Q is the kernel matrix, c is a vector of labels, e is a vector of ones, and C > 0 [3]. We also consider the canonical QP\nmin x\n1 2 xTQx+ qTx subject to Dx ≤ c, (32)\nwhich could be solved by applying ADMM to\nmin u,v\n1 2 uTQu+ qTu+ ι{z: zi≤c}(v) subject to Du− v = 0; (33)\nhere, ιS is the characteristic function of set S: ιS(v) = 0, if v ∈ S, and ιS(v) =∞, otherwise. We study classification problems from [16, 21] with C = 1 and a random synthetic QP from [11], where Q ∈ R500×500 with condition number approximately 4.5× 105. Basis pursuit (BP) and sparse representation. BP solves the constrained minimization problem\nmin x ‖x‖1 subject to Dx = c, (34)\nwhere D ∈ Rm×n, c ∈ Rm,m < n. An extended form with D̂ = [D, I] ∈ Rm×(n+m) has been used to reconstruct occluded and corrupted faces [23]. To apply ADMM, problem (34) is rewritten as\nmin u,v\nι{z:Dz=c}(u) + ‖v‖1 subject to u− v = 0. (35)\nWe experiment with synthetic random D ∈ R10×30. We also use a data matrix for face reconstruction from the Extended Yale B Face dataset [23], where each frontal face image is scaled to 32× 32. For each human subject, an image is selected and corrupted with 5% noisy pixels, and the remaining images from the same subject are used to reconstruct the corrupted image.\nConsensus `1-regularized logistic regression. ADMM has become an important tool for solving distributed problems [2]. Here, we consider the consensus `1-regularized logistic regression\nmin xi,z N∑ i=1 ni∑ j=1 log(1 + exp(−cjDjxi)) + ρ‖z‖1 subject to xi − z = 0, i = 1, . . . , N, (36)\nwhere xi ∈ Rm represents the local variable on the ith distributed node, z is the global variable, ni is the number of samples in the ith block, Dj ∈ Rm is the jth sample, and cj ∈ {−1, 1} is the corresponding label. The synthetic problem is constructed with Gaussian random data and sparse ground truth solutions. Binary classification problems from [16, 17, 21] are also used to test the effectiveness of the proposed method. We use ρ = 1, for small and medium datasets, and ρ = 5 for the large datasets to encourage sparsity. We split the data equally into two blocks and use a loop to simulate the distributed computing of consensus subproblems."
    }, {
      "heading" : "4.3 Convergence results",
      "text" : "Table 1 reports the convergence speed of ADMM and its variants for the applications described in Subsection 4.2. Vanilla ADMM with fixed stepsize does poorly in practice: in 9 out of 17 realistic datasets, it fails to converge in the maximum number of iterations 2. Fast ADMM [11] often outperforms vanilla ADMM, but does not compete with the proposed AADMM, which also outperforms residual balancing in all test cases except in the Rcv1 problem for consensus logistic regression."
    }, {
      "heading" : "4.4 Sensitivity to initial stepsize and problem scaling",
      "text" : "Finally, we study the sensitivity of the different ADMM variants to the initial penalty parameter (τ0) choice and problem scaling. Fig. 1 presents iteration counts for a wide range of values of τ0, for elastic net regression (left) and general QP (right) with synthetic datasets. Scaling sensitivity experiments were done by multiplying the measurement vector c in elastic net and QP by a scalar s . Fast ADMM and vanilla ADMM use the fixed initial penalty parameter τ0, and are highly sensitivity to this choice, as shown in Fig. 1; in contrast, AADMM is stable with respect to the initial τ0 and the problem scale s."
    }, {
      "heading" : "5 Conclusion",
      "text" : "We have proposed adaptive ADMM (AADMM), a new variant of the very popular ADMM algorithm that tackles one of its fundamental drawbacks: critical dependence on a penalty parameter that needs careful tuning. This drawback has made ADMM difficult to use by non-experts, thus AADMM has the potential to contribute to wider and easier applicability of this highly flexible and efficient optimization tool. Our approach imports and adapts the Barzilai-Borwein “spectral” stepsize method from the smooth optimization literature, tailoring it to the more general class of problems handled by ADMM. The cornerstone of our approach is the fact that ADMM is equivalent to Douglas-Rachford splitting (DRS) applied to the dual problem, for which we develop a spectral stepsize selection rule; this rule is then translated into a criterion to select the penalty parameter of ADMM. A safeguarding function that avoids unreliable stepsize choices finally yields AADMM. Experiments on a wide range of problems and datasets have shown that AADMM outperforms other variants of ADMM. AADMM was also shown to be robust with respect to initial parameter choice and problem scaling."
    } ],
    "references" : [ {
      "title" : "Two-point step size gradient methods",
      "author" : [ "J. Barzilai", "J. Borwein" ],
      "venue" : "IMA J. Num. Analysis,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1988
    }, {
      "title" : "Distributed optimization and statistical learning via the alternating direction method of multipliers",
      "author" : [ "S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein" ],
      "venue" : "Found. and Trends in Mach. Learning,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2011
    }, {
      "title" : "LIBSVM: a library for support vector machines",
      "author" : [ "C.-C. Chang", "C.-J. Lin" ],
      "venue" : "ACM Transactions on Intelligent Systems and Technology (TIST),",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "On the Douglas-Rachford splitting method and the proximal point algorithm for maximal monotone operators",
      "author" : [ "J. Eckstein", "D. Bertsekas" ],
      "venue" : "Mathematical Programming,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1992
    }, {
      "title" : "Least angle regression",
      "author" : [ "B. Efron", "T. Hastie", "I. Johnstone", "R. Tibshirani" ],
      "venue" : "The Annals of statistics,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2004
    }, {
      "title" : "Applications of Lagrangian-based alternating direction methods and connections to split Bregman",
      "author" : [ "E. Esser" ],
      "venue" : "CAM report,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2009
    }, {
      "title" : "On the Barzilai-Borwein method. In Optimization and control with applications, pages 235–256",
      "author" : [ "R. Fletcher" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2005
    }, {
      "title" : "A dual algorithm for the solution of nonlinear variational problems via finite element approximation",
      "author" : [ "D. Gabay", "B. Mercier" ],
      "venue" : "Computers & Mathematics with Applications,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1976
    }, {
      "title" : "Optimal parameter selection for the alternating direction method of multipliers: quadratic problems",
      "author" : [ "E. Ghadimi", "A. Teixeira", "I. Shames", "M. Johansson" ],
      "venue" : "IEEE Trans. Autom. Control,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2015
    }, {
      "title" : "Sur l’approximation, par éléments finis d’ordre un, et la résolution, par pénalisation-dualité d’une classe de problémes de Dirichlet non linéaires",
      "author" : [ "R. Glowinski", "A. Marroco" ],
      "venue" : "ESAIM: Modélisation Mathématique et Analyse Numérique,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1975
    }, {
      "title" : "Fast alternating direction optimization methods",
      "author" : [ "T. Goldstein", "B. O’Donoghue", "S. Setzer", "R. Baraniuk" ],
      "venue" : "SIAM Journal on Imaging Sciences,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2014
    }, {
      "title" : "A field guide to forward-backward splitting with a FASTA implementation",
      "author" : [ "T. Goldstein", "C. Studer", "R. Baraniuk" ],
      "venue" : "arXiv preprint arXiv:1411.3406,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2014
    }, {
      "title" : "Adaptive primal-dual splitting methods for statistical learning and image processing",
      "author" : [ "T. Goldstein", "M. Li", "X. Yuan" ],
      "venue" : "In Advances in Neural Information Processing Systems,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2015
    }, {
      "title" : "On non-ergodic convergence rate of Douglas-Rachford alternating direction method of multipliers",
      "author" : [ "B. He", "X. Yuan" ],
      "venue" : "Numerische Mathematik,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2015
    }, {
      "title" : "Alternating direction method with self-adaptive penalty parameters for monotone variational inequalities",
      "author" : [ "B. He", "H. Yang", "S. Wang" ],
      "venue" : "Jour. Optim. Theory and Appl.,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2000
    }, {
      "title" : "Efficient L1 regularized logistic regression",
      "author" : [ "S.-I. Lee", "H. Lee", "P. Abbeel", "A. Ng" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2006
    }, {
      "title" : "Large-scale sparse logistic regression",
      "author" : [ "J. Liu", "J. Chen", "J. Ye" ],
      "venue" : "In ACM SIGKDD,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2009
    }, {
      "title" : "A general analysis of the convergence of ADMM",
      "author" : [ "R. Nishihara", "L. Lessard", "B. Recht", "A. Packard", "M. Jordan" ],
      "venue" : "In ICML,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2015
    }, {
      "title" : "Alternating direction method of multipliers for strictly convex quadratic programs: Optimal parameter selection",
      "author" : [ "A. Raghunathan", "S. Di Cairano" ],
      "venue" : "In American Control Conf.,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2014
    }, {
      "title" : "Convex Analysis",
      "author" : [ "R. Rockafellar" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1970
    }, {
      "title" : "Fast optimization methods for l1 regularization: A comparative study and two new approaches",
      "author" : [ "M. Schmidt", "G. Fung", "R. Rosales" ],
      "venue" : "In ECML,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2007
    }, {
      "title" : "Fast ADMM algorithm for distributed optimization with adaptive penalty",
      "author" : [ "C. Song", "S. Yoon", "V. Pavlovic" ],
      "venue" : "arXiv preprint arXiv:1506.08928,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2015
    }, {
      "title" : "Sparse reconstruction by separable approximation",
      "author" : [ "S. Wright", "R. Nowak", "M. Figueiredo" ],
      "venue" : "IEEE Trans. Signal Processing,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2009
    }, {
      "title" : "Gradient methods with adaptive step-sizes",
      "author" : [ "B. Zhou", "L. Gao", "Y.-H. Dai" ],
      "venue" : "Computational Optimization and Applications,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2006
    }, {
      "title" : "Regularization and variable selection via the elastic net",
      "author" : [ "H. Zou", "T. Hastie" ],
      "venue" : "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "ADMM decomposes complex optimization problems into sequences of simpler subproblems, often solvable in closed form; its simplicity, flexibility, and broad applicability, made ADMM a state-of-the-art solver in machine learning, signal processing, and many other areas [2].",
      "startOffset" : 267,
      "endOffset" : 270
    }, {
      "referenceID" : 0,
      "context" : "automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].",
      "startOffset" : 138,
      "endOffset" : 156
    }, {
      "referenceID" : 6,
      "context" : "automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].",
      "startOffset" : 138,
      "endOffset" : 156
    }, {
      "referenceID" : 11,
      "context" : "automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].",
      "startOffset" : 138,
      "endOffset" : 156
    }, {
      "referenceID" : 22,
      "context" : "automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].",
      "startOffset" : 138,
      "endOffset" : 156
    }, {
      "referenceID" : 23,
      "context" : "automated) stepsize selection rules have been proposed, which essentially dispense with user oversight and dramatically boost performance [1, 7, 12, 23, 24].",
      "startOffset" : 138,
      "endOffset" : 156
    }, {
      "referenceID" : 0,
      "context" : "In this paper, we propose to automate and speed up ADMM by using stepsize selection rules imported from the gradient descent literature, namely the Barzilai-Borwein “spectral” method for smooth unconstrained problems [1, 7].",
      "startOffset" : 217,
      "endOffset" : 223
    }, {
      "referenceID" : 6,
      "context" : "In this paper, we propose to automate and speed up ADMM by using stepsize selection rules imported from the gradient descent literature, namely the Barzilai-Borwein “spectral” method for smooth unconstrained problems [1, 7].",
      "startOffset" : 217,
      "endOffset" : 223
    }, {
      "referenceID" : 7,
      "context" : "ADMM dates back to the 1970s [8, 10].",
      "startOffset" : 29,
      "endOffset" : 36
    }, {
      "referenceID" : 9,
      "context" : "ADMM dates back to the 1970s [8, 10].",
      "startOffset" : 29,
      "endOffset" : 36
    }, {
      "referenceID" : 3,
      "context" : "Its convergence was shown in the 1990s [4], and convergence rates have been the topic of much recent work (see [11, 14, 18] and references therein).",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 10,
      "context" : "Its convergence was shown in the 1990s [4], and convergence rates have been the topic of much recent work (see [11, 14, 18] and references therein).",
      "startOffset" : 111,
      "endOffset" : 123
    }, {
      "referenceID" : 13,
      "context" : "Its convergence was shown in the 1990s [4], and convergence rates have been the topic of much recent work (see [11, 14, 18] and references therein).",
      "startOffset" : 111,
      "endOffset" : 123
    }, {
      "referenceID" : 17,
      "context" : "Its convergence was shown in the 1990s [4], and convergence rates have been the topic of much recent work (see [11, 14, 18] and references therein).",
      "startOffset" : 111,
      "endOffset" : 123
    }, {
      "referenceID" : 1,
      "context" : "In the last decade, ADMM became one of the tools of choice to handle a wide variety of optimization problems in machine learning, signal processing, and many other areas (for a comprehensive review, see [2]).",
      "startOffset" : 203,
      "endOffset" : 206
    }, {
      "referenceID" : 1,
      "context" : "The convergence of the algorithm can be monitored using primal and dual “residuals,” both of which approach zero as the iterates become more accurate, and which are defined as rk = b−Auk −Bvk, and dk = τkAB(vk − vk−1), (5) respectively [2].",
      "startOffset" : 236,
      "endOffset" : 239
    }, {
      "referenceID" : 8,
      "context" : "In the specific case where the objective is a strictly convex quadratic function, criteria for choosing an optimal constant penalty have been recently proposed [9, 19].",
      "startOffset" : 160,
      "endOffset" : 167
    }, {
      "referenceID" : 18,
      "context" : "In the specific case where the objective is a strictly convex quadratic function, criteria for choosing an optimal constant penalty have been recently proposed [9, 19].",
      "startOffset" : 160,
      "endOffset" : 167
    }, {
      "referenceID" : 1,
      "context" : "Residual balancing (RB [2, 15]) is the only available adaptive method for general form problems (1).",
      "startOffset" : 23,
      "endOffset" : 30
    }, {
      "referenceID" : 14,
      "context" : "Residual balancing (RB [2, 15]) is the only available adaptive method for general form problems (1).",
      "startOffset" : 23,
      "endOffset" : 30
    }, {
      "referenceID" : 1,
      "context" : "for parameters μ > 1 and η > 1 [2].",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 21,
      "context" : "RB has recently been adapted to distributed optimization [22] and other primal-dual splitting methods [13].",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 12,
      "context" : "RB has recently been adapted to distributed optimization [22] and other primal-dual splitting methods [13].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 14,
      "context" : "ADMM with adaptive penalty is not guaranteed to converge, although convergence can be enforced by fixing τk = τ after a finite number of iterations [15].",
      "startOffset" : 148,
      "endOffset" : 152
    }, {
      "referenceID" : 3,
      "context" : "We now explain the close relationship between ADMM and Douglas-Rachdord Splitting (DRS) [4, 6, 11], which plays a central role in the proposed approach.",
      "startOffset" : 88,
      "endOffset" : 98
    }, {
      "referenceID" : 5,
      "context" : "We now explain the close relationship between ADMM and Douglas-Rachdord Splitting (DRS) [4, 6, 11], which plays a central role in the proposed approach.",
      "startOffset" : 88,
      "endOffset" : 98
    }, {
      "referenceID" : 10,
      "context" : "We now explain the close relationship between ADMM and Douglas-Rachdord Splitting (DRS) [4, 6, 11], which plays a central role in the proposed approach.",
      "startOffset" : 88,
      "endOffset" : 98
    }, {
      "referenceID" : 19,
      "context" : "with F ∗ denoting the Fenchel conjugate of F , defined as F ∗(y) = supx〈x, y〉 − F (x) [20].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 19,
      "context" : "where we use the standard notation ∂F (x) for the subdifferential of F evaluated at x [20].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 0,
      "context" : "Spectral gradient methods, pioneered by Barzilai and Borwein (BB) [1], adaptively choose the stepsize τk to achieve fast convergence.",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 6,
      "context" : "Spectral gradient methods dramatically outperform schemas with constant stepsize in many applications [7, 24] and have been generalized to handle non-differentiable problems via proximal gradient methods [23, 12].",
      "startOffset" : 102,
      "endOffset" : 109
    }, {
      "referenceID" : 23,
      "context" : "Spectral gradient methods dramatically outperform schemas with constant stepsize in many applications [7, 24] and have been generalized to handle non-differentiable problems via proximal gradient methods [23, 12].",
      "startOffset" : 102,
      "endOffset" : 109
    }, {
      "referenceID" : 22,
      "context" : "Spectral gradient methods dramatically outperform schemas with constant stepsize in many applications [7, 24] and have been generalized to handle non-differentiable problems via proximal gradient methods [23, 12].",
      "startOffset" : 204,
      "endOffset" : 212
    }, {
      "referenceID" : 11,
      "context" : "Spectral gradient methods dramatically outperform schemas with constant stepsize in many applications [7, 24] and have been generalized to handle non-differentiable problems via proximal gradient methods [23, 12].",
      "startOffset" : 204,
      "endOffset" : 212
    }, {
      "referenceID" : 0,
      "context" : "Inspired by the BB method [1], we propose a spectral penalty parameter selection method for ADMM.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 19,
      "context" : "An important property relating F and F ∗ is that y ∈ ∂H(x) if and only if x ∈ ∂H∗(y) [20].",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 23,
      "context" : "As is typical in the spectral stepsize literature [24], the curvature of Ĥ(λ) is estimated via one of the two least squares problems",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 23,
      "context" : "where (following [24]) SD stands for steepest descent stepsize, and MG for minimum gradient stepsize.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 11,
      "context" : "Rather than choosing one or the other, we suggest the hybrid stepsize rule proposed in [12, 24], defined as",
      "startOffset" : 87,
      "endOffset" : 95
    }, {
      "referenceID" : 23,
      "context" : "Rather than choosing one or the other, we suggest the hybrid stepsize rule proposed in [12, 24], defined as",
      "startOffset" : 87,
      "endOffset" : 95
    }, {
      "referenceID" : 14,
      "context" : "As noted in [15], convergence is guaranteed if the adaptivity is turned off after a finite number of iterations; however, we have found this to be unnecessary in practice.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 10,
      "context" : "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 1,
      "context" : "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].",
      "startOffset" : 157,
      "endOffset" : 171
    }, {
      "referenceID" : 8,
      "context" : "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].",
      "startOffset" : 157,
      "endOffset" : 171
    }, {
      "referenceID" : 10,
      "context" : "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].",
      "startOffset" : 157,
      "endOffset" : 171
    }, {
      "referenceID" : 18,
      "context" : "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].",
      "startOffset" : 157,
      "endOffset" : 171
    }, {
      "referenceID" : 1,
      "context" : "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].",
      "startOffset" : 187,
      "endOffset" : 194
    }, {
      "referenceID" : 10,
      "context" : "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].",
      "startOffset" : 187,
      "endOffset" : 194
    }, {
      "referenceID" : 1,
      "context" : "We focus on statistical problems involving non-differentiable objectives: linear regression with elastic net regularization [11], quadratic programming (QP) [2, 9, 11, 19], basis pursuit [2, 11], and consensus `1-regularized logistic regression [2].",
      "startOffset" : 245,
      "endOffset" : 248
    }, {
      "referenceID" : 4,
      "context" : "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].",
      "startOffset" : 108,
      "endOffset" : 131
    }, {
      "referenceID" : 15,
      "context" : "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].",
      "startOffset" : 108,
      "endOffset" : 131
    }, {
      "referenceID" : 16,
      "context" : "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].",
      "startOffset" : 108,
      "endOffset" : 131
    }, {
      "referenceID" : 20,
      "context" : "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].",
      "startOffset" : 108,
      "endOffset" : 131
    }, {
      "referenceID" : 22,
      "context" : "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].",
      "startOffset" : 108,
      "endOffset" : 131
    }, {
      "referenceID" : 24,
      "context" : "We use both synthetic and benchmark datasets (obtained from the UCI repository and the LIBSVM page) used in [5, 16, 17, 21, 23, 25].",
      "startOffset" : 108,
      "endOffset" : 131
    }, {
      "referenceID" : 10,
      "context" : "For comparison, we implemented vanilla ADMM, fast ADMM with a restart strategy [11], and ADMM with residual balancing [2, 15], using μ = 10 and η = 2 in (6), and turned off after 1000",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 1,
      "context" : "For comparison, we implemented vanilla ADMM, fast ADMM with a restart strategy [11], and ADMM with residual balancing [2, 15], using μ = 10 and η = 2 in (6), and turned off after 1000",
      "startOffset" : 118,
      "endOffset" : 125
    }, {
      "referenceID" : 14,
      "context" : "For comparison, we implemented vanilla ADMM, fast ADMM with a restart strategy [11], and ADMM with residual balancing [2, 15], using μ = 10 and η = 2 in (6), and turned off after 1000",
      "startOffset" : 118,
      "endOffset" : 125
    }, {
      "referenceID" : 18,
      "context" : "The initial penalty τ0 = 1/10 is used for all problems except the general QP problem, where τ0 is set to the value proposed for quadratic problems in [19].",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 10,
      "context" : "EN is a modification of the `1 (or LASSO) regularizer that helps preserving groups of highly correlated variables [11, 25], and requires solving",
      "startOffset" : 114,
      "endOffset" : 122
    }, {
      "referenceID" : 24,
      "context" : "EN is a modification of the `1 (or LASSO) regularizer that helps preserving groups of highly correlated variables [11, 25], and requires solving",
      "startOffset" : 114,
      "endOffset" : 122
    }, {
      "referenceID" : 10,
      "context" : "The synthetic dataset introduced in [11, 25] and realistic dataset introduced in [5, 25] are investigated.",
      "startOffset" : 36,
      "endOffset" : 44
    }, {
      "referenceID" : 24,
      "context" : "The synthetic dataset introduced in [11, 25] and realistic dataset introduced in [5, 25] are investigated.",
      "startOffset" : 36,
      "endOffset" : 44
    }, {
      "referenceID" : 4,
      "context" : "The synthetic dataset introduced in [11, 25] and realistic dataset introduced in [5, 25] are investigated.",
      "startOffset" : 81,
      "endOffset" : 88
    }, {
      "referenceID" : 24,
      "context" : "The synthetic dataset introduced in [11, 25] and realistic dataset introduced in [5, 25] are investigated.",
      "startOffset" : 81,
      "endOffset" : 88
    }, {
      "referenceID" : 2,
      "context" : "where z is the SVM dual variable, Q is the kernel matrix, c is a vector of labels, e is a vector of ones, and C > 0 [3].",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 15,
      "context" : "We study classification problems from [16, 21] with C = 1 and a random synthetic QP from [11], where Q ∈ R500×500 with condition number approximately 4.",
      "startOffset" : 38,
      "endOffset" : 46
    }, {
      "referenceID" : 20,
      "context" : "We study classification problems from [16, 21] with C = 1 and a random synthetic QP from [11], where Q ∈ R500×500 with condition number approximately 4.",
      "startOffset" : 38,
      "endOffset" : 46
    }, {
      "referenceID" : 10,
      "context" : "We study classification problems from [16, 21] with C = 1 and a random synthetic QP from [11], where Q ∈ R500×500 with condition number approximately 4.",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 22,
      "context" : "An extended form with D̂ = [D, I] ∈ Rm×(n+m) has been used to reconstruct occluded and corrupted faces [23].",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 22,
      "context" : "We also use a data matrix for face reconstruction from the Extended Yale B Face dataset [23], where each frontal face image is scaled to 32× 32.",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 1,
      "context" : "ADMM has become an important tool for solving distributed problems [2].",
      "startOffset" : 67,
      "endOffset" : 70
    }, {
      "referenceID" : 15,
      "context" : "Binary classification problems from [16, 17, 21] are also used to test the effectiveness of the proposed method.",
      "startOffset" : 36,
      "endOffset" : 48
    }, {
      "referenceID" : 16,
      "context" : "Binary classification problems from [16, 17, 21] are also used to test the effectiveness of the proposed method.",
      "startOffset" : 36,
      "endOffset" : 48
    }, {
      "referenceID" : 20,
      "context" : "Binary classification problems from [16, 17, 21] are also used to test the effectiveness of the proposed method.",
      "startOffset" : 36,
      "endOffset" : 48
    }, {
      "referenceID" : 10,
      "context" : "Fast ADMM [11] often outperforms vanilla ADMM, but does not compete with the proposed AADMM, which also outperforms residual balancing in all test cases except in the Rcv1 problem for consensus logistic regression.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 10,
      "context" : "Application Dataset #samples × #features 3 Vanilla ADMM Fast ADMM [11] Residual balance [15] Adaptive ADMM",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 14,
      "context" : "Application Dataset #samples × #features 3 Vanilla ADMM Fast ADMM [11] Residual balance [15] Adaptive ADMM",
      "startOffset" : 88,
      "endOffset" : 92
    } ],
    "year" : 2017,
    "abstractText" : "The alternating direction method of multipliers (ADMM) is a versatile tool for solving a wide range of constrained optimization problems, with differentiable or non-differentiable objective functions. Unfortunately, its performance is highly sensitive to a penalty parameter, which makes ADMM often unreliable and hard to automate for a non-expert user. We tackle this weakness of ADMM by proposing a method to adaptively tune the penalty parameters to achieve fast convergence. The resulting adaptive ADMM (AADMM) algorithm, inspired by the successful Barzilai-Borwein spectral method for gradient descent, yields fast convergence and relative insensitivity to the initial stepsize and problem scaling.",
    "creator" : "LaTeX with hyperref package"
  }
}