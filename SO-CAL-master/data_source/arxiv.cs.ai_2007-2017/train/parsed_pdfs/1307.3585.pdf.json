{
  "name" : "1307.3585.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Éric Grégoire", "Jean-Marie Lagniez" ],
    "emails" : [ "gregoire@cril.fr", "lagniez@cril.fr", "mazure@cril.fr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n30 7.\n35 85\nv1 [\ncs .A\nI] 1\n2 Ju"
    }, {
      "heading" : "1 Introduction",
      "text" : "In this paper, the focus is on unsatisfiable constraint networks. More precisely, a new approach for extracting minimal cores (or, MUCs for Minimally Unsatisfiable Cores) of constraint networks is proposed. A MUC is a minimal (w.r.t. ⊆) set of constraints that cannot be satisfied all together. When causes of unsatisfiability must be understood and the network must be re-engineered and relaxed to become satisfiable, extracting MUCs can be a cornerstone issue since a MUC provides one explanation for unsatisfiability in terms of a minimal set of incompatible constraints. Despite bad worst-case computational complexity results, various approaches for extracting one MUC have been proposed that appear tractable for many instances [8,2,21,20,18,19,17,15,14].\nA MUC of a network can also be defined as an unsatisfiable sub-network formed of transition constraints, which are constraints that would allow this sub-network to become satisfiable if any of them were removed. Powerful approaches to MUC extraction are founded on transition constraints, both in the CSP [17,14] and the SAT [23,12,13,33,23,28,4] domains. In this last area, a recent approach [32,5] focuses on the following intuition. An assignment of values to the variables that satisfies all constraints except one is called a transition assignment and the unsatisfied constraint is a transition constraint: additional transition constraints might be discovered by so-called\nmodel rotation, i.e., by examining other assignments differing from the transition assignment on the value of one variable, only.\nIn the paper, an approach both extending and enhancing this latter technique is proposed in the constraint network framework. The main idea is to use local search for exploring the neighborhood of transition assignments in an attempt to find out other transition constraints. The technique is put in work in a so-called dichotomy destructive strategy à la DC(WCORE) [17] to extract one MUC. Extensive computational experimentations show that this approach outperforms both the model rotation technique from [5] and the performance of state-of-the-art MUC extractors.\nThe paper is organized as follows. In the next section, basic concepts, definitions and notations are provided. Section 3 focuses on existing techniques for MUC extraction, including DC(WCORE)-like ones, and then on model rotation. In section 4, a local search procedure for exhibiting additional transition constraints is presented and motivated, whereas section 5 describes the full algorithm for MUC extraction. Section 6 describes our experimental investigations and results before some promising paths for further research are presented in the conclusion."
    }, {
      "heading" : "2 Definitions and Notations",
      "text" : "Constraint networks are defined as follows.\nDefinition 1 (Constraint network). A constraint network (CN) is a pair 〈X , C〉, where\n1. X is a finite set of variables s.t. each variable x ∈ X has an associated finite instantiation domain, denoted dom(x);\n2. C is a finite set of constraints s.t. each constraint c ∈ C involves a subset of variables of X , called scope and denoted scp(c). c translates an associated relation that contains all the values for the variables of scp(c) that satisfy c.\nA constraint network where the scope of all constraints is binary can be represented by a non-oriented graph where each variable is a node and each constraint is an edge.\nExample 1. Let X = {i, j, k, l,m}where each variable has the same domain {0, 1, 2, 3, 4} and let C = {c1 : m > i, c2 : m = l + 2, c3 : j > l, c4 : i < j, c5 : k < i, c6 : j < k, c7 : c 6= l} be a set of 7 constraints. The constraint network P = 〈X , C〉 can be represented by the graph of Fig. 1(a).\nDefinition 2 (Assignment and solution). An assignment A of a constraint network"
    }, {
      "heading" : "P = 〈X , C〉 is an assignment of values to all variables of X . A solution to P is any assignment that satisfies all constraints of C.",
      "text" : "A form of Constraint Satisfaction Problem (CSP) consists in checking whether a constraint network P admits at least one solution. This decision problem is an NPcomplete problem. If P admits at least one solution then P is called satisfiable else P is called unsatisfiable. The constraint network of Example 1 is unsatisfiable. When a constraint network is unsatisfiable, it admits at least one Minimal (w.r.t.⊆) Unsatisfiable Core (in short, MUC).\nDefinition 3 (Core and MUC). Let P = 〈X , C〉 be a constraint network. P ′ = 〈X ′, C′〉 is an unsatisfiable core, in short a core, of P iff\n– P ′ is an unsatisfiable constraint network, and – X ′ ⊆ X and C′ ⊆ C.\nP ′ is a Minimal Unsatisfiable Core (MUC) of P iff\n– P ′ is a core of P , and – there does not exist any proper core of P ′: ∀c ∈ C′, 〈X ′, C′ \\ {c}〉 is satisfiable.\nExample 1. (cont’d)P is unsatisfiable and admits only one MUC, illustrated in Fig. 1(b). Whenever P is unsatisfiable, P exhibits at least one MUC. In the worst case, there can be a number of different MUCs that is exponential in the number m of constraints of P (actually it is in O(Cm/2m )). Note that different MUCs of a same network can share constraints. Accordingly, all MUCs need not be extracted in a step-by-step relaxation process to make the network become satisfiable. Especially, such an iterative process where at each step one MUC is extracted and relaxed so that it becomes satisfiable, at most O(m) MUCs need to be extracted.\nExample 2. Fig. 2 depicts an unsatisfiable constraint network with three MUCs, namely {c1, c2, c3}, {c3, c4, c5} and {c1, c2, c4, c5}. In this example, each variable is given the same domain {1, 2}.\nExtracting one MUC from an unsatisfiable constraint network is a heavy computational task in the worst case. Indeed, checking whether a constraint network is a MUC is DP-complete [27]. Despite the aforementioned bad worst-case computational complexity property, various families of approaches that run in acceptable time for many instances have been proposed. We describe representatives of some of the main ones in the next section."
    }, {
      "heading" : "3 MUC Extraction",
      "text" : "Most recent approaches for extracting one MUC from an unsatisfiable constraint network P start by computing one core (which does not need to be minimal) of P . This step can be optional because an unsatisfiable constraint network is already a core. During this step some information can however be collected that will help guiding the further minimization step. In this paper, we focus on this minimization step and make use of the WCORE core extractor introduced in [17] as a preprocessing step, that we briefly describe hereafter."
    }, {
      "heading" : "3.1 WCORE as a pre-processing step",
      "text" : "When the unsatisfiability of a constraint network P is proved thanks to a filtering search algorithm, WCORE [17] delivers a core of P that is formed of all the constraints that have been involved in the proof of unsatisfiability, namely all the constraints that have been used during the search to remove by propagation at least one value from the domain of any variable. Such constraints are called active. Therefore, when P is shown unsatisfiable, active constraints form a core since the other constraints do not actually take part to this proof of inconsistency. The approach from [17] iterates this process until no smaller set of active constraints is found. Consequently, at the end of this first step, constraints that are not active can be removed safely while keeping a remaining constraint network that is unsatisfiable.\nClearly, the resulting core can depend on the order according to which the partial assignments are investigated, which is guided by some branching heuristic. WCORE takes advantage of the powerful dom/wdeg heuristic [16] (see also variants in e.g. [14]), which consists in attaching to each constraint a counter initialized to 1 and that is incremented each time the corresponding constraint is involved in a conflict. In this respect, dom/wdeg selects the variable with the smallest ratio between the current domain size and a weighted degree, which is defined as the sum of the counters of the constraints in which the variable is involved. This heuristic allows to focus on constraints that appear difficult to satisfy. The goal is not only to attempt to ease the search for inconsistency but also to record some indication that these constraints are probably prone to belong to a MUC. Accordingly, it is proposed in [17] to weigh the constraints via the dom/deg\nheuristic and use the WCORE approach as a preprocessing step for MUC extraction to attempt to reduce the size of the core. Likewise, our approach reuses this weighing information in the subsequent steps of the algorithm to compute one MUC."
    }, {
      "heading" : "3.2 Minimization step",
      "text" : "Once a core has been extracted from a constraint network, it must be minimized so that if forms one MUC. To this end, it might be necessary to check whether a constraint belongs or not to the set of MUCs included within a core, which is a task in Σp\n2 [9]. In\npractice, this step is often based on the identification of forms of transition constraints.\nDefinition 4 (Transition constraint). Let P = 〈X , C〉 an unsatisfiable constraint network. c ∈ C is a transition constraint of P iff there exists an assignment A of P such that A is a model of 〈X , C \\ {c}〉.\nExample 1 (cont’d) Consider again Fig. 1(a). c4 is a transition constraint. Indeed P is unsatisfiable and A = {i = 2, j = 0, k = 1, l = 2,m = 4} is a solution of 〈X , C \\ {c4}〉.\nThe following property is straightforward and directly follows from the definition of transition constraints.\nProperty 1. If c is a transition constraint of a core P then c belongs to any MUC of P .\nClearly, all MUCs of a core do not necessarily share a non-empty intersection and a constraint network might thus have no transition constraints. Actually, the process of finding out transition constraints is performed with respect to some subparts of the network adopting e.g. either so-called destructive or constructive approaches [8,2,20,18,17,14]. For example, the constructive approaches (as in [8]) successively insert constraints taken from the core into a set of constraints until this latter set becomes unsatisfiable. At the opposite, destructive approaches [2] successively remove constraints from the initial core until the current network becomes satisfiable. Constraints are ordered and each time a transition constraint is discovered, it is placed at the beginning of the core according to this order. All constraints are tested according to the inverse order. It is also possible to use a dichotomy strategy in order to find out transition constraints [17]. Variants and combinations of these techniques can be traced back to e.g. QuickXplain [19,24] and the combined approach [14].\nClearly, the order according to which the constraints are tested is critical for the efficiency of each approach. This order can be set according to the weighs of constraints computed during the WCORE step. In the rest of the paper, we focus on a dichotomy destructive approach, which will be presented in more detail later on. Before that, let us briefly present a method that has been recently proposed in the SAT research community to find more than one transition constraint at each main iteration of a MUC extraction algorithm (in the SAT domain, a MUC is called a MUS for Minimal Unsatisfiable Subformula).\nAlgorithm 1: Recursive-MR (MR stands for Model Rotation) Input: P = 〈X ,C〉: an unsatisfiable CN,\nCMUC : a set of constraints belonging to every MUC of P , A: a transition assignment of P\nOutput: expanded CMUC c ← the only constraint falsified by A; /* transition constraint */1 CMUC ← CMUC ∪ {c};2 foreach x ∈ scp(c) do3 foreach v ∈ dom(x) do4 A′ ← A where the variable x is assigned to v;5 if A′ is a transition assignment of P then6 Let c′ be the transition constraint associated to A′ w.r.t. P ;7 if c′ /∈ CMUC then CMUC ← Recursive-MR(P , CMUC , A′);8\nreturn CMUC ;9"
    }, {
      "heading" : "3.3 Recursive Model Rotation",
      "text" : "The model rotation approach (MR) has been introduced in [31]. It is based on the transition assignment concept.\nDefinition 5 (Transition assignment). Let P = 〈X , C〉 be a core. An assignment A of P is a transition assignment of P iff A falsifies only one constraint in P .\nProperty 2. Let P = 〈X , C〉 be a core and c ∈ P . c is a transition constraint of P iff there exists an transition assignment of P that falsifies c.\nThe proof is straightforward since c is a transition constraint of P = 〈X , C〉 iff P is unsatisfiable and there exists a solution A of 〈X , C \\ {c}〉 iff A falsifies only the constraint c of 〈X , C〉.\nWhen a transition assignment A is found, the model rotation approach explores assignments that differ from A w.r.t. only one value. If this close assignment also falsifies only one constraint c′, then c′ belongs to every MUC, too.\nIn [5], it is proposed to recursively perform model rotation. This extended technique is called Recursive Model Rotation: it is summarized in a CSP version in Algorithm 1. This algorithm always makes local changes to the value of one variable in the transition assignment in trying to find out another transition assignment exhibiting another constraint (lines 3–5), without a call to a constraint network solver. Contrary to the initial model rotation technique, the process is not stopped when a transition assignment does not deliver an additional transition constraint. Instead, model rotation is recursively performed with all transition assignments found (lines 6–8). See e.g., [4] [3] and [30] for more on the use of model rotation to extract MUSes."
    }, {
      "heading" : "4 Local Search for Transition Constraints",
      "text" : "In the following, we introduce a new approach for computing one MUC by means of exhibiting transition constraints that relies on stochastic local search (in short, SLS)\nas a kernel procedure. Whenever SLS reaches an assignment that falsifies exactly one constraint c, c is a transition constraint and belongs to the final MUC. Obviously, such an assignment is a local minima for SLS, which can then explore neighborhood assignments, including other possible transition assignments that would be discovered by recursive model rotation. Hence, we have investigated a generic approach based on SLS that we call Local Search for Transition Constraints, in short LSTC.\nLocal search in the SAT and CSP domains is usually implemented as a tool intended to search for a model. On the contrary, we make use of SLS to explore the neighborhood of a transition assignment in search for additional transition constraints. Accordingly, some adaptations were made to the usual SLS scheme. Although its escape strategy is close to the so-called breakout method [26], the end criterion was modified in order to allow SLS to focus and stress on parts of the search space that are expectedly very informative, as proposed in [11,1]. More precisely, the nbIt counter of iterations remaining to be performed is increased in a significant way each time an additional transition constraint has been discovered, as SLS might have reached a promising part of the search space that has not been explored so far. On the contrary, when an already discovered transition constraint c is found again, the nbIt counter is decreased by the number of times c has already been considered, as a way to guide SLS outside expectedly wellexplored parts of the search space. Otherwise, the nbIt counter is decremented at each step and the procedure ends when nbIt becomes negative.\nThe objective function was itself modified to enforce the satisfaction of the constraints already identified as belonging to the MUC that will be exhibited. More precisely, these latter constraints have their weighs increased in order to be satisfied first.\nAlgorithm 2 summarizes the approach. It takes as input an unsatisfiable constraint network P ′ = 〈X ′, C′〉, an assignment A and the current set of constraints CMUC that have already been recognized as belonging to the MUC that will be exhibited. Note that in most calls to Algorithm 2, the P ′ parameter is a subpart of the constraint network P for which a MUC must be found; P ′ will represent the current result of a dichotomy destructive strategy in the calling procedure.\nAlso, A does not need to be a transition assignment. When A is empty, it is randomly initialized, like in a classical SLS procedure. Otherwise, A is a transition assignment which is used as the starting point of the search. The algorithm returns CMUC after this set has been possibly extended by additional constraints also belonging to this MUC. The local search is a standard basic random-walk procedure [29] where the objective function has thus been modified in order to take a specific weigh on each constraint into account. Note that these weighs are specific to the call to LSTC and thus different from the counters delivered by the pre-processing step, which are used by the dichotomy strategy.\nA local minimum of a SLS algorithm is a state where there does not exist any assignment that can be reached by a single move of the local search and that would decrease the sum of the weighs of the falsified constraints. Each time a local minimum is reached, the method tries to collect information (lines 6–13). Thus, before applying an escape criterion (line 14), when there is only one constraint c of C′ that is falsified by the current assignment (i.e., when the current assignment is a transition assignment), c must appear in the final MUC. Two sub-cases are thus as follows. When c does not already\nAlgorithm 2: LSTC (stands for Local Search for Transition Constraints) Input: P ′ = 〈X ′, C′〉: a CN,\nCMUC : a set of constraints belonging to every MUC of P ′, A: a transition assignment of P ′ (possibly empty)\nOutput: expanded CMUC\nif A = ∅ then A ← a random assignment of X ′;1 foreach c ∈ C′ do w(c) = 1;2 Initialize nbIt by a preset positive number ; /* Counter nbIt of remaining3 iterations is initialized. */ while (nbIt ≥ 0) do4 if a local minimum is reached then5 if |{c ∈ C′|c is falsified by A}| = 1 then /* transition assignment */6 Let c be the constraint falsified by A ; /* transition constraint */7 if c /∈ CMUC then8\nCMUC ← CMUC ∪ {c};9 Increase nbIt by a preset positive bonus ;10\nelse11 nbIt ← nbIt− w(c) ;12 w(c) ← w(c) + 1 ;13\nChange the value in A of one var. of X ′ according to an escape strategy ;14 else Change the value in A of one var. of X ′ s.t. the sum of the weighs of violated15 constraints decreases; nbIt ← nbIt− 1;16\nreturn CMUC ;17\nbelong to CMUC , c is inserted within CMUC (line 9) and the value of nbIt is increased (line 10). When c already belongs to CMUC , a penalty under the form of a negative number is applied to nbIt (line 12) and the weigh of c is incremented (line 13). In this way, the more a transition constraint is considered, the greater is the penalty. When SLS is not reaching a local minimum, the value of one variable of X ′ is changed in such a way that the sum of the weighs of the falsified constraints decreases (line 15). In both latter cases, the value of the nbIt counter is decreased at each loop (line 16). Finally, when nbIt reaches a strictly negative value, a set of constraints included in the final MUC to be exhibited is returned (line 17).\nLet us stress that Algorithm 2 without colorized lines (6 to 13) is a mere standard stochastic local search procedure.\nNoticeably, this approach differs from [10,13] where a different form of SLS was used to extract MUSes. First, [10,13] was dedicated to the Boolean case using specific features of the clausal Boolean framework: extending it to the general constraint networks setting while still obtaining acceptable running times for many real-life instances remains an open challenge. Second, it was used as a fast-preprocessing step to locate an upper-approximation of a MUS. The role of LSTC is different: this procedure will be called during the fine-tuning process of the approximation delivered by the preprocessing. Finally, [10] and [13] were based on the so-called critical clause concept\nAlgorithm 3: Dichotomy Core Extraction with Local Search (DC(WCORE)+LSTC) Input: P = 〈X ,C〉: an unsatisfiable CN Output: one MUC of P\nC ← WCORE(〈X , C〉) ; /* Preprocessing step */1 CMUC ← ∅; /* Set of constraints belonging to the MUC */2 ATR ← ∅ ; /* Last transition assignment found */3\nCCUT ← choose ⌈ |C| 2 ⌉ constraints of C1; /* Set of constraints analyzed4\nfor possible removal, selected according to a dichotomy strategy */\nwhile CCUT 6= ∅ do5 A ← solve(〈X , C \\ CCUT〉) ; /* Usual MAC algorithm is used */6 if A 6= ∅ and |CCUT| > 1/* A solution is found and more than one */7 then /*constraint has been removed */\nCCUT ← choose ⌈ |CCUT | 2 ⌉ constraints of CCUT 1; /*range of analyzed\nconstraints is reduced*/\nelse8 if A = ∅ then C ← C \\ CCUT ; /* No solution found, CCUT can be9\nremoved from C while the resulting C remains unsat */ else10 /* Solution found and |CCUT | = 1 */ CMUC ← CMUC ∪ CCUT; /* A trans. const. has been found */ ATR ← A ; /* The last transition assignment is saved */11\nCMUC ← LSTC(〈X ,C〉,CMUC ,ATR); /* CMUC is extended by LSTC */12\nCCUT ← choose ⌈ |C\\CMUC| 2 ⌉ constraints of C \\ CMUC 1;13\nreturn 〈X , C〉;14\nto explore the search space, which is not generalized and adopted here in the general framework of constraint networks."
    }, {
      "heading" : "5 Dichotomy Core Extraction with Local Search",
      "text" : "Algorithm 3 summarizes an algorithm that computes one MUC of an unsatisfiable constraint network P = 〈X , C〉, based on the dichotomy strategy and relying on the local search procedure to extract additional transition constraints. As a preprocessing step, WCORE delivers in C an unsatisfiable core of P that is not guaranteed to be minimal (line 1). CMUC , the set of constraints that have already been recognized as belonging to the MUC, is then initialized to the empty set (line 2). The lastly discovered transition assignment ATR is initialized to the empty set (line 3). According to a dichotomy strategy CCUT is initialized with half the constraints of C, themselves selected according to the dom/wdeg scores collected during the WCORE preprocessing step (line 4). A dichotomy-based loop is run until CCUT becomes empty. While there remain constraints in CCUT that have not yet been either removed from the candidate MUC or inserted in this MUC, the sub-network 〈X , C \\ CCUT〉 is solved and the solution is stored in A (line 6). By convention, when A is a model of 〈X , C \\ CCUT〉, it is not empty. In this case and\nwhen at the same time the number of constraints belonging to CCUT is different from 1, no conclusion can be made with this set of constraints and CCUT is then refined according to the dichotomy strategy. When A is empty, 〈X , C \\ CCUT〉 is unsatisfiable and the constraints of CCUT can be removed from C while keeping the unsatisfiability of this latter set (line 9). Finally, when A is not empty and CCUT contains only one constraint c, c is a transition constraint and will appear in the final result CMUC (line 10) while the transition assignment is recorded in ATR .\nCalls to LSTC are performed at each iteration step when A = ∅ or |CCUT | = 1, with the following parameters: the current constraint network 〈X , C〉, the set of constraints already identified as belonging to CMUC in construction and the complete interpretation ATR . These calls are thus intended to find out additional transition constraints with respect to C. Note that after the first main iterations in the loop of Algorithm 3 have allowed a first transition assignment to be found, all calls to LSTC are made with the lastly discovered transition constraints as a parameter. Although there can thus exist several calls to LSTC with the same transition constraint, it is important to note that C evolves, forming another constraint network at each call. It is thus transmitted to the local search procedure together with an expectedly “good” interpretation to start with. When CCUT becomes an empty set, this means that all constraints of C have been proved to belong to the MUC, i.e., C = CMUC . Thus, at the end of the loop C identified as forming one MUC of P is returned (line 14).\nImportantly, Algorithm 3 is complete in the sense that it is delivers one MUC for any unsatisfiable P = 〈X , C〉 in finite time (but it is exponential-time in worst case scenarios, like all complete algorithms to find out one MUC).\nLet us stress that this algorithm differs from the dichotomy destructive strategy DC(WCORE) in [17] according to the colorized lines (namely lines 3, 11 and 12), only."
    }, {
      "heading" : "6 Experimental Results",
      "text" : "In order to assess and compare the actual efficiency of the local-search approach with other methods, and in particular the model-rotation one, we have considered all the benchmarks from the last CSP solvers competitions [6,7],2 which include binary vs. nonbinary, random vs. real-life, satisfiable vs. unsatisfiable CSP instances. Among these instances, only the 772 benchmarks that were proved unsatisfiable in less than 300 seconds using our own C++ RCLCSP3 CSP solver were considered. RCLCSP implements MAC embedding AC3 and makes use of the dom/wdeg variable ordering heuristic.\nThree approaches to the MUC extraction problem have been implemented with RCLCSP as kernel and experimentally compared: (1) DC(WCORE) [17], namely a dichotomy destructive strategy with WCORE as a preprocessing step, without any form of model rotation or local search to find out additional transition constraints, (2) DC(WCORE) + Rec-MR and (3) DC(WCORE)+LSTC. For the latter approach, the nbIt counter was initialized to 10000 and the bonus was set to that value, too. Furthermore, rnovelty [25] was used as local-search escape criterion and the advanced data structures proposed in\n1 The dom/wdeg scores collected during the WCORE step are used to rank-order constraints. 2 The benchmarks are available at http://www.cril.univ-artois.fr/˜lecoutre 3 The executable is available at http://www.cril.univ-artois.fr/˜lagniez\n[22] have been implemented. All three versions have been run on a Quad-core Intel XEON X5550 with 32GB of memory under Linux Centos 5. Time-out has been set to 900 seconds.\nIn Fig. 3, a cactus plot compares the three approaches in terms of the number of instances for which a MUC was extracted, indicating the spent CPU time on the y-axis. Several observations can be made. First, similarly to the SAT setting for model rotation [5], recursive model rotation improves performance in the sense that DC(WCORE)+RecMR found a MUC for 632 instances whereas DC(WCORE) solved 609 instances, only. Then, local search in its turn improves recursive model rotation according to the same criterion: DC(WCORE)+LSTC solved 663 instances. In addition to solving 54 and 31 additional instances respectively, DC(WCORE)+LSTC appears to be more efficient in terms of CPU time and less demanding than the other competing approaches in terms of the number of calls to a CSP solver for the more challenging instances.\nIn Fig. 4, pairwise comparisons between the approaches are provided. Each comparison between two methods is done in terms of CPU time (sub-figures (a) (c) and (e)) and of the number of calls to the MAC solver (sub-figures (b), (d) and (f)), successively. For each scatter, the x-axis (resp. y-axis) corresponds to the CPU time tx (resp. ty) obtained by the method labelled on the same axis. Each dot (tx, ty) thus gives the results for a given benchmark instance. Thus, dots above (resp. below) the diagonal represent instances for which the method labelled on the x-axis is better (resp. worse) than the method labelled on the y-axis. Points on the vertical (resp. horizontal) dashed line mean that the method labelled on the x-axis (resp. y-axis) did not solved the corresponding instance before timeout.\nFirst, the figure 4(a) shows that DC(WCORE)+Rec-MR solves instances faster than DC(WCORE). Then, Fig. 4(c) and 4(e) show that, most generally, DC(WCORE)+LSTC finds one MUC faster than both DC(WCORE) and DC(WCORE)+Rec-MR manage to do it, provided that the instance is difficult in the sense that extracting a MUC requires more than 100 seconds. On easier instances, the additional computational cost of local search (and model rotation) has often a negative impact on the global computing time, but this latter one remains however very competitive. Fig. 4(b) (d) and (f) show the extent\nto which recursive model rotation and local search reduce the number of calls to a CSP solver, and thus of calls to an NP-complete oracle, in order to find out one MUC. Clearly, DC(WCORE)+LSTC often outperforms the other approaches in that respect. The observation of these three figures suggests that local search allows more transition constraints to be discovered by considering assignments in the neighborhood of the transition assignments. This intuition is confirmed by the experimental results reported in Fig. 5. In this latter figure, we give the percentage of the total size of the MUC that has been found by Rec-MR and LSTC, respectively. It shows that LSTC detects more transition constraints than Rec-MR. Moreover, it shows that for almost all instances, more than half of the constraints in the MUC are found thanks to local search when DC(WCORE)+LSTC is under consideration. This ability explains much of the performance gains obtained on difficult instances. Actually, local search detects the totality of the MUC for many instances.\nFinally, Tab. 1 reports the detailed results of each approach on a typical panel of instances from the benchmarks. The first four columns provide the name, numbers of constraints and variables of the instance, the number of remaining constraints after the preprocessing step, successively. Then, for each method, the CPU time, the size of the extracted MUC (the MUCs discovered by the various methods can differ) and the number of CSP calls to find it are listed. In addition, for DC(WCORE)+Rec-MR (resp. DC(WCORE)+LSTC), the number (“by rot.”) of constraints of the MUC detected by model rotation (resp. local search (“by LS”)) is provided. TO means time-out and the best computing time for each instance is shaded in grey. For example, MUCs of a same\nsize (94 constraints) were found for the cc-10-10-2 instance using each of the three methods. LSTCwas best performing in extracting a MUC in 28.28 seconds (vs. 49.38 and 55.36 seconds for the other methods). Note that all constraints in that MUC were discovered through the LSTC procedure."
    }, {
      "heading" : "7 Perspectives and conclusion",
      "text" : "Clearly, the local search scheme proposed in this paper improves the extraction of one MUC by means of destructive strategies and opens many perspectives. Although dichotomy strategies, as explored in this paper, are known to be the most efficient ones, it could be interesting to graft this local search scheme to constructive or QuickXplainlike methods. Also, note that we have not tried to fine-tune the various parameters of this local search scheme. In this respect, it would be interesting to devise forms of dynamical settings for these parameters that better take the recorded information about the previous search steps into account, as explored in [14]. In the future, we plan to explore more advanced concepts that are related to transition constraints in the goal of better guiding the local search towards promising parts of the search space. Especially, so-called critical clauses [12] in the Boolean framework could be generalized in various ways in the full constraint networks setting. Exploring the possible ways according to which LSTC could benefit from this is a promising path for further research."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work has been partly supported by a grant from the Région Nord/Pas-de-Calais and by an EC FEDER grant."
    } ],
    "references" : [ {
      "title" : "Boosting local search thanks to CDCL",
      "author" : [ "Gilles Audemard", "Jean-Marie Lagniez", "Bertrand Mazure", "Lakhdar Saı̈s" ],
      "venue" : "In 17th International Conference on Logic for Programming, Artificial Intelligence and Reasoning",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2010
    }, {
      "title" : "Diagnosing and solving over-determined constraint satisfaction problems",
      "author" : [ "René R. Bakker", "F. Dikker", "Frank Tempelman", "Petronella Maria Wognum" ],
      "venue" : "In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI’93),",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1993
    }, {
      "title" : "Towards efficient MUS extraction",
      "author" : [ "Anton Belov", "Inês Lynce", "João Marques Silva" ],
      "venue" : "AI Communications,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2012
    }, {
      "title" : "MUSer2: An efficient MUS extractor, system description",
      "author" : [ "Anton Belov", "João Marques Silva" ],
      "venue" : "Journal on Satisfiability, Boolean Modeling and Computation JSAT,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2012
    }, {
      "title" : "Accelerating MUS extraction with recursive model rotation",
      "author" : [ "Anton Belov", "João P. Marques Silva" ],
      "venue" : "In Proceedings of the International Conference on Formal Methods in ComputerAided Design",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2011
    }, {
      "title" : "Explanation-based generalization of failures",
      "author" : [ "J.L. de Siqueira N", "Jean-François Puget" ],
      "venue" : "In Proceedings of the Eighth European Conference on Artificial Intelligence",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1988
    }, {
      "title" : "On the complexity of propositional knowledge base revision, updates and counterfactual",
      "author" : [ "Thomas Eiter", "Georg Gottlob" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1992
    }, {
      "title" : "Extracting MUSes",
      "author" : [ "É. Grégoire", "B. Mazure", "C. Piette" ],
      "venue" : "In Proceedings of the 17th European Conference on Artificial Intelligence",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    }, {
      "title" : "A CSP solver focusing on FAC variables",
      "author" : [ "Éric Grégoire", "Jean-Marie Lagniez", "Bertrand Mazure" ],
      "venue" : "In 17th International Conference on Principles and Practice of Constraint Programming",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2011
    }, {
      "title" : "Extracting MUSes",
      "author" : [ "Éric Grégoire", "Bertrand Mazure", "Cédric Piette" ],
      "venue" : "European Conference on Artificial Intelligence",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2006
    }, {
      "title" : "On finding minimally unsatisfiable cores of CSPs",
      "author" : [ "Éric Grégoire", "Bertrand Mazure", "Cédric Piette" ],
      "venue" : "International Journal on Artificial Intelligence Tools (IJAIT),",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "A new heuristic-based albeit complete method to extract MUCs from unsatisfiable CSPs",
      "author" : [ "Éric Grégoire", "Bertrand Mazure", "Cédric Piette", "Lakhdar Saı̈s" ],
      "venue" : "In Proceedings of the IEEE International Conference on Information Reuse and Integration",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2006
    }, {
      "title" : "Boosting systematic search by weighting constraints",
      "author" : [ "Fred Hémery", "Christophe Lecoutre", "Lakhdar Saı̈s", "Frédéric Boussemart" ],
      "venue" : "In Proceedings of the 16th European Conference on Artificial Intelligence",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2004
    }, {
      "title" : "Extracting MUCs from constraint networks",
      "author" : [ "Fred Hémery", "Christophe Lecoutre", "Lakhdar Saı̈s", "Frédéric Boussemart" ],
      "venue" : "In 17th European Conference on Artificial Intelligence",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2006
    }, {
      "title" : "QuickXplain: Conflict detection for arbitrary constraint propagation algorithms. In IJCAI’01 Workshop on Modelling and Solving Problems with Constraints",
      "author" : [ "Ulrich Junker" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2001
    }, {
      "title" : "QuickXplain: Preferred explanations and relaxations for over-constrained problems",
      "author" : [ "Ulrich Junker" ],
      "venue" : "In Proceedings of the 19th National Conference on Artificial Intelligence",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2004
    }, {
      "title" : "The PaLM system: explanation-based constraint programming. In Proceedings of TRICS: Techniques foR Implementing Constraint programming Systems, a post-conference workshop of CP’00",
      "author" : [ "Narendra Jussien", "Vincent Barichard" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2000
    }, {
      "title" : "A data structure boosting the performance of local search for CSP solving",
      "author" : [ "Jean-Marie Lagniez", "Éric Grégoire", "Bertrand Mazure" ],
      "venue" : "In International Conference on Metaheuristics and Nature Inspired Computing (META’12),",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2012
    }, {
      "title" : "On computing minimum unsatisfiable cores",
      "author" : [ "Inês Lynce", "João P. Marques Silva" ],
      "venue" : "In Proceedings of the 7th International Conference on Theory and Applications of Satisfiability Testing (SAT’04),",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2004
    }, {
      "title" : "Minimal sets over monotone predicates in boolean formulae",
      "author" : [ "João Marques-Silva", "Mikoláš", "Anton Belov" ],
      "venue" : "In Proceedings of the 25th International Conference on Computer-Aided Verification (CAV’2013),",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2013
    }, {
      "title" : "Evidence for invariants in local search",
      "author" : [ "David McAllester", "Bart Selman", "Henry A. Kautz" ],
      "venue" : "In Fourteenth National Conference on Artificial Intelligence",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1997
    }, {
      "title" : "The breakout method for escaping from local minima",
      "author" : [ "Paul Morris" ],
      "venue" : "In Proceedings of the Eleventh National Conference on Artificial Intelligence",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1993
    }, {
      "title" : "The complexity of facets resolved",
      "author" : [ "Christos H. Papadimitriou", "David Wolfe" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1988
    }, {
      "title" : "Faster extraction of high-level minimal unsatisfiable cores",
      "author" : [ "Vadim Ryvchin", "Ofer Strichman" ],
      "venue" : "In Proceedings of the 14th International Conference on Theory and Applications of Satisfiability Testing",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2011
    }, {
      "title" : "Noise strategies for improving local search",
      "author" : [ "Bart Selman", "Henry A. Kautz", "Bram Cohen" ],
      "venue" : "In Twelfth National Conference on Artificial Intelligence",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1994
    }, {
      "title" : "Understanding, improving and parallelizing MUS finding using model rotation",
      "author" : [ "Wieringa Siert" ],
      "venue" : "In 18th International Conference on Principles and Practice of Constraint Programming",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2012
    }, {
      "title" : "On improving MUS extraction algorithms. In Theory and Applications of Satisfiability Testing (SAT’11)",
      "author" : [ "João P. Marques Silva", "Inês Lynce" ],
      "venue" : "Lecture Notes in Computer Science,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2011
    }, {
      "title" : "On improving MUS extraction algorithms",
      "author" : [ "João P. Marques Silva", "Inês Lynce" ],
      "venue" : "In Proceedings of the 14th International Conference on Theory and Applications of Satisfiability Testing",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2011
    }, {
      "title" : "Finding guaranteed MUSes fast",
      "author" : [ "Hans Van Maaren", "Siert Wieringa" ],
      "venue" : "In Proceedings of the 11th International Conference on Theory and Applications of Satisfiability Testing",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "Despite bad worst-case computational complexity results, various approaches for extracting one MUC have been proposed that appear tractable for many instances [8,2,21,20,18,19,17,15,14].",
      "startOffset" : 159,
      "endOffset" : 185
    }, {
      "referenceID" : 1,
      "context" : "Despite bad worst-case computational complexity results, various approaches for extracting one MUC have been proposed that appear tractable for many instances [8,2,21,20,18,19,17,15,14].",
      "startOffset" : 159,
      "endOffset" : 185
    }, {
      "referenceID" : 16,
      "context" : "Despite bad worst-case computational complexity results, various approaches for extracting one MUC have been proposed that appear tractable for many instances [8,2,21,20,18,19,17,15,14].",
      "startOffset" : 159,
      "endOffset" : 185
    }, {
      "referenceID" : 14,
      "context" : "Despite bad worst-case computational complexity results, various approaches for extracting one MUC have been proposed that appear tractable for many instances [8,2,21,20,18,19,17,15,14].",
      "startOffset" : 159,
      "endOffset" : 185
    }, {
      "referenceID" : 15,
      "context" : "Despite bad worst-case computational complexity results, various approaches for extracting one MUC have been proposed that appear tractable for many instances [8,2,21,20,18,19,17,15,14].",
      "startOffset" : 159,
      "endOffset" : 185
    }, {
      "referenceID" : 13,
      "context" : "Despite bad worst-case computational complexity results, various approaches for extracting one MUC have been proposed that appear tractable for many instances [8,2,21,20,18,19,17,15,14].",
      "startOffset" : 159,
      "endOffset" : 185
    }, {
      "referenceID" : 11,
      "context" : "Despite bad worst-case computational complexity results, various approaches for extracting one MUC have been proposed that appear tractable for many instances [8,2,21,20,18,19,17,15,14].",
      "startOffset" : 159,
      "endOffset" : 185
    }, {
      "referenceID" : 10,
      "context" : "Despite bad worst-case computational complexity results, various approaches for extracting one MUC have been proposed that appear tractable for many instances [8,2,21,20,18,19,17,15,14].",
      "startOffset" : 159,
      "endOffset" : 185
    }, {
      "referenceID" : 13,
      "context" : "Powerful approaches to MUC extraction are founded on transition constraints, both in the CSP [17,14] and the SAT [23,12,13,33,23,28,4] domains.",
      "startOffset" : 93,
      "endOffset" : 100
    }, {
      "referenceID" : 10,
      "context" : "Powerful approaches to MUC extraction are founded on transition constraints, both in the CSP [17,14] and the SAT [23,12,13,33,23,28,4] domains.",
      "startOffset" : 93,
      "endOffset" : 100
    }, {
      "referenceID" : 18,
      "context" : "Powerful approaches to MUC extraction are founded on transition constraints, both in the CSP [17,14] and the SAT [23,12,13,33,23,28,4] domains.",
      "startOffset" : 113,
      "endOffset" : 134
    }, {
      "referenceID" : 9,
      "context" : "Powerful approaches to MUC extraction are founded on transition constraints, both in the CSP [17,14] and the SAT [23,12,13,33,23,28,4] domains.",
      "startOffset" : 113,
      "endOffset" : 134
    }, {
      "referenceID" : 28,
      "context" : "Powerful approaches to MUC extraction are founded on transition constraints, both in the CSP [17,14] and the SAT [23,12,13,33,23,28,4] domains.",
      "startOffset" : 113,
      "endOffset" : 134
    }, {
      "referenceID" : 18,
      "context" : "Powerful approaches to MUC extraction are founded on transition constraints, both in the CSP [17,14] and the SAT [23,12,13,33,23,28,4] domains.",
      "startOffset" : 113,
      "endOffset" : 134
    }, {
      "referenceID" : 23,
      "context" : "Powerful approaches to MUC extraction are founded on transition constraints, both in the CSP [17,14] and the SAT [23,12,13,33,23,28,4] domains.",
      "startOffset" : 113,
      "endOffset" : 134
    }, {
      "referenceID" : 3,
      "context" : "Powerful approaches to MUC extraction are founded on transition constraints, both in the CSP [17,14] and the SAT [23,12,13,33,23,28,4] domains.",
      "startOffset" : 113,
      "endOffset" : 134
    }, {
      "referenceID" : 27,
      "context" : "In this last area, a recent approach [32,5] focuses on the following intuition.",
      "startOffset" : 37,
      "endOffset" : 43
    }, {
      "referenceID" : 4,
      "context" : "In this last area, a recent approach [32,5] focuses on the following intuition.",
      "startOffset" : 37,
      "endOffset" : 43
    }, {
      "referenceID" : 13,
      "context" : "The technique is put in work in a so-called dichotomy destructive strategy à la DC(WCORE) [17] to extract one MUC.",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 4,
      "context" : "Extensive computational experimentations show that this approach outperforms both the model rotation technique from [5] and the performance of state-of-the-art MUC extractors.",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 22,
      "context" : "Indeed, checking whether a constraint network is a MUC is DP-complete [27].",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 13,
      "context" : "In this paper, we focus on this minimization step and make use of the WCORE core extractor introduced in [17] as a preprocessing step, that we briefly describe hereafter.",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 13,
      "context" : "When the unsatisfiability of a constraint network P is proved thanks to a filtering search algorithm, WCORE [17] delivers a core of P that is formed of all the constraints that have been involved in the proof of unsatisfiability, namely all the constraints that have been used during the search to remove by propagation at least one value from the domain of any variable.",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 13,
      "context" : "The approach from [17] iterates this process until no smaller set of active constraints is found.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 12,
      "context" : "WCORE takes advantage of the powerful dom/wdeg heuristic [16] (see also variants in e.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 10,
      "context" : "[14]), which consists in attaching to each constraint a counter initialized to 1 and that is incremented each time the corresponding constraint is involved in a conflict.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "Accordingly, it is proposed in [17] to weigh the constraints via the dom/deg",
      "startOffset" : 31,
      "endOffset" : 35
    }, {
      "referenceID" : 6,
      "context" : "To this end, it might be necessary to check whether a constraint belongs or not to the set of MUCs included within a core, which is a task in Σ 2 [9].",
      "startOffset" : 146,
      "endOffset" : 149
    }, {
      "referenceID" : 5,
      "context" : "either so-called destructive or constructive approaches [8,2,20,18,17,14].",
      "startOffset" : 56,
      "endOffset" : 73
    }, {
      "referenceID" : 1,
      "context" : "either so-called destructive or constructive approaches [8,2,20,18,17,14].",
      "startOffset" : 56,
      "endOffset" : 73
    }, {
      "referenceID" : 16,
      "context" : "either so-called destructive or constructive approaches [8,2,20,18,17,14].",
      "startOffset" : 56,
      "endOffset" : 73
    }, {
      "referenceID" : 14,
      "context" : "either so-called destructive or constructive approaches [8,2,20,18,17,14].",
      "startOffset" : 56,
      "endOffset" : 73
    }, {
      "referenceID" : 13,
      "context" : "either so-called destructive or constructive approaches [8,2,20,18,17,14].",
      "startOffset" : 56,
      "endOffset" : 73
    }, {
      "referenceID" : 10,
      "context" : "either so-called destructive or constructive approaches [8,2,20,18,17,14].",
      "startOffset" : 56,
      "endOffset" : 73
    }, {
      "referenceID" : 5,
      "context" : "For example, the constructive approaches (as in [8]) successively insert constraints taken from the core into a set of constraints until this latter set becomes unsatisfiable.",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 1,
      "context" : "At the opposite, destructive approaches [2] successively remove constraints from the initial core until the current network becomes satisfiable.",
      "startOffset" : 40,
      "endOffset" : 43
    }, {
      "referenceID" : 13,
      "context" : "It is also possible to use a dichotomy strategy in order to find out transition constraints [17].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 15,
      "context" : "QuickXplain [19,24] and the combined approach [14].",
      "startOffset" : 12,
      "endOffset" : 19
    }, {
      "referenceID" : 19,
      "context" : "QuickXplain [19,24] and the combined approach [14].",
      "startOffset" : 12,
      "endOffset" : 19
    }, {
      "referenceID" : 10,
      "context" : "QuickXplain [19,24] and the combined approach [14].",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 26,
      "context" : "The model rotation approach (MR) has been introduced in [31].",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 4,
      "context" : "In [5], it is proposed to recursively perform model rotation.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 3,
      "context" : ", [4] [3] and [30] for more on the use of model rotation to extract MUSes.",
      "startOffset" : 2,
      "endOffset" : 5
    }, {
      "referenceID" : 2,
      "context" : ", [4] [3] and [30] for more on the use of model rotation to extract MUSes.",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 25,
      "context" : ", [4] [3] and [30] for more on the use of model rotation to extract MUSes.",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 21,
      "context" : "Although its escape strategy is close to the so-called breakout method [26], the end criterion was modified in order to allow SLS to focus and stress on parts of the search space that are expectedly very informative, as proposed in [11,1].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 8,
      "context" : "Although its escape strategy is close to the so-called breakout method [26], the end criterion was modified in order to allow SLS to focus and stress on parts of the search space that are expectedly very informative, as proposed in [11,1].",
      "startOffset" : 232,
      "endOffset" : 238
    }, {
      "referenceID" : 0,
      "context" : "Although its escape strategy is close to the so-called breakout method [26], the end criterion was modified in order to allow SLS to focus and stress on parts of the search space that are expectedly very informative, as proposed in [11,1].",
      "startOffset" : 232,
      "endOffset" : 238
    }, {
      "referenceID" : 24,
      "context" : "The local search is a standard basic random-walk procedure [29] where the objective function has thus been modified in order to take a specific weigh on each constraint into account.",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 7,
      "context" : "Noticeably, this approach differs from [10,13] where a different form of SLS was used to extract MUSes.",
      "startOffset" : 39,
      "endOffset" : 46
    }, {
      "referenceID" : 7,
      "context" : "First, [10,13] was dedicated to the Boolean case using specific features of the clausal Boolean framework: extending it to the general constraint networks setting while still obtaining acceptable running times for many real-life instances remains an open challenge.",
      "startOffset" : 7,
      "endOffset" : 14
    }, {
      "referenceID" : 7,
      "context" : "Finally, [10] and [13] were based on the so-called critical clause concept",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 13,
      "context" : "Let us stress that this algorithm differs from the dichotomy destructive strategy DC(WCORE) in [17] according to the colorized lines (namely lines 3, 11 and 12), only.",
      "startOffset" : 95,
      "endOffset" : 99
    }, {
      "referenceID" : 13,
      "context" : "Three approaches to the MUC extraction problem have been implemented with RCLCSP as kernel and experimentally compared: (1) DC(WCORE) [17], namely a dichotomy destructive strategy with WCORE as a preprocessing step, without any form of model rotation or local search to find out additional transition constraints, (2) DC(WCORE) + Rec-MR and (3) DC(WCORE)+LSTC.",
      "startOffset" : 134,
      "endOffset" : 138
    }, {
      "referenceID" : 20,
      "context" : "Furthermore, rnovelty [25] was used as local-search escape criterion and the advanced data structures proposed in",
      "startOffset" : 22,
      "endOffset" : 26
    }, {
      "referenceID" : 17,
      "context" : "[22] have been implemented.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 4,
      "context" : "First, similarly to the SAT setting for model rotation [5], recursive model rotation improves performance in the sense that DC(WCORE)+RecMR found a MUC for 632 instances whereas DC(WCORE) solved 609 instances, only.",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 10,
      "context" : "In this respect, it would be interesting to devise forms of dynamical settings for these parameters that better take the recorded information about the previous search steps into account, as explored in [14].",
      "startOffset" : 203,
      "endOffset" : 207
    }, {
      "referenceID" : 9,
      "context" : "Especially, so-called critical clauses [12] in the Boolean framework could be generalized in various ways in the full constraint networks setting.",
      "startOffset" : 39,
      "endOffset" : 43
    } ],
    "year" : 2013,
    "abstractText" : "Extracting MUCs (Minimal Unsatisfiable Cores) from an unsatisfiable constraint network is a useful process when causes of unsatisfiability must be understood so that the network can be re-engineered and relaxed to become satisfiable. Despite bad worst-case computational complexity results, various MUCfinding approaches that appear tractable for many real-life instances have been proposed. Many of them are based on the successive identification of so-called transition constraints. In this respect, we show how local search can be used to possibly extract additional transition constraints at each main iteration step. The approach is shown to outperform a technique based on a form of model rotation imported from the SAT-related technology and that also exhibits additional transition constraints. Our extensive computational experimentations show that this enhancement also boosts the performance of state-of-the-art DC(WCORE)-like MUC extractors.",
    "creator" : "gnuplot 4.4 patchlevel 3"
  }
}