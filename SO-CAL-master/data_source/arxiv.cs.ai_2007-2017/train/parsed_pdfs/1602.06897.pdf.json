{
  "name" : "1602.06897.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Enablers and Inhibitors in Causal Justifications of Logic Programs∗",
    "authors" : [ "Pedro Cabalar", "Miroslaw Truszczynski" ],
    "emails" : [ "jorge.fandino}@udc.es)" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 2.\n06 89\n7v 1\n[ cs\n.L O\nKEYWORDS: causal justifications, well-founded semantics, stable models, answer set programming."
    }, {
      "heading" : "1 Introduction",
      "text" : "The strong connection between Non-Monotonic Reasoning (NMR) and Logic Programming (LP) semantics for default negation has made possible that LP tools became nowadays an important paradigm for Knowledge Representation (KR) and problem-solving in Artificial Intelligence (AI). In particular, Answer Set Programming (ASP) (Niemelä 1999; Marek and Truszczyńki 1999) has established as a preeminent LP paradigm for practical NMR with applications in diverse areas of AI including planning, reasoning about actions, diagnosis, abduction and beyond. The ASP paradigm is based on the stable models semantics (Gelfond and Lifschitz 1988) and is also closely related to the other mainly accepted interpretation for default negation, well-founded semantics (WFS) (Van Gelder et al. 1991). One interesting difference between these two LP semantics and classical models (or even other NMR approaches) is that true atoms in LP must be founded or justified by a given derivation. These justifications are not provided in the semantics\n∗ This is an extended version of a paper presented at the Logic Programming and Nonmonotonic Reasoning Conference (LPNMR 2015), invited as a rapid communication in TPLP. The authors acknowledge the assistance of the conference program chairs Giovambattista Ianni and Miroslaw Truszczynski.\nitself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).\nRather than manipulating justifications as mere syntactic objects, two recent approaches have considered extended multi-valued semantics for LP where justifications are treated as algebraic constructions: Why-not Provenance (WnP) (Damásio et al. 2013) and Causal Graphs (CG) (Cabalar et al. 2014a). Although these two approaches present formal similarities, they start from different understandings of the idea of justification. On the one hand, WnP answers the query “why literal L might hold” by providing conjunctions of hypothetical modifications on the program that would allow deriving L. These modifications include rule labels, expressions like not(A) with A an atom, or negations ‘¬’ of the two previous cases. As an example, a justification for L like r1 ∧not(p)∧¬r2 ∧¬not(q) means that the presence of rule r1 and the absence of atom p would allow deriving L (hypothetically) if both rule r2 were removed and atom q were added to the program. If we want to explain why L actually holds, we have to restrict to justifications without ‘¬’, that is, those without program modifications (which will be the focus of this paper).\nOn the other hand, CG-justifications start from identifying program rules as causal laws so that, for instance, (p ← q) can be read as “event q causes effect p.” Under this viewpoint, (positive) rules offer a natural way for capturing the concept of causal production, i.e. a continuous chain of events that has helped to cause or produce an effect (Hall 2004; Hall 2007). The explanation of a true atom is made in terms of graphs formed by rule labels that reflect the ordered rule applications required for deriving that atom. These graphs are obtained by algebraic operations exclusively applied on the positive part of the program. Default negation in CG is understood as absence of cause and, consequently, a false atom has no justification.\nThe explanation of an atom A in CG is more detailed than in WnP, since the former contains graphs that correspond to all relevant proofs of A whereas in WnP we just get conjunctions that do not reflect any particular ordering among rule applications. However, as explained before, CG does not capture the effect of default negation in a given derivation and, sometimes, this information is very valuable, especially if we want to answer questions of the form “why not.”\nAs in the previous paper on CG (Cabalar et al. 2014a), our final goal is to achieve an elaboration tolerant representation of causality that allows reasoning about cause-effect relations. Under this perspective, although WnP is more oriented to program debugging, its possibility of dealing with hypothetical reasoning of the form “why not” would be an interesting feature to deal with counterfactuals, since several approaches to causality (see Section 5) are based on this concept. To understand the kind of problems we are interested in, consider the following example. A drug d in James Bond’s drink causes his paralysis p provided that he was not given an antidote a that day. We know that Bond’s enemy, Dr. No, poured the drug:\np ← d, nota (1)\nd (2)\nIn this case it is obvious that d causes p, whereas the absence of a just enables the application of the rule. Now, suppose we are said that Bond is daily administered an antidote by the MI6, unless it is a holiday h:\na ← noth (3)\nAdding this rule makes a become an inhibitor of p, as it prevents d to cause p by rule (1). But suppose now that we are in a holiday, that is, fact h is added to the program (1)-(3). Then, the\ninhibitor a is disabled and d causes p again. However, we do not consider that the holiday h is a (productive) cause for Bond’s paralysis p although, indeed, the latter counterfactually depends on the former: “had not been a holiday h, Bond would have not been paralysed.” We will say that the fact h, which disables inhibitor a, is an enabler of p, as it allows applying rule (1).\nIn this work we propose dealing with these concepts of enablers and inhibitors by augmenting CG justifications with a new negation operator ‘∼’ in the CG causal algebra. We show that this new approach, which we call Extended Causal Justifications (ECJ), captures WnP justifications under the Well-founded Semantics, establishing a formal relation between WnP and CG as a byproduct.\nThe rest of the paper is structured as follows. The next section defines the new approach. Sections 3 and 4 explain the formal relations to CG and WnP through a running example. Section 5 studies several examples of causal scenarios from the literature and finally, Section 6 concludes the paper. Appendix A contains an auxiliary figure depicting some common algebraic properties and Appendix B contains the formal proofs of theorems from the previous sections."
    }, {
      "heading" : "2 Extended Causal Justifications (ECJ)",
      "text" : "A signature is a pair 〈At,Lb〉 of sets that respectively represent atoms (or propositions) and labels. Intuitively, each atom in At will be assigned justifications built with rule labels from Lb. In principle, the intersection At ∩Lb does not need to be empty: we may sometimes find it convenient to label a rule using an atom name (normally, the head atom). Justifications will be expressions that combine four different algebraic operators: a product ‘∗’ representing conjunction or joint causation; a sum ‘+’ representing alternative causes; a non-commutative product ‘·’ that captures the sequential order that follows from rule applications; and a non-classical negation ‘∼’ which will precede inhibitors (negated labels) and enablers (doubly negated labels).\nDefinition 1 (Terms) Given a set of labels Lb, a term, t is recursively defined as one of the following expressions t ::= l | ∏S | ∑S | t1 · t2 | ∼t1 where l ∈ Lb, t1, t2 are in their turn terms and S is a (possibly empty and possibly infinite) set of terms. A term is elementary if it has the form l, ∼l or ∼∼l with l ∈ Lb being a label.\nWhen S = {t1, . . . , tn} is finite we simply write ∏S as t1∗· · ·∗ tn and ∑S as t1+ · · ·+ tn. Moreover, when S = /0, we denote ∏S by 1 and ∑S by 0, as usual, and these will be the identities of the product ‘∗’ and the addition ‘+’, respectively. We assume that ‘·’ has higher priority than ‘∗’ and, in turn, ‘∗’ has higher priority than ‘+’.\nDefinition 2 (Values) A (causal) value is each equivalence class of terms under axioms for a completely distributive (complete) lattice with meet ‘∗’ and join ‘+’ plus the axioms of Figures 1 and 2. The set of (causal) values is denoted by VLb.\nNote that 〈VLb,+,∗,∼ ,0,1〉 is a completely distributive Stone algebra (a pseudo-complemented, completely distributive, complete lattice which satisfies the weak excluded middle axiom) whose meet and join are, as usual, the product ‘∗’ and the addition ‘+’. Informally speaking, this means that these two operators satisfy the properties of a Boolean algebra but without negation.\nNote also that all three operations, ‘∗’, ‘+’ and ‘·’ are associative. Product ‘∗’ and addition ‘+’ are also commutative, and they hold the usual absorption and distributive laws with respect to infinite sums and products of a completely distributive lattice.\nThe axioms for ‘·’ in Figure 1 are directly extracted from the CG algebraic structure. For a more detailed explanation on their induced behaviour see (Cabalar et al. 2014a). The new contribution in this paper with respect to the CG algebra is the introduction of the ‘∼’ operator whose meaning is captured by the axioms in Figure 2. As we can see, this operator satisfies De Morgan laws and acts as a complement for the product t ∗∼t = 0. However, it diverges from a classical Boolean negation in some aspects. In the general case, the axioms ∼∼t = t (double negation) and t +∼t = 1 (excluded middle) are not valid. Instead1, we can replace a triple negation ∼∼∼t by ∼t, and we have a weak version of the excluded middle axiom ∼t +∼∼t = 1. The negation of an application is defined as the negation of the product ∼(t · u) def= ∼(t ∗ u) which, in turn, is equivalent to ∼(u∗t), since ∗ is commutative. In other words, under negation, the rule application ordering is disregarded. It is not difficult to see that we can apply the axioms of negation to reach an equivalent expression that avoids its application to other operators. We say that a term is in negation normal form (NNF) if no other operator is in the scope of negation ‘∼’. Moreover, an NNF term is in disjuntive normal form (DNF) if: (1) no sum is in the scope of another operator; (2) only elementary terms are in the scope of application; and (3) every product is transitively closed, that is, of the form of a·b ∗ b·c ∗ a·c. Without loss of generality, we assume from now that all functions defined over causal terms are applied over their DNF form, although, we will usually write them in NNF for short.\nThe lattice order relation is defined as usual in the following way:\nt ≤ u iff (t ∗ u = t) iff (t + u = u)\nConsequently 1 and 0 are respectively the top and bottom elements with respect to relation ≤.\nDefinition 3 (Labelled logic program)\n1 This behaviour coincides indeed with the properties for default negation obtained in Equilibrium Logic (Pearce 1996) or the equivalent General Theory of Stable Models (Ferraris et al. 2007).\nGiven a signature 〈At,Lb〉, a (labelled logic) program P is a set of rules of the form:\nri : H ← B1, . . . , Bm, notC1, . . . , notCn (4)\nwhere ri ∈ Lb is a label or ri = 1, H (the head of the rule) is an atom, and Bi’s and Ci’s (the body of the rule) are either atoms or terms.\nWhen n = 0 we say that the rule is positive, furthermore, if in addition m = 0 we say that the rule is a fact and omit the symbol ‘←.’ When ri ∈ Lb we say that the rule is labelled; otherwise ri = 1 and we omit both ri and ‘:’. By these conventions, for instance, an unlabelled fact A is actually an abbreviation of (1 : A ←). A program P is positive when all its rules are positive, i.e. it contains no default negation. It is uniquely labelled when each rule has a different label or no label at all. In this paper, we will assume that programs are uniquely labelled. Furthermore, for the sake of clarity, we also assume that, for every atom A ∈ At, there is an homonymous label A ∈ Lb, and that each fact A in the program actually stands for the labelled rule (A : A ←). For instance, following these conventions, a possible labelled version for the James Bond’s program could be program P1 below:\nr1 : p ← d,nota\nr2 : a ← noth\nd\nh\nwhere facts d and h stand for rules (d : d ←) and (h : h ←), respectively. An ECJ-interpretation is a mapping I : At −→ VLb assigning a value to each atom. For interpretations I and J we say that I ≤ J when I(A)≤ J(A) for each atom A ∈ At. Hence, there is a ≤-bottom interpretation 0 (resp. a ≤-top interpretation 1) that stands for the interpretation mapping each atom A to 0 (resp. 1). The value assigned to a negative literal notA by an interpretation I, denoted as I(notA), is defined as I(notA) def=∼I(A), as expected. Similarly, for a term t, I(t) def= [t] is the equivalence class of t.\nDefinition 4 (Model) An interpretation I satisfies a rule like (4) iff\n( I(B1)∗ . . .∗ I(Bm)∗ I(notC1)∗ . . .∗ I(notCn) ) · ri ≤ I(H) (5)\nand I is a (causal) model of P, written I |= P, iff I satisfies all rules in P.\nAs usual in LP, for positive programs, we may define a direct consequence operator TP s.t.\nTP(I)(H) def= ∑\n{ ( I(B1)∗ . . .∗ I(Bn) ) · ri | (ri : H ← B1, . . . ,Bn) ∈ P }\nfor any interpretation I and atom H ∈ At. We also define TP ↑α (0) def= TP(TP ↑α−1 (0)) for any successor ordinal α and\nTP ↑ α (0) def= ∑\nβ<α TP ↑\nβ (0)\nfor any limit ordinal alpha. As usual, ω denotes the smallest infinite limit ordinal. Note that 0 is considered a limit ordinal and, thus, TP ↑0 (0) = ∑β<0 TP ↑β (0) = 0.\nTheorem 1 Let P be a (possibly infinite) positive logic program. Then, (i) the least fixpoint of the TP operator, denoted by lfp(TP), satisfies lfp(TP) = TP ↑ω (0) and it is the least model of P, (ii) furthermore, if P is positive and has n rules, then lfp(TP) = TP ↑ω (0) = TP ↑n (0).\nTheorem 1 asserts that, as usual, positive programs have a ≤-least causal model. As we will see later, this least model coincides with the traditional least model (of the program without labels) when one just focuses on the set of true atoms, disregarding the justifications explaining why they are true. For programs with negation we define the following reduct.\nDefinition 5 (Reduct) Given a program P and an interpretation I we denote by PI the positive program containing a rule of the form\nri : H ← B1, . . . ,Bm, I(notC1), . . . , I(notCn) (6)\nfor each rule of the form (4) in P.\nProgram PI is positive and, from Theorem 1, it has a least causal model. By ΓP(I) we denote the least model of program PI . The operator ΓP is anti-monotonic and, consequently, Γ2P is monotonic (Proposition 4 in the appendix) so that, by Knaster-Tarski’s theorem, it has a least fixpointLP and a greatest fixpoint UP\ndef= ΓP(LP). These two fixpoints respectively correspond to the justifications for true and for non-false atoms in the (standard) well-founded model (WFM), we denote as WP.\nFor instance, in our running example, LP1 (d) = Γ2P1 ↑α (0)(d) = d for 1 ≤ α points out that atom d is true because of fact d. Similarly, LP1 (h) = h and LP1 (a) =∼h·r2 reveals that atom h is true because of fact h, and that atom a is not true because fact h has inhibited rule r2. Furthermore,\nLP1 (p) = Γ2P1 ↑α (0)(p) = (∼(∼h·r2)∗ d)·r1 = (∼∼h ∗ d)·r1 +(∼r2 ∗ d)·r1\nfor 2 ≤ α . That is, Bond has been paralysed because fact h has enabled drug d to cause the paralysis by means of rule r1. This corresponds to the justification (∼∼h ∗ d)·r1. Notice how the real cause d is a positive label (not in the scope of negation) whereas the enabler h is in the scope of a a double negation ∼∼h. Justification (∼r2 ∗ d)·r1 means that d·r1 would have been sufficient to cause p, had not been present r2. This example is also useful for illustrating the importance of axiom appl. negation. By directly evaluating the body of rule r1, we have seen that Γ2P1 ↑2 (0)(p)=(∼(∼h · r2)∗ d) · r1. Then, axiom appl. negation allows us to break the dependence between ∼h and r2 into enablers and inhibitors: ∼(∼h · r2) =∼(∼h ∗ r2) =∼∼h+∼r2 and, applying distributivity, we obtain one enabled justification, (∼∼h ∗ d)·r1, and one disabled one, (∼r2 ∗ d)·r1.\nIn our previous example, the least and greatest fixpoint coincided LP1 =UP1 = Γ2P1 ↑2 (0). To illustrate the case where this does not hold consider, for instance, the program P2 formed by the following negative cycle:\nr1 : a ← notb r2 : b ← nota\nIn this case, the least fixpoint of Γ2P assigns LP2(a) =∼r2·r1 and LP2(b) = ∼r1·r2, while, in its turn, the greatest fixpoint of Γ2P corresponds to UP2(a) = r1 and UP2(b) = r2. If we focus on atom a, we can observe that it is not concluded to be true, since the least fixpoint LP has only provided one disabled justification ∼r2·r1 meaning that r2 is acting as a disabler for a. But, on the other hand, a cannot be false either since the greatest fixpoint provides an enabled justification r1 for being non-false (remember that UP provides justifications for non-false atoms). As a result, we get that a is left undefined because r2 prevents it to become true while r1 can still be used to conclude that it is not false.\nTo capture these intuitions, we provide some definitions. A query literal (q-literal) L is either an atom A, its default negation ‘notA’ or the expression ‘undef A’ meaning that A is undefined.\nDefinition 6 (Causal well-founded model) Given a program P, its causal well-founded model WP is a mapping from q-literals to values s.t.\nWP(A) def= LP(A) WP(notA) def= ∼UP(A) WP(undef A) def=∼WP(A)∗∼WP(notA)\nLet l be a label occurrence in a term t in the scope of n ≥ 0 negations. We say that l is an odd or an even occurrence if n is odd or even, respectively. We further say that l is a strictly even occurrence if it is even and n > 0.\nDefinition 7 (Justification) Given a program P and a q-literal L we say that a term E with no sums is a (sufficient causal) justification for L iff E ≤ WP(L). Odd (resp. strictly even) labels2 in E are called inhibitors (resp. enablers) of E . A justification is said to be inhibited if it contains some inhibitor and it is said to be enabled otherwise.\nTrue atoms will have at least one enabled justification, whereas false atoms only contain disabled justifications. As an example of a query for a plain atom A, take the already seen explanation for p in Bond’s example program P1: WP1 (p)=LP1 (p)=(∼∼h ∗ d)·r1 +(∼r2 ∗ d)·r1. We have here two justifications for atom p, let us call them E1=(∼∼h∗d)·r1 and E2 = (∼r2 ∗d)·r1. Justification E1 is enabled because it contains no inhibitors (in fact, E1 is the unique real support for p). Moreover, h is an enabler in E1 because it is strictly even (it is in the scope of double negation) whereas d is a productive cause, since it is not in the scope of any negation. On the contrary, E2 is disabled because it contains the inhibitor r2 (it occurs in the scope of one negation). Intuitively, r2 has prevented d·r1 to become a justification of p. On the other hand, for atom a we had WP1\n(a)=∼h · r2 that only contains an inhibited justification (being h the inhibitor), and so, atom a is not true. Now, if we query about the negative q-literal nota, we obtain WP1 (nota)=∼UP1 (a) which in this case happens to be ∼LP1\n(a)=∼(∼h · r2) = ∼∼h+∼r2. That is, q-literal nota holds, being enabled by h. Moreover, ∼r2 points out that removing r2 would suffice to cause nota too. It is easy to see that the explanations we can get for q-literals notA or undef A will have all their labels in the scope of negation (either as inhibitors or as enablers).\nTo illustrate a query for undef A, let us return to program P2 whose standard well-founded model left both a and b undefined. Given the values we obtained in the least and greatest fixpoints, the causal WFM will assign WP2 (a) = ∼r2·r1 and WP2 (b) = ∼r1·r2, that is, r2 prevents r1 to cause a and r1 prevents r2 to cause b. Furthermore, the values assigned to their respective negations, WP2 (nota) = ∼r1 and WP2 (notb) = ∼r2, point out that atoms a and b are not false because rules r1 and r2 have respectively prevented them to be so. Finally, we obtain that undef a is true because\nWP(undef a) =∼WP2 (a)∗∼WP2 (nota) = (∼∼r2 +∼r1)∗∼∼r1 =∼∼r2 ∗∼∼r1\nthat is, rules r1 and r2 together have made a undefined. Similarly, b is also undefined because of rules r1 and r2, WP(undef b) =∼∼r1 ∗∼∼r2.\n2 We just mention labels, and not their occurrences because terms are in NNF and E contains no sums. Thus, having odd and even occurrences of a same label at a same time would mean that E = 0.\nThe next theorem shows that the literals satisfied by the standard WFM are precisely those ones containing at least one enabled justification in the causal WFM.\nTheorem 2 Let P be a labelled logic program over a signature 〈At,Lb〉 where Lb is a finite set of labels and let WP its (standard) well-founded model. A q-literal L holds with respect to WP if and only if there is some enabled justification E of L, that is, E ≤WP(L) and E does not contain odd negative labels.\nBack to our example program P1, as we had seen, atom p had a unique enabled justification E1 = (∼∼h ∗ d)·r1. The same happens for atoms d and h whose respective justifications are just their own atom labels. Therefore, these three atoms hold in the standard WFM, WP1. On the contrary, as we discussed before, the only justification for a, WP1 (a) = ∼h·r2, is inhibited by h, and thus, a does not hold in WP1 . The interest of an inhibited justification for a literal is to point out “potential” causes that have been prevented by some abnormal situation. In our case, the presence of ∼h in WP1\n(a) = ∼h·r2 points out that an exception h has prevented r2 to cause a. When the exception is removed, the inhibited justification (after removing the inhibitors) becomes an enabled justification.\nIn our running example, if we consider a program P3 obtained by removing the fact h from P1, then WP3(a) = r2 points out that a has been caused by rule r2 in this new scenario. This intuition about inhibited justifications is formalized as follows.\nDefinition 8 Given a term t in DNF, by ρx : VCGLb −→ V CG Lb , we denote the function that removes the elementary term x from t as follows:\nρx(t) def=\n\n  \n  \nρx(u)⊗ρx(w) if t = u⊗ v with ⊗ ∈ {+,∗, ·} 1 if ∼∼t is equivalent to ∼∼x\n0 if t is equivalent to ∼x\nNote that we have assumed that t is in DNF. Otherwise, ρx(t) def= ρx(u) where u is an equivalent term in DNF.\nTheorem 3 Let P be a program over a signature 〈At,Lb〉 where Lb is a finite set of labels. Let Q be the result of removing from P all rules labelled by some ri ∈ Lb. Then, the result of removing ri from the justifications of some atom A with respect to program P are justifications of A with respect to Q, that is, ρ∼ri(WP(A))≤WQ(A)."
    }, {
      "heading" : "3 Relation to Causal Graph Justifications",
      "text" : "We discuss now the relation between ECJ and CG approaches. Intuitively, ECJ extends CG causal terms by the introduction of the new negation operator ‘∼’. Semantically, however, there are more differences than a simple syntactic extension. A first minor difference is that ECJ is defined in terms of a WFM, whereas CG defines (possibly) several causal stable models. In the case of stratified programs, this difference is irrelevant, since the WFM is complete and coincides with the unique stable model. A second, more important difference is that CG exclusively considers productive causes in the justifications, disregarding additional information like the inhibitors or\nenablers from ECJ. As a result, a false atom in CG has no justification – its causal value is 0 because there was no way to derive the atom. For instance, in program P1, the only CG stable model I just makes I(a) = 0 and we lose the inhibited justification ∼h · r2 (default r2 could not be applied). True atoms like p also lose any information about enablers: I(p) = d·r1 and nothing is said about ∼∼h. Another consequence of the CG orientation is that negative literals notA are never assigned a cause (different from 0 or 1), since they cannot be “derived” or produced by rules. In the example, we simply get I(nota) = 1 and I(not p) = 0.\nTo further illustrate the similarities and differences between ECJ and CG, consider the following program P4 capturing a variation of the Yale Shooting Scenario.\ndt+1 : deadt+1 ← shoott , loadedt , notabt\nlt+1 : loadedt+1 ← loadt\nat+1 : abt+1 ← watert\nloaded0\ndead0\nab0\nload1\nwater3\nshoot8\nplus the following rules corresponding inertia axioms\nFt+1 ← Ft , notF t+1 Ft+1 ← F t , notFt+1\nfor F ∈ {loaded, ab, dead}. Atoms of the form A represent the strong negation of A and we disregard models satisfying both A and A. Atom dead9 does not hold in the standard WFM of P4, and so there is no CG-justification for it. Note here the importance of default reasoning. On the one hand, the default flow of events is that the turkey, Fred, continues to be alive when nothing threats him. Hence, we do not need a cause to explain why Fred is alive. On the other hand, shooting a loaded gun would normally kill Fred, being this a cause of its death. But, in this example, another exceptional situation – water spilled out – has inhibited this existing threat and allowed the world to flow as if nothing had happened (that is, following its default behaviour).\nIn the CG-approach, dead9 is simply false by default and no justification is provided. However, a gun shooter could be “disappointed” since another conflicting default (shooting a loaded gun normally kills) has not worked. Thus, an expected answer for the shooter’s question “why notdead9?” is that water3 broke the default, disabling d9. In fact, ECJ yields the following inhibited justification for dead9:\nWP4 (dead9) = (∼water3 ∗ shoot8 ∗ load1·l2) ·d9 (7)\nmeaning that dead9 could not be derived because inhibitor water3 prevented the application of rule d9 to cause the death of Fred. Note that inertia rules are not labelled, which, as mentioned before, is syntactic sugar for rules with label 1. Since 1 is the identity of product and application, this has the effect of not being traced in the justifications. Note also that, according to Theorem 3, if we remove fact water3 (the inhibitor) from P4 leading to a new program P5, then we get:\nWP5 (dead9) = (shoot8 ∗ load1·l2) ·d9 (8)\nwhich is nothing else but the result of removing ∼water3 from (7). In fact, the only CG stable model of P5 makes this same assignment (8) which also corresponds to the causal graph depicted in Figure 3. In the general case, CG-justifications intuitively correspond to enabled justifications after forgetting all the enablers. Formally, however, there is one more difference in the definition of causal values: CG causal values are defined as ideals for the poset of a type of graphs formed by rule labels.\nDefinition 9 (Causal graph)\nGiven some set Lb of (rule) labels, a causal graph (c-graph) G ⊆ Lb× Lb is a reflexively and transitively closed set of edges. By GLb, we denote the set of causal graphs. Given two c-graphs G and G′, we write G ≤ G′ when G ⊇ G′.\nIntuitively, causal graphs, like G2 in Figure 3, are directed graphs representing the causal structure that has produced some event. Furthermore, G ≤ G′ means that G contains enough information to yield the same effect as G′, but perhaps more than needed (this explains G ⊇ G′). For this reason, we sometimes read G ≤ G′ as “G′ is stronger than G.” Causes will be ≤- maximal (or ⊆-minimal) causal graphs. Formally, including reflexive and transitive edges allows to capture this intuitive relation simply by the subgraph relation. Note that, since causal graphs are reflexively closed, every vertex has at least one edge (the reflexive one) and, thus, we can omit the set of vertices. Besides, for the sake of clarity, we only depict the minimum set of edges necessary for defining a causal graph (transitive and reflexive reduction). For instance, graph G2 in Figure 3 is the transitive and reflexive reduction of the causal graph G∗2.\nDefinition 10 (CG Values in Cabalar et al. 2014a) Given a set of labels Lb, a CG causal value is any ideal (or lower-set) for the poset 〈GLb,≤〉. By ICGLb , we denote the set of CG causal values. Product ‘∗’, sums ‘+’ and the ≤-order relation are defined as the set intersection, union and the subset relation, respectively. Application is given by U ·U ′ def= { G′′ ≤ G ·G′ ∣ ∣ G ∈U and G′ ∈U ′ }.\nIt has been shown in (Fandinno 2015a) that CG values can be alternatively characterised as a free algebra generated by rule labels under the axioms of a complete distributive lattice plus the axioms of Figure 1.\nDefinition 11 (CG Values in Fandinno 2015a) Given a set of labels Lb, a CG term is a term without negation ‘∼’. CG causal values are the equivalence classes of CG terms for a completely distributive (complete) lattice with meet ‘∗’ and join ‘+’ plus the axioms of Figure 1. By VCGLb , we denote the set of CG causal values.\nTheorem 4 (Causal values isomorphism from Fandinno 2015a) The function term : ICGLb −→ V CG Lb given by\nterm(U) 7→ ∑ G∈U ∏ (v1,v2)∈G v1·v2\nis an isomorphism between algebras 〈ICGLb ,+,∗, ·,GLb, /0〉 and 〈V CG Lb ,+,∗, ·,1,0〉.\nTheorem 4 states that CG causal values can be equivalently described either as ideals of causal graphs or as elements of an algebra of terms. Furthermore, by abuse of notation, by G we also denote the ideal whose maximum element is G, corresponding to term(G) as well. For instance, for the causal graph G2 in Figure 3, it follows G2 = term(G2) = term(↓G2) with ↓G2 the ideal whose maximum element is G2. Moreover, from the equivalences in Figure 1, it also follows that\nG2 = shoot8·d9 ∗ load1·l2 ∗ l2·d9 ∗ α = shoot8·d9 ∗ load1·l2 ∗ l2·d9\n= shoot8·d9 ∗ load1·l2·d9\n= (shoot8 ∗ load1·l2)·d9\nwhere α = load1·d9 ∗ shoot8·shoot8 ∗ d9·d9 ∗ load1·load1 ∗ l2·l2 ∗ d9·d9 is a term that, as we can see, can be ruled out and corresponds to the transitive and reflexive doted edges in G∗2. That is, justification (8) associated to atom dead9 by the causal well-founded model of program P5 actually corresponds to causal graph G2.\nTheorem 4 also formalises the intuition that opens this section: ECJ extends CG causal terms by the introduction of the new negation operator ‘∼’. We formalise next the correspondence between CG and ECJ justifications.\nDefinition 12 (CG mapping) We define a mapping λ c : VLb −→ VCGLb from ECJ values into CG values in the following recursive way:\nλ c(t) def=\n\n    \n    \nλ c(u)⊗λ c(w) if t = u⊗ v with ⊗ ∈ {+,∗, ·} 1 if t =∼∼l with l ∈ Lb\n0 if t = ∼l with l ∈ Lb\nl if t = l with l ∈ Lb\nNote that we have assumed that t is in DNF. Otherwise, λ c(t) def= λ c(u) where u is an equivalent term in DNF.\nFunction λ c maps every negated label ∼l to 0 (which is the annihilator of both product ‘∗’ and application ‘·’ and the identity of addition ‘+’). Hence λ c removes all the inhibited justifications. Furthermore λ c maps every doubly negated label ∼∼l to 1 (which is the identity of both product ‘∗’ and application ‘·’). Therefore λ c removes all the enablers (i.e. doubly negated labels ∼∼l) for the remaining (i.e. enabled) justifications.\nA CG interpretation is a mapping Ĩ : At −→ VCGLb . The value assigned to a negative literal notA by a CG interpretation Ĩ, denoted as Ĩ(not A), is defined as: Ĩ(notA) def= 1 if Ĩ(A) = 0; Ĩ(notA) def= 0 otherwise. A CG interpretation Ĩ is a CG model of rule like (4) iff\n( Ĩ(B1)∗ . . .∗ Ĩ(Bm)∗ Ĩ(notC1)∗ . . .∗ Ĩ(notCn) ) · ri ≤ Ĩ(H) (9)\nNotice that the value assigned to a negative literal by CG and ECJ interpretations is different. According to (Cabalar et al. 2014a), a CG interpretation Ĩ is a CG stable model of a program P iff Ĩ is the least model of the program PĨ . In the following, we provide an ECJ based characterisation of the CG stable models that will allow us to relate both approaches. By λ c(I) we will denote a CG interpretation Ĩ s.t. Ĩ(A) = λ c(I(A)) for every atom A.\nDefinition 13 (CG stable models) Given a program P, a CG interpretation Ĩ is a CG stable model of P iff there exists a fixpoint I of the operator Γ2P, i.e. ΓP(ΓP(I)) = I, such that Ĩ = λ c(I) = λ c(ΓP(I)).\nTheorem 5 Let P be a program over a signature 〈At,Lb〉 where Lb is a finite set of labels. Then, the CG stable models (Definition 13) are exactly the causal values and causal stable models defined in (Cabalar et al. 2014a).\nTheorem 5 shows that Definition 13 is an alternative definition of CG causal stable models. Furthermore, it settles that every causal model corresponds to some fixpoint of the operator Γ2P. Therefore, for every enabled justification there is a corresponding CG-justification common to all stable models. In order to formalise this idea we just take the definition of causal explanation from (Cabalar et al. 2014b).\nDefinition 14 (CG-justification) Given an interpretation I we say that a c-graph G is a (sufficient) CG-justification for an atom A iff term(G)≤ Ĩ(A).\nSince term(·) is a one-to-one correspondence, we can define its inverse graph(v) def= term−1(v) for all v ∈ VCGLb .\nTheorem 6 Let P be a program over a signature 〈At,Lb〉 where Lb is a finite set of labels. For any enabled justification E of some atom A w.r.t. WP, i.e. E ≤WP(A), there is a CG-justification G def= graph(λ c(E)) of A with respect to any stable model Ĩ of P.\nAs happens between the (standard) well-founded and stable model semantics, the converse of Theorem 6 does not hold in general. That is, we may get a justification that is common to all CG-stable models but does not occur in the ECJ well-founded model. For instance, let P6 be the program consisting on the following rules:\nr1 : a ← notb r2 : b ← nota, notc c r3 : c ← a r4 : d ← b, notd\nThe (standard) WFM of program P6 is two-valued and corresponds to the unique (standard) stable model {a,c}. Furthermore, there are two causal explanations of c with respect to this unique stable model: the fact c and the pair of rules r1·r3. Note that when c is removed {a,c} is still the unique stable model, but all atoms are undefined in the WFM. Hence, r1·r3 is a justification with respect to the unique stable model of the program, but not with respect to its WFM."
    }, {
      "heading" : "4 Relation to Why-not Provenance",
      "text" : "An evident similarity between ECJ and WnP approaches is the use of an alternating fixpoint operator (Van Gelder 1989) which has been actually borrowed from WnP. However, there are some slight differences. A first one is that we have incorporated from CG the non-commutative operator ‘·’ which allows capturing not only which rules justify a given atom, but also the dependencies among these rules. The second is the use of a non-classical negation ‘∼’ that is crucial to distinguish between productive causes and enablers. This distinction cannot be represented with the classical negation ‘¬’ in WnP since double negation can always be removed. Apart from the\ninterpretation of negation in both formalisms, there are other differences too. As an example, let us compare the justifications we obtain for dead9 in program P5. While for ECJ we obtained (8) (or graph G2 in Figure 3), the corresponding WnP justification has the form:\nl2 ∧d9 ∧ load1 ∧ shoot8\n∧not(ab1)∧not(ab2)∧ . . .∧not(ab7)∧not(water0)∧ . . .∧not(water6) (10)\nA first observation is that the subexpression l2∧d9∧ load1∧shoot8 constitutes, informally speaking, a “flattening” of (8) (or graph G2) where the ordering among rules has been lost. We get, however, new labels of the form not(A) meaning that atom A is required not to be a program fact, something that is not present in CG-justifications. For instance, (10) points out that water can not be spilt on the gun along situations 0, . . . ,7. Although this information can be useful for debugging (the original purpose of WnP) its inclusion in a causal explanation is obviously inconvenient from a Knowledge Representation perspective, since it explicitly enumerates all the defaults that were applied (no water was spilt at any situation) something that may easily blow up the (causally) irrelevant information in a justification.\nAn analogous effect happens with the enumeration of exceptions to defaults, like inertia. Take program P7 obtained from P4 by removing all the performed actions, i.e., facts load1, water3, and shoot7. As expected, Fred will be alive, deadt , at any situation t by inertia. ECJ will assign no cause for deadt , not even any inhibited one, i.e. WP(deadt) = 1 and WP(deadt) = 0 for any t. The absence of labels in WP(deadt) = 1 is, of course, due to the fact that inertia axioms are not labelled, as they naturally represent a default and not a causal law. Still, even if inertia were labelled, say, with ink per each situation k, we would obtain a unique cause for WP(deadt) = in1 · . . . · int for any t > 0 while maintaining no cause for WP(deadt) = 0. However, the number of minimal WnP justifications of deadt grows quadratically, as it collects all the plans for killing Fred in t steps loading and shooting once. For instance, among others, all the following:\nd9 ∧¬not(load0)∧ r2 ∧¬not(shoot1)∧not(water0)∧ not(ab1)\nd9 ∧¬not(load0)∧ r2 ∧¬not(shoot2)∧not(water0)∧not(water1)∧not(ab1)∧not(ab2)\nd9 ∧¬not(load1)∧ r2 ∧¬not(shoot3)∧not(water0)∧\n∧ not(water1) ∧not(water2)∧ not(ab1) ∧not(ab2)∧not(ab3)\n. . .\nare WnP-justifications for dead9. The intuitive meaning of expressions of the form ¬not(A) is that dead9 can be justified by adding A as a fact to the program. For instance, the first conjunction means that it is possible to justify dead9 by adding the facts load0 and shoot1 and not adding the fact water0. We will call these justifications, which contain a subterm of the form ¬not(A), hypothetical in the sense that they involve some hypothetical program modification.\nDefinition 15 (Provenance values) Given a set of labels Lb, a provenance term t is recursively defined as one of the following expressions t ::= l | ∏S | ∑S | ¬t1 where l ∈ Lb, t1 is in its turn a provenance term and S is a (possibly empty and possible infinite) set of provenance terms. Provenance values are the equivalence classes of provenance terms under the equivalences of the Boolean algebra. We denote by BLb the set of provenance values over Lb.\nInformally speaking, with respect to ECJ, we have removed the application ‘·’ operator, whereas product ‘∗’ and addition ‘+’ hold the same equivalences as in Definition 2 and negation ‘∼’\nhas been replaced by ‘¬’ from Boolean algebra. Thus, ‘¬’ is classical and satisfies all the axioms of ‘∼’ plus ¬¬t = t. Note also that, in the examples, we have followed the convention from (Damásio et al. 2013) of using the symbols ‘∧’ and ∨ to respectively represent meet and join. However, in formal definitions, we will keep respectively using ‘∗’ and ‘+’ for that purpose. We define a mapping λ p : VLb −→ BLb in the following recursive way:\nλ p(t) def=\n\n    \n     λ p(u)⊗λ p(w) if t = u⊗ v with ⊗ ∈ {+,∗} λ p(u) ∗ λ p(w) if t = u · v ¬λ p(u) if t =∼u l if t = l with l ∈ Lb\nDefinition 16 (Provenance) Given a program P, the why-not provenance program P(P) def= P∪P′ where P′ contains a labelled fact of the form (∼not(A) : A) for each atom A ∈ At not occurring in P as a fact. We will write P instead of P(P) when the program P is clear by the context. We denote by WhyP(L) def= λ p(WP(L)) the why-not provenance of a q-literal L. We also say that a justification is hypothetical when not(A) occurs oddly negated in it, non-hypothetical otherwise.\nTheorem 7 Let P be program over a finite signature 〈At,Lb〉. Then, the provenance of a literal according to Definition 16 is equivalent to the provenance defined by (Damásio et al. 2013).\nTheorem 8 Let P be program over a finite signature 〈At,Lb〉.WP is the result of removing all non-hypothetical justification from WP and each occurrence of the form ∼∼not(A) for the remaining ones, that is, WP = ρ(WP) where ρ is the result of removing every label of the form not(A), that is ρ is the composition of ρnot(A1) ◦ρnot(A2) ◦ . . .◦ρnot(An) with At = {A1,A2, . . . ,An}.\nOn the one hand, Theorem 7 shows that the provenance of a literal can be obtained by replacing the negation ‘∼’ by ‘¬’ and ‘·’ by ‘∗’ in the causal WFM of the augmented program P. On the other hand, Theorem 8 asserts that non-hypothetical justifications of a program and its augmented one coincide when subterms of the form ∼∼not(A) are removed from justifications of the latter. Consequently, we can establish the following correspondence between the ECJ justifications and the non-hypothetical WnP justifications.\nTheorem 9 Let P be program over a finite signature 〈At,Lb〉. Then, the ECJ justifications of some atom A (after replacing “·” by “∗” and “∼” by “¬”) correspond to the WnP justifications of A (after removing every label of the form not(B) with B ∈ At), that is, λ p(WP)(A) = ρ(WhyP)(A) where ρ is the result of removing every label of the form not(A) as in Theorem 8.\nTheorem 9 establishes a correspondence between non-hypothetical WnP-justifications and (flattened) ECJ justifications. In our running example, (7) is the unique causal justification of dead9, while (11) (below) is its unique non-hypothetical WnP justification.\n¬water3 ∧ shoot8 ∧ load1 ∧ l2 ∧d9 ∧\n∧not(dead1)∧ . . .∧not(dead9)∧not(ab1)∧ . . .∧not(ab8) (11)\nIt is easy to see that, by applying λ p to (7) we obtain\nλ p ( (∼water3 ∗ shoot8 ∗ load1·l2) ·d9 ) = ¬water3 ∧ shoot8 ∧ load1 ∧ l2 ∧d9 (12)\nwhich is just the result of removing all labels of the form ‘not(A)’ from (11). The correspondence between the ECJ justification (8) and the WnP justification (10) for program P5 can be easily checked in a similar way.\nHypothetical justifications are not directly captured by ECJ, but can be obtained using the augmented program P as stated by Theorem 7. As a byproduct we establish a formal relation between WnP and CG.\nTheorem 10 Let P be a program over a finite signature 〈At,Lb〉. Then, every non-hypothetical and enabled WnP-justification D of some atom A (after removing every label of the form not(B) with B ∈ At) is a justification with respect to every CG stable model Ĩ (after replacing “·” by “∗” and “∼” by “¬”), that is D ≤ W hyP(A) implies ρ(D) ≤ λ p(Ĩ)(A) where ρ is the result of removing every label of the form not(B) as in Theorem 8.\nNote that, as happened between the ECJ and CG justifications, the converse of Theorem 10 does not hold in general due to the well-founded vs stable model difference in their definitions. As an example, the explanation for atom c at program P6 has a unique WnP justification c as opposed to the two CG justifications, c and r1·r3."
    }, {
      "heading" : "5 Contributory causes",
      "text" : "Intuitively, a contributory cause is an event that has helped to produce some effect. For instance, in program P5, it is easy to identify both actions, load1 and shoot8, as events that have helped to produce dead9 and, thus, they are both contributory causes of Fred’s death. We may define the above informal concept of contributory cause as: any non-negated label l that occurs in a maximal enabled justification of some atom A. Similarly, a contributory enabler can be defined as a doubly negated label ∼∼l that occurs in a maximal enabled justification of some atom A. These definitions correctly identify load1 and shoot8 as contributory causes of dead9 in program P5 and d as a contributory cause of p in program P1. Fact h is considered a contributory enabler of p. These definitions will also suffice for dealing with what Hall (2007) calls trouble cases: nonexistent threats, short-circuits, late-preemption and switching examples.\nIt is worth to mention that, in the philosophic and AI literature, the concept of contributory cause is usually discussed in the broader sense of actual causation which tries to provide an unique everyday-concept of causation. Pearl (2000) studied actual and contributory causes relying on causal networks. In this approach, it is possible to conclude cause-effect relations like “A has been an actual (resp. contributory) cause of B” from the behaviour of structural equations by applying, under some contingency (an alternative model in which some values are fixed) the counterfactual dependence interpretation from (Hume 1748): “had A not happened, B would not have happened.” Consider the following example which illustrates the difference between contributory and actual causes under this approach.\nExample 1 (Firing Squad) Suzy and Billy form a two-man firing squad that responds to the order of the captain. The shot of any of the two riflemen would kill the prisoner. Indeed, the captain gives the order, both riflemen shoot together and the prisoner dies.\nOn the one hand, the captain is an actual cause of the prisoner’s death: “had the captain not given the order, the riflemen would not have shot and the prisoner would not have died.” On the other hand, each rifleman alone is not an actual cause: “had one rifleman not shot, the prisoner would have died anyway because of the other rifleman.” However, each rifleman’s shot is a contributory cause because, under the contingency where the other rifleman does not shoot, the prisoner’s death manifests counterfactual dependence on the first rifleman’s shot. Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner’s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen’s shoots, but not each of them alone, as actual causes. We will focus here on representing the above concept of contributory cause and leave to the reader whether this agrees with the concept of cause in the every-day discourse or not.\nAs has been slightly discussed in the introduction, Hall (2004; 2007), has emphasized the difference between two types of causal relations: dependence and production. The former relies on the idea that “counterfactual dependence between wholly distinct events is sufficient for causation.” The latter is characterised by being transitive, intrinsic (two processes following the same laws must be both or neither causal) and local (causes must be connected to their effects via sequences of causal intermediates).\nThese two concepts can be illustrated in Bond’s example by observing the difference between pouring the drug (atom d), which is a cause under both understandings, and being a holiday (atom h), which is not considered a cause under the production viewpoint, although it is considered a cause under the dependence one.\nIn this sense, all the above approaches to actual causation, but (Hall 2004), can be classified in the dependence category. ECJ and CG do not consider h a productive cause of d because the default (or normal) behaviour of rule (1) is that “d causes p.” This default criterion is also shared by (Hall 2007; Halpern 2008; Hitchcock and Knobe 2009; Halpern and Hitchcock 2011). Note that, ECJ (but not CG) captures the fact that d counterfactually depends on h, as it considers it an enabler. In (Hall 2004), the author relies on intrinsicness for rejecting h as a productive cause of d: any causal structure (justification) including h and p would have to include the absence of the antidote (atom a), and it would be enough that Bond had taken the antidote by another reason to break the counterfactual dependence between h and p. By applying the above contributory cause definition to the WnP justification h∧d ∧ r1 of Bond’s paralysis (atom p) in program P1, we can easily identify that h is being considered a cause in WnP, thus, a causal interpretation of WnP clearly follows the dependence-based viewpoint. On the other hand, the unique CG justification d·r1 only considers d as a cause, which illustrates the fact that CG is mostly related to the concept of production. ECJ combines both understandings, and what is a cause under the dependence viewpoint is either an enabler or a cause under the production viewpoint.\nIn order to illustrate how ECJ can be used for representing the so-called non-existent threat scenarios, consider a variation of Bond’s example where today is not a holiday and, thus, Bond takes the antidote. The poured drug d is a threat to Bond’s safety, represented as s, but that threat is prevented by the antidote. We may represent this scenario by program P8 below:\nr1 : p ← d,nota\nr2 : a ← noth\nr3 : s ← not p\na\nd\nThe causal WFM of program P8 assigns\nWP8 (s) = ∼∼r2·r3 + ∼d·r3 + ∼r1·r3\nwhich recognises rule r2 (taking the antidote) as a contributory enabler of Bond’s safety. The difficulty in this kind of scenarios consists in avoiding the wrong recognition of r2 as an enabler when the threat d does not exist. If we remove fact d from P8 to get the new program P9 then we obtain that WP9 (d) = 0 and, consequently,WP9 (s) = r3. Intuitively, in the absence of any threat, Bond is just safe because that is his default behaviour as stated by rule r3. Short-circuit examples consist in avoiding the wrong recognition of an event as a contributory enabler that provokes a threat that eventually prevents itself. Consider the program P10 below:\nr1 : p ← a, not f\nr2 : f ← c, notb\nr3 : b ← c\na\nc\nHere, c is a threat to p, since it may cause f through rule r2. However, c eventually prevents r2, since it also causes b through rule r3. The causal WFM of program P10 assigns\nWP10(p) = (a ∗∼∼r3)·r1 + (a ∗∼r2)·r1 + (a ∗∼c)·r1\nwhich correctly avoids considering c as a contributory enabler of p and recognises r3 as the enabler of p. Note that c is actually considered an inhibitor due to justification (a∗∼c)·r1 pointing out that, had c not happened, then a·r1 would have been an enabled justification. But then, (a ∗∼∼r3)·r1 would stop being a justification since (a ∗∼∼r3)·r1 + a·r1 = a·r1.\nTo illustrate late-preemention consider the following example from (Lewis 2000).\nExample 2 (Rock Throwers)\nBilly and Suzy throw rocks at a bottle. Suzy throws first and her rock arrives first. The bottle shattered. When Billy’s rock gets to where the bottle used to be, there is nothing there but flying shards of glass. Who has caused the bottle to shatter?\nThe key of this example is to recognise that Suzy, and not Billy, has caused the shattering. The usual way of representing this scenario in the actual causation literature is by introducing two new fluents hit suzy and hit billy in the following way (Hall 2007; Halpern and Hitchcock 2011; Halpern 2014; Halpern 2015):\nhit suzy ← throw suzy (13)\nhit billy ← throw billy, ¬hit suzy (14)\nshattered ← hit suzy (15)\nshattered ← hit billy (16)\nIt is easy to see that such a representation mixes, in law (14), both the description of the world and the narrative fact asserting that Suzy threw first. This may easily lead to a problem of elaboration tolerance. For instance, if we have N shooters and they shoot sequentially we would have to modify the equations for all of them in an adequate way, so that the last shooter’s equation would have the negation of the preceding N-1 and so on. Moreover, all these equations would have to be reformulated if we simply change the shooting order. On the other hand, we may represent\nthis scenario by a program P11 consisting of the following rules\nst+1 : shatteredt+1 ← throw(A)t , not shatteredt\nshattered0\nthrow(suzy)0\nthrow(billy)1\nwith A ∈ {suzy, billy}, plus the following rules corresponding to the inertia axioms\nshatteredt+1 ← shatteredt, not shatteredt+1\nshatteredt+1 ← shatteredt , not shatteredt+1\nAtom shattered2 holds in the standard WFM of P11 and its justification corresponds to\nthrow(suzy)0·s1 + (∼throw(suzy)∗ throw(billy)1)·s2 + (∼s1 ∗ throw(billy)1)·s2\nOn the one hand, the first addend points out that fact throw(suzy)0 has caused shattered2 by means of rule s1. On the other hand, the second addend indicates that throw(billy)1 has not caused it because Suzy’s throw has prevented it. Finally, the third addend means that throw(billy)1 would have caused the shattering if it were not for rule s1. This example shows how our semantics is able to recognise that it was Suzy, and not Billy, who caused the bottle shattering. Furthermore, it also explains that Billy did not cause it because Suzy did it first.\nFinally, consider the following example from (Hall 2000).\nExample 3 (The Engineer) An engineer is standing by a switch in the railroad tracks. A train approaches in the distance. She flips the switch, so that the train travels down the right-hand track, instead of the left. Since the tracks reconverge up ahead, the train arrives at its destination all the same; let us further suppose that the time and manner of its arrival are exactly as they would have been, had she not flipped the switch.\nThis has been a controversial example. In (Hall 2000), the author has argued that the switch should be considered a cause of the arrival because switch has contributed to the fact that the train has travelled down the right-hand track. In a similar manner, it seems clear that the train travelling down the right-hand track has contributed to the train arrival. If causality is considered to be a transitive relation, as (Hall 2000) does, the immediate consequence of the above reasoning is that flipping the switch has contributed to the train arrival. In (Hall 2007) he argues otherwise and points out that commonsense tells that the switch is not a cause of the arrival. (Halpern and Pearl 2005) had considered switch a cause of arrival depending on whether the train travelling down the tracks is represented by one or two variables in the model. Although our understanding of causality is closer to the one expressed in (Hall 2007), it is not the aim of this work to go more in depth in this discussion, but to show instead how both understandings can be represented in ECJ. Consider the following program P12\nr1 : arrival ← right\nr2 : arrival ← le f t\nr3 : right ← train, not switch\nr4 : le f t ← train, not switch\nswitch ← not switch\nswitch ← not switch\ntrain\nswitch\nwhere switch represents the strong negation of switch. The two unlabelled rules capture the idea that the switch behaves classically, that is, it must be activated or not. The literal not switch in the body of rule r3 points out that the switch position is an enabler and not a cause of the track\ntaken by the train. This representation can be arguable, but the way in which the rule has been written would be expressing that if a train is coming, then a train will cross the right track by default unless switch prevents it. In that sense, the only productive cause for right (a train in the right track) is train (a train is coming) whereas the switch position just enables the causal rule to be applied. A similar default r4 is built for the left track, flipping the roles of switch and switch.\nThe causal WFM of program P12 corresponds to\nWP12 (arrival) = (train ∗∼∼switch)·r3·r1 + (train ∗∼switch)·r4·r2\nIt is easy to see that switch is a doubly-negated label occurring in the maximal enabled justification E1 = (train ∗∼∼switch)·r3·r1 and, thus, we may identify it as a contributory enabler of arrival, but not its productive cause. On the other hand, by looking at the inhibited justification E2 = (train∗∼switch)·r4·r2, we observe that switch is also preventing rules r4 and r2 to produce the same effect, arrival, that is helping to produce in E1.\nIf we want to ignore the way in which the train arrives, one natural possibility is using the same label for all the rules for atom arrival, reflecting in this way that we do not want to trace whether r1 or r2 has been actually used. Suppose we label r2 with r1 instead, leading to the new program P13\nr1 : arrival ← right\nr1 : arrival ← le f t\nr3 : right ← train, not switch\nr3 : le f t ← train, not switch\nswitch ← not switch\nswitch ← not switch\ntrain\nswitch\nwhose causal WFM corresponds to\nWP12 (arrival) = (train ∗∼∼switch)·r3·r1 + (train ∗∼switch)·r3·r1 = train·r3·r1\nAs we can see, this justification does not consider switch at all as a cause of the arrival (nor even a contributory enabler, as before). In other words, switch is irrelevant for the train arrival, which probably coincides with the most common intuition.\nHowever, we do not find this solution fully convincing yet, because the explanation we obtain for right,WP13\n(right)= (train∗∼∼switch)·r3 is showing that switch is just acting as an enabler, as we commented before. If we wanted to represent switch as a contributory cause of right, we would have more difficulties to simultaneously keep switch irrelevant in the explanation of arrival. One possibility we plan to explore in the future is allowing the declaration of a given atom or fluent, like our switch, as classical so that we include both, the the rule:\nswitch ← notnotswitch\nin the logic program3 and the axiom ∼∼switch = switch in the algebra. The latter immediately implies switch+∼switch = 1 (due to the weak excluded middle axiom).\n3 This implication actually corresponds to a choice rule 0{switch}1, commonly used in Answer Set Programming.\nThen, P13 could be simply expressed as\nr1 : arrival ← right\nr1 : arrival ← le f t\nr3 : right ← train, switch\nr3 : le f t ← train, not switch\ntrain\nswitch\nand the justification of right and le f t would become\nWP(right) = (train ∗ switch)·r3 WP(le f t) = (train ∗∼switch)·r3\npointing out that switch is a cause (resp. an inhibitor) of the train travelling down the right (resp. left) track. Then, the justification of arrival would be\nWP(arrival) = (train ∗ switch)·r3·r1 + (train ∗∼switch)·r3·r1 = train·r3·r1\nWe leave the study of this possibility for a future deeper analysis."
    }, {
      "heading" : "6 Conclusions and other related work",
      "text" : "In this paper we have introduced a unifying approach that combines causal production with enablers and inhibitors. We formally capture inhibited justifications by introducing a “non-classical” negation ‘∼’ in the algebra of causal graphs (CG). An inhibited justification is nothing else but an expression containing some negated label. We have also distinguished productive causes from enabling conditions (counterfactual dependences that are not productive causes) by using a double negation ‘∼∼’ for the latter. The existence of enabled justifications is a sufficient and necessary condition for the truth of a literal. Furthermore, our justifications capture, under the WellFounded Semantics, both Causal Graph and Why-not Provenance justifications. As a byproduct we established a formal relation between these two approaches.\nWe have also shown how several standard examples from the literature on actual causation can be represented in our formalism and illustrated how this representation is suitable for domains which include dynamic defaults – those whose behaviour are not predetermined, but rely on some program condition – as for instance the inertia axioms. As pointed out by (Maudlin 2004), causal knowledge can be structured by a combination of inertial laws – how the world would evolve if nothing intervened – and deviations from these inertial laws.\nIn addition to the literature on actual causes cited in Section 5, our work also relates to papers on reasoning about actions and change (Lin 1995; McCain and Turner 1997; Thielscher 1997). These works have been traditionally focused on using causal inference to solve representational problems (such as, the frame, ramification and qualification problems) without paying much attention to the derivation of cause-effect relations. Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013). The most important difference of these works with respect to ECJ, and also WnP and CG, is that the last three provide fully algebraic semantics in which justifications are embedded into program models. A formal relation between (Pontelli et al. 2009) and WnP was established in (Damásio et al. 2013) and so, using Theorems 7 and 9, it can be directly extended to ECJ, but at the cost of flattening the graph information (i.e. losing the order among rules).\nInteresting issues for future study are incorporating enabled and inhibited justifications to the\nstable model semantics and replacing the syntactic definition in favour of a logical treatment of default negation, as done for instance with the Equilibrium Logic (Pearce 1996) characterisation of stable models. Other natural steps would be the consideration of syntactic operators, for capturing more specific knowledge about causal information as done in (Fandinno 2015b) capturing sufficient causes in the CG approach, and also the representation of non-deterministic causal laws, by means of disjunctive programs or the incorporation of probabilistic knowledge.\nAcknowledgements We are thankful to Carlos Damásio for his suggestions and comments on earlier versions of this work. We also thank the anonymous reviewers for their help to improve the paper. This research was partially supported by Spanish Project TIN2013-42149-P."
    }, {
      "heading" : "Appendix A. Auxiliary figures",
      "text" : "Associativity\nt + (u+w) = (t+u) + w t ∗ (u∗w) = (t ∗u) ∗ w\nCommutativity\nt + u = u + t t ∗ u = u ∗ t\nAbsorption\nt = t + (t ∗u) t = t ∗ (t+u)\nDistributive\nt + (u∗w) = (t+u) ∗ (t+w) t ∗ (u+w) = (t ∗u) + (t ∗w)\nIdentity\nt = t + 0 t = t ∗ 1\nIdempotency\nt = t + t t = t ∗ t\nAnnihilator\n1 = 1 + t 0 = 0 ∗ t\nFig. A 1. Sum and product satisfy the properties of a completely distributive lattice."
    }, {
      "heading" : "Appendix B. Proofs of Theorems and Implicit Results",
      "text" : "In the following, by abuse of notation, for every function f : VLb −→ VLb, we will also denote by f a function over the set of interpretations such that f (I)(A) = f (I(A)) for every atom A ∈ At. We have organized the proofs into different subsections."
    }, {
      "heading" : "Appendix B.1. Proofs of Propositions 1 to 3",
      "text" : "Proposition 1 Negation ‘∼’ is anti-monotonic. That is t ≤ u holds if and only if ∼t ≥ ∼u for any given two causal terms t and u.\nProof . By definition t ≤ u iff t ∗u= t. Furthermore, by De Morgan laws, ∼(t ∗u) =∼t+∼u and, thus, ∼(t ∗ u) = ∼t iff ∼t +∼u = ∼t. Finally, just note that ∼t +∼u = ∼t iff ∼t ≥ ∼u. Hence, t ≤ u holds iff ∼t ≥∼u.\nProposition 2 The map t 7→ ∼∼t is a closure. That is, it is monotonic, idempotent and it holds that t ≤∼∼t for any given causal term t.\nProof . To show that t 7→ ∼∼t is monotonic just note that t 7→ ∼t is antimonotonic (Proposition 1) and then t ≤ u iff ∼t ≥ ∼u iff ∼∼t ≤ ∼∼u. Furthermore, ∼∼(∼∼t) = ∼(∼∼∼t) = ∼∼t, that\nis, t 7→ ∼∼t is idempotent. Finally, note that, by definition, t ≤∼∼t iff t ∗∼∼t = t and\nt ∗∼∼t = t ∗∼∼t + 0 (identity)\n= t ∗∼∼t + t ∗∼t (pseudo-complement)\n= (t ∗∼∼t + t)∗ (t ∗∼∼t +∼t) (distributivity)\n= (t + t) ∗ (∼∼t + t) ∗ (t +∼t) ∗ (∼∼t +∼t) (distributivity)\n= t ∗ (∼∼t + t) ∗ (t +∼t) ∗ (∼∼t +∼t) (idempotency)\n= t ∗ (t +∼t) ∗ (∼∼t + t) ∗ 1 (w. excluded middle)\n= t ∗ (t +∼t) ∗ (∼∼t + t) (identity)\n= t ∗ (∼∼t + t) (absorption)\n= t (absorption)\nHence, t 7→ ∼∼t is a closure.\nProposition 3 Given any term t, it can be rewritten as an equivalent term u in negation and disjuntive normal forms.\nProof . This is a trivial proof by structural induction using the DeMorgan laws and negation of application axiom. Furthermore, using the axiom ∼∼∼t = t no more than two nested negations are required. Furthermore, it is easy to see that by applying distributivity of “·” and “∗” over “+,” every term can be equivalently represented as a term “+” is not in the scope of any other operation. Moreover, applying distributivity of “·” over “∗” every such term can be represented as one in every application subterm is elementary.\nLemma B.1 Let t be a join irreducible causal value. Then, either t ∗∼∼u = 0 or t ∗∼∼u is join irreducible for every causal value u ∈ VLb.\nProof . Suppose that t ∗ u is not join irreducible and let W ⊆ VLb a set of causal values such that w 6= t ∗∼∼u for every w ∈ W and t ∗∼∼u = ∑w∈W w. Since t ∗∼∼u = ∑w∈W w, it follows that w ≤ t ∗∼∼u for every w ∈ W and, since w 6= t ∗∼∼u, it follows that w < t ∗∼∼u for every w ∈W . Furthermore, t ∗∼∼u+ t ∗∼u = t ∗ (∼∼u+∼u) = t.\nSince t is join irreducible, it follows that either t = t ∗∼∼u or t = t ∗∼u. If t = t ∗∼u, then t ∗∼∼u = (t ∗∼u)∗∼∼u = 0. Otherwise, t = t ∗∼∼u and t is join irreducible by hypothesis.\nLemma B.2 Let t be a term. Then λ p(∼t) = ¬λ p(t).\nProof . We proceed by structural induction assuming that t is in negated normal form. In case that t = a is elementary, it follows that λ p(∼a) = ¬a = ¬λ p(a). In case that t = ∼a with a elementary, λ p(∼t) = λ p(∼∼a) and λ p(∼∼a) = a = ¬¬a = ¬λ p(∼a) = λ p(t). In case that t =∼∼a, with a elementary, λ p(∼t) = λ p(∼∼∼a) and\nλ p(∼∼∼a) = λ p(∼a) = ¬a = ¬λ p(∼∼a) = ¬λ p(t)\nIn case that t = u+ v. Then\nλ p(∼t) = λ p(∼u ∗∼v) = λ p(∼u)∧λ p(∼v)\nBy induction hypothesis λ p(∼u) = ¬λ p(u) and λ p(∼v) = ¬λ p(v) and, therefore, it holds that λ p(∼t) = ¬λ p(u)∧¬λ p(v). Thus, ¬λ p(t) = ¬(λ p(u)∨λ p(v)) = ¬λ p(u)∧¬λ p(v) = λ p(∼t).\nIn case that t = u⊗ v with ⊗ ∈ {∗, ·}. Then λ p(∼t) = λ p(∼u+∼v) = λ p(∼u)∨ λ p(∼v) and by induction hypothesis λ p(∼u) = ¬λ p(u) and λ p(∼v) = ¬λ p(v). Consequently it holds that λ p(∼t) = ¬λ p(t).\nLemma B.3 Let t be a term and φ a provenance term. If φ ≤ λ p(t), then λ p(∼t)≤¬φ and if λ p(t)≤ φ , then ¬φ ≤ λ p(∼t).\nProof . If φ ≤ λ p(t), then φ = λ p(t) ∗ φ and then ¬φ = ¬λ p(t) +¬φ and, by Lemma B.2, it follows that ¬φ = λ p(∼t) +¬φ . Hence λ p(∼t) ≤ ¬φ . Furthermore if λ p(t) ≤ φ , then φ = λ p(t)+ φ and then ¬φ = ¬λ p(t) ∗¬φ and, by Lemma B.2, it follows that ¬φ = λ p(∼t) ∗¬φ . Hence ¬φ ≤ λ p(∼t)."
    }, {
      "heading" : "Appendix B.2. Proof of Theorem 1",
      "text" : "The proof of Theorem 1 will relay on the definition of the following direct consequence operator\nT̃P(Ĩ)(H) def= ∑\n{ ( Ĩ(B1)∗ . . .∗ Ĩ(Bn) ) · ri | (ri : H ← B1, . . . ,Bn) ∈ P }\nfor any CG interpretation Ĩ and atom H ∈ At. Note that the definition of this direct consequence operator T̃P is analogous to the TP operator, but the domain and image of T̃P are the set of CG interpretations while the domain and image of TP are the set of ECJ interpretations.\nTheorem 11 (Theorem 2 from Cabalar et al. 2014a) Let P be a (possibly infinite) positive logic program with n causal rules. Then, (i) lfp(T̃P) is the least model of P, and (ii) lfp(T̃P) = T̃P ↑ω (0) = T̃P ↑n (0).\nProof of Theorem 1. Assume that every term occurring in P is NNF and let Q be the program obtained by renaming in P each occurrence of ∼l as l′ and each occurrence of ∼∼l as l′′ with l′ and l′′ new symbols. Note that this renaming implies that ∼l and ∼∼l are treated as completely independent symbols from l and, thus, all equalities among terms derived from program Q are also satisfied by P, although the converse does not hold. Note also that, since ∼ does not occur in Q, this is also a CG program. From Theorem 11, lfp(T̃Q) = T̃Q ↑ω (0) is the least model of Q. By renaming back l′ and l′′ as ∼l and ∼∼l in T̃Q ↑k (0) we obtain TP ↑k (0) for any k. Hence, lfp(TP) = TP ↑ω (0) is the least model of P. Statement (ii) is proved in the same manner.\nAppendix B.3. Proof of Proposition 4\nLemma B.4 Let P1 and P2 be two programs and let U1 and U2 be two interpretations such that P1 ⊇ P2 and U1 ≤U2. Let also I1 and I2 be the least models of P U1 1 and P U2 2 , respectively. Then I1 ≥ I2.\nProof . First, for any rule ri and pair of interpretations J1 and J2 such that J1 ≥ J2,\nJ1(body +(rU1i )) ≥ J2(body +(rU2i ))\nFurthermore, since U1 ≤U2, by Proposition 1, it follows\nU1(body −(rU1i )) ≥ U2(body −(rU2i ))\nand, since by Definition 5 J j(body−(r U1 i )) def= U j(body−(r U1 i )), it follows that\nJ1(body −(rU1i )) ≥ J2(body −(rU2i ))\nHence, we obtain that J1(body(r U1 i ))≥ J2(body(r U2 i )).\nSince P1 ⊇ P2, it follows that every rule ri ∈ P2 is in P1 as well. Thus, TPU11 (J1)(H)≥ TPU22 (J2)(H) for every atom H. Furthermore, since\nT P\nU1 1\n↑0 (0)(H) = T P\nU2 2\n↑0 (0)(H) = 0\nit follows T P\nU1 1\n↑i (0)(H) ≥ T P\nU2 2\n↑i (0)(H) for all 0 ≤ i. Finally,\nT P\nUj j ↑ω (0)(H) def= ∑ i≤ω T P Uj j ↑i (0)(H) = 0\nand hence T P\nU1 1\n↑ω (0)(H) ≥ T P\nU2 2\n↑ω (0)(H). By Theorem 1, these are respectively the least\nmodels of PU11 and P U2 2 . That is I1 ≥ I2.\nProposition 4 ΓP operator is anti-monotonic and operator Γ2P is monotonic. That is, ΓP(U1) ≥ ΓP(U2) and Γ2P(U1)≤ Γ2P(U2) for any pair of interpretations U1 and U2 such that U1 ≤U2.\nProof . Since U1 ≤ U2, by Lemma B.4, it follows I1 ≥ I2 with I1 and I2 being respectively the least models of PU1 and PU2 . Then, ΓP(U1) = I1 and ΓP(U2) = I2 and, thus, ΓP(U1) ≥ ΓP(U2). Since ΓP is anti-monotonic it follows that Γ2P is monotonic."
    }, {
      "heading" : "Appendix B.4. Proof of Theorem 2",
      "text" : "The proof of Theorem 2 will rely on the relation between ECJ justifications and non-hypothetical WnP justifications established by Theorem 9 and it can be found below the proof of that theorem in page 36.\nAppendix B.5. Proof of Theorem 3\nDefinition 17 A term t ∈ VLb is join irreducible iff t = ∑u∈U u implies that u = t for some u ∈U and it is join prime iff t ≤ ∑u∈U u implies that u ≤ t for some u ∈U .\nProposition 5 The following results hold:\n1. A term is join irreducible iff is join prime. 2. If Lb is finite, then every term t can be represented as a unique finite sum of pairwise\nincomparable join irreducible terms.\nProof . The first result directly follows from Theorem 1 in (Balbes and Dwinger 1975, page 65). Furthermore, from Theorem 2 in (Balbes and Dwinger 1975, page 66), in every distributive lattice satisfying the descending chain condition, any element can be represented as a unique finite sum of pairwise incomparable join irreducible elements and it is clear that every finite lattice satisfies the descending chain condition.\nLemma B.5 Let P be a positive program over a signature 〈At,Lb〉 where Lb is a finite set of labels and Q be the result of removing all rules labelled by some label l ∈ Lb. Let I and J be two interpretations such that J such that ρ∼l(I)≥ J. Then, ρ∼l(ΓP(I))≤ ΓQ(J).\nProof . By definition ΓP(I) and ΓQ(J) are the least models of programs PI and QJ , respectively. Furthermore, from Theorem 1, the least model of any program P is the least fixpoint of the TP operator, that is, ΓX (Y ) = TXY ↑ω (0) with X ∈ {P,Q} and XY ∈ {PI,PJ}. Then, the proof follows by induction assuming that u ≤ TQJ ↑\nβ (0)(H) implies ρ∼l(u) ≤ TQI ↑β (0)(H) for any join irreducible u, atom H and every ordinal β < α .\nNote that TQJ ↑ 0 (0)(H) = 0 = ρ∼l(0) = TPI ↑0 (0)(A) for any atom H and, thus, the statement holds vacuous.\nIf α is a successor ordinal, since u ≤ TPI ↑α (0)(H), there is a rule in P of the form (4) such that\nu ≤ (uB1 ∗ . . .∗ uBm ∗ uC1 ∗ . . .∗ uCn) · ri\nwhere uB j ≤ TPI ↑ α−1 (0)(B j) and uC j ≤∼I(C j) for each positive literal B j and each negative literal not C j in the body of rule ri. Then,\n1. By induction hypothesis, it follows that ρ∼l(uB j)≤ TQJ ↑α−1 (0)(B j), and 2. from ρ∼l(I(H))≥ J(H), it follows that uC j ≤∼I(C j) implies ρ∼l(uC j )≤∼J(C j).\nFurthermore, if ri 6= l, then ri ∈ Q and, thus,\nρ∼l(u) ≤ (ρ∼l(uB1)∗ . . .∗ρ∼l(uBm)∗ρ∼l(uC1)∗ . . .∗ρ∼l(uCn)) · ri ≤ TQJ ↑ α (0)(H)\nIf otherwise ri = l, then ρ∼l(u) = 0 ≤ TQJ ↑α (0)(H).\nIn case that α is a limit ordinal, u ≤ TPI ↑α (0) iff u ≤ TPI ↑β (0) for some β < α and any join irreducible u. Hence, by induction hypothesis, it follows that ρ∼l(u) ≤ TQJ ↑β (0) ≤ TQJ ↑α (0) and, thus, ρ∼l(TPI ↑α (0))≤ TQJ ↑α (0).\nProof of Theorem 3. In the sake of simplicity, we just write ρ instead of ρ∼ri . Note that, by definition, for any atom H, it follows that WX(H) = LX(H) with X ∈ {P,Q}. The proof follows by induction in the number of steps of the Γ2 operator assuming as induction hypothesis that Γ2Q ↑β (0)≤ ρ(Γ2P ↑β (0)) for every β < α . Note that Γ2Q ↑0 (0)(H) = 0 ≤ ρ(Γ2P ↑0 (0))(H) and, thus, the statement trivially holds for α = 0 .\nIn case that α is a successor ordinal, by induction hypothesis, it follows that\nΓ2Q ↑ α−1 (0) ≤ ρ(Γ2P ↑ α−1 (0))\nand, from Lemma B.5, it follows that\nΓQ(Γ2Q ↑ α−1 (0)) ≥ ρ(ΓP(Γ2P ↑ α−1 (0))) Γ2Q(Γ 2 Q ↑ α−1 (0)(H))) ≤ ρ(Γ2P(Γ 2 P ↑ α−1 (0)))\nThat is, Γ2Q ↑α (0) ≤ ρ(Γ2P ↑α (0). Finally, in case that α is a limit ordinal, every join irreducible u satisfies u ≤ Γ2Q ↑ α (0) = ∑β<α Γ2Q ↑β (0) iff u ≤ Γ2Q ↑β (0) for some β < α and, thus, by induction hypothesis ρ(u) ≤ Γ2P ↑β (0)≤ Γ2P ↑α (0). Consequently, Γ2Q ↑∞ (0)≤ ρ(Γ2P ↑∞ (0) and WQ(A)≤ ρ(WP(A) for any atom A."
    }, {
      "heading" : "Appendix B.6. Proof of Theorem 5",
      "text" : "By Γ̃P(Ĩ) we denote the least model of a program PĨ . Note that the relation between Γ̃P and ΓP is similar to the relation between T̃P and TP: the Γ̃P operator is a function in the set of CG interpretations while ΓP is a function in the set of ECJ interpretations. Note also that the evaluation of negated literals with respect to CG and ECJ interpretations and, thus, the reducts PĨ and PI may be different even if Ĩ(A) = I(A) for every atom A.\nLemma B.6 Let P be a labelled logic program, Ĩ and J be respectively an CG and a ECJ interpretation such that Ĩ ≥ λ c(J). Then Γ̃P(Ĩ)≤ λ c(ΓP(J)).\nProof . By definition Γ̃P(Ĩ) and ΓP(J) are respectively the least model of the programs PĨ and PJ . Furthermore, from Theorem 1 the least model of any program P is the least fixpoint of the TP operator, that is, Γ̃P(Ĩ) = T̃PĨ ↑\nω (0) and ΓP(J) = TPJ ↑ω (0). In case that α = 0, it follows that T̃PĨ ↑\n0 (0)(H) = 0 ≤ λ c(TPJ ↑0 (0))(H) for every atom H. We assume as induction hypothesis that T̃PĨ ↑ β (0)≤ λ c(TPJ ↑β (0)) for all β < α . In case that α is a successor ordinal, E ≤ T̃PĨ ↑ α (0)(H) = T̃PĨ (T̃PĨ ↑ α−1 (0))(H) if and only if there is a rule RI in PĨ of the form\nri : H ← B1, . . . ,Bm,\nwhich is the reduct of a rule R of the form (4) in P and that satisfies E ≤ (EB1 ∗ . . .∗EBm) · ri with each EB j ≤ T̃PĨ ↑\nα−1 (0)(B j) and Ĩ(C j) = 0 for all B j and C j in body(R). Hence there is a rule in PJ of the form\nri : H ← B1, . . . ,Bm, J(notC1), . . . , J(notCn)\nand, by induction hypothesis, EB j ≤ λ c ( TPJ ↑ α−1 (0)(B j) )\nfor all B j. Furthermore, by definition (\nTPJ ↑ α−1 (0)(B1)∗ . . .∗TPJ ↑ α−1 (0)(Bm)∗ J(notC1)∗ . . .∗ J(notCm) ) · ri ≤ TPJ ↑ α (0)(H)\nFrom the fact that Ĩ(C j) = 0 and the lemma’s hypothesis Ĩ ≥ λ c(J), it follows that 0 ≥ λ c(J(C j)) and, thus, 1 ≤ λ c(∼J(C j)) = λ c(J(notC j)). Hence,\nλ c ( (TPJ ↑ α−1 (0)(B1)∗ . . .∗TPJ ↑ α−1 (0)(Bm)∗ J(notC1)∗ . . .∗ J(notCm)) · ri ) =\n= λ c ( (TPJ ↑ α−1 (0)(B1)∗ . . .∗TPJ ↑ α−1 (0)(Bm) ) ∗λ c ( J(notC1) ) ∗ . . .∗λ c ( J(notCm) )) · ri = λ c (\n(TPJ ↑ α−1 (0)(B1)∗ . . .∗TPJ ↑ α−1 (0)(Bm) ) ∗ 1 ∗ . . .∗ 1 ) · ri\n= λ c ( (TPJ ↑ α−1 (0)(B1)∗ . . .∗TPJ ↑ α−1 (0)(Bm) )) · ri\nand, thus,\nλ c ( (TPJ ↑ α−1 (0)(B1)∗ . . .∗TPJ ↑ α−1 (0)(Bm) )) · ri ≤ λ c ( TPJ ↑ α (0)(H) )\nSince EB j ≤ λ c ( TPJ ↑ α−1 (0)(B j) ) for all B j, it follows that\nE ≤ (EB1 ∗ . . .∗EBm) · ri ≤ λ c(TPJ ↑ α (0))(H)\nFinally, in case that α is a limit ordinal, it follows from Theorem 1 that α = ω . Furthermore, since Ĩ is a CG interpretation, it follows that PĨ is a CG program and, thus, E ≤ TPĨ ↑\nω (0) iff E ≤ TPĨ ↑\nn (0) for some n < ω (see Cabalar et al. 2014a). Hence, by induction hypothesis, it follows that E ≤ TPJ ↑ n (0)≤ TPJ ↑ ω (0).\nLemma B.7 Let P be a labelled logic program over a signature 〈At,Lb〉 where Lb is a finite set of labels, Ĩ and J respectively be a CG and a ECJ interpretation such that Ĩ ≤ λ c(J). Then Γ̃P(Ĩ)≥ λ c(ΓP(J)).\nProof . Since Lb is finite, it follows that VLb is also finite. Furthermore, since VLb is a finite distributive lattice, every element t ∈ VLb can be represented as a unique sum of join irreducible elements (Proposition 5).\nAssume as induction hypothesis that u ≤ TPJ ↑ β (0)(H) implies λ c(u)≤ T̃PĨ ↑ β (0)(H) for every join irreducible u, atom H ∈ At and ordinal β < α .\nIn case that α is a successor ordinal. For any join irreducible justification u≤ TPJ ↑α (0)(H) there is a rule RJ in PJ of the form (6) and there are join irreducible terms uB j ≤ TPJ ↑\nα−1 (0)(B j) and uC j ≤∼J(C j) for all B j and C j such that\nu ≤ (uB1 ∗ . . .∗ uBm ∗ uC1 ∗ . . .∗ uCn) · ri\nIf uC j contains an oddly negated label for some C j, then λ c(uC j ) = 0 and it consequently follows that λ c(u) = 0 ≤ T̃PĨ ↑\nα (0)(H). Thus, we assume that uC j only contains evenly negated labels for any C j. Note that, since uC j ≤ ∼J(C j), then uC j cannot contain any non-negated label, that is, all occurrences of labels in uC j are strictly evenly negated and, thus, every term u ′ C j ≤ J(C j) must contain some oddly negated label. Hence, Ĩ(C j)≤ λ c(J(C j)) = 0 for any C j and there is a rule RĨ in QĨ of the form\nri : H ← B1, . . . ,Bm\nBy induction hypothesis, uB j ≤ TPJ ↑ α−1 (0)(B j) implies λ c(uB j) ≤ T̃PĨ ↑ α−1 (0)(B j) and, consequently, λ c(u)≤ T̃PĨ ↑ α (0)(H). Since TPJ ↑ α (0)(H) = ∑u∈UH u where every u ∈UH is join irreducible and every u ∈UH satisfies u≤ TPJ ↑ α (0)(H), it follows that λ c(u)≤ T̃PĨ ↑ α (0)(H) and, thus, ∑u∈UH λ c(u)≤ T̃PĨ ↑\nα (0)(H). Note that, by definition, λ c(∑u∈UH u) = ∑u∈UH λ c(u) and, thus,\nλ c(TPJ ↑ α (0)(H)) = λ c( ∑\nu∈UH\nu) ≤ T̃PĨ ↑ α (0)(H)\nIn case that α is a limit ordinal, it follows u ≤ TPJ ↑α (0)(H) iff u ≤ TPJ ↑β (0)(H) for some β < ω and, by induction hypothesis, it follows that λ c(u)≤ T̃PĨ ↑ β (0)(H)≤ T̃PĨ ↑ α (0)(H) and, thus, T̃PĨ ↑ α (0)≥ λ c(TPJ ↑α (0)).\nFinally, by definition Γ̃P(Ĩ) and ΓP(J) are respectively the least models of PĨ and PJ and, from Theorem 11, these are precisely T̃PĨ ↑ ω (0) and TPJ ↑ ω (0). Hence, T̃PĨ ↑\nω (0) ≥ λ c(TPJ ↑ω (0)) implies Γ̃P(Ĩ)≥ λ c(ΓP(J)).\nProposition 6\nGiven a program P over a signature 〈At,Lb〉 where Lb is a finite set of labels, any ECJ interpretation I satisfies Γ̃P(λ c(I)) = λ c(ΓP(I))).\nProof of Proposition 6. Let Ĩ be a CG interpretation such that I(H) = Ĩ(H) for every atom H. Then, it follows that Ĩ = λ c(I). Hence, from Lemmas B.6 and B.7, it respectively follows that Γ̃P(Ĩ)≤ λ c(ΓP(I)) and Γ̃P(Ĩ)≥ λ c(ΓP(I)). Then, Γ̃P(Ĩ) = Γ̃P(λ c(I)) = λ c(ΓP(I)).\nProof of Theorem 5. According to (Cabalar et al. 2014a), a CG interpretation Ĩ is a CG stable model of P iff Ĩ is the least model of the program PĨ . Then, the CG stable models are just the fixpoints of the Γ̃P operator.\nLet Ĩ be a CG stable model according to (Cabalar et al. 2014a), let I be a ECJ interpretation such that I(H) = Ĩ(H) for every atom H ∈ At and let J def= Γ2P ↑∞ (I) be the least fixpoint of Γ2P iterating from I. Since I(H) = Ĩ(H) for every atom H ∈ At, it follows that Ĩ = λ c(I) and, by definition of CG stable model, it follows that Ĩ = Γ̃P(Ĩ). Thus, from Proposition 6, it follows that Ĩ = λ c(ΓP(I)). Applying Γ̃P to both sides of this equality, we obtain that Γ̃P(Ĩ) = Γ̃P(λ c(ΓP(I))). From Proposition 6 again, it follows that Γ̃P(λ c(ΓP(I))) = λ c(ΓP(ΓP(I))) = λ c(Γ2P(I)) and, thus, Γ̃P(Ĩ) = λ c(Γ2P(I)). Furthermore, since Ĩ = Γ̃P(Ĩ), it follows that Ĩ = λ c(Γ2P(I)). Inductively applying this argument, it follows that Ĩ = λ c(Γ2P ↑α (I)) for any successor ordinal α . Moreover, for a limit ordinal α ,\nλ c ( Γ2P ↑ α (I) )\n= λ c (\n∑ β<α Γ2P ↑ β (I)\n)\n= ∑ β<α λ c ( Γ2P ↑ β (I) ) = Ĩ\nThen, since we have defined J = Γ2P ↑∞ (I), it follows that Ĩ = λ c(J) = λ c(I) and, since we also have that Ĩ = λ c(ΓP(I)), we obtain that λ c(I) = λ c(ΓP(I)).\nThe other way around. Let I be a fixpoint of Γ2P such that λ c(I) = λ c(ΓP(I)) and let Ĩ def= λ c(I). In the same way as above, it follows that Γ̃P(Ĩ) = λ c(ΓP(I)) = λ c(I) = Ĩ. That is, Γ̃P(Ĩ) = Ĩ and so that Ĩ is a causal stable model of P according to (Cabalar et al. 2014a)."
    }, {
      "heading" : "Appendix B.7. Proof of Theorem 6",
      "text" : "Proof of Theorem 6 . Let Ĩ be a causal stable model of P and I be the correspondent fixpoint of Γ2P with Ĩ = λ c(I). Since E is a enabled justification of A, i.e. E ≤WP(A), then E ≤ LP(A) with LP the least fixpoint of Γ2P. Since, I is a fixpoint of Γ2P, if follows that E ≤ LP(A) ≤ I(A) and, thus, λ c(E) ≤ λ c(I(A)) = Ĩ(A). Then G def= graph(λ c(E)) is, by definition, a causal explanation of the atom A."
    }, {
      "heading" : "Appendix B.8. Proof of Theorem 7",
      "text" : "The proof of Theorem 7 will need the following definition.\nDefinition 18 Given a program P, a WnP interpretation is a mapping I : At −→ BLb assigning a Boolean formula to each atom. The evaluation of a negated literal notA with respect to a WnP interpretation is given by I(notA) = ¬I(A). An interpretation I is a WnP model of rule like (4) iff\nI(B1)∗ . . .∗I(Bm)∗I(notC1)∗ . . .∗I(notCn)∗ ri ≤ I(H)\nThe operator GP(I) maps a WnP interpretation I to the least model of the program PI.\nNote that the only differences in the model evaluation between ECJ and WnP comes from the valuation of negative literals and the use of ‘∗’ instead of ‘·’ for keeping track of rule application. Besides, we will also use the following facts whose proof is addressed in an appendix.\nDefinition 19 Given a positive program P, we define a direct consequence operator TP such that\nTP(I)(H) def= ∑\n{ I(B1)∗ . . .∗I(Bn)∗ ri | (ri : H ← B1, . . . ,Bn) ∈ P }\nfor any WnP interpretation I and atom H ∈ At.\nDefinition 20 (From Damásio et al. 2013) Given a program P, its why-not program is given by P def= P∪P′ here P′ contains a labelled fact of the form\n¬not(A) : A\nfor each atom A ∈ At not occurring in P as a fact. The why-not provenance information under the well-founded semantics is defined as follows: WhyP(H) = [TP(H)]; WhyP(H) = [¬TUP(H)]; and WhyP(undef A) = [¬TP(H)∧TUQ(H)] where TP and TUP =GP (TP) be the least and greates fixpoints of G2\nP , respectively.\nLemma B.8 Let P be a labelled logic program over a signature 〈At,Lb〉 where Lb is a finite set of labels and let I and I be respectively a ECJ and a WnP interpretation such that λ p(I) ≥ I. Then, λ p(ΓP(I))≤GP(I).\nProof . By definition ΓP(I) and GP(I) are the least model of the programs PI and PI, respectively. Furthermore, the least model of programs PI and PI are the least fixpoint of the TPI and T\nPJ operators, that is, ΓP(I) = TPI ↑ω (0) and GP(J) = TPI ↑ω (⊥).\nIn case that α = 0, it follows that λ p(TPI ↑0 (0)(H)) = TPI ↑0 (⊥)(H) = 0 for every atom H. We assume as induction hypothesis that λ p(TPI ↑β (0))≤ TPI ↑β (⊥) for all β < α . In case that α is a successor ordinal. Assume that u≤ TPI ↑α−1 (0)(H) for some join irreducible u and atom H. Then there is a rule ri ∈ P of the form (4) and\nu ≤ (uB1 ∗ . . .∗ uB1 ∗ uC1 ∗ . . .∗ uC1) · ri\nwhere uB j ≤ TPI ↑ α−1 (0)(B j) and uC j ≤∼I(C j). Hence, by induction hypothesis, it follows that λ p(uB j) ≤ TPI ↑α−1 (⊥)(B j) and, since uC j ≤∼I(C j), it also follows that λ p(uC j )≤ ¬I(C j) for all C j. Consequently, we have that λ p(u)≤ TPI ↑α (⊥)(H). In case that α is a limit ordinal, u ≤ TPI ↑α (0) iff u ≤ TPI ↑β (0) for some β < α and all join irreducible u. Hence, by induction hypothesis, it follows that λ p(u)≤ T\nPJ ↑β (0)≤ T PJ ↑α (0)\nand, thus, λ p(TPI ↑α (0))≤ TPJ ↑α (⊥).\nLemma B.9 Let P be a labelled logic program over a signature 〈At,Lb〉 where Lb is a finite set of labels and let I and I be respectively a ECJ and a WnP interpretation such that λ p(I) ≤ I. Therefore, λ p(ΓP(I))≥GP(I).\nProof . The proof is similar to the proof of Lemma B.8 and we just show the case in which α is a successor ordinal.\nAssume that u ≤ T PI ↑α (⊥)(H) for some join irreducible u and atom H. Hence, there is some rule ri ∈ P of the form (4) and\nu ≤ uB1 ∗ . . .∗ uBm ∗ uC1 ∗ . . .∗ uCn ∗ ri\nwhere uB j ≤ TPI ↑ α−1 (⊥)(B j) for each B j and uC j ≤ ¬I(C j) for each C j. By induction hypothesis, uB j ≤ λ p(TPI ↑α−1 (0))(B j) for all B j. Furthermore, since λ p(I) ≤ I it follows, from Lemma B.3, that λ p(∼I)≥ ¬I and, since uC j ≤ ¬I(C j), it also follows that uC j ≤ λ p(∼I(C j)). Hence,\nλ (u) ≤ (λ p(uB1)∗ . . .∗λ p(uB1)∗λ p(uC1)∗ . . .∗λ p(uC1))∗ ri ≤ λ p(TPI ↑ α (0)(H))\nThus, T PI ↑α (⊥)(B j)≤ λ p(TPI ↑α (0)(B j)).\nNote that the image of λ p is a boolean algebra and the set of causal values corresponding to negated terms { ∼t ∣\n∣ t ∈ VLb } are also a boolean algebra. Consequently, we define a function λ q(t) =∼∼t which is analogous to λ p but whose image is in VLb.\nLemma B.10 Let P be a labelled logic program and let I be an ECJ interpretation. Then, ΓP(I) = ΓP(λ q(I)) and λ p(t) = λ p(λ q(t)).\nProof . For ΓP(I) = ΓP(λ q(I)). Since λ q(t) = ∼∼t and ∼∼∼t = ∼t, it follows that λ q(∼I) = ∼∼∼I = ∼I and, thus, PI =Pλ\nq(I). Since by definition ΓP(I) and ΓP(λ q(I)) are respectively the least models of programs PI and Pλ q(I) it is clear that ΓP(I) = ΓP(λ q(I)).\nFor λ p(t) = λ p(λ q(t)), just note λ p(λ q(t)) = λ p(∼∼t) = ¬¬λ p(t) = λ p(t).\nProposition 7 Let P be a program over a signature 〈At,Lb〉 where Lb is a finite set of labels. Then, any causal interpretation I satisfies:\n(i). GP(λ p(I)) = λ p(ΓP(I)), (ii). ΓP(λ q(I)) = ΓP(I) and\n(iii). λ p(t) = λ p(λ q(t)).\nProof . (i) From Lemmas B.8 and B.9, it respectively follows that λ p(ΓP(I)) ≤ GP (λ p(I)) and that λ p(ΓP(I)) ≥ GP(λ p(I)). Then, GP(λ p(I)) = λ p(ΓP(I)). (ii) and (iii) follow from Lemma B.10.\nProof of Theorem 7. Note that WhyP(A) = TP(A) and that, by λ p definition, it follows that λ p(0) = 0 and thus, from Proposition 7 (i), it follows that GP(⊥) =GP (λ p(0)) = λ p(ΓP(0)) and\nGP(⊥) = GP(λ p(0)) = λ p(ΓP (0)) = λ p(λ q(ΓP(0)))\nHence, from Proposition 7, it follows that\nG2P(⊥) = GP (GP(⊥)) = GP (λ p(λ q(ΓP(0))))\n= λ p(ΓP(λ q(ΓP(0)))) = λ p(ΓP(ΓP(0))) = λ p(Γ2P(0))\nInductively applying this reasoning it follows thatG2 P ↑∞ (0)= λ p(Γ2P ↑ ∞ (0)) which, by KnasterTarski theorem are the least fixpoints of the operators, that is, TP = λ p(LP) and, consequently, WhyP(A) = TP(A) = λ p(LP(A)) = λ p(WP(A)) =WhyP(A). Similarly, by definition, it follows that W hyP(notA) = ¬TUP(A) where TUP is the greatest fixpoint of the operator G2P . Thus,\nW hyP(notA) = ¬GP (TP) = λ p(∼ΓP(LP)) = λ p(∼UP(A)) = λ p(WP(notA))\nFinally, WhyP(undef A) = ¬TP(A)∗TUP(A) and, thus\nWhyP(undef A) = λ p(∼LP(A))∗λ p(∼∼UP(A)) = λ p(∼LP(A)∗∼∼UP(A)) = λ p(∼WP(A)∗∼WP(notA)) = λ p(WP(undef A))\nand, thus, WhyP(undef A) = λ p(WP(undef A)) =WhyP(notA).\nAppendix B.9. Proof of Theorem 8\nLemma B.11 Let P be a labelled logic program over a signature 〈At,Lb〉 where Lb is a finite set of labels and no rule is a labelled by not(A) nor ∼∼not(A). Let Q be the result of removing all rules labelled by ∼not(A) for some atom A. Let I and J be two interpretations such that J = ρnot(A)(I). Then, ΓQ(J) = ρnot(A)(ΓP(I)).\nProof . In the sake of simplicity, we just write ρ instead of ρnot(A). By definition ΓP(I) and ΓQ(J) are respectively the least model of PI and QJ . The proof follows then by induction on the steps of the TP operator assuming that ρ(TPI ↑β (0)) = TQJ ↑β (0) for all β < α .\nNote that, TX ↑0 (0)(H) = 0 for any program X and atom H and, thus, the statement trivially holds.\nIn case that α is a successor ordinal. Let u ∈ VLb be a join irreducible causal value such that u ≤ TPI ↑ α (0)(H). Then, there is a rule in P of the form (4) such that\nu ≤ (uB1 ∗ . . .∗ uBm ∗ uC1 ∗ . . .∗ uCn) · ri\nwhere uB j ≤ TPI ↑ α−1 (0)(B j) and uC j ≤∼I(C j) for each positive literal B j and each negative literal notC j in the body of rule ri.\nIf ri =∼not(A), then ρ(u) = 0 ≤ TQ ↑α−1 (0)(H). Otherwise,\n1. By induction hypothesis, it follows that ρ(uB j)≤ TQ ↑α−1 (0)(B j), and 2. from J(H) = ρ(I(H)) and uC j ≤∼I(C j), it follows that ρ(uC j)≤∼J(C j).\nFurthermore, no rule in the program P is labelled with not(A) nor ∼∼not(A) and, thus, ri 6= not(A) and ri 6=∼∼not(A). Hence, ρ(u)≤ TQ ↑α−1 (0)(H).\nThe other way around is similar. Since u ≤ TQJ ↑ α (0)(H) there is a rule in Q of the form (4) such that\nu ≤ (uB1 ∗ . . .∗ uBm ∗ uC1 ∗ . . .∗ uCn) · ri\nand uB j ≤ TQJ ↑ α−1 (0)(B j) and uC j ≤∼J(C j) for each positive literal B j and each negative literal notC j in the body of rule ri. By induction hypothesis, uB j ≤ ρ(TPI ↑α−1 (0)(B j)) for each B j with 1 ≤ j ≤ m and, since J(H) = ρ(I(H)) and uC j ≤∼J(C j), it follows that uC j ≤ ρ(∼I(C j)). Then, u ≤ ρ(TPI ↑α (0)(H)). In case that α is a limit ordinal TX ↑α (0) = ∑β<α TX ↑β (0)(H) and, thus, u ≤ TX ↑α (0) if and only if u≤ TX ↑β (0)(H) with β <α . By induction hypothesis, ρ(TPI ↑β (0)(H))= TQJ ↑β (0)(H) and, thus, u≤ ρ(TPI ↑α (0)) if and only if u≤ TQJ ↑α (0). Hence, ρ(TPI ↑α (0)) = TQJ ↑α (0) and, consequently, ΓQ(J) = ρ(ΓP(I)).\nProposition 8 Let P be a labelled logic program over a signature 〈At,Lb〉 where Lb is a finite set of labels where no rule is a labelled by not(A) nor ∼∼not(A). Let Q be the result of removing all rules labelled by ∼not(A) for some atom A. Then, LQ = ρnot(A)(LP) and UQ = ρnot(A)(UP).\nProof . Note that LX = Γ2X ↑∞ (0) with X ∈ {P,Q}. Furthermore, by definition, it follows that Γ2P ↑0 (0) = Γ2Q ↑0 (0) = 0. Then, assume as induction hypothesis that Γ2Q ↑β (0) = ρ(Γ2P ↑β (0)) for all β < α . When α is a successor ordinal, by definition Γ2X ↑α (0) = Γ2X(Γ2X ↑α−1 (0)) = ΓX(ΓX (Γ2X ↑α−1 (0))) with X ∈ {P, Q} and, thus, the statement follows from Lemma B.11. In case that α is a limit ordinal Γ2X ↑α (0) = ∑β<α Γ2X ↑β (0). Then, for every join irreducible u it follows that u ≤ Γ2P ↑α (0) if and only if u ≤ Γ2P ↑β (0) for some β < α (by induction hypothesis) iff ρ(u) ≤ Γ2P ↑β (0) iff ρ(u) ≤ Γ2P ↑α (0). Hence, Γ2Q ↑α (0) = ρ(Γ2P ↑α (0)) and, conseuqntly, LQ = ρ(LP)\nFinally, note that UX = ΓX (LX ) with X ∈ {P, Q} and, thus, the statement follows directly from Lemma B.11.\nProof of Theorem 8. By definition, program P is the result of removing all rules labelled with ∼not(A) in P. In case that L is some atom H, by definition, it follows that WP(H) = LP(H) and WP(H) =LP(H) and, from Proposition 8, it follows that LP = ρ(LP) and, thus WP = ρ(WP).\nSimilarly, in case that L is a negative literal (L = notH), then WP(H) =∼UP(H) and WP(H) = ∼UP(H) and, from Proposition 8, it follows that UP = ρ(UP). Just note tha ρx(∼u) = ∼ρx(u) for any elementary term x and any value u. Hence, UP = ρ(UP) implies that ∼UP = ρ(∼UP) and, consequently, WP = ρ(WP).\nIn case that L is an undefined literal (L = undef H), by definition, it follows that WP(H) = ∼WP(H)∗∼WP(notH) =∼LP(H)∗∼∼UP(H) and WP(H) =∼LP(H)∗∼∼UP(H) and the result follows as before from Proposition 8."
    }, {
      "heading" : "Appendix B.10. Proof of Theorem 9",
      "text" : "Proof of Theorem 9. Note that ρ(λ p(u)) = λ p(ρ(u)) for any causal value u∈ VLb. By definition WhyP(L) = λ p(WP)(L) and, thus\nρ(WhyP(L)) = ρ(λ p(WP)(L)) = λ p(ρ(WP))(L)\nFrom Theorem 8, it follows that WP = ρ(WP) and, thus, ρ(WhyP(L)) = λ p(WP)(L)."
    }, {
      "heading" : "Appendix B.11. Proof of Theorem 2",
      "text" : "The proof of Theorem 2 will rely on the relation between ECJ justifications and non-hypothetical WnP justifications established by Theorem 9 plus the following result from (Damásio et al. 2013). First, we need some notation. Given a conjuntion of labels D, by Remove(D) we denote the set of negated labels in D, by Keep(D) the set of positive labels, by AddFacts(D) the set of facts A such that ¬not(A) occurs in D and by NoFacts(D) the set of facts A such that not(A) occurs in D.\nTheorem 12 (Theorem 3 from Damásio et al. 2013) Given a labelled logic program P, let N be a set of facts not in program P and R be a subset of rules of P. A literal L belongs to the WFM of (P\\R)∪ N iff there is a conjunction of literals D |=WhyP(L), such that Remove(D)⊆ R, Keep(D)∩R = /0, AddFacts(D)⊆ N, and NoFacts(D)∩N = /0.\nDefinition 21 Given a positive program P, we define a direct consequence operator T̂P such that\nT̂P(Î)(H) def= ∑\n{ Î(B1)∗ . . .∗ Î(Bn) | (ri : H ← B1, . . . ,Bn) ∈ P }\nfor any standard interpretation interpretation Î and atom H ∈ At.\nLemma B.12 Let P be a labelled logic program over a signature 〈At,Lb〉 where Lb is a finite set of labels and let I and Î be respectively a ECJ and a standard interpretation satisfying that there is some enable justification E ≤ ∼I(H) for every atom H such that Î(H) = 0. Then, every atom H satisfies Γ̂P(Î)(H) = 1 iff there is some enabled justification E ≤ ΓP(I)(H).\nProof . By definition ΓP(I) and Γ̂P(Î) are the least model of the programs PI and PÎ , respectively. Furthermore, the least model of programs PI and PÎ are the least fixpoint of the TP and T̂P operators, that is, ΓP(I) = TPI ↑ω (0) and Γ̂P(J) = T̂PÎ ↑\nω (0). In case that α = 0, it follows that T̂PÎ ↑\n0 (0)(H) for every atom H and, thus, the statement holds vacuous. We assume as induction hypothesis that for every atom H and ordinal β < α such that T̂PÎ ↑\nβ (0)(H) = 1, there is some enabled justification E ≤ TPI ↑ β (0)(H). In case that α is a successor ordinal. If T̂PI ↑α−1 (0)(H) = 1, then there is a rule ri ∈ P of the form (4) such that T̂PI ↑\nα−1 (0)(B j) = 1 and I(C j) = 0. On the one hand, by induction hypothesis, it follows that there is some enabled justification EB j ≤ TPI ↑\nα−1 (0)(B j) and, by hypothesis, there is some enabled justification EC j ≤∼I(C j). Hence,\nE def= (EB1 ∗ . . .EBm ∗EC1 ∗ . . .∗ECn)·ri\nis an enabled justification E ≤ TPI ↑ α (0)(H). The other way around, let E be some join irreducible justification. If E ≤ TPI ↑ α (0)(H), then there is a rule ri ∈ P of the form (4) such that\nE ≤ (EB1 ∗ . . .EBm ∗EC1 ∗ . . .∗ECn)·ri\nwhere EB j ≤ TPI ↑ α (0)(B j) and EC j ≤ ∼I(C j) are enabled justifications. Hence, it follows that T̂PÎ ↑ α (0)(B j) = 1 and Î(C j) = 0. In case that α is a limit ordinal, T̂PĨ ↑ α (0) = 1 iff T̂PĨ ↑\nβ (0) = 1 for some β < α iff there is a join irreducible enabled justification E ≤ TPI ↑ β (0))≤ λ p(TPI ↑α (0).\nProof of Theorem 2. Let E ≤WP(L) be an enabled justification of L∈ {A, notA, undef A}. From Theorem 9, it follows that λ p(E) ≤ λ p(WP(L)) = ρ(WhyP(L)), that is, λ p(E) ≤ ρ(WhyP(L)). Note that the minimum causal value t such that ρ(t) = ρ(WhyP(L)) is WhyP(L)∧ ∧\nA∈At not(A) and, thus, D ≤ WhyP(L) where D is defined by D = λ p(E)∧ ∧\nA∈At not(A). Furthermore, since E is an enabled justification, λ p(E) is a positive conjunction and, thus, so it is D. Hence, there is a positive conjunction D such that D ≤WhyP(L) and, from Theorem 12, it follows that L holds with respect to the standard WFM of P.\nThe other way around. If L = A is an atom, then L holds with respect to the standard WFM iff lfp(Γ̂2P)(L) = 1. Furthermore, Γ̂2P ↑0 (0)(H) = Γ2P ↑0 (0) = 0 for any atom H and, thus, there is an enabled justification E ≤∼Γ2P ↑0 (0) =∼0 = 1 for any atom H. Then, from Lemma B.12, for any atom H , there is an enabled justification E ≤ ΓP(Γ2P ↑0 (0))(H) iff Γ̂P(Γ̂2P ↑0 (0))(H) = 1. Applying this result again, it follows that E ≤ Γ2P ↑1 (0)(H) = Γ2P(Γ2P ↑0 (0))(H) if and only if Γ̂2P ↑1 (0))(H) = Γ̂2P(Γ̂2P ↑0 (0))(H) = 1. Inductively applying this reasoning it follows that Γ̂2P ↑∞ (0)(H) = 1 iff there is an enabled justification E ≤ Γ2P ↑∞ (0)(H) which, by Knaster-Tarski theorem are the least fixpoints respectively of the Γ̂P and ΓP operators.\nSimilarly, if L= notA, then L holds with respect to the standard WFM if and only if gfp(Γ̂2P)(L) = Γ̂P(lfp(Γ̂2P))(L) = 0 iff there is not any an enabled justification E ≤ΓP(lfp(Γ2P))(L) = gfp(Γ2P)(L) iff there is an enabled justification E ≤WP(L) =∼gfp(Γ2P)(L).\nFinally, if L = undef A, then L holds with respect to the standard WFM iff lfp(Γ̂2P)(L) = 0 and gfp(Γ̂2P)(L) = 1 if and only if there is not any enabled justification E ≤WP(L) and there is not\nany enabled justification E ≤ WP(notL) iff there is some enabled justification E ≤ ∼WP(L) and there is some enabled justification E ≤ ∼WP(notL) iff there is some enabled justification WP(undef A) =∼WP(A)∗∼WP(notA).\nAppendix B.12. Proof of Theorem 10\nLemma B.13 Let t and u be two causal terms such that no-sums occur in t ant t ≤ u. Then, ρx(t)≤ ρx(u).\nProof . By definition t ≤ u if and only if t = t ∗u. Then, ρx(t) = ρx(t ∗u) = ρx(t)∗ρx(u) and, thus if follows that ρx(t)≤ ρx(u).\nLemma B.14 Let t be a causal term. Then, λ c(λ p(t))≤ λ p(λ c(t)).\nProof . If t ∈ Lb is a label, then λ c(t) = t and λ p(t) = t and, thus, λ c(λ p(t)) = t ≤ t = λ p(λ c(t)). If t = ∼l with l ∈ Lb a label, then λ c(t) = 0 and λ p(t) = ¬l and, thus, λ c(λ p(t)) = 0 ≤ 0 = λ p(λ c(t)). If t = ∼∼l with l ∈ Lb a label, then λ c(t) = 1 and λ p(t) = l and, thus, λ c(λ p(t)) = l ≤ 1 = λ p(λ c(t)).\nAssume as induction hypothesis that λ c(λ p(u)) ≤ λ p(λ c(u)) for every subterm u of t. If t = u1·u2, then\nλ c(λ p(u1·u2)) = λ c(λ p(u1)∗λ c(λ p(u2) ≤ λ p(λ c(u1)∗λ p(λ c(u2) = λ p(λ c(u1·u2))\nSimilarly, if t = ∑u∈U u, then\nλ c(λ p(∑ u∈U u) = ∑ u∈U λ c(λ p(u) ≤ ∑ u∈U λ p(λ c((u)) = λ p(λ c(∑ u∈U u))\nand if t = ∏u∈U u, then\nλ c(λ p(∏ u∈U u) = ∏ u∈U λ c(λ p(u) ≤ ∏ u∈U λ p(λ c((u)) = λ p(λ c(∏ u∈U u))\nProof of Theorem 10. From Theorem 9, it follows that ρ(WhyP(A)) = λ p(WP)(A). Furthermore, since D ≤W hyP(A), from Lemma B.13, it follows that\nρ(D) ≤ ρ(WhyP(A)) = λ p(WP)(A) = λ p(LP)(A)\nand, thus, λ c(ρ(D))≤ λ c(λ p(LP))(A). Let Ĩ be any CG stable model. Then, since Ĩ = λ c(I) for some fixpoint I of Γ2P, it follows that λ c(LP) ≤ Ĩ and, thus, λ p(λ c(LP)) ≤ λ p(Ĩ). Furthermore, from Lemma B.14, it follows that λ c(λ p(LP))≤ λ p(λ c(LP)) and, thus\nλ c(ρ(D)) ≤ λ c(λ p(LP))(A) ≤ λ p(λ c(LP))(A) ≤ λ p(Ĩ)(A)\nNote that, since D is non-hypothetical and enabled, it does not contain negated labels and, thus, λ c(ρ(D)) = ρ(D). Consequently, ρ(D)≤ λ p(Ĩ)(A)."
    } ],
    "references" : [ {
      "title" : "Distributive lattices",
      "author" : [ "R. BALBES", "P. DWINGER" ],
      "venue" : "Melinda Inn.",
      "citeRegEx" : "BALBES and DWINGER,? 1975",
      "shortCiteRegEx" : "BALBES and DWINGER",
      "year" : 1975
    }, {
      "title" : "Causal graph justifications of logic programs",
      "author" : [ "P. CABALAR", "J. FANDINNO", "M. FINK" ],
      "venue" : "Theory and Practice of Logic Programming TPLP 14, 4-5, 603–618.",
      "citeRegEx" : "CABALAR et al\\.,? 2014a",
      "shortCiteRegEx" : "CABALAR et al\\.",
      "year" : 2014
    }, {
      "title" : "A complexity assessment for queries involving sufficient and necessary causes",
      "author" : [ "P. CABALAR", "J. FANDINNO", "M. FINK" ],
      "venue" : "Logics in Artificial Intelligence - 14th European Conference, JELIA 2014, Funchal, Madeira, Portugal, September 24-26, 2014. Proceedings, E. Fermé and J. Leite, Eds. Lecture Notes in Computer Science, vol. 8761. Springer, 297–310.",
      "citeRegEx" : "CABALAR et al\\.,? 2014b",
      "shortCiteRegEx" : "CABALAR et al\\.",
      "year" : 2014
    }, {
      "title" : "Justifications for logic programming",
      "author" : [ "C.V. DAMÁSIO", "A. ANALYTI", "G. ANTONIOU" ],
      "venue" : "Logic Programming and Nonmonotonic Reasoning, Twelfth International Conference, LPNMR 2013, Corunna, Spain, September 15-19, 2013. Proceedings, P. Cabalar and T. C. Son, Eds. Lecture Notes in Computer Science, vol. 8148. Springer, 530–542.",
      "citeRegEx" : "DAMÁSIO et al\\.,? 2013",
      "shortCiteRegEx" : "DAMÁSIO et al\\.",
      "year" : 2013
    }, {
      "title" : "Justification semantics: A unifiying framework for the semantics of logic programs",
      "author" : [ "M. DENECKER", "D.D. SCHREYE" ],
      "venue" : "Logic Programming and Non-monotonic Reasoning, 2nd International Workshop, LPNMR 1993, Lisbon, Portugal, June 1993. The MIT Press, 365–379.",
      "citeRegEx" : "DENECKER and SCHREYE,? 1993",
      "shortCiteRegEx" : "DENECKER and SCHREYE",
      "year" : 1993
    }, {
      "title" : "A causal semantics for logic programming",
      "author" : [ "J. FANDINNO" ],
      "venue" : "Ph.D. thesis, University of Corunna.",
      "citeRegEx" : "FANDINNO,? 2015a",
      "shortCiteRegEx" : "FANDINNO",
      "year" : 2015
    }, {
      "title" : "Towards deriving conclusions from cause-effect relations",
      "author" : [ "J. FANDINNO" ],
      "venue" : "ASPOCP.",
      "citeRegEx" : "FANDINNO,? 2015b",
      "shortCiteRegEx" : "FANDINNO",
      "year" : 2015
    }, {
      "title" : "A new perspective on stable models",
      "author" : [ "P. FERRARIS", "J. LEE", "V. LIFSCHITZ" ],
      "venue" : "IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence, Hyderabad, India, January 6-12, 2007, M. M. Veloso, Ed. 372–379.",
      "citeRegEx" : "FERRARIS et al\\.,? 2007",
      "shortCiteRegEx" : "FERRARIS et al\\.",
      "year" : 2007
    }, {
      "title" : "A meta-programming technique for debugging answer-set programs",
      "author" : [ "M. GEBSER", "J. PÜHRER", "T. SCHAUB", "H. TOMPITS" ],
      "venue" : "Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence, AAAI 2008, Chicago, Illinois, USA, July 13-17, 2008, D. Fox and C. P. Gomes, Eds. AAAI Press, 448–453.",
      "citeRegEx" : "GEBSER et al\\.,? 2008",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2008
    }, {
      "title" : "The stable model semantics for logic programming",
      "author" : [ "M. GELFOND", "V. LIFSCHITZ" ],
      "venue" : "Logic Programming, Proceedings of the Fifth International Conference and Symposium, Seattle, Washington, August 15-19, R. A. Kowalski and K. A. Bowen, Eds. MIT Press, 1070–1080.",
      "citeRegEx" : "GELFOND and LIFSCHITZ,? 1988",
      "shortCiteRegEx" : "GELFOND and LIFSCHITZ",
      "year" : 1988
    }, {
      "title" : "Causation and the price of transitivity",
      "author" : [ "N. HALL" ],
      "venue" : "The Journal of Philosophy 97, 4, 198–222.",
      "citeRegEx" : "HALL,? 2000",
      "shortCiteRegEx" : "HALL",
      "year" : 2000
    }, {
      "title" : "Two concepts of causation",
      "author" : [ "N. HALL" ],
      "venue" : "Causation and counterfactuals, J. Collins, N. Hall, and L. A. Paul, Eds. Cambridge, MA: MIT Press, 225–276.",
      "citeRegEx" : "HALL,? 2004",
      "shortCiteRegEx" : "HALL",
      "year" : 2004
    }, {
      "title" : "Structural equations and causation",
      "author" : [ "N. HALL" ],
      "venue" : "Philosophical Studies 132, 1, 109–136.",
      "citeRegEx" : "HALL,? 2007",
      "shortCiteRegEx" : "HALL",
      "year" : 2007
    }, {
      "title" : "Defaults and normality in causal structures",
      "author" : [ "J.Y. HALPERN" ],
      "venue" : "Principles of Knowledge Representation and Reasoning: Proceedings of the Eleventh International Conference, KR 2008, Sydney, Australia, September 16-19, 2008, G. Brewka and J. Lang, Eds. AAAI Press, 198–208.",
      "citeRegEx" : "HALPERN,? 2008",
      "shortCiteRegEx" : "HALPERN",
      "year" : 2008
    }, {
      "title" : "Appropriate causal models and stability of causation",
      "author" : [ "J.Y. HALPERN" ],
      "venue" : "Principles of Knowledge Representation and Reasoning: Proceedings of the Fourteenth International Conference, KR 2014, Vienna, Austria, July 20-24, 2014, C. Baral, G. D. Giacomo, and T. Eiter, Eds. AAAI Press.",
      "citeRegEx" : "HALPERN,? 2014",
      "shortCiteRegEx" : "HALPERN",
      "year" : 2014
    }, {
      "title" : "A modification of the halpern-pearl definition of causality",
      "author" : [ "J.Y. HALPERN" ],
      "venue" : "Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence, IJCAI 2015, Buenos Aires, Argentina, July 25-31, 2015, Q. Yang and M. Wooldridge, Eds. AAAI Press, 3022–3033.",
      "citeRegEx" : "HALPERN,? 2015",
      "shortCiteRegEx" : "HALPERN",
      "year" : 2015
    }, {
      "title" : "Actual causation and the art of modeling",
      "author" : [ "J.Y. HALPERN", "C. HITCHCOCK" ],
      "venue" : "CoRR abs/1106.2652.",
      "citeRegEx" : "HALPERN and HITCHCOCK,? 2011",
      "shortCiteRegEx" : "HALPERN and HITCHCOCK",
      "year" : 2011
    }, {
      "title" : "Causes and explanations: A structural-model approach",
      "author" : [ "J.Y. HALPERN", "J. PEARL" ],
      "venue" : "part I: Causes. Proceedings of the Seventeenth Conference in Uncertainty in Artificial Intelligence, UAI 2001, University of Washington, Seattle, Washington, USA, August 2-5, 194–202.",
      "citeRegEx" : "HALPERN and PEARL,? 2001",
      "shortCiteRegEx" : "HALPERN and PEARL",
      "year" : 2001
    }, {
      "title" : "Causes and explanations: A structural-model approach",
      "author" : [ "J.Y. HALPERN", "J. PEARL" ],
      "venue" : "part I: Causes. British Journal for Philosophy of Science 56, 4, 843–887.",
      "citeRegEx" : "HALPERN and PEARL,? 2005",
      "shortCiteRegEx" : "HALPERN and PEARL",
      "year" : 2005
    }, {
      "title" : "Cause and norm",
      "author" : [ "C. HITCHCOCK", "J. KNOBE" ],
      "venue" : "Journal of Philosophy 11, 587–612.",
      "citeRegEx" : "HITCHCOCK and KNOBE,? 2009",
      "shortCiteRegEx" : "HITCHCOCK and KNOBE",
      "year" : 2009
    }, {
      "title" : "An enquiry concerning human understanding",
      "author" : [ "D. HUME" ],
      "venue" : "Reprinted by Open Court Press, LaSalle, IL, 1958.",
      "citeRegEx" : "HUME,? 1748",
      "shortCiteRegEx" : "HUME",
      "year" : 1748
    }, {
      "title" : "Causation as influence",
      "author" : [ "D.K. LEWIS" ],
      "venue" : "The Journal of Philosophy 97, 4, 182–197.",
      "citeRegEx" : "LEWIS,? 2000",
      "shortCiteRegEx" : "LEWIS",
      "year" : 2000
    }, {
      "title" : "Embracing causality in specifying the indirect effects of actions",
      "author" : [ "LIN F." ],
      "venue" : "Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, IJCAI 95, Montréal Québec, Canada, August 20-25 1995, 2 Volumes. Morgan Kaufmann, 1985–1993.",
      "citeRegEx" : "F.,? 1995",
      "shortCiteRegEx" : "F.",
      "year" : 1995
    }, {
      "title" : "Stable models and an alternative logic programming paradigm",
      "author" : [ "V.W. MAREK", "M. TRUSZCZYŃKI" ],
      "venue" : "The Logic Programming Paradigm, K. R. Apt, V. W. Marek, M. Truszczyński, and D. Warren, Eds. Artificial Intelligence. Springer Berlin Heidelberg, 375–398.",
      "citeRegEx" : "MAREK and TRUSZCZYŃKI,? 1999",
      "shortCiteRegEx" : "MAREK and TRUSZCZYŃKI",
      "year" : 1999
    }, {
      "title" : "Causation, counterfactuals, and the third factor",
      "author" : [ "T. MAUDLIN" ],
      "venue" : "Causation and Counterfactuals, J. Collins, E. J. Hall, and L. A. Paul, Eds. MIT Press.",
      "citeRegEx" : "MAUDLIN,? 2004",
      "shortCiteRegEx" : "MAUDLIN",
      "year" : 2004
    }, {
      "title" : "Causal theories of action and change",
      "author" : [ "N. MCCAIN", "H. TURNER" ],
      "venue" : "Proceedings of the Fourteenth National Conference on Artificial Intelligence and Ninth Innovative Applications of Artificial Intelligence Conference, AAAI 97, IAAI 97, July 27-31, 1997, Providence, Rhode Island., B. Kuipers and B. L. Webber, Eds. AAAI Press / The MIT Press, 460–465.",
      "citeRegEx" : "MCCAIN and TURNER,? 1997",
      "shortCiteRegEx" : "MCCAIN and TURNER",
      "year" : 1997
    }, {
      "title" : "Logic programs with stable model semantics as a constraint programming paradigm",
      "author" : [ "I. NIEMELÄ" ],
      "venue" : "Annals of Mathematics and Artificial Intelligence 25, 3-4, 241–273.",
      "citeRegEx" : "NIEMELÄ,? 1999",
      "shortCiteRegEx" : "NIEMELÄ",
      "year" : 1999
    }, {
      "title" : "Catching the ouroboros: On debugging non-ground answer-set programs",
      "author" : [ "J. OETSCH", "J. PÜHRER", "H. TOMPITS" ],
      "venue" : "CoRR abs/1007.4986.",
      "citeRegEx" : "OETSCH et al\\.,? 2010",
      "shortCiteRegEx" : "OETSCH et al\\.",
      "year" : 2010
    }, {
      "title" : "A new logical characterisation of stable models and answer sets",
      "author" : [ "D. PEARCE" ],
      "venue" : "Non-Monotonic Extensions of Logic Programming, NMELP 1996, Bad Honnef, Germany, September 5-6, 1996, Selected Papers, J. Dix, L. M. Pereira, and T. C. Przymusinski, Eds. Lecture Notes in Computer Science, vol. 1216. Springer, 57–70.",
      "citeRegEx" : "PEARCE,? 1996",
      "shortCiteRegEx" : "PEARCE",
      "year" : 1996
    }, {
      "title" : "Causality: models, reasoning, and inference",
      "author" : [ "J. PEARL" ],
      "venue" : "Cambridge University Press, New York, NY, USA.",
      "citeRegEx" : "PEARL,? 2000",
      "shortCiteRegEx" : "PEARL",
      "year" : 2000
    }, {
      "title" : "Online justification for tabled logic programs",
      "author" : [ "G. PEMMASANI", "H. GUO", "Y. DONG", "C.R. RAMAKRISHNAN", "I.V. RAMAKRISHNAN" ],
      "venue" : "Functional and Logic Programming, Seventh International Symposium, FLOPS 2004, Nara, Japan, April 7-9, 2004, Proceedings, Y. Kameyama and P. J. Stuckey, Eds. Lecture Notes in Computer Science, vol. 2998. Springer, 24–38.",
      "citeRegEx" : "PEMMASANI et al\\.,? 2004",
      "shortCiteRegEx" : "PEMMASANI et al\\.",
      "year" : 2004
    }, {
      "title" : "Justifications for logic programs under answer set semantics",
      "author" : [ "E. PONTELLI", "T.C. SON", "O. EL-KHATIB" ],
      "venue" : "Theory and Practice of Logic Programming TPLP 9, 1, 1–56.",
      "citeRegEx" : "PONTELLI et al\\.,? 2009",
      "shortCiteRegEx" : "PONTELLI et al\\.",
      "year" : 2009
    }, {
      "title" : "Aba-based answer set justification",
      "author" : [ "C. SCHULZ", "F. TONI" ],
      "venue" : "Theory and Practice of Logic Programming TPLP 13, 4-5 Online-Supplement.",
      "citeRegEx" : "SCHULZ and TONI,? 2013",
      "shortCiteRegEx" : "SCHULZ and TONI",
      "year" : 2013
    }, {
      "title" : "Generating explanation trees even for negations in deductive database systems",
      "author" : [ "G. SPECHT" ],
      "venue" : "Proceedings of the Fifth Workshop on Logic Programming Environments (LPE 1993), October 29-30, 1993, In conjunction with ILPS 1993, Vancouver, British Columbia, Canada, M. Ducassé, B. L. Charlier, Y. Lin, and L. Ü. Yalçinalp, Eds. IRISA, Campus de Beaulieu, France, 8–13.",
      "citeRegEx" : "SPECHT,? 1993",
      "shortCiteRegEx" : "SPECHT",
      "year" : 1993
    }, {
      "title" : "Ramification and causality",
      "author" : [ "M. THIELSCHER" ],
      "venue" : "Artificial Intelligence 89, 1-2, 317–364.",
      "citeRegEx" : "THIELSCHER,? 1997",
      "shortCiteRegEx" : "THIELSCHER",
      "year" : 1997
    }, {
      "title" : "The alternating fixpoint of logic programs with negation",
      "author" : [ "A. VAN GELDER" ],
      "venue" : "Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, March 29-31, 1989, Philadelphia, Pennsylvania, USA, A. Silberschatz, Ed. ACM Press, 1–10.",
      "citeRegEx" : "GELDER,? 1989",
      "shortCiteRegEx" : "GELDER",
      "year" : 1989
    }, {
      "title" : "The well-founded semantics for general logic",
      "author" : [ "A. VAN GELDER", "K.A. ROSS", "J.S. SCHLIPF" ],
      "venue" : null,
      "citeRegEx" : "GELDER et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "GELDER et al\\.",
      "year" : 1991
    }, {
      "title" : "Given a labelled logic program P, let N be a set of facts not in program P and R be a subset of rules of P. A literal L belongs to the WFM of (P\\R)∪ N iff there is a conjunction of literals D",
      "author" : [ "Damásio" ],
      "venue" : null,
      "citeRegEx" : "Damásio,? \\Q2013\\E",
      "shortCiteRegEx" : "Damásio",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "The ASP paradigm is based on the stable models semantics (Gelfond and Lifschitz 1988) and is also closely related to the other mainly accepted interpretation for default negation, well-founded semantics (WFS) (Van Gelder et al.",
      "startOffset" : 57,
      "endOffset" : 85
    }, {
      "referenceID" : 33,
      "context" : "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 115,
      "endOffset" : 262
    }, {
      "referenceID" : 4,
      "context" : "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 115,
      "endOffset" : 262
    }, {
      "referenceID" : 30,
      "context" : "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 115,
      "endOffset" : 262
    }, {
      "referenceID" : 8,
      "context" : "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 115,
      "endOffset" : 262
    }, {
      "referenceID" : 31,
      "context" : "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 115,
      "endOffset" : 262
    }, {
      "referenceID" : 27,
      "context" : "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 115,
      "endOffset" : 262
    }, {
      "referenceID" : 32,
      "context" : "itself, but can be syntactically built in some way in terms of the program rules, as studied in several approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 115,
      "endOffset" : 262
    }, {
      "referenceID" : 1,
      "context" : "2013) and Causal Graphs (CG) (Cabalar et al. 2014a).",
      "startOffset" : 29,
      "endOffset" : 51
    }, {
      "referenceID" : 11,
      "context" : "a continuous chain of events that has helped to cause or produce an effect (Hall 2004; Hall 2007).",
      "startOffset" : 75,
      "endOffset" : 97
    }, {
      "referenceID" : 12,
      "context" : "a continuous chain of events that has helped to cause or produce an effect (Hall 2004; Hall 2007).",
      "startOffset" : 75,
      "endOffset" : 97
    }, {
      "referenceID" : 1,
      "context" : "” As in the previous paper on CG (Cabalar et al. 2014a), our final goal is to achieve an elaboration tolerant representation of causality that allows reasoning about cause-effect relations.",
      "startOffset" : 33,
      "endOffset" : 55
    }, {
      "referenceID" : 1,
      "context" : "For a more detailed explanation on their induced behaviour see (Cabalar et al. 2014a).",
      "startOffset" : 63,
      "endOffset" : 85
    }, {
      "referenceID" : 28,
      "context" : "1 This behaviour coincides indeed with the properties for default negation obtained in Equilibrium Logic (Pearce 1996) or the equivalent General Theory of Stable Models (Ferraris et al.",
      "startOffset" : 105,
      "endOffset" : 118
    }, {
      "referenceID" : 7,
      "context" : "1 This behaviour coincides indeed with the properties for default negation obtained in Equilibrium Logic (Pearce 1996) or the equivalent General Theory of Stable Models (Ferraris et al. 2007).",
      "startOffset" : 169,
      "endOffset" : 191
    }, {
      "referenceID" : 5,
      "context" : "It has been shown in (Fandinno 2015a) that CG values can be alternatively characterised as a free algebra generated by rule labels under the axioms of a complete distributive lattice plus the axioms of Figure 1.",
      "startOffset" : 21,
      "endOffset" : 37
    }, {
      "referenceID" : 1,
      "context" : "According to (Cabalar et al. 2014a), a CG interpretation Ĩ is a CG stable model of a program P iff Ĩ is the least model of the program PĨ .",
      "startOffset" : 13,
      "endOffset" : 35
    }, {
      "referenceID" : 1,
      "context" : "Then, the CG stable models (Definition 13) are exactly the causal values and causal stable models defined in (Cabalar et al. 2014a).",
      "startOffset" : 109,
      "endOffset" : 131
    }, {
      "referenceID" : 2,
      "context" : "In order to formalise this idea we just take the definition of causal explanation from (Cabalar et al. 2014b).",
      "startOffset" : 87,
      "endOffset" : 109
    }, {
      "referenceID" : 20,
      "context" : "contributory) cause of B” from the behaviour of structural equations by applying, under some contingency (an alternative model in which some values are fixed) the counterfactual dependence interpretation from (Hume 1748): “had A not happened, B would not have happened.",
      "startOffset" : 209,
      "endOffset" : 220
    }, {
      "referenceID" : 10,
      "context" : "These definitions will also suffice for dealing with what Hall (2007) calls trouble cases: nonexistent threats, short-circuits, late-preemption and switching examples.",
      "startOffset" : 58,
      "endOffset" : 70
    }, {
      "referenceID" : 10,
      "context" : "These definitions will also suffice for dealing with what Hall (2007) calls trouble cases: nonexistent threats, short-circuits, late-preemption and switching examples. It is worth to mention that, in the philosophic and AI literature, the concept of contributory cause is usually discussed in the broader sense of actual causation which tries to provide an unique everyday-concept of causation. Pearl (2000) studied actual and contributory causes relying on causal networks.",
      "startOffset" : 58,
      "endOffset" : 408
    }, {
      "referenceID" : 17,
      "context" : "Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner’s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen’s shoots, but not each of them alone, as actual causes.",
      "startOffset" : 22,
      "endOffset" : 92
    }, {
      "referenceID" : 18,
      "context" : "Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner’s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen’s shoots, but not each of them alone, as actual causes.",
      "startOffset" : 22,
      "endOffset" : 92
    }, {
      "referenceID" : 11,
      "context" : "Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner’s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen’s shoots, but not each of them alone, as actual causes.",
      "startOffset" : 22,
      "endOffset" : 92
    }, {
      "referenceID" : 12,
      "context" : "Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner’s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen’s shoots, but not each of them alone, as actual causes.",
      "startOffset" : 22,
      "endOffset" : 92
    }, {
      "referenceID" : 15,
      "context" : "Later approaches like (Halpern and Pearl 2001; Halpern and Pearl 2005; Hall 2004; Hall 2007) have not made this distinction and consider the captain and the two riflemen as actual causes of the prisoner’s death, while (Halpern 2015) considers the captain and the conjunction of both riflemen’s shoots, but not each of them alone, as actual causes.",
      "startOffset" : 218,
      "endOffset" : 232
    }, {
      "referenceID" : 11,
      "context" : "In this sense, all the above approaches to actual causation, but (Hall 2004), can be classified in the dependence category.",
      "startOffset" : 65,
      "endOffset" : 76
    }, {
      "referenceID" : 12,
      "context" : "” This default criterion is also shared by (Hall 2007; Halpern 2008; Hitchcock and Knobe 2009; Halpern and Hitchcock 2011).",
      "startOffset" : 43,
      "endOffset" : 122
    }, {
      "referenceID" : 13,
      "context" : "” This default criterion is also shared by (Hall 2007; Halpern 2008; Hitchcock and Knobe 2009; Halpern and Hitchcock 2011).",
      "startOffset" : 43,
      "endOffset" : 122
    }, {
      "referenceID" : 19,
      "context" : "” This default criterion is also shared by (Hall 2007; Halpern 2008; Hitchcock and Knobe 2009; Halpern and Hitchcock 2011).",
      "startOffset" : 43,
      "endOffset" : 122
    }, {
      "referenceID" : 16,
      "context" : "” This default criterion is also shared by (Hall 2007; Halpern 2008; Hitchcock and Knobe 2009; Halpern and Hitchcock 2011).",
      "startOffset" : 43,
      "endOffset" : 122
    }, {
      "referenceID" : 11,
      "context" : "In (Hall 2004), the author relies on intrinsicness for rejecting h as a productive cause of d: any causal structure (justification) including h and p would have to include the absence of the antidote (atom a), and it would be enough that Bond had taken the antidote by another reason to break the counterfactual dependence between h and p.",
      "startOffset" : 3,
      "endOffset" : 14
    }, {
      "referenceID" : 21,
      "context" : "To illustrate late-preemention consider the following example from (Lewis 2000).",
      "startOffset" : 67,
      "endOffset" : 79
    }, {
      "referenceID" : 12,
      "context" : "The usual way of representing this scenario in the actual causation literature is by introducing two new fluents hit suzy and hit billy in the following way (Hall 2007; Halpern and Hitchcock 2011; Halpern 2014; Halpern 2015):",
      "startOffset" : 157,
      "endOffset" : 224
    }, {
      "referenceID" : 16,
      "context" : "The usual way of representing this scenario in the actual causation literature is by introducing two new fluents hit suzy and hit billy in the following way (Hall 2007; Halpern and Hitchcock 2011; Halpern 2014; Halpern 2015):",
      "startOffset" : 157,
      "endOffset" : 224
    }, {
      "referenceID" : 14,
      "context" : "The usual way of representing this scenario in the actual causation literature is by introducing two new fluents hit suzy and hit billy in the following way (Hall 2007; Halpern and Hitchcock 2011; Halpern 2014; Halpern 2015):",
      "startOffset" : 157,
      "endOffset" : 224
    }, {
      "referenceID" : 15,
      "context" : "The usual way of representing this scenario in the actual causation literature is by introducing two new fluents hit suzy and hit billy in the following way (Hall 2007; Halpern and Hitchcock 2011; Halpern 2014; Halpern 2015):",
      "startOffset" : 157,
      "endOffset" : 224
    }, {
      "referenceID" : 10,
      "context" : "Finally, consider the following example from (Hall 2000).",
      "startOffset" : 45,
      "endOffset" : 56
    }, {
      "referenceID" : 10,
      "context" : "In (Hall 2000), the author has argued that the switch should be considered a cause of the arrival because switch has contributed to the fact that the train has travelled down the right-hand track.",
      "startOffset" : 3,
      "endOffset" : 14
    }, {
      "referenceID" : 10,
      "context" : "If causality is considered to be a transitive relation, as (Hall 2000) does, the immediate consequence of the above reasoning is that flipping the switch has contributed to the train arrival.",
      "startOffset" : 59,
      "endOffset" : 70
    }, {
      "referenceID" : 12,
      "context" : "In (Hall 2007) he argues otherwise and points out that commonsense tells that the switch is not a cause of the arrival.",
      "startOffset" : 3,
      "endOffset" : 14
    }, {
      "referenceID" : 18,
      "context" : "(Halpern and Pearl 2005) had considered switch a cause of arrival depending on whether the train travelling down the tracks is represented by one or two variables in the model.",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 12,
      "context" : "Although our understanding of causality is closer to the one expressed in (Hall 2007), it is not the aim of this work to go more in depth in this discussion, but to show instead how both understandings can be represented in ECJ.",
      "startOffset" : 74,
      "endOffset" : 85
    }, {
      "referenceID" : 24,
      "context" : "As pointed out by (Maudlin 2004), causal knowledge can be structured by a combination of inertial laws – how the world would evolve if nothing intervened – and deviations from these inertial laws.",
      "startOffset" : 18,
      "endOffset" : 32
    }, {
      "referenceID" : 25,
      "context" : "In addition to the literature on actual causes cited in Section 5, our work also relates to papers on reasoning about actions and change (Lin 1995; McCain and Turner 1997; Thielscher 1997).",
      "startOffset" : 137,
      "endOffset" : 188
    }, {
      "referenceID" : 34,
      "context" : "In addition to the literature on actual causes cited in Section 5, our work also relates to papers on reasoning about actions and change (Lin 1995; McCain and Turner 1997; Thielscher 1997).",
      "startOffset" : 137,
      "endOffset" : 188
    }, {
      "referenceID" : 33,
      "context" : "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 98,
      "endOffset" : 245
    }, {
      "referenceID" : 4,
      "context" : "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 98,
      "endOffset" : 245
    }, {
      "referenceID" : 30,
      "context" : "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 98,
      "endOffset" : 245
    }, {
      "referenceID" : 8,
      "context" : "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 98,
      "endOffset" : 245
    }, {
      "referenceID" : 31,
      "context" : "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 98,
      "endOffset" : 245
    }, {
      "referenceID" : 27,
      "context" : "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 98,
      "endOffset" : 245
    }, {
      "referenceID" : 32,
      "context" : "Focusing on LP, our work obviously relates to explanations obtained from ASP debugging approaches (Specht 1993; Denecker and Schreye 1993; Pemmasani et al. 2004; Gebser et al. 2008; Pontelli et al. 2009; Oetsch et al. 2010; Schulz and Toni 2013).",
      "startOffset" : 98,
      "endOffset" : 245
    }, {
      "referenceID" : 31,
      "context" : "A formal relation between (Pontelli et al. 2009) and WnP was established in (Damásio et al.",
      "startOffset" : 26,
      "endOffset" : 48
    }, {
      "referenceID" : 28,
      "context" : "stable model semantics and replacing the syntactic definition in favour of a logical treatment of default negation, as done for instance with the Equilibrium Logic (Pearce 1996) characterisation of stable models.",
      "startOffset" : 164,
      "endOffset" : 177
    }, {
      "referenceID" : 6,
      "context" : "Other natural steps would be the consideration of syntactic operators, for capturing more specific knowledge about causal information as done in (Fandinno 2015b) capturing sufficient causes in the CG approach, and also the representation of non-deterministic causal laws, by means of disjunctive programs or the incorporation of probabilistic knowledge.",
      "startOffset" : 145,
      "endOffset" : 161
    } ],
    "year" : 2016,
    "abstractText" : "To appear in Theory and Practice of Logic Programming (TPLP). In this paper we propose an extension of logic programming (LP) where each default literal derived from the well-founded model is associated to a justification represented as an algebraic expression. This expression contains both causal explanations (in the form of proof graphs built with rule labels) and terms under the scope of negation that stand for conditions that enable or disable the application of causal rules. Using some examples, we discuss how these new conditions, we respectively call enablers and inhibitors, are intimately related to default negation and have an essentially different nature from regular cause-effect relations. The most important result is a formal comparison to the recent algebraic approaches for justifications in LP: Why-not Provenance (WnP) and Causal Graphs (CG). We show that the current approach extends both WnP and CG justifications under the Well-Founded Semantics and, as a byproduct, we also establish a formal relation between these two approaches.",
    "creator" : "LaTeX with hyperref package"
  }
}