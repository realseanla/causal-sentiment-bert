{
  "name" : "1409.7281.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Causal Graph Justifications of Logic Programs∗",
    "authors" : [ "Pedro Cabalar", "Jorge Fandinno", "Michael Fink" ],
    "emails" : [ "jorge.fandino}@udc.es)", "fink@kr.tuwien.ac.at)" ],
    "sections" : [ {
      "heading" : null,
      "text" : "KEYWORDS: Answer Set Programming, Causality, Knowledge Representation, Multi-valued Logic Programming"
    }, {
      "heading" : "1 Introduction",
      "text" : "An important difference between classical models and most Logic Programming (LP) semantics is that, in the latter, true atoms must be founded or justified by a given derivation. Consequently, falsity is understood as absence of proof: for instance, a common informal way reading for default literal not p is “there is no way to derive p.” Although this idea seems quite intuitive, it actually resorts to a concept, the ways to derive p, outside the scope of the standard LP semantics. In other words, LP semantics point out whether there exists some derivation for an atom, but do not provide the derivations themselves, if several alternatives exist.\nHowever, such information on justifications for atoms can be of great interest for Knowledge Representation (KR), and especially, for dealing with problems related to causality. In the area of diagnosis, for instance, when a discrepancy between expected and observed behaviour\n∗ This research was partially supported by Spanish MEC project TIN2009-14562-C05-04, Xunta program INCITE 2011 and Inditex-University of Corunna 2013 grants, as well as by the Austrian Science Fund (FWF) project P24090.\nar X\niv :1\n40 9.\n72 81\nv1 [\ncs .A\nis found, it may be convenient to not only exhibit a set of malfunctioning components as explanation, but also the way (a causal graph) in which these breakdowns have eventually caused the discrepancies. Another potential application area is legal reasoning where determining a legal responsability usually involves finding out which agent or agents have eventually caused a given result, regardless the chain of effects involved in the process. An important challenge in causal reasoning is the capability of not only deriving facts of the form “A has caused B,” but also being able to represent them and reason about them. As an example, take the assertion:\n“If somebody causes an accident, (s)he is legally responsible for that.” This law does not specify the possible ways in which a person may cause an accident. Depending on a representation of the domain, the chain of events from the agent’s action(s) to the final effect may be simple (a direct effect) or involve a complex set of indirect effects and defaults like inertia. Regarding representation of the above law, for instance, one might think of an informal rule:\nresponsible(X ,Y )← action(A), person(X), accident(Y ), “do(A,X) caused occurs(Y )” .\nIf the pseudo-literal “do(A,X) caused occurs(Y )” actually corresponds to an explicit representation of all the possible ways of causing an accident, however, one immediately runs into a problem of elaboration tolerance (McCarthy 1998) — adding new rules that causally connect do(A,X) to occurs(Y ) (in a direct or indirect way) would force us to build new rules for responsible(X ,Y ). What is needed instead, and what we actually propose as an eventual aim and future extension of our work, is to introduce, indeed, some kind of new LP literal “A caused B,” with an associated semantics capable of revealing causes A of a given true atom B.\nWhile not straightforward, the rewarding perspective of such a semantic approach is an extension of Answer Set Programming (ASP) (Brewka et al. 2011) with causal literals capable of representing different kinds of causal influences (sufficient cause, necessary cause, etc). In this paper, we tackle the above issue and, as a first step and basic underlying requirement, develop a suitable semantics capable of associating causal justifications with each true atom. To this end, we propose a multi-valued extension of logic programs under the stable model semantics (Gelfond and Lifschitz 1988) where each true atom in a model is associated with a set of justifications in the form of causal graphs. To further illustrate our motivation, consider the following example.\nExample 1 (From Cabalar 2011) Some country has a law l that asserts that driving drunk is punishable with imprisonment. On the other hand, a second law m specifies that resisting arrest has the same effect. The execution e of a sentence establishes that a punishment implies imprisonment. Suppose that some person drove drunk and resisted to be arrested.\nWe can capture this scenario with the following logic program P1:\nl : punish← drive, drunk m : punish← resist e : prison← punish d : drive k : drunk r : resist\nThe least model of this positive program makes atom prison true, so we know that there exists a possible derivation for it. In particular, two alternative justifications can be made, corresponding to the graphs in Figure 1(a): driving drunk and, independently, resisting to authority (vertices and edges respectively corresponds with rule labels and their dependences).\nMore specifically, we summarise our contributions as follows. • We define a multi-valued semantics for (normal) logic programs based on causal graphs.\nAn important result is that, despite of this semantic nature, we are able to show that causal\nvalues have a direct correspondence to (relevant) syntactic proofs using the program rules involved in the graphs (cf. Section 4). • We also define an ordering relation that specifies when a cause is stronger than another, and show how causal values form a lattice with three associated algebraic operations: a product ‘∗’ representing conjunction or joint causation; a sum ‘+’ representing alternative causes; and a non-commutative product ‘·’ that stands for rule application. We study beneficial properties of these operations that allow manipulating and reasoning with causal values in an analytical way (cf. Sections 2 and 3). Fostered by its algebraic treatment of causal values, our work facilitates the incorporation of dedicated, more specific causal expressions representing causal influence of different kinds."
    }, {
      "heading" : "2 Causes as graphs",
      "text" : "In this and subsequent Section 3, we introduce the lattice of causal values in two different steps. In a first step, we focus on the idea of an “individual” cause and then we proceed to explain the concept of causal value that allows collecting different alternative causes.\nWe begin recalling several graph definitions and notation. A (directed) graph is a pair 〈V,E〉 where V is a set of vertices V and E is a set of edges E ⊆V ×V . In the following definitions, let G = 〈V,E〉 and G′ = 〈V ′,E ′〉 be two graphs. We say that G is a subgraph of G′, written G⊆ G′, when V ⊆V ′ and E ⊆E ′. We write G∪G′ to stand for the graph 〈V ∪V ′,E∪E ′〉. We represent the reflexive and transitive closure of G as G∗. Finally, we introduce a concatenation operation G G′ on graphs corresponding to a graph with vertices V ∪V ′ and edges E∪E ′∪{(x,y) | x∈V,y∈V ′}. Notice that, G∪G′ ⊆G G′, that is, the concatenation extends the union of graphs by adding all possible arcs that go from some node in G to some node in G′.\nDefinition 1 (Causal graph) Given some set Lb of (rule) labels, a causal graph (c-graph) G is a reflexively and transitively closed directed graph, i.e., G∗ = G, whose vertices are labels, i.e. V ⊆ Lb. We denote by CLb the set of all possible causal graphs over Lb.\nIntuitively, the vertices correspond to rules involved in a derivation of a given atom (or formula), and the edges point out a (partial) ordering of application of rules in the derivation. Figure 1(a) shows two causal graphs with labels from P1. Transitivity is crucial for interpreting the subgraph relation G⊆ G′ as a way to express that G′ is redundant with respect to G. For instance, a graph G3 formed by the single edge (r,e) is not a subgraph of G2 but is simpler (does not require using m). This fact is captured by G∗3 ⊆ G∗2. Reflexivity is convenient for simpler definitions. For\ninstance, the causal graph formed by a single label l also has a single edge (l, l)—we call this an atomic causal graphs and represent it just by its label. For simplicity, we will usually omit transitive and reflexive arcs when depicting a causal graph. For instance, taking G1 and G2 in Figure 1(a) as causal graphs actually amounts to considering the graphs shown in Figure 1(b), where previously omitted arcs are shown as dotted lines. We define next a natural ordering relation among them.\nDefinition 2 (Sufficient) A causal graph G is sufficient for another causal graph G′, written G≤ G′, when G⊇ G′.\nSaying that G is sufficient for G′ intuitively means that G contains enough information to yield the same effect than G′, but perhaps more than needed (this explains G ⊇ G′). For this reason, we sometimes read G≤ G′ as “G′ is stronger than G.”\nSince graphs with the subgraph relation form a poset, the set of causal graphs also constitutes a poset 〈CLb,≤〉 with a top element corresponding to the empty c-graph G /0 = 〈 /0, /0〉. This stands for a kind of “absolute truth” and is of interest for including rules or facts one does not want to label, that is, their effect will not be traced in the justifications.\nAny causal graph can be built up from labels (atomic causal graphs) using two basic operations: the product G∗G′ def= (G∪G′)∗ that stands for union of causal graphs or joint interaction, and the concatenation G ·G′ def= (G G′)∗ that captures their sequential application. The reason for applying a closure is that the result of G∪G′ and G G′ does not need to be closed under transitivity. We can extend the product to any (possibly empty and possibly infinite) set of causal graphs S so that ∏S def= ( ⋃ G∈S G\n)∗. Example 2 (Ex. 1 continued) The cause for the body of l in P1 is the product of causes for drive and drunk, that is d ∗ k formed with vertices {d,k} and edges {(d,d),(k,k)}. As a result, the explanation of the rule head, punish, is formed by the concatenation of its body cause d ∗k with its label, that is (d ∗k) · l. In its turn, this becomes the cause for the body of e and so, we get the explanation (d ∗ k) · l · e for atom prison represented as G1 in Figure 1(b). Similarly, G2 corresponds to r ·m · e.\nWhen writing these causal expressions, we assume that ‘·’ has higher priority than ‘∗’. Furthermore, we will usually omit ‘·’ when applied to consecutive labels, so that r ·m · e will be abbreviated as rme. It is easy to see that G ∗G′ = G′ ∗G while, in general, G ·G′ 6= G′ ·G, that is, concatenation is not commutative. Another observation is that G ·G′ ≤ G ∗G′, that is, concatenation is sufficient for the product, but the opposite does not hold in general. Moreover, in our running example, we can check that (d ∗ k) · l is equal to (d · l) ∗ (k · l). In fact, application distributes over products and, as a result, we can identify any causal graph with the product of all its edges. To conclude this section, we note that the set of causal graphs CLb ordered by ≤ forms a lower semilattice 〈CLb,∗〉, where the product constitutes the infimum."
    }, {
      "heading" : "3 Alternative causes",
      "text" : "Having settled the case for individual causes, let us now proceed to represent situations in which several alternative and independent causes can be found for an atom p. The obvious possibility is just using a set of causal graphs for that purpose. However, we should additionally disregard causes for which a stronger alternative exists. For instance, as we saw before, cause rme is sufficient for explaining punish and therefore, it is also an alternative way to prove this atom, but redundant in the presence of the stronger cause rm. This suggests to choose sets of ≤-maximal\ncausal graphs as ‘truth values’ for our multi-valued semantics. In principle, this is the central idea, although≤-maximal causal graphs incur some minor inconveniences in mathematical treatment. For instance, if we collect different alternative causes by just using the union of sets of maximal causal graphs, the elements in the result need not be maximal. Besides, the operations of product and concatenation are expected to extend to the sets adopted as causal values. To address these issues, a more solid representation is obtained resorting to ideals of causal graphs.\nGiven any poset 〈A,≤〉, an ideal I is any set I ⊆ A satisfying1: if x ∈ I and y ≤ x then y ∈ I. A compact way of representing an ideal I is by using its set of maximal elements S, since the rest of I contains all elements below them. The principal ideal of an individual element x ∈ A is denoted as ↓ x def= {y ∈ A | y ≤ x}. We extend this notion for any set of elements S so that ↓ S def= ⋃ {↓ x | x ∈ S}= {y ∈ A | y≤ x, for some x ∈ S}. Thus, we will usually represent an ideal I as ↓ S where S are the maximal 2 elements in I. In fact, maximal elements constitute the relevant information provided by the ideal, while keeping all other elements is convenient for simplicity of algebraic treament (but we do not assign a particular meaning to them).\nDefinition 3 (Causal Value) Given a set of labels Lb, a causal value is any ideal for the poset 〈CLb,≤〉. We denote by VLb the set of causal values.\nProduct, concatenation and the ≤-relation are easily extended to any pair U , U ′ of causal values respectively as: U ∗U ′ def= U ∩U ′ and U ·U ′ def= ↓{ G ·G′ ∣∣ G ∈U and G′ ∈U ′ } and U ≤U ′ iff U ⊆ U ′. We also define addition as: U +U ′ def= U ∪U ′ allowing to collect alternative causes. Using terminology and results from lattice theory in (Stumme 1997) we can prove the following.\nTheorem 1 VLb forms a free, completely distributive lattice with join + and meet ∗ generated by the lower semilattice 〈CLb,∗〉 with the injective homomorphism (or embedding) ↓: CLb −→ VLb . Essentially, this theorem means that the mapping ↓ from c-graph G to its principal ideal ↓G is preserved for their respective products, ↓(G1 ∗G2) =↓G1 ∗ ↓G2, and ordering relations: G1 ≤ G2 (among c-graphs) iff ↓G1 ≤ ↓G2 (among causal values). Example 3 (Ex. 1 continued) The interpretation for punish has two alternative causes (d ∗ k) · l and rm that become the causal values ↓(d ∗ k) · l and ↓rm. The causal value for punish is then formed by their addition: ↓(d ∗ k) · l + ↓rm = ↓(d ∗ k) · l ∪ ↓rm = ↓{ (d ∗ k) · l, rm } This ideal contains, among others, the cause rme, although it is not maximal due to rm:\n↓{ (d ∗ k) · l, rm } ∪ ↓rme = ↓{ (d ∗ k) · l, rm, rme} = ↓{ (d ∗ k) · l, rm }\nThe term completely distributive lattice in Theorem 1 means that meet (resp. join) operation is defined for any infinite subset of VLb and distributes over infinite joins (resp. meets). There is also a bottom element, the empty ideal /0 (standing for “falsity”) that will be denoted as 0, and a top element, the ideal formed by the empty causal graph ↓G /0 = CLb (standing for “absolute truth”) that is denoted as 1 from now on. To improve readability, we introduce the syntactic notion of causal terms, that allow representing the possible causal values without explicitly resorting to graphs or ideals.\n1 We use terminology from (Stumme 1997). In some texts this is known as semi-ideal or down-set to differentiate this definition from the stronger case in which ideals are applied on a (full) lattice rather than a semi-lattice. 2 Note that, in the case of causal graphs, the existence of maximal elements for the ≤-relation amounts to the existence of minimal elements for the subgraph relation, and this holds since the latter is well-founded.\nDefinition 4 (Causal term) A (causal) term, t, over a set of labels Lb, is recursively defined as one of the following expressions t ::= l | ∏S | ∑S | t1 ·t2 where l ∈ Lb, t1, t2 are in their turn causal terms and S is a (possibly empty and possible infinite) set of causal terms. When S is finite and non-empty, S = {t1, . . . , tn} we write ∏S simply as t1 ∗ · · · ∗ tn and ∑S as t1 + · · ·+ tn.\nWe assume that ‘∗’ has higher priority than ‘+’. The causal value associated to a causal term is naturally obtained by the recursive application of its operators until we reach the level of labels, so that each label l in the term actually stands for the principal ideal ↓ l. When S = /0, the union in S corresponds to the bottom causal value that is, ∑ /0 = 0. Analogously, the intersection of elements in S = /0 corresponds to top causal value, i.e., ∏ /0 = 1.\nFrom now on, we will use causal terms as compact representations of causal values. Individual causes (i.e. causal graphs) correspond to terms without addition (note that this also excludes 0, the empty sum). Several interesting algebraic properties can be proved for causal values. In particular, Theorem 1 guarantees that they form a free completely distributive lattice with respect to ‘∗’ and ‘+’ satisfying the standard properties such as associativity, commutativity, idempotence, absorption or distributivity on both directions3. Besides, as usual, 0 (resp. 1) is the annihilator for ‘∗’ (resp. ‘+’) and the identity for ‘+’ (resp. ‘∗’). More significantly, the main properties for ‘·’ are shown in Figure 2."
    }, {
      "heading" : "4 Positive programs and minimal models",
      "text" : "Let us now reconsider logic programs and provide a semantics based on the causal values we have just defined. For the syntax, we recall standard LP definitions, just slightly extending it by introducing rule labels. A signature is a pair 〈At,Lb〉 of sets that respectively represent a set of atoms (or propositions) and a set of labels. As usual, a literal is defined as an atom p (positive literal) or its default negation not p (negative literal). In this paper, we will concentrate on programs without disjunction in the head (leaving its treatment for future work).\nDefinition 5 (Causal logic program) Given a signature 〈At,Lb〉, a (causal) logic program P is a (possible infinite) set of rules of the form: t : H← B1, . . . ,Bn, (1) where t ∈ Lb∪{1}, H is an atom (the head of the rule) and B1, . . . ,Bn are literals (the body).\nFor any rule R of the form (1) we define label(R) def= t. We denote by head(R) def= H its head, and by body(R) def= {B1, . . . ,Bn} its body. When n = 0 we say that the rule is a fact and omit the symbol ‘←.’ When t ∈ Lb we say that the rule is labelled; otherwise t = 1 and we omit both t\n3 The term “free lattice” in Theorem 1 means that any equivalence with ∗ and + can be derived from these properties.\nand ‘:’. By these conventions, for instance, an unlabelled fact p is actually an abbreviation of (1 : p←). A logic program P is positive if it contains no default negation. A program is uniquely labelled if no pair of labelled rules share the same label, and completely labelled if, additionally, all rules are labelled. For instance, P1 is completely labelled.\nGiven a signature 〈At,Lb〉 a causal interpretation is a mapping I : At −→ VLb assigning a causal value to each atom. For any interpretations I, J, we say that I ≤ J when I(p) ≤ J(p) for each atom p ∈ At. Hence, there is a ≤-bottom (resp. ≤-top) interpretation 0 (resp. 1) that stands for the interpretation mapping each atom p to 0 (resp. 1). The value assigned to a negative literal not p by an interpretation I, denoted as I(not p), is defined as: I(not p) def= 1 if I(p) = 0; and I(not p) def= 0 otherwise. An interpretation is two-valued if it maps all atoms to {0,1}. Furthermore, for any causal interpretation, its corresponding two-valued interpretation, written Icl , is defined so that for any atom p: Icl(p) def= 0 if I(p) = 0; and Icl(p) def= 1 otherwise.\nDefinition 6 (Causal model) Given a positive causal logic program P, a causal interpretation I is a causal model, in symbols I |= P, if and only if, for each rule R ∈ P of the form (1), the following condition holds:(\nI(B1)∗ . . .∗ I(Bn) ) · t ≤ I(H)\nExample 4 (Ex. 1 continued) Take rule l from program P1 and let I be such that I(drive) = d and I(drunk) = k. Then I will be a model of l when (d∗k) · l≤ I(punish). In particular, this holds when I(punish) = (d ∗ k) · l + r ·m which was the value we expected for that atom. But it would also hold when, for instance, I(punish) = l +m or I(punish) = 1. The inequality in Definition 6 is important to accommodate possible additional facts such as (l : punish) or even (1 : punish) in the program.\nThe fact that any I(punish) greater than (d ∗k) · l+ r ·m also becomes a model clearly points out the need for selecting minimal models. In fact, as it is the case for non-causal programs, positive programs have a≤-least model that can be computed by iterating an extension of the well-known direct consequences operator (van Emden and Kowalski 1976).\nDefinition 7 (Direct consequences) Given a positive logic program P over signature 〈At,Lb〉, the operator of direct consequences is a function TP : I−→ I such that, for any causal interpretation I and any atom p ∈ At:\nTP(I)(p) def= ∑ { ( I(B1)∗ . . .∗ I(Bn) ) · t | (t : p← B1, . . . ,Bn) ∈ P } Theorem 2 Let P be a (possibly infinite) positive logic program with n causal rules. Then, (i) lfp(TP) is the least model of P, and (ii) lfp(TP) = TP ↑ ω (0) = TP ↑ n (0).\nThe proof of this theorem relies on an encoding of causal logic programs into Generalized Annotated Logic Programming (GAP) (Kifer and Subrahmanian 1992) and applying existing results for that general multi-valued LP framework. Theorem 2 just guarantees that the least fixpoint of TP is well-behaved, but does not explain the nature of the obtained causal values. We illustrate next that these values have a direct relation to the syntactic idea of proof in a positive program.\nDefinition 8 Given a positive program P, a proof π(p) of an atom p can be recursively defined as a derivation:\nπ(p) def= π(B1) . . . π(Bn)\np (R),\nwhere R ∈ P is a rule with head(R) = p and body(R) = {B1, . . . ,Bn}. When n = 0, the derivation antecedent π(B1) . . . π(Bn) is replaced by > (corresponding to the empty body).\nEach derivation in a proof is a particular application of Modus Ponens where, once the body (conjunction of literals B) of a rule R (p← B) has been proved, then the head p can be concluded.\nExample 5 (Ex. 1 continued) Program P1 is positive and, in fact, completely labelled, so we can identify each rule with its label. Atom prison can be derived in P1 using the two proofs on the left in Figure 3. These two proofs have a clear correspondence to causes (d ∗ k) · le and rme depicted in Figure 1(b). In fact, the least model I of P1 assigns causal value I(punish) = (d ∗ k) · le+ rme.\nLet P be a positive, completely labelled program. Given a proof π , we define its graph Gπ as follows. For each sub-derivation in π of the form π(p) in Definition 8 we include an edge (li,m) where m is the label of rule R and li is the label of the top-level rule in π(Bi), for all i = 1, . . . ,n. The vertices in Gπ exclusively collect the labels in those edges. We define graph(π) def= G∗π . The two left proofs in Figure 3 are then obviously mapped to the causal graphs in Figure 1(b). If Π is a set of proofs, we define graph(Π) def= {graph(π) | π ∈Π}.\nA proof can be sometimes redundant, in the sense that some of its derivation steps could be removed. A natural way of defining a non-redundant proof is resorting to its associated graph. We say that a proof π(p) of an atom p in a positive, completely labelled program P is redundant if there exists another proof of p, π ′(p), such that graph(π(p))≤ graph(π ′(p)), in other words, we can build another proof π ′ with a smaller associated graph.\nExample 6 Suppose that we introduce an atom sentence which acts as a synonym for punish. Furthermore, assume law m mentions sentence as its head now, instead of punish. Hence, let P2 be program:\nl : punish← drive,drunk d : drive n : punish← sentence m : sentence← resist k : drunk s : sentence← punish e : prison← punish r : resist\nThen, the rightmost proof shown in Figure 3 together with its associated graph (d ∗ k) · lsne is redundant, since the (still valid) leftmost proof in Figure 3 for prison has an associated stronger cause (or smaller graph) (d ∗ k) · le. Considering the positive loop formed by n and s, one may wonder why it does not spoil the computation of TP2 to iterate forever (adding more and more\nconcatenations of n and s). The reason is that, at a given point, subsequent iterations yield redundant graphs subsumed by previous steps. In particular, the iteration of TP2 yields the steps:\ni drive drunk resist sentence punish prison\n1 d k r 0 0 0 2 d k r rm (d ∗ k) · l 0 3 d k r rm+(d ∗ k) · ls (d ∗ k) · l + rmn (d ∗ k) · le 4 d k r rm+(d ∗ k) · ls (d ∗ k) · l + rmn ((d ∗ k) · l + rmn) · e\nreaching a fixpoint at step 4. The value for sentence at step 4 would actually be the sum of rm (derived from resist) with the value of punish in the previous step, (d ∗k) · l+ rmn followed by s. This corresponds to:\nrm+((d ∗ k) · l + rmn︸ ︷︷ ︸ punish ) · s = rm+(d ∗ k) · ls+ rmns distributivity = rm+ rmns+(d ∗ k) · ls commutativity = rm+ rm ·ns+(d ∗ k) · ls associativity = rm+1 · rm ·ns+(d ∗ k) · ls identity = rm+(d ∗ k) · ls absorption for ‘+’ and ‘·’\nThat is, iterating the loop rmns is redundant since a stronger cause rm was obtained before.\nTheorem 3 Let P be a positive, completely labelled program, and Πp the set of non-redundant proofs of some atom p with respect to P. If I denotes the least model of P, then:\nG ∈ graph(Πp) iff G is a maximal causal graph in I(p)\nNote the importance of this result: it reveals that the information we obtain by a purely semantic treatment of causal values (computing the least model by algebraic operations) has a one-to-one correspondence to syntactic proofs obtained by modus ponens that are further guaranteed to be non-redundant (they do not contain unnecessary steps). Completely labelled programs are interesting for establishing the correspondence in the theorem above, but there are several scenarios in which one may be interested in disregarding the effect of rules in a program or in identifying a group of rules under the same label.\nExample 7 Let P3 be the following variation of P2:\nz : sentence← drive,drunk d : drive punish← sentence z : punish← resist k : drunk sentence← punish e : prison← punish r : resist\nwhere l and m in P2 are now just two cases of a common law z, and punish and sentence depend on each other through unlabelled rules.\nRemoving the labels in the positive cycle between sentence and punish captures the idea that, since they are synonyms, whenever we have a cause for sentence, it immediately becomes a cause for punish and vice versa. By iterating the TP operator, it is not difficult to see that the least causal model I3 makes the assignments I3(sentence) = I3(punish) = (d ∗ k) · z+ rz (that is sentence and punish are equivalent) and I3(prison) = (d ∗ k) · ze+ rze. This result could also be computed from the least model I2 for P2 by replacing l and m by z and “removing” n and s (that\nis, replacing them by 1). This is, in fact, a general property we formalise as follows. Given two causal terms t,u and a label l, we define t[l 7→ u] as the result of replacing label l in t by term u.\nTheorem 4 Let P be a positive causal logic program and P′ be the result of replacing a label l in P by some u, where u is any label or 1. Furthermore, let I and I′ be the least models of P and P′, respectively. Then, I′(p) = I(p)[l 7→ u] for any atom p.\nIn particular, in our example, I3(p) = I2(p)[l 7→ z][m 7→ z][n 7→ 1][s 7→ 1], for any atom p. If we remove all labels in a program, we eventually get a standard, unlabelled program. Obviously, its least model will be two-valued, since removing all labels in causal terms, eventually collapses all of them to {0,1}. As a result, we can easily establish the following correspondence.\nTheorem 5 Let P be a causal positive logic program and P′ its unlabelled version. Furthermore, let I be the least causal model of P and I′ the least classical model of P′. Then I′ = Icl ."
    }, {
      "heading" : "5 Default negation",
      "text" : "To introduce default negation, let us consider the following variation of our running example.\nExample 8 Assume now that law e is a default and that there may be exceptional cases in which punishment is not effective. In particular, some of such exceptions are a pardon, that the punishment was revoked, or that the person has diplomatic immunity. A possible program P4 encoding this variant of the scenario is:\nl : punish← drive,drunk d : drive abnormal← pardon m : punish← resist k : drunk abnormal← revoke e : prison← punish,not abnormal r : resist abnormal← diplomat\nThis program has a unique stable model which still keeps prison true, since no proof for abnormal could be obtained, i.e. no exception occurred.\nFrom a causal perspective, saying that the lack of an exception is part of a cause (e.g., for imprisonment) is rather counterintuitive. It is not the case that we go to prison because of not receiving a pardon, not having a punishment revocation, not being a diplomat, or whatever possible exception that might be added in the future4. Instead, as nothing violated default e, the justifications for prison should be those shown in Figure 1(a). In this way, falsity becomes the default situation that is broken when a cause is found5. This interpretation carries over to negative literals, so that the presence of not p in a rule body does not propagate causal information, but instead is a check for the absence of an exception. To capture this behaviour, we proceed to extend the traditional program reduct (Gelfond and Lifschitz 1988) to causal logic programs.\n4 A case of the well-known qualification problem (McCarthy 1977), i.e., the impossibility of listing all the possible conditions that prevent an action to cause a given effect. Appendix B (available online) contains a more elaborated example showing how the qualification problem may affect causal explanations when inertia is involved. 5 The paper (Hitchcock and Knobe 2009) contains an extended discussion with several examples showing how people ordinarily understand causes as deviations from a norm.\nDefinition 9 (Program reduct) The reduct of program P with respect to causal interpretation I, in symbols PI , is the result of:\n1. removing from P all rules R, s.t. I(B) 6= 0 for some negative literal B ∈ body(R); 2. removing all negative literals from the remaining rules of P.\nAn interpretation I is a causal stable model of program P iff I is the least causal model of PI .\nExample 9 (Ex. 8 continued) Suppose that we add atoms (p : pardon) and (d : diplomat) to program P4. The only stable model I of this extended program makes I(prison) = 0 and I(abnormal) = p+d as expected.\nTheorem 6 (Correspondence to non-causal stable models) Let P be a causal logic program and P′ its unlabelled version. Then:\n1. If I is a causal stable model of P, then Icl is a stable model of P′. 2. If I′ is a stable model of P′ then there is a unique causal stable model I of P s.t. I′ = Icl .\nThis theorem also shows a possible method for computing causal stable models of a program P. We may first run a standard ASP solver on the unlabelled version of P to obtain a stable model I′. This stable model I′ has a corresponding causal stable model I, such that I′ = Icl and both interpretations coincide in their assignment of 0’s. Therefore, PI = PI ′ and we can use the latter to iterate the TP operator and obtain the least causal model of this reduct, which will mandatorily be a causal stable model due to Theorem 6."
    }, {
      "heading" : "6 Related Work",
      "text" : "Cabalar (2011) already introduced the main motivations of our work, but used ad hoc operations on proof trees without resorting to algebraic structures. A preliminary version (Cabalar and Fandinno 2013) of the current approach relied on chains of labels but was actually weaker, missing basic properties we can derive now from causal graphs.\nThere exists a vast literature on causal reasoning in Artificial Intelligence. Papers on reasoning about actions and change (Lin 1995; McCain and Turner 1997; Thielscher 1997) have been traditionally focused on using causal inference to solve representational problems (mostly, the frame, ramification and qualification problems) without paying much attention to the derivation of cause-effect relations. Perhaps the most established AI approach for causality is relying on causal networks (Pearl 2000; Halpern and Pearl 2005; Halpern 2008). In this approach, it is possible to conclude cause-effect relations like “A has caused B” from the behaviour of structural equations by applying the counterfactual interpretation from Hume (1748): “had A not happened, B would not have happened.” As discussed by Hall (2004), the counterfactual-based definition of causation corresponds to recognising some kind of dependence relation in the behaviour of a non-causal system description. As opposed to this, Hall considers a different (and incompatible) definition where causes must be connected to their effects via sequences of causal intermediates, something that is closer to our explanations in terms of causal graphs.\nApart from the different AI approaches and attitudes towards causality, from the technical point of view, the current approach can be classified as a labelled deductive system (Broda et al. 2004). In particular, the work that has had a clearest and most influential relation to the current proposal is the Logic of Proofs (LP) by Artëmov (2001). We have borrowed from that formalism part of the notation for our causal terms and rule labellings and the fundamental idea of keeping track of justifications by considering rule applications.\nFocusing on LP, our work obviously relates to explanations as provided by approaches to debugging in ASP (Gebser et al. 2008; Pontelli et al. 2009; Schulz et al. 2013; Damásio et al. 2013). Pereira et al. (1991) and Denecker and De Schreye (1993) also define different semantics in terms of justifications, but do not provide calculi for them. In these works, explanations usually contain all possible ways to derive an atom or to prevent its derivation, including paths through negation. This differs from a KR orientation where only the cause-effect relations that “break the norm” should be considered relevant. This point of view is also shared, e.g., by the counterfactualbased causal LP approach (Vennekens 2011). Fages (1991) characterised stable models in terms of loop-free justifications expressed as partial order relations among atoms in positive bodies. We conjecture that the causal values obtained in our semantics formally capture Fages’ justifications. A more far-fetched resemblance exists to work on the analysis of tabled Prolog computations. There, the goal is to identify potential causes for non-termination of program evaluations, which can be achieved examining so-called forest logs, i.e., a log of table operations for a computation. By adding unique labels for rules (with the original intention to disambiguate analysis results, cf. Liang and Kifer (2013), however not as an explicit means for representing knowledge), in principle a forest log implicitly contains the information necessary to read of the causal model of a completely labelled positive causal logic program."
    }, {
      "heading" : "7 Conclusions",
      "text" : "In this paper we have provided a multi-valued semantics for normal logic programs whose truth values form a lattice of causal graphs. A causal graph is nothing else but a graph of rule labels that reflects some order of rule applications. In this way, a model assigns to each true atom a value that contains justifications for its derivation from the existing rules. We have further provided three basic operations on the lattice: an addition, that stands for alternative, independent justifications; a product, that represents joint interaction of causes; and a concatenation that reflects rule application. We have shown that, for positive programs, there exists a least model that coincides with the least fixpoint of a direct consequences operator, analogous to van Emden and Kowalski (1976). With this, we are able to prove a direct correspondence between the semantic values we obtain and the syntactic idea of proof. These results have been extrapolated to stable models of programs with default negation, understanding the latter as “absence of cause.” Although, for space reasons, we have not dealt with programs with variables, their semantics is obtained from their (possibly infinite) grounding, as usual.\nSeveral topics remain open for future study. An interesting issue is to replace the syntactic definition by a reduct in favour of a logical treatment of default negation, as has been done for (noncausal) stable models and their characterisation in terms of Equilibrium Logic (Pearce 2006). Regarding the representation of causal information, a natural next step would be the consideration of syntactic operators for more specific knowledge like the influence of a particular event or label in a conclusion, expressing necessary or sufficient causes, or even dealing with counterfactuals. Further ongoing work is focused on implementation, complexity assessment, and an extension to disjunctive programs, respectively the introduction of strong negation. Exploring related areas of KR and reasoning, such as, e.g., Paraconsistent Reasoning and Belief Revision, seems promising with respect to extending the range of problems to which our approach may effectively be applied.\nAcknowledgements We are thankful to David Pearce, Manuel Ojeda, Jesús Medina, Carlos Damasio and Joost Vennekens for their suggestions and comments on earlier versions of this work. We also thank the anonymous reviewers for their help to improve the paper."
    }, {
      "heading" : "Appendix A. Auxiliary figures",
      "text" : ""
    }, {
      "heading" : "Appendix B. An example of causal action theory",
      "text" : "In this section we consider a more elaborated example from Pearl (2000).\nExample 10 Consider the circuit in Figure 5 with two switches, a and b, and a lamp l. Note that a is the main switch, while b only affects the lamp when a is up. Additionally, when the light is on, we want to track which wire section, v or w, is conducting current to the lamp.\nAs commented by Pearl (2000), the interesting feature of this circuit is that, seen from outside as a black box, it behaves exactly as a pair of independent, parallel switches, so it is impossible to detect the causal dependence between a and b by a mere observation of performed actions and their effects on the lamp. Figure 5 also includes a possible representation for this scenario; let us call it program P5. It uses a pair of fluents up(X) and down(X) for the position of switch X , as well as on and off to represent the state of the lamp. Fluents up(X) and down(X) (respectively, on and off) can be seen as the strong negation of each other, although we do not use an operator for that purpose6. Action m(X ,D) stands for “move switch X in direction D ∈ {u,d}” (up and down, respectively). Actions between state t and t +1 are located in the resulting state. Finally, we have also labelled inertia laws (by i) to help keeping track of fluent justifications inherited by persistence.\nSuppose we perform the following sequence of actions: we first move down both switches, next switch b is moved first up and then down, and finally we move up switch a. Assume also that each action occurrence is labelled with the action name so that, for instance, moving b up in Situation 1 corresponds to the program fact m(b,u)1 : m(b,u)1. The table in Figure 6 shows the resulting temporal projection. Note how the lamp turns on in Situation 1 but only because of v, that is, moving a down. Movements of b at 2 and 3 do not affect the lamp, and its causal explanation (down(a)) is maintained by inertia. In Situation 4, the lamp is still on but the reason has changed. The explanation this time is that we had closed down b at 3 (and this persisted by inertia) while we have just moved a up, firing rule w. This example also illustrates why we are not interested in providing negative justifications through default negation. This would mean to explicitly include non-occurrences of actions that might\n6 Notice how strong negation would point out the cause(s) for a boolean fluent to take value false, whereas default negation represents the absence of cause.\notherwise have violated inertia. For instance, the explanation for on2 would include the fact that we did not perform m(a,u)2. Including this information for one transition is perhaps not so cumbersome, but suppose that, from 2 we executed a high number of transitions without performing any action. The explanation for on3 would additionally collect that we did not perform m(a,u)3 either. The explanation for on4 should also collect the negation of further possibilities: moving a up at 4; three movements of a up, down and up; moving b at 3 and both switches at 4; moving both switches at 3 and b at 4; etc. It is easy to see that negative explanations grow exponentially: at step t we would get the negation of all possible plans for making ont false, while indeed, nothing has actually happened (everything persisted by inertia).\nExample 11 (The gear wheels) Consider a gear mechanism with a pair of wheels, each one powered by a separate motor. Each motor has a switch to start and stop it. There is another switch to connect or disconnect the wheels. (McCain 1997).\nThis example can be captured by the logic program P6 formed by the following causal rules:\nmotor(W )t ← start(W )t ¬motor(W )t ← stop(W )t\nturn(W )t ← motor(W )t coupledt ← couplet ¬coupledt ← uncouplet\nturn(1)t ← turn(2)t , coupledt turn(2)t ← turn(1)t , coupledt ¬turn(1)t ← ¬turn(2)t , coupledt ¬turn(2)t ← ¬turn(1)t , coupledt\nplus the fhe following inertia axioms:\nmotor(W )t+1← motor(W )t , not ¬motor(W )t+1 ¬motor(W )t+1← ¬motor(W )t , not motor(W )t+1\nturn(W )t+1 ← turn(W )t , not ¬turn(W )t+1 (2) ¬turn(W )t+1 ← ¬turn(W )t , not turn(W )t+1\ncoupledt+1 ← coupledt , not ¬coupledt+1 ¬coupledt+1 ← ¬coupledt , not coupledt+1\nSuppose that initially both motors are off an the wheels are immobile. This is reflected by the following set of facts { ¬motor(1)0, ¬motor(2)0, ¬turn(1)0, ¬turn(2)0, ¬cuopled0 } . Then\nwe perform the following actions { s(1)3 : start(1)3, c6 : couple6, u9 : uncouple9 }\n. Figure 7(a) shows the causal values associated with each fluent in each time interval. Note that we only have labelled the actions avoiding tracing rule application for clearity sake. This example illustrates the behaviour of causal logic programs in the presence of causal cycles. When no action is performed the value of a fluent is just propagate by inertia.\nAn iteresting variation of this example is incorporating some mechanic device to stop the wheels (Van Belleghem et al. 1998; Lin and Soutchanski 2011). This can be achived by adding the following set of rules:\nbreaked(W )t ← break(W )t ¬breaked(W )t ← unbreak(W )t ¬turn(W )t ← breaked(W )t\nbreaked(W )t+1← breaked(W )t , not ¬breaked(W )t+1 ¬breaked(W )t+1← ¬breaked(W )t , not breaked(W )t+1\nIf the second wheel is breaked at s9 we will get insted that turn(2)9 is false an the cause of ¬turn(2)t in any future situation is break(2)9. Another interesiting situations is when we break the second wheel in the situation 5. In such case we have an incosistence. On the one hand the cause of turn(1)6 and turn(2)6 are respectively s1 and s(1)3 ∗ c(6). On the other hand the cause of ¬turn(1)6 and ¬turn(2)6 are respectively break(2)5 ∗ c(6) and break(2)5. Note that, causal values not only points the existence of an incosistence but also can be explaoited to explain why. In particual, in this case, the motor forces the wheels to spin whereas the break opposed to it.\nAnother iteresting variation of this example is assuming that wheels are breaked by friction as soon as the motriz force over them is absent. This can be achived by just replacing the inertia axiom (2) for turn by the following causal rule:\nf (W )t : ¬turn(W )t+1← not ¬turn(W )t , not turn(W )t+1\nFigure 7(b) shows the variation in the causal value of turn(2). Note that ∗ means that the value is the same as Figure 7(a).\nAppendix C. Example with infinite rules\nExample 12 Consider the infinite program P7 given by the ground instances of the set of rules:\nl(s(X)) : nat(s(X))← nat(X) l(z) : nat(z)\ndefining the natural numbers with a Peano-like representation, where z stands for “zero.” For each natural number n, the causal value obtained for nat(sn(z)) in the least model of the program is l(z) · l(s(z)) . . . l(sn(z)). Read from right to left, this value can be seen as the computation steps performed by a top-down Prolog interpreter when solving the query nat(sn(z)). As a further elaboration, assume that we want to check that at least some natural number exists. For that purpose, we add the following rule to the previous program:\nsome← nat(X) (3)\nThe interesting feature of this example is that atom some collects an infinite number of causes from all atoms nat(sn(z)) with n ranging among all the natural numbers. That is, the value for some is I(some) = α0 +α1 +α2 + . . .+αn + . . . where αn def= l(z) · l(s(z)) · . . . · l(sn(z)). However, it is easy to see that the fact nat(z) labelled with l(z) is not only sufficient to prove the existence of some natural number, but, due to the recursive definition of the natural numbers, it is also necessary – note how all the proofs αi actually begin with an application of l(z).\nThis fact is captured in our semantic by the algebraic equivalences showed in Fig 2. From associativity and identity of ‘·’, the following equivalence holds:\nαn = 1 · l(z) · βn with βi def= l(s(z)) · . . . · l(si(z))\nfor any n≥ 1. Furthermore, from absorption of ‘·’ w.r.t the addition, it also holds that\nα0 +αn = l(z) + 1 · l(z) · βn = l(z)\nAs a consequence, the previous infinite sum just collapses to I(some) = l(z), reflecting the fact that, to prove the existence of a natural number, only the fact labelled as l(z) is relevant.\nSuppose now that, rather than defining natural numbers in a recursive way, we define them by\ndirectly asserting an infinite set of facts as follows:\nl(sn(z)) : nat(sn(z)) (4)\nfor any n≥ 0, where s0(z) stands for z. In this variant, the causal value obtained for nat(sn(z)) is simply l(sn(z)), so that the dependence we had before on lower natural numbers does not exist any more. Adding rule (3) to the set of facts (4) allows us concluding I(some) = l(z)+ l(s(z))+ l(s2(z))+ . . .+ l(sn(z))+ . . . and this infinite sum cannot be collapsed into any finite term. This reflects that we have now infinite independent ways to prove that some natural number exists.\nThis last elaboration can be more elegantly captured by replacing the infinite set of facts (4) by an auxiliary recursive predicate aux defined as follows:\naux(s(X))← aux(X) aux(z)\nl(X) : nat(X)← aux(X)\nSince rules for aux are unlabelled, the value of aux(sn(z)) in the least model is I(aux(sn(z))= 1 so the effect of this predicate is somehow “transparent” regarding causal justifications. As a result, the value of nat(sn(z)) is just l(sn(z)) as before."
    }, {
      "heading" : "Appendix D. Proofs",
      "text" : "In order to improve clarity, for any causal graph G = 〈V,E〉, vertices v1 and v2 and edge (v1,v2) we respectively use the notation v1 ∈ G and (v1,v2) ∈ G instead of v1 ∈V and (v1,v2) ∈ E."
    }, {
      "heading" : "7.1 Causes as graphs",
      "text" : "Proposition 1 (Monotonicity) Let G,G′ be a pair of causal graph with G≤ G′. Then, for any causal graph H:\nG∗H ≤ G′ ∗H, G ·H ≤ G′ ·H and H ·G≤ H ·G′\nProof . First we will show that G∗H ≤G′ ∗H. Suppose that E(G∗H) 6⊇ E(G′ ∗H) and let (l1, l2) be an edge in E(G′ ∗H) but not in E(G∗H ′), i.e. (l1, l2) ∈ E(G′ ∗H)\\E(G∗H ′).\nThus, since by product definition E(G′∗H) =E(G′)∪E(H), it follows that either (l1, l2)∈E(G′) or (l1, l2) ∈ E(H). It is clear that if (l1, l2) ∈ E(H) then (l1, l2) ∈ E(G ∗H) = E(G)∪ E(H). Furthermore, since G≤ G′ it follows that E(G)⊇ E(G′), if (l1, l2) ∈ E(G′) then (l1, l2) ∈ E(G) and consequently (l1, l2) ∈ E(G ∗H) = E(G)∪E(H). That is E(G ∗H) ⊇ E(G′ ∗H) and then G ∗H ≤ G′ ∗H. Note that V (G ∗H) ⊇ V (G′ ∗H) follows directly from E(G ∗H) ⊇ E(G′ ∗H) and the fact that every vertex has and edge to itself.\nTo show that G ·H ≤ G′ ·H (the case for H ·G≤ H ·G′ is analogous) we have has to show that, in addition to the previous, for every edge (lG, lH) ∈ E(G′ ·H) with lG ∈V (G′) and lH ∈V (H) it holds that (lG, lH) ∈ E(G ·H). Simply note that since G≤ G′ it follows V (G)⊇V (G)′ and then lG ∈V (G). Consequently (lG, lH) ∈ E(G ·H).\nProposition 2 (Application associativity for causal graphs) Let G1, G2 and G3 be three causal graphs. Then G1 · (G2 ·G3) = (G1 ·G2) ·G3.\nProof . By definition, it follows that V ( (G1 ·G2) ·G3 ) = (V (G1)∪V (G2))∪V (G3) = V (G1)∪ (V (G2)∪V (G3)) (5)\nE ( (G1 ·G2) ·G3 ) = ( E(G1)∪E(G2)∪E12 ) ∪E(G3)∪E12,3 = E(G1)∪E(G2)∪E(G3)∪E12∪E12,3 (6) E ( G1 · (G2 ·G3) ) = E(G1)∪ ( E(G2)∪E(G3)∪E23 ) ∪E1,23\n= E(G1)∪E(G2)∪E(G3)∪E1,23∪E23 (7)\nwhere\nE12 def= { (v1,v2) ∣∣ v1 ∈V1 and v2 ∈V2 } E12,3 def= { (v12,v3) ∣∣ v12 ∈V1∪V2 and v3 ∈V3 } E23 def= { (v2,v3) ∣∣ v2 ∈V2 and v3 ∈V3 } E1,23 def= { (v1,v23) ∣∣ v1 ∈V1 and v23 ∈V2∪V3 }\nFrom (5) and (7), it follows that\n(G1 ·G2) ·G3 = G1 · (G2 ·G3) if and only if E12∪E12,3 = E1,23∪E23 if and only if E12,3 ⊆ E1,23∪E23 and E1,23 ⊆ E12∪E12,3\nNote that E12 ⊆ E1,23 and E23 ⊆ E12,3. Then, we will show that E12,3 ⊆ E1,23 ∪E23. Suppose there is an edge (v12,v3) ∈ E12,3 such that (v12,v3) /∈ E23 and (v12,v3) /∈ E1,23. Since (v12,v3), v12 ∈ V1 ∪V2 and v3 ∈ V3. If v12 ∈ V1, then (v12,v3) ∈ E12,3 which is a contradiction, and if,\notherwise, v12 ∈V2, then (v12,v3)∈E23 which is also a contradiction. The case E1,23⊆E12∪E12,3 is symmetric.\nProposition 3 For every causal graph G = 〈V,E〉 it holds that G = ∏ { l · l′ ∣∣ (l, l′) ∈ E }. Proof . Let G′ be a causal graphb s.t. G′ = ∏ { l · l′\n∣∣ (l, l′) ∈ E }. Then for every edge (l, l′) ∈ E(G) it holds that (l, l′)∈ E(l · l′) and then (l, l′)∈ E(G′) = ⋃ { E(l · l′)\n∣∣ (l, l′)∈ E }, i.e. E(G)⊆ E(G′). Furthermore for every (l, l′) ∈ E(G′) there is li · l j s.t. (l, l′) ∈ li · l j and (li, l j) ∈ E(G). Then, since E(li · l j) = {(li, l j)} it follows that (l, l′) ∈ E(G), i.e. E(G) ⊇ E(G′). Consequently G = G′ = ∏ { l · l′\n∣∣ (l, l′) ∈ E }. Proposition 4 (Infimum) Any set of causal graphs S has a ≤-infimum given by their product ∏S.\nProof . By definition ∏S is the causal graph whose vertices and edges are respectively the sets V (∏S) = ⋃{ V (G) ∣∣ G ∈ S } and E(∏S) = ⋃{ E(G) ∣∣ G ∈ S }. It is easy to see that ∏S is the supremum of the subgraph relation, so that, since for every pair of causal graphs G ≤ G′ iff G⊇ G′, it follows that infimum of S w.r.t. ≤.\nProposition 5 (Application distributivity w.r.t. products over causal graphs) For every pair of sets of causal graphs S and S′, it holds that(\n∏S ) · ( ∏S′ ) = ∏ { G ·G′ ∣∣ G ∈ S and G′ ∈ S′ }. Proof . For readability sake, we define two causal graphs\nGR def= ( ∏S ) · ( ∏S′ ) and GL def= ∏ { G ·G′ ∣∣ G ∈ S and G′ ∈ S′ }\nand we assume that both S and S′ are not empty sets. Note that ∏ /0 = CLb = ∏{G /0}. Then, by product definition, it follows that\nE(GL) = (⋃{ E(G) ∣∣ G ∈ S }∪⋃{ E(G′) ∣∣ G ∈ S′ }∪EL)∗\nE(GR) = (⋃{ E(G)∪E(G′)∪ER(G,G′) ∣∣ G ∈ S and G′ ∈ S′ })∗\nwhere EL = { (l, l′) ∣∣ l ∈⋃{ V (G) ∣∣ G ∈ S } and l′ ∈⋃{ V (G′) ∣∣ G′ ∈ S′ } } ER(G,G′) = { (l, l′)\n∣∣ l ∈V (G) and l′ ∈V (G′) } Furthermore let ER = ⋃ { ER(G,G′)\n∣∣ G ∈ S and G′ ∈ S′ }. For every edge (l, l′) ∈ EL there are a pair of c-graphs G∈ S and G′ ∈ S′ s.t. l ∈V (G) and l′ ∈V (G′) and then (l, l′)∈ ER(G,G′) and so (l, l′) ∈ ER. Moreover, for every edge (l, l′) ∈ ER there are a pair of c-graphs G ∈ S and G′ ∈ S′ s.t. (l, l′) ∈ ER(G,G′) with l ∈V (G) and l′ ∈V (G)′. So that (l, l′) ∈ EL. That is EL = ER. Then\nE(GR) = (⋃{ E(G) ∣∣ G ∈ S }∪⋃{ E(G′) ∣∣ G′ ∈ S′ }∪ER)∗\n= ( E(GL)\\EL∪ER )∗ = ( E(GL) )∗ = E(GL)\nConsequently GL = GR.\nProposition 6 (Transitive application distributivity w.r.t. products over causal graphs) For any causal graphs G, G′ 6= /0 and G′′, it holds that\nG ·G′ ·G′′ = G ·G′ ∗G′ ·G′′\nProof . It is clear that G ·G′ ·G′′ ≤ G ·G′ and G ·G′ ·G′′ ≤ G′ ·G′′ and then G ·G′ ·G′′ ≤ G · G′ ∗G′ ·G′′. Let G1, G2, GL and GR be respectively G1 = G ·G′, G2 = G′ ·G′′, GL = G1 ·G′′, and GR = G1 ∗G2. Suppose that GL < GR, i.e. GL ⊃ GR and there is an edge (v1,v2) ∈ GL but (v1,v2) /∈ GR. Then G1 ⊆ GR and G′′ ⊆ G2 ⊆ GR and one of the following conditions holds:\n1. (v1,v2) ∈ G1 ⊆ GR or (v1,v2) ∈ G′′ ⊆ GR which is a contradiction with (v1,v2) /∈ GR. 2. v1 ∈ G1 and v2 ∈ G′′, i.e. v1 ∈ G and v2 ∈ G′′ or v1 ∈ G′ and v2 ∈ G′′. Furthermore, if the\nlast it is clear that (v1,v2) ∈G′ ·G′′ = G2 ⊆GR which is a contradiction with (v1,v2) /∈GR.\nThus it must be that v1 ∈ G and v2 ∈ G′′. But then, since G′ 6= /0 there is some v′ ∈ G′ and consequently there are edges (v1,v′) ∈G ·G′ = G1 ⊆GR and (v′,v2) ∈G′ ·G′′ = G2 ⊆GR. Since GR is closed transitively, (v1,v2) ∈GR which is a contradiction with the assumption that (v1,v2) /∈ GR. That is, GL = G ·G′ ·G′′ = G ·G′ ∗G′ ·G′′ = GR.\nProposition 7 (Application idempotence w.r.t. singleton causal graphs) For any causal graph G whose only edge is (l, l), G ·G = G. Proof . By definition G ·G = G∪G∪{ (v1,v2) ∣∣ v1 ∈ G and v2 ∈ G }. Since the only vertex of G is l, it follows that G ·G = G∪{(l, l)}= G.\nProposition 8 (Application absorption over causal grapsh) Let G1, G2 and G3 be three causal graphs. Then G1 ·G2 ·G3 = G2 ∗G1 ·G2 ·G3.\nProof . By definition, it is clear that G1 ·G2 ·G3 ⊇ G2 and then\nG2 ∗G1 ·G2 ·G3 = (G2∪G1 ·G2 ·G3)∗ = (G1 ·G2 ·G3)∗ = G1 ·G2 ·G3\nProposition 9 (Absorption Extended) Let a and b be elements of an algebra holding the identity and absorption equivalences showed in Figure 2. Then\na∗a ·b = a ·b a∗b ·a = b ·a\nProof . The proof follow from the following equivalences:\na∗a ·b = a∗1 ·a ·b (identity) = 1 ·a ·b (absorption) = a ·b (identity)\na∗b ·a = a∗b ·a ·1 (identity) = b ·a ·1 (absorption) = b ·a (identity)\nProposition 10 (Transitivity extended) Let a, b and c be elements of an algebra holding the identity and absorption equivalences showed in Figure 2 such that b is different from 1. Then\na ·b∗b · c = a ·b∗b · c∗a · c\nfollows from application associative, identity and absorption and distributivity over products.\nProof .\na ·b∗b · c∗a · c = (a ·b∗b · c)∗a · c (associative ‘∗’) = (a ·b · c)∗a · c (transitivity) = a · (b · c)∗a · c (associative ’·’) = a · (b · c∗ c) (distributivity) = a · (b · c) (absorption ext.) = a ·b · c (associativity) = a ·b∗b · c (transitivity)\nCorollary 1 Given causal graphs G1, G2, G3 and Gl such that (l, l) is the only edge of Gl , the equivalences reflected in the Figures 8 and 9 hold.\nTheorem 7 Given a set of labels Lb, 〈CLb,∗, ·〉 is the free algebra generated by Lb defined by equations in the Figure 8, i.e. the mapping graph : Lb −→ CLb mapping each label l to the graph Gl containing the only edge (l, l) is an injective (preserving-idempotence) homomorphism and for any set F and idempotence-preserving map δ : Lb−→ F , there exists a homomorphism term : CLb −→ F defined as term(G) 7→∏{ δ (l1) ·δ (l2)\n∣∣ (l1, l2) ∈ G } such that δ = term◦graph. Proof . For clarity sake we omit the idempotence-preserving mapping δ and we write just l instead of δ (l). Thus the mapping term : CLb −→ F is just term(G) 7→∏{ l1·l2\n∣∣ (l1, l2) ∈G }. We start showing that graph preservers the ‘·’ idempotence equation.\ngraph(l) ·graph(l) = Gl ·Gl = Gl ∪Gl ∪{ (l1, l2) ∣∣ l1 ∈ Gl and l2 ∈ Gl }\n= Gl ∪Gl ∪{(l, l)}= Gl ∪Gl ∪Gl = Gl = graph(l)\nFurthermore, suppose graph(l1) = graph(l2), i.e. {(l1, l2)} = {(l2, l2)}. Then l1 = l2. Hence graph is an injective homomorphism. Now we show that term preserves the ‘∗’. Let D= ⋃ G∈U G. Then\n∏ G∈U term(G) = ∏ G∈U ∏ (l1,l2)∈G l1·l2 = ∏ (l1,l2)∈D l1·l2\n= ∏ (l1,l2)∈D∗ l1·l2 = term(D∗)\n= term (( ⋃ G∈U G )∗) = term ( ∏ G∈U G )\nWe will show now that term also preserves ‘·’. term(G1) · term(G2) = (\n∏ (u1,u2)∈Gu\nu1·u2 ) · (\n∏ (v1,v2)∈Gv\nv1·v2 )\n= ∏ (u1,u2)∈Gu, (v1,v2)∈Gv (u1·u2) · (v1·v2) = ∏ (u1,u2)∈Gu, (v1,v2)∈Gv u1 · (u2·v1·v2) = ∏ (u1,u2)∈Gu, (v1,v2)∈Gv u1 · (u2·v1 ∗ v1·v2) = ∏ (u1,u2)∈Gu, (v1,v2)∈Gv u1·u2·v1 ∗u1·v1·v2 = ∏ (u1,u2)∈Gu, (v1,v2)∈Gv u1·u2 ∗u2·v1 ∗u1·v1 ∗ v1·v2 ∗u1·v1 ∗u1·v2 = ∏ (u1,u2)∈Gu, (v1,v2)∈Gv (u1·u2 ∗ v1·v2)∗ (u2·v1 ∗u1·v1 ∗u1·v1 ∗u1·v2) = ∏ (u1,u2)∈Gu, (v1,v2)∈Gv (u1·u2 ∗ v1·v2)∗ ∏ (u1,u2)∈Gu, (v1,v2)∈Gv (u2·v1 ∗u1·v1 ∗u1·v1 ∗u1·v2) = ∏ (l1,l2)∈Gu∪Gv (l1·l2)∗ ∏ u∈Gu, v∈Gv (u·v) = ∏ (l1,l2)∈Gu·Gv (l1·l2) = term(G1 ·G2)\nFinally note that term(graph(l)) = l·l = l (note that l stands for the more formally δ (l))."
    }, {
      "heading" : "7.2 Alternative causes",
      "text" : "We define an explanation formed by a set of causal graphs S as:\n∑S = G if G ∈ S and G∗G′ = G′ for all G′ ∈ S\nTheorem 8 The set of causal values VLb with the opperations join ‘+’ and meet ‘∗ forms the free, complete distributive lattice with generated by the set of causal graphs CLb and further ↓: CLb −→ VLb is an injective homomorphism from the algebra 〈CLb,+,∗, ·〉 to 〈VLb,+,∗, ·〉. .\nProof of Theorem ??. Let F be the set of filters over the lower semilattice 〈CLb,∗〉. Stumme was showed in (Stumme 1997) that the concept lattice B〈F,VLb,∆〉 (with F∆I⇔ F ∩ I 6= /0) is isomorphic to the free completely distributive complete lattice generated by the partial lattice 〈CLb,+,∗〉 where + and ∗ are two partial functions corresponding with the supremum and infimum. In our particular, case for every set of causal graphs S its infimum is defined as ∏S and the supremum is defined as G ∈ S such that G′ ≤G for all G′ ∈ S, when such G exists and undefined otherwise. Thus VLb is the set of ideals over the partial lattice 〈CLb,+,∗〉, i.e. every I ∈ VLb is also closed under defined suprema. He also show that the elements of such lattice are described as pairs {\n(Ft ,It) ∣∣ Ft ⊆ F, It ⊆ VLb, FIt = It and Ft = IIt }\nwhere FIt = { I ∈ I ∣∣ ∀F ∈ Ft : F ∩ I 6= /0 }\nIIt = { F ∈ F ∣∣ ∀I ∈ It : F ∩ I 6= /0 }\nThat is, every element is in the form 〈IIt ,It〉. Furthermore infima and suprema can be described as follows: ∧\nt∈T (IIt ,It) = (⋂ t∈T IIt , ( ⋃ t∈T It )II)\n∨ t∈T (IIt ,It) = ((⋃ t∈T IIt )II , ⋂ t∈T It )\nWe will show that εI : B−→ VLb given by (IIt ,It) 7→ ⋂\nIt is an isomorphism between 〈B,∨,∧〉 and 〈VLb,∪,∩〉. Note that, since ∏ /0 = G /0 it holds that the empty set is not close under defined infimum and then it is not a filter, i.e. /0 6∈ F, and then for every filter F ∈ F it holds that G /0 ∈ F . Thus if It = /0 follows that IIt =F and then IIIt = {I ∈VLb |G /0 ∈ I}=CLb 6= It . That is, 〈 /0I , /0〉 6∈B.\nWe will show that for every ideal It ∈ I and for every set of ideals It ⊆ I s.t. It = ⋂ It it holds that\n(IIt ,It) ∈B〈F,I,∆〉 ⇐⇒ It = { I ∈ I ∣∣ It ⊆ I } (8)\nand consequently εI is a bijection between and B and VLb.\nSuppose that (IIt ,It) ∈B〈F,I,∆〉. For every I ∈ It it holds that It ⊆ I. So suppose there is I ∈ I s.t. It ⊆ I and I 6∈ It . Then there is F ∈ IIt s.t. I∩F = /0 and for every element I′ ∈ It it holds that I′ ∩F 6= /0. Pick a causal graph G s.t. G = ∏{G′ | G′ ∈ I′ ∩F and I′ ∈ It}. Since for every G′ it holds G′ ∈ F and G ≤ G′ follows that G ∈ F (F is close under infimum) and G ∈ I′ (every I′ is close under ≤). That is, for every I′ ∈ It it holds that G ∈ I′∩F and then, since It = ⋂ It , it also\nholds that G ∈ It ∩F and since It ⊆ I also G ∈ I∩F which contradict that I∩F = /0. So that I ∈ It and it holds that\n(IIt ,It) ∈B〈F,I,∆〉=⇒ It = { I ∈ I ∣∣ It ⊆ I }\nSuppose that It = {I ∈ I | It ⊆ I} but (IIt ,It) ∈B〈F,I,∆〉, i.e. It 6= IIIt . Note that It ⊆ IIIt because otherwise there are I ∈ It and F ∈ IIt s.t. I∩F = /0 which is a contradiction with the fact that for every F ∈ IIt and I ∈ It it holds that F ∩ I 6= /0.\nSo, there is I ∈ IIIt s.t. I 6∈ It , i.e. for every F ∈ IIt it holds that F ∩ I 6= /0 but It 6⊆ I. Pick G ∈ It\\I and F = {G′ | G ≤ G′}. It is clear that F ∈ F and F ∩ It 6= /0 because G ∈ It , so that F ∈ IIt . Furthermore F ∩ I = /0, because G 6∈ I, which is a contradiction with the assumption. Thus\n(IIt ,It) ∈B〈F,I,∆〉 ⇐= It = { I ∈ I ∣∣ It ⊆ I }\nNow, we will show that (II1,I1)∨ (II2,I2) = (II3,I3) iff I1 ∪ I2 = I3. From the above statement follows that\nI1∩ I2 = {I ∈ I | I1 ⊆ I and I2 ⊆ I}= = {I ∈ I | I1∪ I2 ⊆ I}\nI3 = {I ∈ I | I3 ⊆ I}\nThat is, I1 ∩ I2 = I3 iff I1 ∪ I2 = I3 and by definition of ∨ the first is equivalent to (II1,I1)∨ (II2,I2) = (I I 3,I3).\nFinally we will show that (II1,I1)∧ (II2,I2) = (II3,I3) iff I1∩ I2 = I3. It holds that (I1∪ I2)II = ({ I ∈ I ∣∣ I1 ⊆ I or I2 ⊆ I })II =\n= ({ I ∈ I ∣∣ I1∩ I2 ⊆ I })II\nI3 = { I ∈ I ∣∣ I3 ⊆ I }\nSince εI is a bijection, it holds that (I1∪ I2)II = I3 iff I1∩ I2 = I3.\nThus εI : B −→ VLb is an isomorphism between 〈B,∨,∧〉 and 〈VLb,∪,∩〉, i.e. 〈VLb,∪,∩〉 is isomorphic to the free completely distributive lattice generated by 〈CLb,+,∗〉.\nLet’s check now that ↓: CLb −→VLb is an injective homomorphism. Stumme has already showed that εp : CLb −→B given by\nεp(G) 7→ ({ F ∈ F ∣∣ G ∈ F },{ I ∈ I ∣∣ G ∈ I })\nis an injective homomorphism between the partial lattice 〈CLb,+,∗〉 and 〈B,∨,∧〉. So that εI ◦εp is an injective homomorphism between 〈CLb,+,∗〉 and 〈VLb,∪,∩〉 given by\nεI ◦ εp(G) 7→ ⋂{ I ∈ VLb ∣∣ G ∈ I } = ↓G\nNote that for any causal graph G and G′ ∈ CLb s.t. G′ ≤ G it holds that G′ ∈ εI ◦ εp(G), that is ↓ G ⊆ εI ◦ εp(G). Furthermore for every causal graph G it holds that ε(G) is an ideal, i.e. ↓ G ∈ VLb and it is clear that G ∈ ↓G so that, εI ◦ εp is an intersection with ↓ G as one of its operands, thus εI ◦ εp(G) ⊆↓ G. That is ↓ G = εI ◦ εp(G) and consequently it is an injective homomorphism between 〈CLb,+,∗〉 〈VLb,∪,∩〉.\nLet us show now that the mapping ↓ also preserves the ‘·’ operation. Take any causal graphs G1 and G2, then\n↓G1 · ↓G2 = ↓{ (G′1 ·G′2) ∣∣ G′1 ∈ ↓G1 and G′2 ∈ ↓G2 }\n= ↓{ (G′1 ·G′2) ∣∣ G′1 ≤ G1 and G′2 ≤ G2 } = ↓(G1 ·G2)\nNote that, from Proposition 1, it follows that G′1 ·G′2 ≤ G1 ·G2. That is, ↓ in an homomorphism between 〈CLb,+,∗·〉 and 〈VLb,+,∗·〉.\nCorollary 2 Every equivalence showed in Figure 4 hold. Futheremore equivalences showed in Figures 8 and 9 also hold if principal ideals ↓G1, ↓G2 and ↓G3 are considered instead of causal graphs G1, G2 and G3.\nCorollary 3 Given causal terms without sums c, d, e and a label l, the equivalences reflected in the Figures 10 and 11 hold.\nProposition 11 (Application associativity) Let T , U and W be three causal values. Then T · (U ·W ) = (T ·U) ·W .\nProof . By definition, it follows that (T ·U) ·W = ↓{ Gt ·Gu ∣∣ Gt ∈ T and Gu ∈U } ·W\n= ↓{ G′ ·Gw ∣∣ G′ ≤ Gt ·Gu, Gt ∈ T, Gu ∈U and Gw ∈W }\nIt is clear that Gt ·Gu ≤ Gt ·Gu and then ↓{ (Gt ·Gu) ·Gw ∣∣ Gt ∈ T, Gu ∈U and Gw ∈W } ⊆ ↓{ G′ ·Gw ∣∣ G′ ≤ Gt ·Gu, Gt ∈ T, . . . }\nFurthermore since ‘·’ is monotonic, for every G′ ≤ Gt ·Gu, it holds that G′ ·Gw ≤ (Gt ·Gu) ·Gw and then\n(T ·U) ·W = ↓{ (Gt ·Gu) ·Gw ∣∣ Gt ∈ T, Gu ∈U and Gw ∈W }\nApplying the same reasoning we can also conclude that T · (U ·W ) = ↓{ Gt · (Gu ·Gw) ∣∣ Gt ∈ T, Gu ∈U and Gw ∈W }\nThat is, T · (U ·W ) = (T ·U) ·W holds whether, for every causal graph Gt , Gu and Gw, it holds that (Gt ·Gu) ·Gw = Gt · (Gu ·Gw). This holds due to Proposition 2.\nProposition 12 (Application distributivity w.r.t. additions) Let T , U and W be three causal values. Then, it holds that U · (T +W ) = (U ·T )+(U ·W ) and (U +T ) ·W = (U ·W )+(T ·W ).\nProof . By definition, it follows that\n(U ·T )+(U ·W ) = (U ·T )∪ (U ·W ) = ↓ { GU ·GT ∣∣ GU ∈U and GT ∈ T } ∪ ↓{ GU ·GT ∣∣ GU ∈U and GW ∈W } = ↓ { GU ·G′\n∣∣ GU ∈U and G′ ∈ T ∪W }=U · (T ∪W ) =U · (T +W ) Furthermore (U +T ) ·W = (U ·W )+(T ·W ) holds symmetrically.\nProposition 13 (Application absorption) Let T , U and W be three causal values. Then T = T + U ·T ·W and U ·T ·W = T ∗U ·T ·W\nProof . From Proposition 11 it follows that U ·T ·W = ↓ { GU ·GT ·GW ∣∣ GU ∈U, GT ∈ T and GW ∈W }\nFurthermore, for every c-graph GT ∈ T , it holds that GU ·GT · TW ≤ GT . Then, since T is an ideal, it follows that GU ·GT ·TW ∈ T and consequently U ·T ·W ⊆ T . Thus U ·T ·W ∪T = T and U ·T ·W ∩T =U ·T ·W and, by definition, these equalities can be rewritten as U ·T ·W +T = T and U ·T ·W ∗T =U ·T ·W .\nProposition 14 (Application identity and annihilator)\nGiven a causal value T , it holds that T = 1 ·T , T = T ·1, 0 = T ·0 and 0 = 0 ·T .\nProof . Note that 1 and 0 respectively correspond to CLb and /0 and by definition it follows that\n1 ·T = ↓ { G ·GT ∣∣ G ∈ CLb and GT ∈ T }= T\n0 ·T = ↓ { G ·GT ∣∣ G ∈ /0 and GT ∈ T }= /0 = 0\nThe other cases are symmetric.\nCorollary 4\nThe equivalences reflected in the Figure 2 hold.\nTheorem 9\nGiven a set of labels Lb, 〈VLb,+,∗, ·〉 is the free algebra generated by Lb defined by equations in the Figure 4 and 2, i.e. the mapping value : Lb−→ VLb mapping each label l to the causal value ↓Gl with Gl being the causal graph containing the only edge (l, l) is an injective (preservingidempotence) homomorphism and for any set F and idempotence-preserving map δ : Lb−→ F , there exists a homomorphism term : VLb −→ F defined as term(U) 7→ ∑{ term(G)\n∣∣ G ∈U } such that δ = term◦graph.\nProof . Note, from Theorems 7 and 8, that graph : Lb −→ CLb and ↓: CLb −→ VLb are injective homomorphisms respectively from Lb to CLb and from CLb to VLb. Furthermore the composition of injective homomorphisms is injective too. So that value(l) 7→ ↓graph(l) is an injective homomorphism between Lb and VLb. We will show now that term : VLb −→ F preserves the ‘+’:\nterm (\n∑ U∈U\nU ) = term (⋃ U ) = ∑\nG∈ ⋃ U term(G) = ∑ U∈U ∑ G∈U term(G) = ∑ U∈U term(U)\nthat term also preserves ‘∗’:\n∏ U∈U term(U) = ∏ U∈U ∑ G∈U term(G) = ∑ ϕ∈Φ ∏ U∈U term(ϕ(U)) = ∑ ϕ∈Φ\nterm (\n∏ U∈U\nϕ(U) ) = ∑\nt∈T1 t\nterm (\n∏ U∈U\nU ) = term (⋂ U )\n= ∑ G∈ ⋂ U term(G) = ∑ t∈T2 t\nwhere Φ def= { ϕ ∣∣ ϕ(U)∈U with U ∈U }. Note that G∈⋂U implies that G∈U for all U ∈U\nand consequently there is ϕ ∈ Φ s.t. ϕ(U) = G for all U ∈ U . Thus term ( ∏U∈U ϕ(U) ) =\nterm ( ∏U∈U G ) = term(G). That is T2 ⊆ T1. Note also that ∏U∈U ϕ(U) = (⋃ U∈U U )∗ ⊇ ϕ(U) for all U ∈ U and consequently ∏U∈U U ∈U for all U ∈ U and so that ∏U∈U U ∈ ⋂ U and\nT2 ⊇ T1. And that term preserves ‘·’ too: term(U) · term(W ) = (\n∑ Gu∈U\nterm(Gu) ) · (\n∑ Gw∈W\nterm(Gw) )\n= ∑ Gu∈U, Gw∈W term(Gu) · term(Gw) = ∑ Gu∈U, Gw∈W term(Gu ·Gw)\n= term (\n∑ Gu∈U, Gw∈W\nGu ·Gw )\n= term (\n∑ Gu∈U Gu · ∑ Gw∈W\nGw )\n= term(U ·W )\nFinally term(value(l)) = ∑G∈value(l) term(G) = term(Gl) and, from Theorem 7, term(Gl) = l.\n7.3 Positive programs\nLemma 7.1 Let P be a positive (and possible infinite) logic program over signature 〈At,Lb〉. Then, (i) the least fix point of TP, lfp(TP) is the least model of P, and (ii) lfp(TP) = TP ↑ ω (0).\nProof . Since the set of causal values forms a lattice causal logic programs can be translated to Generalized Annotated Logic Programming (GAP). GAP is a general a framework for multivalued logic programming where the set of truth values must to form an upper semilattice and rules (annotated clauses) have the following form:\nH : ρ ← B1 : µ1 & . . . & Bn : µn (9)\nwhere L0, . . . ,Lm are literals, ρ is an annotation (may be just a truth value, an annotation variable or a complex annotation) and µ1, . . . ,µn are values or annotation variables. A complex annotation is the result to apply a total continuous function to a tuple of annotations. Thus a positive program P is encoded in a GAP program, GAP(P) rewriting each rule R ∈Π of the form\nt : H← B1∧ . . .∧Bn (10)\nas a rule GAP(R) in the form (9) where µ1, . . . ,µn are annotation that capture the causal values of each body literal and ρ is a complex annotation defined as ρ = (µ1 ∗ . . .∗µn) · t.\nThus we will show that a causal interpretation I |= Π if and only if I |=r GAP(P) where |=r refers to the GAP restricted semantics.\nFor any program P and interpretation I, by definition, I |= P (resp. I |=r GAP(P)) iff I |= R (resp. I |=r GAP(R)) for every rule R ∈ P. Thus it is enough to show that for every rule R it holds that I |= R iff I |=r GAP(R). By definition, for any rule R of the form of (10) and an interpretation I, I |= R if and only if( I(B1)∗ . . .∗ I(Bn) ) · t ≤ I(H) whereas for any rule GAP(R) in the form of (9), I |=r GAP(R) iff for all µi ≤ I(Bi) implies that ρ = (µ1 ∗ . . .∗µn) · t ≤ I(H).\nFor the only if direction, take µi = I(Bi), then ρ = (µ1 ∗ . . .∗µn) · t = (I(B1)∗ . . .∗ I(Bn)) · t and then ρ ≤ I(H) implies ( I(B1)∗ . . .∗ I(Bn) ) · t ≤ I(H), i.e. I |=r GAP(R) implies I |= R. For the if direction, take µi ≤ I(Bi) then, since product an applications are monotonic operations, it follows that (µ1 ∗ . . .∗µn) · t ≤ (I(B1)∗ . . .∗ I(Bn)) · t ≤ I(H), That is, I |= R also implies I |=r GAP(R). Consequently I |= R iff I |=r GAP(R).\nThus, from Theorem 1 in (Kifer and Subrahmanian 1992), it follows that the operator TP is monotonic.\nTo show that the operator TP is also continuous we need to show that for every causal program P the translation GAP(P) is an acceptable program. Indeed since in a program GAP(P) all body atoms are v-annotated it is acceptable. Thus from Theorem 3 in (Kifer and Subrahmanian 1992), it follows that TP ↑ ω (0) = l f p(TP) and this is the least model of P.\nLemma 7.2 Given a positive and completely labelled program P, for every atom p and integer k ≥ 1,\nTP ↑ k (0)(p) = ∑ R∈Ψ ∑ f∈R\n∏ { f ( TP ↑ k−1 (0)(q) ) ∣∣ q ∈ body(R) } · label(R)\nwhere Ψ is the set of rules Ψ = { R ∈ Π ∣∣ head(R) = p } and R is the set of choice functions\nR = { f ∣∣ f (S) ∈ S }.\nProof . By definition of TP ↑ k (0)(p) it follows that TP ↑ k (0)(p) = ∑ { ( TP ↑ k−1 (0)(q1)∗ . . .∗TP ↑ k−1 (0)(q1) ) · label(R) ∣∣ R ∈ P with head(R) = p } then, applying distributive of application w.r.t. to the sum and and rewriting the sum and the product aggregating properly, it follows that\nTP ↑ k (0)(p) = ∑ R∈Ψ\n∏ { TP ↑ k−1 (0)(q) ∣∣ q ∈ body(R) } · label(R)\nFurthermore for any atom q the causal value TP ↑ k−1 (0)(q) can be expressed as the sum of all c-graphs in it and then\nTP ↑ k (0)(p) = ∑ R∈Ψ\n∏ {\n∑ f∈R\nf ( TP ↑ k−1 (0)(q) ) ∣∣ q ∈ body(R) } ·abel(R) and applying distributivity of products over sums it follows that\nTP ↑ k (0)(p) = ∑ R∈Ψ ∑ f∈R\n∏ { f ( TP ↑ k−1 (0)(q) ) ∣∣ q ∈ body(R) } · lR\nLemma 7.3 Given a positive and completely labelled program P and a causal graph G, for every atom p and integer k≥ 1, it holds that G∈ TP ↑ k (0)(p) iff there is a rule l : p← q1, . . . ,qm and causal graphs Gq1 , . . . , Gqm respectively in TP ↑ k−1 (0)(qi) and G≤ ( Gq1 ∗ . . .∗Gqm ) · l.\nProof . From Lemma 7.2 it follows that G ∈ TP ↑ k (0)(p) iff G ∈ value (\n∑ R∈Ψ ∑ f∈R\n∏ { f ( TP ↑ k−1 (0)(q) ) ∣∣ q ∈ body(R) } · label(R) ) iff G ∈\n⋃ R∈Ψ ⋃ f∈R value ( ∏ { ↓ f ( TP ↑ k−1 (0)(q) )) ∣∣ q ∈ body(R) } · label(R) iff there is R ∈Φ, with head(R) = p and a choice function f ∈Ψ s.t.\nG ∈ value ( ∏ { f ( TP ↑ k−1 (0)(q) ) ∣∣ q ∈ body(R) } · label(R)) Let R = l : p← q1, . . . ,qm and f ( TP ↑ k−1 (0)(qi) ) = Gqi . Then the above can be rewritten as\nG≤ ( Gq1 ∗ . . .∗Gqm ) · l.\nDefinition 10 Given a causal graph G = 〈V,E〉, we define the restriction of G to a set of vertex V ′ ⊆ V as the casual graph G′ = 〈V ′,E ′〉 where E ′ = { (l1, l2) ∈ E ∣∣ l1 ∈ V ′ and l2 ∈ V ′ }, and we define the reachable restriction of G to a set of vertex V ′ ⊆ V , in symbols GV ′ , as the restriction of G to the set of vertex V ′′ from where some vertex l ∈ V ′ is reachable V ′′ = { l′ ∈ V\n∣∣ (l′, l) ∈ E∗ for some l ∈V ′ }. When V ′ = l is a singleton we write Gl .\nLemma 7.4 Let P be a positive, completely labelled program, p and q be atoms, G be a causal graph, R be a causal rule s.t. head(R) = q and label(R) = l is a vertex in G and k ∈ {1, . . . ,ω} be an ordinal. If G ∈ TP ↑ k (0)(p), then Gl ∈ TP ↑ k (0)(q).\nProof . In case that k = 0 the lemma statement holds vacuous. Otherwise assume as induction hypothesis that the lemma statement holds for k−1. From Lemma 7.3, since G∈ TP ↑ k (0)(p), there is a rule Rp = (lp : p← p1, . . . , pm) and c-graph Gp1 , . . . ,Gpm s.t. each Gpi ∈ TP ↑ k−1 (0)(pi) and G≤ (Gp1 ∗ . . .∗Gpm) · lp.\nIf l = lp then, since P is uniquely labelled, R = Rp, Gl = G and by assumption G ∈ TP ↑ k (0)(p). Otherwise l ∈ Gpi for some Gpi and in its turn Gpi ∈ TP ↑ k−1 (0)(pi). By induction hypothesis Gl ∈ TP ↑ k−1 (0)(q) and since TP ↑ k−1 (0)(q)⊆ TP ↑ k (0)(q) it follows that Gl ∈ TP ↑ k (0)(q).\nIn case that k = ω , by definition TP ↑ ω (0)(p) = ∑i<ω TP ↑ i (0)(p) and the same for atom q. Thus, if G ∈ TP ↑ ω (0)(p) there is some i < ω s.t. G ∈ TP ↑ i (0)(p), and as we already show, Gl ∈ TP ↑ i (0)(q) and consequently Gl ∈ TP ↑ ω (0)(q).\nLemma 7.5 Let P be a positive, completely labelled program, p be an atom and G be a causal graph and k≥ 1 be an integer. If G is maximal in TP ↑ k (0)(p) then\n1. there is a causal rule R = (l : p← p1, . . . , pm) and there are causal graphs Gp1 , . . . ,Gpm s.t. each Gpi ∈maxTP ↑ k−1 (0)(pi) and Gp = (Gp1 ∗ . . .∗Gpm) · l and 2. l is not a vertex of any Gpi .\nProof . From Lemma 7.3 it follows that G∈ TP ↑ k (0)(p) iff there is a rule R=(l : p← q1, . . . ,qm) and causal graphs G′q1 , . . . ,G ′ qm s.t. each Gpi ∈maxTP ↑ k−1 (0)(pi) and G = ( G′q1 ∗ . . .∗G ′ qm ) · l. Let Gq1 , . . . ,Gqm be causes such that each Gqi ∈ maxTP ↑ k−1 (0)(qi) and G′qi ≤ Gqi and let G ′\nbe the c-graph G′ = ( Gq1 ∗ . . . ∗Gqm ) · l. By product and application monotonicity it holds that G≤G′ and, again from Lemma 7.3, it follows that G′ ∈ TP ↑ k (0)(p). Thus, since G is maximal, it must to be that G = G′ and consequently G = ( Gq1 ∗ . . .∗Gqm ) · l where each Gqi is maximal.\nSuppose that l is a vertex of Gpi for some Gpi . From Lemma 7.4, if follows that G l pi ∈TP ↑ k (0)(p). Furthermore, since Gpi ⊇ Glpi , it follows that Gpi ≤ G l pi and, since l is a label (l 6= 1), it follows that G < Gpi and so that G < G l pi which contradicts the assumption that G ∈maxTP ↑ k (0)(p).\nDefinition 11 Given a causal graph G we define height(G) as the length of the maximal simple (no repeated vertices) path in G.\nLemma 7.6 Let P be a positive, completely labelled program, p be an atom, k ∈ {1, . . . ,ω} be an ordinal and G be a causal graph. If G ∈maxTP ↑ k (0)(p) and height(G) = h≤ k then G ∈ TP ↑ h (0)(p).\nProof . In case that h = 0, from Lemma 7.5, it follows that if G ∈ maxTP ↑ k (0)(p) there is a causal rule R = (l : p← p1, . . . , pm) and c-graphs. . . . Furthermore, since P is completely labelled, it follows that l 6= 1 and then G < l < 1. Since 1 is the only c-graph whose height is 0 the lemma statement holds vacuous.\nIn case that h > 0, we proceed by induction assuming as hypothesis that the lemma statement holds for any h′ < h. From Lemma 7.5, there is a causal rule l : p← p1, . . . , pm, and there are causal graphs Gp1 , . . . ,Gpm s.t. each Gpi ∈ maxTP ↑ k−1 (0)(pi), G = GR · l and l 6∈ V (Gpi) for any Gpi where GR = Gp1 ∗ . . .∗Gpm .\nIf m = 0 then G = 1 · l = l, height(l) = 1 and l ∈ maxTP ↑ k (0)(p) for any k ≥ 1. Otherwise, since any path in Gpi is also a path Gp, it is clear that height(Gpi) = h ′ pi ≤ h for any Gpi . Suppose that h′pi = h for some Gpi . Then there is a simple path l1, . . . , lh of length h in Gpi and, since G = GR · l, there is an edge (lh, l) ∈ E(G). That is l1, . . . , lh, l is a walk of length h+1 in G and, since l 6∈V (Gpi), it follows that li 6= l with 1≤ i≤ h. So that l1, . . . , lh, l is a simple path of length h+1 which contradicts the assumption that height(G) = h. Thus height(Gpi) = h ′ pi < h for any Gpi and then, by induction hypothesis, Gpi ∈maxTP ↑ h′pi (0)(pi).\nLet h′ = max{ h′pi ∣∣ 1≤ i≤m }< h. Since the TP operator is monotonic and h′pi ≤ h′ for any pi, it follows that TP ↑ h ′ pi (0)(pi)≤ TP ↑ h ′ (0)(pi) and then there are casual graphs G′p1 , . . . ,G ′ pm such that each G′pi ∈ maxTP ↑ h′ (0)(pi), Gpi ≤ G′pi and G ′ = GR · l where G′R = G′p1 ∗ . . .∗G ′ pm . By product and application monotonicity, it follows that G ≤ G′, and, from Lemma 7.3, it follows that G′ ∈ TP ↑ h\n′+1 (0)(p). Since h′+1≤ h it follows that G′ ∈ TP ↑ h (0)(p) and since G≤ G′ it follows that G ∈ TP ↑ h (0)(p).\nSuppose that G 6∈ maxTP ↑ h (0)(p). Then there is G′′ ∈ maxTP ↑ h (0)(p) s.t. G < G′′ and then, since h ≤ k, it follows that G′′ ∈ TP ↑ k (0)(p) which, since G < G′′, contradicts the assumption that G ∈maxTP ↑ k (0)(p). Thus, if G ∈maxTP ↑ k (0)(p) and height(G) = h≤ k it follows that G ∈ TP ↑ h (0)(p).\nIn case that k=ω , by definition TP ↑ ω (0)(p)=∑i<ω TP ↑ i (0)(p). Thus, if G∈maxTP ↑ ω (0)(p) and height(G) = h then there is some i<ω s.t. G∈maxTP ↑ i (0)(p) and h≤ i, and as we already show, then G ∈ TP ↑ h (0)(p).\nLemma 7.7\nLet P,Q two positive causal logic programs such that Q is the result of replacing label l in P by some u (a label or 1) then TQ ↑ k (0)(p) = TP ↑ k (0)(p)[l 7→ u] for any atom p and k ∈ {1, . . . ,ω}.\nProof . In case that n = 0, TQ ↑ k (0)(p) = 0 and TP ↑ k (0)(p) = 0 and 0 = 0[l 7→ u]. That is TQ ↑ k (0)(p) = TP ↑ k (0)(p)[l 7→ u].\nWe proceed by induction on k assuming that TQ ↑ k−1 (0)(p) = TP ↑ k−1 (0)(p)[l 7→ u] for any atom p and we will show that TQ ↑ (0)(p) = TP ↑ k (0)(p)[l 7→ u].\nPick G ∈ TP ↑ k (0)(p) then, from Lemma 7.3, there is a rule l′ : p ← q1, . . . ,qm and causal graphs Gq1 , . . . , Gqm each one respectively in TP ↑ k−1 (0)(qi) s.t. G≤ GR = (Gq1 ∗ . . .∗Gqm) · l′. Thus, by induction hypothesis, for every atom qi and c-graph Gqi ∈ TP ↑ k−1 (0)(q) it holds that Gqi [l 7→ u] ∈ TQ ↑ k−1 (0)(qi).\nLet GR[l 7→ u] be a c-graph defined as GR[l 7→ u] = ( Gq1 [l 7→ u] ∗ . . . ∗Gqm [l 7→ u] ) · l′[l 7→ u]. Then, since G ≤ GR, it follows that G[l 7→ u] ≤ GR[l 7→ u] and then, again from Lemma 7.3, it follows that G[l 7→ u] ∈ TQ ↑ n (0)(p). That is TP ↑ k (0)(p)[l 7→ u]⊆ TQ ↑ k (0)(p).\nPick G ∈ TQ ↑ k (0)(p) then, from Lemma 7.3, there is a rule there is a rule l′ : p← q1, . . . ,qm and c-graphs Gq1 , . . . , Gqm respectively in TP ↑ k−1 (0)(qi) s.t. G ≤ GR where GR = (Gq1 ∗ . . . ∗ Gqm) · l′. By induction hypothesis, for every atom qi and graph Gqi it holds that if Gqi ∈ TQ ↑ k−1 (0)(qi) then Gqi ∈ TP ↑ k−1 (0)(qi)[l 7→ u]. Thus, it follows that there is a graph G′qi ∈ TP ↑\nk−1 (0)(qi) such that G′qi [l 7→ u] = Gqi . Let G ′ R be a graph s.t. G ′ R = ( G′q1 ∗ . . .∗G ′ qm ) · l′. From Lemma 7.3 for every causal graph G′ ≤G′R it holds that G′ ∈ TP ↑ k (0)(p). Since G′R[l 7→ u] = GR and G≤GR it follows that G≤GR[l 7→ u] and, since GR ∈ TP ↑ k (0)(p), it follows that G∈ TP ↑ k (0)(p)[l 7→ u]. Consequently TP ↑ k (0)(p)[l 7→ u]⊇ TQ ↑ n (0)(p) and then TP ↑ k (0)(p)[l 7→ u] = TQ ↑ n (0)(p).\nIn case that k = ω , by definition TP ↑ ω (0)(p)[l 7→ u] = ∑i<ω TP ↑ (0)(i)p[l 7→ u] and as we alerady show TP ↑ (0)(i)p[l 7→ u] = TQ ↑ i (0)(p) for all integer i < ω , so that, their sum is also equal and consequently TP ↑ ω (0)(p)[l 7→ u] = TQ ↑ ω (0)(p).\nProof of Theorem 2. Let P′ be a positive, completely labelled causal program with the same rules as P. From Lemma 7.1 it follows that (i) lfp(TP) and lfp(TP′) are respectively the least model of the programs P and P′, and (ii) lfp(TP) = TP ↑ ω (0) and lfp(TP′) = TP′ ↑ ω (0).\nFuthermore, it is clear that if P is an infinite program, i.e. n = ω , then TP′ ↑ n (0) = TP′ ↑ ω (0). Otherwise, by definition it holds that TP′ ↑ n (0) ≤ TP′ ↑ ω (0). Suppose TP′ ↑ n (0)< TP′ ↑ ω (0). Then there is some atom p and c-graph G ∈ TP′ ↑ ω (0)(p) such that G 6∈ TP′ ↑ n (0)(p). The longest simple path in G must be smaller than the number of its vertices and this must be smaller than the number of labels of the program which in its turn is equal to the number of rules n, i.e. height(G) = h≤ n. From Lemma 7.6 it follows that G ∈ TP′ ↑ h (0)(p) and since h≤ n it follows that TP′ ↑ h (0)(p)⊆ TP′ ↑ n (0)(p) and so that G ∈ TP′ ↑ n (0)(p) which is a contradiction with the assumption that G ∈ TP ↑ ω (0)(p) but G 6∈ TP ↑ n (0)(p). Thus TP′ ↑ n (0) = TP′ ↑ ω (0).\nFurthermore, from Lemma 7.7, TP ↑ k (0)(p) = TP′ ↑ k (0)(p)[l′1 7→ l1] . . . [l′n 7→ ln] for k ∈ {n,ω} and where l′1, . . . , l ′ n are the labels of rules of P\n′ and l1, . . . , ln are the correspondent labels of such rules in P. Thus, since TP′ ↑ n (0) = TP′ ↑ ω (0), it follows that TP ↑ n (0) = TP ↑ ω (0).\nLemma 7.8 For any proof π(p) it holds that\ngraph (π(q1), . . . ,π(qm) p (l) ) = ( graph(π(q1))∗ . . .∗graph(π(q1)) ) · l\nProof . We proceed by structural induction assuming that for every proof in the antecedent π(qi) and every label l′ ∈V (graph(π(qi))) there is an edge (l′, label(π(qi))) ∈ E(graph(π(qi))).\nBy definition graph(π(p)) = G∗π(p) is the reflexive and transitive closure of Gπ(p) and then\ngraph(π(p)) = (⋃{ graph(π(qi)) ∣∣ 1≤ i≤ m }∪{ (label(π(qi), l) ∣∣ 1≤ i≤ m })∗\nThus, graph(π(p))≥∏ { graph(π(qi)) ∣∣ 1≤ i≤m } · l and remain to show that for every atom qi and label l′ ∈ V (graph(π(qi))) the edge (l′, l) ∈ E(graph(π(p))). Indeed, since by induction hypothesis there is an edge (l′, label(π(qi))) ∈ E(graph(π(qi)))⊆ E(graph(π(p)), the fact that the edge (label(π(qi), l) ∈ E(graph(π(p))) and since graph(π(p)) is closed transitively, it follows that (l′, l) ∈ E(graph(π(p))).\nLemma 7.9 Let P be a positive, completely labelled program and π(p) be a proof for p w.r.t. P. Then it holds that graph(πp) ∈ TP ↑ h (0)(p) where h is the height of π(p) which is recursively defined as\nheight(π) = 1+max{ height(π ′) ∣∣ π ′ is a sub-proof of π }\nProof . In case that h = 1 the antecedent of π(p) is empty, i.e.\nπ(p) = > p (l)\nwhere l is the label of the fact (l : p). Then graph(π(p)) = l. Furthermore, since the fact (l : p) is in the program P, it follows that l ∈ TP ↑ 1 (0)(p).\nIn the remain cases, we proceed by structural induction assuming that for every natural number h ≤ n− 1, atom p and proof π(p) of p w.r.t. P whose height(π(p)) = h it holds that graph(π(p)) ∈ TP ↑ h (0)(p) and we will show it in case that h = n.\nSince height(πp)> 1 it has a non empty antecedent, i.e.\nπ(p) = π(q1), . . . ,π(qm)\np (l)\nwhere l is the label of the rule l : p ← q1, . . . ,qm. By height definition, for each qi it holds that height(π(qi))≤ n−1 and so that, by induction hypothesis, graph(π(qi)) ∈ TP ↑ h−1 (0)(qi). Thus, from Lemmas 7.3 and 7.8, it follows respectively that\n∏{ graph(π(qi)) ∣∣ 1≤ i≤ m } · l ∈ TP ↑ h (0)(p)\ngraph(π(p)) = ∏{ graph(π(qi)) ∣∣ 1≤ i≤ m } · l\nThat is, graph(π(p)) ∈ TP ↑ h (0)(p).\nLemma 7.10 Let P be a positive, completely labelled program and π(p) be a proof of p w.r.t. P. For every atom p and maximal causal graph G ∈ TP ↑ ω (0)(p) there is a non-redundant proof π(p) for p w.r.t. P s.t. graph(π(p)) = G.\nProof . From Lemma 7.5 for any maximal graph G∈TP ↑ k (0)(p), there is a rule l : p← q1, . . . ,qm and maximal graphs Gq1 ∈ TP ↑ h−1 (0)(q1), . . . ,Gqm ∈ TP ↑ k−1 (0)(qm) s.t.\nG = (Gq1 ∗ . . .∗Gqm) · l\nFurthermore, we assume as induction hypothesis that for every atom qi there is a non redundant proof π(qi) for qi w.r.t. P s.t. graph(π(qi)) = Gqi . Then π(p) defined as\nπ(p) = π(q1), . . . ,π(qm)\np (l)\nis a proof for p w.r.t. P which holds graph(π(p)) = Gp (from Lemma 7.8) and height(π(p) ≤ h. Furthermore, suppose that π(p) is redundant, i.e. there is a proog π ′ for p w.r.t P such that graph(π(p)) < graph(π ′). Let h = height(π ′). Then, from Lemma 7.9, it follows that graph(π ′) ∈ TP ↑ h (0)(p) and then graph(π ′) ∈ TP ↑ ω (0)(p) which contradicts the hypothesis that G is maximal in TP ↑ ω (0)(p).\nProof of Theorem 3. From Theorem 2 it follows that the least model I is equal to TP ↑ ω (0). For the only if direction, from Lemma 7.10, it follows that for every maximal c-graph G ∈ I(p) = TP ↑ ω (0)(p) there is a non-redundant proof π(p) for p w.r.t P s.t. G = graph(π(p)). That is, π(p) ∈ Πp and then G = graph(π(p)) ∈ graph(Πp). For the if direction, from Lemma 7.9, for every G ∈ graph(Πp), i.e. G = graph(π(p)) for some non-redundant proof π(p) for p w.r.t. P, it holds that G ∈ TP ↑ ω (0)(p) and so that G ∈ I(p). Furthermore, suppose that G is not maximal, i.e. there is a maximal c-graph G′ ∈ I(p) s.t. G < G′ and a proof π ′ for p w.r.t. P s.t. graph(π ′) = G′ which contradicts that π(p) is non-redundant.\nLemma 7.11 Let t be a causal term. Then value(t[l 7→ u]) = value(t)[l 7→ u].\nProof . We proceed by structural induction. In case that t is a label. If t = l then value(l[l 7→ u] = value(u) =↓ u = value(l)[l 7→ u]. If t = l′ 6= l then value(l′[l 7→ u] = value(l′) =↓ l′ = value(l′)[l 7→ u]. In case that t = ∏T it follows that value(∏T [l 7→ u]) = ⋂ { value(t ′[l 7→\nu]) ∣∣ t ′ ∈T }) and by induction hypothesis value(t ′[l 7→ u])= value(t ′)[l 7→ u]. Then value(∏T [l 7→\nu]) = ⋂ { value(t ′)[l 7→ u] ∣∣ t ′ ∈ T }) = value(∏T )[l 7→ u]. The cases for t = ∑T is analogous. In case that t = t1 · t2 it follows that value(t[l 7→ u]) = value(t1[l 7→ u]) ·value(t2[l 7→ u]) = value(t1)[l 7→ u] · value(t2)[l 7→ u] = value(t)[l 7→ u]\nProof of Theorem 4. From Theorem 2, models I and I′ are respectively equal to TP ↑ ω (0) and TP′ ↑ ω (0). Furthermore, from Lemma 7.7, it follows that TP′ ↑ ω (0)(p) = TP ↑ ω (0)(p)[l 7→ u] for any atom p. Lemma 7.11 shows that the replacing can be done in any causal term without operate it.\nProof of Theorem 5. It is clear that if every rule in P is unlabelled, i.e. P = P′, then their least model assigns 0 to every f alse atom and 1 to every true atom, so that their least models coincide with the classical one, i.e. I = I′ and then Icl = I = I′. Otherwise, let Pn be a program where n rules are labelled. We can build a program Pn−1 removing one label l and, from Theorem 4, it follows that In−1 = In[l→ 1]. By induction hypothesis the corresponding classical interpretation of least model of Pn−1 coincides with the least model of the unlabelled program, i.e. Icln−1 = I\n′, and then In[l 7→ 1]cl = Icln−1 = I′. Furthermore, for every atom p and c-graph G it holds that G ∈ In(p) iff G[l 7→ 1] ∈ In[l 7→ 1](p). Simple remain to note that value(z) = /0, so that In(p) = 0 iff In[l 7→ 1](p) = 0 and consequently Icln = In[l 7→ 1]cl = I′.\nProof of Theorem 6. By definition I and Icl assigns 0 to the same atoms, so that PI = PI cl\n. Furthermore let Q (instead of P′ for clarity) be the unlabelled version of P. Then QI cl is the unlabelled version of PI . (1) Let I be a stable model of P and J be the least model of QI cl\n. Then, I is the least model of PI and, from Theorem 5, it follows that Icl = J, i.e. Icl is a stable model of Q. (2) Let I′ is a stable model of Q and I be the least model of PI ′ . Since I′ is a stable model of Q, by definition it is the least model of QI ′ , furthermore, since QI ′ is the unlabelled version of PI ′ it follows, from Theorem 5, that Icl = I′. Note that PI = PI cl = PI ′ . Thus I is a stable model of P."
    }, {
      "heading" : "8 Algebraic completeness",
      "text" : "We will show that causal terms with the algebraic properties reflected in Figures 12 and 13 are correct and complete with respect to the algebra of causal values.\nFirst note that the algebraic properties for “∗” and “+” reflected Figure 12 are the common algebraic properties satisfy by distributive lattices. Then their correctness follows directly from Theorem 1.\nProposition 15 (Application homomorphism) The mapping ↓: CLb,−→ VLb is an homomorphism between 〈CLb, ·〉 and 〈VLb, ·〉,\nProof . Take any c-graphs G1 and G2, then ↓G1 · ↓G2 = ↓{ (G′1 ·G′2) ∣∣ G′1 ∈ ↓G1 and G′2 ∈ ↓G2 }\n= ↓{ (G′1 ·G′2) ∣∣ G′1 ≤ G1 and G′2 ≤ G2 } = ↓(G1 ·G2)\nNote that, from Proposition 1,it follows that G′1 ·G′2 ≤ G1 ·G2. That is, ↓ in an homomorphism between 〈CLb, ·〉 and 〈VLb, ·〉.\nTheorem 10 (Homomorphism between causal graphs and values) The mapping ↓: CLb,−→VLb is an injective homomorphism between 〈CLb,+,∗·〉 and 〈VLb,+,∗, ·〉,\nProof . This follows directly from the Theorem 1 and Proposition 15\nProposition 16 For every causal term t without addition ‘+’ there exists a causal graph G such that t = ↓G.\nProof . In case that t is a label, by definition is the principal ideal ↓ t. We proceed by structural induction. In case that t = ∏S, by induction hypothesis, for every ti ∈ S there is some causal graph Gi such that ti = ↓Gi and from Theorem 1 it follows that\nt = ∏S = ∏{ ↓Gi ∣∣ ti ∈ S }= ↓{ Gi ∣∣ ti ∈ S }\nwhich is a principal ideal. In case that t = t1 · t2, by induction hypothesis, t1 = ↓G1 and t2 = ↓G2 and from Proposition 15, it follows that\nt = t1 · t2 = ↓G1 · ↓G2 = ↓(G1 ·G2)\nwhich is a principal idea.\nLemma 8.1 Let Gu and Gv be two causal graphs. If Gu ⊇ Gv, then term(Gu)≤ term(Gv) follows from the equivalence laws reflected in Figures 12 and 13.\nProof . By definition term(Gu)∗ term(Gv) is equal to ∏ { u1·u2 ∣∣ (u1,u2) ∈ Gu }∗∏{ v1·v2 ∣∣ (v1,v2) ∈ Gv } (11)\nand since, Gu ⊇ Gv, it follows that every edge (v1,v2) ∈ Gv also belong to Gu. Thus applying associative and conmutative laws we can rewrite (11) as\n∏ { u1·u2 ∣∣ (u1,u2) ∈ Gu\\Gv }∗∏{ (v1·v2)∗ (v1·v2) ∣∣ (v1,v2) ∈ Gv }\nthat, by product idempotence, is clearly equivalent to ∏ { u1·u2 ∣∣ (u1,u2) ∈ Gu\\Gv }∗∏{ (v1·v2) ∣∣ (v1,v2) ∈ Gv }\nThat is, term(Gu)∗ term(Gv) = term(Gu) which implies term(Gu)≤ term(Gv).\nLemma 8.2 Let U and V be two causal values. If U ⊆V , then term(U)≤ term(V ) follows from the equivalence laws reflected in Figures 12 and 13.\nProof . By definition term(U)+ term(V ) is equal to ∑{ term(Gu) ∣∣ Gu ∈U }+∑{ term(Gv) ∣∣ Gv ∈V } (12)\nand since, U ⊆V , it follows that every c-graph Gu ∈U also belong to V . Thus applying associative and conmutative laws we can rewrite (12) as\n∑ { Gu ∣∣ (u1,u2) ∈U }+∑{ Gv +Gv ∣∣ Gv ∈V\\U }\nthat, by summ idempotence, is clearly equivalent to ∑ { Gu ∣∣ (u1,u2) ∈U }+∑{ Gv ∣∣ Gv ∈V\\U }\nThat is, term(U)+ term(V ) = term(V ) which implies term(U)≤ term(V ).\nProposition 17 (Application associativity) Let T , U and W be three causal values. Then, it holds that U · (T ·W ) = (U ·T ) ·W and further U ·T ·W = ↓ { GU ·GT ·GW ∣∣ GU ∈U, GT ∈ T and GW ∈W }. Proof . By definition it follows that\n(U ·T ) ·W = ↓{ GU ·GT ∣∣ GU ∈U and GT ∈ T } ·W\n= ↓{ G′ ·GW ∣∣ GU ∈U, GT ∈ T, G′ ≤ GU ·GT and GW ∈W }\n= ↓{ (GU ·GT ) ·GW ∣∣ GU ∈U, GT ∈ T and GW ∈W }\nIn the same way, it also follows that U · (T ·W ) = ↓{ GU · (GT ·GW ) ∣∣ GU ∈U, GT ∈ T and GW ∈W }\nThen it is enough to show that (GU ·GT ) ·GW = GU · (GT ·Gw) = GU ·GT ·GW which holds due to Proposition 2.\nProposition 18 (Application absorption) Let T , U and W be three causal values. Then T = T + U ·T ·W and U ·T ·W = T ∗U ·T ·W\nProof . From Proposition 17 it follows that U ·T ·W = ↓ { GU ·GT ·GW ∣∣ GU ∈U, GT ∈ T and GW ∈W }\nFurthermore, for every c-graph GT ∈ T , it holds that GU ·GT · TW ≤ GT . Then, since T is an ideal, it follows that GU ·GT ·TW ∈ T and consequently U ·T ·W ⊆ T . Thus U ·T ·W ∪T = T and U ·T ·W ∩T =U ·T ·W and, by definition, these equalities can be rewritten as U ·T ·W +T = T and U ·T ·W ∗T =U ·T ·W .\nProposition 19 (Application distributivity w.r.t. additions) Let T , U and W be three causal values. Then, it holds that U · (T +W ) = (U ·T )+ (U ·W and (U +T ) ·W = (U ·W )+(T ·W ).\nProof . By definition, it follows that\n(U ·T )+(U ·W ) = (U ·T )∪ (U ·W ) = ↓ { GU ·GT ∣∣ GU ∈U and GT ∈ T } ∪ ↓{ GU ·GT ∣∣ GU ∈U and GW ∈W } = ↓ { GU ·G′\n∣∣ GU ∈U and G′ ∈ T ∪W }=U · (T ∪W ) =U · (T +W ) Furthermore (U +T ) ·W = (U ·W )+(T ·W ) holds symmetrically.\nProduct distributivity laws follows from Propositions 5 and 6.\nCorollary 5 The applications distributivity properties reflected in Figure 13 hold.\nProof . From proposition 16, it follows that c, d and e are the principal ideals ↓Gc, ↓Gd and ↓Ge for some c-graphs Gc, Gd and Ge. Furthermore, from Proposition 5 distributivity holds for causal graphs, i.e. Gc · (Gd ∗Ge) = (Gc ·Gd)∗ (Gc ·Ge) and (Gc ∗Gd) ·Ge = (Gc ·Ge)∗ (Gd ·Ge) and from Theorem 10 it follows that this also holds for they principal ideals ↓Gc, ↓Gd and ↓Ge. In the same way, from Proposition 6, it follows c ·d · e = (c ·d)∗ (d · e).\nProposition 20 (Application identity and annihilator) Given a causal value T , it holds that T = 1 ·T , T = T ·1, 0 = T ·0 and 0 = 0 ·T .\nProof . Note that 1 and 0 respectively correspond to CLb and /0 and by definition it follows that 1 ·T = ↓ { G ·GT ∣∣ G ∈ CLb and GT ∈ T }= T\n0 ·T = ↓ { G ·GT ∣∣ G ∈ /0 and GT ∈ T }= /0 = 0\nThe other cases are symmetric.\nProposition 21 (Application idempotentce) Given a label l, it holds that l · l = l\nProof . By definition l corresponds to the causal value ↓Gl where Gl is the causal graphs which contains the only edge (l, l). Furthermore Gl ·Gl = Gl and from Theorem 10 it follows that ↓Gl = ↓Gl · ↓Gl and consequently l = l · l.\nProposition 22 (Causal term representation) For every causal value T is equal to ∑ { term(G) ∣∣ G ∈ T }. Proof . For every causal term T , it holds that T = ∑{ ↓G\n∣∣ G ∈ T }. Furthermore, from Proposition 3, it follows that every causal graph G is equal to ∏{ l1 · l2\n∣∣ (l1, l2) is an edge of G } and then, from Theorem 10, it holds that ↓G = ∏{ l1 · l2\n∣∣ (l1, l2) is an edge of G }. Consequently T = ∑{ term(G)\n∣∣ G ∈ T }. Proposition 23 Every causal term without sums c can be rewritten as normal(c) def=∏{ l1 ·l2)\n∣∣ (l1, l2) is an edge of G } for some casual graph G using the algebraic equivalences in Figures 12 and 13.\nProof . We start rewritten c as ∏C where every causal term x ∈C is in the form of l1 · . . . · ln by by applying the distributive law until no product is in the scope of “·”. Then we remove each occurrence of 1 applying the identity law and we replace term x by x ·x when x is a label. That is, we have C′ s.t. every x′ ∈C is equal to x′ = l1 · . . . · ln with n > 1 and li 6= 1. Then we rewrite each x′ ∈C′ as l1 · l2 ∗ l2 · l3 ∗ . . .∗ ln−1 · ln by successively application of the equivalence c ·d ·e = c ·d ∗ d · e. Finally we add every transitive edge applying the equivalence c ·d ∗d · e = c ·d ∗d · e∗ c · e (Proposition 10).\nProposition 24 Every causal term t can be rewritten as normal(t) def= { normal(c) ∣∣ c ∈ S } for some set of terms without sums S using the algebraic equivalences in Figures 12 and 13.\nProof . We only have to rewrite t as a causal term where sums are not in the scope of “∗” and “·” by successively application of distributivity over sums. Then the statement holds from Proposition 23\nProposition 25 Let c and d be causal terms without “+”. Then c ≤ d iff c = c ∗ d follows from the algebraic equivalences in Figures 12 and 13. Proof . From Proposition 23, c and d can be rewrite as c′ = ∏{ l1 · l2) ∣∣ (l1, l2) is an edge of Gc }\nand d′ = ∏{ l1 · l2) ∣∣ (l1, l2) is an edge of Gd } for some causal graphs Gc and Gd . Furthermore, from Proposition 3 and Theorem 10, it holds that ↓Gc = c′ and ↓Gd = d′. Thus, by definition c≤ d iff ↓Gc ≤ ↓Gd iff ↓Gc =↓Gc ∩ ↓Gd iff ↓Gc = ↓Gc ∗ ↓Gd iff c′ = c′ ∗d′. Let us see that c′ = c′ ∗d′ can be follows from the algebraic equivalences."
    } ],
    "references" : [ {
      "title" : "Explicit provability and constructive semantics",
      "author" : [ "S.N. ARTËMOV" ],
      "venue" : "Bulletin of Symbolic Logic 7, 1, 1–36.",
      "citeRegEx" : "ARTËMOV,? 2001",
      "shortCiteRegEx" : "ARTËMOV",
      "year" : 2001
    }, {
      "title" : "Answer set programming at a glance",
      "author" : [ "G. BREWKA", "T. EITER", "M. TRUSZCZYNSKI" ],
      "venue" : "Commun. ACM 54, 12, 92–103.",
      "citeRegEx" : "BREWKA et al\\.,? 2011",
      "shortCiteRegEx" : "BREWKA et al\\.",
      "year" : 2011
    }, {
      "title" : "Compiled Labelled Deductive Systems: A Uniform Presentation of Non-Classical Logics",
      "author" : [ "K. BRODA", "D. GABBAY", "L. LAMB", "A. RUSSO." ],
      "venue" : "Research Studies Press.",
      "citeRegEx" : "BRODA et al\\.,? 2004",
      "shortCiteRegEx" : "BRODA et al\\.",
      "year" : 2004
    }, {
      "title" : "Logic programs and causal proofs",
      "author" : [ "P. CABALAR" ],
      "venue" : "AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning. AAAI.",
      "citeRegEx" : "CABALAR,? 2011",
      "shortCiteRegEx" : "CABALAR",
      "year" : 2011
    }, {
      "title" : "An algebra of causal chains",
      "author" : [ "P. CABALAR", "J. FANDINNO" ],
      "venue" : "Proc. of the 6th Workshop on Answer Set Programming and Other Computing Paradigms (ASPOCP’13).",
      "citeRegEx" : "CABALAR and FANDINNO,? 2013",
      "shortCiteRegEx" : "CABALAR and FANDINNO",
      "year" : 2013
    }, {
      "title" : "Justifications for logic programming",
      "author" : [ "C.V. DAMÁSIO", "A. ANALYTI", "G. ANTONIOU" ],
      "venue" : "Proc. of the 12th Intl. Conf. on Logic Programming and Nonmonotonic Reasoning, (LPNMR’13). Lecture Notes in Computer Science, vol. 8148. Springer, 530–542.",
      "citeRegEx" : "DAMÁSIO et al\\.,? 2013",
      "shortCiteRegEx" : "DAMÁSIO et al\\.",
      "year" : 2013
    }, {
      "title" : "Justification semantics: A unifiying framework for the semantics of logic programs",
      "author" : [ "M. DENECKER", "D. DE SCHREYE" ],
      "venue" : "Proc. of the Logic Programming and Nonmonotonic Reasoning Workshop. 365–379.",
      "citeRegEx" : "DENECKER and SCHREYE,? 1993",
      "shortCiteRegEx" : "DENECKER and SCHREYE",
      "year" : 1993
    }, {
      "title" : "A new fixpoint semantics for general logic programs compared with the well-founded and the stable model semantics",
      "author" : [ "F. FAGES" ],
      "venue" : "New Generation Computing 9, 3-4, 425–443.",
      "citeRegEx" : "FAGES,? 1991",
      "shortCiteRegEx" : "FAGES",
      "year" : 1991
    }, {
      "title" : "Meta-programming technique for debugging answer-set programs",
      "author" : [ "M. GEBSER", "J. PÜHRER", "T. SCHAUB", "H. TOMPITS" ],
      "venue" : "Proc. of the 23rd Conf. on Artificial Inteligence (AAAI’08). 448–453.",
      "citeRegEx" : "GEBSER et al\\.,? 2008",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2008
    }, {
      "title" : "The stable model semantics for logic programming",
      "author" : [ "M. GELFOND", "V. LIFSCHITZ" ],
      "venue" : "Logic Programming: Proc. of the Fifth International Conference and Symposium (Volume 2), R. A. Kowalski and K. A. Bowen, Eds. MIT Press, Cambridge, MA, 1070–1080.",
      "citeRegEx" : "GELFOND and LIFSCHITZ,? 1988",
      "shortCiteRegEx" : "GELFOND and LIFSCHITZ",
      "year" : 1988
    }, {
      "title" : "Two concepts of causality",
      "author" : [ "N. HALL" ],
      "venue" : "181–276.",
      "citeRegEx" : "HALL,? 2004",
      "shortCiteRegEx" : "HALL",
      "year" : 2004
    }, {
      "title" : "Defaults and normality in causal structures",
      "author" : [ "J.Y. HALPERN" ],
      "venue" : "Proc. of the Eleventh International Conference on Principles of Knowledge Representation and Reasoning (KR 2008). 198–208.",
      "citeRegEx" : "HALPERN,? 2008",
      "shortCiteRegEx" : "HALPERN",
      "year" : 2008
    }, {
      "title" : "Causes and explanations: A structural-model approach",
      "author" : [ "J.Y. HALPERN", "J. PEARL" ],
      "venue" : "part I: Causes. British Journal for Philosophy of Science 56, 4, 843–887.",
      "citeRegEx" : "HALPERN and PEARL,? 2005",
      "shortCiteRegEx" : "HALPERN and PEARL",
      "year" : 2005
    }, {
      "title" : "Cause and norm",
      "author" : [ "C. HITCHCOCK", "J. KNOBE" ],
      "venue" : "Journal of Philosophy 11, 587–612.",
      "citeRegEx" : "HITCHCOCK and KNOBE,? 2009",
      "shortCiteRegEx" : "HITCHCOCK and KNOBE",
      "year" : 2009
    }, {
      "title" : "An enquiry concerning human understanding",
      "author" : [ "D. HUME" ],
      "venue" : "Reprinted by Open Court Press, LaSalle, IL, 1958.",
      "citeRegEx" : "HUME,? 1748",
      "shortCiteRegEx" : "HUME",
      "year" : 1748
    }, {
      "title" : "Theory of generalized annotated logic programming and its applications",
      "author" : [ "M. KIFER", "V.S. SUBRAHMANIAN" ],
      "venue" : "Journal of Logic Programming 12.",
      "citeRegEx" : "KIFER and SUBRAHMANIAN,? 1992",
      "shortCiteRegEx" : "KIFER and SUBRAHMANIAN",
      "year" : 1992
    }, {
      "title" : "A practical analysis of non-termination in large logic programs",
      "author" : [ "S. LIANG", "M. KIFER" ],
      "venue" : "TPLP 13, 4-5, 705–719.",
      "citeRegEx" : "LIANG and KIFER,? 2013",
      "shortCiteRegEx" : "LIANG and KIFER",
      "year" : 2013
    }, {
      "title" : "Embracing causality in specifying the indirect effects of actions",
      "author" : [ "LIN F." ],
      "venue" : "Proc. of the Intl. Joint Conf. on Artificial Intelligence (IJCAI), C. S. Mellish, Ed. Morgan Kaufmann, Montreal, Canada.",
      "citeRegEx" : "F.,? 1995",
      "shortCiteRegEx" : "F.",
      "year" : 1995
    }, {
      "title" : "Causal theories of actions revisited",
      "author" : [ "F. LIN", "M. SOUTCHANSKI" ],
      "venue" : "AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning.",
      "citeRegEx" : "LIN and SOUTCHANSKI,? 2011",
      "shortCiteRegEx" : "LIN and SOUTCHANSKI",
      "year" : 2011
    }, {
      "title" : "Causal theories of action and change",
      "author" : [ "N. MCCAIN", "H. TURNER" ],
      "venue" : "Proc. of the AAAI-97. 460–465.",
      "citeRegEx" : "MCCAIN and TURNER,? 1997",
      "shortCiteRegEx" : "MCCAIN and TURNER",
      "year" : 1997
    }, {
      "title" : "Causality in commonsense reasoning about actions",
      "author" : [ "N.C. MCCAIN" ],
      "venue" : "Tech. rep.",
      "citeRegEx" : "MCCAIN,? 1997",
      "shortCiteRegEx" : "MCCAIN",
      "year" : 1997
    }, {
      "title" : "Epistemological problems of Artificial Intelligence",
      "author" : [ "J. MCCARTHY" ],
      "venue" : "Proc. of the Intl. Joint Conf. on Artificial Intelligence (IJCAI). MIT Press, Cambridge, MA, 1038–1044.",
      "citeRegEx" : "MCCARTHY,? 1977",
      "shortCiteRegEx" : "MCCARTHY",
      "year" : 1977
    }, {
      "title" : "Elaboration tolerance",
      "author" : [ "J. MCCARTHY" ],
      "venue" : "Proc. of the 4th Symposium on Logical Formalizations of Commonsense Reasoning (Common Sense 98). London, UK, 198–217. Updated version at http://www-formal.stanford.edu/jmc/elaboration.ps.",
      "citeRegEx" : "MCCARTHY,? 1998",
      "shortCiteRegEx" : "MCCARTHY",
      "year" : 1998
    }, {
      "title" : "Equilibrium logic",
      "author" : [ "D. PEARCE" ],
      "venue" : "Ann. Math. Artif. Intell. 47, 1-2, 3–41.",
      "citeRegEx" : "PEARCE,? 2006",
      "shortCiteRegEx" : "PEARCE",
      "year" : 2006
    }, {
      "title" : "Causality: models, reasoning, and inference",
      "author" : [ "J. PEARL" ],
      "venue" : "Cambridge University Press, New York, NY, USA.",
      "citeRegEx" : "PEARL,? 2000",
      "shortCiteRegEx" : "PEARL",
      "year" : 2000
    }, {
      "title" : "Derivation procedures for extended stable models",
      "author" : [ "L.M. PEREIRA", "J.N. APARÍCIO", "J.J. ALFERES" ],
      "venue" : "Proceedings of the 12th International Joint Conference on Artificial Intelligence, J. Mylopoulos and R. Reiter, Eds. Morgan Kaufmann, 863–869.",
      "citeRegEx" : "PEREIRA et al\\.,? 1991",
      "shortCiteRegEx" : "PEREIRA et al\\.",
      "year" : 1991
    }, {
      "title" : "Justifications for logic programs under answer set semantics",
      "author" : [ "E. PONTELLI", "T.C. SON", "O. EL-KHATIB" ],
      "venue" : "Theory and Practice of Logic Programming 9, 1, 1–56.",
      "citeRegEx" : "PONTELLI et al\\.,? 2009",
      "shortCiteRegEx" : "PONTELLI et al\\.",
      "year" : 2009
    }, {
      "title" : "Argumentation-based answer set justification",
      "author" : [ "C. SCHULZ", "M. SERGOT", "F. TONI" ],
      "venue" : "Proc. of the 11th Intl. Symposium on Logical Formalizations of Commonsense Reasoning (Commonsense’13).",
      "citeRegEx" : "SCHULZ et al\\.,? 2013",
      "shortCiteRegEx" : "SCHULZ et al\\.",
      "year" : 2013
    }, {
      "title" : "Free distributive completions of partial complete lattices",
      "author" : [ "G. STUMME" ],
      "venue" : "Order 14, 179–189.",
      "citeRegEx" : "STUMME,? 1997",
      "shortCiteRegEx" : "STUMME",
      "year" : 1997
    }, {
      "title" : "Ramification and causality",
      "author" : [ "M. THIELSCHER" ],
      "venue" : "Artificial Intelligence Journal 1-2, 89, 317–364.",
      "citeRegEx" : "THIELSCHER,? 1997",
      "shortCiteRegEx" : "THIELSCHER",
      "year" : 1997
    }, {
      "title" : "A constructive approach to the ramification problem",
      "author" : [ "K. VAN BELLEGHEM", "M. DENECKER", "D. THESEIDER-DUPRÉ" ],
      "venue" : "Proceedings of ESSLLI. Citeseer, 1–17.",
      "citeRegEx" : "BELLEGHEM et al\\.,? 1998",
      "shortCiteRegEx" : "BELLEGHEM et al\\.",
      "year" : 1998
    }, {
      "title" : "The semantics of predicate logic as a programming language",
      "author" : [ "M.H. VAN EMDEN", "R.A. KOWALSKI" ],
      "venue" : "J. ACM 23, 4, 733–742.",
      "citeRegEx" : "EMDEN and KOWALSKI,? 1976",
      "shortCiteRegEx" : "EMDEN and KOWALSKI",
      "year" : 1976
    }, {
      "title" : "Actual causation in cp-logic",
      "author" : [ "J. VENNEKENS" ],
      "venue" : "TPLP 11, 4-5, 647–662.",
      "citeRegEx" : "VENNEKENS,? 2011",
      "shortCiteRegEx" : "VENNEKENS",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 22,
      "context" : "If the pseudo-literal “do(A,X) caused occurs(Y )” actually corresponds to an explicit representation of all the possible ways of causing an accident, however, one immediately runs into a problem of elaboration tolerance (McCarthy 1998) — adding new rules that causally connect do(A,X) to occurs(Y ) (in a direct or indirect way) would force us to build new rules for responsible(X ,Y ).",
      "startOffset" : 220,
      "endOffset" : 235
    }, {
      "referenceID" : 1,
      "context" : "While not straightforward, the rewarding perspective of such a semantic approach is an extension of Answer Set Programming (ASP) (Brewka et al. 2011) with causal literals capable of representing different kinds of causal influences (sufficient cause, necessary cause, etc).",
      "startOffset" : 129,
      "endOffset" : 149
    }, {
      "referenceID" : 9,
      "context" : "To this end, we propose a multi-valued extension of logic programs under the stable model semantics (Gelfond and Lifschitz 1988) where each true atom in a model is associated with a set of justifications in the form of causal graphs.",
      "startOffset" : 100,
      "endOffset" : 128
    }, {
      "referenceID" : 28,
      "context" : "Using terminology and results from lattice theory in (Stumme 1997) we can prove the following.",
      "startOffset" : 53,
      "endOffset" : 66
    }, {
      "referenceID" : 28,
      "context" : "1 We use terminology from (Stumme 1997).",
      "startOffset" : 26,
      "endOffset" : 39
    }, {
      "referenceID" : 15,
      "context" : "The proof of this theorem relies on an encoding of causal logic programs into Generalized Annotated Logic Programming (GAP) (Kifer and Subrahmanian 1992) and applying existing results for that general multi-valued LP framework.",
      "startOffset" : 124,
      "endOffset" : 153
    }, {
      "referenceID" : 9,
      "context" : "To capture this behaviour, we proceed to extend the traditional program reduct (Gelfond and Lifschitz 1988) to causal logic programs.",
      "startOffset" : 79,
      "endOffset" : 107
    }, {
      "referenceID" : 21,
      "context" : "4 A case of the well-known qualification problem (McCarthy 1977), i.",
      "startOffset" : 49,
      "endOffset" : 64
    }, {
      "referenceID" : 13,
      "context" : "5 The paper (Hitchcock and Knobe 2009) contains an extended discussion with several examples showing how people ordinarily understand causes as deviations from a norm.",
      "startOffset" : 12,
      "endOffset" : 38
    }, {
      "referenceID" : 4,
      "context" : "A preliminary version (Cabalar and Fandinno 2013) of the current approach relied on chains of labels but was actually weaker, missing basic properties we can derive now from causal graphs.",
      "startOffset" : 22,
      "endOffset" : 49
    }, {
      "referenceID" : 19,
      "context" : "Papers on reasoning about actions and change (Lin 1995; McCain and Turner 1997; Thielscher 1997) have been traditionally focused on using causal inference to solve representational problems (mostly, the frame, ramification and qualification problems) without paying much attention to the derivation of cause-effect relations.",
      "startOffset" : 45,
      "endOffset" : 96
    }, {
      "referenceID" : 29,
      "context" : "Papers on reasoning about actions and change (Lin 1995; McCain and Turner 1997; Thielscher 1997) have been traditionally focused on using causal inference to solve representational problems (mostly, the frame, ramification and qualification problems) without paying much attention to the derivation of cause-effect relations.",
      "startOffset" : 45,
      "endOffset" : 96
    }, {
      "referenceID" : 24,
      "context" : "Perhaps the most established AI approach for causality is relying on causal networks (Pearl 2000; Halpern and Pearl 2005; Halpern 2008).",
      "startOffset" : 85,
      "endOffset" : 135
    }, {
      "referenceID" : 12,
      "context" : "Perhaps the most established AI approach for causality is relying on causal networks (Pearl 2000; Halpern and Pearl 2005; Halpern 2008).",
      "startOffset" : 85,
      "endOffset" : 135
    }, {
      "referenceID" : 11,
      "context" : "Perhaps the most established AI approach for causality is relying on causal networks (Pearl 2000; Halpern and Pearl 2005; Halpern 2008).",
      "startOffset" : 85,
      "endOffset" : 135
    }, {
      "referenceID" : 2,
      "context" : "Apart from the different AI approaches and attitudes towards causality, from the technical point of view, the current approach can be classified as a labelled deductive system (Broda et al. 2004).",
      "startOffset" : 176,
      "endOffset" : 195
    }, {
      "referenceID" : 2,
      "context" : "6 Related Work Cabalar (2011) already introduced the main motivations of our work, but used ad hoc operations on proof trees without resorting to algebraic structures.",
      "startOffset" : 15,
      "endOffset" : 30
    }, {
      "referenceID" : 2,
      "context" : "6 Related Work Cabalar (2011) already introduced the main motivations of our work, but used ad hoc operations on proof trees without resorting to algebraic structures. A preliminary version (Cabalar and Fandinno 2013) of the current approach relied on chains of labels but was actually weaker, missing basic properties we can derive now from causal graphs. There exists a vast literature on causal reasoning in Artificial Intelligence. Papers on reasoning about actions and change (Lin 1995; McCain and Turner 1997; Thielscher 1997) have been traditionally focused on using causal inference to solve representational problems (mostly, the frame, ramification and qualification problems) without paying much attention to the derivation of cause-effect relations. Perhaps the most established AI approach for causality is relying on causal networks (Pearl 2000; Halpern and Pearl 2005; Halpern 2008). In this approach, it is possible to conclude cause-effect relations like “A has caused B” from the behaviour of structural equations by applying the counterfactual interpretation from Hume (1748): “had A not happened, B would not have happened.",
      "startOffset" : 15,
      "endOffset" : 1095
    }, {
      "referenceID" : 2,
      "context" : "6 Related Work Cabalar (2011) already introduced the main motivations of our work, but used ad hoc operations on proof trees without resorting to algebraic structures. A preliminary version (Cabalar and Fandinno 2013) of the current approach relied on chains of labels but was actually weaker, missing basic properties we can derive now from causal graphs. There exists a vast literature on causal reasoning in Artificial Intelligence. Papers on reasoning about actions and change (Lin 1995; McCain and Turner 1997; Thielscher 1997) have been traditionally focused on using causal inference to solve representational problems (mostly, the frame, ramification and qualification problems) without paying much attention to the derivation of cause-effect relations. Perhaps the most established AI approach for causality is relying on causal networks (Pearl 2000; Halpern and Pearl 2005; Halpern 2008). In this approach, it is possible to conclude cause-effect relations like “A has caused B” from the behaviour of structural equations by applying the counterfactual interpretation from Hume (1748): “had A not happened, B would not have happened.” As discussed by Hall (2004), the counterfactual-based definition of causation corresponds to recognising some kind of dependence relation in the behaviour of a non-causal system description.",
      "startOffset" : 15,
      "endOffset" : 1173
    }, {
      "referenceID" : 2,
      "context" : "Apart from the different AI approaches and attitudes towards causality, from the technical point of view, the current approach can be classified as a labelled deductive system (Broda et al. 2004). In particular, the work that has had a clearest and most influential relation to the current proposal is the Logic of Proofs (LP) by Artëmov (2001). We have borrowed from that formalism part of the notation for our causal terms and rule labellings and the fundamental idea of keeping track of justifications by considering rule applications.",
      "startOffset" : 177,
      "endOffset" : 345
    }, {
      "referenceID" : 8,
      "context" : "Focusing on LP, our work obviously relates to explanations as provided by approaches to debugging in ASP (Gebser et al. 2008; Pontelli et al. 2009; Schulz et al. 2013; Damásio et al. 2013).",
      "startOffset" : 105,
      "endOffset" : 188
    }, {
      "referenceID" : 26,
      "context" : "Focusing on LP, our work obviously relates to explanations as provided by approaches to debugging in ASP (Gebser et al. 2008; Pontelli et al. 2009; Schulz et al. 2013; Damásio et al. 2013).",
      "startOffset" : 105,
      "endOffset" : 188
    }, {
      "referenceID" : 27,
      "context" : "Focusing on LP, our work obviously relates to explanations as provided by approaches to debugging in ASP (Gebser et al. 2008; Pontelli et al. 2009; Schulz et al. 2013; Damásio et al. 2013).",
      "startOffset" : 105,
      "endOffset" : 188
    }, {
      "referenceID" : 32,
      "context" : ", by the counterfactualbased causal LP approach (Vennekens 2011).",
      "startOffset" : 48,
      "endOffset" : 64
    }, {
      "referenceID" : 23,
      "context" : "An interesting issue is to replace the syntactic definition by a reduct in favour of a logical treatment of default negation, as has been done for (noncausal) stable models and their characterisation in terms of Equilibrium Logic (Pearce 2006).",
      "startOffset" : 230,
      "endOffset" : 243
    }, {
      "referenceID" : 7,
      "context" : "Focusing on LP, our work obviously relates to explanations as provided by approaches to debugging in ASP (Gebser et al. 2008; Pontelli et al. 2009; Schulz et al. 2013; Damásio et al. 2013). Pereira et al. (1991) and Denecker and De Schreye (1993) also define different semantics in terms of justifications, but do not provide calculi for them.",
      "startOffset" : 106,
      "endOffset" : 212
    }, {
      "referenceID" : 7,
      "context" : "Focusing on LP, our work obviously relates to explanations as provided by approaches to debugging in ASP (Gebser et al. 2008; Pontelli et al. 2009; Schulz et al. 2013; Damásio et al. 2013). Pereira et al. (1991) and Denecker and De Schreye (1993) also define different semantics in terms of justifications, but do not provide calculi for them.",
      "startOffset" : 106,
      "endOffset" : 247
    }, {
      "referenceID" : 7,
      "context" : "Fages (1991) characterised stable models in terms of loop-free justifications expressed as partial order relations among atoms in positive bodies.",
      "startOffset" : 0,
      "endOffset" : 13
    }, {
      "referenceID" : 7,
      "context" : "Fages (1991) characterised stable models in terms of loop-free justifications expressed as partial order relations among atoms in positive bodies. We conjecture that the causal values obtained in our semantics formally capture Fages’ justifications. A more far-fetched resemblance exists to work on the analysis of tabled Prolog computations. There, the goal is to identify potential causes for non-termination of program evaluations, which can be achieved examining so-called forest logs, i.e., a log of table operations for a computation. By adding unique labels for rules (with the original intention to disambiguate analysis results, cf. Liang and Kifer (2013), however not as an explicit means for representing knowledge), in principle a forest log implicitly contains the information necessary to read of the causal model of a completely labelled positive causal logic program.",
      "startOffset" : 0,
      "endOffset" : 665
    }, {
      "referenceID" : 7,
      "context" : "Fages (1991) characterised stable models in terms of loop-free justifications expressed as partial order relations among atoms in positive bodies. We conjecture that the causal values obtained in our semantics formally capture Fages’ justifications. A more far-fetched resemblance exists to work on the analysis of tabled Prolog computations. There, the goal is to identify potential causes for non-termination of program evaluations, which can be achieved examining so-called forest logs, i.e., a log of table operations for a computation. By adding unique labels for rules (with the original intention to disambiguate analysis results, cf. Liang and Kifer (2013), however not as an explicit means for representing knowledge), in principle a forest log implicitly contains the information necessary to read of the causal model of a completely labelled positive causal logic program. 7 Conclusions In this paper we have provided a multi-valued semantics for normal logic programs whose truth values form a lattice of causal graphs. A causal graph is nothing else but a graph of rule labels that reflects some order of rule applications. In this way, a model assigns to each true atom a value that contains justifications for its derivation from the existing rules. We have further provided three basic operations on the lattice: an addition, that stands for alternative, independent justifications; a product, that represents joint interaction of causes; and a concatenation that reflects rule application. We have shown that, for positive programs, there exists a least model that coincides with the least fixpoint of a direct consequences operator, analogous to van Emden and Kowalski (1976). With this, we are able to prove a direct correspondence between the semantic values we obtain and the syntactic idea of proof.",
      "startOffset" : 0,
      "endOffset" : 1694
    }, {
      "referenceID" : 17,
      "context" : "An example of causal action theory In this section we consider a more elaborated example from Pearl (2000).",
      "startOffset" : 12,
      "endOffset" : 107
    }, {
      "referenceID" : 23,
      "context" : "As commented by Pearl (2000), the interesting feature of this circuit is that, seen from outside as a black box, it behaves exactly as a pair of independent, parallel switches, so it is impossible to detect the causal dependence between a and b by a mere observation of performed actions and their effects on the lamp.",
      "startOffset" : 16,
      "endOffset" : 29
    }, {
      "referenceID" : 20,
      "context" : "(McCain 1997).",
      "startOffset" : 0,
      "endOffset" : 13
    }, {
      "referenceID" : 18,
      "context" : "An iteresting variation of this example is incorporating some mechanic device to stop the wheels (Van Belleghem et al. 1998; Lin and Soutchanski 2011).",
      "startOffset" : 97,
      "endOffset" : 150
    }, {
      "referenceID" : 28,
      "context" : "Stumme was showed in (Stumme 1997) that the concept lattice B〈F,VLb,∆〉 (with F∆I⇔ F ∩ I 6= / 0) is isomorphic to the free completely distributive complete lattice generated by the partial lattice 〈CLb,+,∗〉 where + and ∗ are two partial functions corresponding with the supremum and infimum.",
      "startOffset" : 21,
      "endOffset" : 34
    }, {
      "referenceID" : 15,
      "context" : "Thus, from Theorem 1 in (Kifer and Subrahmanian 1992), it follows that the operator TP is monotonic.",
      "startOffset" : 24,
      "endOffset" : 53
    }, {
      "referenceID" : 15,
      "context" : "Thus from Theorem 3 in (Kifer and Subrahmanian 1992), it follows that TP ↑ ω (0) = l f p(TP) and this is the least model of P.",
      "startOffset" : 23,
      "endOffset" : 52
    } ],
    "year" : 2014,
    "abstractText" : "In this work we propose a multi-valued extension of logic programs under the stable models semantics where each true atom in a model is associated with a set of justifications. These justifications are expressed in terms of causal graphs formed by rule labels and edges that represent their application ordering. For positive programs, we show that the causal justifications obtained for a given atom have a direct correspondence to (relevant) syntactic proofs of that atom using the program rules involved in the graphs. The most interesting contribution is that this causal information is obtained in a purely semantic way, by algebraic operations (product, sum and application) on a lattice of causal values whose ordering relation expresses when a justification is stronger than another. Finally, for programs with negation, we define the concept of causal stable model by introducing an analogous transformation to Gelfond and Lifschitz’s program reduct. As a result, default negation behaves as “absence of proof” and no justification is derived from negative literals, something that turns out convenient for elaboration tolerance, as we explain with a running example.",
    "creator" : "LaTeX with hyperref package"
  }
}