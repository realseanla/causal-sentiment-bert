{
  "name" : "1706.05261.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "From Propositional Logic to Plausible Reasoning: A Uniqueness Theorem",
    "authors" : [ "Kevin S. Van Horn" ],
    "emails" : [ "vanhorn@adobe.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We consider the question of extending propositional logic to a logic of plausible reasoning, and posit four requirements that any such extension should satisfy. Each is a requirement that some property of classical propositional logic be preserved in the extended logic; as such, the requirements are simpler and less problematic than those used in Cox’s Theorem and its variants. As with Cox’s Theorem, our requirements imply that the extended logic must be isomorphic to (finite-set) probability theory. We also obtain specific numerical values for the probabilities, recovering the classical definition of probability as a theorem, with truth assignments that satisfy the premise playing the role of the “possible cases.”\nKeywords: Bayesian, Carnap, Cox, Jaynes, logic, probability"
    }, {
      "heading" : "1. Introduction",
      "text" : "E. T. Jaynes [13, p. xxii] proposes the view that probability theory is the uniquely determined extension of classical propositional logic (CPL) to a “logic of plausible reasoning” :\nOur theme is simply: probability theory as extended logic. . . . the mathematical rules of probability theory are not merely rules for calculating frequencies of ‘random variables’; they are also the unique consistent rules for conducting inference (i.e. plausible reasoning) of any kind. . .\nThis view is grounded in the work of Pólya [17] and Cox [9], especially the latter. In this paper we aim to set the notion of probability theory as the necessary extension of CPL on solid footing.\nISubmitted and currently under review at International Journal of Approximate Reasoning.\nII c©2017. This manuscript version is made available under the CC-BY-NC-ND 4.0 license http://creativecommons.org/licenses/by-nc-nd/4.0/.\nEmail address: vanhorn@adobe.com (Kevin S. Van Horn)\nPreprint submitted to Elsevier\nar X\niv :1\n70 6.\n05 26\n1v 1\n[ cs\n.A I]\n1 6\nJu n\n20 17\nOur goal is to generalize the logical consequence relation, which deals only in certitudes, to handle degrees of certainty. Whereas X |= A means that A (the conclusion) is a logical consequence of X (the premise), we write A | X for “the reasonable credibility of the proposition A (the query) when the proposition X (the premise) is known to be true” (paraphrasing Cox [9].) We call (· | ·) the plausibility function. If X |= A then A | X is some value indicating “certainly true,” if X |= ¬A then A | X is some value indicating “certainly false,” and otherwise A | X is a value indicating some intermediate level of plausibility. Our task is to determine what the plausibility function must be, based on logical criteria.\nAs a generalization of the logical consequence relation, the plausibility function must depend only on its two explicit arguments; the value it returns must not depend on any additional information that varies according to the problem domain to which it is applied, nor according to the intended meanings of the propositional symbols. This is a formal logical theory we are developing, and so any intended semantics of the propositional symbols must be expressed axiomatically in the premise.\nOne might question whether all relevant information for determining the plausibility of some proposition A can be expressed in propositional form for inclusion in the premise X. Might not our background information include “soft” relationships, mere propensities for propositions to be associated in some way? Although we provide some suggestive examples, we do not attempt to resolve that question. Instead we ask, given that the background information and intended semantics are expressed in propositional form and included in the premise, with no other information available, what can we conclude about the plausibility function?\nWe posit four Requirements for the plausibility function. Each of these requires that some property of the logical consequence relation be retained in the generalization to a plausibility function. Three are invariance properties, and the fourth is a requirement to preserve distinctions in degree of plausibility that already exist within CPL. These Requirements (discussed in detail later) are the following:\nR1. If X and Y are logically equivalent, and A and B are logically equivalent assuming X, then A | X = B | Y (Section 4.)\nR2. We may define a new propositional symbol without affecting the plausibility of any proposition that does not mention that symbol. Specifically, if s is a propositional symbol not appearing in A, X, or E, then A | X = A | (s↔ E) ∧X (Section 5.)\nR3. Adding irrelevant information to the premise does not affect the plausibility of the query. Specifically, if Y is a satisfiable propositional formula that uses no propositional symbol occurring in A or X, then A | X = A | Y ∧X (Section 6.)\nR4. The implication ordering is preserved: if X |= A→ B but not X |= B → A\nthen A | X is a plausibility value that is strictly less than B | X (Section 7.)\nNote that we do not assume that plausibility values are real numbers, nor that they are totally ordered; R4 presumes only that there is some partial order on plausibility values.\nGiven R1–R4, we prove that plausibilities are essentially probabilities in disguise. Specifically, we show that\n1. there is an order-preserving isomorphism P between the set of plausibility values P and the set of rational probabilities Q ∩ [0, 1];\n2. P (A | X), the plausibility A | X mapped via P to the unit interval, is necessarily the ratio of the number of truth assignments that satisfy both A and X to the number of truth assignments that satisfy X; and\n3. hence the usual laws of probability follow as a consequence.\nThis identifies finite-set probability theory as the uniquely determined extension of CPL to a logic of plausible reasoning.\nThe body of this paper is organized as follows:\n• In Section 2 we compare this work to Cox’s Theorem and variants, as well as Carnap’s system of logical probability.\n• In Section 3 we review some notions from CPL, discuss the partial plausibility ordering that already exists within CPL, and discuss the nature of the plausibility function.\n• Our main result is proven in Sections 4, 5, 6, and 7, which also introduce the Requirements, discuss the motivation behind them, and explore some of their consequences. Along the way we discuss how Carnap’s system violates R3.\n• In Section 8 we prove that R1–R4 are consistent.\n• Section 9 discusses three topics: the connection of our results to the classical definition of probability, the issue of non-uniform probabilities, and an initial attempt at extending our results to infinite domains."
    }, {
      "heading" : "2. Relation to Prior Work",
      "text" : "To set the context for this paper, clarify our goals, and head off possible misconceptions, we now review similar prior work and point out the differences."
    }, {
      "heading" : "2.1. Cox’s Theorem",
      "text" : "R. T. Cox [9] proposes a handful of intuitively-appealing, qualitative requirements for any system of plausible reasoning, and shows that these requirements imply that any such system is just probability theory in disguise. Specifically, he shows that there is an order isomorphism between plausibilities and the unit\ninterval [0, 1] such that A | X, after mapping from plausibilities to [0, 1], respects the laws of probability.\nOver the years Cox’s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox’s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox’s original proof. One version of the requirements [21] may be summarized as follows:\nC1. A | X is a real number.\nC2. A | X = A′ | X whenever A is logically equivalent to A′, and B | X ≤ A | X for any tautology A.\nC3. There exists a nonincreasing function S such that ¬A | X = S (A | X) for all A and satisfiable X.\nC4. The set of plausibility triples (y1, y2, y3) where y1 = A1 | X, y2 = A2 | A1∧X, and y3 = A3 | A2 ∧A1 ∧X for some A1, A2, A3, and X, is dense in [0, 1]3.\nC5. There exists a continuous function F : [f, t]2 → [f, t], strictly increasing in both arguments on (f, t]2, such that A ∧B | X = F (A | B ∧X, B | X) for any A, B, and satisfiable X. Here we use t , A | X for any tautology A, and f , S (t).\nThese requirements have not been without controversy. For example, Shafer [18] objects to C1, C3, and C5; Halpern [11, 12] questions C4; and Colyvan [8] objects to C2 on the basis that it presumes the law of the excluded middle.\nOur approach has no equivalent of C1, C3, C4, or C5:\n• We are agnostic as to the set of allowed plausibility values. We do not even require that plausibility values be totally ordered.\n• We have no requirement on how the plausibility ¬A decomposes.\n• We have no density requirement on plausibility values.\n• We have no requirement on how the plausibility of A∧B decomposes, much less any continuity or strictness requirements for such decompositions.\nWe do retain a variant of C2. Our goal is to extend the classical propositional logic; we make no attempt to address intuitionistic logic.\nOur requirements are all based on preserving in the extended logic some existing property of CPL. Three of these are invariances—ways in which A or X may be modified without altering A | X—and the last is a requirement to preserve those distinctions in degree of plausibility already present in CPL. We believe that such an approach leaves far less room for objections to the requirements.\nThe results we obtain are similar to those of Cox’s Theorem, with these differences:\n• We obtain an order isomorphism P between plausibility values and rational probability values.\n• We obtain specific numerical values for P (A | X), and not just the laws for decomposing P (A | X).\n• The conditioning information X is necessarily a propositional formula. (Some variants [7, 13, 21] of Cox’s Theorem allow X to be an undefined “state of information” to which we may add additional propositional information.)\n• Our results apply only to finite problem domains or finite approximations of infinite domains. (In Section 9.3 we discuss how to extend our results to infinite domains.)"
    }, {
      "heading" : "2.2. Clayton and Waddington: bridging the intution gap",
      "text" : "In a recent paper, Clayton and Waddington [7] seek to “bridge the intuition gap” in Cox’s Theorem by proposing alternative requirements they argue are more intuitively reasonable, and then proving C4 and the strictness of F in C5 as theorems. We find their most interesting and important contributions to be the following:\n• Rather than just tweaking Cox’s Theorem, they have instead created an entirely new proof of its result. The meat of the proof of Cox’s Theorem lies in deriving functional equations that F and S must satisfy, then solving those equations. But by the time they have “bridged the intuition gap” in the requirements, they already have most of the proof completed, without any need to solve functional equations.\n• Jaynes [13] argues that, if one’s background information is “indifferent” between two propositions, then they should be assigned equal plausibility. They formalize this idea as an invariance principle: if A′ | X ′ is obtained from A | X by consistently renaming all propositional symbols used via a one-to-one mapping, then the two plausibilities are equal.\n• Their proof yields the classical definition of probability—the ratio of the number of positive cases to the number of all possible cases—as a theorem in certain cases they call “N -urns.”\nHowever, the list of assumptions they use is fairly long: 11 altogether. We obtain similar results with fewer and simpler requirements, given in Sections 4–7. Here is a comparison:\n• Clayton and Waddington use a variant of C2 that replaces “A is logically equivalent to A′” with “A ∧X is logically equivalent to A′ ∧X”; this and their Assumption 2.1 are comparable to our R1 (replacement of premise or query with a logically equivalent formula).\n• Our R4 (preservation of the implication ordering) is a stronger (more general) version of their Assumption 2.7. We do not actually need this more general form—Lemma 13 only uses a restricted form that corresponds to their Assumption 2.7—but we feel that the rationale for the requirement is more clearly seen in this more general form.\n• Our R2 (invariance under definition of new propositional symbols) and R3 (invariance under addition of irrelevant information) have no direct equivalent among their assumptions, but are inspired by their discussion of the Principle of Indifference and their Assumption 2.3 (translation invariance).\n• We use no equivalent of C1 nor their Assumptions 1.2, 1.3, 1.4, 3.2, 3.3, and 3.5.\nFrom the above comparison one can see that it is the replacement of Assumption 2.3 with R2 and R3 that allows a drastic pruning of the assumptions used in obtaining the main results of their paper.\nOur approach was inspired by Clayton and Waddington’s notion of an “N - urn” and the results they prove for N -urns. Our most important innovation is Lemma 6 showing how to reduce every allowable query-premise pair to a certain kind of N -urn."
    }, {
      "heading" : "2.3. Carnap: logical probability",
      "text" : "Carnap [5] undertakes an extensive investigation of “logical probability.” He mentions two notions of probability: probability1 is epistemic probability1 (“the degree of confirmation of a hypothesis h with respect to an evidence statement e”), and probability2 is relative frequency. His focus is on probability1 and the problem of induction. Our terminology and his correspond roughly as follows:\n• Instead of a “plausibility function” Carnap discusses a “confirmation function” c.\n• The rough equivalent of A | X in Carnap’s system is c(A,X), with a crucial difference described below.\n• We call A and X the query and premise, respectively; he calls them the hypothesis and evidence.\nWe take A and X to be propositional formulas, whereas Carnap allows them to be sentences in a variant of first-order predicate logic in which the only allowed terms are variables and constant symbols. The domain of discourse is taken to be a countably infinite set of individuals, and for each individual there is a corresponding constant symbol. He calls this most general form of the language L∞.\n1Carnap later favored a decision-theoretic view of probability1 [5, Preface to the Second Edition].\nCarnap also considers restricted languages LN , N ≥ 1, in which only the first N constant symbols are allowed and the domain of discourse is only the first N individuals. Most of the focus is on the finite languages LN , with confirmation functions for L∞ defined via a limiting process on the sequence of languages LN , N ≥ 1. This is similar in spirit, though not in detail, to our approach to infinite domains.\nA difference between Carnap’s approach and ours is that we posit a single language and single set of propositional symbols S to be used for all problem domains, whereas in Carnap’s system each problem domain has its own language L∞ with its own set of predicate symbols and associated arities and interpretations.\nCarnap’s finite languages LN are equivalent to propositional languages with a finite number of propositional symbols. Let an atomic sentence be a formula of the form p (s1, . . . , sk) for some k-ary predicate symbol p and constant symbols s1, . . . , sk. There are a finite number of distinct atomic sentences in LN . Define the propositional language L′N to have as propositional symbols the atomic sentences of LN . We can transform any sentence A ∈ LN into an equivalent propositional formula A′ ∈ L′N :\n1. Remove all quantifiers by repeatedly replacing any occurrence of a subformula ∀xϕ(x) with the semantically equivalent finite conjunction ϕ (s1) ∧ · · · ∧ ϕ (sN ), where s1, . . . , sN are the constant symbols for the first N individuals.\n2. If equality is allowed, replace any subformula si = si with a logically valid sentence, and any subformula si = sj , i 6= j, with an unsatisfiable sentence. In both cases choose replacement sentences that contain no quantifiers nor use of equality. (Carnap specifies that distinct constant symbols are assumed to reference distinct individuals.)\nWe end up with propositional formulas in which the propositional symbols have internal structure, but this internal structure is of no consequence from the standpoint of deductive logic. To have logical effect, any intended meaning for this internal structure must be given by additional formulas in L′N , axioms that are added to the set of premises used. For example, suppose that we are deducing the logical consequences of a set of premises Γ, that we have a twoplace predicate lt, and that the intended meaning of lt(x, y) is that individual x precedes individuals y in some total ordering. Then we must add to Γ a set of axioms such as the following:\n∀x¬lt(x, x) ∀x∀y (lt(x, y) ∨ lt(y, x) ∨ x = y)\n∀x∀y ∀z (lt(x, y) ∧ lt(y, z)→ lt(x, z))\nMore precisely, we must add to Γ the result of transforming the above sentences of LN into equivalent propositional formulas of L′N .\nCarnap, however, is unwilling to axiomatize the intended interpretations of the predicate symbols in this way. He writes [5, p. 55],\nSince we intend to construct inductive logic as a theory of degree of confirmation, based upon the meanings of the sentences involved—in contradistinction to a mere calculus—we shall construct the language systems L with an interpretation, hence as a system of semantical rules, not as uninterpreted syntactical systems.\n(Emphasis added.) This is an important difference between Carnap’s system and ours, one that we discuss further in Section 3.4 and Section 9.2. Thus the equivalent of Carnap’s c(h, e) in our scheme is not h | e, but instead h | e ∧X, where X is a conjunction of\n• propositional axioms expressing the logical structure of the problem domain, and\n• propositional formulas expressing any other background information. Unlike Cox [9], Carnap makes no attempt to derive the laws of probability from more fundamental considerations; instead, his “conventions on adequacy” [5, p. 285] require that a valid confirmation function should conform to the laws of probability. He ensures this by proceeding as follows:\n1. A state description for LN amounts to a truth assignment on the set of atomic sentences of LN . 2. A regular measure function for LN amounts to a strictly positive probability mass function over the set of state descriptions for LN . 3. A regular confirmation function c for LN is then a confirmation function defined as\nc(h, e) = m(h ∧ e)/m(e) for some regular measure function m on LN .\n4. These notions are extended to L∞ by imposing a consistency condition on a sequence of regular measure functions mN on LN , N ≥ 1, considering the associated regular confirmation functions cN , and defining c∞(h, e) = limN→∞ cN (h, e).\nWe see therefore that, although it is the conditional probabilities c(h, e) that most interest Carnap, unconditional probabilities are for him more fundamental. In contrast, we take conditional plausibilities as the fundamental concept and, rather than imposing the laws of probability, seek to derive them.\nCarnap’s goal is that the confirmation function appropriate to a problem domain should be uniquely determined by the semantics of the language L∞, specifically, the intended interpretation of the predicate symbols and constant symbols. In this he fails. Limiting his attention to systems that contain monadic predicates (“properties”) only, he proposes a specific confirmation function c∗, but says [5, p. 563],\nNow the chief arguments in favor of the function c∗. . . will consist in showing that this function is free of the inadequacies in the other methods. It may then still be inadequate in other respects. It will not be claimed that c∗ is a perfectly adequate explicatum for probability1, let alone that it is the only adequate one. . .\nHe later [5, Preface to Second Edition][6] proposes instead an entire family of confirmation functions cλ parameterized by a positive number λ.\nIn contrast, we show in Theorem 14 that there is (up to isomorphism) a single, unique plausibility function satisfying our criteria. Ironically, it corresponds to the one confirmation function explicitly rejected by Carnap: a uniform distribution over the set of truth assignments satisfying the premise / evidence. We discuss this further in Section 9.2."
    }, {
      "heading" : "3. Logical Preliminaries",
      "text" : "In this section we review some concepts from CPL, introduce some additional logical concepts of our own, and discuss the nature of the plausibility function as extending the logical consequence relation |=."
    }, {
      "heading" : "3.1. Review of classical propositional logic",
      "text" : "A proposition is a statement or assertion that must be true or false; it is atomic if it cannot be decomposed into simpler assertions. A propositional symbol is one of a countably infinite set of symbols S that are used to represent atomic propositions. We abbreviate this to just “symbol” when the meaning is clear.\nIf S ⊆ S then a propositional formula on S is one of the following:\n• a propositional symbol from S;\n• a formula ¬A, meaning “not A”, for some propositional formula A on S; or\n• a formula A ∧ B, meaning “A and B,” where A and B are propositional formulas on S.\nThe other common logical operators—A∨B (or), A→ B (implies), and A↔ B (if and only if)—are defined in terms of ¬ and ∧ in the usual way. We abbreviate “propositional formula” as just “formula” when the meaning is clear.\nWe write Φ (S) for the set of all propositional formulas on S, and Φ+(S) for the satisfiable formulas.\nWe write σ JA1, . . . , AnK for the set of all propositional symbols occuring in any of the propositional formulas A1, . . . , An.\nA truth assignment on S is a function ρ : S → {0, 1}, with 0 and 1 standing for falsity and truth, respectively. We recursively extend it to all formulas on S in the obvious way:\nρ JAK = ρ(A) if A ∈ S ρ J¬AK = 1− ρ JAK\nρ JA ∧BK = ρ JAK · ρ JBK\nwhere ‘·’ is just integer multiplication.\nA truth assignment ρ on S satisfies a formula A on S if ρ JAK = 1. A formula A is satisfiable if there is some truth assignment ρ on σ JAK that satisfies A. A formula A is logically valid, written |= A, if every truth assignment on σ JAK satisfies A.\nWe say that B is a logical consequence of A, or A logically implies B, written A |= B, if every truth assignment on σ JA,BK that satisfies A also satisfies B. This captures the notion of a logically valid argument: conclusion B follows as a logical consequence of premises A1, . . . , An if A1 ∧ · · · ∧ An |= B. Note that A |= B if and only if |= A→ B.\nThe restriction of a truth assignment ρ on S to some S′ ⊆ S is the truth assignment ρ′ on S′ such that ρ′(s) = ρ(s) for every s ∈ S′.\nNote that ρ JAK depends only on the truth values assigned to those symbols that actually appear in A; if A is a formula on S′ ⊆ S, ρ is a truth assignment on S, and ρ′ is the restriction of ρ to S′, then ρ′ JAK = ρ JAK. Because of this, we have some leeway in choosing the set of propositional symbols to use in the definitions of “logically valid,” “satisfiable,” and “logical consequence.” If σ JAK ⊆ SA and σ JA,BK ⊆ SAB , then • A is logically valid iff every truth assignment on SA satisfies A.\n• A is satisfiable iff some truth assignment on SA satisfies A.\n• A |= B iff every truth assignment on SAB that satisfies A also satisfies B.\nSome notation.\n• Two formulas are logically equivalent, written A ≡ B, if |= A↔ B.\n• A and B are logically equivalent assuming X, written A ≡X B, if X |= A↔ B.\n• We will use finite quantification as an abbreviation where convenient, for example writing ∧n i=1Ai for A1 ∧ · · · ∧An.\n• If we write A1 ∧ · · · ∧ An and n = 0, we understand this to mean some logically valid formula such as s ∨ ¬s.\n• If we write A1 ∨ · · · ∨ An and n = 0, we understand this to mean some unsatisfiable formula such as s ∧ ¬s."
    }, {
      "heading" : "3.2. Finite sample spaces",
      "text" : "The development of probability theory usually begins with the idea of a sample space, which has been downplayed so far—the focus has been on propositions. We find in Theorem 14 that A | X can be characterized in terms of an induced sample space: the set of truth assignments that satisfy X.2 In particular, we find that A | X is a function of the proportion of points from this induced sample space that satisfy A. This motivates the following:\n2This is similar to Carnap’s system, in which the set of state descriptions serve as a sample space.\nDefinition 1. #S(X) is the number of truth assignments on S satisfying X, for any formula X and finite S such that σ JXK ⊆ S ⊆ S.\nThe size of the induced sample space is #S(X), and the proportion of points from the induced sample space that satisfy A is #S (A ∧X) /#S(X), for S ⊇ σJA,XK.\nTypically one thinks of a finite sample space as an arbitrary set of n > 0 distinct values Ω = {ω1, . . . , ωn} representing different possible states of some system under consideration. We can relate this to our notion of an induced sample space by choosing a set of n propositional symbols S = {s1, . . . , sn}, with the intended interpretation of si being that the state of the system is ωi. If our premise X is a formula expressing that exactly one of the si is true, then there is a one-to-one correspondence between our original sample space Ω and the induced sample space of truth assignments, with ωi corresponding to the single truth assignment ρ on S satisfying si ∧X. This motivates the following:\nDefinition 2. Given any sequence of n > 0 propositional symbols s1, . . . , sn, 〈s1, . . . , sn〉 = (s1 ∨ · · · ∨ sn) ∧ ∧\n1≤i<j≤n\n¬ (si ∧ sj) ;\nthat is, 〈s1, . . . , sn〉 means that exactly one of the si is true."
    }, {
      "heading" : "3.3. The implication ordering",
      "text" : "At first blush it would seem that CPL tells us very little about the relative plausibilities of different propositions, beyond determining which are certainly true and which are certainly false given a premise X. The reality is quite the opposite: CPL comes equipped with a rich inherent plausibility ordering that we call the implication ordering.\nDefinition 3. Let A,B,X ∈ Φ (S) with X satisfiable. We define\n(A XB) ⇔ (X |= A→ B) (A ≺XB) ⇔ (A XB) and not (B XA) .\nThe following properties are easily verified:\n• The relation X is a preorder: it is reflexive and transitive, but not antisymmetric.\n• A ≺XB is the same as (A XB and not A ≡XB).\n• A ≡XB if and only A XB and B XA.\n• If A ≡XA′ and B ≡XB′ and A XB then A′ XB′.\nHence X defines a partial order on the equivalence classes of propositional formulas under the relation ≡X. This partial order is essentially just the subset ordering on truth assignments:\nProperty. Let A1, A2, X ∈ Φ (S) with X satisfiable. Then A1 X A2 if and only if α JA1K ⊆ α JA2K, where α JAK is the set of truth assignments on S that satisfy both A and X.\nAssuming X, we therefore conclude the following:\n• If A X B then B is at least as plausible as A, since B is true for any possible world (truth assignment satisfying X) for which A is true.\n• If A ≡X B then A XB and B XA, hence A and B are equally plausible.\n• If A ≺XB then B is strictly more plausible than A, since there are possible worlds for which B is true and A is not, but not vice versa.\nConsider an example that uses three propositional symbols s1, s2, s3 with X defined to be the formula stating that exactly one of these three is true: X = 〈s1, s2, s3〉. Let F be any unsatisfiable formula and T be any logically valid formula. Then\nF ≺X s1 ≺X (s1 ∨ s2) ≺X (s1 ∨ s2 ∨ s3) ≡X T.\nNote that adding additional information to the premise yields additional formulas A → B as logical consequences, and hence may collapse previously distinct plausibilities. Continuing the example, if we add additional information to X to obtain Y = X ∧ ¬s2, then\nF ≺Y s1 ≡Y (s1 ∨ s2) ≺Y (s1 ∨ s2 ∨ s3) ≡Y T."
    }, {
      "heading" : "3.4. The plausibility function",
      "text" : "We extend CPL to Jaynes’s “logic of plausible reasoning” by introducing a plausibility function (· | ·) whose domain is Φ (S) × Φ+ (S). Think of (· | ·) as extending the logical consequence relation: whereas X |= A means that A is known true (given X), and X |= ¬A means that A is known false, it may be that neither of these relations hold; (· | ·) fills in the gaps, so to speak, by assigning intermediate plausibilities in such a case.\nThe logical consequence relation, as we have defined it, takes only a single premise X on the left-hand side, rather than a set of premises X . The compactness theorem for CPL says that if A is a logical consequence of a set of premises X , then it is a logical consequence of a finite subset of X [14, p. 16]; but any finite set of premises X1, . . . , Xn can be combined into a single premise X = X1 ∧ · · · ∧Xn. Likewise, the plausibility function (· | ·) takes only a single premise as its second argument.\nWe write P for the range of the plausibility function, but leave it otherwise unspecified:\nDefinition 4. P is the set of achievable and meaningful plausibility values; that is,\nP = {(A | X) : A,X ∈ Φ (S) and X is satisfiable} .\nThere has been much unnecessary controversy over Cox’s Theorem due to differing implicit assumptions as to the nature of its plausibility function. Halpern [11, 12] claims to demonstrate a counterexample to Cox’s Theorem by examining a finite problem domain, but his argument presumes that there is a different plausibility function for every problem domain. Others [9, 16] seem to presume a single plausibility function, but with domain-specific information serving as an implicit extra argument3. A third interpretation [7, 13, 21] presumes a single plausibility function with all relevant information about the problem domain encapsulated in the second argument, the “state of information.”\nWe follow this third interpretation, with the premise—a propositional formula—serving as the state of information:\n• In CPL there is only a single logical consequence relation |=, defined on Φ (S), rather than entirely different logical consequence relations for each problem domain. In our extended logic there is likewise only a single plausibility function, defined on Φ (S)×Φ+ (S), and a single set of plausibility values P that are used for all problem domains.\n• In CPL any information about the problem domain that we wish to use for deduction must be included in the premise(s) to the logical consequence relation. Likewise in our extended logic, all relevant background information about the problem domain must be included in the premise to the plausibility function.\nThink of the plausibility function as something one could implement as a pure function in some programming language, taking as input two strings matching the grammar for propositional formulas (or their corresponding parse trees), and having access to no other source of information about the problem domain.\nNote that we use the same set of propositional symbols S for all problem domains, rather than having a different set of propositional symbols for each problem domain. The latter option would make the set of allowed propositional symbols an implicit extra argument to the plausibility function. The set of symbols S is countably infinite to allow modeling arbitrarily complex problem domains.\nAs an example of incorporating background information into the premise, suppose that we wish to discuss the outcome of rolling a six-sided die, and our background knowledge is simply the list of distinct possible outcomes. Let symbols si, 1 ≤ i ≤ 6, have the intended interpretation that the outcome is i. The formula 〈s1, . . . , s6〉 expresses our background knowledge, and so\ns2 | 〈s1, . . . , s6〉\n3Strictly speaking, this also amounts to a different plausibility function for every problem domain, but the practical difference is that certain structural properties of the plausibility function, such as its range and the choice of the functions F and S, remain the same across problem domains.\nis the plausibility of rolling a 2, and\ns1 ∨ s2 | (s1 ∨ s3 ∨ s5) ∧ 〈s1, . . . , s6〉\nis the plausibility of rolling a 1 or 2 given that the outcome is odd. This stands in stark contrast to Carnap, who as previously mentioned rejects such an axiomatic approach. The second argument to his confirmation function is the evidence, which is “an observational report” that “refer[s] to facts” [5, pp. 19–20]; background knowledge about the meaning of the symbols and logical structure of the domain is excluded. Given a situation like our die roll, in which there is a “family of related properties,” exactly one of which holds true for each individual, Carnap goes so far as to require modifying the definition of a fundamental concept in his system, the state-description, rather than simply including this information in the evidence [5, p. 77]."
    }, {
      "heading" : "4. Invariance from Logical Equivalence",
      "text" : "In this and the following sections we introduce our Requirements on the plausibility function and prove their consequences. These are all based on preserving existing properties of CPL. We shall consider properties of the logical consequence relation |=, as well as the implication ordering X for a given premise X.\nThe first property we consider is invariance under replacement of premise or query by a logically equivalent formula.\nThe logical consequence relation |= is invariant to replacement of premise by a logically equivalent formula: if X ≡ Y then for all formulas A we have X |= A if and only if Y |= A. We require that the plausibility function exhibit this same invariance. This may be further justified by noting that the implication orderings X and Y are identical when X ≡ Y .\nThe relation |= is also invariant to replacement of conclusion by a logically equivalent formula. In fact, the replacement formula need only be logically equivalent assuming the premise: if A ≡XB, then X |= A if and only if X |= B. We require that the plausibility function exhibit this invariance also, for the query. This may be further justified by our argument in Section 3.3 that we should consider A and B equally plausible, assuming X, whenever A ≡XB.\nWe combine these into a single requirement:\nR1. If X ≡ Y and A ≡X B then A | X = B | Y ."
    }, {
      "heading" : "5. Invariance under Definition of New Symbols",
      "text" : "It is common in mathematical proofs to define new symbols as abbreviations for complex expressions or formulas. The same may be done in propositional logic: we may introduce a new propositional symbol s (that appears in neither the premises nor conclusion) and use it as an abbreviation for some complex propositional formula E, by adding the definition s↔ E to our premises. This\ndoes not invalidate any logical consequence we already had, nor any create any new logical consequence that does not mention s.\nSpecifically, let s be a symbol not occurring in X, E, or A, and define Y = (s↔ E) ∧X . Then X |= A if and only if Y |= A, and consequently, X and Y are identical on Φ (S \\ {s}). We require that the plausibility function exhibit the same invariance:\nR2. Let s ∈ S but s /∈ σ JA,X,EK. Then A | X = A | (s↔ E) ∧X.\nOne cannot evade the force of this Requirement by supposing a problem domain with a limited set of symbols. Recall that there is only one plausibility function, used for all problem domains, and that S is countably infinite. Furthermore, even if the plausibility function were to take as a third argument a finite set of symbols from which the query and premise are constructed, the notion of extending a domain by defining an additional variable as a function of existing variables would still make sense. Forbidding such extension would be an artificial and unreasonable restriction, as one can already do this in CPL."
    }, {
      "heading" : "5.1. Invariance under renaming",
      "text" : "To build some intuition for R2 we now explore some of its more straightforward consequences, in conjunction with R1 (logical equivalence). Let us write B [s/C] for the result of replacing every occurrence of symbol s in formula B with the formula C. If s and t are distinct symbols, with t not occurring in formulas A or X, then using R2 to introduce a definition and later remove a different one gives us\nA | X = A | (t↔ s) ∧X = A[s/t] | (t↔ s) ∧X[s/t] = A[s/t] | (s↔ t) ∧X[s/t] = A[s/t] | X[s/t].\nThat is, we can rename any single symbol, replacing it throughout A and X with a new symbol, and this leaves the plausibility unchanged.\nRepeating the process, the plausibility is invariant if we rename any set of symbols S = {s1, . . . , sn} to new symbols T = {t1, . . . , tn} not occurring in A or X. We can also permute the symbol names, by renaming from s1, . . . , sn to t1, . . . , tn and then to a permuation s′1, . . . , s′n of s1, . . . , sn. That is, if we write B [s1/C1, . . . , sn/Cn] for the formula obtained by simultaneously replacing each symbol si with the formula Ci, we have\nA | X = A [s1/s′1, . . . , sn/s′n] | X [s1/s′1, . . . , sn/s′n] .\nThis result is the same as Clayton & Waddington’s Assumption 2.3 (translation invariance) [7], which they motivate via Jaynes’s “indifference” criterion [13, p. 19]:\nThe robot always represents equivalent states of knowledge by equivalent plausibility assignments. That is, if in two problems the robot’s state of knowledge is the same (except perhaps for the labeling of the propositions), then it must assign the same plausibilities in both.\nFor example, if a, b, c, d are distinct symbols, then the following equalities hold:\na | a ∨ b = c | c ∨ d a | a→ b = b | b→ a\nConsider specifically the case where X treats symbols s and t symmetrically: that is, X is logically equivalent to X ′ = X[s/t, t/s]. One example would be\nX = (s ∨ t) ∧ ¬ (s ∧ t) X ′ = (t ∨ s) ∧ ¬ (t ∧ s) .\nIn this case we find that s and t must be equally plausible:\ns | X = t | X ′ = t | X.\nThis result is similar in spirit to the principle of insufficient reason: our premise X provides no information that differs between s and t, so intuition suggests these propositions should be equally plausible. The result is more general, however, in that s and t need not be mutually exclusive nor exhaustive.\nAnother transformation we can consider is that of replacing all occurrences of symbol s with ¬s in both premise and query. As before, let s and t be distinct symbols, with t not occurring in formulas A nor X. Again we use R2 to introduce a definition and later remove a different one; we also add a final step that invokes the above-demonstrated invariance under renaming. This yields the following:\nA | X = A | (t↔ ¬s) ∧X = A[s/¬¬s] | (t↔ ¬s) ∧X[s/¬¬s] = A[s/¬t] | (t↔ ¬s) ∧X[s/¬t] = A[s/¬t] | (s↔ ¬t) ∧X[s/¬t] = A[s/¬t] | X[s/¬t] = A[s/¬t][t/s] | X[s/¬t][t/s] = A[s/¬s] | X[s/¬s].\nThat is, the plausibility is invariant to a transformation in which we uniformly replace any single symbol with its negation throughout both A and X. In particular, if X is logically equivalent to X[s/¬s], then\ns | X = ¬s | X.\nThis result may be viewed as an instance of the principle of insufficient reason applied to the case of two indistinguishable possibilities.\nTake note of the common pattern in the above two derivations:\n1. Use R2 to introduce a definition of some symbol t in terms of symbol s appearing in the premise or query.\n2. Use logical equivalence and the definition of t to rewrite premise and query in a way that removes all occurrences of s except its occurrence in the right-hand side of the definition of t.\n3. Use logical equivalence to rewrite the definition of t in terms of s as a definition of s in terms of t.\n4. Use R2 to drop the definition of s, as this symbol is now used nowhere else in the premise or query.\nLemma 6 in Section 5.3 extends this pattern to sets of symbols, simultaneously introducing multiple definitions in step 1, and this yields a stronger form of transformation invariance that subsumes the results derived here."
    }, {
      "heading" : "5.2. Invariance under change of variables",
      "text" : "Renaming symbols and swapping s for ¬s throughout both premise and query are special cases of more general change of variables transformations. As an example of this, suppose that we are considering a problem domain in which there is some quantity x that can take on any of n discrete, ordered values v1 < v2 < · · · < vn. There are two different vocabularies we might use for this domain:\n1. Use symbols s1, . . . , sn with the intended meaning of si being “x = vi,” and express “x ≤ vi” as s1 ∨ · · · ∨ si. 2. Use symbols t1, . . . , tn with the intended meaning of ti being “x ≤ vi,” and express “x = vi” as ti ∧ ¬ti−1 when i > 1, or just ti when i = 1.\nThe two vocabularies can express exactly the same propositions, so there is no fundamental reason to choose one over the other, and it seems that the plausibility A | X should not depend on which vocabulary we use. Going from one vocabulary to the other is just a change of variables: we can express each of the si in terms of t1, . . . , tn, or we can express each of the ti in terms of s1, . . . , sn.\nThis isn’t quite enough, though. Defining\nτst(A) = A [s1 / t1, s2 / t2 ∧ ¬t1, . . . , sn / tn ∧ ¬tn−1] τts(B) = B [t1 / s1, t2 / s1 ∨ s2, . . . , tn / s1 ∨ · · · ∨ sn]\nwe want τst and τts to be inverses of each other (up to logical equivalence). We find that τts (τst (A)) is logically equivalent to A, but\nτst (τts (B)) ≡ B [t1 / t1, t2 / t1 ∨ t2, . . . , tn / t1 ∨ · · · ∨ tn]\nwhich is not, in general, logically equivalent to B. We need to assume that ti → ti+1 for 1 ≤ i < n to get the desired equivalence. Such an assumption concords with the intended meaning of ti, and must be implied by the premise when vocabulary 2 is used. (Likewise, the premise must imply 〈s1, . . . , sn〉 when\nvocabulary 1 is used.) So this notion of change of variables is more subtle than it appears at first glance; how do we define a general rule that accounts for issues like this?\nThe solution is to define a change of variables in terms of a bijection between\n• the set of truth assignments satisfying the premise when vocabulary 1 is used, and\n• the set of truth assignments satisfying the premise when vocabulary 2 is used.\nThis motivates the following:\nDefinition 5. f is a change-of-variables transformation between the pairs (A,X) and (A′, X ′) if it is a bijection between\n• the set of truth assignments on some S ⊇ σ JA,XK satisfying X, and\n• the set of truth assignments on some S′ ⊇ σ JA′, X ′K satisfying X ′,\nwith the additional property that any truth assignment ρ on S satisfies A ∧X if and only if f(ρ) satisfies A′ ∧X ′.\nNote that the logical consequence relation trivially satisfies invariance under change of variables:\nX |= A⇔ X ′ |= A′ if there exists a change-of-variables transformation f between (A,X) and (A′, X ′).\nFor the plausibility function, invariance under change of variables means the following:\nA | X = A′ | X ′ if there exists a change-of-variables transformation f between (A,X) and (A′, X ′).\nInvariance under definition of new symbols is a special case of invariance under change of variables: we have A′ = A, X ′ = (s↔ E) ∧ X, S = σ JA,X,EK, S′ = S ∪ {s}, and f(ρ) = ρ′ where\nρ′(s) = ρ JEK ρ′(t) = ρ(t) if t ∈ S.\nThe inverse of f maps ρ′ to the restriction of ρ′ to S. We show in Corollary 9 that R1 and R2 together imply invariance under change of variables. So, given R1, invariance under change of variables and invariance under definition of new symbols are equivalent. We chose the latter as our requirement because it is easier to explain and justify."
    }, {
      "heading" : "5.3. Reduction to canonical form",
      "text" : "We take the first step towards our main result by showing that we can reduce every query-premise pair to a canonical form in which the premise merely states that we have a sample space of n distinct possibilities, and the query merely states that one of the first m ≤ n possibilities is true. In the following, keep in mind our convention that A1 ∨ · · · ∨ Am stands for some unsatisfiable formula when m = 0.\nLemma 6. Let S ⊆ S be finite, A ∈ Φ (S), and X ∈ Φ+(S). Then R1 and R2 together imply that\nA | X = (t1 ∨ · · · ∨ tm | 〈t1, . . . , tn〉)\nwhere n = #S(X) > 0, m = #S (A ∧X) ≤ n, and T = {t1, . . . , tn} is any set of n propositional symbols disjoint from S.\nProof. Let ρ1, . . . , ρn be the truth assignments on S that satisfy X, ordered so that the first m also satisfy A. Enumerate the elements of S as s1, . . . , sp. The proof proceeds in four steps.\nStep 1. For each 1 ≤ i ≤ n and 1 ≤ j ≤ p define\nZi = Li,1 ∧ · · · ∧ Li,p\nLi,j = { sj if ρi (sj) = 1 ¬sj if ρi (sj) = 0.\nNote that ρi is the one and only truth assignment on S that satisfies Zi. Define the formulas\nDt,i = ti ↔ Zi Dt = Dt,1 ∧ · · · ∧Dt,n.\nThen by R2, A | X = A | Dt ∧X. (5.1)\nStep 2. The formulas Zi were constructed such that\nA ∧X ≡ Z1 ∨ · · · ∨ Zm\nand hence Dt ∧X |= (A↔ Z1 ∨ · · · ∨ Zm) .\nR1 then gives A | Dt ∧X = (t1 ∨ · · · ∨ tm | Dt ∧X) . (5.2)\nStep 3. Define the following:\nIj = {i : 1 ≤ i ≤ n, ρi (sj) = 1} Ds,j = sj ↔ ∨ i∈Ij ti\nDs = Ds,1 ∧ · · · ∧Ds,p.\nConsider how to construct the set of truth assignments ρ̃ on S ∪ T that satisfy both 〈t1, . . . , tn〉 and Ds:\n1. Choose any i ∈ {1, . . . , n}. 2. Set ρ̃ (ti) = 1 and ρ̃ (th) = 0 for h 6= i. 3. For j ∈ {1, . . . , p}, set ρ̃ (sj) to the unique value required to satisfy Ds,j ;\nthis value is 1 iff i ∈ Ij , and i ∈ Ij iff ρi (sj) = 1, so the required value is just ρi (sj).\n1 and 2 construct all the ways of ensuring that 〈t1, . . . , tn〉 is satisfied, and 3 then is the only way to finish defining ρ̃ that satisfies Ds.\nSimilarly, consider how to construct the set of truth assignments ρ̃ on S ∪ T that satisfy both X and Dt:\n1. Choose any i ∈ {1, . . . , n}. Recall that ρi is one of the truth assignments satisfying X. 2. For j ∈ {1, . . . , p}, set ρ̃ (sj) = ρi (sj). 3. For h ∈ {1, . . . , n}, set ρ̃ (th) to the unique value required to satisfy Dt,h.\nThis is just ρi JZhK, which is 1 for h = i and 0 for h 6= i. 1 and 2 construct all the ways of ensuring that X is satisfied, and 3 then is the only way to finish defining ρ̃ that satisfies Dt.\nBut these two sets of truth assignments are the same set! Therefore\nDs ∧ 〈t1, . . . , tn〉 ≡ Dt ∧X\nand so, by R1,\n(t1 ∨ · · · ∨ tm | Dt ∧X) = (t1 ∨ · · · ∨ tm | Ds ∧ 〈t1, . . . , tn〉) . (5.3)\nStep 4. Using R2 we have\n(t1 ∨ · · · ∨ tm | Ds ∧ 〈t1, . . . , tn〉) = (t1 ∨ · · · ∨ tm | 〈t1, . . . , tn〉) (5.4)\nsince the symbols s1, . . . , sp appear only on the left-hand-sides of the definitions in Ds.\nCombining (5.1)–(5.4) yields the theorem."
    }, {
      "heading" : "5.4. Additional consequences",
      "text" : "In light of Lemma 6 we define the following:\nDefinition 7. For any n > 0 and 0 ≤ m ≤ n,\nΥ2 (m,n) = (s1 ∨ · · · ∨ sm | 〈s1, . . . , sn〉) ,\nwhere s1, . . . , sn ∈ S are n distinct propositional symbols.\nWe may then restate Lemma 6 as follows:\nCorollary 8. Let A ∈ Φ (S) and X ∈ Φ+ (S) for some finite S ⊆ S. Then R1 and R2 together imply that\nA | X = Υ2 (#S (A ∧X) ,#S (X)) .\nProof. Let m = #S (A ∧X) and n = #S (X) > 0. Choose any n symbols t1, . . . , tn ∈ S disjoint from both σ JA,XK and the set of symbols {s1, . . . , sn} in the definition of Υ2. Then two applications of Lemma 6 yields\nA | X = (t1 ∨ · · · ∨ tm | 〈t1, . . . , tn〉) = (s1 ∨ · · · ∨ sm | 〈s1, . . . , sn〉) = Υ2(m,n).\nWe also obtain invariance under change of variables as an immediate consequence:\nCorollary 9. Let f be a change-of-variables transformation between (A,X) and (A′, X ′). Then R1 and R2 together imply that\nA′ | X ′ = A | X.\nProof. Let f map from truth assignments on S ⊇ σ JA,XK to truth assignments on S′ ⊇ σ JA′, X ′K. Then #S (X) = #S′ (X ′) and #S (A ∧X) = #S′ (A′ ∧X ′); the result then follows from Corollary 8."
    }, {
      "heading" : "6. Invariance under Addition of Irrelevant Information",
      "text" : "Suppose we are interested in a problem domain whose concepts are represented by the propositional symbols in some set S. A formula Y containing no symbol from S tells us nothing about this domain; it is irrelevant information. Adding Y to the premise does not allow us to draw any new conclusions involving only symbols in S.\nSpecifically, let Y be a satisfiable formula having no symbols in common with X or A, and define Z = Y ∧X. Then X |= A if and only if Z |= A, and consequently the implication orderings X and Z are identical on Φ (S \\ σ JY K). We require the plausibility function to be invariant in the same way:\nR3. Let Y be a satisfiable formula with σ JX,AK ∩ σ JY K = ∅. Then A | X = A | Y ∧X.\nAgain, one cannot evade the force of this Requirement by supposing a problem domain with a limited set of symbols, as discussed for R2. Furthermore, even if we were to associate a finite set of allowable symbols with each different problem domain, the notion of combining two unrelated problem domains into one would still make sense. Forbidding such a combining operation would be an artificial and unreasonable restriction, as one can already do this in CPL."
    }, {
      "heading" : "6.1. Independence",
      "text" : "The Requirements so far do not force A | X to be any sort of conditional probability; but if A | X is the conditional probability of A given X for some probability distribution, R3 implies that we don’t come pre-supplied with dependencies between the atomic propositions. Any such dependencies have to be created by information in X. This is in line with our intention that the plausibility function be universal, one single function used in all problem domains, computed using no source of information other than the query and premise themselves, with any information needed to distinguish different problem domains required to be included in the premise.\nCarnap’s proposed confirmation function c∗ in particular violates R3, as it imposes a probabilistic dependency between any two atomic sentences having the same predicate and the same number of distinct arguments. In particular, it is a violation of R3 that, for distinct individual constants a1, . . . , ak+1 and monadic predicate π, we have\nc∗ (π (ak+1)) = 1\n2\nbut c∗ (π (ak+1) | π (a1) ∧ · · · ∧ π (ak)) ≈ 1 for large k.\nCarnap finds it necessary to introduce this dependency between atomic sentences to allow induction, but as we will show in Section 9.2, the problem arises only because he omits background information from the premise / evidence. Once the necessary background information is included in the premise there is no longer a violation of R3."
    }, {
      "heading" : "6.2. Scale invariance of Υ2",
      "text" : "Suppose that S = σ JA,XK and T is obtained from S by adding r symbols not found in S. Then #T (X) = 2r ·#S(X) and #T (A ∧X) = 2r ·#S (A ∧X), from which we conclude that Υ2 (2rm, 2rn) = Υ2(m,n). Adding R3 allows us to extend this scale invariance to multipliers k that are not powers of 2, and hence to show that A | X is a function only of the ratio of #S (A ∧X) to #S(X).\nLemma 10. Suppose that R1, R2, and R3 hold. Then for every n, k > 0 and 0 ≤ m ≤ n,\nΥ2 (km, kn) = Υ2 (m,n) .\nProof. Let S1 = {s11, . . . , s1n} and S2 = {s21, . . . , s2k} be two disjoint sets of propositional symbols. There are kn truth assignments on S1 ∪ S2 satisfying both 〈s21, . . . , s2k〉 and 〈s11, . . . , s1n〉, and km of these truth assignments also satisfy s11 ∨ · · · ∨ s1m. Then\nΥ2 (m,n) = (s11 ∨ · · · ∨ s1m | 〈s11, . . . , s1n〉) = (s11 ∨ · · · ∨ s1m | 〈s21, . . . , s2k〉 ∧ 〈s11, . . . , s1n〉) = Υ2 (km, kn) .\nThe first and third equalities follows from Corollary 8. The second equality follows from R3, invariance under addition of irrelevant information.\nDefinition 11. For any n > 0 and 0 ≤ m ≤ n,\nΥ1 (m n ) = Υ2 (m,n) .\nLemma 10 ensures that Υ1 (r) is uniquely defined for any rational r in the unit interval when the appropriate Requirements hold. We then obtain the following:\nCorollary 12. Let S ⊆ S be finite, A ∈ Φ (S), and X ∈ Φ+(S). Then R1, R2, and R3 together imply that\nA | X = Υ1 (\n#S (A ∧X) #S (X)\n) .\nProof. Let m = #S (A ∧X) and n = #S (X). From Corollary 8 and Lemma 10 we get\nA | X = Υ2 (m,n) = Υ1 (m/n) ."
    }, {
      "heading" : "7. Preservation of Existing Distinctions in Degree of Plausibility",
      "text" : "Our final requirement is that the plausibility function be consistent with the implication ordering for the premise. Strictly more plausible queries, according to the implication ordering, must yield strictly greater plausibility values.\nR4. There is a partial order ≤P on P such that, for any satisfiable formula X, if A ≺XB then A | X <P B | X.\nAs usual, we understand p1 <P p2 to mean p1 ≤P p2 and p1 6= p2. The previous Requirements all have the effect of collapsing together what might otherwise be distinct plausibilities, but say nothing about when plausibilities must remain distinct from each other. They do not even rule out the possibility that all plausibilities collapse down to a single value. Adding R4 prevents any further collapse of plausibility values beyond that of Corollary 12, as we prove with Lemma 13 below."
    }, {
      "heading" : "7.1. A too-simple plausibility function",
      "text" : "Suppose that we choose the plausibility function to be a direct translation of the logical consequence relation, defining\nA | X =  F if X |= ¬A T if X |= A u otherwise\nwith P = {F, u,T} and F <P u <P T. It is straightforward to verify that this definition satisfies R1, R2, and R3, by appealing to the corresponding properties of the logical equivalence relation |=. However, this definition violates R4, since R4 implies that P must be infinite.\nTo see this, suppose that P is finite. Choose n > |P| distinct symbols s1, . . . , sn and define\nX = n−1∧ i=1 (si → si+1) .\nThen s1 ≺X s2 ≺X · · · ≺X sn\nand R4 therefore mandates that\ns1 | X < s2 | X < · · · < sn | X;\nbut this cannot be, as P contains fewer than n elements."
    }, {
      "heading" : "7.2. Probability from plausibility",
      "text" : "We proceed with the proof of our main result, starting with a lemma.\nLemma 13. If R1–R4 hold then for all r, r′ ∈ Q01 , Q ∩ [0, 1] we have\nΥ1 (r) = Υ1 (r ′)⇔ r = r′ Υ1 (r) <P Υ (r ′)⇔ r < r′.\nProof. We may express r and r′ as ratios with a common denominator n > 0 as r = m/n and r′ = m′/n. Using R4 and writing X for 〈s1, . . . , sn〉 we have\nr < r′ ⇒ m < m′\n⇒ (s1 ∨ · · · ∨ sm) ≺X (s1 ∨ · · · ∨ sm′) ⇒ Υ1(r) <P Υ1(r′). (7.1)\nFurthermore, using antisymmetry of the partial order ≤P and (7.1),\nr 6< r′ ⇒ (r = r′) ∨ (r′ < r) ⇒ Υ1 (r′) ≤P Υ1 (r) ⇒ Υ1 (r) 6<P Υ1 (r′) .\nTrivially, r = r′ ⇒ Υ1 (r) = Υ1 (r′) .\nFurthermore, using (7.1) again,\nr 6= r′ ⇒ (r < r′) ∨ (r′ < r) ⇒ Υ1 (r) 6= Υ1 (r′) .\nAnd now we arrive at the central result of this paper.\nTheorem 14. If R1–R4 hold then\n1. Υ1 is an order isomorphism between the posets (Q01,≤) and (P,≤P); 2. for all finite S ⊆ S, A ∈ Φ(S), and X ∈ Φ+(S) we have\nP (A | X) = #S (A ∧X) #S(X) .\nwhere P = Υ−11 .\nProof. By Corollary 12, Υ1 : Q01 → P is onto, and by Lemma 13, Υ1 is a strictly increasing function (hence also one-to-one). So Υ1 is an order-preserving bijection between Q01 and P, that is, it is an order isomorphism.\nSince Υ1 is a bijection, its inverse P exists. The second claim is then just a restatement of Corollary 12.\nThe laws of probability follow directly from Theorem 14. In stating them it is convenient to extend the plausibility function to unsatisfiable premises using the convention that A | X = Υ1(1), and hence P (A | X) = 1, when X is unsatisfiable. This may be justified by noting that for satisfiable X we have P (A | X) = 1 whenever X |= A, and when X is unsatisfiable we have X |= A for all formulas A.\nCorollary 15. If R1–R4 hold and we define A | X = Υ1(1) for unsatisfiable X, then\n1. 0 ≤ P (A | X) ≤ 1. 2. P (A | X) = 1 if X |= A. 3. P (A | X) = 0 if X |= ¬A and X is satisfiable. 4. P (¬A | X) = 1− P (A | X) if X is satisfiable. 5. P (A ∧B | X) = P (B | X) · P (A | B ∧X).\nProof. (1)–(4) are trivial, but (5) merits comment because care must be taken in handling unsatisfiable premises. There are three cases:\n1. If X is unsatisfiable then so is B ∧X, and the claim reduces to 1 = 1 · 1. 2. If X is satisfiable but B ∧X is not then X logically implies both ¬B and ¬ (A ∧B), so P (B | X) = 0 and P (A ∧B | X) = 0 and P (A | B ∧X) = 1, and the claim reduces to 0 = 0 · 1. 3. If X and B ∧X are both satisfiable, let S = σ JA,B,XK, n = #S(X) > 0, p = #S (B ∧X) > 0, and m = #S (A ∧B ∧X); then\nP (A ∧B | X) = m n = p n · m p = P (B | X) · P (A | B ∧X) .\nTheorem 14 and Corollary 15 tell us that plausibilities are essentially just probabilities, following the classical definition of probability as the ratio of favorable cases to all cases. That is, our four Requirements, based entirely on preserving existing properties of CPL, lead us to identify finite-set probability theory as the uniquely determined extension of CPL to a logic of plausible reasoning."
    }, {
      "heading" : "8. Consistency of Requirements",
      "text" : "An issue that must be addressed for any axiomatic development is whether its content is vacuous by virtue of there not existing any mathematical structure satisfying the given axioms. If our Requirements are inconsistent—if there does not exist any plausibility function (· | ·) for which the Requirements all hold—then Theorem 14 is trivially true, and our entire exercise is pointless. We now show that this is not the case, by exhibiting a specific plausibility function that satisfies all the Requirements.\nTheorem 14 provides an obvious candidate for this plausibility function. However, that theorem (and the results leading up to it) cannot help in proving that the Requirements can be satisfied, as they are consequences of assuming that one already has some plausibility function satisfying the Requirements.\nTheorem 16. R1–R4 are consistent. In particular, suppose that for any formula A and satisfiable formula X we define\nA | X = #T (A ∧X) #T (X) ,\nwhere T = σ JA,XK; then R1–R4 all hold. Proof. Consider any finite set of symbols S ⊇ T . If S contains k additional symbols beyond those in T then #S(X) = 2k#T (X) and #S (A ∧X) = 2k#T (A ∧X), hence\nA | X = #S (A ∧X) #S (X) .\nThus we may use any superset of the symbols appearing in A and X when evaluating A | X.\nWe now consider each of the Requirements in turn. R1. LetX ≡ Y and A ≡XB and S = σ JA,B,X, Y K. Then #S(X) = #S(Y ) and #S (A ∧X) = #S (B ∧X) = #S (B ∧ Y ), hence A | X = B | Y . R2. Let Y be (s↔ E) ∧ X, where s is a propositional symbol not in S = σ JA,X,EK. Let S′ = S ∪{s}. Each truth assignment on S satisfying X can be extended to a truth assignment on S′ satisfying Y in exactly one way, therefore #S′(Y ) = #S(X). Likewise, #S′ (A ∧ Y ) = #S (A ∧X). Hence A | Y = A | X.\nR3. Let S = σ JA,XK, S′ = σ JY K, and T = S ∪ S′. Since S and S′ are disjoint, we have\n#T (Y ∧X) = #S′(Y )#S(X) #T (A ∧ Y ∧X) = #S′(Y )#S (A ∧X)\nand hence A | X = A | Y ∧X. R4. Choose (P,≤P) to be (Q01,≤). Suppose that X is satisfiable and let S = σ JA,B,XK. If A ≺X B then all truth assignments satisfying both A and X also satisfy B, and there is some truth assignment satisfying both B and X that does not satisfy A. Hence #S (A ∧X) < #S (B ∧X), yielding A | X < B | X."
    }, {
      "heading" : "9. Discussion",
      "text" : ""
    }, {
      "heading" : "9.1. The classical definition of probability",
      "text" : "The classical definition of probability goes back to Cardano in the mid 16th Century [4, Chapter 14]; perhaps its clearest statement was given by Laplace [15]:\nThe probability of an event is the ratio of the number of cases favorable to it, to the number of possible cases, when there is nothing to make us believe that one case should occur rather than any other, so that these cases are, for us, equally possible.\nThis definition fell out of favor with the rise of both frequentist and subjective interpretations of probability. Theorem 14 takes us back to the beginnings of probability theory, validating the classical definition and sharpening it. We can now say that a “possible case” is simply a truth assignment satisfying the premise X. The phrase “these cases are, for us, equally possible,” which arguably makes the definition circular, may simply be dropped as unnecessary. The phrase “there is nothing to make us believe that one case should occur rather than any other” means that we possess no additional information that, if conjoined with our premise, would expand the satisfying truth assignments by differing multiplicities.\nWe shall illustrate this subtle but important point with Bertrand’s “Box Paradox” [2]. There are three identical boxes in a row, each with two drawers. One of the boxes, call it GG, has gold coins in both drawers; one box, call it SS, has silver coins in both drawers; and the remaining box, call it GS, has a gold coin in one drawer and a silver coin in the other. Not knowing which is which, you open the first drawer of the second box, and observe that it contains a gold coin; what is the probability that the other drawer also holds a gold coin?\nThis problem is often resolved by appeal to Bayes’ Rule, yielding a probability of 2/3. Let’s apply Theorem 14 instead. A naïve analysis, using only information about the second box itself, gives a probability of 1/2: the second box must be either GG or GS (two cases), and since the first drawer contains a gold coin, the second drawer also contains a gold coin only if the second box is GG (one case). But this ignores the (seemingly irrelevant) information we have about the first and third boxes. Table 1 gives an exhaustive list of all possible cases when the other boxes are included. We see that the case “second box is GS” gets expanded into two cases, while the case “second box is GG” gets expanded into four cases, thereby invalidating the naïve analysis. Using the expanded table gives the correct answer of 2/3."
    }, {
      "heading" : "D11 D12 D21 D22 D31 D32",
      "text" : ""
    }, {
      "heading" : "9.2. Uniform versus non-uniform probabilities",
      "text" : "One concern about Theorem 14 may be that it mandates the uniform distribution on Ω, the induced sample space of truth assignments satisfying the premise X. But what other reasonable option is there? Remember that the premise X contains all the information to which we have access in determining our probability distribution. There is no implicit third argument to the plausibility function that varies from one problem domain to another. Ω is just the reification of X as a set—X tells us that one of the elements of Ω is the correct description of the situation, and that is all it tells us. It gives us no information by which we could favor one of these possibilities over another.\nYet non-uniform distributions are the norm in practical applications of probability theory, and one may ask where they come from. The “Box Paradox” example illustrates one answer: via marginalization. A uniform distribution at the finest level of granularity can correspond to a nonuniform distribution at coarser levels obtained by considering the induced sample space for some subset of the symbols in σ JA,XK.\nFor a more complete answer, let’s consider Carnap’s objection to the uniform distribution. He defines a confirmation function c† for LN based on a uniform distribution over state-descriptions, and notes that if a1, . . . , ak, ak+1 are distinct individual constants and π is a monadic predicate (property), then\nc† (π (ak+1) , π (a1) ∧ · · · ∧ π (ak)) = 1\n2\nfor any k < N . He concludes [5, p. 565],\nThus the choice of c† as the degree of confirmation would be tantamount to the principle never to let our past experiences influence our expectations for the future.\nYet Carnap encounters this problem with c† for precisely the same reason that he cannot find a uniquely determined confirmation function. As Jaynes writes [13, p. 279],\nCarnap was seeking the general inductive rule (i.e., the rule by which, given the record of past results, one can make the best possible\nprediction of future ones). But. . . he never rises to the level of seeing that different inductive rules correspond to different prior information. It seems to us obvious. . . that this is the primary fact controlling induction, without which the problem cannot even be stated, much less solved; there is no ‘general inductive rule.’ Yet neither the term ‘prior information’ nor the concept ever appears in Carnap’s exposition.\nThis prior information belongs in the premise, and Carnap chooses not to include it there, as discussed in Section 2.3 and Section 3.4.\nAs an example of such prior information, consider Carnap’s proposed confirmation function c∗ and associated measure function m∗, for a language having a single monadic predicate π. Let us write xi for the atomic sentence π (ai), where ai is the i-th individual constant. Then m∗ is equivalent to defining the joint distribution\nθ ∼ Uniform(0, 1) xi ∼ Bernoulli(θ) independently for all i\nand marginalizing out θ. That is, give θ a uniform distribution over the interval (0, 1), then independently give each xi a probability θ of being true.\nWe now construct a propositional formula that expresses an arbitarily close approximation of this prior information. Let I and K be large, positive integers. Consider the xi, 1 ≤ i ≤ I, as propositional symbols. Let hk, 0 ≤ k ≤ K, have the intended interpretation “θ = k/K.” Let us imagine that individual i may be in any of K distinct fine-grained states, and let sij , 1 ≤ j ≤ K, have the intended interpretation that individual i is in state j. Finally, define X to be the conjunction of the following (K2 +K + 1)I + 1 formulas:\n〈h0, . . . , hK〉 〈si1, . . . , siK〉 for 1 ≤ i ≤ I hk ∧ sij → lijk for 1 ≤ i ≤ I, 1 ≤ j ≤ K, 0 ≤ k ≤ K\nwhere\nlijk = { xi if j ≤ k ¬xi if j > k.\nThat is, exactly one of the hk is true; for each i, exactly one of the sij is true; and if hk is true then each xi is true in k out of the K possible states for individual i. Using Theorem 14 we then have\nP (xi | hk ∧X) = k/K for all i independently P (hk | X) = 1/ (k + 1) .\nThis illustrates the general lesson: non-uniform probabilities arise by introducing latent variables, including in the premise information that links the latent variables to observables, and then marginalizing out latent variables."
    }, {
      "heading" : "9.3. Infinite domains",
      "text" : "How might one extend these results to infinite domains, which are required for the bulk of practical applications of probability theory? Jaynes proposes a finite sets policy [13, p. 43]:\nIt is very important to note that our consistency theorems have been established only for probabilities assigned on finite sets of propositions. In principle, every problem must start with such finite-set probabilities; extension to infinite sets is permitted only when this is the result of a well-defined and well-behaved limiting process from a finite set.\nIn the same vein, he writes [13, p. 663],\nIn probability theory, it appears that the only safe procedure known at present is to derive our results first by strict application of the rules of probability theory on finite sets of propositions; then, after the finite-set result is before us, observe how it behaves as the number of propositions increases indefinitely.\nAs an example, consider P ( y < (1− x)2 | x, y ∈ [0, 1) ∧ y < x2 ) . We can con-\nsider this to be the limiting value of P (An | Xn) as n→∞, where the queries An and premises Xn are defined as follows:\n1. Symbols ai and bi, for 1 ≤ i ≤ n, are intended to mean i − 1 ≤ nx < i and i− 1 ≤ ny < i respectively.\n2. Let An be ∨ (i,j)∈K (ai ∧ bj) where K = { (i, j) : j/n ≤ (1− i/n)2 } .\n3. Let Xn be ∨ (i,j)∈L (ai ∧ bj) where L = { (i, j) : j/n ≤ (i/n)2 } .\nFigure 9.1 illustrates Xn ∧ An in black and Xn ∧ ¬An in gray for n = 30. As n→∞, An tends in the limit to the desired query “y < (1− x)2” and Xn tends in the limit to the desired premise “y < x2,” with x, y ∈ [0, 1) implicit in the problem encoding.\nThough straightforward, it would be tedious to have to explicitly construct the limiting process and find the limiting value every time we considered a probability involving an infinite domain. Modern probability theory is based on measure theory, so it should be no surprise that measure theory provides the tools to automate this process of constructing a sequence of finite approximations that converge to a limit. We will not attempt to provide a full account of this large topic. By way of illustration, however, we will discuss one particularly simple case. We only sketch things out here; see Appendix Appendix A for more details.\nConsider the Cantor set of infinite binary sequences Bω, where B = {0, 1}. Enumerating the elements of S as s1, s2, . . ., we can consider Bω to be the set of truth assignments on S if we identify a truth assignment ρ with the infinite sequence w such that wi = ρ (si) for all i. We write C and µC for the Borel\nFigure 9.1: Approximating P\n( y < (1− x)2 | y < x2 ) with n = 30\nσ-algebra on Bω and Borel measure on C respectively, which may be considered a uniform distribution over Bω. Defining\n[A] = {w ∈ Bω : w satisfies A}\nfor any A ∈ Φ (S), and\nPr ( Ã; X̃, µ ) = µ ( Ã ∩ X̃ ) µ ( X̃ )\nfor any two measurable sets Ã, X̃ and measure µ with µ ( X̃ ) > 0, we find that\nP (A | X) = Pr ([A]; [X], µC) .\nFinally, Theorem 26 (Appendix Appendix A) states that for any measurable sets Ã, X̃ ∈ C with µC ( X̃ ) > 0 there exists a sequence of formulas Ai ∈ Φ (S)\nand Xi ∈ Φ+ (S) such that\nµC ( [Ai]4Ã ) → 0\nµC ( [Xi]4X̃ ) → 0\nP (Ai | Xi)→ Pr ( Ã; X̃, µC ) as i → ∞, where 4 stands for set difference. That is, Jaynes’s “well-defined and well-behaved limiting process” is guaranteed to exist under the conditions of the Theorem, and Pr ( Ã; X̃, µC ) is the limiting probability.\nNow we turn to the space Ω = Bm × [0, 1)n. We write D for the powerset of Bm (the maximal σ-algebra on Bm) and define µD(Ã) = ∣∣∣Ã∣∣∣ /2m for Ã ∈ D.\nWe write B and µB for the Borel σ-algebra on [0, 1)n and Borel measure on B, respectively. Let A = σ (D × B) be the product σ-algebra of D and B, and let µA = µD × µB be the product measure of µD and µB. The measure µA may be considered a uniform distribution over Bm× [0, 1)n, with µA ( Ã× B̃\n) being∣∣∣Ã∣∣∣ /2m times the n-dimensional hypervolume of B̃.\nThe set B∗1ω of binary sequences ending in an infinite sequence of 1’s is a measurable set of measure 0. Let us define I = Bω \\B∗1ω to be all infinite binary sequences except this measure-0 set. Define the function f : I→ Ω as\nf (w) = (f0(w), r (f1(w)) , . . . , r (fn(w)))\nf0(w) = w1 · · ·wm fj(w) = v1v2 · · · where vi = wm+ι(i,j), for j 6= 0\nr(v) = ∞∑ i=1 2−ivi\nι(i, j) = j + (i− 1)n.\nThat is, applying the mapping f amounts to interpreting symbol sm+ι(i,j), for i ≥ 1 and 1 ≤ j ≤ n, as the i-th bit in the infinite binary expansion of xj ∈ [0, 1), or more precisely, as the proposition “ ⌊ 2ixj ⌋ mod 2 = 1.” We interleave n infinite sequences into one sequence by mapping index i of sequence j to index ι(i, j) of the combined sequence. Using symbols sm+1 through sm+ι(k,n) we can express any subspace of [0, 1)n at a granularity of hypercubes of length 2−k on each side, and we can make this granularity as fine as desired by choosing k sufficiently large.\nThe function f is a bijection between I and Ω. (We excluded B∗1ω to ensure this, as dyadic rationals m/2n have two possible binary expansions.) Furthermore, both f and f−1 are measurable: f−1(A) ∈ C and f−1(A) ⊆ I whenever A ⊆ A, and f(B) ∈ A whenever B ∈ C and B ⊆ I. Finally, f is measurepreserving: µC ( f−1(A) ) = µA (A) whenever A ∈ A. This guarantees that\nPr ( Ã; X̃, µA ) = Pr ( f−1 ( Ã ) ; f−1 ( X̃ ) , µC ) .\nTherefore, we can apply Theorem 26 and find that for any measurable sets Ã, X̃ ∈ A with µA ( X̃ ) > 0 there exist sequences of formulas Ai and Xi, with\nXi satisfiable, such that\nµC ( [Ai]4f−1 ( Ã )) → 0\nµC ( [Xi]4f−1 ( X̃ )) → 0\nP (Ai | Xi)→ Pr ( Ã; X̃, µA ) as i→∞.\nIn the example given at the beginning of this section, we have m = 0, n = 2, and\nÃ = { (x, y) ∈ [0, 1)2 : y < (1− x)2 }\nX̃ = { (x, y) ∈ [0, 1)2 : y < x2 } .\nThe above results tell us that we don’t need to explicitly construct the sequence of approximating formulas for this example; it is guaranteed to exist, and the limiting probability is\nPr ( Ã; X̃, µA ) =\n∫ 1 0 min ( x2, (1− x)2 ) dx∫ 1\n0 x2dx\n= 1\n4 .\nAs another example, let us revisit and generalize the inductive model described in Section 9.2:\nθ ∼ Distr (F ) xi ∼ Bernoulli(θ) independently for all 1 ≤ i ≤ I\nwhere Distr(F ) is the distribution on the unit interval with cdf F , which we take to be continuous (and hence invertible). Doing a change of variables and augmenting with latent variables si, the above is equivalent to\np ∼ Uniform(0, 1) θ = F−1(p)\nsi ∼ Uniform(0, 1)\nxi = { 1 if si < θ 0 otherwise\nafter marginalizing out p and s. We have independent uniform distributions on p and each si, plus equations relating each xi to p and si; hence the above is equivalent to using as premise the measurable set\nX̃ = { (x, p, s) ∈ BI × [0, 1)1+I : xi = 1⇔ si < F−1 (p) for all 1 ≤ i ≤ I } ,\nagain using the σ-algebra A and measure µA, with m = I and n = I + 1. For any measurable Ã we are again guaranteed that Pr ( Ã; X̃, µA ) is the limiting\nprobability obtained from a sequence of approximating formulas Ai and Xi. This is not a complete solution to handling infinite problem domains. For instance, in the example above we used BI (with finite I) instead of Bω, because µA ( X̃ ) → 0 as I → ∞. In addition, the measure µC on C and encoding of\nreal numbers used above works well for a bounded interval like [0, 1) but does not suffice for unbounded intervals, such as all of R. For such cases we need alternative measures on C and corresponding analogs to Theorem 26, along with alternative encodings for these domains.\nOther work that remains to be done on this topic includes the following:\n1. Finding a general method of constructing the needed sequence of approximating formulas for any computable probability measure [10, 22].\n2. Extending our language of propositional formulas to express measurable sets beyond just the cylinder sets, while ensuring that P (A | X) remains computable, as is appropriate for a logical system.\nWe have made some initial investigations of these open issues and believe that they can be resolved."
    }, {
      "heading" : "10. Conclusion",
      "text" : "We have strengthened the case for probability theory as the uniquely determined extension of classical propositional logic to a logic of plausible reasoning. Our proof relies on a small and simple set of requirements such a logic must satisfy. These requirements are harder to dispute than those of previous such efforts because every one of the requirements is motivated by a desire to retain in our extended logic some property of CPL. A crucial distinction between our approach and similar previous work is that A | X depends only on the explicit arguments A and X, and not on any other domain-specific or problem-specific information; any such relevant information must be included in the premise X. This makes the plausibility function a legitimate analog of the logical consequence relation: the truth or falsity of X |= A likewise depends only on X and A, and not on any implicit domain-specific or problem-specific information.\nR2 (invariance under definition of new symbols) in conjunction with R1 (logical equivalence) turns out to have far-reaching implications. It yields invariance under renaming of propositional symbols and, in fact, a fully general invariance under change-of-variable transformations. Most importantly, it implies that A | X is a function only of #S (A ∧X) and #S(X) for any S containing all the symbols used in A and X. R3 (invariance under addition of irrelevant information) excludes Carnap’s system, which comes pre-supplied with dependencies between propositions rather than letting any dependencies be specified in the premise. Adding R3 implies that A | X is a function of the ratio of #S (A ∧X) to #S(X).\nFinally, with R4 we made use of the underappreciated fact that CPL already comes equipped with an inherent plausibility ordering on propositions, for any given premise. The invariances of R1–R3 “stitch together” these partial orderings for distinct premises, and we find that we have an order-preserving isomorphism P between the set of plausibilities P and the set of rational probabilities Q01. The numeric value we find for P (A | X) recreates the classical definition of probability, but in a sharper, clearer form with the troublesome circularity excised, and as a theorem rather than as a definition. The “possible cases” are identified as truth assignments satisfying the premise, and the meaning of “equally possible cases” is simply that we have no additional information that would expand the satisfying truth assignments by differing multiplicities.\nWe addressed two possible concerns about our result: that it seems to allow only uniform probabilities, and that it yields probabilities only for finite\ndomains. We showed how non-uniform probabilities arise via the introduction of latent variables, along with information in the premise linking these latent variables to the observables. Following Jaynes, we proposed that probabilities for infinite domains be obtained via a well-defined and well-behaved limiting process, and demonstrated how measure theory can automate the construction of such limiting processes in at least some cases."
    }, {
      "heading" : "Appendix A. Measure Theory",
      "text" : ""
    }, {
      "heading" : "Appendix A.1. Some results from measure theory",
      "text" : "We assume the reader is already familiar with the basic concepts of measure theory: an algebra, a σ-algebra, a measurable set, the σ-algebra σ(A) generated by an algebra A, a measurable function, a measure on an algebra or σ-algebra, and a σ-finite measure. Billingsley [3] and Tao [19] are good references. Here we highlight some results we will use.\nA measure on an algebra A can always be consistently extended to a measure on σ (A) [3, Theorem 11.3]:\nTheorem 17. If µ is a measure on an algebra A then µ extends to a measure on σ (A), that is, there exists a measure µ′ on σ (A) such that µ(A) = µ′(A) for all A ∈ A. If µ is σ-finite then µ′ is unique, and is also σ-finite.\nIn many cases of interest the elements of a σ-algebra can be approximated arbitrarily closely by sets from the generating algebra [3, Theorem 11.4]:\nTheorem 18. If A is an algebra on Ω, µ is a σ-finite measure on σ (A), and B ∈ σ (A) with µ (B) < ∞, then for every > 0 there exists some A ∈ A such that µ (A4B) < .\nWe use the following measure-related properties of set differences A4B, which we state without proof:\nProperty 19. For any measure µ on an algebra A and any A,B ∈ A,\n|µ(A)− µ(B)| ≤ µ (A4B) .\nProperty 20. For any measure µ on an algebra A and any A1, A2, X1, X2 ∈ A,\nµ ((A1 ∩X1)4 (A2 ∩X2)) ≤ µ (A14A2) + µ (X14X2) ."
    }, {
      "heading" : "Appendix A.2. Constructing the “well-defined and well-behaved limiting process”",
      "text" : "To avoid confusion between propositional formulas and measurable sets, in this section we will generally decorate the names of measurable sets with a tilde (Ã, B̃, etc.) and leave the names of propositional formulas undecorated (A, B, etc.)\nThe Borel σ-algebra and Borel measure for the Cantor set Bω are constructed as follows:\nDefinition 21. A cylinder set is a subset of Bω of the form cyl (n,C) , CBω for some C ⊆ Bn. C0 is the collection of all cylinder sets. This set is an algebra, and the Borel σ-algebra for Bω is C , σ (C0), the σ-algebra generated by C0.\nCylinder sets are the basis of a topology on Bω in which the open sets are any finite or countable union of cylinder sets, and this is why we call C the Borel σ-agebra for Bω.\nDefinition 22. The Borel measure for C is the measure µC such that\nµC (cyl (n,C)) = 2 −n |C|\nfor any n ≥ 0 and C ⊆ Bn.\nThe definition above is unambiguous because cyl(n,C) = cyl(n + m,C ′) if and only if C ′ = CBm. Note that µC is trivially σ-finite, since Bω itself is a cylinder set and µC (Bω) is finite. By Theorem 17 µC is uniquely defined once we define its value on cylinder sets.\nLet us enumerate the elements of S as s1, s2, . . . and identify a sequence w ∈ Bω with the truth assignment ρ on S such that ρ (si) = wi for all i; then every propositional formula corresponds to a cylinder set:\nDefinition 23. If A is a propositional formula then [A] is the set of w ∈ Bω that satisfy A (considered as truth assignments.)\nNote that [A] = cyl(n,C) and µC ([A]) = 2−n#S(A), where σ JAK ⊆ S = {s1, . . . , sn} and C is the set of w ∈ Bn that satisfy A. Likewise, every cylinder set corresponds to a propositional formula:\nLemma 24. For any cylinder set Ã there is a formula A ∈ Φ (S) such that Ã = [A].\nProof. Let Ã = cyl (n,C) and define the propositional formula A as A = ∨ c∈C Ac\nAc = n∧ i=1 Li,ci\nLi,0 = ¬si Li,1 = si\nIt is straightforward to see that [A] = Ã.\nWe can define an analog to P (A | X), but for measurable sets:\nDefinition 25. Let A be a σ-algebra and µ a measure on A. For any Ã, X̃ ∈ A with µ ( X̃ ) > 0, define\nPr ( Ã; X̃, µ ) = µ ( Ã ∩ X̃ ) µ ( X̃ ) .\nWe then find that\nP (A | X) = 2 −n#S (A ∧X) 2−n#S (X) = Pr ([A]; [X], µC)\nwhere we choose n to be large enough that σ JA,XK ⊆ S = {s1, . . . , sn}. We use this fact to show that Jaynes’s “well-defined and well-behaved limiting process” is guaranteed to exist for measurable sets:\nTheorem 26. Let Ã, X̃ ∈ C, with µC ( X̃ ) > 0. Then there exists a sequence\nof formulas Ai ∈ Φ (S) and Xi ∈ Φ+ (S) such that 1. limi→∞ µC ( [Ai]4Ã ) = 0.\n2. limi→∞ µC ( [Xi]4X̃ ) = 0.\n3. limi→∞ P (Ai | Xi) = Pr ( Ã; X̃, µC ) .\nProof. Let i, i ≥ 1 be any decreasing sequence of positive numbers whose limit is 0, with 1 < µC ( X̃ ) . Using Theorem 18 and Lemma 24 we can define\nAi = some A ∈ Φ (S) such that µC ( [A]4Ã ) < i\nXi = some X ∈ Φ (S) such that µC ( [X]4X̃ ) < i\n1 and 2 in the theorem statement follow directly from these definitions. From Property 19 we have∣∣∣µC ([Xi])− µC (X̃)∣∣∣ ≤ µC ([X]4X̃) < i < µC (X̃) and so µC ([Xi]) > 0, i.e., Xi is satisfiable. Property 19 also gives us\nlim i→∞ µC ([Xi]) = µC\n( X̃ ) .\nProperty 20 gives us\nµC ( [Ai ∧Xi]4 ( Ã ∩ X̃ )) < 2 i\nand then Property 19 yields\nlim i→∞\nµC ([Ai ∧Xi]) = µC ( Ã ∩ X̃ ) .\nFinally we have\nlim i→∞ P (Ai | Xi) = lim i→∞ µC ([Ai ∧Xi]) µC ([Xi]) = µC\n( Ã ∩ X̃ ) µC ( X̃ ) = Pr(Ã; X̃, µC) ."
    } ],
    "references" : [ {
      "title" : "Lectures on Functional Equations and Their Applications",
      "author" : [ "J. Aczél" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1996
    }, {
      "title" : "Probability and Measure, Third Edition",
      "author" : [ "P. Billingsley" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1995
    }, {
      "title" : "Logical Foundations of Probability (2nd edition)",
      "author" : [ "R. Carnap" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1962
    }, {
      "title" : "The Continuum of Inductive Methods",
      "author" : [ "R. Carnap" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1952
    }, {
      "title" : "Bridging the intuition gap in Cox’s Theorem: A Jaynesian argument for universality.",
      "author" : [ "A. Clayton", "T. Waddington" ],
      "venue" : "International Journal of Approximate Reasoning",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2017
    }, {
      "title" : "The philosophical significance of Cox’s theorem.",
      "author" : [ "M. Colyvan" ],
      "venue" : "International Journal of Approximate Reasoning",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2004
    }, {
      "title" : "Probability, frequency and reasonable expectation.",
      "author" : [ "R.T. Cox" ],
      "venue" : "American Journal of Physics",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1946
    }, {
      "title" : "A computable approach to measure and integration theory.",
      "author" : [ "A. Edalat" ],
      "venue" : "Information and Computation",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2009
    }, {
      "title" : "A Counterexample to Theorems of Cox and Fine.",
      "author" : [ "J.Y. Halpern" ],
      "venue" : "Journal of Artificial Intelligence Research",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1999
    }, {
      "title" : "Technical addendum: Cox’s Theorem revisited.",
      "author" : [ "J.Y. Halpern" ],
      "venue" : "Journal of Artificial Intelligence Research",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1999
    }, {
      "title" : "Probability Theory: The Logic of Science",
      "author" : [ "E.T. Jaynes" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2003
    }, {
      "title" : "Notes on Logic and Set Theory (1st edition)",
      "author" : [ "P.T. Johnstone" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1987
    }, {
      "title" : "The Uncertain Reasoner’s Companion: A Mathematical Perspective",
      "author" : [ "J.B. Paris" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1994
    }, {
      "title" : "Mathematics and Plausible Reasoning: Vol 2: Patterns of Plausible Inference",
      "author" : [ "G. Pólya" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1954
    }, {
      "title" : "Comments on constructing a logic of plausible inference: a guide to Cox’s Theorem, by Kevin S",
      "author" : [ "G. Shafer" ],
      "venue" : "Van Horn.” International Journal of Approximate Reasoning",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2004
    }, {
      "title" : "An Introduction to Measure Theory. American Mathematical Society",
      "author" : [ "T. Tao" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2011
    }, {
      "title" : "Rational Descriptions, Decisions, and Designs",
      "author" : [ "M. Tribus" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1969
    }, {
      "title" : "Constructing a logic of plausible inference: a guide to Cox’s Theorem.",
      "author" : [ "K.S. Van Horn" ],
      "venue" : "International Journal of Approximate Reasoning",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2003
    }, {
      "title" : "Representations of measurable sets in computable measure theory.",
      "author" : [ "K. Weihrauch", "N.R. Tavana" ],
      "venue" : "Logical Methods in Computer Science",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "This view is grounded in the work of Pólya [17] and Cox [9], especially the latter.",
      "startOffset" : 43,
      "endOffset" : 47
    }, {
      "referenceID" : 6,
      "context" : "This view is grounded in the work of Pólya [17] and Cox [9], especially the latter.",
      "startOffset" : 56,
      "endOffset" : 59
    }, {
      "referenceID" : 6,
      "context" : "Whereas X |= A means that A (the conclusion) is a logical consequence of X (the premise), we write A | X for “the reasonable credibility of the proposition A (the query) when the proposition X (the premise) is known to be true” (paraphrasing Cox [9].",
      "startOffset" : 246,
      "endOffset" : 249
    }, {
      "referenceID" : 0,
      "context" : "there is an order-preserving isomorphism P between the set of plausibility values P and the set of rational probabilities Q ∩ [0, 1]; 2.",
      "startOffset" : 126,
      "endOffset" : 132
    }, {
      "referenceID" : 6,
      "context" : "Cox [9] proposes a handful of intuitively-appealing, qualitative requirements for any system of plausible reasoning, and shows that these requirements imply that any such system is just probability theory in disguise.",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "interval [0, 1] such that A | X, after mapping from plausibilities to [0, 1], respects the laws of probability.",
      "startOffset" : 9,
      "endOffset" : 15
    }, {
      "referenceID" : 0,
      "context" : "interval [0, 1] such that A | X, after mapping from plausibilities to [0, 1], respects the laws of probability.",
      "startOffset" : 70,
      "endOffset" : 76
    }, {
      "referenceID" : 0,
      "context" : "Over the years Cox’s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox’s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox’s original proof.",
      "startOffset" : 59,
      "endOffset" : 78
    }, {
      "referenceID" : 10,
      "context" : "Over the years Cox’s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox’s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox’s original proof.",
      "startOffset" : 59,
      "endOffset" : 78
    }, {
      "referenceID" : 12,
      "context" : "Over the years Cox’s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox’s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox’s original proof.",
      "startOffset" : 59,
      "endOffset" : 78
    }, {
      "referenceID" : 16,
      "context" : "Over the years Cox’s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox’s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox’s original proof.",
      "startOffset" : 59,
      "endOffset" : 78
    }, {
      "referenceID" : 17,
      "context" : "Over the years Cox’s arguments have been refined by others [1, 13, 16, 20, 21], making explicit some requirements that were only implicit in Cox’s original presentation, and replacing some of the requirements with slightly less demanding assumptions than those used in Cox’s original proof.",
      "startOffset" : 59,
      "endOffset" : 78
    }, {
      "referenceID" : 17,
      "context" : "One version of the requirements [21] may be summarized as follows:",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 0,
      "context" : "The set of plausibility triples (y1, y2, y3) where y1 = A1 | X, y2 = A2 | A1∧X, and y3 = A3 | A2 ∧A1 ∧X for some A1, A2, A3, and X, is dense in [0, 1].",
      "startOffset" : 144,
      "endOffset" : 150
    }, {
      "referenceID" : 14,
      "context" : "For example, Shafer [18] objects to C1, C3, and C5; Halpern [11, 12] questions C4; and Colyvan [8] objects to C2 on the basis that it presumes the law of the excluded middle.",
      "startOffset" : 20,
      "endOffset" : 24
    }, {
      "referenceID" : 8,
      "context" : "For example, Shafer [18] objects to C1, C3, and C5; Halpern [11, 12] questions C4; and Colyvan [8] objects to C2 on the basis that it presumes the law of the excluded middle.",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 9,
      "context" : "For example, Shafer [18] objects to C1, C3, and C5; Halpern [11, 12] questions C4; and Colyvan [8] objects to C2 on the basis that it presumes the law of the excluded middle.",
      "startOffset" : 60,
      "endOffset" : 68
    }, {
      "referenceID" : 5,
      "context" : "For example, Shafer [18] objects to C1, C3, and C5; Halpern [11, 12] questions C4; and Colyvan [8] objects to C2 on the basis that it presumes the law of the excluded middle.",
      "startOffset" : 95,
      "endOffset" : 98
    }, {
      "referenceID" : 4,
      "context" : "(Some variants [7, 13, 21] of Cox’s Theorem allow X to be an undefined “state of information” to which we may add additional propositional information.",
      "startOffset" : 15,
      "endOffset" : 26
    }, {
      "referenceID" : 10,
      "context" : "(Some variants [7, 13, 21] of Cox’s Theorem allow X to be an undefined “state of information” to which we may add additional propositional information.",
      "startOffset" : 15,
      "endOffset" : 26
    }, {
      "referenceID" : 17,
      "context" : "(Some variants [7, 13, 21] of Cox’s Theorem allow X to be an undefined “state of information” to which we may add additional propositional information.",
      "startOffset" : 15,
      "endOffset" : 26
    }, {
      "referenceID" : 4,
      "context" : "Clayton and Waddington: bridging the intution gap In a recent paper, Clayton and Waddington [7] seek to “bridge the intuition gap” in Cox’s Theorem by proposing alternative requirements they argue are more intuitively reasonable, and then proving C4 and the strictness of F in C5 as theorems.",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 10,
      "context" : "• Jaynes [13] argues that, if one’s background information is “indifferent” between two propositions, then they should be assigned equal plausibility.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 2,
      "context" : "Carnap: logical probability Carnap [5] undertakes an extensive investigation of “logical probability.",
      "startOffset" : 35,
      "endOffset" : 38
    }, {
      "referenceID" : 6,
      "context" : "Unlike Cox [9], Carnap makes no attempt to derive the laws of probability from more fundamental considerations; instead, his “conventions on adequacy” [5, p.",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 3,
      "context" : "He later [5, Preface to Second Edition][6] proposes instead an entire family of confirmation functions cλ parameterized by a positive number λ.",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 8,
      "context" : "Halpern [11, 12] claims to demonstrate a counterexample to Cox’s Theorem by examining a finite problem domain, but his argument presumes that there is a different plausibility function for every problem domain.",
      "startOffset" : 8,
      "endOffset" : 16
    }, {
      "referenceID" : 9,
      "context" : "Halpern [11, 12] claims to demonstrate a counterexample to Cox’s Theorem by examining a finite problem domain, but his argument presumes that there is a different plausibility function for every problem domain.",
      "startOffset" : 8,
      "endOffset" : 16
    }, {
      "referenceID" : 6,
      "context" : "Others [9, 16] seem to presume a single plausibility function, but with domain-specific information serving as an implicit extra argument3.",
      "startOffset" : 7,
      "endOffset" : 14
    }, {
      "referenceID" : 12,
      "context" : "Others [9, 16] seem to presume a single plausibility function, but with domain-specific information serving as an implicit extra argument3.",
      "startOffset" : 7,
      "endOffset" : 14
    }, {
      "referenceID" : 4,
      "context" : "A third interpretation [7, 13, 21] presumes a single plausibility function with all relevant information about the problem domain encapsulated in the second argument, the “state of information.",
      "startOffset" : 23,
      "endOffset" : 34
    }, {
      "referenceID" : 10,
      "context" : "A third interpretation [7, 13, 21] presumes a single plausibility function with all relevant information about the problem domain encapsulated in the second argument, the “state of information.",
      "startOffset" : 23,
      "endOffset" : 34
    }, {
      "referenceID" : 17,
      "context" : "A third interpretation [7, 13, 21] presumes a single plausibility function with all relevant information about the problem domain encapsulated in the second argument, the “state of information.",
      "startOffset" : 23,
      "endOffset" : 34
    }, {
      "referenceID" : 4,
      "context" : "3 (translation invariance) [7], which they motivate via Jaynes’s “indifference” criterion [13, p.",
      "startOffset" : 27,
      "endOffset" : 30
    }, {
      "referenceID" : 0,
      "context" : "If R1–R4 hold then for all r, r′ ∈ Q01 , Q ∩ [0, 1] we have Υ1 (r) = Υ1 (r ′)⇔ r = r′ Υ1 (r) <P Υ (r ′)⇔ r < r′.",
      "startOffset" : 45,
      "endOffset" : 51
    }, {
      "referenceID" : 7,
      "context" : "Finding a general method of constructing the needed sequence of approximating formulas for any computable probability measure [10, 22].",
      "startOffset" : 126,
      "endOffset" : 134
    }, {
      "referenceID" : 18,
      "context" : "Finding a general method of constructing the needed sequence of approximating formulas for any computable probability measure [10, 22].",
      "startOffset" : 126,
      "endOffset" : 134
    }, {
      "referenceID" : 1,
      "context" : "Billingsley [3] and Tao [19] are good references.",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 15,
      "context" : "Billingsley [3] and Tao [19] are good references.",
      "startOffset" : 24,
      "endOffset" : 28
    } ],
    "year" : 2017,
    "abstractText" : "We consider the question of extending propositional logic to a logic of plausible reasoning, and posit four requirements that any such extension should satisfy. Each is a requirement that some property of classical propositional logic be preserved in the extended logic; as such, the requirements are simpler and less problematic than those used in Cox’s Theorem and its variants. As with Cox’s Theorem, our requirements imply that the extended logic must be isomorphic to (finite-set) probability theory. We also obtain specific numerical values for the probabilities, recovering the classical definition of probability as a theorem, with truth assignments that satisfy the premise playing the role of the “possible cases.”",
    "creator" : "LaTeX with hyperref package"
  }
}