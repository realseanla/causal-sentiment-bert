{
  "name" : "1409.6831.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "The Application of Differential Privacy for Rank Aggregation: Privacy and Accuracy",
    "authors" : [ "Shang Shang", "Tiance Wang", "Paul Cuff", "Sanjeev Kulkarni" ],
    "emails" : [ "kulkarni}@princeton.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords—Rank Aggregation, Privacy, Accuracy\nI. INTRODUCTION\nWith the increasing interest in social networks and the availability of large datasets, rank aggregation has been studied intensively in the context of social choice. From the NBA’s Most Valuable Player to Netflix’s movie recommendations, from web search to presidential elections, voting and ranking are ubiquitous. Informally, rank aggregation is the problem of combining a set of full or partial rankings of a set of alternatives into a single consensus ranking. In recommender systems, users are motivated to submit their rankings in order to receive personalized services. On the other hand, they may also be concerned about the risk of possible privacy leakage.\nEven accumulated or anonymized datasets are not as “safe” as they seem to be. Information on individual rankings or preferences can still be learned even if the querier only has access to global statistics. In 2006, Netflix launched a data competition with 100 million movie ratings from half a million anonymized users. However, researchers subsequently demonstrated that individual users from this “sanitized” dataset could be identified by matching with the Internet Movie Database (IMDb). This raises the privacy concerns about sharing honest opinions.\nDifferential privacy is a framework that aims to obscure individuals’ appearances in the database. It makes no assumptions on the attacker’s background knowledge. Mathematical guarantees are provided in [1] and [2]. Differential privacy has gained popularity in various applications, such as social networks [3], recommendations [4], advertising [5], etc. However, there is a trade-off between the accuracy of the query results and the privacy of the individuals included in the statistics. In [6], the authors showed that good private social recommendations are achievable only for a small subset of users in the social network.\nIn this paper, we apply the framework of differential privacy to rank aggregation. Privacy is protected by adding noise to the query of ranking histograms. The user can then apply a rank aggregation rule to the “noisy” query results. In general, stronger noise guarantees better differential privacy. However, excessive noise reduces the utility of the query results. We measure the utility by the probability that the aggregated ranking is accurate. A summary of the contributions of this paper is as follows: • A privacy-preserving algorithm for rank aggregation is\nproposed. Instead of designing differential privacy for each individual ranking rule, we propose to add noise to the ranking histogram, irrespective of the ranking rules to be used. • General upper bounds on the ranking error rate are derived for all positional ranking rules. Moreover, we show that the asymptotic error rate approaches zero when the number of voters goes to infinity for any ranking rules with a fixed number of candidates. • An example using Borda count is given to show how to extend the proposed analysis to derive a tighter upper bound on the error rate for a specific positional rule. Simulations are performed to validate the analysis.\nThe rest of the paper is organized as follows. We define the problem of rank aggregation, introduce the definition of differential privacy, and describe the privacy preserving algorithm in Section 2. We then discuss the accuracy of the algorithm, and provide analytical upper bounds on the error rates in Section 3, followed by simulation results in Section 4, and conclusions in Section 5."
    }, {
      "heading" : "II. DIFFERENTIAL PRIVACY IN RANK AGGREGATION",
      "text" : ""
    }, {
      "heading" : "A. Rank Aggregation: Definitions and Notations",
      "text" : "Let C = {1, ...,M} be a finite set of M candidates, M ≥ 3. Denote the set of permutations on C by TM . Denote the number of voters by N . Each ballot xi, i = 1, ..., N is an element of TM , or a strict linear ordering. A rank aggregation algorithm, or a ranking rule is a function g : TNM → TM . The input (x1, . . . , xN ) is called a profile.\nA ranking rule g is neutral if it commutes with permutations on C [7]. Intuitively, a neutral ranking method is not biased in favor of or against any candidate.\nA ranking rule g is anonymous if the “names” of the voters do not matter [7], i.e.\ng(x1, ..., xN ) = g(π(x1, ..., xN )) (1)\nar X\niv :1\n40 9.\n68 31\nv1 [\ncs .A\nI] 2\n4 Se\np 20\n14\n2 for any permutation π on 1, ..., N . For an anonymous ranking method, we use the anonymized profile, a vector q ∈ NM !, instead of the complete profile (x1, . . . , xN ) as the input. Let q denote the histogram of rankings: It counts the number of appearances of each ranking in all n rankings. The rank aggregation function can therefore be rewritten as g : NM ! → TM .\nAn anonymous ranking rule is scale invariant if the output depends only on the empirical distribution of votes v = q/N , not the number of voters N . That is,\ng(q) = g(αq) (2)\nfor any α > 0. There are many different neutral and scale invariant rank aggregation algorithms. Popular ones include plurality, Borda count, instant run-off, the Kemeny-Young method and so on. Each algorithm has its own merits and disadvantages. For example, the Kemeny-Young method satisfies the Condorcet criterion (a candidate preferred to any other candidate by a strict majority of voters must be ranked first) but is computationally expensive. In fact it is NP-Hard even for M = 4 [8]. This is especially an issue for recommender systems since the number of items to be recommended can be large.\nA class of ranking rules, known as the positional rules, has an edge in computational complexity. A positional rule takes complete rankings as input, and assigns a score to each candidate according to their position in a ranking. The candidates are sorted by their total scores summed up from all rankings. The time complexity is only O(MN +M logM), where the M logM term comes from sorting. All positional rules satisfy anonymity and neutrality but fail the Condorcet criterion [9]. A positional rule with M candidates has M parameters: s1 ≥ · · · ≥ sM , where si is the score assigned to the ith highest-ranked candidate. We can further normalize the scores without affecting the ranking rule so that s1 = 1, sM = 0. Borda count, a widely used positional rule, is specified by si = (M − i)/(M − 1). Note that plurality is a positional rule with si = 0 for i ≥ 2. Plurality is popular due to its simplicity. However, it is not ideal as a rank aggregation algorithm because it discards too much information. In this paper, we specifically focus on positional rules because of their computational efficiency and ease of error rate analysis."
    }, {
      "heading" : "B. Differential Privacy",
      "text" : "In this paper, we consider a strong notion of privacy, differential privacy [1]. Intuitively, a randomized algorithm has good differential privacy if its output distribution is not sensitive to a single entity’s information. For any dataset A, let N (A) denote the set of neighboring datasets, each differing from A by at most one record, i.e., if A′ ∈ N (A), then A′ has exactly one entry more or one entry less than A.\nDefinition 1. [2] A random algorithm M satisfies ( , δ)differential privacy if for any neighboring datasets A and A′, and any subset S of possible outcomes Range(M),\nPr[M(A) ∈ S] ≤ exp( )× Pr[M(A′) ∈ S] + δ. (3)\nRemark: ( , δ)-differential privacy is a slight relaxation from the -differential privacy in that the ratio\nPr[M(A) ∈ S]/Pr[M(A′) ∈ S]\nneed not be bounded if both probabilities are very small. Differential privacy has been widely used in various applications [4], [5]."
    }, {
      "heading" : "C. Privacy Preserving Algorithms",
      "text" : "Much work has been done on developing differentially private algorithms [10], [11]. Let D denote the set of all datasets, and f is an operation on the dataset, such as sum, count, etc.\nDefinition 2. The l2-sensitivity ∆f of a function f : D → Rd is\n∆f(A) = max A′∈N (A)\n‖f(A)− f(A′)‖2\nfor all A′ ∈ N (A) differing in at most one element, and A,A′ ∈ D.\nTheorem 1. [2] Define M(A) to be f(A) + N (0, σ2Id×d). M provides ( , δ)-differential privacy, whenever\nσ2 ≥ 2 ln( 2δ )\n2 · max A′∈N (A) ‖f(A)− f(A′)‖22, (4)\nfor all A′ ∈ N (A) differing in at most one element, and A,A′ ∈ D.\nIn our model, f(A) is the histogram of all rankings, i.e. the input vector q defined in Section II-A. It is clear that the l2 sensitivity of f(A) is 1, since adding or removing a vote can only affect one element of q by 1. In the exposition, we will denote the private data and released data by x and x̂ respectively. When we add noise n to a variable x, we write x̂ = x+ noise. Thus\nq̂ = q +N (0, σ2IM !×M !) (5)\nwhere σ2 = 2 ln(2δ )/ 2, and M is the number of candidates. We use Gaussian instead of Laplacian noise which achieves stronger -privacy [1], because Gaussian noise enjoys the nice property that any linear combination of jointly Gaussian random variables is Gaussian.\nNote that there is a positive probability that q̂i < 0 for some index i. This does not harm our analysis since positional rules are well defined even if we allow negative vote counts.\nFinally, we define the error rate of a privacy preserving rank aggregation algorithm on ranking. The error rate is the probability that the aggregated ranking changes after adding noise. This probability depends on the ranking rule, the noise distribution, and the distribution of profiles.\nDefinition 3. The error rate PMe of a privacy preserving rank aggregation algorithm g with M candidates is defined as E1{g(q)6=g(q̂)}.\n3"
    }, {
      "heading" : "III. GENERAL ERROR BOUNDS",
      "text" : "In this section, we discuss the error rates in the rank aggregation problem. We give the expression for the general error rate and derive upper bounds on the error rate for all positional ranking rules under the assumption that profiles are uniformly distributed."
    }, {
      "heading" : "A. Geometric Perspective of Positional Ranking Systems",
      "text" : "We normalize the anonymous profile by dividing by the number of voters N . The resulting vector v = q/N is the empirical distribution of votes, v ∈ [0, 1]M !. All empirical distributions are contained in a unit simplex, called the rank simplex:\nV = {v ∈ RM ! : M !∑ i=1 vi = 1 and vi ≥ 0 for ∀i}. (6)\nA rank simplex with M candidates has a dimension of M !− 1. We assume that the normalized profile v is uniformly distributed on the rank simplex V .\nGeometrically, a ranking rule is a partition of the rank simplex. For positional ranking rules, the rank simplex is partitioned into M ! congruent polytopes by ( M 2 ) hyperplanes. Each polytope represents a ranking, and each hyperplane represents the equality of the score of two candidates. Moreover, each polytope is uniquely defined by M − 1 hyperplanes and the faces of the rank simplex V . An example of how to define the hyperplane from given ranking rule will be given in Section IV.\nTo maintain neutrality, we break ties randomly when there is a tie. For example, if the score of candidate a and b happens to be equal, then we rank a ahead of b with probability one half. We only mention tie as a side remark since it does not have an affect on the probability analysis.\nProposition 1. Let v̂ = v + ω (7)\nwhere ω is a M !-dimensional random variable with distribution\nN (0, σ̂2IM !×M !),\nwhere σ̂2 = 2 ln (2/δ) 2N2 . We have\nE1{g(q)6=g(q̂)} = E1{g(v)6=g(v̂)}.\nProof: This follows directly from the scale invariant property of the ranking rules.\nRemark: Note that v̂ may not be in the probability simplex. The ranking result of v̂ is uniquely defined by the cone formed by M − 1 hyperplanes representing the equality of scores of two candidates."
    }, {
      "heading" : "B. An Upper Bound on the General Error Rate",
      "text" : "Rather than providing different upper bounds for each and every positional rule, we derive a general bound that works for any positional rule. Therefore, the user can decide which positional rule to apply to the queried noisy histogram, and the\nsystem has some guarantee on the error rate given the privacy level.\nIf noise switches the order of the scores of any two candidates, then the final ranking necessarily changes. Let Si(v), Sj(v) denote the score of candidate i and j for an arbitrary positional rule given the profile v. As mentioned in Section III-A, there are ( M 2 ) hyperplanes separating the simplex into M ! polytopes. The hyperplanes are defined by Si = Sj for any pair of candidates i, j, and there are ( M 2 ) such pairs. Let βij denote the unit normal vector of hyperplane Hij : Si = Sj . That is,\n||βij ||2 = 1 (8)\nThen βij · w is the scalar projection of βij for vector w. Let Dij(v) be the distance from v to hyperplane Hij . Given the uniform distribution of v over the rank simplex, Dij(v) is a continuous random variable that takes values on [− √ 2, √ 2] ( √\n2 is the edge length of the probability simplex). The sign indicates on which side of the hyperplane v locates. Let pD denote the probability density function of Dij . By the neutrality of positional rules, pD is identical for any i 6= j and pD(l) = pD(−l). By symmetry,∫ √2\n0\npD(l)dl = 1\n2 . (9)\nGeometrically, pD(l) is proportional to the (M !− 2)-measure of the cross section of the hyperplane Hij(l) with the simplex, where Hij(l) is parallel to Hij with distance l. Lemma 1. Let pD be as defined as above. Then pD is maximal at 0 on [0, √ 2] for any positional rule.\nProof: Let H be the hyperplane defined by the equality of the score of two candidates for an arbitrary positional rule, and β be the unit normal vector of H. That is, H = {v ∈ RM ! : βv = 0}. Let H + sβ denote the hyperplane βv = s. Let X1, . . . , XM ! be i.i.d. random variables with the following density function:\nf(x) = { e−x if x ≥ 0 0 otherwise.\n(10)\nThat is, Xj’s are independent exponential random variables with parameter λ = 1. The density of the random variable Y = ∑M ! i=1 βjXj is [12]\nG(s) = ∫ H+sβ M !∏ j=1 f(x)dVolH (11)\nwhere VolH denotes the Lebesgue measure on H. It is shown in [12] that\nVolM !−2(H ∩ V) = √ M !\nΓ(M !− 1) ∫ H M !∏ j=1 f(x)dVolH (12)\nwhere VolM !−2 denotes M !−2 - dimensional volume, V is the unit regular M ! − 1 - simplex embedded in RM !, as defined in Equation (6). This result is shown in [12] for H passing\n4 through the origin and centroid, but it holds for any hyperplane, i.e.,\nVolM !−2 ( (H+ sβ) ∩ V ) =\n√ M !\nΓ(M !− 1) G(s). (13)\nThe characteristic function of Y is\nφY (t) = M !∏ j=1 φXj (βjt) = M !∏ j=1 (1 + iβjt) −1. (14)\nNote that for any entry j, there is a corresponding entry j′ such that the j′th ranking is the reversed order of the jth ranking. By symmetry, βj = −βj′ , (1 + iβjt)(1 + iβj′t) = 1 + β2j t2. Without loss of generality, suppose βj > 0 for 1 ≤ j ≤M !/2, then\nφY (t) = M !/2∏ j=1 (1 + β2j t 2)−1. (15)\nSince φY (t) is always real and positive, by Bochner’s theorem [13], G(s) is a positive-definite function, i.e.,\n|G(s)| ≤ G(0).\nThis is also easy to prove by directly applying the inverse Fourier Transform:\n|G(s)| = ∣∣∣∣ 12π ∫ +∞ −∞ φY (t)e −istds ∣∣∣∣ ≤ 1\n2π ∫ +∞ −∞ ∣∣φY (t)e−ist∣∣ ds = 1\n2π ∫ +∞ −∞ φY (t) ∣∣e−ist∣∣ ds\n= 1\n2π ∫ +∞ −∞ φY (t)ds\n= G(0). (16)\nThus we have, VolM !−2 ( (H+ sβ) ∩ V ) ≤ VolM !−2(H ∩ V).\nLemma 2. The ranking error rate PMe satisfies\nPMe ≤ ( M\n2\n) · 2 τ∫ 0 pD(l)Q ( l σ̂ ) dl +Q ( τ σ̂ ) ,∀τ > 0,\nfor all positional ranking aggregation algorithms with M candidates and N voters, taking input from the ( , δ)-differentially private system defined in Section II-C.\nProof: The main idea of the proof is as follows. Divide the rank simplex into two parts: a “high error” region, denoted as RH , and a “low error” region, denoted as RL, as shown in Figure 1. RH consists of the thin slices of the simplex close to the boundary hyperplanes. RL occupies most of the simplex, but P (error|v ∈ RL) is upper bounded by the error rate at the point closest to the boundary. We choose an appropriate\nthickness τ of RH such that the sum of the error rate of the two parts is minimized. Thus we have,\nPMe =P M e in RH + P M e in RL ≤ ( M\n2\n) · P (Si, Sj switches order in RH) + PMe in RL\n=\n( M\n2\n) · 2 τ∫ 0 pD(l)P (βij · ω > l)dl + PMe in RL\n=\n( M\n2\n) · 2 τ∫ 0 pD(l)Q ( l σ̂||βij ||2 ) dl + PMe in RL (17)\nQ(·) is the tail probability of the standard normal distribution and is decreasing on [0,+∞). Thus for the “low error” region, we have,\nPMe in RL < P (v ∈ RL) ·Q (\nτ\nσ̂||βij ||2 ) < Q ( τ\nσ̂||βij ||2\n) (18)\nFrom Equation (8), (17), and (18), we have,\nPMe ≤ ( M\n2\n) · 2 τ∫ 0 pD(l)Q ( l σ̂ ) dl +Q ( τ σ̂ ) . (19)\nTheorem 2. For any positional ranking aggregation algorithm with M candidates and N voters, taking input from the ( , δ)differentially private system defined in Section II-C, the ranking error rate PMe (N) satisfies\nPMe (N) ≤ ( M\n2\n) M !− 1√\n2 τ +Q\n( Nτ√\n2 ln(2/δ)\n) ,∀τ > 0.\nProof: By Lemma 2, we have,\nPMe ≤ ( M\n2\n) · 2 τ∫ 0 pD(l)Q ( l σ̂ ) dl +Q ( τ σ̂ )\n≤ ( M\n2\n) · 2 τ∫ 0 pD(l)Q(0)dl +Q ( τ σ̂ )\n=\n( M\n2\n) · τ∫\n0\npD(l)dl +Q ( τ σ̂ ) (20)\nBy Lemma 1, for any positional rules, pD(l) ≤ pD(0). Hence we have,\nPMe ≤ ( M\n2\n) · τ∫\n0\npD(0)dl +Q ( τ σ̂ ) = ( M\n2\n) · pD(0)τ +Q ( τ σ̂ ) (21)\n5 For positional rules, all hyperplanes Hij pass through the (M ! − 1)-simplex centroid for any i, j ∈ {1, . . . ,M} since the profile at the centroid must be a tie for all candidates due to symmetry. From the literature in high dimensional geometry [12], we know that the largest cross section through the centroid of a regular M ! − 1-simplex is exactly the slice that contains M ! − 2 of its vertices and the midpoint of the remaining two vertices. The (M ! − 2)-measure of the cross section is √ M !/ (√ 2(M !− 2)! ) for the probability simplex. Since the (M ! − 1)-measure of the probability simplex is√ M !/(M !− 1)!, we have,\npD(0) ≤ √ M !/\n(√ 2(M !− 2)! ) √ M !/(M !− 1)! = M !− 1√ 2 (22)\nFrom Equations (21) and (22), and the fact that σ̂2 = 2 ln( 2δ )/ 2N2, we have\nPMe (N) ≤ ( M\n2\n) M !− 1√\n2 τ +Q ( τ σ̂ ) = ( M\n2\n) M !− 1√\n2 τ +Q\n( Nτ√\n2 ln(2/δ)\n) (23)\nBy taking the derivative with respect to τ , we can show that the right side of Equation (23) is minimized when\nτ =\n√ 2 ln(2/δ)\nN\n√ −2 ln √ π ln(2/δ)M(M − 1)(M !− 1)√\n2 N .\n(24) Remark: To better understand this upper bound, we can use a Q-function approximation to represent the result of Theorem 2. It is known that\nQ(x) ≤ e − x22 √\n2πx ,∀x > 0. (25)\nThis is a good approximation when x is large [14]. Thus we can rewrite Equation (23) as\nPMe (N) ≤ ( M\n2\n) M !− 1√\n2 τ +\n√ ln(2/σ̂)\n2 √ π Nτ\ne− ( Nτ)2\n4 ln(2/σ̂) ,∀τ > 0. (26)\nWe can further simplify the expression by letting τ = 2 √ lnN ln(2/δ)/( N):\nPMe (N) ≤ 1\nN\n(( M 2 ) (M !− 1) √ 2 lnN ln(2/δ)\n+\n1\n2 √ π lnN\n) .\n(27) It is shown in (27) that the error rate goes to 0 at least as fast as O( √ lnN N ) for fixed δ, ."
    }, {
      "heading" : "C. Asymptotic Error Rate",
      "text" : "In this section, we analyze the asymptotic error rate for any positional ranking rule. We start by showing a tighter bound on the general error rate that can be derived from the proof of Theorem 2.\nFig. 1: An example of Petrie polygon (skew orthogonal projections) of three candidates. Three hyperplanes, under Borda count ranking rule, separate the simplex into six polytopes.\nLemma 3. An upper bound for the ranking error rate of any ( , δ)-differentially private positional ranking system with M candidates and N voters is( M\n2\n)√ 2(M !− 1)Q ( Nτ\n2 √ 2 ln(2/δ)\n) τ +Q ( Nτ√\n2 ln(2/δ) ) for ∀τ > 0.\nProof: Since the Q-function is convex on [0,+∞), by Jensen’s Inequality, from Lemma 1 and Lemma 2, we have\nPMe (N) ≤ ( M\n2\n) · 2 τ∫ 0 pD(l)Q ( l σ̂ ) dl +Q ( τ σ̂ )\n≤ ( M\n2\n) · 2 τ∫ 0 pD(0)Q ( l σ̂ ) dl +Q ( τ σ̂ ) ≤ ( M\n2\n) · 2pD(0)Q ( τ 2σ̂ ) +Q ( τ σ̂ ) = ( M\n2\n)√ 2(M !− 1)Q ( Nτ\n2 √ 2 ln(2/δ)\n) τ\n+Q ( Nτ√\n2 ln(2/δ)\n) . (28)\nLemma 3 slightly improves the bound in Theorem 2. We use this lemma to assist the proof of the following Theorem.\nTheorem 3. For any positional ranking aggregation algorithm with M candidates, taking input from the ( , δ)-differentially private system defined in Section II-C,\nlim N→∞\nPMe (N) = 0\n6 for any given and δ.\nProof: This directly follows from Lemma 3 and the Bounded Convergence Theorem."
    }, {
      "heading" : "IV. SIMULATION RESULTS",
      "text" : "In this section, we use Borda count with three candidates as an example. Once the ranking rule is known, we can derive a tighter bound than the general error rate bound in Section III, because we know exactly what the pairwise comparison boundaries are. We will compare all upper bounds with the simulation error rates.\nIn Borda count, for every vote the candidate ranked first receives 1 point, the second receives 0.5 points, and the bottom candidate receives no points. The aggregated rank is sorted according to the total points each candidate receives. We list 3! = 6 permutations in the following order, and we will stick to this order for the rest of this paper: abc, acb, cab, cba, bca, bac. Let\nM =\n( 1 1 0.5 0 0 0.5\n0.5 0 0 0.5 1 1 0 0.5 1 1 0.5 0\n) . (29)\nThen we have ( Sa Sb Sc ) = Mv, (30)\nwhere v is defined in Section III-A and Sa, Sb, Sc are the aggregated score of candidates a, b and c respectively. The hyperplane Hab satisfies Sa = Sb,\n2v1 + 2v2 + v3 + v6 = v1 + v4 + 2v5 + 2v6 (31)\ni.e. Hab : v1 + 2v2 + v3 − v4 − 2v5 − v6 = 0 (32)\nSimilarly, we have\nHbc : v1 − v2 − 2v3 − v4 + v5 + 2v6 = 0 (33)\nHac : 2v1 + v2 − v3 − 2v4 − v5 + v6 = 0 (34)\nWith Equations (32), (33) and (34), we can compute the volume of the cross section made by the hyperplane cutting through the probability simplex (6), using methods proposed in [15]. Then an upper bound specifically for Borda count can be derived with a similar approach as Theorem 2 or Lemma 3.\nFigure 2 shows the simulation results of Borda count with 3 candidates and 2,000 voters, repeated 100,000 times. We set δ = 5× 10−4 (which is 0.1 divided by the number of voters), and plot the graph of error rate with taking values between 0.05 and 0.24. We compare the simulation results with the general upper bound derived in Theorem 2 and the improved upper bound in Lemma 3, as well as the ranking rule-specific upper bound described above.\nFigure 3 shows the simulation results for Borda count with 3 candidates with fixed , repeated 20,000 times. We set = 0.1 and δ = 0.1/N , where N is the number of voters. The number of voters varies from 1,000 to 100,000. The error vanishes fast with a growing number of voters, even if we set δ to be inversely proportional to the number of voters. We also\ncompare the simulation results with the general upper bound derived in Theorem 2 and the improved upper bound in Lemma 3, as well as the ranking rule-specific upper bound described above."
    }, {
      "heading" : "V. CONCLUSIONS",
      "text" : "In this paper, we apply the framework of differential privacy to rank aggregation by adding noise in the votes. We analyze the probability that the aggregated ranking becomes inaccurate due to the noise and derive upper bounds on the error rates of ranking for all positional ranking rules under the assumption that profiles are uniformly distributed. The bounds can be tightened using techniques in high dimensional polytope volume computation if we are given a specific ranking rule. Our results provide insights into the trade-offs between privacy and accuracy in rank aggregation.\n7"
    }, {
      "heading" : "VI. ACKNOWLEDGMENTS",
      "text" : "This research was supported in part by the Center for\nScience of Information (CSoI), a National Science Foundation (NSF) Science and Technology Center, under grant agreement CCF-0939370, by NSF under the grant CCF-1116013, by Air Force Office of Scientific Research, under the grant FA955012-1-0196, and by a research grant from Deutsche Telekom AG."
    } ],
    "references" : [ {
      "title" : "Differential privacy",
      "author" : [ "Cynthia Dwork" ],
      "venue" : "Automata, languages and programming, pp. 1–12. Springer, 2006.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Our data, ourselves: Privacy via distributed noise generation",
      "author" : [ "Cynthia Dwork", "Krishnaram Kenthapadi", "Frank McSherry", "Ilya Mironov", "Moni Naor" ],
      "venue" : "Advances in Cryptology-EUROCRYPT 2006, pp. 486–503. Springer, 2006.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "A guide to differential privacy theory in social network analysis",
      "author" : [ "Christine Task", "Chris Clifton" ],
      "venue" : "Proceedings of the 2012 International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2012). IEEE Computer Society, 2012, pp. 411–417.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Differentially private recommender systems: building privacy into the net",
      "author" : [ "Frank McSherry", "Ilya Mironov" ],
      "venue" : "Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2009, pp. 627–636.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A practical application of differential privacy to personalized online advertising",
      "author" : [ "Yehuda Lindell", "Eran Omri" ],
      "venue" : "IACR Cryptology ePrint Archive, vol. 2011, pp. 152, 2011.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Personalized social recommendations: accurate or private",
      "author" : [ "Ashwin Machanavajjhala", "Aleksandra Korolova", "Atish Das Sarma" ],
      "venue" : "Proceedings of the VLDB Endowment, vol. 4, no. 7, pp. 440–450, 2011.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "A fourier-theoretic perspective on the condorcet paradox and arrow’s theorem",
      "author" : [ "Gil Kalai" ],
      "venue" : "Advances in Applied Mathematics, vol. 29, no. 3, pp. 412–426, 2002.",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Improved bounds for computing kemeny rankings",
      "author" : [ "Vincent Conitzer", "Andrew Davenport", "Jayant Kalagnanam" ],
      "venue" : "AAAI, 2006, vol. 6, pp. 620–626.",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Rank aggregation methods for the web",
      "author" : [ "Cynthia Dwork", "Ravi Kumar", "Moni Naor", "Dandapani Sivakumar" ],
      "venue" : "Proceedings of the 10th international conference on World Wide Web. ACM, 2001, pp. 613–622.",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Calibrating noise to sensitivity in private data analysis",
      "author" : [ "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith" ],
      "venue" : "Theory of Cryptography, pp. 265–284. Springer, 2006.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Privacy, accuracy, and consistency too: a holistic solution to contingency table release",
      "author" : [ "Boaz Barak", "Kamalika Chaudhuri", "Cynthia Dwork", "Satyen Kale", "Frank McSherry", "Kunal Talwar" ],
      "venue" : "Proceedings of the twenty-sixth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems. ACM, 2007, pp. 273–282.",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Central slices of the regular simplex",
      "author" : [ "Simon Webb" ],
      "venue" : "Geometriae Dedicata, vol. 61, no. 1, pp. 19–28, 1996.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "An improved approximation for the gaussian q-function",
      "author" : [ "George K Karagiannidis", "Athanasios S Lioumpas" ],
      "venue" : "Communications Letters, IEEE, vol. 11, no. 8, pp. 644–646, 2007.",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Polytope volume computation",
      "author" : [ "Jim Lawrence" ],
      "venue" : "Mathematics of Computation, vol. 57, no. 195, pp. 259–271, 1991.",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 1991
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Mathematical guarantees are provided in [1] and [2].",
      "startOffset" : 40,
      "endOffset" : 43
    }, {
      "referenceID" : 1,
      "context" : "Mathematical guarantees are provided in [1] and [2].",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 2,
      "context" : "Differential privacy has gained popularity in various applications, such as social networks [3], recommendations [4], advertising [5], etc.",
      "startOffset" : 92,
      "endOffset" : 95
    }, {
      "referenceID" : 3,
      "context" : "Differential privacy has gained popularity in various applications, such as social networks [3], recommendations [4], advertising [5], etc.",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 4,
      "context" : "Differential privacy has gained popularity in various applications, such as social networks [3], recommendations [4], advertising [5], etc.",
      "startOffset" : 130,
      "endOffset" : 133
    }, {
      "referenceID" : 5,
      "context" : "In [6], the authors showed that good private social recommendations are achievable only for a small subset of users in the social network.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 6,
      "context" : "A ranking rule g is neutral if it commutes with permutations on C [7].",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 6,
      "context" : "A ranking rule g is anonymous if the “names” of the voters do not matter [7], i.",
      "startOffset" : 73,
      "endOffset" : 76
    }, {
      "referenceID" : 7,
      "context" : "In fact it is NP-Hard even for M = 4 [8].",
      "startOffset" : 37,
      "endOffset" : 40
    }, {
      "referenceID" : 8,
      "context" : "All positional rules satisfy anonymity and neutrality but fail the Condorcet criterion [9].",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 0,
      "context" : "In this paper, we consider a strong notion of privacy, differential privacy [1].",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 1,
      "context" : "[2] A random algorithm M satisfies ( , δ)differential privacy if for any neighboring datasets A and A′, and any subset S of possible outcomes Range(M), Pr[M(A) ∈ S] ≤ exp( )× Pr[M(A′) ∈ S] + δ.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "Differential privacy has been widely used in various applications [4], [5].",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 4,
      "context" : "Differential privacy has been widely used in various applications [4], [5].",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 9,
      "context" : "Much work has been done on developing differentially private algorithms [10], [11].",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 10,
      "context" : "Much work has been done on developing differentially private algorithms [10], [11].",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 1,
      "context" : "[2] Define M(A) to be f(A) + N (0, σId×d).",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 0,
      "context" : "We use Gaussian instead of Laplacian noise which achieves stronger -privacy [1], because Gaussian noise enjoys the nice property that any linear combination of jointly Gaussian random variables is Gaussian.",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 0,
      "context" : "The resulting vector v = q/N is the empirical distribution of votes, v ∈ [0, 1] .",
      "startOffset" : 73,
      "endOffset" : 79
    }, {
      "referenceID" : 11,
      "context" : "The density of the random variable Y = ∑M ! i=1 βjXj is [12]",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 11,
      "context" : "It is shown in [12] that",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 11,
      "context" : "This result is shown in [12] for H passing",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 11,
      "context" : "From the literature in high dimensional geometry [12], we know that the largest cross section through the centroid of a regular M ! − 1-simplex is exactly the slice that contains M ! − 2 of its vertices and the midpoint of the remaining two vertices.",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 12,
      "context" : "This is a good approximation when x is large [14].",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 13,
      "context" : "Hbc : v1 − v2 − 2v3 − v4 + v5 + 2v6 = 0 (33) Hac : 2v1 + v2 − v3 − 2v4 − v5 + v6 = 0 (34) With Equations (32), (33) and (34), we can compute the volume of the cross section made by the hyperplane cutting through the probability simplex (6), using methods proposed in [15].",
      "startOffset" : 267,
      "endOffset" : 271
    } ],
    "year" : 2014,
    "abstractText" : "The potential risk of privacy leakage prevents users from sharing their honest opinions on social platforms. This paper addresses the problem of privacy preservation if the query returns the histogram of rankings. The framework of differential privacy is applied to rank aggregation. The error probability of the aggregated ranking is analyzed as a result of noise added in order to achieve differential privacy. Upper bounds on the error rates for any positional ranking rule are derived under the assumption that profiles are uniformly distributed. Simulation results are provided to validate the probabilistic analysis. Keywords—Rank Aggregation, Privacy, Accuracy",
    "creator" : "LaTeX with hyperref package"
  }
}