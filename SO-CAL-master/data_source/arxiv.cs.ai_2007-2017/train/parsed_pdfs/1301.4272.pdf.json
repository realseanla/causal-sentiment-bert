{
  "name" : "1301.4272.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "View-based propagation of decomposable constraints",
    "authors" : [ "Marco Correia", "Pedro Barahona" ],
    "emails" : [ "mvc@fct.unl.pt", "pb@fct.unl.pt" ],
    "sections" : [ {
      "heading" : null,
      "text" : "{mvc,pb}@fct.unl.pt CENTRIA - Centre for Artificial Intelligence Departamento de Informática FCT/UNL Quinta da Torre 2829-516 CAPARICA - Portugal Tel. (+351) 21 294 8536 FAX (+351) 21 294 8541\nView-based propagation of decomposable constraints\nMarco Correia Pedro Barahona\nJune 1, 2017\nThe final publication is available at http://link.springer.com\nar X\niv :1\n30 1.\n42 72\nv1 [\ncs .A\nI] 1\n7 Ja\nn 20\n13\nConstraints that may be obtained by composition from simpler constraints are present, in some way or another, in almost every constraint program. The decomposition of such constraints is a standard technique for obtaining an adequate propagation algorithm from a combination of propagators designed for simpler constraints. The decomposition approach is appealing in several ways. Firstly because creating a specific propagator for every constraint is clearly infeasible since the number of constraints is infinite. Secondly, because designing a propagation algorithm for complex constraints can be very challenging. Finally, reusing existing propagators allows to reduce the size of code to be developed and maintained. Traditionally, constraint solvers automatically decompose constraints into simpler ones using additional auxiliary variables and propagators, or expect the users to perform such decomposition themselves, eventually leading to the same propagation model. In this paper we explore views, an alternative way to create efficient propagators for such constraints in a modular, simple and correct way, which avoids the introduction of auxiliary variables and propagators."
    }, {
      "heading" : "1 Introduction",
      "text" : "Most specialized filtering algorithms, i.e. propagators, available in constraint solvers target constraints with a specific algebraic structure. When the problem to be solved has a constraint for which no propagator exists one option is to decompose it into some logically equivalent formula involving simpler constraints. This can be done either by the user, or automatically if the solver supports it, by introducing a set of auxiliary variables and propagators. In practice the constraints which are most often decomposed are those involving multiple distinct arithmetic or logical expressions. Throughout this paper we will refer to constraints for which no specialized filtering algorithm is appropriate, and which are therefore considered for decomposition, as decomposable constraints. In this paper we describe view-based propagation - a method for propagating decomposable constraints that avoids the use of auxiliary variables and propagators. Although this method does not improve the strength of the propagation algorithm, it results in significantly faster propagation compared with the decompositions obtained with auxiliary variables for the specific class of bounds completeness. An important aspect of view based propagation is that it does not preclude the introduction of auxiliary variables when required, meaning it can be combined with other modeling techniques such as subexpression substitution or variable elimination. It can also be used with specialized propagation algorithms, e.g. used in global constraints (or even replace them), allowing the exploitation of the decomposition approach combined with the efficiency of such dedicated algorithms. The problem of propagating decomposable constraints may be approached using knowledge compilation techniques [15, 7]. These methods create a compact tractable representation of the set of solutions to the constraint and apply a general propagation algorithm which filters tuples not found in this set. However, due to its expensive runtime complex-\nity applying these methods with arithmetic expressions is only practical when expressions have small domains. In contrast, view-based propagators for decomposable constraints, extending previous proposals for propagators (e.g. indexical constraints [17, 6]), do not require exponential memory. Rina Dechter [22] approaches decomposition of constraints from a different perspective. There, the full constraint network is taken into consideration in order to obtain generic global search algorithms with theoretical performance guarantees. The propagation is still time or space exponential but depends exclusively on specific graph-based parameters of the graph describing the constraint network. In contrast, we focus on the decomposition of a single constraint into simpler constraints for which local propagation algorithms are applied independently. View based-propagation was introduced in [10] and [24]. The former presents a general overview of a constraint solver incorporating type polymorphism and its application for creating propagators from decomposable expressions. The latter coins the term view (we originally called them polymorphic constraints), and describes how it can be used for creating generic propagator implementations, that is, propagators which can be reused for different constraints. The present work can be seen as an extension of [26, 25] for allowing the use of a particular kind of view over functions involving multiple variables ([26] restricts the use of views to injective functions and therefore to unary functions mostly). We adapted and extended its formalization to present and prove important properties of our model. Additionally, our framework employs views as modeling primitives by automatically deriving new propagators for decomposable constraints present in a problem. In contrast, views as described in [26] are used essentially as a development tool for increasing the number of available propagators in the library. Compilers for constraint modeling languages [21, 11, 1] generate efficient constraint solvers from a high level description of a constraint problem. The solver generation process may avoid introducing auxiliary variables for a decomposable constraint whenever a specific propagator is available. In this paper we will show that, in the absence of a specific propagator for a given constraint, a view-based propagator may be an appealing alternative. Indexicals [17, 6] and constrained expressions [18] are conceptually close to the idea of views described in this paper. Like views, these techniques intend to support automatic propagation of decomposable constraints, however they require extra work from the user (in the case of indexicals) or the CPU (in the case of constrained expressions) when compared to our approach, These (dis)similarities will be discussed after the necessary background is presented. This paper is organised as follows. The following section overviews the main concepts of constraint programming, introducing domains and domain approximations as well as constraint propagators and their main properties. Section 3 presents some examples of decomposable constraints and how to express propagators for such constraints, discussing the properties of various approximations, namely soundness and completeness. It also introduces box view propagators, the propagation model that will be used throughout the paper. Section 4 briefly addresses two alternatives for implementing box views in strongly\ntyped programming languages (exploiting either subtype or parametric polymorphism). Section 5 presents experimental results for a comprehensive set of benchmarks. The paper concludes in section 6 with a summary of the results obtained and some suggestions for future work."
    }, {
      "heading" : "2 Background: Domains and Propagators",
      "text" : "This section presents the necessary concepts and notation for describing propagation in detail."
    }, {
      "heading" : "2.1 Constraint Satisfaction Problems",
      "text" : "A constraint satisfaction problem (CSP) is a triple 〈X,D,C〉 where X is a finite set of variables, D is a finite set of variable domains, and C is a finite set of constraints. We refer to the set of constraints involving some variable x ∈ X as C (x) and the set of variables in some constraint c ∈ C as X (c). An n-ary constraint (on variables x1, ... xn) is a set of tuples on its n variables (ntuples). Although tuples of integers will be most often used, we only expect that the elements in a tuple are from totally ordered types. In general, we will denote an n-tuple as xn and a set of n-tuples as Sn (or simply x and S respectively when there is no ambiguity on its arity) and the set of tuples of constraint c as con (c). Implicitly, a constraint restricts the values of each of its variables. Denoting by proji (S n) or simply Sni the projection of the set of tuples to their i-th element, constraint c restricts its i-th variable to take values in con (c)i. In particular, the variable domain constraint D (x) is a special case of a unary constraint, restricting the initial values of variable x."
    }, {
      "heading" : "2.2 Domain Approximations",
      "text" : "Following [26] we generalise the notion of domains from single variables to more general n-ary domains and characterize their approximations. First we denote by conv ( S1 ) the convex hull of some set S1 from an ordered type D i.e.\nconvD ( S1 ) = { z ∈ D : min ( S1 ) ≤ z ≤ max ( S1 )}\nWe introduce now important tuple set operations: Cartesian approximation (see for example [2]) and box approximation [4].\nDefinition 2.1 (Cartesian approximation). The Cartesian approximation Sδ (or δapproximation) of a tuple set S ⊆ Zn is the smallest Cartesian product which contains S, that is:\nSδ = proj1 (S)× . . .× projn (S)\nDefinition 2.2 (Box approximation). The box approximation Sβ(D) (or β-approximation) of a tuple set S ⊆ Dn is the smallest n-dimensional box containing S, that is:\nSβ(D) = convD (proj1 (S))× . . .× convD (projn (S))\nWe will address integer and real box approximations, i.e. Sβ(Z) or Sβ(R), and denote these box approximations by Sβ and Sρ, respectively. Additionally, we will use the identity approximation in order to simplify notation.\nDefinition 2.3 (Identity approximation). The identity operator transforms a tuple set in itself, i.e. S1 = S.\nProposition 2.4. Domain approximations have the following properties, for any n-tuple sets S, S1, S2 ⊆ Dn and Φ ∈ {1, δ, β, ρ},\n1. idempotency: ( SΦ )Φ = SΦ,\n2. monotonicity: S1 ⊆ S2 =⇒ SΦ1 ⊆ SΦ2 , and\n3. closure under intersection: SΦ1 ∩ SΦ2 = ( SΦ1 ∩ SΦ2 )Φ. Note that in general it is not the case that SΦ1 ∩ SΦ2 = (S1 ∩ S2) Φ.\nWe may now define approximation domains, or Φ-domains, as follows\nDefinition 2.5 (Φ-domain). A tuple set S is a Φ-domain iff S = SΦ (for Φ ∈ {1, δ, β, ρ}).\nDefinition 2.6. A domain S1 is stronger than a domain S2 (S2 is weaker than S1), iff S1 ⊆ S2. S1 is strictly stronger than S2 (S2 is strictly weaker than S1) iff S1 ⊂ S2.\nThe following lemma (proofs for most propositions and lemmas in this paper are given in [8]) shows how the previously defined approximations are ordered for a given tuple set (or constraint).\nLemma 2.7. Let S ⊆ Zn be an arbitrary tuple set. Then,\nS = S1 ⊆ Sδ ⊆ Sβ ⊆ Sρ"
    }, {
      "heading" : "2.3 Propagation",
      "text" : "Definition 2.8 (Propagator). A propagator (or filter) implementing a constraint c ∈ C is a function πc : ℘ (Dn) → ℘ (Dn) that is contracting (i.e. πc (S) ⊆ S for any tuple set S ⊆ D) and sound (it never removes tuples from the associated constraint, i.e. con (c) ∩ S ⊆ πc (S)).\nWe will assume that propagators are monotonic, i.e. πc (S1) ⊆ πc (S2) if S1 ⊆ S2, although this property is not mandatory in modern constraint solvers, as shown in [26]. Two other properties of propagators are of interest: idempotency and completeness. A propagator πc is idempotent iff πc (πc (S)) = πc (S) for any tuple set S. We denote by π?c the iterated application of propagator πc until a fixpoint is reached (hence πc (π?c (S)) = π?c (S)). Additionally, if propagator πc is idempotent for any tuple set S we will refer to it as π?c . The contracting condition alone sets a very loose upper bound on the output of a propagator. Many functions meet these requirements without performing any useful filtering (e.g. the identity function). In general, useful propagators aim at being complete with respect to some domain, thus achieving some consistency on the constraint associated with the propagator.\nDefinition 2.9 (Propagator completeness). A propagator πc for a constraint c ∈ C is ΦΨ-complete, denoted as πΦΨc , iff\nπ?c (S) ⊆ ( con (c) ∩ SΦ )Ψ We should note that when considering real box approximations, con (c) in the above definition corresponds to the relaxation of constraint c to the real numbers [26]. Table 1 shows the correspondence between the constraint consistencies that are traditionally considered [26, 22, 20, 5] and the different ΦΨ-completeness of the propagators.\nExample 2.10 (Propagator completeness taxonomy). A hierarchy of the different types of ΦΨ-completenesses described is shown below, where propagators at the start of the arrows are stronger than those at their end (double arrow denotes strictly stronger propagators for the shown tuples). The figure considers constraint c = [2x+ 3y = z], and the arrows are labelled with tuple sets S = Sx × Sy × Sz, where the crossed-out values are removed by the stronger but not by the weaker propagator. For example, when applied to a domain S = {〈0, 1〉 , 〈0〉 , 〈0, 1, 2〉}, a domain (δδ-complete) propagator is able to prune tuples 〈0, 0, 1〉 and 〈1, 0, 1〉 that a bounds(D) (δβ-complete) propagator cannot.\ndomain\nbounds(D)\nbounds(Z)\nbounds(R)\nrange\nSx = {0, 1} Sy = {0}\nSz = {0, 1/, 2}\nSx = {0, 1/} Sy = {0, 1} Sz = {0, 3}\nSx = {0, 1/} Sy = {0, 1} Sz = {0, 3}\nSx = {0} Sy = {0, 1} Sz = {0, 2/, 3}\nSx = {0, 1} Sy = {0, 1} Sz = {1/, 2, 3}\nSx = {0} Sy = {0, 1} Sz = {0, 1/, 3}\nSx = {0, 1/} Sy = {0, 1} Sz = {0, 3}\nNotice that propagators achieving bounds(D) and range consistency are incomparable, as illustrated by the tuple sets that label the two single arrows with opposing directions.\nNote also that bounds(R) completeness is weaker than bounds(Z) completeness, as shown in the figure. In particular, whereas a bounds(Z) complete propagator prunes value z = 1 from the tuples in the figure, this is not the case with bounds(R) complete propagators since 〈0.5, 0, 1〉 is a solution of the relaxation of constraint to the real numbers."
    }, {
      "heading" : "3 Views for Propagation of Decomposable Constraints",
      "text" : "This section describes propagation of decomposable constraints as a function of views, an abstraction representing the pointwise evaluation of a function over a given (tuple) set. First we characterize decomposable constraints (3.1). Then we introduce views (3.2), and show that they may be used to express sound propagators for decomposable constraints (3.3). Section 3.4 briefly discusses propagation strength of view-based propagators, a subject that will be revisited later in section 5.3.4 after the implementation details are presented. Finally, we introduce box view-based propagators (3.5), a special case of view-based propagators that may be implemented efficiently in a straightforward way, as described in the rest of the paper."
    }, {
      "heading" : "3.1 Decomposable constraints",
      "text" : "As previously discussed, constraint solvers do not have a specific propagator for all possible constraints. Constraints that cannot be captured by a single specific propagator are usually decomposed into a logically equivalent conjunction of simpler constraints for which specific propagators exist. Many types of constraints used in practice are decomposable in this sense. Below are some examples.\nExample 3.1 (Arithmetic constraints). These are probably the most common type of decomposable constraints. Examples are constraints involving a sum of variables, e.g. [ ∑ i xi = k], a linear combination, e.g. [ ∑ i aixi ≥ k], or a product, e.g. [ ∏ i xi = k]. While some solvers do have specific propagators for these constraints (e.g. by using the notion of linear relation), that approach does not work for more irregular arithmetic constraints that may include an arbitrary combination of arithmetic operators, such as for example [|x1 − x2| = 2x3].\nExample 3.2 (Boolean constraints). Boolean constraints involve Boolean domain variables or expressions, for example a disjunction of variables [ ∨ i xi], or more complex ex-\npressions on Boolean constraints such as disjunctions [ ∨ i (xi > 0)], logical implications [x > 0⇒ y < 0] or equivalences [x > 0⇔ y].\nExample 3.3 (Counting constraints). Counting constraints restrict the number of occurrences of some values within a collection of variables, for example the exactly(x, v, c) constraint [ ∑ i (xi = v) = c], or the among(x, V, c) constraint [ ∑ i (xi ∈ V ) = c].\nExample 3.4 (Data constraints). Also known as ad-hoc constraints, they represent an access to an element of a data structure (a table, a matrix, a relation) [3]. The most common constraint in this class is the element(x, i, y) constraint enforcing [xi = y] where i is a variable. Decomposable constraints involving this constraint are for example [xi ≥ y] or [xi − xj ≥ 0].\nWe propose to express decomposable constraints as a composition of functions. For this purpose we will make extensive use of functions that evaluate to tuples, i.e. f : Zn → Zk where k ≥ 1, together with tuple projections, and the usual composition and Cartesian product of functions:\nDefinition 3.5 (Functional composition). Functional composition is denoted by operator ◦ as usual: (f ◦ g) (x) = f (g (x)).\nDefinition 3.6 (Cartesian product of functions). Cartesian product of functions is denoted by operator × as follows: (f × g) (x) = 〈f (x) , g (x)〉. If x is a tuple we may write\n(f × g) (x1, . . . , xn) = 〈f (x1, . . . , xn) , g (x1, . . . , xn)〉\nWe exemplify our approach to decomposition for some of the constraints given above. In the following examples let x, xi and y represent variables, x represent a tuple of variables xi, a a constant, and pi (x) = xi the projection operator.\nExample 3.7 (Equality constraint). Let constraint ceq (x) = [x1 = x2] be the binary constraint stating that variables x1 and x2 must take the same value. A unary equality constraint ceqc (x, a) = [x = a] may be obtained by ceqc = [ceq ◦ (p1 × fa)], where fa (x) = a.\nExample 3.8 (Sum constraint). Let f (x) = x1 + x2. A sum of three variables is represented by f ◦ (f × p3). The generalization to a sum of n variables is defined as\ng = f ◦ (f × p3) ◦ (f × p3 × p4) ◦ . . . ◦ (f × p3 × p4 × . . .× pn)\nTherefore we may decompose a constraint for a sum of n variables csum0 (xn) = [ ∑n\ni xi = 0] as csum0 = [ceq0 ◦ g], where ceq0 (x) = ceqc (x, 0) defined in the previous example.\nExample 3.9 (Linear constraint). A linear constraint clin0 (an,xn) = [ ∑n\ni=1 aixi = 0] may be decomposed as follows. Let f1, . . . , fn : Zn → Z, where fi (xn) = aixi. Then, clin0 = [csum0 ◦ (f1 × . . .× fn)], where csum0 is defined in the previous example.\nExample 3.10 (Arbitrary arithmetic constraint). Let f (x) = x1 − x2, g (x) = |x|, h (x) = 2x. The arithmetic constraint c ( x3 ) = [|x1 − x2| = 2x3] may be represented as\nc = [ceq ◦ ((g ◦ f ◦ (p1 × p2))× (h ◦ p3))]\nExample 3.11 (Exactly constraint). This constraint, represented by [ ∑\ni (xi = v) = c], may be obtained similarly to example 3.9 but where fi (xn) = [xi = v] and the constraint ceqc is used instead of ceq0."
    }, {
      "heading" : "3.2 Views",
      "text" : "In most constraint solvers, domains of subexpressions occurring in constraints are not directly available to propagators, which are designed to work exclusively with variable domains. In these solvers, an offline modeling phase is responsible for obtaining an equivalent CSP where all constraints are flattened, that is where each subexpression appearing in a constraint is replaced by an auxiliary variable whose domain is the domain of the subexpression.\nAlternatively, we present a conceptual model that considers explicit subexpression domains while abstracting on how they are computed and maintained. This will allow us to perform a theoretical analysis of the propagation on the constraint decomposition, regardless of the method used for representing the subexpression domains. We begin by defining a view as an abstraction which captures the domain of a subexpression in a constraint.\nDefinition 3.12 (View). A view over a function f : Zn → Zk is a pair ϕ = 〈 ϕ+f , ϕ − f 〉 of two functions, the image function ϕ+f : ℘ (Z n) → ℘ ( Zk ) , and the object function\nϕ−f : ℘ ( Zk ) → ℘ (Zn), defined as\nϕ+f (S n) =\n{ f (xn) ∈ Zk : xn ∈ Sn } , ∀S ⊆ Zn\nϕ−f\n( Sk ) = { xn ∈ Zn : f (xn) ∈ Sk } , ∀S ⊆ Zk\nA view ϕf is therefore defined by considering the pointwise application of f over a given set. The image function computes a set of images of f , that is the set resulting from applying f to all the points in the given set. The object function does the inverse transformation, computing the set of objects of f for which its image is in the given set.\nExample 3.13. Consider the view over function f (x) = x+ 1 and the unary tuple set S = {1, 2, 3}:\nϕ+f ({1, 2, 3}) = {2, 3, 4} ϕ−f ({2, 3, 4}) = {1, 2, 3}\nNotice some similarities of views with indexicals introduced in [17, 6] to create propagators for arithmetic constraints. An indexical roughly corresponds to the image function ϕ+ in the sense that it computes the domain of an expression. However, unlike views, indexicals do not define the inverse transformation ϕ− and therefore are less powerful - representing a decomposable constraint using indexicals requires the additional definition of the projection of the object function for each variable in the constraint, even if this projection may be performed automatically as shown in [6]. As discussed earlier, propagating a constraint may require consulting and updating the domain of a subexpression. A view over the subexpression defines these operations:\nExample 3.14. Consider a view ϕg over function g (x, y) = x + y, and constraint c = [x1 + x2 = x3] on variables x1, x2, x3 with domains D (x1) = D (x2) = D (x3) = {1, 2, 3}. Function ϕ+g may be used to compute the subexpression domain D (x1 + x2) from the variable domains D (x1) and D (x2), while function ϕ−g may be used to specify the set of values for the variables x1, x2 that satisfy constraint c.\nϕ+g (D (x1)×D (x2)) = [2 . . . 6] ϕ−g ([2 . . . 6]) = { 〈x, y〉 ∈ Z2 : x+ y ∈ [2 . . . 6] }\nPropagation consists of removing inconsistent values from the domain of the variables. In this sense, the computation of ϕ−f , i.e. the set of consistent assignments, must be intersected with the original domain to guarantee that the propagation is contracting. The following definition captures exactly that.\nDefinition 3.15 (Contracting object function). Let S1 ∈ Zn, S2 ∈ Zk, be two arbitrary tuple sets and f : Zn → Zk an arbitrary function. Then,\nϕ̂f (S2, S1) = ϕ − f (S2) ∩ S1\nExample 3.16. The result of evaluating and updating the domain D (x1 + x2), as defined in the previous example, may be formalized using views as follows:\nϕ+g (D (x1)×D (x2)) = [2 . . . 6] ϕ̂g ([2 . . . 6] , D (x1)×D (x2)) = D (x1)×D (x2)"
    }, {
      "heading" : "3.3 View-based Propagators",
      "text" : "Propagators for decomposable constraints may be obtained by exploring the concept of views introduced in the previous section. As illustrated above, an n-ary decomposable constraint may be regarded as a special case of functions of the form c ◦ f where f is a tuple-function f : Zn → Zk and c a constraint, mapping k-tuples to the Boolean domain.\nDefinition 3.17. Let c be a k-ary constraint for which πc is a propagator and f be a tuple-function f : Zn → Zk. A view-based propagator for constraint c ◦ f , denoted as π̌c◦f , is obtained by\nπ̌c◦f (S n) = ϕ̂f ( π11?c ( ϕ+f (S n) ) , Sn ) Example 3.18. Consider the view-based propagator for the constraint d = [x1 + x2 = x3], and let us analyse the propagation achieved on the tuple set S1 = {〈1, 2, 3〉 , 〈4, 5, 6〉}. We note that the constraint d can be decomposed into a simpler constraint c = [x1 = x2] and function g = f × p3, where function g is the Cartesian product of function f (x) = x1 + x2 applied to the 2 initial elements of the tuples 〈x1, x2, x3〉 and p3 the projection to their third element. Function ϕ+g applies the addition and projection operations to the original set, S2 = ϕ+g (S1) = {〈3, 3〉 , 〈9, 6〉}. The resulting set S2 is filtered by propagator S3 = π11?c (S2) = {〈3, 3〉}, and transformed back into ϕ̂g (S3, S1) = {〈1, 2, 3〉}."
    }, {
      "heading" : "3.4 Approximate view-based propagators",
      "text" : "In this section we present approximate view-based propagators and relate them to the completeness classes introduced in table 1 on page 7.\nDefinition 3.19 (ΦΨ−complete view-based propagator). A ΦΨ view-based propagator for a constraint c ◦ f is defined as\nπ̌ΦΨc◦f (S) = ϕ̂f ( π11?c ◦ ϕ+f ( SΦ ) , SΦ )Ψ ∩ S, where Φ,Ψ ∈ {1, δ, β}\nIntuitively, ΦΨ-completeness of a view-based propagator for a decomposable constraint of the form c ◦ f1 · · · ◦ fm is obtained by approximating the input of the image function ϕ+f and the output of the object function ϕ̂f , and not approximating the remaining view functions or propagators involved. For these view-based propagators the following property can be proved [8].\nProposition 3.20. A ΦΨ view-based propagator for a constraint c ◦ f is a ΦΨ-complete and idempotent propagator for c ◦ f .\nThe use of the above proposition is rather limited since it applies only to a propagator πc that is 11-complete and idempotent. Achieving such completeness is usually intractable in time and/or space in general, inequality constraints being a notable exception. Moreover other approximations are performed in practical view-based propagators, which are now presented."
    }, {
      "heading" : "3.5 Box view-based propagators",
      "text" : "A box view-based propagator (or simply box view propagator) is a relaxation of a ββcomplete view-based propagator. In addition to the β-approximations already presented, it\n1. β-approximates the output of the image function ϕ+,\n2. β-approximates the input of the contracting object function ϕ̂,\n3. uses a ββ-complete and idempotent propagator for c\nTo simplify its formalization, we use the following notation for special applications of Φ-approximations to views:\nΦ+f (S) = ( ϕ+f ( SΦ ))Φ\nΦ̂f (S1, S2) = ( ϕ̂f ( SΦ1 , S Φ 2 ))Φ We may now formalize box view-based propagators.\nDefinition 3.21 (Box view-based propagator). A box view-based propagator for a constraint c ◦ f is defined as\nπ c◦f (S) = β̂f ( πββ?c ( β+f (S) ) , S ) ∩ S\nBox view-based propagators allow very efficient implementations since β-domains may be stored in constant space (the domain is fully characterized by its lower and upper bound), and computing views on β-domains does not depend on the size of the domain for most functions.\nExample 3.22. Let f (x) = |x| and S1, S2 ⊆ Z two arbitrary sets of unary tuples, and assume bS2c ≥ 0. By definition,\nβ+f (S1) = { |x| : x ∈ Sβ1 }β β̂f (S2, S1) = { x : |x| ∈ Sβ2 ∧ x ∈ S β 1\n}β This definition may suggest that evaluating these functions would take linear time, but in fact they may be computed in constant time assuming that finding the minimum and maximum of S1, S2 takes constant time:\nβ+f (S1) =  [bS1c . . . dS1e] ⇐ bS1c > 0 [−dS1e . . .− bS1c] ⇐ dS1e < 0 [0 . . .max (−bS1c , dS1e)] otherwise\nβ̂f (S2, S1) =  [max (bS2c , bS1c) . . .min (dS2e , dS1e)] ⇐ bS1c > 0 [max (−dS2e , bS1c) . . .min (−bS2c , dS1e)] ⇐ dS1e < 0 [max (−dS2e , bS1c) . . .min (dS2e , dS1e)] otherwise\nA thorough analysis of the propagation achieved with box view propagators is complex and dependent on the constraints involved (see [8]). Here we only present a sufficient condition for a box view based propagator to be bounds(R) complete.\nProposition 3.23. A box view-based propagator for c ◦ f is always at least bounds(R) complete if f is continuous.\nProof.\nπ c◦f (S) =β̂f ( πββ?c ( β+f (S) ) , S ) ∩ S (def. 3.21)\n=β̂f\n(( con (c) ∩ ( β+f (S) )β)β , S ) ∩ S (def.2.9)\nGiven that ( β+f (S) )β = β+f (S) and β − f ( Sβ ) = β−f (S),\nπ c◦f (S) =β̂f ( con (c) ∩ β+f (S) , S ) ∩ S\nSince con (c) ⊆ conR (c), Sβ ⊆ Sρ for any S ⊆ Zn, and all operators are monotonic, π c◦f (S) ⊆ ρ̂f ( conR (c) ∩ ρ+f (S) , S ) ∩ S\nNote that when f is continuous the following is true, ρ+f (S) = ( ϕ+f (S ρ) )ρ = ϕ+f (S ρ)\nρ̂f (S1, S2) = (ϕ̂f (S ρ 1 , S2)) ρ = (ϕ̂f (S1, S2)) ρ\nRewriting the above expression using these equivalences gives, π c◦f (S) ⊆ ( ϕ̂f ( conR (c) ∩ ϕ+f (S ρ) , S ))ρ ∩ S\n⊆πρρ?c◦f (S) (def.2.9)\nSo far we have been discussing view based propagators obtained from composition of views with propagators that are idempotent. Some practical propagators are nonidempotent (or have non-idempotent implementations) for efficiency reasons. Unfortunately, the strength of a view based propagator for c◦f is influenced by the idempotency of the underlying propagator πc.\nProposition 3.24. A box view-based propagator for a constraint c ◦ f is stronger than a corresponding view-based propagator using a non-idempotent propagator πc for c. Moreover, it may be strictly stronger.\nThe fact that a view-based propagator for a constraint c ◦ f with an idempotent propagator for c achieves at least the same pruning as with a non-idempotent propagator for c is not surprising since π?c is always stronger than πc and all other involved functions and operators are monotonic. The following example shows it can indeed achieve more pruning.\nExample 3.25. Let c ◦ f = [2 · x1 · x2 = x3] be a decomposable constraint, where c = [2 · x1 = x2] and f (x1, x2, x3) = 〈x1 · x2, x3〉. A box view-based propagator π c◦f applied to D = [2 . . . 3] × [2 . . . 3] × [9 . . . 15] leaves the domains of x1 and x2 unchanged, but prunes the domain of x3 since\nβ+f (D) = [4 . . . 9]× [9 . . . 15]\nπββ?c ([4 . . . 9]× [9 . . . 15]) = [5 . . . 7]× [10 . . . 14] β̂f ([5 . . . 7]× [10 . . . 14] , D) ∩D = [2 . . . 3]× [2 . . . 3]× [10 . . . 14]\nNow consider the following non-idempotent propagator πββc for the same constraint c:\nπββc = { D (x3) ← D (x3) ∩ [bD (x1 × x2)c × 2 . . . dD (x1 × x2)e × 2] D (x1 × x2) ← D (x1 × x2) ∩ [bD (x3)c /2 . . . dD (x3)e /2]\nUnlike in the previous case, the box view propagator obtained from composition with the non-idempotent propagator πc would not achieve any pruning, since\nβ+f (D) [4 . . . 9]× [9 . . . 15]\nπββc ([4 . . . 9]× [9 . . . 15]) = [5 . . . 7]× [9 . . . 15] β̂f ([5 . . . 7]× [9 . . . 15] , D) ∩D = [2 . . . 3]× [2 . . . 3]× [9 . . . 15]\nThe reason for this may be explained as follows: not being idempotent, the change in the domain of D (x1 × x2) is not immediately propagated back to D (x3) but instead is approximated back to the initial value by the encapsulating view functions, β+f and β̂f . Therefore, the subsequent application of the box view propagator to have no effect. The above proposition explains the differences in propagation strength between decompositions using auxiliary variables and view objects. With variable decomposition, non-idempotent propagators for sub-expressions will always act as idempotent propagators: sub-expressions are propagated independently and will be added to the propagation queue until a fix point is reached. In theory this means that decompositions using auxiliary variables may attain stronger propagation. In practice these differences do not seem to be very significant, and are compensated by other factors as the experimental results presented later suggest."
    }, {
      "heading" : "4 Implementation",
      "text" : "Implementation of views for an arbitrary expression may be complex, depending on the type of approximations the view is considering. For the specific case of box view propagators, the code that implements a view over an expression e should be no more complex than the code for a propagator of e = z, where e is an expression involving variables (i.e. not other expressions) and z is a variable. For example, implementing a box view for the expressions e1 + e2, or e1 × e2, where ei are expressions is very similar to implementing the propagator for x1 + x2 = x3, or x1 × x2 = x3, where xi are variables. The simplicity of these implementations is in fact a key advantage of box view propagators. The following sections provide some examples of such implementations."
    }, {
      "heading" : "4.1 Box view propagators in strongly typed programming languages",
      "text" : "Implementing our conceptual box view propagator in a strongly typed programming language is possible if some sort of type polymorphism support is available in the language. Most if not all popular strongly typed programming languages have built in support for subtype polymorphism, either by overloading or through the use of inheritance in the case of object oriented programming languages. In addition, parametric polymorphism has been introduced in some object oriented programming languages such as C++, Java and C#. Parametric polymorphism allows aggressive compiler optimizations, namely function code inlining (i.e. replacing function calls by the actual code), which has a significant impact on performance as we will see later. We have implemented box view propagators in C++. Since C++ supports both subtype and parametric polymorphism, we were able to integrate the two variants of our model within the constraint solver engine, therefore obtaining a fair experimental platform."
    }, {
      "heading" : "4.1.1 Subtype polymorphism",
      "text" : "Subtype polymorphism is available in C++ through the use of inheritance. In this setting we need to define an abstract interface for box view objects:\nclass Box { virtual int getMin ()=0; virtual int getMax ()=0; virtual bool updMin( int i )=0; virtual bool updMax( int i )=0; } ;\nA box view object for a specific function implements the box view object interface (for convenience the update methods return whether the operation does not result in an empty box).\nExample 4.1. The following class defines the subtype polymorphic box view object for the addition of two box view objects.\nclass Add2 : Box { Add2(Box ax , Box ay ) : x ( ax ) , y ( ay ) {} virtual int getMin ( ) { return x . getMin()+y . getMin ( ) ; } virtual int getMax ( ) { return x . getMax()+y . getMax ( ) ; } virtual bool updMin( int i ) { return x . updMin( i−y . getMax ( ) ) and y . updMin( i−x . getMax ( ) ) ; } virtual bool updMax( int i ) { return x . updMax( i−y . getMin ( ) ) and y . updMax( i−x . getMin ( ) ) ; } Box x ; Box y ; } ;\nWe should note that for the sake of simplicity we omit details on the efficient copy and garbage collection of box view objects. Compiling a given constraint into subtype polymorphic box view objects is straightforward since in C++ expressions are evaluated bottom-up. Below are a set of convenience functions which may be used to create subtype polymorphic view box objects for a binary addition.\nAdd2 add (Box x , Box y ) { return Add2(x , y ) ; }\nAdd2 operator+(Box x , Box y ) { return Add2(x , y ) ; }\nThe user may then create box view objects for arbitrary expressions in C++ using a clean syntax:\nDomVar a , b , c ; a+b∗c ; add (a , mul (b , c ) ) ;\nFrom what we could infer from the available documentation, constrained expressions introduced in ILOG Solver [18] correspond to box view objects implemented using subtype polymorphism as shown above."
    }, {
      "heading" : "4.1.2 Parametric polymorphism",
      "text" : "The fact that the C++ compiler evaluates expressions bottom-up makes the implementation of parametric polymorphic view objects slightly more complex, since they need to be compiled top-down. The solution we propose breaks the compilation algorithm in two phases. The first phase creates a syntactic representation of the expression, called a type parametric relation object, using the natural bottom-up evaluation order intrinsic in the language. Type parametric relations capture the data and the type of the objects and operations involved in the constraint. After the full constraint is compiled, we use the obtained relation object for instantiating the required view objects. We will use templates for defining type parametric relations, since this is the language mechanism available in C++ to support type parametric polymorphism. The following\ntemplate defines generic binary relations, where “Op” is a type describing the operator, and “X” and “Y” are types of the operands.\ntemplate<class Op, class X, class Y> class Rel2 {\nRel2 (X x , Y y ) : x (x ) , y (y ) {} X x ; Y y ;\n} ;\nSince any expression may be transformed to a relation object with a unique type, we can create view objects over arbitrary expressions by defining templates over relation objects.\nExample 4.2. The following template defines the parametric polymorphic box view object for the addition of two arbitrary objects:\ntemplate<class X, class Y> class Box<Rel2<Add ,X,Y> > {\nBox( Rel2<Add ,X,Y> r ) : x ( r . x ) , y ( r . y ) {} int getMin ( ) { return x . getMin()+y . getMin ( ) ; } int getMax ( ) { return x . getMax()+y . getMax ( ) ; } bool updMin( int i ) { return x . updMin( i−y . getMax ( ) ) and y . updMin( i−x . getMax ( ) ) ; } bool updMax( int i ) { return x . updMax( i−y . getMin ( ) ) and y . updMax( i−x . getMin ( ) ) ; } Box<X> x ; Box<Y> y ;\n} ;\nParametric relation objects are created by a set of convenience functions, such as:\ntemplate<class X, class Y> Rel2<Add ,X,Y> add (X x ,Y y ) { return Rel2<Add ,X,Y>(x , y ) ; }\ntemplate<class X, class Y> Rel2<Add ,X,Y> operator+(X x ,Y y) { return Rel2<Add ,X,Y>(x , y ) ; }\nNote that the above functions only create the relation object for the expression, and not the corresponding view object. Creating the view object is accomplished by providing the relation object to the following function (which is basically a convenience function to avoid specifying the parameter T):\ntemplate<class T> Box<T> box (T t ) { return Box<T>(t ) ; }\nThe following code instantiates two parametric box view objects for an expression using the above constructs.\nDomVar a , b , c ; box ( a+b∗c ) ; box ( add (a , mul (b , c ) ) ) ;"
    }, {
      "heading" : "4.2 Incrementality",
      "text" : "It is important to note that incremental propagators (i.e. propagators which maintain a state) may be used transparently with views. This may be very useful in practice, for example to model the bounds complete distinct propagator over expressions, such as the main constraint of the Golomb ruler problem (given in the next section),\ndistinct ({xi − xj : 1 ≤ j < i ≤ m})\nThere is also nothing preventing us from creating views that maintain an internal state. Although we have implemented this for some expressions, namely the Element expression, it does not seem to be useful for most ββ views that are cheap to evaluate. However, it could certainly make a difference if using δδ views for domain propagation. In summary, using views does not constrain the propagator implementation model to be either incremental or non-incremental."
    }, {
      "heading" : "4.3 Triggering",
      "text" : "Triggering is a well known method for decreasing the number of redundant propagations during a fixpoint computation [23]. A trigger may be seen as a condition for propagation - propagators are known to be idempotent for the current domain until the condition is true, i.e. when they may perform propagation. The way triggering is used with views is not much different from its use in the variable decomposition approach. In addition to the methods presented above, each view object must provide methods for creating/deleting triggers on the relevant events. This must be adapted to the events available in the solver: for example, a trigger on both bounds of an expression x+ y should map to the four bounds of x and y, whereas a trigger on the minimum of −x maps to the maximum of x. Given that each view object provide methods for creating and removing triggers, moving triggers is also possible using views. Consider for example a box view over the expression ifThenElse(C, T, F ) which represents the box T if C is true, and F if it is false. Initially the box view object for this expression creates triggers on C, T , and F (note that inference can be made even if C is not ground). When C is instantiated it removes the trigger on either T or F . We should make two important remarks about creating/deleting triggers. Firstly, at least in our current implementation, moving triggers is not as efficient as in e.g. [14]. This is due to the fact that it is recursive on the structure of the expression (consider for example creating a trigger on an expression containing deeply nested expressions). This is tantamount with other aspects of views - a specialized propagator for the constraint will always have better runtime performance. Secondly, view objects must always check beforehand if it is safe to move a trigger. In\nour example, the box view object must check if C is ground (i.e. if getMin()=getMax()) before deleting the relevant triggers, even if it has updated the domain of C itself. This has to do with (non) persistence of update operations explained in the following section."
    }, {
      "heading" : "4.4 Persistent operations and idempotency checking",
      "text" : "An important feature of box view objects is that operations are not guaranteed to be persistent. Consider for example the constraint c = [X 6= k], where X is an expression and k is a constant. The pseudocode for a bounds consistent propagator for this constraint is as follows:\n1 bool propagate (Box<int> X, int k ) { 2 i f (X. min()==k) 3 return X. updateMin (k+1); 4 i f (X.max()==k) 5 return X. updateMax (k−1); 6 return true ; 7 }\nThis propagator may be used for propagating several constraints by specifying different expressions for X, for instance the constraints c1 = [x1 6= k] and c2 = [y1 + y2 6= k] where X is respectively x1 and y1 + y2. While lines 3 and 5 guarantee that the domain of expression X will be different from k when propagating constraint c1, this is not guaranteed when propagating constraint c2 (consider for example D (y1) = D (y2) = {1, 2} and k = 4). In this simple propagator the fact that some update operations are nonpersistent is not important: the propagator will be scheduled again when either the minimum or maximum of X changes, eventually leading to a persistent update. In general, view based propagators must be designed to take non-persistent update operations into consideration. The class of propagators that check for idempotency deserves special attention. Idempotency checking is a technique for decreasing the number of redundant propagations during solving. The main idea is to avoid scheduling propagators that report idempotency for a given domain since no further pruning would be achieved. A naive (but incorrect) implementation of this optimization on the propagator above would be as follows:\ns t a tu s propagate (Box<int> X, int k ) { i f (X. min()==k)\nreturn (X. updateMin (k+1))? idempotent : f a i l e d ; i f (X.max()==k) return (X. updateMax (k−1))? idempotent : f a i l e d ; return suspend ;\n}\nIn the above pseudocode a propagator can be in one of three states: failed (i.e. inconsistent for the current domain), idempotent, or suspended (i.e. neither failed nor\nidempotent). Due to non-persistent operations for some instantiations of X this propagator may report “idempotent” when in fact it is not. Instead, a correct implementation of this optimization must not rely on persistent update operations:\ns t a tu s propagate (Box<int> X, int k ) { i f (X. min()==k) {\ni f (X. updateMin (k+1)) return (X. min()>k )? idempotent : suspend ; else return f a i l e d ;\n} i f (X.max()==k) ( s im i l a r ) return suspend ;\n}\nIn summary, checking for idempotent view-based propagators is possible but must be carefully designed in order not to rely on persistent update operations as shown above."
    }, {
      "heading" : "4.5 Complexity analysis",
      "text" : "The adoption of views avoids introducing auxiliary variables and propagators for every subexpression. Conceptually, a view object over an expression serves the same purpose as the auxiliary variable introduced for that expression: to expose its domain. However these models have distinct operational tradeoffs. To illustrate this let us focus on an arithmetic constraint involving n variables with uniform domain size d, with an unbalanced syntax tree, i.e. where each operator in the expression involves at least one variable. Figure 1 shows a fragment of the expression syntax tree. We will refer to the decomposition model using auxiliary variables as Vars, subtype polymorphic view as SViews, and parametric polymorphic views as PViews."
    }, {
      "heading" : "4.5.1 Memory",
      "text" : "A box view object can be designed to expose just the subset of the expression’s domain required for the view’s client (e.g. the bounds of the expression). In contrast, a variable maintains the domain of the expression, possibly containing regions that will always be ignored for propagation. For an expression containing n−1 operators (fig. 1), the memory overhead of the Vars model is in O (nD), where D is the size of the largest domain of an auxiliary variable. In practice, although D may be as large as dn−1, many solvers [12, 13, 18] use intervals to store the domains of the auxiliary variable (i.e. D = 2), thus eliminating this problem."
    }, {
      "heading" : "4.5.2 Runtime",
      "text" : "The analysis of runtime complexity focuses on the number of propagator executions, function calls, arithmetic operations performed and updates of variable bounds, for a single propagation of the expression. We consider two worst-case situations: a) when propagation (up to the root) is due to a change in the domain of a leaf variable, and b) when propagation to leaf variables is caused by a change in the domain of the root. These situations correspond, respectively, to accessing and updating the bounds of the expression.\na) In the Vars model O (n) propagators may execute, forcing changes in the bounds of O (n) (auxiliary) variables with O (n) operations. In both view models, an update of a leaf variable domain causes one single propagator to execute and evaluate the full expression. Such evaluation requires O (n) function calls and O (n) operations1.\nb) In the Vars model O (n) propagators may execute, forcing changes in the bounds of up to O (2n) variables (n leaf variables and n− 2 auxiliary variables), requiring up to O (n) operations. Both view models force O (n) updates of bounds of the (leaf) variables, through O (n) function calls and O (n) operations, but no extra propagators will execute.\nAlthough all the models present the same worst-case propagation complexity of O ( n2d ) , breaking down the costs shows that the view models perform fewer calls to propagators and fewer variable updates (there are no auxiliary variable) than the Vars model. The fundamental operational difference between the Vars model and both view models is that a view object computes its domain on demand, that is, it will never update its domain before needed by the view’s client, in contrast with the Vars model, where additional propagators will be posted to prune the domains of the auxiliary variables. Among all contributions, managing the extra propagators should involve the most significant\n1A single update of the expression requires the evaluation of the full tree, possibly involving n2 total operations (as well as n2 function calls in case of the SViews model), if subexpressions are evaluated multiple times recursively. It is possible to decrease this number to n if the evaluation of the subexpressions is cached during the execution of the propagator. This may be done efficiently with box views since the cached data is simply the two bounds of the subexpression that do not have to be backtrackable.\ncosts. On the other hand, the view models require extra operations and function calls. Overall, and despite the same worst-case complexity we expect that the VARS models, that may suffer from the execution of more propagators, are out-performed by the Views models, specially by the PViews where the compiler is often able to avoid the overhead of function calls using inlining. But these expectations can only be adequately assessed by experimentation, so in the next section we present results obtained in a comprehensive set of experiments."
    }, {
      "heading" : "5 Experimental Results",
      "text" : "In this section we evaluate the performance of the decomposition methods described in the previous sections on a set of benchmarks."
    }, {
      "heading" : "5.1 Experiments",
      "text" : "Specifically we are interested in comparing the following models."
    }, {
      "heading" : "5.1.1 Models",
      "text" : "Vars. This is the classical method for decomposing constraints into primitive propagators introducing one auxiliary variable for each subexpression.\nVars+Global. This model is similar to the previous but uses global constraints for lowering the number of auxiliary variables. Only a subset of problems support this decomposition in which case we will specifically mention which global constraints are used.\nPViews. The model that implements the decomposition based on parametric polymorphic view objects.\nSViews. The decomposition based on subtype polymorphic view objects.\nViews+Global. Like the Vars+Global model, this model uses a combination of some type of views and a global constraint propagator.\nAll the above decomposition models were implemented in CaSPER [9, 10]. Additionally, we also implemented the first two in Gecode [12] denoted Gecode-Vars and GecodeVars+Global respectively. Comparing to the Gecode solver assesses the competitiveness of CaSPER as a whole, in order to clarify that the performance of using our method for propagation compared to using auxiliary variables is not due to an inefficient implementation of the latter."
    }, {
      "heading" : "5.1.2 Problems",
      "text" : "The set of benchmarks covers a total of 22 instances from 6 different problems. Before we present them in detail, we should make a few general considerations. For each given instance we used the same labeling heuristics (or no heuristics at all) for testing the above models. This means that, for each instance, the solvers resulting from the implementation of the above models explore exactly the same search space, unless the decompositions have different propagation strength, which may occur as we have already seen. In the following, we will mostly focus on the decomposable constraints for which our models apply. When describing the model, we may choose to ignore other necessary, redundant, or symmetry breaking constraints that we used in our implementations. These\nwere kept constant across all implementations of the above models for each benchmark and therefore do not influence our conclusions. For additional information, we provide references to detailed descriptions of the problems in the online constraint programming benchmark database CSPLib [16]. The source code for all the implementations can be obtained from the first author upon request.\nSystems of linear equations. This experiment consists in solving a system of linear equations. Linear equations are usually integrated in Constraint Programming using a specific global constraint propagator. The goal of the experiment is therefore to assess the overhead of decomposing expressions using the presented models compared to a decomposition which uses a special purpose algorithm, i.e. a global constraint. Each system of linear equations is described by a tuple 〈n, d, c, a, s|u〉 where n is the number of variables in the problem, d is the uniform domain size, c is the number of linear equations, a is the number of terms in each equation, and the last term denotes if the problem is (s)atisfiable or (u)nsatisfiable. Each problem is defined by\nc∧ i=1 ∑ v∈p(i) v = t\nwhere p (i) is a function returning a combination of a variables for the equation i, selected randomly from the full set of Cna possible combinations. The independent term t in each equation was selected randomly with a uniform probability from the interval [a . . . a× d]. Different random seeds were experimented in order to generate difficult instances. The a-ary sum constraints were decomposed using binary sums implementing a subset of the previously described models, namely Vars, SViews, and PViews. Model Vars+Global used global constraint propagators for the a-ary sums (in this case no auxiliary variables are required).\nSystems of nonlinear equations. The second experiment considers systems of nonlinear equations. These problems arise often in practice, and since the decomposition to special purpose propagators is not so direct as in the previous case, it provides a realistic opportunity to apply the previously discussed models. A system of nonlinear equations is described by a tuple 〈n, d, c, a1, a2, s|u〉 where a1 is the number of terms in each equation, each term is composed of a product of a2 factors, and all remaining variables have the same meaning as before. Each system of nonlinear equations is formally defined as:\nc∧ i=1 a1∑ j=1 ∏ v∈p(i,j) v = t\nwhere p (i, j) is a function returning a combination of a2 variables for the term j of equation i, selected randomly from the full set of Cna2 possible combinations. The tested models consist of the decomposition into binary sums and products using auxiliary variables exclusively (Vars) and using view models (SViews, PViews). We\nalso tested two models where each product is decomposed using either auxiliary variables or views, projected to a variable xi, and a sum propagator is used to enforce ∑a1 i=1 xi for each equation (Vars+Global and PViews+Global respectively).\nSocial golfers (prob10 in CSPLib). The Social golfers problem consists in scheduling a golf tournament. The golf tournament lasts for a specified number of weeks w, organizing g games each week, each game involving s players. There is therefore a total of g × s players participating in the tournament. The goal is to come up with a schedule where each pair of golfers plays in the same group at most once. This problem may be solved efficiently in Constraint Programming using a 3-dimensional matrix x of w×g×s integer domain variables, where each variable identifies a golf player in the tournament. For two groups of players G1, G2, the meetOnce constraint ensures that any pair of players in one group does not meet in the other group,\nmeetOnce (G1, G2) =  ∑ x∈G1,y∈G1 (x = y) ≤ 1  This constraint is then used to impose that each pair of players meets at most once during the entire tournament,∧\n1≤wi<wj≤w meetOnce\n( {xwi,gi,si : 1 ≤ gi ≤ g, 1 ≤ si ≤ s} ,{ xwj ,gj ,sj : 1 ≤ gj ≤ g, 1 ≤ sj ≤ s } )\nWe tested a subset of our models for propagating the meetOnce constraint, namely PViews+Global, SViews+Global, and Vars+Global. View based models implement the meetOnce constraint using the above expression directly using a global propagator for the sum constraint:\nmeetOnce (G1, G2) = [sum (all (x ∈ G1, y ∈ G2, x = y)) ≤ 1]\nThe all predicate is used for aggregating a set of expressions from the instantiation of a template expression (e.g. x = y) over a set of possible values (e.g. x ∈ G1, y ∈ G2). The Vars+Global model implements the traditional decomposition using a set b of s2 auxiliary boolean domain variables,\nmeetOnce (G1, G2) = ∧\nx∈G1,y∈G2\n[bi = (x = y)] (1)\n∧  s2∑ i=1 bi ≤ 1  (2) In this case we used the (reified) equality propagator for each equation in the conjunction of eq. 1, and a sum global propagator for eq. 2.\nGolomb ruler (prob6 in CSPLib). A Golomb ruler of m marks and length xm is a set of m integers,\n0 = x1 < x2 < . . . < xm\nsuch that the m(m− 1)/2 differences xi − xj , 1 ≤ j < i ≤ m are distinct. The Golomb ruler problem is an optimization problem, where the goal is to find the smallest possible Golomb ruler with a given number of marks. This problem makes use of a constraint of the form\ndistinct ({xi − xj : 1 ≤ j < i ≤ m})\nenforcing that the pairwise differences xi−xj are all distinct. The classical decomposition for this constraint (Vars+Global) introduces one auxiliary variable for each pairwise difference, and makes use of the distinct global propagator for the distinct constraint,∧\n1≤i<j≤m [ai,j = xi − xj ] ∧ [distinct (a)]\nUsing views avoids introducing the set of auxiliary variables a. Instead, the constraint is used directly as follows,\ndistinct (all (1 ≤ i ≤ m, 1 ≤ j ≤ m, j < i, xi − xj))\nand enforced with the bounds complete propagator introduced by [19]. In our benchmarks we solved the decision version of this problem, i.e. we provided the size of the ruler xm as a parameter of the problem, and asked for a ruler satisfying the constraints.\nLow autocorrelation binary sequences (prob5 in CSPLib). The goal is to construct a binary sequence S = x1, . . . , xn of length n, where D (xi) = {−1, 1}, 1 ≤ i ≤ n, that minimizes the autocorrelations between bits, i.e. that minimizes the following expression,\nm = n−1∑ i=1 n−i−1∑ j=1 xj × xj+i+1 2 (3) The Vars+Global model decomposes the above expression using three sets of auxiliary variables a, b, and c, and sum constraints as follows,∧n−1\ni=1 ∧n−i−1 j=1 [xj × xj+i+1 = ai,j ]∧n−1\ni=1\nn−i−1∑ j=1 ai,j = bi  ∧n−1 i=1 [ b2i = ci\n] ∧ [ m =\nn−1∑ i=1 ci ] The PViews, and SViews models implements expression 3 directly, without introdu-\ncing any auxiliary variable.\nFixed-length error correcting codes (prob36 in CSPLib). This problem involves generating a set of strings from a given alphabet which satisfy a pairwise minimum distance. Each instance is defined by a tuple 〈a, n, l, d〉 where a is the alphabet size, n is the number of strings, l is the string length, and d is the minimum distance allowed between any two strings. For measuring the distance between two strings we have used the Hamming distance on two instances and the Lee distance on the other two. For two arbitrary strings x, y of length l, these measures are defined as follows,\nHamming (x, y) = l∑\ni=1\n(xi 6= yi)\nLee (x, y) = l∑\ni=1\nmin (|xi − yi| , a− |xi − yi|) (4)\nThis problem was modeled by a matrix x of n× l integer domain variables, where each variable xi,j can take a value in 1 . . . a corresponding to the symbol of string i in position j. Then, distance constraints are imposed between each pair of strings,∧\n1≤i1<i2≤n distance ({xi1,j : 1 ≤ j ≤ l} , {xi2,j : 1 ≤ j ≤ l}) ≥ d\nThe Vars+Global model decomposes distance constraints using auxiliary variables and sum constraints. Note that in the case of the Lee distance, a total of 4l auxiliary variables are introduced for each distance constraint. The SViews, and PViews models implement both distance functions without any extra variables."
    }, {
      "heading" : "5.2 Setup",
      "text" : "The experiments were compiled with the gcc-4.5.3 C++ compiler and executed on an Intel Core i7 @ 3.39GHz running Mac OS X 10.7.4. The versions of the CaSPER and Gecode solvers were the most recently available at the time of these experiments, respectively version 1.0.0rc2 and version 3.7.3. Each benchmark was repeated ten times and then kept repeating until the standard deviation of the runtime was below 2% of the average time. The minimum runtime was then used. The source code for all experiments can be made available upon request (please email the first author)."
    }, {
      "heading" : "5.3 Discussion",
      "text" : "The results of all benchmarks are summarized in tables 2 to 6 (more detailed in [8]) from which we may draw the following conclusions."
    }, {
      "heading" : "5.3.1 Type parametric views versus Subtype polymorphic views",
      "text" : "Recall from section 4.1 on page 17 that solvers using type parametric view objects are able to avoid a number of function calls due to code inlining optimizations. Table 2\nshows how this optimization improves performance in practice. Overall the speed-up of PViews wrt. SViews is 50% (i.e. 1/0.67 − 1). In particular for problems involving a large number of subexpressions the speed-up can reach up to 300%. Given that type parametric views are consistently better, we choose to use this model exclusively on the remaining experiments."
    }, {
      "heading" : "5.3.2 Auxiliary variables versus Type parametric views",
      "text" : "Table 3 compares the runtime of the best model using auxiliary variables, i.e. either Vars or Vars+Global, with the runtime of the best model that uses type parametric views, i.e. either PViews or PViews+Global. View objects do not intend to be a replacement for global constraint propagators, and therefore this table shows how much the runtime of a constraint program may be improved when using the best available tools. Before we take a global view on the results in this table, let us focus on the special case of the benchmark involving systems of linear equations. We recall that this benchmark should not be considered as part of a realistic application of views or auxiliary variables since it may be modeled using a global constraint propagator exclusively. However, modeling the global sum constraint using type parametric views over binary sums was only 10% worse on average, which is nevertheless remarkable. For all other benchmarks, using type parametric views instead of auxiliary variables was consistently better, approximately twice as fast on (geometric) average, and always more than 33% faster. An interesting particular case are the two instances of the “Fixed length error correcting codes” problem using the Lee distance. These instances are in fact the only ones for which decomposing using auxiliary variables could be recommended. This is because there is a subexpression which occurs twice in the expression, and therefore can be represented by the same auxiliary variable (see equation 4), possibly leading to a smaller search tree. Even without this optimization, the solver using type parametric views was almost twice as fast on average on these instances. Regarding propagation, even if using auxiliary variables may sometimes lead to smaller\nsearch trees (due to proposition 3.24), the difference was not significant in our experiments. In fact, for those instances where using auxiliary variables increases propagation strength compared to views, the discrepancy in the number of fails was only of 6% on average, and never more than 20% (table 4)."
    }, {
      "heading" : "5.3.3 Competitiveness",
      "text" : "Modeling decomposable constraints using type parametric views makes CaSPER competitive with the state-of-the-art Gecode solver. This may be seen by comparing the results presented in table 5 and table 6. In the first table we compare the runtimes obtained by running the same model on both solvers, i.e. Vars+Global and GecodeVars+Global. The second table compares the PViews model against GecodeVars+Global, which are the best models that can be implemented in both platforms using the available modeling primitives. While CaSPER is worse in all but one problem when using auxiliary variables and global propagators, it becomes faster when using type parametric views. We believe that the discrepancy observed in the “Fixed length error correcting codes” benchmark is related to aspects of the architecture of both solvers\nwhich are orthogonal to the tested models. In summary, we have seen how box view objects may be implemented using several language paradigms, with a focus on strongly typed languages, namely C++. Decomposition models based on auxiliary variables, subtype polymorphic views, and type parametric views were implemented for a number of well known benchmarks, and the results were discussed. We observed that type parametric views are clearly more efficient than models resulting from the other decomposition/compilation methods for all benchmarks. Moreover, we have seen that this technique improves the performance of CaSPER to the point of being competitive with Gecode, which is regarded as one of the most efficient solvers available."
    }, {
      "heading" : "5.3.4 Monitoring Execution",
      "text" : "The theoretical discussion in the previous section hints at the reasons why the view models, in particular the PViews model, achieve better performance than the Vars model. We checked whether these hints were confirmed in the experiments described earlier. To do so, we monitored the execution of many instances of the problems and consistently obtained results similar to those reported below. Table 7 shows the results obtained with two instances of the problem involving systems of nonlinear equations (see 5.1.2). First, we note that in the first (satisfiable) instance, the same search trees were explored by all models, whereas in the second (unsatisfiable) the Vars model explores a slightly smaller tree (1% less failures). As expected, the better performance of both view models (about 2 times faster) is due to the lower number of propagator executions as well as domain updates (one order of magnitude less than in the Vars model). Moreover, PViews improves (20-30 %) on the SViews model because of its better inlining, although the compiler is not able to inline all the function calls. A similar picture is obtained with three instances of the Golomb problem presented in table 8. Again, despite exploring a slightly smaller search space (<1% less failures), the performance of the Vars model is penalized (about 33% slow down) by the larger number of propagator executions as well as domain updates, both again one order of magnitude higher than in the view models. Within these, PViews performs slightly better due to function inlining (in this case, there are fewer function calls than the previous example even if all function calls were inlined)."
    }, {
      "heading" : "6 Conclusion and Future Work",
      "text" : "In this paper we addressed the modeling of decomposable constraints and challenged the traditional view that such decomposition is best made through the use of auxiliary variables. We showed that the propagation of such decomposable constraints may be performed by view based propagators that do not require such auxiliary variables, and discussed the properties of several approximations of this approach. In particular, we focused on models using box view-based propagators for pragmatic reasons, and showed that, notwithstanding the fact that asymptotic worst-case analysis leads to the same complexity, when applied to a comprehensive set of benchmarks they perform significantly better than those based on auxiliary variables, even when the latter models use stronger propagators. We have intentionally restricted the instantiation of view models to those consisting only of box approximations, largely because box view objects may be implemented efficiently. In fact, other view models may be propagated using a similar approach, but creating efficient corresponding view objects is much more challenging in general. As an example, consider designing a domain view object, that is an object which propagates constraints of the form c ◦ fi · · · ◦ fm and computes a δδ-approximation for every image and object function of each of the functions fi. Such object must thus be able to compute δ-domains, which cannot be done in constant time for most functions fi as it is the case for β-domains. But it will be interesting to check whether this could be done for specific classes of functions, similarly to what was done in [26]. Finally, given the superior performance of PViews compared with SViews, one may question what to do when the former cannot be used directly, as occurs when the problem at hand is specified in an interpreted environment such as MiniZinc [21] where there is no C++ compilation involved. In this case, an option is to generate C++ code for the constraints and compile it with a JIT (Just In Time) C++ compiler. Pre-processing constraint problems for generating specific solver binaries is shown in [1]. It would be interesting to see if the compilation time would compensate the solving time in our case."
    } ],
    "references" : [ {
      "title" : "An automated approach to generating efficient constraint solvers",
      "author" : [ "D. Balasubramaniam", "C. Jefferson", "L. Kotthoff", "I. Miguel", "P. Nightingale" ],
      "venue" : "Proceedings of the 2012 International Conference on Software Engineering, ICSE 2012, pages 661–671, Piscataway, NJ, USA",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Boolean and Cartesian abstraction for model checking C programs",
      "author" : [ "T. Ball", "A. Podelski", "S.K. Rajamani" ],
      "venue" : "International Journal on Software Tools for Technology Transfer (STTT), 5(1):49–58",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Global constraint catalog",
      "author" : [ "N. Beldiceanu", "M. Carlsson", "J.-X. Rampon" ],
      "venue" : "The Internet",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Interval constraint logic programming",
      "author" : [ "F. Benhamou" ],
      "venue" : "A. Podelski, editor, Constraint programming: basics and trends, volume 910 of Lecture Notes in Computer Science, pages 1–21. Springer",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Heterogeneous constraint solving",
      "author" : [ "F. Benhamou" ],
      "venue" : "Algebraic and Logic Programming, ALP’96, volume 1139 of Lecture Notes in Computer Science, pages 62–76. Springer-Verlag",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Compiling and executing finite domain constraints",
      "author" : [ "B. Carlson" ],
      "venue" : "PhD thesis, Uppsala University",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Maintaining generalized arc consistency on ad hoc r-ary constraints",
      "author" : [ "K.C.K. Cheng", "R.H.C. Yap" ],
      "venue" : "Principles and Practice of Constraint Programming, CP’08,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2008
    }, {
      "title" : "Modern Techniques for Constraint Solving: The CaSPER Experience",
      "author" : [ "M. Correia" ],
      "venue" : "PhD thesis,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "On the Efficiency of Impact Based Heuristics",
      "author" : [ "M. Correia", "P. Barahona" ],
      "venue" : "Principles and Practice of Constraint Programming, CP’08, volume 5202 of Lecture Notes in Computer Science, pages 608–612. Springer",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "CaSPER: A programming environment for development and integration of constraint solvers",
      "author" : [ "M. Correia", "P. Barahona", "F. Azevedo" ],
      "venue" : "F. Azevedo, editor, Workshop on Constraint Programming Beyond Finite Integer Domains, BeyondFD’05",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "The essence of essence: A constraint language for specifying combinatorial problems",
      "author" : [ "A.M. Frisch", "M. Grum", "C. Jefferson", "B.M. Hernandez", "I. Miguel" ],
      "venue" : "In Proceedings of the 20th International Joint Conference on Artificial Intelligence, pages 73–88",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Minion: A fast scalable constraint solver",
      "author" : [ "I.P. Gent", "C. Jefferson", "I. Miguel" ],
      "venue" : "European Conference on Artificial Intelligence, ECAI’06, pages 98–102. IOS Press",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Watched literals for constraint propagation in minion",
      "author" : [ "I.P. Gent", "C. Jefferson", "I. Miguel" ],
      "venue" : "F. Benhamou, editor, Principles and Practice of Constraint Programming, CP’06, volume 4204 of Lecture Notes in Computer Science, pages 182–197. Springer",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Data structures for generalised arc consistency for extensional constraints",
      "author" : [ "I.P. Gent", "C. Jefferson", "I. Miguel", "P. Nightingale" ],
      "venue" : "Conference on Artificial Intelligence, AAAI’07, pages 191–197. AAAI Press",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "CSPLib: a benchmark library for constraints",
      "author" : [ "I.P. Gent", "T. Walsh" ],
      "venue" : "Technical report, APES-09-1999",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Constraint processing in cc(FD)",
      "author" : [ "P.V. Hentenryck", "V. Saraswat", "Y. Deville" ],
      "venue" : "Technical report, Brown University",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "A fast and simple algorithm for bounds consistency of the alldifferent constraint",
      "author" : [ "R. Lopez-Ortiz", "C.-G. Quimper", "J. Tromp", "P.V. Beek" ],
      "venue" : "International Joint Conference on Artificial Intelligence, IJCAI’03, pages 245–250. Morgan Kaufmann Publishers, Inc",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Propagation completeness of reactive constraints",
      "author" : [ "M.J. Maher" ],
      "venue" : "International Conference on Logic Programming, ICLP’02, volume 2401 of Lecture Notes in Computer Science, pages 148–162. Springer",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Minizinc: Towards a standard CP modelling language",
      "author" : [ "N. Nethercote", "P.J. Stuckey", "R. Becket", "S. Brand", "G.J. Duck", "G. Tack" ],
      "venue" : "Principles and Practice of Constraint Programming, CP’07,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2007
    }, {
      "title" : "editors",
      "author" : [ "F. Rossi", "P.V. Beek", "T. Walsh" ],
      "venue" : "Handbook of Constraint Programming. Foundations of Artificial Intelligence. Elsevier Science",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Speeding up constraint propagation",
      "author" : [ "C. Schulte", "P.J. Stuckey" ],
      "venue" : "Principles and Practice of Constraint Programming, CP’04, volume 3258 of Lecture Notes on Computer Science, pages 619–633. Springer",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Views and iterators for generic constraint implementations",
      "author" : [ "C. Schulte", "G. Tack" ],
      "venue" : "Recent Advances in Constraints, volume 3978 of Lecture Notes in Computer Science, pages 118–132. Springer",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "View-based propagator derivation",
      "author" : [ "C. Schulte", "G. Tack" ],
      "venue" : "Constraints, pages 1–33",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Constraint Propagation – Models, Techniques, Implementation",
      "author" : [ "G. Tack" ],
      "venue" : "Doctoral dissertation,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "The problem of propagating decomposable constraints may be approached using knowledge compilation techniques [15, 7].",
      "startOffset" : 109,
      "endOffset" : 116
    }, {
      "referenceID" : 6,
      "context" : "The problem of propagating decomposable constraints may be approached using knowledge compilation techniques [15, 7].",
      "startOffset" : 109,
      "endOffset" : 116
    }, {
      "referenceID" : 15,
      "context" : "indexical constraints [17, 6]), do not require exponential memory.",
      "startOffset" : 22,
      "endOffset" : 29
    }, {
      "referenceID" : 5,
      "context" : "indexical constraints [17, 6]), do not require exponential memory.",
      "startOffset" : 22,
      "endOffset" : 29
    }, {
      "referenceID" : 19,
      "context" : "Rina Dechter [22] approaches decomposition of constraints from a different perspective.",
      "startOffset" : 13,
      "endOffset" : 17
    }, {
      "referenceID" : 9,
      "context" : "View based-propagation was introduced in [10] and [24].",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 21,
      "context" : "View based-propagation was introduced in [10] and [24].",
      "startOffset" : 50,
      "endOffset" : 54
    }, {
      "referenceID" : 23,
      "context" : "The present work can be seen as an extension of [26, 25] for allowing the use of a particular kind of view over functions involving multiple variables ([26] restricts the use of views to injective functions and therefore to unary functions mostly).",
      "startOffset" : 48,
      "endOffset" : 56
    }, {
      "referenceID" : 22,
      "context" : "The present work can be seen as an extension of [26, 25] for allowing the use of a particular kind of view over functions involving multiple variables ([26] restricts the use of views to injective functions and therefore to unary functions mostly).",
      "startOffset" : 48,
      "endOffset" : 56
    }, {
      "referenceID" : 23,
      "context" : "The present work can be seen as an extension of [26, 25] for allowing the use of a particular kind of view over functions involving multiple variables ([26] restricts the use of views to injective functions and therefore to unary functions mostly).",
      "startOffset" : 152,
      "endOffset" : 156
    }, {
      "referenceID" : 23,
      "context" : "In contrast, views as described in [26] are used essentially as a development tool for increasing the number of available propagators in the library.",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 18,
      "context" : "Compilers for constraint modeling languages [21, 11, 1] generate efficient constraint solvers from a high level description of a constraint problem.",
      "startOffset" : 44,
      "endOffset" : 55
    }, {
      "referenceID" : 10,
      "context" : "Compilers for constraint modeling languages [21, 11, 1] generate efficient constraint solvers from a high level description of a constraint problem.",
      "startOffset" : 44,
      "endOffset" : 55
    }, {
      "referenceID" : 0,
      "context" : "Compilers for constraint modeling languages [21, 11, 1] generate efficient constraint solvers from a high level description of a constraint problem.",
      "startOffset" : 44,
      "endOffset" : 55
    }, {
      "referenceID" : 15,
      "context" : "Indexicals [17, 6] and constrained expressions [18] are conceptually close to the idea of views described in this paper.",
      "startOffset" : 11,
      "endOffset" : 18
    }, {
      "referenceID" : 5,
      "context" : "Indexicals [17, 6] and constrained expressions [18] are conceptually close to the idea of views described in this paper.",
      "startOffset" : 11,
      "endOffset" : 18
    }, {
      "referenceID" : 23,
      "context" : "Following [26] we generalise the notion of domains from single variables to more general n-ary domains and characterize their approximations.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 1,
      "context" : "We introduce now important tuple set operations: Cartesian approximation (see for example [2]) and box approximation [4].",
      "startOffset" : 90,
      "endOffset" : 93
    }, {
      "referenceID" : 3,
      "context" : "We introduce now important tuple set operations: Cartesian approximation (see for example [2]) and box approximation [4].",
      "startOffset" : 117,
      "endOffset" : 120
    }, {
      "referenceID" : 7,
      "context" : "The following lemma (proofs for most propositions and lemmas in this paper are given in [8]) shows how the previously defined approximations are ordered for a given tuple set (or constraint).",
      "startOffset" : 88,
      "endOffset" : 91
    }, {
      "referenceID" : 23,
      "context" : "πc (S1) ⊆ πc (S2) if S1 ⊆ S2, although this property is not mandatory in modern constraint solvers, as shown in [26].",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 23,
      "context" : "We should note that when considering real box approximations, con (c) in the above definition corresponds to the relaxation of constraint c to the real numbers [26].",
      "startOffset" : 160,
      "endOffset" : 164
    }, {
      "referenceID" : 23,
      "context" : "Table 1 shows the correspondence between the constraint consistencies that are traditionally considered [26, 22, 20, 5] and the different ΦΨ-completeness of the propagators.",
      "startOffset" : 104,
      "endOffset" : 119
    }, {
      "referenceID" : 19,
      "context" : "Table 1 shows the correspondence between the constraint consistencies that are traditionally considered [26, 22, 20, 5] and the different ΦΨ-completeness of the propagators.",
      "startOffset" : 104,
      "endOffset" : 119
    }, {
      "referenceID" : 17,
      "context" : "Table 1 shows the correspondence between the constraint consistencies that are traditionally considered [26, 22, 20, 5] and the different ΦΨ-completeness of the propagators.",
      "startOffset" : 104,
      "endOffset" : 119
    }, {
      "referenceID" : 4,
      "context" : "Table 1 shows the correspondence between the constraint consistencies that are traditionally considered [26, 22, 20, 5] and the different ΦΨ-completeness of the propagators.",
      "startOffset" : 104,
      "endOffset" : 119
    }, {
      "referenceID" : 2,
      "context" : "Also known as ad-hoc constraints, they represent an access to an element of a data structure (a table, a matrix, a relation) [3].",
      "startOffset" : 125,
      "endOffset" : 128
    }, {
      "referenceID" : 15,
      "context" : "Notice some similarities of views with indexicals introduced in [17, 6] to create propagators for arithmetic constraints.",
      "startOffset" : 64,
      "endOffset" : 71
    }, {
      "referenceID" : 5,
      "context" : "Notice some similarities of views with indexicals introduced in [17, 6] to create propagators for arithmetic constraints.",
      "startOffset" : 64,
      "endOffset" : 71
    }, {
      "referenceID" : 5,
      "context" : "However, unlike views, indexicals do not define the inverse transformation φ− and therefore are less powerful representing a decomposable constraint using indexicals requires the additional definition of the projection of the object function for each variable in the constraint, even if this projection may be performed automatically as shown in [6].",
      "startOffset" : 346,
      "endOffset" : 349
    }, {
      "referenceID" : 7,
      "context" : "For these view-based propagators the following property can be proved [8].",
      "startOffset" : 70,
      "endOffset" : 73
    }, {
      "referenceID" : 7,
      "context" : "A thorough analysis of the propagation achieved with box view propagators is complex and dependent on the constraints involved (see [8]).",
      "startOffset" : 132,
      "endOffset" : 135
    }, {
      "referenceID" : 20,
      "context" : "Triggering is a well known method for decreasing the number of redundant propagations during a fixpoint computation [23].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 12,
      "context" : "[14].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "In practice, although D may be as large as dn−1, many solvers [12, 13, 18] use intervals to store the domains of the auxiliary variable (i.",
      "startOffset" : 62,
      "endOffset" : 74
    }, {
      "referenceID" : 8,
      "context" : "All the above decomposition models were implemented in CaSPER [9, 10].",
      "startOffset" : 62,
      "endOffset" : 69
    }, {
      "referenceID" : 9,
      "context" : "All the above decomposition models were implemented in CaSPER [9, 10].",
      "startOffset" : 62,
      "endOffset" : 69
    }, {
      "referenceID" : 14,
      "context" : "For additional information, we provide references to detailed descriptions of the problems in the online constraint programming benchmark database CSPLib [16].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 16,
      "context" : "Instead, the constraint is used directly as follows, distinct (all (1 ≤ i ≤ m, 1 ≤ j ≤ m, j < i, xi − xj)) and enforced with the bounds complete propagator introduced by [19].",
      "startOffset" : 170,
      "endOffset" : 174
    }, {
      "referenceID" : 7,
      "context" : "The results of all benchmarks are summarized in tables 2 to 6 (more detailed in [8]) from which we may draw the following conclusions.",
      "startOffset" : 80,
      "endOffset" : 83
    }, {
      "referenceID" : 23,
      "context" : "But it will be interesting to check whether this could be done for specific classes of functions, similarly to what was done in [26].",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 18,
      "context" : "Finally, given the superior performance of PViews compared with SViews, one may question what to do when the former cannot be used directly, as occurs when the problem at hand is specified in an interpreted environment such as MiniZinc [21] where there is no C++ compilation involved.",
      "startOffset" : 236,
      "endOffset" : 240
    }, {
      "referenceID" : 0,
      "context" : "Pre-processing constraint problems for generating specific solver binaries is shown in [1].",
      "startOffset" : 87,
      "endOffset" : 90
    } ],
    "year" : 2017,
    "abstractText" : null,
    "creator" : "TeX"
  }
}