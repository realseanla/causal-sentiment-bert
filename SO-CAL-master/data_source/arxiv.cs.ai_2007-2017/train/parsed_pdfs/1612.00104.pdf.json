{
  "name" : "1612.00104.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Robust Optimization for Tree-Structured Stochastic Network Design",
    "authors" : [ "Xiaojian Wu", "Akshat Kumar", "Daniel Sheldon", "Shlomo Zilberstein" ],
    "emails" : [ "xw458@cornell.edu", "akshatkumar@smu.edu.sg", "sheldon@cs.umass.edu", "shlomo@cs.umass.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Many problems, such as influence maximization (Kempe, Kleinberg, and Tardos 2003), spatial and fish conservation planning (Sheldon et al. 2010; O’Hanley and Tomberlin 2005), and predisaster preparation (Schichl and Sellmann 2015) can be formulated as a variant of the stochastic network design problem. A stochastic network design problem (SNDP) is defined by a directed graph where each edge is either present or absent with some probability. Management actions can be taken to change the probabilities of edge presence. The goal is to determine which actions to take, subject to a budget, to optimize some outcome of the stochastic network over a time period. Several approaches to solve SNDPs have been shown to scale up to large networks (Chen, Wang, and Wang 2010; Kumar, Wu, and Zilberstein 2012; Wu, Sheldon, and Zilberstein 2014b; 2016).\nAn important assumption made in SNDPs is that the network parameters (e.g., probabilities of edge presence) are estimated accurately, which is not feasible in real world ecological domains due to noisy observations, model drift, climate change, and the diversity of species. To handle parameter uncertainty, researchers have formulated robust network\nCopyright c© 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\ndesign problems that include uncertain network probabilities (He and Kempe 2014; Chen et al. 2016). Recently, Kumar et al. (2016) also studied a robust conservation planning problem where the movement probabilities of species and sizes of habitats are not accurately specified. The robust network design problem we address differs from previous work, which does not allow management actions to modify interval parameters (e.g., edge probabilities). They only modify network structure, for example, by adding sources or nodes. In contrast, we allow management actions that can modify both interval bounds and network structure. As a result of the richer action space, it is unclear whether the sample average approximation (SAA) approach used in previous settings (Kumar et al. 2016) is applicable to our problem. To address these challenges, we develop a dynamic programming and mixed-integer programming based approach that can optimize connectivity without using SAA.\nWe study robust SNDPs for tree-structured river networks. The motivating application is the barrier removal problem (Neeson et al. 2015), where the goal is to decide which instream barriers to remove or repair to help fish move upstream and get access to their historical habitats. In this domain, the passage probability of a barrier can only be inaccurately estimated, and the new passage probability of a repaired barrier is even harder to estimate. Hence, we model the uncertainty in passage probability using well known interval bounds (Boutilier et al. 2003). We then develop a scalable algorithm to find the robust policy for barrier removal.\nThe robustness of a policy can be quantified by two correlated metrics: robust ratio (He and Kempe 2014; Chen et al. 2016) and regret (Boutilier et al. 2003; Kumar et al. 2016). Intuitively, assume that given a policy, nature chooses an adversarial policy that selects parameters within their interval bounds so as to either minimize the ratio between the values of the given policy and the adversarial policy (called robust ratio) or maximize the value difference between them (called regret). We develop a scalable algorithm to find a robust policy that maximizes the robust ratio by solving a bilevel optimization problem. We also show that, with minor modifications, our approach can be used to minimize regret.\nThe algorithm is based on a constraint generation procedure (Boutilier et al. 2003) that interleaves between two optimization steps. The decision optimization step finds a decision policy that maximizes the robust ratio when nature can\nar X\niv :1\n61 2.\n00 10\n4v 1\n[ cs\n.A I]\n1 D\nec 2\n01 6\nchoose policies and probabilities from a given limited number of choices. In the second ratio minimization step, the best adversarial policy and probabilities are found for the selected decision policy and are added to the set of choices for nature. We provide a mixed integer linear programming formulation for the decision optimization problem. The ratio minimization problem is much harder; we develop an algorithm called rounded dynamic programming (RDP) by combining a dynamic programming algorithm and a rounding method and show that it is a fully polynomial time approximation schema (FPTAS). In experiments, we show that RDP performs nearly optimally as it selects the adversarial policy and probabilities. Our algorithm can find policies that are more robust than policies found by baseline methods with respect to both robustness metrics. We also provide insights on the robustness metrics by visualizing the solutions."
    }, {
      "heading" : "2 River Network Design",
      "text" : "The problem is defined on a directed rooted tree T =(V,E) with a unique root denoted by s. Edges spread out from the root. A node v represents a contiguous region of the river network. It denotes a connected set of stream segments among which fish can move freely without passing any barriers. A node v is associated with a reward rv which is proportional to the total amount of habitat in that region (e.g., the total length of all segments). An edge e encodes a river barrier. Fig. 1 shows how to encode a river network as a directed rooted tree. Each barrier is associated with a passage probability—the probability that a fish can pass the barrier. Before any repair action is taken, the probability is called the initial passage probability denoted by pe. A finite set of candidate actions denoted by Ae = {0, 1, ...,m} are available at e; an action i has cost ce(i), and, if taken, can raise passage probability to pe|i. The action 0 is the null action with pe|0 = pe and zero cost. A policy π indicates which action is taken at each edge. The passage probability for a given policy is denoted by pe|π . The accessibility of a node v denoted by ps v|π is the probability that a fish passed all barriers on the path from s to v or ps v|π = ∏ e: on path from s to t pe|π . A reward rv can be collected only if a fish can reach v. The value of policy π, denoted by z(π), is the total reward of nodes weighted by their accessibilities: z(π) = ∑ v∈V ps v|πrv . We also call z(π) the objective value to differentiate be-\ntween other values assigned to π. The barrier removal problem (Wu, Sheldon, and Zilberstein 2014a) is to find a policy maximizing z(π) subject to a budget constraint:\narg max π\nz(π) s.t. c(π) ≤ B (1)\nwhere c(π) is the total cost of action taken for each edge in the network. Let X = {π : c(π) ≤ B} denote the set of feasible policies.\nRobust River Network Design The barrier removal problem is defined upon the assumption that all the passage probabilities are known. However, this is an unrealistic assumption. Often, in real world settings, it is not possible to accurately estimate such probabilities. Therefore, in our model only interval bounds are specified for different probabilities (Boutilier et al. 2003). Specifically, the passage probability for an edge e and action i ∈ Ae can take any value within a given interval. That is, pe|i ∈Pe|i = [pe|i, pe|i]. Let p denote a vector of all probabilities p=(pe|i)e∈E,i∈Ae . Let the space of all the allowed probabilities p be denoted as P =×e∈E,i∈AePe|i. Our goal is to find a policy πMRR that maximizes the robust ratio as defined by Kouvelis and Yu (2013) and Chen et al. (2016):\nπMRR ∈ argmax π∈X min π′∈X ,p∈P\nz(π;p) z(π′;p) . (2)\nIn the outer maximization, the decision maker seeks a decision policy π that is robust relative to adversarial choices made by nature. In the inner minimization, nature adversarially chooses a policy π′ and feasible parameters p (a policyparameter pair) to minimize the ratio between the value of the decision policy π and the adversarial policy π′ on this set of parameters. The optimal value of the adversary is called the robust ratio of policy π with respect to parameter space P . A policy (such as πMRR) that maximizes the robust ratio is called MRR-optimal, and the robust ratio of such a policy is called the MRR-value. Suppose πMRR is MRR-optimal with MRR-value α: then πMRR achieves at least α fraction of the optimal reward for any parameter setting p ∈ P . Fig. 2 illustrates the concept.\nAlgorithm 1 Robust Policy Optimization 1: Initialize C = {(π′0,p0)} and T = 1. 2: Decision Optimization: obtain πT by solving:\nU = max π min (π′,p)∈C\nz(π;p)/z(π′;p) (3)\n3: Adversary Optimization: obtain the adversarial policyparameter pair (π′T ,pT ) with respect to πT by solving:\nL = min (π′,p)∈C\nz(πT ;p)/z(π ′;p). (4)\n4: if U − L ≤ threshold, return πT . Otherwise set C = C ∪ {(π′T ,pT )}, increment T , and go to step 2."
    }, {
      "heading" : "3 Our Method",
      "text" : "We develop an iterative method (Algorithm 1) to solve Problem (2) using constraint generation (Boutilier et al. 2003). The high-level idea is to interleave two optimization problems. First, in the decision optimization problem, the decision maker finds the best decision policy πT relative to a limited adversary, who can only pick policy-parameter pairs from the finite set C. Then, the adversary selects a new policy-parameter pair to minimize the robust ratio with respect to the current decision policy πT . The decision player’s value U is an upper bound on the MRR-value, because the adversary is limited to a finite subset of policy-parameter pairs. The adversary’s optimal value L is a lower bound on the MRR-value. When U = L, we have an MRR-optimal decision policy. By allowing a small gap between the two bounds, we can find a nearly MRR-optimal policy. The set C is initialized with an arbitrary policy and probabilities."
    }, {
      "heading" : "3.1 The Decision Optimization Problem",
      "text" : "The goal of Problem (3) is to find a decision policy that maximizes the robust ratio with respect to the limited adversary. Fig. 3 presents a mixed-integer linear program (MILP) to solve this problem building on techniques from (Neeson et al. 2015). The variable M encodes the MRR-value. The inner minimization is replaced by inequality constraints (6) on M . The continuous variable zp encodes the objective value of the decision policy for probability setting p by (7). z(π′;p) is a constant for each policy-parameter pair (π′;p) ∈ C. xie is a binary decision variable indicating whether action i ∈ Ae is applied to e (= 1) or not (= 0). Constraint (8) enforces that one and only one action is taken at each edge, and (9) is the budget constraint.\nThe constraint set Ω(p, x) defined in (12)–(18) forces zp to be the objective value of π under probability setting p. The variable αpv encodes the accessibility of node v. The root node has accessibility 1 by (13). Π(v) denotes the parent of node v. Recall that each node has at most one parent. The variable λpv,i encodes the increment in the accessibility of node v if an action i ∈ AΠ(v),v is applied to edge (Π(v), v). In (14), the accessibility of v equals to the cumulative passability when no action is taken on edge (Π(v), v) (the term αpΠ(v)pΠ(v)v) plus the total increment (the term∑ i∈AΠ(v)v λ p v,i). Actually, at most one action can be taken,\nso only one λpv,i will be nonzero in the summation. The increment λpv,i is nonzero only if x i Π(v)v is 1 by (15), and can be at most (pΠ(v)v|i−pΠ(v)v) αpΠ(v) by (16), which is exactly the increment when action i is taken."
    }, {
      "heading" : "3.2 The Adversary Optimization Problem",
      "text" : "In the adversary optimization step, we wish to solve Problem (4) to find a policy-parameter pair (π′∗,p∗) to minimize the robust ratio with respect to the current decision policy.\nHere is our main result. Theorem 1. There is an FPTAS for problem (4). It finds a policy-parameter pair with robust ratio at most (1+ )OPT in time O(n 4\nµ2 ) where µ = 2+ , n is the number of nodes in the tree, and OPT is the optimal value of (4). The FPTAS only approximately minimizes the objective, so the value L̂ it achieves not a lower bound in in Algorithm 1. However, the approximation guarantee implies thatL = L̂1+ is a lower bound.\nIn the rest of this section, we prove Theorem 1 (proofs of some auxiliary results are left in appendix). We first propose a dynamic programming (DP) algorithm for problem (4), but this takes exponential time. We then develop a rounding strategy to reduce the running time to polynomial time and prove that this is an FPTAS. This basic idea is originally used for the barrier removal problem (1) (Wu, Sheldon, and Zilberstein 2014a). The adversary optimization problem here is more complex as the adversary tries to simultaneously minimize the value of decision policies and maximizes the value of adversarial policies. To guarantee the approximation rate, we round these two values distinctly.\nTo simplify the presentation, we assume without loss of generality the following: Assumption 1. Each node u ∈ T has at most two children. Any problem instance can be converted to satisfy this assumption (Wu, Sheldon, and Zilberstein 2014a). Our first lemma restricts the space of parameters to be considered. Lemma 1. There exists an optimal policy-parameter pair (π′∗,p∗) for Problem (4) with the following property. Suppose π′∗ takes action i and the decision policy π takes action j on edge e. If j 6= i, then p∗e|i = pe|i and p ∗ e|j = pe|j . Otherwise, p∗e|i is either pe|i or pe|i.\nLemma 1 guarantees that the optimal adversary probability is either the upper or lower bound of the interval.\nPolicy-Parameter Actions and Optimization First, we redefine problem (4) in the following way so that it is amenable to dynamic programming.\nLet π be fixed. The new optimization problem is the same as the river network design problem (1) except that its objective is the robust ratio z(π;p)z(π′;p) and its actions encode both the actions and parameters of the adversary.\nWe define a finite set of policy-parameter actions Ape for each edge, which encode choices made by the adversary for edge e, including both the action taken and the probability setting for each available action. A policy-parameter action is a vector (iae ,pe|0, ...,pe||Ae|) taking value in A p e =\nAe × ∏ j∈Ae{pe|j , pe|j}. i a e specifies the action that the adversary takes at e. pe|j specifies the passage probability on e for action j. It is easy to see from Lemma 1 that a given policy-parameter action need only consider p\ne|j and pe|j as possible values for pe|j without sacrificing optimality. In addition, Lemma 1 allows us to eliminate certain policy-parameter actions from consideration. For example, if Ae = {0, 1} and the decision policy π takes action 1, Ase only needs to include 3 policy-parameter actions\n(0, pe|0, pe|1), (1, pe|0, pe|1), (1, pe|0, pe|1)\nMore generally, we have Corollary 1. For a fixed π, only |Ae|+ 1 actions in Ase are needed to compute (π′∗,p∗).\nIn summary, the choice of a policy-parameter action for each edge to minimize the robust ratio gives the optimal policy-parameter pair (π′∗,p∗) for problem (27).\nDynamic Programming We now present a dynamic programming algorithm to solve this new problem with policyparameter actions.\nIn a rooted directed tree, each node u corresponds to a subtree Tu. Define πu (or π′u) to be the subset of π (or π′) that only includes actions for edges within Tu, and define pu to be the subset of p including probabilities only in Tu. Define zu(πu;pu) to be the objective value of policy πu on subtree Tu with probability vector pu pretending that u is the overall root, i.e., zu(πu;pu) = ∑ t∈Tu pu t|πrt. Similarly, zu(π′u;pu) is the value of π ′ u for Tu. The following recurrences calculate both values for a given (πu;pu) zu(π\n′ u;pu)=ru+puv|π′uzv(π ′ v;pv) + puw|π′uzw(π ′ w;pw) (19)\nzu(πu;pu)=ru+puv|πuzv(πv;pv) + puw|πuzw(πw;pw) (20)\nThe DP table of subtree Tu is indexed by pairs (zau, zdu), where zau represents an objective value of an adversary policy and zdu represents an objective value of the (fixed) decision policy on that subtree. The table includes only pairs that are achievable by some probability vector pu and adversary policy π′u for subtree Tu, that is, zdu = zu(πu;pu) and zau = zu(π ′ u,pu). Let Φ(z a u, z d u) = {(π′u,pu) | zu(π′u;pu) = zau, zu(πu;pu) = z d u} be the set of all policy-parameter pairs that map to a pair of objective values (zau, z d u). For the entry of the table indexed by (zau, z d u), we record only the minimum-cost adversary policy, and the minimum cost (denoted by mc) it achieves:\nmc(zau, z d u) = min (π′,p)∈Φ(zau,zdu) c(π′u) (21)\nThe DP tables for all subtrees can be calculated recursively from leaf nodes toward the root s in the following way. First, the table at a leaf node contains a single tuple with cost 0 because the subtree contains only the leaf node. Consider a node u with two children v and w. We can build the DP table at u if we have the DP tables of v and w by computing all achievable objective-value pairs at u and their minimum costs. From each pair (zav , z d v) at v and each pair (zaw, z d w) at w, policy-parameter pairs (π ′ v,pv) and (π′w,pw) can be extracted. For each policy-parameter action (iauv,puv) on edge (u, v) and each policy-parameter action (iauw,puw) on edge (u,w), a new pair (π ′ u,pu) at u can be built, with which we can compute a pair (zau, z d u) using recurrences (19) and (20). The cost of this new pair is\nc(iauv) + c(i a uw) + mc(z a v , z d v) + mc(z a w, z d w) (22)\nThe same pair may be generated multiple times, but only the minimum cost is recorded.\nOnce all DP tables are computed, the optimal solution can be extracted from the table at s by finding a tuple\n(za∗s , z d∗ s ) ∈ arg min\nmc(zas ,z d s )≤B zds zas\nThe pair (π′∗,p∗) associated with the tuple minimizes the objective.\nUnfortunately, the table size grows exponentially with the height of the node in the tree. We next introduce a rounding strategy to make the algorithm scalable.\nRounding We define rounded value functions ẑu(π′;p) and ẑu(π;p) for subtree u and introduce the following recurrences for rounded value functions:\nẑu(π ′ u;pu)=Ku\n⌊ ru+ puv|π′u ẑv(π ′ v;pv) + puw|π′u ẑw(π ′ w;pw)\nKu\n⌋ (23)\nẑu(πu;pu)=Ku\n⌈ ru+ puv|πu ẑv(πv;pv) + puw|πu ẑw(πw;pw)\nKu\n⌉ (24)\nwhere Ku is an user defined rounding parameter. Intuitively, values are rounded and grouped into discrete bins, which reduces the number of pairs in the DP table. The following theorem states that for any given policy-parameter pair, the rounded objective values are not too far from the true values.\nTheorem 2. Let µ > 0. If we set Ku = µru, for any (π′u,pu) and any πu, we have\nzu(π ′ u;pu)−ẑu(π ′ u;pu)≤ ∑ t∈Tu pu t|π′uKt=µzu(π ′ u;pu) (25)\nẑu(πu;pu)−zu(πu;pu)≤ ∑ t∈Tu pu t|πuKt=µzu(πu;pu) (26) zu(π ′ u;pu) ≥ ẑu(π ′ u;pu) (27) ẑu(πu;pu) ≥ zu(πu;pu) (28)\nProof sketch. Intuitively, in (23), the floor rounding operation at a node t reduces the value by at mostKt, which is discounted by probability pu t|π′ . Therefore, we have (25) and (27). In (24), the ceiling rounding operation at a node t introduces an increment bounded by Kt, which is discounted by pu t|π′ . Therefore, we have (26) and (28).\nThe rounded dynamic programming (RDP) algorithm works the same as the DP algorithm except that instead of keeping a list of (zau, z d u) in the table of u, a list of rounded pairs denoted by (ẑau, ẑ d u) are kept, which are calculated by recurrences (23) and (24). Each rounded pair is associated with the minimum cost to achieve it and the correspondent policy-parameter pair. Intuitively, since multiple zaus (or z d us) are rounded into the same ẑau (or ẑ d u), the size of the table is reduced. It can be shown that RDP can find\n(π′r,pr) ∈ arg min π′,p\nẑ(π;p) ẑ(π′;p) (29)\nWe show that (π′r,pr) is a good approximation to the optimal policy-parameter pair (π′∗,p∗). That is, it is within (1 + ) optimal if µ is set properly. Specifically, Theorem 3. If µ = 2+ , we have\nOPT = z(π;p∗)\nz(π′∗;p∗) ≤ z(π;p\nr)\nz(π′r;pr) ≤ (1 + )OPT\nProof. By (25) and (26), for any (π′,p), we have\nẑ(π;p) ẑ(π′;p) ≤ (1 + µ)z(π;p) (1− µ)z(π′;p) = (1 + ) z(π;p) z(π′;p)\nSince (π′r,pr) produces the minimum ratio for rounded value functions (24) and (23), we have\nẑ(π;pr)\nẑ(π′r;pr) ≤ ẑ(π;p\n∗)\nẑ(π′∗;p∗) ≤ (1 + ) z(π;p\n∗)\nz(π′∗;p∗)\nBy (27) and (28), we have\nz(π;pr)\nz(π′r;pr) ≤ ẑ(π;p\nr)\nẑ(π′r;pr)\nThus, the theorem is proved.\nRuntime Analysis In Theorem 3, we see that the Ku values of affect the approximation rate. Now, we analyze the dependence of the RDP algorithm running time on these values. First, we make the following assumption. Assumption 2. There are two constants m and M independent of |V | such that m ≤ ru ≤M for all u ∈ V .\nThe assumption is reasonable because rewards represent habitat areas of stream segments, which do not increase or decrease as the number of segments increases.\nLet the number of different values of ẑau and ẑ d u in the table\nat u be mau and m d u. We have\nLemma 2. If Ku = µru, we have mau = O (nu µ ) , mdu = O (nu µ ) where nu is the number of nodes in subtree Tu.\nProof. Since ẑ(π′u;pu) is upper-bounded by z(π ′ u;pu) ≤ nu · M , the number of different rounded values with Ku is mau ≤ nu·MKu ≤ nu·M µm = O( nu µ ). Similarly, ẑ(π;p) is upper-bounded by (1 + µ)z(πu;pu) ≤ (1 + µ)nuM , so mdu = O( nu µ ) as well.\nDefine T (nu) to be the running time for subtree u, which is calculated by recurrence\nT (nu) = O(m a vm d vm a wm d w) + T (nv) + T (nw)\nTogether with Lemma 2, it can be shown that\nTheorem 4. T (nu) = O( n4u µ2 ).\nThus, the running time of the RDP algorithm is O(n 4\nµ2 )\nwhere n is the number of nodes in the directed rooted tree. Combining Theorems 3 and 4, Theorem 1 is proved."
    }, {
      "heading" : "4 Other Criterion of Robustness",
      "text" : "A slightly different way to quantify robustness is to use regret (Kumar et al. 2016; Boutilier et al. 2003). The policy that minimizes the regret is defined by\nπMR ∈ arg min π:c(π)≤B max π′:c(π′)≤B z(π′;p)− z(π;p) (30)\nThe robust ratio and the regret are correlated as\nz(π;p) z(π′;p) = 1− z(π ′;p)− z(π;p) z(π′;p)\nThe robust ratio is in some way the scaled version of the regret. In experiments, we show that πMRR also produces small regret compared to policies computed by other baseline methods. Our algorithm with minor modifications can find a nearly optimal πMR empirically."
    }, {
      "heading" : "5 Experiments",
      "text" : "We use data from the CAPS project (McGarigal et al. 2011) for the river networks in Massachusetts and synthetically define the missing parameters from the data. The data provides the point estimates of the initial passability probabilities. We use the method in (Kumar et al. 2016) to define the intervals of initial passage probabilities before taking actions. The interval of an initial passage probability is [p − βp, p + βp] where p is an point estimate and β is a parameter controlling the interval sizes.\nThe data contains two types of barriers: culverts and dams. The point estimates for culverts provided by the data\nare mostly in the range [0.8, 0.9]. A typical action that removes a culvert raises its passage probability to 1.0 and costs $100,000. Most of the point estimates for dams are less than 0.2. A typical action to repair a dam costs $173,030, and shifts its probability interval to [p′ − βp′, p′ + βp′] where p′ = p + a random value in [0.5, 0.9] . The cost estimates are based on a study by Neeson et al. (2015). All intervals are truncated to fit within [0, 1.0].\nWe compare our algorithm against two baseline methods: a “midpoint” policy is obtained by solving problem (1) and assuming true passage probabilities being the mid-point values of the intervals; a “worst” policy is obtained by solving problem (1) and conservatively assuming true passage probabilities being the lower bounds of the intervals. The policy calculated by our algorithm is the “MRR” policy.\nApproximate Rate of the RDP Algorithm First, we evaluate the approximation rates of the RDP algorithm for problem (4), and of a modified RDP algorithm for solving the inner maximization problem of (30) on a small network of only 22 nodes. The DP algorithm runs out of memory on networks of larger sizes. The results are shown in Fig. 4. We setKu in two different ways— = 0.1 (denoted by “µ”) and Ku = 5 (denoted by “constant”). Setting Ku = 5 makes the algorithm about 20 times faster than setting µ = 0.1 and 100–600 times faster than DP. Note that robust ratios produced by our algorithm are greater than OPT and regrets are smaller than OPT . From the figures, we see that the (modified) RDP algorithm produces nearly optimal policyparameter pairs. In the rest of experiments, we do not show\nthe results of the modified algorithm to solve problem (30). We test on a larger network of 2028 culverts and 166 dams to see what value of K, when we set Ku=K, is sufficiently large for the RDP algorithm to produce good robust ratios. The optimal objective value is not available on this network. The results are shown in Fig. 5. We see that robust ratios converge within 2 minutes for all testing policies, and random policies are much worst than two baseline policies. The value of K in the convergence area implies that it is sufficient to produce near-optimal solutions.\nRobustness Comparison On the same network, we compare the robustness of three policies using the value of K in the convergence area. Fig. 6 shows how the robust ratio and regret computed by “MRR” change as the size of intervals (i.e., β) varies. Budget sizes are relative to the cost of removing all barriers. We see that as β increases, the robust ratio decreases and the regret increases almost linearly. “MRR” gives the largest robust ratio. Although “MRR” maximizes the robust ratio, it produces the smallest regret, implying that the two robustness metrics are correlated.\nFinally, we test our algorithms on a large network of 9335 nodes, 7566 culverts and 596 dams with 5% budget. In this very difficult setting, we obtain results similar to those shown in Fig. 6 even without using the value of K in the convergence area. Due to the limitation of space, we do not show those similar figures here, but only visualize the computed policies in Fig. 7. The “midpoint” policy allocates most of the budget around the main stream, near the middle vertical line of the river. The adversarial policy can easily achieve much better value by taking actions in other important areas and assigns high probabilities if actions are taken (e.g., the adversarial policy) and low probabilities if actions are not taken (e.g., the decision policy.) In contrast, the “MRR” policy is more robust by allocating the budget to several important areas so that the adversarial policy cannot use the same trick to achieve much better value."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We describe an approximate robust optimization algorithm for a tree-structured stochastic network design problem, which is motivated by the river network design problem for fish conservation. The algorithm iteratively solves two optimization problem: the decision optimization problem and the ratio minimization problem. The former is encoded into\na MILP, and an FPTAS is developed for the latter, which is the harder problem. Empirically, we show that the policies computed by maximizing the robust ratio are more robust than policies computed by two other baseline methods. Besides finding policies of high robust ratio, our algorithm can also produce policies with small regret on large-scale networks. These algorithms provide new computational tools for environmental scientists who tackle decision problems with imprecise models."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This work was partially funded by a UMass Graduate School Dissertation Writing Fellowship awarded to the first author. Second author is supported by the research center at the School of Information Systems at the Singapore Management University."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "Stochastic network design is a general framework for optimizing network connectivity. It has several applications in computational sustainability including spatial conservation planning, pre-disaster network preparation, and river network optimization. A common assumption in previous work has been made that network parameters (e.g., probability of species colonization) are precisely known, which is unrealistic in real-world settings. We therefore address the robust river network design problem where the goal is to optimize river connectivity for fish movement by removing barriers. We assume that fish passability probabilities are known only imprecisely, but are within some interval bounds. We then develop a planning approach that computes the policies with either high robust ratio or low regret. Empirically, our approach scales well to large river networks. We also provide insights into the solutions generated by our robust approach, which has significantly higher robust ratio than the baseline solution with mean parameter estimates.",
    "creator" : "TeX"
  }
}