{
  "name" : "1301.2307.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Decision-Theoretic Planning with Concurrent Temporally Extended Actions",
    "authors" : [ "Khashayar Rohanimanesh", "Sridhar Mahadevan" ],
    "emails" : [ "khash@cse.msu.edu", "mahadeva@cse.msu.edu" ],
    "sections" : null,
    "references" : [ {
      "title" : "Exploiting structure in policy construction",
      "author" : [ "C. Boutilier", "M. Goldszmidt" ],
      "venue" : "In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Boutilier and Goldszmidt,? \\Q1995\\E",
      "shortCiteRegEx" : "Boutilier and Goldszmidt",
      "year" : 1995
    }, {
      "title" : "Reinforcement learn­ ing methods for continuous-time markov decision problems",
      "author" : [ "S. Bradtke", "M. Duff" ],
      "venue" : "Advances in Neural Information Process­ ing Systems,",
      "citeRegEx" : "Bradtke and Duff,? \\Q1995\\E",
      "shortCiteRegEx" : "Bradtke and Duff",
      "year" : 1995
    }, {
      "title" : "Learning multidimensional control actions from delayed reinforcements",
      "author" : [ "P. Cichosz" ],
      "venue" : "Eighth Inter­ national Symposium on System-Modelling-Control (SMC-8)",
      "citeRegEx" : "Cichosz,? \\Q1995\\E",
      "shortCiteRegEx" : "Cichosz",
      "year" : 1995
    }, {
      "title" : "Model minimization in markov decision processes",
      "author" : [ "T. Dean", "R. Givan" ],
      "venue" : "n Proceedings of the Fourteenth National Conference on Aritificial Intel­ ligenceProceedings of AAAI",
      "citeRegEx" : "Dean and Givan,? \\Q1997\\E",
      "shortCiteRegEx" : "Dean and Givan",
      "year" : 1997
    }, {
      "title" : "Computing factored value functions for policies in structured mdps",
      "author" : [ "D. Koller", "R. Parr" ],
      "venue" : "16th International Joint Conference on Artificial Intelli­ gence (IJCAI),",
      "citeRegEx" : "Koller and Parr,? \\Q1999\\E",
      "shortCiteRegEx" : "Koller and Parr",
      "year" : 1999
    }, {
      "title" : "How to dynamically merge markov decision processes",
      "author" : [ "S. Singh", "D. Cohn" ],
      "venue" : "Proceedings of NIPS",
      "citeRegEx" : "Singh and Cohn,? \\Q1998\\E",
      "shortCiteRegEx" : "Singh and Cohn",
      "year" : 1998
    }, {
      "title" : "Between MOPs and Semi-MDPs: A framework for tempo­ ral abstraction in reinforcement learning",
      "author" : [ "R. Sutton", "D. Precup", "S. Singh" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Sutton et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Sutton et al\\.",
      "year" : 1999
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "We adopt the theoretical framework of options (Sutton et al., 1999) to model temporally extended actions, since it is both a well-developed rigorous framework that addresses planning under uncertainty with temporally extended actions, and it allows looking inside behaviors to im­ prove composition of temporally extended actions.",
      "startOffset" : 46,
      "endOffset" : 67
    }, {
      "referenceID" : 2,
      "context" : "multi-dimensional vector action spaces (Cichosz, 1995) to planning with multiple simultaneous MDPs (Singh & Cohn, 1998), where the composite state space is the cross product of the state spaces of each individual",
      "startOffset" : 39,
      "endOffset" : 54
    }, {
      "referenceID" : 6,
      "context" : "Options are a generalization of primitive actions that include temporally extended courses of action in the context of reinforcement learning (Sutton et al., 1999).",
      "startOffset" : 142,
      "endOffset" : 163
    }, {
      "referenceID" : 6,
      "context" : "It has been shown earlier that the set of Markov options defines a semi-Markov decision process (SMDP) (Sutton et al., 1999).",
      "startOffset" : 103,
      "endOffset" : 124
    }, {
      "referenceID" : 6,
      "context" : "We adopt the rooms example from (Sutton et al., 1999) and we add doors in each of the four hallways (F igure 1).",
      "startOffset" : 32,
      "endOffset" : 53
    }, {
      "referenceID" : 6,
      "context" : "continuing the multi-option (Sutton et al., 1999).",
      "startOffset" : 28,
      "endOffset" : 49
    } ],
    "year" : 2011,
    "abstractText" : "We investigate a model for planning un­ der uncertainty with temporally extended ac­ tions, where multiple actions can be taken concurrently at each decision epoch. Our model is based on the options framework, and combines it with factored state space mod­ els, where the set of options can be parti­ tioned into classes that affect disjoint state variables. We show that the set of deci­ sion epochs for concurrent options defines a semi-Markov decision process, if the underly­ ing temporally extended actions being paral­ lelized are restricted to Markov options. This property allows us to use SMDP algorithms for computing the value function over concur­ rent options. The concurrent options model allows overlapping execution of options in or­ der to achieve higher performance or in or­ der to perform a complex task. We describe a simple experiment using a navigation task which illustrates how concurrent options re­ sults in a more optimal plan when compared to the case when only one option is taken at a time.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}