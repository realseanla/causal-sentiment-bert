{
  "name" : "1508.06781.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Computing Stable Coalitions: Approximation Algorithms for Reward Sharing",
    "authors" : [ "Elliot Anshelevich", "Shreyas Sekar" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "“How should a central agency incentivize agents to create high value, and then distribute this value among them in a fair manner?” – this question forms the central theme of this paper. Formally, we model a set of selfish agents in a combinatorial setting consisting of a set P of projects. Each project k is characterized by a valuation function; vk(S) specifies the welfare generated by a set S of agents working on project k. The problem that we study is the following: compute an assignment of agents to projects to maximize social welfare, and provide rewards or payments to each agent so that no group of agents deviate from the centrally prescribed solution.\nFor example, consider a firm dividing its employees into teams to tackle different projects. If these employees are not provided sufficient remuneration, then some group could break off, and form their own startup to tackle a niche task. Alternatively, one could imagine a funding agency incentivizing researchers to tackle specific problems. More generally, a designer’s goal in such a setting is to delicately balance the twin objectives of optimality and stability : forming a high-quality solution while making sure this solution is stable. A common requirement that binds the two objectives together is budget-balancedness: the payments provided to the agents must add up to the total value of the given solution.\nCooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40]. The notion of a ‘fair division’ is perhaps best captured by the Core: a set of payments so that no group of agents would be better off forming a coalition by themselves. Although the\nar X\niv :1\n50 8.\n06 78\n1v 1\n[ cs\n.G T\n] 2\n7 A\nug 2\n01 5\nCore is well understood, implicit in the papers that study this notion is the underlying belief that there are infinite copies of one single project [5,12], which is often not realistic. For example, a tacit assumption is that if the payments provided are ‘not enough’, then every agent i can break off, and simultaneously generate a value of v(i) by working alone; such a solution does not make sense when the number of projects or possible coalitions is limited. Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.\nThe fundamental premise of this paper is that many coalition formation settings feature multiple non-identical projects, each with its own (subadditive) valuation vk(S). Although our model allows for duplicate projects, the inherently combinatorial nature of our problem makes it significantly different from the classic problem with infinite copies of a single project. For example, in the classic setting with a single valuation v(S), the welfare maximization problem is often trivial (complete partition when v is subadditive), and the stabilizing core payments are exactly the dual variables to the allocation LP [10]. This is not the case in our setting where even the welfare maximization problem is NP-Hard, and known approximation algorithms for this problem use LP-rounding mechanisms, which are hard to reconcile with stability. Given this, our main contribution is a poly-time approximation algorithm that achieves stability without sacrificing too much welfare."
    }, {
      "heading" : "1.1 The Core",
      "text" : "Given an instance (N ,P, (vk)k∈P) with N agents (N ) and m projects, a solution is an allocation S = (S1, . . . , Sm) of agents to projects along with a vector of payments (p̄)i∈N . With unlimited copies of a project, core stability refers to the inability of any set of agents to form a group on their own and obtain more value than the payments they receive. The stability requirement that we consider is a natural extension of core stability to settings with a finite number of fixed projects. That is, when a set T of agents deviate to project k, they cannot displace the agents already working on that project (Sk). Therefore, the payments of the newly deviated agents (along with the payments of everyone else on that project) must come from the total value generated, vk(Sk ∪ T ). One could also take the Myersonian view [38] that ‘communication is required for negotiation’ and imagine that all the agents choosing project k (Sk ∪ T ) together collaborate to improve their payments. Formally, we define a solution (S, p̄) to be core stable if the following two conditions are satisfied,\n(Stability) No set of agents can deviate to a project and obtain more total value for everyone in that project than their payments, i.e., for every set of agents T and project k, ∑ i∈T∪Sk p̄i ≥\nvk(T ∪ Sk). (Budget-Balance) The total payments sum up to the social welfare (i.e., total value) of the\nsolution: ∑ i∈N p̄i = ∑ k∈P vk(Sk).\nObserve that Stability for T = ∅ together with budget-balancedness imply that the value created from a project will go to the agents on that project only. Finally, we consider a full-information setting as it is reasonable to expect the central authority to be capable of predicting the value generated when agents work on a project.\n(Example 1) We begin our work with an impossibility result: even for simple instances with two projects and four agents, a core stable solution need not exist. Consider P = {1, 2}, and\ndefine v1(N ) = 4 and v1(S) = 2 otherwise; v2(S) = 1+ for all S ⊆ N . If all agents are assigned to project 1, then in a budget-balanced solution at least one agent has to have a payment of at most 1; such an agent would deviate to project 2. Instead, if some agents are assigned to project 2, then it is not hard to see that they can deviate to project 1 and the total utility goes from 3 + to 4.\nApproximating the Core Our goal is to compute solutions that guarantee a high degree of stability. Motivated by this, we view core stability under the lens of approximation. Specifically, as is standard in cost-sharing literature [29,39], we consider relaxing one of the two requirements for core stability while retaining the other one. First, suppose that we generalize the Stability criterion as follows:\n(α-Stability) For every set of agents T and every project k, vk(Sk ∪T ) ≤ α ∑\ni∈Sk∪T p̄i.\nα-stability captures the notion of a ‘switching cost’ and is analogous to an Approximate Equilibrium; in our example, one can imagine that employees do not wish to quit the firm unless the rewards are at least a factor α larger. In the identical projects literature, the solution having the smallest value of α is known as the Multiplicative Least-Core [10]. Next, suppose that we only relax the budget-balance constraint,\n(β-Budget Balance) The payments are at most a factor β larger than the welfare of the solution.\nThis generalization offers a natural interpretation: the central authority can subsidize the agents to ensure high welfare, as is often needed in other settings such as public projects or academic funding [7]. In the literature, this parameter β has been referred to as the Cost of Stability [4,35].\nWe do not argue which of these two relaxations is the more natural one: clearly that depends on the setting. Fortunately, it is not difficult to see that these two notions of approximation are equivalent. In other words, every approximately core stable solution with α-stability can be transformed into a solution with α-budget balancedness by scaling the payments of every player by a factor α. Therefore, in the rest of this paper, we will use the term α-core stable without loss of generality to refer to either of the two relaxations. All our results can be interpreted either as forming fully budget-balanced payments which are α-stable, or equivalently as fully stable payments which are α-budget balanced. Finally, the problem that we tackle in this paper can be summarized as follows:\n(Problem Statement) Given an instance with subadditive valuation functions, compute an α-core stable solution (S, (p̄)i∈N ) having as small a value of α as possible, that approximately maximizes social welfare."
    }, {
      "heading" : "1.2 Our Contributions",
      "text" : "The problem that we face is one of bi-criteria approximation: to simultaneously optimize both social welfare and the stability factor α (α = 1 refers to a core stable solution). For the rest of this paper, we will use the notation (α, c)-Core stable solution to denote an α-Core solution that is also a c-Approximation to the optimum welfare. The bounds that we derive are quite strong: we are able to approximate both α and c simultaneously to be close to the individually\nbest-possible lower bounds. In a purely algorithmic sense, our problem can be viewed as one of designing approximation algorithms that require the additional property of stabilizability.\nMain Result Our main result is the following black-box reduction that reduces the problem of finding an approximately core stable solution to the purely algorithmic problem of welfare maximization,\n(Informal Theorem). For any instance where the projects have subadditive valuations, any LP-based α-approximation to the optimum social welfare can be transformed in poly-time to a (2α, 2α)-core stable solution.\nThe strength of this result lies in its versatility: our algorithm can stabilize any input allocation at the cost of half the welfare. The class of subadditive valuations is extremely general, and includes many well-studied special classes all of which use LP-based algorithms for welfare maximization; one can simply plug-in the value of α for the corresponding class to derive an approximately core stable solution. In particular, for general subadditive valuations, one can use the 2-approximation algorithm of Feige [20] and obtain a (4, 4)-Core. As is standard in the literature [18], we assume that our subadditive functions are specified in terms of a demand oracle (see Section 2 for more details). However, even in the absence of a demand oracle, one can obtain a poly-time reduction as long as we are provided an allocation and the optimum dual prices as input.\nFor various sub-classes of subadditive valuations, we obtain stronger results by exploiting special structural properties of those functions. These results are summarized in Table 1. The classes that we study are extremely common and have been the subject of widespread interest in many different domains.\nLower Bounds. All of our results are ‘almost tight’ with respect to the theoretical lower bounds for both welfare maximization and stability. Even with anonymous functions, a (2− ) core may not exist; thus our (2, 2)-approximation for this class is tight. For general subadditive functions, one cannot compute better than a 2-approximation to the optimum welfare efficiently, and so our (4, 4) result has only a gap of 2 in both criteria. Finally, for XoS and Submodular functions, we get almost stable solutions ((1+ )-Core) that match the lower bounds for welfare maximization.\nA Fast Algorithm for Anonymous Subadditive Functions We devise a greedy 2-approximation algorithm for anonymous functions that may be of independent algorithmic interest. The only known 2-approximation algorithm even for this special class is the rather complex LP rounding mechanism for general subadditive functions. In contrast, we provide an intuitive greedy algorithm that obtains the same factor, and use the structural properties of our algorithm to prove\nimproved bi-criteria bounds ((2, 2) as opposed to (4, 4)).\nTies to Combinatorial Auctions with Item Bidding We conclude by pointing out a close relationship between our setting and simultaneous auctions where buyers bid on each item separately [9,14,17]. Consider ‘flipping’ an instance of our problem to obtain the following combinatorial auction: every project k ∈ P is a buyer with valuation vk, and every i ∈ N is an item in the market. We prove an equivalence between Core stable solutions in our setting and Pure Nash equilibrium for the corresponding flipped simultaneous second price auction. Adapting our lower bounds to the auction setting, we make a case for Approximate Nash Equilibrium by constructing instances where every exact Nash equilibrium requires buyers to overbid by a factor of O( √ N), when they have anonymous subadditive valuations. Finally, we apply our earlier algorithms to efficiently compute approximate equilibria with small over-bidding for two settings, namely, (i) a 12 -optimal, 2-approximate equilibrium when buyers have anonymous subadditive valuations, and (ii) a (1− 1e )-optimal, 1 + -approximate equilibrium for submodular buyers."
    }, {
      "heading" : "1.3 Related Work",
      "text" : "The core has formed the basis for a staggering body of research in a myriad of domains, and one cannot hope to do justice to this vast literature. Therefore, we only review the work most pertinent to our model. The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an α-core. That said, there are a few overarching differences between our model, and almost all of the papers studying the core and its relatives; (i) Duplicate Projects: In the classic setting, it is assumed that there are infinite copies of one identical project so that different subsets of agents (say S1, S2) working independently on the same project can each generate their full value (v(S1) + v(S2)), and (ii) Superaddivity: In order to stabilize the grand coalition, most papers assume that the valuation is superadditive, which inherently favors cooperation. On the contrary, our setting models multiple dissimilar projects where each project is a fixed resource with a subadditive valuation.\nAlthough cooperative games traditionally do not involve any optimization, a number of papers have studied well-motivated games where the valuation or cost function (c(S)) is derived from an underlying combinatorial optimization problem [15,26,28,34]. For example, in the vertex cover game [15, 19] where each edge is an agent, c(S) is the size of the minimum cover for the edges in S. Such settings are fundamentally different from ours because the hardness arises from the fact that the value of the cost function cannot be obtained precisely. For many such problems, core payments can be computed almost directly using LP Duality [26,28,34].\nIn the cooperative game theory literature, our setting is perhaps closest to the work studying coalitional structures where instead of forming the grand coalition, agents are allowed to arbitrarily partition themselves [4,27] or form overlapping coalitions [12]. This work has yielded some well-motivated extensions of the Core, albeit for settings with duplicate projects. Our work is similar in spirit to games where agents form coalitions to tackle specific tasks, e.g., threshold task games [12] or coalitional skill games [5]. In these games, there is still a single valuation function v(S) which depends on the (set of) task(s) that the agents in S can complete. Once again, the tacit assumption is that there are an infinite number of copies of each task.\nRecently, there has been a lot of interest in designing cost-sharing mechanisms that satisfy strategy-proofness in settings where a service is to be provided to a group of agents who hold private values for the same [16, 37]. In contrast, we look at a full information game where the central agency can exactly estimate the output due to a set of agents working on a project. A powerful relationship between our work and the body of strategy-proof mechanisms was discovered by Moulin [36] who showed that a natural class of ‘cross-monotonic cost sharing schemes’ can be used to design mechanisms that are both core-stable (CS) and strategy-proof (SP). This has led to the design of beautiful SP+CS mechanisms for several combinatorially motivated problems with a single identical project or service [25, 39]. Finally, we briefly touch upon the large body of literature in non-transferable utility games that (like us) study coalition formation with a finite number of asymmetric projects [2, 11, 13,23]. However, these papers use fixed reward-sharing schemes, and thus do not model the bargaining power of agents that is a key aspect of coalition formation."
    }, {
      "heading" : "2 Model and Preliminaries",
      "text" : "We consider a transferable-utility coalition formation game with a set P of m projects and a set N of N agents. Each project k ∈ P is specified by a monotone non-decreasing valuation function vk : 2\nN → R+ ∪ {0}. A solution consists of an allocation of agents to projects S = (S1, . . . , Sm), and a payment scheme (p̄)i∈N and is said to be (α, c)-core stable for α ≥ 1, c ≥ 1 if • The payments are fully budget-balanced, and for every project k, and set T of agents, vk(Sk ∪ T ) ≤ α ∑ i∈Sk∪T p̄i. An equivalent condition is that the payments are at most a\nfactor α times the social welfare of the solution, and we have full stability, i.e., vk(Sk ∪ T ) ≤∑ i∈Sk∪T p̄i. • The allocation S is a c-approximation to the optimum allocation, i.e., the welfare of the solution S is at least 1c times the optimum welfare.\nThroughout this paper, we will use OPT to denote the welfare maximizing allocation as long as the instance is clear. Given an allocation S = (S1, . . . , Sm), we use SW (S) = ∑m k=1 vk(Sk) to denote the social welfare of this allocation, and ζ(S) to be the set of projects that are empty under S, i.e., k ∈ ζ(S) if Sk = ∅."
    }, {
      "heading" : "Comparison to Traditional Models",
      "text" : "We digress briefly to highlight the key differences between our model as defined above and traditional utility-sharing settings found in the literature. Traditionally, a transferable-utility coalition formation game consists of a single valuation function v(S). The objective there is to provide a vector of payments (pi to user i) in order to stabilize some desired solution S = (S1, . . . , Sr)\n1, where the number of coalitions r can be any positive integer. Here, core stability means that for any group of agents T ⊆ N , ∑i∈T pi ≥ v(T ). Notice from the above definition that (unlike our setting), the same core payments are applicable for every single solution S, i.e., the payments are completely independent of the solution formed.\nA stark contrast to our notion of a stable solution is the implicit assumption that there are an infinite number of copies of a single project (specified by v(S)) available for the agents\n1 Usually, this is the grand coalition but it can also refer to other solutions, for example, the social welfare maximizing solution\nto deviate to. For instance, a necessary condition for core stability is that pi ≥ v(i) for every agent i; this implies that in theory, each of the N agents could work independently on the same project and generate a total value of ∑ i v(i) and not v(N). As mentioned in the introduction, such assumptions do not always make sense, and it is reasonable to assume that the value generated depends on which project the agents deviate to, and how many other agents are currently working on that project or resource. Finally, in the traditional model, the minimum core payments (irrespective of the solution) can be obtained directly using the dual of the allocation LP. In contrast, this is not so in our setting due to the presence of slack variables (See Section 3).\nValuation Functions Our main focus in this paper will be on the class of monotone subadditive valuation functions. A valuation function v is said to be subadditive if for any two sets S, T ⊆ N , v(S ∪ T ) ≤ v(S) + v(T ), and monotone if v(S) ≤ v(S ∪ T ). The class of subadditive valuations encompasses a number of popular and well-studied classes of valuations, but at the same time is significantly more general than all of these classes. It is worth noting that when there are an unlimited number of allowed groups, subadditive functions are almost trivial to deal with: both the maximum welfare solution and the stabilizing payments are easily computable. For our setting, however, computing OPT becomes NP-Hard, and a fully core-stable solution need not exist. Due to the importance and the natural interpretation of subadditive functions, we believe it is very desirable to understand utility sharing under such valuations; our paper presents the first known results on utility sharing for general subadditive functions. In addition, we are able to show stronger results for the following two sub-classes that are extremely common in the literature.\nSubmodular Valuations For any two sets S, T with T ⊆ S, and any agent i, v(S ∪ {i}) − v(S) ≤ v(T ∪ {i})− v(T ). Fractionally Subadditive (also called ‘XoS’) Valuations ∃ a set of additive functions (a1, . . . , ar) such that for any T ⊆ N , v(T ) = maxrj=1 aj(T ). These additive functions are referred to as clauses.\nRecall that an additive function aj has a single value aj(i) for each i ∈ N so that for a set T of agents, aj(T ) = ∑ i∈T aj(i). The reader is asked to refer to [18, 20, 31, 44] for alternative definitions of the XoS class and an exposition on how both these classes arise naturally in many interesting applications. Anonymous Subadditive Functions In project assignment settings in the literature modeling a number of interesting applications [30, 35], it is reasonable to assume that the value from a project depends only on the number of users working on that project. Mathematically, this idea is captured by anonymous functions: a valuation function is said to be anonymous if for any two subsets S, T with |S| = |T |, we have v(S) = v(T ). One of our main contributions in this paper is a fast algorithm for the computation of Core stable solutions when the projects have anonymous subadditive functions. We remark here that anonymous subadditive functions form an interesting sub-class of subadditive functions that are quite different from submodular and XoS functions.\nDemand Oracles. The standard approach in the literature while dealing with set functions (where the input representation is often exponential in size) is to assume the presence of an\noracle that allows indirect access to the valuation by answering specific types of queries. In particular, when dealing with a subadditive function v, it is typical to assume that we are provided with a demand oracle that when queried with a vector of payments p, returns a set T ⊆ N that maximizes the quantity v(T )−∑i∈T pi [18]. Demand oracles have natural economic interpretations, e.g., if p represents the vector of potential payments by a firm to its employees, then v(T )−∑i∈T pi denotes the assignment that maximizes the firm’s revenue or surplus.\nIn this paper, we do not explicitly assume the presence of a demand oracle; our algorithmic constructions are quite robust in that they do not make any demand queries. However, any application of our black-box mechanism requires as input an allocation which approximates OPT, and the optimum dual prices, both of which cannot be computed without demand oracles. For example, it is well-known [18] that one cannot obtain any reasonable approximation algorithm for subadditive functions (better than O( √ N)) in the absence of demand queries. That said, for several interesting valuations, these oracles can be constructed efficiently. For example in the case of XoS functions, a demand oracle can be simulated in time polynomial in the number of input clauses. We conclude this discussion by reiterating that demand oracles are an extremely standard tool used in the literature to study combinatorial valuations; almost all of the papers [18,20,25] studying Subadditive or XoS functions take the presence of a demand oracle for granted.\n2.1 Warm-up Result: (1, 2)-Core for Submodular Valuations\nWe begin with an easy result: an algorithm that computes a core stable solution when all projects have submodular valuations, and also retains half the optimum welfare. Although this result is not particularly challenging, it serves as a useful baseline to highlight the challenges involved in computing stable solutions for more general valuations. Later, we show that by sacrificing an amount of stability, one can compute for submodular functions, a solution with a much better social welfare ( ee−1 -approximation to OPT).\nClaim 1 We can compute in poly-time a (1, 2)-Core stable solution for any instance with submodular project valuations.\nThe above claim also implies that for every instance with submodular project valuations, there exists a Core stable solution. In contrast, for subadditive valuations, even simple instances (Example 1) do not admit a Core stable solution.\nProof: The proof uses the popular greedy half-approximation algorithm for submodular welfare maximization due to [31]. Initialize the allocation X to be empty. At every stage, add an agent i to project k so that the value vk(Xk ∪ {i}) − vk(Xk) is maximized. Set i’s final payment p̄i to be exactly the above marginal value. Let the final allocation once the algorithm terminates be S, so ∑ i∈Sk p̄i = vk(Sk). Consider any group of agents T , and some project k: by the definition of the greedy algorithm, and by submodularity, it is not hard to see that ∀i ∈ T , p̄i ≥ vk(Sk ∪ {i}) − vk(Sk). Therefore, we have that ∑ i∈T p̄i ≥ vk(Sk ∪ T ) − vk(Sk), and since the payments are clearly budget-balanced, the solution is core-stable.\nChallenges and Techniques for Subadditive Valuations At the heart of finding a Core allocation lies the problem of estimating ‘how much is an agent worth to a coalition’. Unfortunately, the idea used in Claim 1 does not extend to more general valuations as the marginal value is no longer representative of an agent’s worth. One alternative approach is to use the\ndual variables to tackle this problem: for example, in the classic setting with duplicate projects, every solution S along with the dual prices as payments yields an α-budget balanced core. Therefore, the challenge there is to bound the factor α using the integrality gap. However, this is no longer true in our combinatorial setting as the payments are closely linked to the actual solution formed, and moreover, there is no clear way of dividing the dual variables due to the presence of slack (see LP 1). Our Approach. We attempt to approximately resolve the question of finding each agent’s worth by identifying (for each project) a set of “heavy users” who contribute to half the project’s value. We provide large payments to each heavy user based on her best outside option which are determined using Greedy Matchings. Finally, the dual variables are used only as a ‘guide’ to ensure that ∀k ∈ P, the payment given to the users on that project is at least a good fraction of the value they generate."
    }, {
      "heading" : "3 Computing Approximately Core Stable Solutions",
      "text" : "In this section, we show our main algorithmic result, namely a black-box mechanism that reduces the problem of finding a core stable solution to the algorithmic problem of subadditive welfare maximization. We use this black-box in conjunction with the algorithm of Feige [20] to obtain a (4, 4)-Core stable solution, i.e., a 4-approximate core that extracts one-fourth of the optimum welfare. Using somewhat different techniques, we form stronger bounds ((2, 2)-Core) for the class of anonymous subadditive functions. Our results for the class of anonymous functions are tight: there are instances where no (2 − , 2 − )-core stable solution exists. This indicates that our result for general subadditive valuations is close to tight (up to a factor of two).\nWe begin by stating the following standard linear program relaxation for the problem of computing the welfare maximizing allocation. Although the primal LP contains an exponential number of variables, the dual LP can be solved using the Ellipsoid method where the demand oracle serves as a separation oracle [18]. The best-known approximation algorithms for many popular classes of valuations use LP-based rounding techniques; of particular interest to us is the 2-approximation for Subadditive valuations [20], and ee−1 -approximation for XoS valuations [18].\nmax M∑ k=1 ∑ S⊆N xk(S)vk(S) (D) min N∑ i=1 pi + M∑ k=1 zk\ns.t. M∑ k=1 ∑ S3i xk(S) ≤ 1 ∀i ∈ N s.t. ∑ i∈S\npi + zk ≥ vk(S) ∀S, k∑ S⊆N xk(S) ≤ 1, ∀k ∈ P pi ≥ 0, ∀i ∈ N xk(S) ≥ 0, ∀S,∀k zk ≥ 0, ∀k ∈ P\n(1)\nAs long as the instance is clear from the context, we will use (p∗, z∗) to denote the optimum solution to the Dual LP, referring to p∗ as the dual prices, and z∗ as the slack. Main Result We are now in a position to show the central result of this paper. The following black-box mechanism assumes as input an LP-based α-approximate allocation, i.e., an allocation whose social welfare is at most a factor α smaller than the value of the LP optimum for that instance. LP-based approximation factors are a staple requirement for black-box mechanisms that\nexplicitly make use of the optimum LP solution [25]. Along these lines, we make the assumption that the optimum dual variables (for the given instance) are available to the algorithm along with an input allocation.\nTheorem 2. Given any α-approximate solution to the LP optimum, we can construct a (2α, 2α)Core Stable Solution in polynomial time as long as the projects have subadditive valuations.\nFor general subadditive functions, the only known poly-time constant-factor approximation is the rather intricate randomized LP rounding scheme proposed in [20]. Using this 2- approximation, we get the following corollary.\nCorollary 3. We can compute in poly-time a (4, 4)-Core stable solution for any instance with subadditive projects.\nWe now prove Theorem 2.\nProof: We provide an algorithm that takes as input an allocation A = (A1, . . . Am) that is an α-approximation to the LP Optimum and returns a core stable solution S = (S1, . . . , Sm) along with payments (p̄)i∈N whose welfare is at least half that of A, and such that the total payments are at most 2α times the welfare of S.\nRecall that in a core stable solution S, it is necessary that for every project k and set T of agents, vk(Sk ∪ T ) ≤ ∑ i∈Sk∪T p̄i. A naive approach is to consider whether the dual payments (price p∗i plus the slack z ∗ k divided equally among Ak) would suffice to enforce core stability to the solution A. Unfortunately, this naive strategy fails because the payments are not enough to prevent the deviation of agents to empty projects. To remedy this, we take the following approach: we implement a matching-based routine that allows us to identify the ‘light’ and ‘heavy’ users at each project so that when the light users deviate to the empty projects, there is not much welfare loss (and vice-versa for the heavy users). We assign the light users to these projects, and provide the heavy users with payments that depend on both ‘the best outside option’ available to them and their contribution to social welfare in order to stabilize them.\nWe begin by defining a simple Greedy Matching with Reserve Prices procedure that will serve as a building block for our main algorithm. The procedure is straightforward so we state it in words here and formally define it in Appendix A.\nAlgorithm 2: “Begin with an input allocation and initial payments. During every iteration, assign an agent i to a currently empty project k, as long as her current payment pi < vk(i), and update her payment to vk(i). Terminate when pi ≥ vk(i) for each agent i and empty project k.”\nWe begin our analysis of the above procedure with a simple observation: during the course of the algorithm, the payments of the agents are non-decreasing (in fact, in every iteration, the payment of at least one agent strictly increases). Specifically, we are interested in analyzing the solution returned by the algorithm when the input allocation is A, and the input payments are the naive dual payments discussed above. We first describe some notation and then prove some lemmas regarding the solution returned by the algorithm for this input. Recall that for any given solution X, ζ(X) denotes the set of empty projects under X.\nWe denote by p0 the marginal contributions given by the optimal dual payment plus the slack divided equally as per A, i.e., if agent i ∈ Ak, then p0i = p∗i + z∗k |Ak| . Suppose we run the\nalgorithm on the input (A,p0); let the corresponding output allocation be B, and the payments be pB. Also define for every k ∈ P \\ ζ(A), A+k = Ak ∩ Bk to be the agents who remained on project k, A−k = Ak \\A+k to be the agents who left project k, and Pk to be the set of projects that the agents in A−k switched to in allocation B. Note that all the projects in Pk will only have one agent each in B due to the definition of the algorithm. We now divide the non-empty projects in A into two categories based on the welfare lost after running the algorithm. Specifically, consider any project k in P \\ ζ(A). We refer to k as a good project if the welfare in B due to the agents originally in Ak is at least half their original welfare, and refer to k as a bad project otherwise. That is, k is a good project iff,\nvk(A + k ) + ∑ l∈Pk vl(Bl) ≥ vk(Ak) 2 .\nThe following lemma which we prove in the Appendix establishes the crucial fact that although bad projects may result in heavy welfare losses, they surprisingly retain at least half the agents originally assigned to them under A. Later, we use this to infer that the agents who deviated from bad projects are ‘heavy’ users who contribute significantly to the project’s welfare.\nLemma 4. For every bad project k, |A+k | > |A−k |, i.e., more than half the agents in Ak still remain in project k.\nOur next lemma relates the output payments pB to the optimal dual variables.\nLemma 5. For every project k, and every agent i who is allocated to k in B, her payment under pB is not larger than p∗i + z∗k |Bk| .\nProof: We prove the lemma in two cases. First consider any agent i whose allocation remains the same (say project k) during the entire course of Algorithm 2 for the input (A,p0). Clearly, this agent’s final payment returned by the algorithm pBi is exactly the same as her initial payment p0i = p ∗ i + z∗k |Ak| . However, we know that |A + k | ≤ Bk. Therefore, pBi = p∗i + z∗k |Ak| ≤ p ∗ i + z∗k |Bk| .\nNext, consider an agent i ∈ Bk whose allocation changed at some point during the course of the algorithm. This means that |Bk| = 1. Then, by definition, her final payment is exactly vk(i), which is not larger than p∗i + z ∗ k by dual feasibility. ut\nMain Algorithm: Phase I While the returned solution B is indeed core stable, its welfare may be poor due to the presence of one or more bad projects. Instead of using solution B, we use its structure as a guide for how to form a high-welfare solution. For good projects, we can put the agents in A+k onto k and the agents in A − k onto Pk; since these are good projects this is guaranteed to get us half of the welfare vk(Ak), as desired. For bad projects, on the other hand, more than half of the welfare disappeared when we moved agents on A−k away; due to sub-additivity this means that vk(A − k ) ≥ vk(Ak) 2 . So instead we will assign agents in A − k to project k (which is the opposite of what happens in solution B), and put some agents from A+k onto projects Pk. This is Phase I of our main algorithm, defined formally in Appendix A. Payments at the end of Phase I: Suppose that the allocation at the end of the above procedure is S′; let us define the following payment vector p′. For every good project k: for each agent i assigned to l ∈ k ∪ Pk, her payment is p′i = p∗i + z∗l |S′l | . For every bad project k, define Dk := S ′ k \\ A−k to be the set of dummy agents belonging to that project. Each dummy agent\nreceives exactly p′i = p ∗ i as payment; every non-dummy agent assigned to a bad project receives p′i = p B i plus the left over slack from that project. For each bad project k, every agent i assigned to some l ∈ Pk receives a payment of p′i = p∗i + z∗l . We break the flow of our algorithm and show some properties satisfied by the solution returned by Phase I of our algorithm (S′,p′). Mainly we show that this solution is almost corestable and has desired welfare properties. In Phase II, we once again invoke our Greedy Matching Procedure to ensure core-stability. Recall that every bad project contains at least one dummy agent; all the agents N other than the dummy agents will be referred to as non-dummy agents.\nLemma 6. For every agent i that does not belong to the set of dummy agents, her payment at the end of the first phase (p′i) is at least her payment returned by the call to the Greedy Matching Procedure pBi .\nSpecifically, the above lemma implies that with respect to the non-dummy agents, our solution (S′,p′) retains the ‘nice’ stability properties guaranteed by the greedy matching procedure.\nCorollary 7. For every empty project k in S′ (i.e., k ∈ ζ(S′)), and every non-dummy agent i, her payment at the end of the first phase is at least her individual valuation for project k, i.e.,\np′i ≥ vk(i).\nNow that we have a lower bound on the payments returned by the first phase of our algorithm, we show a stricter lemma giving an exact handle on the payments.\nLemma 8. For every non-empty project k /∈ ζ(S′), the total payment to agents in k at the end of Phase I is exactly ∑ i∈S′k p∗i + z ∗ k.\nOur final lemma shows that the total welfare at the end of the first phase is at least half the welfare of the original input allocation A.\nLemma 9. For every good project k, the welfare due to the agents in k ∪ Pk is at least half of vk(Ak)\n2 . For every bad project k, the welfare due to the non-dummy agents in k, i.e., A − k is at\nleast half of vk(Ak)2 .\nProof: The first half of the lemma is trivially true because of the definition of good projects and the fact that the allocation of agents to the projects in k ∪ Pk is the same as the allocation returned by the call to Algorithm 2.\nMoving on to bad projects, we know that S′k ⊇ A−k and the agents in A−k are exactly the non-dummy agents in project k. Therefore, we have\nvk(A − k ) ≥ vk(Ak)− vk(A+k ) ≥ vk(Ak)−\nvk(Ak)\n2 (By the definition of bad projects).\nObserve that by virtue of this lemma, we can immediately obtain that the solution returned by the first phase of our algorithm has half the social welfare of the allocation A. ut"
    }, {
      "heading" : "Main Algorithm - Phase II",
      "text" : "From the above lemmas, it is not hard to conclude that the solution S′ at the end of Phase I has good social welfare and is resilient against deviations to empty projects as long as we only consider non-dummy agents2. In the second phase of our algorithm, we fix this issue by allowing dummy agents to deviate to empty projects using our Greedy Matching procedure and lower bounding their final payments using the dual variables. We formalize the algorithm for Phase II in the Appendix. Suppose that S is the solution returned by the Greedy Matching Algorithm with input (S′,p′), and p̄ is the payment vector where all the agents who deviated from S′ receive as much as their dual variables, and the rest of the agents receive their payment under p′. We now state some simple properties that compare the output of Phase II with its input, and formally prove them in Appendix A.\nClaim 10 The following properties are true:\n1. The set of empty projects in S is a subset of the set of empty projects in S′, i.e., ζ(S) ⊆ ζ(S′). 2. For all non-dummy agents, their strategies in S′ and S coincide. 3. For every agent i ∈ N , her payment at the end of Phase II (p̄i) is at least her payment at the end of Phase I.\nOur final lemma before showing the main theorem tells us that for every project, the total payment made to agents of that project coincides with the dual payments. The final payments to agents, therefore, are simply a redistribution of the dual payments. We defer its proof to the Appendix.\nLemma 11. For every non-empty project k /∈ ζ(S), the total payments made to agents in k is exactly ∑ i∈Sk p ∗ i + z ∗ k. Moreover, the payment made to any agent i is at least her dual price p ∗ i .\nThe rest of the theorem follows almost immediately. We begin by showing that the solution (S, (p̄)i) is core stable. Consider any project k, and a deviation by some set of agents T to this project. We only have to show that the total payment made to the agents in Sk ∪ T is at least vk(Sk ∪ T ). We proceed in two cases.\nFirst, suppose that Sk = ∅. Then, we have vk(Sk ∪ T ) ≤ ∑ i∈Sk∪T vk(i) ≤ ∑\ni∈Sk∪T p̄i from Subadditivity, and Claim 10 respectively. Claim 10). Now suppose that Sk 6= ∅. Then, we have∑\ni∈Sk∪T p̄i = ∑ i∈Sk p̄i + ∑ i∈T p̄i ≥ ∑ i∈Sk p∗i + z ∗ k + ∑ i∈T p∗i By Lemma 11\n≥ vk(Sk ∪ T ) By dual feasibility\nWe now establish that the social welfare of our solution is at least half the social welfare of the original allocation A. Recall that every non-empty project in A was classified as a good or bad project. For every good project k and its associated projects Pk, the fact that vk(Sk) +∑\nl∈Pk vl(Sl) ≥ vk(Ak)/2 follows from Lemma 9 since Sk = S ′ k, and Sl = S ′ l.\nConsider any bad project k. We know that for every non-dummy agent in S′k, her strategy in S is still project k. Therefore, the welfare due to any bad project is at least the welfare due to the non-dummy agents in that project which by Lemma 9 is at least half of vk(Ak). Finally,\n2 We can also show that the solution is resilient against deviations to non-empty projects, although this is not needed at this time.\nall that remains is to show that the total payments made in (p̄)i are at most a factor 2α larger than the welfare of the solution.\nFrom Lemma 11, we know that the total payments made to agents at the end of Phase I is at most the value of the Dual Optimum of LP 1, which by Strong Duality is equal to the value of the Primal Optimum. However, we know that the welfare of S is at least half the welfare of A, which by definition is at most a factor α away from the LP Optimum. This completes the proof."
    }, {
      "heading" : "3.1 Anonymous Functions",
      "text" : "Our other main result in this paper is a (2, 2)-Core stable solution for the class of subadditive functions that are anonymous. Recall that for an anonymous valuation v, v(T1) = v(T2) for any |T1| = |T2|. Such functions are frequently assumed in coalition formation and project assignment settings [30]. We begin with some existential lower bounds for approximating the core. From Example (1), we already know that the core may not exist even in simple instances. Extending this example, we show a much stronger set of results.\nClaim 12 (Lower Bounds) There exist instances having only two projects with anonymous subadditive functions such that\n1. For any > 0, no (2− , c1)-core stable solution exists for any value c1. 2. For any > 0, no (c2, 2− )-core stable solution exists for any value c2.\n(Proof Sketch) (Part 1) For ease of notation, we show that no (2− )-budget-balanced core stable solution exists for a given > 0. Consider an instance with N buyers. The valuations for the two projects are v1(S) = N 2 ∀S ⊂ N , and v1(N ) = N ; v2(S) = 2 ∀S ⊆ N . Assume by contradiction that there is a (2− )-core stable solution, then this cannot be achieved when all of the agents are assigned to project 1 because they would each require a payment of 2 to prevent them from deviating to project 2. On the other hand, suppose that some agents are assigned to project 2, then the social welfare of the solution is at most N2 + 2. If these agents cannot deviate to project 1, then, the total payments would have to be at least v1(N ) = N . For a sufficiently large N , we get that the budget-balance is NN/2+2 > 2 − . The example for Part 2 is provided in the Appendix.\nWe now describe an intuitive 2-approximation algorithm (Algorithm 1) for maximizing welfare that may be of independent interest. To the best of our knowledge, the only previously known approach that achieves a 2-approximation for anonymous subadditive functions is the LP-based rounding algorithm for general subadditive functions [20]. Our result shows that for the special class of anonymous functions, the same approximation factor can be achieved by a much faster, greedy algorithm. In addition, our greedy algorithm also possesses other ‘nice structural properties’ that may be of use in other settings such as mechanism design [33]. Recall that the quantity v(T |S) refers to v(S ∪ T )− v(S). Although Algorithm 1 is only an approximation algorithm, the following theorem shows that we can utilize the greedy structure of the allocation and devise payments that ensure core stability. In particular, the solution that we use to construct a (yet to be proved) (2, 2)-core is (S, p̄), where S is the allocation returned by the algorithm, and p̄i = 2pi is the payment provided to agent i. We remark that the ‘marginal contributions’ are defined only for the sake\nAlgorithm 1: Greedy 2-Approximation Algorithm for Anonymous Subadditive Functions 1: Initialize the set of unallocated agents U ← N 2: Initialize the current allocation S ← (∅, . . . , ∅) 3: while U 6= ∅ do 4: Find a set T ⊆ U that maximizes the ratio vk(T |Sk)|T | over all k ∈ P\n5: Assign the agents in T to the project k that maximizes the above ratio {Sk = Sk ∪ T and U = U \\ T .} 6: For all i ∈ T , set agent i’s marginal contribution pi = vk(T |Sk)|T | . 7: end while 8: Return the final allocation S.\nof convenience. They do not serve any other purpose. We make the following simple observation regarding the algorithm: the total social welfare of the solution S, SW (S) is exactly equal to the sum of the marginal contributions ∑ i∈N pi.\nTheorem 13. For any instance with anonymous subadditive projects, the allocation S returned by Algorithm 1 along with a payment of p̄i = 2pi for every i ∈ N constitutes a (2, 2)-core stable solution.\nProof: We begin with some basic notation and simple lemmas highlighting the structural properties of our algorithm leading up to the main result. First, note that the total payments are exactly equal to the twice the aggregate marginal contribution, which in turn is equal to twice the social welfare. Therefore, our solution is indeed 2-budget balanced. Now, let us divide the execution of the greedy algorithm into iterations from 1 to r such that in every iteration, the algorithm chooses a set of unallocated agents maximizing the marginal contribution (average increase in welfare). We define Aj to be the set of agents assigned to some project during iteration j ≤ r. Clearly, all the agents in Aj are allocated to the same project, and have the exact same marginal contribution, and therefore payment. Let us use p(j) to refer to the marginal contribution of the agents in Aj .\nNote that in order to characterize the state of the algorithm during iteration j, it is enough if we express the set of agents assigned to each project, and the set of unallocated agents. Define S (j) k to be the set of agents allocated to project k at the beginning of iteration j (before the agents in Aj are assigned), and U (j) to be the set of unallocated agents during that instant. Suppose that the agents in Aj are assigned to project k, then by definition the following equation must be true,\np(j) = vk(Aj |S(j)k ) |Aj | .\nFinally, given any T ⊆ N , we denote by T>, the ordered set of elements in T in the decreasing order of their payment. We begin with a simple property that links the prices to the welfare of every project.\nProposition 14. In the final allocation S, the social welfare due to every project k equals the total marginal contributions to the agents assigned to that project, i.e.,∑\ni∈Sk\npi = vk(Sk).\nThe proof follows directly from the definition of the algorithm. Now, we establish that as the algorithm proceeds, the marginal contributions of the agents cannot increase.\nLemma 15. For every i, j with i < j, the marginal of the agents in Ai is not smaller than the marginal of the agents in Aj, i.e., p (1) ≥ p(2) ≥ . . . ≥ p(r).\n(Proof Sketch) Since, the assignment of agents to any one project does not affect the marginal contribution (or average increase in welfare) in other projects, it suffices to prove the lemma for the case when Ai and Aj are assigned to the same project. The rest of the proof involves showing that if the lemma does not hold, then adding Ai ∪Aj instead of Ai in iteration i would have lead to larger average welfare. The full proof is in the Appendix.\nRecall that Proposition 14 equates the marginal contributions to the welfare for every set Sk. The following lemma establishes a relationship between payments and welfare for subsets of Sk. Note that since the payments to the agents are exactly twice their marginal, we can use the payments and marginal contributions interchangeably. Once again, its proof is in Appendix B.\nLemma 16. For every project k, and any given positive integer t ≤ |Sk|, the total marginal contribution of the t highest paid agents in Sk is at least the value derived due to any set of t agents, i.e., if T denotes the set of t-highest paid agents in Sk, then∑\ni∈T pi ≥ vk(T ).\nWe now move on to the most important component of our theorem, which we call the Doubling Lemma. This lemma will serve as the fundamental block required to prove both core stability and the necessary welfare bound. The essence of the lemma is rather simple; it says that if we take some project k and add any arbitrary set of elements T on top of Sk, then the total resulting welfare is no larger than the final payments to the agents in T ∪Sk. We first state the Doubling Lemmma here and then prove that using this lemma as a black-box, we can obtain both our welfare and stability result. The proof of the lemma is deferred to the Appendix.\nLemma 17. (Doubling Lemma) Consider any project k and the set of elements assigned to k in our solution (Sk). Let T be some set of agents such that T ∩ Sk = ∅ and |T | > |Sk|. Then, the total payment to the agents in T ∪ Sk is at least vk(Sk ∪ T ), i.e.,∑\ni∈T∪Sk\np̄i ≥ vk(Sk ∪ T )."
    }, {
      "heading" : "Proof of Core stability",
      "text" : "We need to show that our solution (S, (p̄)i) is core stable, i.e., for every project k and set of agents T , vk(Sk ∪ T ) ≤ ∑ i∈Sk∪T p̄i. Assume by contradiction that ∃ some project k and some set T that does not satisfy the inequality for stability. We claim that |T | > |Sk|. Lemma 18. If vk(Sk ∪ T ) > ∑\ni∈Sk∪T p̄i, then there are strictly more agents in the set T than in project k under S, i.e., |T | > |Sk|.\nProof: We know that\nvk(T ∪ Sk) > ∑\ni∈T∪Sk p̄i ≥ 2 ∑ i∈Sk pi = 2vk(Sk).\nLet Q be some arbitrary set of size |T∪Sk|2 . Applying Proposition 25, we get,\nvk(Q) ≥ 1\n2 vk(T ∪ Sk) > vk(Sk).\nBy monotonicity, it must be that |Q| > |Sk|, and so |T ∪Sk| > 2|Sk| giving us the desired lemma. ut\nSo, Sk and T satisfy the conditions required for the doubling lemma. Applying the lemma, we get ∑ i∈Sk∪T p̄i ≥ vk(Sk ∪T ), which is a contradiction. Therefore, our solution is indeed core stable."
    }, {
      "heading" : "Welfare Bound",
      "text" : "Suppose that the optimum solution O∗ = (O∗1, . . . , O ∗ M ) has a social welfare of v(O ∗). We need to show that the social welfare of our solution v(S) is at least half of v(O∗). Recall that our social welfare is exactly equal to half the payments ∑ i p̄i. Therefore, it suffices if we prove that the welfare of the optimal solution v(O∗) is not larger than the sum of the payments. Our approach is as follows: we will map every project k to a proxy set Xk ⊆ N so that ∑ i∈Xk p̄i ≥ vk(O ∗ k). If we ensure that the sets (Xk)k∈P are mutually disjoint, we can sum these inequalities up to get our desired welfare bound.\nWe begin by dividing the projects into three categories based on the number of agents assigned to these projects in our solution |Sk| and how this compares to |O∗k|, 1. (P1) All projects k satisfying, |O∗k| ≥ |Sk| ≥ 12 |O∗k|, 2. (P2) All projects k satisfying |Sk| > |O∗k|, 3. (P3) All projects k satisfying |O∗k| > 2|Sk|, i.e., in the optimum solution k has more than\ndouble the number of agents assigned to k in our solution.\nWe define the sets Xk as follows: for every project k ∈ P1, Xk = Sk. For every project k ∈ P2, Xk is defined as the set of |O∗k| agents in Sk with the highest payments as per our solution. Notice that for every k ∈ P2, there are some ‘left over’ agents who are not yet assigned to any Xk′ . Let Rem be the union of such leftover agents over all projects in P2.\nFinally, for every project k ∈ P3, we define Xk to be Sk plus some arbitrarily chosen |O∗k|−|Sk| agents from the set Rem. It is not hard to see that we can choose Xk’s for the projects in P3 in such a manner that these sets are all mutually disjoint. Indeed, this is true because\n|Rem|+ ∑ k∈P3 |Sk| ≥ ∑ k∈P3 |O∗k|.\nThe above inequality comes from the fact that |O∗k| − |Xk| summed over all k ∈ P1 ∪ P2 is a non-negative number. Now all that remains is for us to show that ∑ i∈Xk p̄i ≥ vk(O ∗ k) for every k. First, look at the projects in P1. We can show that ∑ i∈Xk p̄i = 2vk(Sk) ≥ 2. 1 2vk(O ∗ k), where the last inequality comes from Proposition 25 since Sk has at least half as many agents as O ∗ k.\nNow, for the projects in P2, we can directly apply Lemma 16 to get ∑ i∈Xk p̄i = 2 ∑\ni∈Xk pi ≥ vk(O ∗ k).\nFinally, look at the projects in P3. Fix some k ∈ P3, and define T = Xk\\Sk. Since |Xk| = |O∗k|, we immediately get |T | > |Sk| from the definition of P3. Therefore, we can apply the important Doubling Lemma and get the desired result. This completes the proof of our final welfare bound.\nEnvy-Free Payments One interpretation for projects having anonymous valuations is that all the agents possess the same level of skill, and therefore, the value generated from a project depends only on the number of agents assigned to it. In such scenarios, it may be desirable that the payments given to the different agents are ‘fair’ or envy-free, i.e., all agents assigned to a certain project must receive the same payment. The following theorem (which we formally prove in the Appendix) shows that Algorithm 1 can be used to compute a (2, 2)-approximate core that also satisfies this additional constraint of envy-freeness.\nClaim 19 For any instance where the projects have anonymous subadditive valuations, there exists a (2, 2)-core stable solution such that the payments are envy-free, i.e., all the agents assigned to a single project receive the same payment."
    }, {
      "heading" : "3.2 Submodular and Fractionally Subadditive (XoS) Valuations",
      "text" : "Submodular and Fractionally Subadditive valuations are arguably the most popular classes of subadditive functions, and we show several interesting and improved results for these sub-classes. For instance, for XoS valuations, we can compute a (1 + )-core using Demand and XoS oracles (see [18] for a treatment of XoS oracles), whereas without these oracles, we can still compute a ( ee−1)-core. For submodular valuations, we provide an algorithm to compute a (1 + )-core even without a Demand oracle. All of these solutions retain at least a fraction (1− 1e ) of the optimum welfare, which matches the computational lower bound for both of these classes. We begin with a simple existence result for XoS valuations, that the optimum solution along with payments obtained using a XoS oracle form an exact core stable solution. All the results that we state in this Section, and Section 4 are proved in the Appendix.\nProposition 20. There exists a (1, 1)-core stable solution for every instance where the projects have XoS valuations.\nSince Submodular ⊂ XoS, this result extends to Submodular valuations as well. Unfortunately, it is known that the optimum solution cannot be computed efficiently for either of these classes unless P=NP [18]. However, we show that one can efficiently compute approximately optimal solutions that are almost-(core)-stable.\nTheorem 21. 1. For any instance where the projects have XoS valuations, we can compute (1 + , ee−1)-core stable solution using Demand and XoS oracles, and a ( e e−1 , e e−1)-core stable\nsolution without these oracles. 2. For submodular valuations, we can compute a (1 + , ee−1)-core stable solution using only a\nValue oracle.\nNote that for both the classes, a (1 + )-core can be computed in time polynomial in the input, and 1 . We conclude by pointing out that the results above are much better than what could have been obtained by plugging in α = ee−1 in Theorem 2 for Submodular or XoS valuations."
    }, {
      "heading" : "4 Relationship to Combinatorial Auctions",
      "text" : "We now change gears and consider the seemingly unrelated problem of Item Bidding Auctions, and establish a surprising equivalence between Core stable solutions and pure Nash equilibrium in Simultaneous Second Price Auctions. Following this, we adapt some of our results specifically for the auction setting and show how to efficiently compute Approximate Nash equilibrium when buyers have anonymous or submodular functions.\nIn recent years, the field of Auction Design has been marked by a paradigm shift towards ‘simple auctions’; one of the best examples of this is the growing popularity of Simultaneous Combinatorial Auctions [9, 14, 17], where the buyers submit a single bid for each item. The auction mechanism is simple: every buyer submits one bid for each of the N items, the auctioneer then proceeds to run N -parallel single-item auctions (usually first-price or second-price). In the case of Second Price Auctions, each item is awarded to the highest bidder (for that item) who is then charged the bid of the second highest bidder. Each buyer’s utility is her valuation for the bundle she receives minus her total payment.\nWe begin by establishing that for every instance of our utility sharing problem, there is a corresponding combinatorial auction, and vice-versa. Formally, given an instance (N ,P, (v)k∈P), we define the following ‘flipped auction’: there is a set N of N items, and a set P of m buyers. Every buyer k ∈ P has a valuation function vk for the items. In the simultaneous auction, the strategy of every buyer is a bid vector bk; bk(i) denotes buyer k’s bid for item i ∈ N . A profile of bid vectors (b1, . . . , bm) along with an allocation is said to be a pure Nash equilibrium of the simultaneous auction if no buyer can unilaterally change her bids and improve her utility at the new allocation.\nOver-Bidding Nash equilibrium in Simultaneous Auctions is often accompanied by a rather strong no-overbidding condition that a player’s aggregate bid for every set S of items is at most her valuation vk(S) for that set. In this paper, we also study the slightly less stringent weak no-overbidding assumption considered in [24] and [22] which states that ‘a player’s total bid for her winning set is at most her valuation for that set’. The set of equilibrium with no-overbidding is strictly contained in the set of equilibrium with weak no-overbidding. Finally, to model buyers who overbid by small amounts, we focus on the following natural relaxation of no-overbidding known as γ-conservativeness that was defined by Bhawalkar and Roughgarden [9]. Definition 22. (Conservative Bids) [9] For a given buyer k ∈ P, a bid vector bk is said to be γ-conservative if for all T ⊆ N , we have ∑i∈T bk(i) ≤ γ · vk(T ). We now state our main equivalence result that is based on a simple black-box transformation to convert a Core stable solution (S, p̄) to a profile of bids (bk)k∈P that form a Nash Equilibrium: bk(i) = p̄i if i ∈ Sk, and bk(i) = 0 otherwise.\nTheorem 23. Every Core stable solution for a given instance of our game can be transformed into a Pure Nash Equilibrium (with weak no-overbidding) of the corresponding ‘flipped’ simultaneous second price auction, and vice-versa.\nExistence and Computation of Equilibrium Although simultaneous auctions enjoy several desirable properties like good Price of Anarchy [9, 14], their applicability is limited by both existential and computational barriers. Particularly, while a no over-bidding Nash equilibrium\nalways exists for simple valuations like XoS, it may not be possible to actually compute one [17]. For more general subadditive (and even anonymous) valuations, Nash equilibria without overbidding may not even exist [9], and whether or not they exist cannot be determined without exponential communication [17]. A case for Approximate Equilibrium The exciting connection between Core stable solutions and Nash Equilibrium unfortunately extends to negative results as well. One can extend our lower bound examples (See Appendix) to show that even when all buyers have anonymous subadditive functions, there exist instances where every Nash equilibrium requires O( √ N)-conservative bids. The expectation that buyers will overbid by such a large amount appears to be unreasonable. In light of these impossibility results and the known barriers to actually compute a (no-overbidding) equilibrium [17], we argue that in many auctions, it seems reasonable to consider α-approximate Nash equilibrium that guarantee that buyers’ utilities cannot improve by more than a factor α when they change their bids. In the following result, we adapt our previous algorithms to compute approximate equilibria with high social welfare for two useful settings. Moreover, these solutions require small over-bidding, and can be obtained via simple mechanisms, so it seems likely that they would actually arise in practice when pure equilibria either do not exist or require a large amount of overbidding.\nClaim 24 Given a Second Price Simultaneous Combinatorial Auction, we can compute in time polynomial in the input (and 1 for a given > 0)\n1. A 2-approximate Nash equilibrium that extracts half the optimal social welfare as long as the buyers have anonymous subadditive valuations. 2. A (1 + )-approximate Nash equilibrium that is a ee−1 -approximation to the optimum welfare when the buyers have submodular valuations.\nThe first solution involves 4-conservative bids, and the second solution involves (1 + )- conservative bids.\nGiven a submodular valuation vk, define vmax = maxi,S vk(i|S). Also, define∆ = mini,S vk(i|S) such that vk(i|S) > 0. That is ∆ is the smallest non-zero increment in utility. Then, the algorithm for Submodular Functions converges in Poly(N,m, 1 , log(\nvmax ∆ )) time. One can contrast this re-\nsult to an algorithm by [17] that computes an exact Nash equilibrium in pseudo-polynomial time, i.e., O(vmax∆ ). On the contrary, we show that we can compute an approximate Nash equilibrium in poly-time (using a PTAS)."
    }, {
      "heading" : "Conclusion",
      "text" : "We conclude by remarking that despite the large body of work in Simultaneous Auctions, our main results do not follow from any known results in that area, and we hope that our techniques lead to new insights for computing auction equilibria."
    }, {
      "heading" : "A Appendix: Proofs for Subadditive Valuations",
      "text" : "We begin by formally defining the Greedy Matching Procedure procedure that is the building block of our main algorithm.\nAlgorithm 2: Greedy Matching with Reserve Prices\nInput : Allocation I = (I1, . . . , IM ), Payments p I = (pI1, . . . , p I N ). Output: Allocation O = (O1, . . . , OM ), Payments p O = (pO1 , . . . , p O N ).\n1 Initialize the current allocation S = I, and current payments p = pI . 2 if ∃ empty project k with Sk = ∅ and agent i such that vk(i) > pi then 3 Remove agent i from her current project and assign her to the empty project l with the maximum value of vl(i). Update agent i’s payment to pi = vl(i). 4 else 5 return the current allocation S and payments p. 6 end\nLemma 4. For every bad project k, |A+k | > |A−k |, i.e., more than half the agents in Ak still remain in project k.\nProof: We prove this by contradiction. Suppose that for some such k, |A−k | ≥ |A+k |. Recall that the marginal contributions given to agents in A−k is∑\ni∈A−k\np∗i + |A−k | |Ak| z∗k ≥ ∑ i∈A−k p∗i + z∗k 2\n(since Ak = A + k ∪A−k ).\nMoreover, the payments are non-decreasing under Algorithm 2, and agent i ∈ A−k is transferred from project k to some project l only if vl(i) > p ∗ i +\nz∗k |Ak| . Therefore, we have,∑\nl∈Pk vl(Bl) > ∑ i∈A−k (p∗i + z∗k |Ak| ) ≥ ∑ i∈A−k p∗i + z∗k 2 .\nNow, p∗ and z∗ are feasible solutions to the dual LP; this means that ∑\ni∈A−k p∗i + z ∗ k ≥ vk(A−k ).\nSo, we have,\nvk(A + k ) + ∑ l∈Pk vl(Bl) ≥ vk(A+k ) + ∑ i∈A−k p∗i + z∗k 2\n> vk(A + k ) +\n1 2 vk(A − k )\n≥ 1 2 (vk(A + k ) + vk(A − k )) ≥ 1 2 vk(Ak).\nThe last inequality follows from subadditivity and the fact that Ak = A + k ∪ A−k . However, this contradicts the definition of a bad project. So, we must have that |A−k | < |A+k |. ut"
    }, {
      "heading" : "Main Algorithm - Phase I",
      "text" : "1. Run Algorithm 2 on the allocation A with payments p0. Let the output be B,pB, and define A+k , A − k , and Pk as mentioned above. 2. (Good Projects) For every good project k ∈ P \\ ζ(A) (a) ∀i ∈ A+k , assign them to project k, set p′i = p∗i +\nz∗k |A+k |\n(b) ∀i ∈ A−k , assign them to their project l ∈ Pk, set p′i = p∗i + z∗l (c) Denote the resulting sets by S′k and S ′ l\n3. (Bad Projects) For every bad project k ∈ P \\ ζ(A) (a) Arbitrarily choose dummy agents Dk ⊂ A+k such that |Dk| = |A+k |− |A−k | (this is possible\ndue to Lemma 4). (b) Set S′k = A − k ∪Dk. (c) For i ∈ A−k , set p′i = pBi + z′k |A−k | where z′k is the leftover slack defined as z ∗ k− ∑ i∈A−k (pBi −p∗i ).\nFor i ∈ Dk, set p′i = p∗i . (d) Assign the non-dummy agents in A+k arbitrarily to the projects in Pk so that each project\nin Pk gets exactly one agent from (A + k \\Dk). (S′l is defined accordingly for l ∈ Pk).\n(e) For every l ∈ Pk: for i ∈ S′l, set p′i = p∗i + z∗l .\nLemma 6. For every agent i that does not belong to the set of dummy agents, her payment at the end of the first phase (p′i) is at least her payment returned by the call to the Greedy Matching Procedure pBi .\nProof: For each agent assigned to a good project k and the associated set of agents in Pk, the claim follows almost trivially from Lemma 5 and the definition of the final payment p′i. Moreover, suppose that k is a bad project, then we claim that the leftover slack z′k is non-negative. This is true because ∑\ni∈A−k\npBi = ∑ l∈Pk vl(Bl) < vk(Ak)/2 < vk(A − k ) ≤ ∑ i∈A−k p∗i + z ∗ k.\n(The first inequality above is since k is a bad project; the second is due to the fact that vk is subadditive and vk(A + k ) < vk(Ak)/2 since k is a bad project. The last is due to dual feasibility.)\nTherefore, by definition, the payment to a non-dummy agent i assigned to a bad project\np′i = p B i + z′l |A−k | ≥ pBi . Finally, fix a bad project k and consider the agents assigned to the projects in Pk. We claim that for every l ∈ Pk, z∗l is at least as large as z∗k |Ak| . We first show how this claim leads to the desired lemma and then conclude by proving the claim. For any l ∈ Pk, let S′l be some agent i. Since agent i ∈ A+k , it remained on the same project k in solution B. This means that her payment as output by the matching procedure is exactly the same as the input payment p∗i + z∗k |Ak| , which by the above claim is not larger than p ∗ i + z ∗ l giving us the desired lemma. (Proof of Claim that z∗l ≥ z∗k |Ak|) Suppose that some agent j ∈ Ak belonged to project l in the solution returned by the matching B. Then, by the monotonicity of payments in Algorithm 2, it must hold that j’s payment at the termination of Algorithm 2, pBj , is at least her initial payment p∗j + z∗k |Ak| . Applying dual feasibility, we get the desired claim\np∗j + z ∗ l ≥ vl(j) = pBj ≥ p∗j + z∗k |Ak| .\nut Lemma 8. For every non-empty project k /∈ ζ(S′), the total payment to agents in k at the end of Phase I is exactly ∑ i∈S′k p∗i + z ∗ k.\nProof: First consider any good project k and the associated set of projects in Pk. By definition, for every l ∈ k ∪Pk, the total payments to the agents in S′l is exactly as given by the lemma. So the proof for good projects and associated projects is trivial. Suppose that k is a bad project, then every l ∈ Pk contains exactly one agent i whose payment is exactly p∗i + z∗l . Finally, look at project k and recall that Dk is the set of dummy agents in k. Then, by definition of the payments to the agents in S′k, we have∑\ni∈S′k\np′i = ∑\ni∈S′k\\Dk\np′i + ∑ i∈Dk p′i = ∑\ni∈S′k\\Dk\np∗i + z ∗ k + ∑ i∈Dk p∗i .\nut"
    }, {
      "heading" : "Main Algorithm - Phase II",
      "text" : "1. Input to this Phase is the output of Phase I: (S′,p′) 2. Run Algorithm 2 with the input (S′,p′) 3. Let the output of Algorithm 2 be (S,ptemp). 4. Construct the final payment vector (p̄)i as follows: if agent i belongs to strategy k in both S\nand S′, then set p̄i = p temp i . Otherwise if agent i’s strategy in S is k but her strategy is S ′ is not k, then set p̄i = p ∗ i + z ∗ k.\n5. Output the final solution: S, (p̄)i.\nWe now prove some simple properties that compare the output of Phase II with its input. Claim 10. The following properties are true:\n1. The set of empty projects in S is a subset of the set of empty projects in S′, i.e., ζ(S) ⊆ ζ(S′). 2. For all non-dummy agents, their strategies in S′ and S coincide. 3. For every project k that was empty in S′ but not in S, Sk consists of a single dummy agent i. 4. For every agent i ∈ N , her payment at the end of Phase II (p̄i) is at least her payment at the end of Phase I.\nProof: Recall that in every stage of our greedy matching procedure, an agent i is transferred to an empty group (say k) having the largest value of vk(i) as long as it is greater than the agent’s current payment. Consider the execution of the greedy matching procedure in our algorithm’s second phase. We prove by induction that at every stage of this procedure, (i) the set of empty projects is a subset of ζ(S), ii) for every non-dummy agent, her strategy remains the same as in S′. Clearly, this is true at the beginning. Moreover, note that every project k /∈ ζ(S′) contains at least one non-dummy agent under S’.\nSuppose that the two induction hypotheses hold up to some iteration t of the algorithm. Let Pe be the set of empty projects at the end of this iteration, and let p be the payment vector after iteration t. In iteration t + 1, the agent i assigned to an empty project k satisfies pi < vk(i). This implies that i cannot be a non-dummy agent because due to Corollary 7 and\nthe monotonicity of payments, we know that for every non-dummy agent j, pj ≥ p′j ≥ vk(i) since k ∈ ζ(S′). Therefore, project k gains a dummy agent in iteration t + 1 and the positions of non-dummy agents remain the same as they were in the previous iteration. Moreover, every non-empty project in S′ still has one non-dummy agent and therefore, remains non-empty. We conclude the proof of Properties (1) and (2). Property (3) is simply a corollary of Property (2).\nFinally, we know by the monotonicity of payments that ptemp ≥ p′. Moreover, for every agent i whose strategy did not change from S′, her payment remains the same as in ptemp and therefore, the input payments. For any dummy agent (say i) who transferred to an empty project (say k), her final payment is p∗i + z ∗ k which by dual feasibility is not smaller than p temp i = vk(i) which in turn is larger than p′i. Therefore, Property (4) also holds. ut Lemma 11. For every non-empty project k /∈ ζ(S), the total payments made to agents in k is exactly ∑ i∈Sk p ∗ i + z ∗ k. Moreover, the payment made to any agent i is at least her dual price p ∗ i .\nProof: The proof is rather straightforward and is analogous to Lemma 8. The only change caused by Phase II is in the strategies of dummy agents, and because dummy agents only belong to bad projects, it suffices to show this lemma for bad projects and the projects that newly gained a dummy agent in Phase II, i.e., k ∈ ζ(S′)\\ζ(S). For the latter case, the lemma is true trivially due to the definition of Phase II. Now, consider some bad project k, and let X be the set of dummy agents belonging to Sk (ones that did not deviate in the greedy matching procedure). Moreover, for every agent in Sk, her payment is the same as her input payment because these agents did not deviate during the course of the matching procedure. Therefore, the final payments to the agents can be aggregated similar to the method in Lemma 8,∑\ni∈Sk\np̄i = ∑\ni∈Sk\\X\np̄i + ∑ i∈X p̄i = ∑ i∈Sk p∗i + z ∗ k + ∑ i∈X p∗i .\nut"
    }, {
      "heading" : "B Appendix: Proofs for Anonymous Subadditive Valuations",
      "text" : "We begin with a basic property of anonymous subadditive functions that we require in all of the proofs. In the rest of this paper, the notation v(T |S) refers to v(S ∪ T )− v(S).\nProposition 25. Let S ⊆ N be some set of agents, and suppose T ⊆ N such that |T | ≥ |S|2 . Then for an anonymous subadditive function v, we have v(T ) ≥ v(S)2 .\nThe proof follows from the fact that v(T ) + v(S \\ T ) ≥ v(S), and |T | ≥ |S|. Claim 12. (Lower Bounds) There exists instances having only two projects with anonymous subadditive functions such that\n1. For any > 0, no (2− , c)-core stable solution exists for any value c. 2. For any > 0, no (α, 2− )-core stable solution exists for any constant α.\nProof: (Part 2) Consider an instance with N agents and 2 projects. We choose a large enough N so that the following condition is satisfied N\nN/2+ √ N > 2 − . Now the project valuations are\ndefined as follows:\nv1(S) = N\n2 for S 6= N v2(S) =\n√ N ∀S ⊆ N\nv1(N ) =N,\nThe social welfare is maximized when all agents are allocated to project 1. It is also not hard to see (due to our choice of N) that no other solution has a social welfare that is at most a factor 2 − away from OPT. Now, using the same reasoning as we did for the previous claim, we can conclude that in order to stabilize the optimum solution, every agent needs a payment of at least √ N , and therefore, the total payments have to be at least a factor √ N larger than the optimum welfare. ut Lemma 15. For every i, j with i < j, the marginal of the agents in Ai is not smaller than the marginal of the agents in Aj , i.e., p (1) ≥ p(2) ≥ . . . ≥ p(r).\nProof: We argue that it is sufficient if we prove the lemma only for the case where the agents in Ai and Aj are assigned to the same project in S. To see why, suppose that the lemma holds for every such pair, now look at some Ai, Aj with i < j such that the agents in Ai belong to project ki and Aj belong to project kj with ki 6= kj . Next, define i < l ≤ j to be the smallest index such that the agents in Al are assigned to project kj , the same as the agents in Aj . Note that by definition of l, S (i) kj = S (l) kj\n: the set of agents in project kj are the same before iterations i, and l. This implies that the assignment of the agents in Al to project kj was a possible step for the greedy algorithm for iteration i. However, since the greedy algorithm actually chose Ai → ki, this means that\np(i) = vki(Ai|S (i) ki ) |Ai| ≥ vkj (Al|S (l) kj ) |Al| = p(l).\nBut we know that p(l) ≥ p(j) since the agents in Al and Aj are assigned to the same project. Therefore, it suffices to prove the lemma for the case where the two sets of agents are assigned to the same project, i.e., we need to prove that if the agents in Ai and Aj are assigned to the same project with i < j, then p(i) ≥ p(j).\nSuppose that the agents in Ai and Aj are both assigned to project k and assume by contradiction that p(j) > p(i). Without loss of generality, we can assume that no agents are assigned to project k in between iterations i and j. Since p(i) < p(j), we have\nvk(Ai|S(i)k ) |Ai| < vk(Aj |S(i)k ∪Ai) |Aj | .\nConsider the set Ai ∪Aj . We have that\nvk(Ai ∪Aj |S(i)k ) |Ai|+ |Aj | = vk(Aj |Ai ∪ S(i)k ) + vk(Ai|S (i) k ) |Aj |+ |Ai| > vk(Ai|S(i)k ) |Ai| .\nThe last inequality follows from the basic algebraic property that a+cb+d > min( a b , c d) as long as ab 6= cd . In other words, the average welfare due to adding the agents in Ai ∪ Aj to project k during the ith iteration is strictly larger than the average welfare due to adding the agents in Ai\nto project k in the same iteration. However, this means that in iteration i, the algorithm would have chosen the agents in Ai ∪Aj and assigned them to to project k instead of the agents in Ai, which is a contradiction. This completes the proof. ut Lemma 16. For every project k, and any given positive integer t ≤ |Sk|, the total marginal contribution of the t highest paid agents in Sk is at least the value derived due to any set of t agents, i.e., if T denotes the set of t-highest paid agents in Sk, then∑\ni∈T pi ≥ vk(T ).\nProof: Define l to be the smallest index such that after the lth iteration, the project k contains at least t agents, i.e., |S(l)k | < t and |S (l+1) k | ≥ t. Then, from the monotonicity of the marginals (Lemma 15) it is not hard to see that the set T of the t highest paid agents must contain S (l) k and some arbitrary t − |S(l)k | agents from the set of agents added in lth iteration. Consider the average welfare increase obtained by adding the agents in T \\ S(l)k to project k during iteration l; this cannot be larger than p(l), the actual average welfare obtained by our greedy algorithm in that iteration, i.e.,\np(l) ≥ vk(T )− vk(S (l) k )\n|T | − |S(l)k | .\nTherefore, the total marginal contributions of the t top agents in Sk can be bounded as follows, ∑\ni∈T pi = vk(S\n(l)) k ) + (|T | − |S (l) k |)p(l) ≥ vk(T ).\nThe first part of the above inequality comes from the fact that the total payment to the\nagents in S (l) k is exactly vk(S (l) k ). ut Lemma 17. (Doubling Lemma) Consider any project k and the set of elements assigned to k in our solution (Sk). Let T be some set of agents such that T ∩ Sk = ∅ and |T | > |Sk|. Then, the total payment to the agents in T ∪ Sk is at least vk(Sk ∪ T ), i.e.,∑\ni∈T∪Sk\np̄i ≥ vk(Sk ∪ T ).\nProof: We assume for convenience that both |T | and |Sk| are even. The same proof holds when one or both the sets are odd with a few minor modifications. We introduce some additional notation: recall that T> consists of the elements of T in the decreasing order of their marginal (or payment). We partition T> into two sets T1 and T2 containing the first |T | 2 + |Sk| 2 elements of T>, and the last |T |2 − |Sk| 2 elements respectively (see Figure 1). Let x be the agent in T2 who was first assigned to some project during the course of our algorithm. By definition, for every i ∈ T1, pi ≥ px, and by the monotonicity of the marginals, for every i ∈ T2, pi ≤ px.\nThe rest of the proof proceeds as follows, we first establish lower bounds on px and then use the fact that pi ≥ px for all i ∈ T1 to show that the payments are large enough. Suppose that agent x was assigned to some project during iteration l of our algorithm. Let Rem be the agents in Sk who were unassigned before the l th iteration, i.e., Rem = Sk \\ S(l)k . Since the\ngreedy algorithm did not choose to assign the agents in T2 ∪Rem to project k during iteration l, this means that the marginal contribution of the agents chosen in iteration l by our algorithm (p(l) = px) is at least the average welfare due to the alternative assignment that was not chosen, i.e.,\npx ≥ vk(T2 ∪Rem | S(l)k ) |Rem|+ |T2| = vk(Sk ∪ T2)− vk(S(l)k ) |Rem|+ |T2| .\nSince |Rem| ≤ |Sk| and |T2| = |T |2 − |Sk| 2 , we get that |Rem|+|T2| ≤ 12(|T |+|Sk|). Substituting\nthis in the above inequality, and bringing the denominator over to the other side, we obtain\n(|T |+ |Sk|)px ≥ 2(vk(Sk ∪ T2)− vk(S(l)k )). Look at the set Sk ∪ T2, the cardinality of this set is exactly 12(|T |+ |Sk|). Therefore, from our fundamental Proposition 25, we know that vk(Sk ∪ T2) ≥ 12vk(Sk ∪ T ). Therefore, we get the following final lower bound on px multiplied by |T |+ |Sk|,\n(|T |+ |Sk|)px ≥ vk(Sk ∪ T )− 2vk(S(l)k ) ≥ vk(Sk ∪ T )− 2vk(Sk).\nThe last inequality comes from the fact that S (l) k ⊆ Sk. Remember that the final payment to every agent is twice her marginal. Moreover, for every agent in T1, her initial payment is at least px. Now, we can finally prove the desired lemma,∑\ni∈Sk∪T p̄i ≥ 2 ∑ i∈Sk pi + 2 ∑ i∈T1 pi\n≥ 2vk(Sk) + 2|T1|px = 2vk(Sk) + (|T |+ |Sk|)px ≥ 2vk(Sk) + vk(Sk ∪ T )− 2vk(Sk) = vk(Sk ∪ T ).\nut\nFair Payments Given a payment vector p and an allocation S, we say that the payments are fair or envy-free, if for every i, j ∈ N such that both i and j belong to project k in S, then pi = pj .\nClaim 19. For any instance where the projects have anonymous subadditive valuations, there exists a (2, 2)-core stable solution such that the payments are envy-free, i.e., all the agents assigned to a single project receive the same payment.\nProof: Once again, we run Algorithm 1 to obtain an allocation S, but the payments that we provide are defined as follows: for every agent i ∈ Sk, her payment is now p(ef)i = 2 vk(Sk) |Sk| . From the proof of Theorem 13, the solution is still a 2-approximation to OPT . Moreover, the payments are clearly 2-budget balanced. It only remains for us to show that no group of agents T can deviate to any project k and collectively improve their utility. Instead of proving this from scratch, we piggyback on the proof of Theorem 13 and reduce our stability condition to that of the Theorem. More specifically, suppose that (p̄)i∈N denotes the payment vector used in Theorem 13. Then we show that as long as the solution (S, (p̄)i) is a 2-core, so is the envyfree solution (S,p(ef)). The following lemma is the basic building block that facilitates this reduction.\nLemma 26. For a given project k, and any positive integer t ≤ |Sk|, let T denote the set of t agents in Sk with the smallest payments according to (p̄)i∈N , i.e., for any i ∈ T , and any j ∈ Sk \\ T , p̄j ≥ p̄i. Then, ∑\ni∈T p̄i ≤ ∑ i∈T p (ef) i = 2t vk(Sk) |Sk| .\nProof: Assume by contradiction that the above inequality is false, i.e., ∑\ni∈T p̄i > 2t vk(Sk) |Sk| . Then,\nthere must exist at least one agent i ∈ T whose payment p̄i is strictly larger than 2vk(Sk)|Sk| . This implies that for every agent j in Sk \\ T , her payment is also strictly larger than the above quantity. Therefore, we have\n∑ i∈Sk p̄i = ∑ i∈T p̄i + ∑ i/∈T p̄i > 2t vk(Sk) |Sk| + 2(|Sk| − t) vk(Sk) |Sk| .\nHowever, this is a contradiction since we know that ∑\ni∈Sk p̄i = 2vk(Sk). ut Now, we are ready to show that for every project k, and every group T , ∑ i∈T∪Sk p (ef) i ≥ vk(T ∪Sk). Without loss of generality, we can assume that from every project l only the members with the lowest payments under the solution (p̄)i∈N deviate. That is, suppose that T consists of some t members originally in project l, then we can assume that these coincide with the t members of Sl who had the lowest payments in (p̄)i∈N . Now, from Lemma 26, we know that\n∑ i∈T p (ef) i = ∑ l∈P ∑ i∈T∩Sl p (ef) i ≥ ∑ l∈P ∑ i∈T∩Sl p̄i = ∑ i∈T p̄i.\nSince ∑ i∈Sk p̄i = ∑ i∈Sk p (ef) i = 2vk(Sk), this means that ∑ i∈T∪Sk p (ef) i ≥ ∑ i∈T∪Sk p̄i. How-\never, from the proof of Theorem 13, we know that ∑\ni∈T∪Sk p̄i ≥ vk(T ∪Sk). This completes the proof."
    }, {
      "heading" : "C Appendix: Proofs for Submodular and Fractionally Subadditive Valuations",
      "text" : ""
    }, {
      "heading" : "XoS Oracles",
      "text" : "One of our results for this section requires access to an XoS oracle [18], which when queried with a XoS valuation vk and a set Sk returns the XoS clause a (l) k that maximizes a (l) k (Sk). In addition, we also assume the presence of a Demand Oracle for each function. For any XoS function, both of these oracles can be implemented in time polynomial in the size of the input (number agents, number of independent clauses).\nProposition 20. There exists a (1, 1)-core stable solution for every instance where the projects have XoS valuations.\nSince Submodular functions are contained in the XoS class, this result extends to Submodular valuations as well.\nProof: The proof is simple: let O = (O1, . . . , Om) be the welfare maximizing solution. We define the following procedure to award payments to each agent: for each project k, invoke the XoS oracle for vk, Ok and suppose that the returned additive clause is a (l) k . For every i ∈ Sk, her payment is exactly p̄i = a (l) k . Notice that by definition of the XoS class, for every project k, and\nset T ⊆ Sk, a(l)k (T ) = ∑\ni∈T p̄i ≤ vk(T ). We now claim that these payments along with the allocation O form a core stable solution. Clearly the solution is budget-balanced, so we only need to show that no group of agents can deviate. Assume to the contrary, and suppose that some set T of agents can deviate to project k and collectively improve their utility. Let O′ be the allocation obtained from O by the deviation of the agents in T to project k. Then, we show that the social welfare of O′ must be strictly larger than the social welfare of O, which is a contradiction, i.e.,\nSW (O′) = vk(Sk ∪ T ) + ∑ l 6=k vl(O ′ l)\n> ∑\ni∈Sk∪T p̄i + ∑ l 6=k ∑ i∈Sl\\T p̄i = ∑ i∈N p̄i = SW (O ∗).\nTheorem 21.\n1. For any instance where the projects have XoS valuations, we can compute (1 + , ee−1)-core stable solution using Demand and XoS oracles, and a ( ee−1 , e e−1)-core stable solution without\nthese oracles.\n2. For submodular valuations, we can compute a (1 + , ee−1)-core stable solution using only a Value oracle.\nProof:\n(Part 1.1) Xos Valuations with Demand, Xos Oracles\nWe begin with some additional notation. Given an allocation X, we define the ‘XoS price’ of every agent i, pi(X) as follows: suppose that i ∈ Xk, then use the XoS oracle and obtain the maximizing additive clause a\n(l) k for Xk. Set pi(X) = a (l) k (i), i.e., the value of agent i in the\nadditive valuation that obtains the maximum value for the allocation Xk. It is not hard to see that for every project, the sum of XoS prices of the agents assigned to that project is exactly the welfare due to that project, i.e., ∀k ∈ P,∑\ni∈Xk\npi(X) = a (l) k (Xk) = vk(Xk).\nThe algorithm that we present is quite intuitive and based on a best response approach using the social welfare as a potential function.\n1. Initialize the input allocation A to be the ee−1 ≈ 1.58 approximation to OPT obtained using the Algorithm of [18]. 2. Let pi(A) denote the XoS price of every agent i for the allocation A. 3. Define the current allocation X = A, and current payments pi = pi(A) + N SW (A). 4. Perform a best-response step, i.e., allow a set T of agents to deviate to project k if we can simultaneously improve all of their payments, i.e., if vk(T |Xk) > ∑ i∈T pi. 5. Update the current allocation X, and the current payments to be pi = pi(X) + N SW (X). 6. When no such deviation is possible, return the allocation S = X, and the final payments (p̄)i∈N = p.\nWe need to show the following: (i) for a given > 0, the algorithm converges after making a polynomial number of queries to the Demand and XoS oracles, (ii) the solution returned has at least the welfare of the initial allocation A, (iii) the solution is (1 + )-Core stable.\nWe begin with an easy observation: after every iteration of our algorithm, the total payment made to all the agents is at most a factor (1+ ) times the current social welfare. This is because the payment to every agent is her XoS price plus N times the current welfare; since there are a total of N agents we get that the total payments is the aggregate XoS price plus times the social welfare. Our next claim is that in every iteration, our algorithm makes at most m calls to the XoS oracle and to the Demand oracle. Observe that we require the XoS oracle only when we choose payments for the agents (invoke the XoS prices), the demand oracle is only required for identifying a best-response step in our algorithm (Step (5)). In order to find the XoS prices, it suffices if we invoke the XoS oracle once for each every project k, given the allocation Xk. Next, in order to check for a best-response step, we need to see if ∃ k, T such that vk(T |Xk) > ∑ i∈T pi. This can be done using the demand oracle for project k using the price vector p, and the reduced valuation function vk(.|Xk). Therefore, in order to determine whether there exists a best-response step, we need to call the Demand oracle at most m times, once for each project. This completes the proof of the claim.\nNow that we know that our algorithm makes at most m calls to each of the oracles in each iteration, if we can prove that our algorithm converges after a polynomial number of iterations, then the total number of queries to the oracles is also polynomially bounded. In order to show this, we first prove a more fundamental lemma that gives a lower bound on the increase in social welfare during each iteration.\nLemma 27. In every iteration, the social welfare of the current allocation increases strictly by at least a fraction N of current social welfare.\nThat is, suppose that during some iteration, the initial allocation was X1, and the allocation after the best-response was X2, then SW (X2) > SW (X1)(1 + N ).\nProof: Suppose that during this allocation, some set T of agents deviate to project k. Let the initial payments of all the agents (before the deviation) be p. We also know by definition of the best-response step that vk(T |X1k) > ∑ i∈T pi. Moreover, it is not hard to see that (initially) for\nevery project l, the payments are at most the welfare due to the project plus a markup, i.e.,∑ i∈X1l pi = vl(X 1 l ) + |X1l | N SW (X1).\nOur next observation establishes a relationship between the welfare of any project l after the best-response step, and the initial set of prices. We know that for all l ∈ P with l 6= k, X2l ⊆ X1l . Then, we show that:\nvl(X 2 l ) ≥ ∑ i∈X2l (pi − N SW (X1)).\nTo see why the above inequality is true, suppose that for a given project l 6= k, r1 and r2 are the maximizing clauses for the assignments X1l and X 2 l respectively. The above inequality follows from the fact that vl(X 2 l ) = a r2 l (X 2 l ) ≥ ar1l (X2l ). The final term is exactly the initial XoS prices of the agents in X2l , which is pi − N SW (X1) for every agent i. Now we are in a position to show our desired result,\nSW (X2) = vk(X 2 k) + ∑ l 6=k vl(X 2 l )\n≥ [ vk(X 1 k) + vk(T |X1k) ] + ∑ l 6=k ∑ i∈X2l (pi − N SW (X1))\n> vk(X 1 k) + ∑ i∈T pi + ∑ l 6=k ∑ i∈X2l (pi − N SW (X1)).\nNow we can rearrange the above inequality by assigning every agent i ∈ T to the project that i belonged to in X1, and then rewriting pi for these agents as pi− N SW (X1)+ N SW (X1). This gives us,\nSW (X2) > vk(X 1 k) + ∑ l 6=k ∑ i∈X1l (pi − N SW (X1)) + N |T |SW (X1)\n≥ vk(X1k) + ∑ l 6=k vl(X 1 l ) + N SW (X1)\n= SW (X1) + N SW (X1).\nThis completes the proof of the lemma. ut Now, we can use the above lemma to prove the main theorem. We begin by showing that our algorithm converges after a polynomial number of iterations. Clearly, the social welfare of the current allocation is non-decreasing throughout our algorithm, and therefore bounded from\nbelow by SW (A). This means that in every iteration, the increase in welfare is strictly larger than N SW (A). But we also know that e e−1SW (A) ≥ SW (OPT ). Therefore, we can bound the number of iterations of our algorithm by the total possible increase in welfare divided by the increase in welfare in each iteration,\nSW (OPT )− SW (A) N SW (A) ≤ N (e− 1) .\nTherefore, our algorithm converges after a polynomial number of calls to the Demand and XoS Oracles. The final welfare, as per Lemma 27 is at least the initial welfare, i.e., SW (A). Core stability follows by definition of the best-response phase because if there existed a set T , and a project k, such that vk(T |Sk) > ∑ i∈T p̄i, then our algorithm would not have terminated.\nTogether with the fact that ∑ i∈Sk p̄i ≥ vk(Sk), we get that ∑\ni∈T∪Sk p̄i ≥ vk(T |Sk) + vk(Sk) = vk(T ∪ Sk), as desired. Finally, the payments are (1 + )-budget balanced:∑\ni∈N p̄i = ∑ k∈P (vk(Sk) + |Sk| N SW (S)) = SW (S) + SW (S)\n(Part 1.2) XoS Valuations without the Oracles\nWe actually show a much stronger result here, namely that given a α-approximation to the LP optimum, we can obtain a (α, α)-Core stable solution. Plugging in α = ee−1 for fractionally subadditive functions, we get the desired result. Note that a (α, α)-core result is strictly better than our (2α, 2α) result for general subadditive functions.\nWe only sketch the key features of this proof since the approach is very similar to our algorithm for general subadditive functions as described in Theorem 2. Suppose that the input allocation is A, and the optimum dual prices are p∗, z∗ as usual. Given any allocation X, define margi(X) to be agent i’s marginal contribution to her project, i.e., suppose that agent i ∈ Xk, then define margi(X) = vk(Xk) − vk(Xk − {i}). Now, our algorithm for this theorem involves the following adaptation of the Greedy Matching procedure described in the proof of Theorem 2. Recall that for any allocation X, ζ(X) gives the set of empty projects under that allocation.\n1. Let the current allocation X be initialized to A. 2. Allow a single agent i to deviate to some empty project k ∈ ζ(X) as long as this leads to a\nstrict increase in social welfare, i.e, vk(i) > margi(X). 3. Update the current allocation X and repeat Step (2) until no agent wants to deviate. 4. Output S to be the (final) current allocation.\nClearly, it is not hard to see that the welfare of the final allocation is not smaller than the welfare of the initial allocation A. Moreover, the above algorithm must converge in time Poly(N,m). The crux of the proof lies in the following slightly intricate payment scheme,\n• Define for every project k, high value users (SHk ) and low value users (SLk ) as follows, SHk = {i ∈ Sk|margi(S) > p∗i } , SLk = Sk \\ SHk .\n• Define for every project k, the residual slack zk as follows, zk = ∑ i∈SHk p∗i + z ∗ k − ∑ i∈SHk margi(S).\n• For every project k, and every low value agent i ∈ Sk, let her final payment be p̄i = p∗i . • For every project k, and every high value agent i ∈ Sk, let her final payment be p̄i = margi(S) +\nzk |SHk | .\nThe following is the crucial lemma that helps us show core stability.\nLemma 28. For every agent i, her payment is at least her marginal value. Moreover, the total payment to the members of any project k is exactly ∑ i∈Sk p ∗ i + z ∗ k.\nProof: Let us begin with the first part of the lemma, this is clearly true for low value agents by definition. Therefore, we only need to focus on the high value agents. Since every high value agent’s payment is her marginal value plus some fraction of the residual slack, it is enough if we show that for every project k, the residual slack is positive. We use the following property of XoS functions: given assignment Sk, let l be the clause that maximizes a (l) k (Sk), then, margi(S) = vk(Sk)− vk(Sk−{i}) ≤ a(l)k (Sk)− a (l) k (Sk−{i}) = a (l) k (i). Now we can prove the first part of the lemma,\nzk = ∑ i∈SHk p∗i + z ∗ k − ∑ i∈SHk margi(S)\n≥ vk(SHk )− ∑ i∈SHk a (l) k (i) ≥ vk(SHk )− vk(SHk ) = 0.\nThis completes the first part of the lemma. The second part follows from definition of the payments. ut\nNow the rest of the proof follows in the same fashion as that of Theorem 2. Clearly, the final payments are exactly equal to the value of the Dual Optimum which is a factor α larger than the welfare of the current solution. In order to show that no group of agents T can deviate to any project for subadditive valuations (remember that XoS is a sub-class of subadditive valuations), it is enough to show the following (See proof of Theorem 2) (i) every agent i’s payment is at least p∗i , (ii) for every project k, the total payment of the members of that project is at least ∑ i∈Sk p ∗ i + z ∗ k, (iii) if k is an empty project, then for any agent i, p̄i ≥ vk(i). (i) and (ii) guarantee that any deviation to a non-empty project k will not occur due to dual feasibility, and (iii) together with subadditivity guarantees that no set benefits from deviating to an empty project. The first two requirements follow immediately from the definition of the payments and the above Lemma. For the third requirement, observe that at the end of the payment algorithm defined above, margi(S) ≥ vk(i) for k ∈ ζ(S). Therefore, as per Lemma 28, p̄i ≥ margi(S) ≥ vk(i). This completes the proof.\n(Part 2) Submodular Functions with only Value Queries\nThe algorithm is exactly the same as in the proof for XoS functions in Part 1.1; recall that submodular functions are a strict sub-class of XoS functions. The key difference here is that we can eliminate the dependence on both Demand and XoS oracles using the nice properties of Submodular functions. First, note that we use the XoS oracle to find the corresponding additive\nclause for a given valuation function vk(Sk). It is known that one can implement XoS queries in polynomial time for Submodular functions using a simple Greedy Approach as in Claim 1.\nMore specifically, given a submodular function vk, and a corresponding set Sk, the goal of an XoS oracle query is to obtain an additive function a such that vk(Sk) = a(Sk) and for all T ⊆ Sk, vk(T ) ≥ a(T ). It is not hard to see that this gives us the XoS clause which is maximum at Sk without loss of generality. For submodular functions, we can compute the XoS prices as follows: (i) order the elements of Sk in some arbitrary order, (ii) add the elements of Sk to vk(∅) one after the other in the predetermined order, (iii) agent i’s XoS price is the marginal cost of adding her to the set, i.e., if Ai is the set of elements before i in the predetermined order, then agent i’s XoS price is vk(Ai ∪ {i}) − vk(Ai). These prices give us the additive function a, as desired.\nNow, we move on to Demand Oracles whose main purpose is to identify in every iteration, a project k, and a set T such that vk(T |Xk) > ∑ i∈T pi, where Xk is the set of agents currently assigned to that project. For submodular functions, instead of looking at group deviations to a project, it suffices if we look at individual deviations. More specifically, our claim is the following: if ∃T satisfying vk(T |Xk) > ∑ i∈T pi, then there exists at least one agent i ∈ T satisfying vk(Xk ∪ {i})− vk(Xk) > pi. This follows almost directly from submodularity,∑ i∈T pi < vk(T |Xk) < ∑ i∈T vk(Xk ∪ {i})− vk(Xk).\nTherefore, our claim must be true for at least one such agent. The claim has the following implication: the best-response algorithm for Submodular functions can be obtained from the B-R algorithm for XoS valuations in Part 1.1 by changing step (4) to “allow a single i to deviate to project k as long as vk(Xk ∪ {i}) − vk(Xk) > pi”. Whether or not such a deviation exists can be found using O(Nm) value queries. Finally, we remark that a ee−1 -approximation to OPT that we use as an input to the algorithm can be computed for submodular functions using only Value Queries [45].\nThe rest of the proof follows."
    }, {
      "heading" : "D Appendix: Proofs from Section 4",
      "text" : "Theorem 23. Every Core stable solution for a given instance of our utility sharing game can be transformed into a Pure Nash Equilibrium (with weak no-overbidding) of the corresponding ‘flipped’ simultaneous second price auction, and vice-versa.\nProof: Suppose that we are given an instance (N ,P, (v)k∈P) of our combinatorial utility sharing game along with a core stable solution (S, (p̄)i∈N ). We construct a bid profile b = (b1, . . . , bm) for the flipped combinatorial auction that in combination with the allocation S, and the corresponding second-price payments constitutes a Pure Nash equilibrium with no weak-overbidding. Our construction is simple, for every buyer k ∈ P, and item i ∈ N : bk(i) = p̄i if i ∈ Sk and bk(i) = 0 otherwise. Notice that for every item, only one buyer (the winning buyer) has a positive bid, therefore, the corresponding auction mechanism will output S as the winning allocation along with zero payments. Therefore, every every buyer k’s utility is exactly vk(Sk).\nIn order to show that this is a pure Nash equilibrium, it is enough to prove for a fixed buyer k, and for any alternative bid vector b′k, buyer k’s utility cannot strictly improve at her new bid\nwhen all the other buyers bid according to the constructed profile. Suppose that at the new bid vector, player k wins the set S′k of items and define T = S ′ k \\ Sk. Then, for every item i ∈ T , buyer k has to pay exactly p̄i (the bid of the second highest bidder) in the new auction solution. Therefore, player k’s new utility is\nuk(b ′ k, b−k) = vk(S ′ k)− ∑ i∈T p̄i ≤ vk(Sk ∪ T )− ∑ i∈T p̄i.\nNow upon applying the core stability requirement for the empty set, we get vk(Sk) ≤∑ i∈Sk p̄i. This condition must be true for every project l ∈ P. Moreover, this condition in com-\nbination with budget-balance indicates that for project k (and every other project), vk(Sk) =∑ i∈Sk p̄i. Now, we can bound the player’s new utility using core-stability as\nvk(Sk ∪ T )− ∑ i∈T p̄i ≤ ∑ i∈Sk p̄i = vk(Sk).\nThe last quantity is player k’s original utility, and therefore this deviation cannot strictly benefit the player. Notice that this also implies the no weak-overbidding condition.\nNow, for the other direction, suppose that we are given a winning allocation S along with a bid profile b that together forms a Nash Equilibrium (the second-price payments P are implicit in the bid). Construct the following payment vector: for every item i ∈ N , pi = maxk∈P bk(i), i.e., the highest bid for that item. Consider any player k, and a set of items T outside of her current allocation. In order to win these items as well as the items she received in S, player k must bid at least pi + for every i ∈ T without changing her bids for the items in Sk. Let b′k be the modified bid vector reflecting these increased bids for the items in T . However, since this is a Nash equilibrium, the utility of the player under the modified bid vector cannot be larger than her original utility, i.e.,\nuk(b ′ k, b−k) = vk(Sk ∪ T )− P (Sk)− ∑ i∈T pi\n≤ uk(b) = vk(Sk)− P (Sk).\nTherefore, we have for every buyer k, and every set of items T , vk(Sk∪T )− ∑\ni∈T pi ≤ vk(Sk). Due to the weak no-overbidding assumption, we know that for each k, ∑ i∈Sk pi ≤ vk(Sk). We now set\nthe final payments p̄i by increasing the payments pi arbitrarily for each k until ∑\ni∈Sk p̄i = vk(Sk). These payments are clearly budget-balanced. Moreover, since we only increased the payments, we still have that for every buyer k, and every set of items T , vk(Sk∪T )−vk(Sk) ≤ ∑ i∈T p̄i. From this inequality, it is easy to see that the solution S along with the payments (p̄)i∈N constitutes a core-stable solution. This solution retains the welfare of the original Nash equilibrium.\nInstance where every Nash Equilibrium requires a large amount of overbidding\nThe example that we use here is the same as the instance for Part (2) of Claim 12. Consider an auction with just two buyers having the following anonymous subadditive valuations: v1(S) = N 2 for S 6= N , v1(N ) = N ; and v2(S) = √ N ∀S ⊆ N . We show that in any Pure Nash\nEquilibrium (b1, b2) and S, at least one buyer has to over-bid by a factor O( √ N). First, consider\nany Nash equilibrium where buyer 1 wins all of the items. Then, it is not hard to see that b1(i) ≥ √ N for every i ∈ N or else buyer 2 can bid for i (b′2(i) = √ N), win the item and\nstrictly improve her utility. Therefore, we have b1(N ) ≥ √ N ×N = √ Nv1(N ), which gives us the amount by which buyer 1 overbids.\nNext, suppose that in a Nash Equilibrium of this auction, buyer 2 receives some (S2) but not all the items. Then, buyer 1’s utility is v1(S1)− b2(S1) = N2 − b2(S1). Now what if buyer 1 modifies her bids in order to win all the items in N and pays b2(N ) for the same? Such a deviation cannot improve her utility, i.e., N − b2(N ) ≤ N2 − b2(S1). Simplifying this, we get b2(S2) ≥ N2 . Since v2(S2) = √ N , we get that the amount of over-bidding by buyer 2 is N\n2 √ N = √ N 2 . It is not\nhard to see that this must be the case even when buyer 2 wins all of the items in N .\nClaim 24. Given a Second Price Simultaneous Combinatorial Auction with Item Bidding, we can compute\n1. A 2-approximate Nash Equilibrium that extracts half the optimal social welfare as long as the buyers have anonymous subadditive valuations. 2. A 1 + -approximate Nash equilibrium that is a ee−1 -approximation to the optimum welfare when the buyers have submodular valuations.\nThe first solution involves 4-conservative bids, and the second solution involves (1 + )- conservative bids.\nProof: (Proof of Statement 1) Once again, we turn to our greedy algorithm (Algorithm 1). Consider the solution S returned by our greedy algorithm and envy-free payments (p(ef))i∈N as per Claim 19. Convert the payments into a bid profile b using the transformation mechanism described in the proof of Theorem 23. Clearly, the solution has the some social welfare as the original allocation, so we only need to prove stability and quantify the level of over-bidding. As with the proof of Theorem 23, suppose that some buyer k changes his bids so that his new winning set is S′k and T = S ′ k \\ Sk. Then we have that the player’s new utility is at most\nvk(Sk ∪ T )− ∑ i∈T p̄i ≤ ∑ i∈Sk p̄i = 2vk(Sk)\nTherefore, the player’s new utility is at most twice her original utility, and therefore, the solution is a 2-approximate Nash Equilibrium. Now, it only remains for us to prove that the bid vector is 4-conservative for every buyer k.\nConsider some k ∈ P, it suffices to show that ∑i∈T bk(i) ≤ 4vk(T ) holds only for the case when T is subset of Sk. This is because the player’s bid is zero for every item outside of her winning set. Suppose that |T | = t, and let r be a non-negative integer satisfying, 2rt ≤ |Sk| ≤ 2r+1t. We know that player k’s bid for every item in Sk is exactly\n2vk(SK) |Sk| . Abusing notation,\nwe denote by vk(2 rt) the value of any set of size 2rt. Now, from a repeated application of the Fundamental Proposition for Anonymous Functions (Proposition 25), we get\nvk(T ) ≥ vk(2\nrt)\n2r .\nNow we are ready for the final leg of our proof.∑ i∈T bk(i) = 2vk(Sk) |Sk| t\n≤ 2vk(Sk)t 2rt = 2 vk(Sk) 2r ≤ 22vk(2 rt)\n2r (From Proposition 25)\n≤ 4vk(T )2 r\n2r = 4vk(T )\n(Proof of Statement 2) One could be tempted to claim that the Algorithm in Theorem 21 yields a 1 + -approximate equilibrium (even for XoS valuations), and indeed it does. Unfortunately, in the final payments, every agent is provided her XoS clause price along with an additive mark-up of SW (S). Therefore, the level of multiplicative over-bidding (as measured by γ-conservativeness) for this solution could be quite large. However, we only need to make a few high-level modifications to the Algorithm for Submodular valuations in Theorem 21 that will allow us to improve the conservativeness while retaining the approximation factor.\nThe key step in this modified algorithm is how we price items (using the XoS prices) in Step (5) of the algorithm. In particular, the property that we require from the pricing mechanism is the following: after any best-response move that leads to a strict improvement of the social welfare, the price of any given item cannot decrease. A simple pricing mechanism for Submodular functions that achieves this property was described in [17], the reader is asked for refer to Claim 2.5 of that paper for the exact construction. At a high level, the pricing mechanism works as follows: in every iteration, every buyer maintains an ordering on the item set, which is dynamically updated. Suppose that for a given item i assigned to buyer k at some instance, Ai denotes the set of items before i in buyer k’s ordering. Then, the price of item i is exactly vk({i} |Ai).\nWe simply use the above mechanism as a black-box here. Now, we are in a position to describe our modified algorithm: in every round we maintain a single price (or payment) for each item. At the end, we derive bids for the players using the same idea as in Theorem 23.\n1. Initialize the input allocation A to be the ee−1 ≈ 1.58 approximation to OPT obtained using the Algorithm of [45]. 2. Let pi(A) denote the Submodular price of every item i for the allocation A obtained using the mechanism of [17]. 3. Define the current allocation X = A, and current payment pi = pi(A)(1 + ). 4. Perform a best-response step, i.e., allow an item i to deviate to project k as long as vk(i|Xk) > pi. 5. Update the current allocation X, and let pi(X) be the current submodular prices obtained using the mechanism of [17]. Then, every agent i’s payment is pi = pi(X)(1 + ). 6. When no such deviation is possible, return the allocation S = X, and the final payments (p̄)i∈N = p.\nWe first argue for core-stability before showing the properties of the approximate Nash equilibrium. Clearly, the solution returned is (approximately) core-stable, and has a social welfare that is at least a ee−1 -approx to OPT (since the best-response is welfare increasing). We now\nshow bounds on the running time. Notice that in every round, the price of at least one item is increasing by a multiplicative factor of 1 + , i.e., i deviates to project k because vk(i|Xk) > pi, then her price becomes vk(i|Xk)(1 + ).\nGiven this, it is not hard to see that the algorithm proceeds for at most O(Nlog(1+ )( vmax ∆ )) since no agent’s price can be strictly larger than vmax by definition. We need not worry about agents whose initial payment is zero; either their final payment is still zero or their payment (during some iteration) increases up to ∆, and then multplicatively increases in each subsequent round where it deviates. Moreover, since log(1+ )( vmax ∆ ) = O( 1 log( vmax ∆ )), we get the desired run time. Now, let use the black-box mechanism of Theorem 21 to convert payments to bids. We first show that the solution is a (1+ )-approximate Nash equilibrium. Observe that for every project k, ∑ i∈Sk bk(i) = ∑\ni∈Sk p̄i = (1 + )vk(Sk). Now suppose that buyer k modifies her bid, receives an additional set T of items, then her new utility is\nvk(Sk ∪ T )− ∑ i∈T p̄i ≤ ∑ i∈Sk p̄i = (1 + )vk(Sk),\nwhere vk(Sk) is her old utility. Therefore, the solution is a (1 + )-approximate equilibrium. Next, we prove that the bids are (1+ )-conservative. Recall that (as per the pricing mechanism) for every project k, there exists an ordering of agents (Ok) so that each agent’s (final) price is (1 + )-times her marginal price when adding agents according to that order. In order to show that the bids are conservative, consider any set T ⊆ Sk. We argue that∑\ni∈T bk(i) = ∑ i∈T p̄i ≤ (1 + )vk(T ).\nIndeed, consider the item i in T who appears first in Ok. Clearly its payment is at most vk(i) by submodularity (since it may not be the first item in Ok). This argument can be repeated for every agent recursively. Therefore, in the solution that we obtain, the Nash Equilibrium has (1 + )-conservative bids."
    } ],
    "references" : [ {
      "title" : "Approximate equilibrium and incentivizing social coordination",
      "author" : [ "Elliot Anshelevich", "Shreyas Sekar" ],
      "venue" : "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, July",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2014
    }, {
      "title" : "Dynamics of profit-sharing games",
      "author" : [ "John Augustine", "Ning Chen", "Edith Elkind", "Angelo Fanelli", "Nick Gravin", "Dmitry Shiryaev" ],
      "venue" : "Internet Mathematics,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2015
    }, {
      "title" : "The bargaining set for cooperative games",
      "author" : [ "Robert J Aumann", "Michael Maschler" ],
      "venue" : "Advances in game theory,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1964
    }, {
      "title" : "The cost of stability in coalitional games",
      "author" : [ "Yoram Bachrach", "Edith Elkind", "Reshef Meir", "Dmitrii V. Pasechnik", "Michael Zuckerman", "Jörg Rothe", "Jeffrey S. Rosenschein" ],
      "venue" : "In Algorithmic Game Theory, Second International Symposium,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2009
    }, {
      "title" : "Computing cooperative solution concepts in coalitional skill games",
      "author" : [ "Yoram Bachrach", "David C. Parkes", "Jeffrey S. Rosenschein" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2013
    }, {
      "title" : "Improved equilibria via public service advertising",
      "author" : [ "Maria-Florina Balcan", "Avrim Blum", "Yishay Mansour" ],
      "venue" : "In Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2009
    }, {
      "title" : "Core extensions for non-balanced tu-games",
      "author" : [ "Camelia Bejan", "Juan Camilo Gómez" ],
      "venue" : "Int. J. Game Theory,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2009
    }, {
      "title" : "Approximating pure nash equilibrium in cut, party affiliation, and satisfiability games",
      "author" : [ "Anand Bhalgat", "Tanmoy Chakraborty", "Sanjeev Khanna" ],
      "venue" : "In Proceedings 11th ACM Conference on Electronic Commerce (EC-2010),",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "Welfare guarantees for combinatorial auctions with item bidding",
      "author" : [ "Kshipra Bhawalkar", "Tim Roughgarden" ],
      "venue" : "In Proceedings of the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2011
    }, {
      "title" : "Coalition games on interaction graphs: A horticultural perspective",
      "author" : [ "Nicolas Bousquet", "Zhentao Li", "Adrian Vetta" ],
      "venue" : "In Proceedings of the Sixteenth ACM Conference on Economics and Computation, EC",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2015
    }, {
      "title" : "Coalitional affinity games and the stability gap",
      "author" : [ "Simina Brânzei", "Kate Larson" ],
      "venue" : "IJCAI",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2009
    }, {
      "title" : "Cooperative games with overlapping coalitions",
      "author" : [ "Georgios Chalkiadakis", "Edith Elkind", "Evangelos Markakis", "Maria Polukarov", "Nick R. Jennings" ],
      "venue" : "J. Artif. Intell. Res. (JAIR),",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2010
    }, {
      "title" : "On discrete preferences and coordination",
      "author" : [ "Flavio Chierichetti", "Jon M. Kleinberg", "Sigal Oren" ],
      "venue" : "In ACM Conference on Electronic Commerce, EC ’13,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2013
    }, {
      "title" : "Bayesian combinatorial auctions. In Automata, Languages and Programming, 35th International Colloquium, ICALP 2008, Reykjavik, Iceland",
      "author" : [ "George Christodoulou", "Annamária Kovács", "Michael Schapira" ],
      "venue" : "July 7-11,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Algorithmic aspects of the core of combinatorial optimization games",
      "author" : [ "Xiaotie Deng", "Toshihide Ibaraki", "Hiroshi Nagamochi" ],
      "venue" : "Mathematics of Operations Research,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1999
    }, {
      "title" : "Strategyproof cost-sharing mechanisms for set cover and facility location games",
      "author" : [ "Nikhil R. Devanur", "Milena Mihail", "Vijay V. Vazirani" ],
      "venue" : "Decision Support Systems,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2005
    }, {
      "title" : "On the complexity of computing an equilibrium in combinatorial auctions",
      "author" : [ "Shahar Dobzinski", "Hu Fu", "Robert D. Kleinberg" ],
      "venue" : "In Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2015
    }, {
      "title" : "Approximation algorithms for combinatorial auctions with complement-free",
      "author" : [ "Shahar Dobzinski", "Noam Nisan", "Michael Schapira" ],
      "venue" : "bidders. Math. Oper. Res.,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2010
    }, {
      "title" : "Core stability of vertex cover games",
      "author" : [ "Qizhi Fang", "Liang Kong", "Jia Zhao" ],
      "venue" : "Internet Mathematics,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2008
    }, {
      "title" : "On maximizing welfare when utility functions are subadditive",
      "author" : [ "Uriel Feige" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2009
    }, {
      "title" : "A unified framework for strong price of anarchy in clustering games. In Automata, Languages, and Programming - 42nd International Colloquium, ICALP 2015, Kyoto, Japan",
      "author" : [ "Michal Feldman", "Ophir Friedler" ],
      "venue" : "July 6-10,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2015
    }, {
      "title" : "Simultaneous auctions are (almost) efficient",
      "author" : [ "Michal Feldman", "Hu Fu", "Nick Gravin", "Brendan Lucier" ],
      "venue" : "In Symposium on Theory of Computing Conference,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2013
    }, {
      "title" : "Hedonic clustering games",
      "author" : [ "Moran Feldman", "Liane Lewin-Eytan", "Joseph Naor" ],
      "venue" : "In 24th ACM Symposium on Parallelism in Algorithms and Architectures, SPAA ’12,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2012
    }, {
      "title" : "Conditional equilibrium outcomes via ascending price processes with applications to combinatorial auctions with item bidding",
      "author" : [ "Hu Fu", "Robert Kleinberg", "Ron Lavi" ],
      "venue" : "In ACM Conference on Electronic Commerce, EC ’12,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2012
    }, {
      "title" : "Black-box reductions for cost-sharing mechanism design",
      "author" : [ "Konstantinos Georgiou", "Chaitanya Swamy" ],
      "venue" : "Games and Economic Behavior,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2013
    }, {
      "title" : "Cooperative facility location games",
      "author" : [ "Michel X Goemans", "Martin Skutella" ],
      "venue" : "Journal of Algorithms,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2004
    }, {
      "title" : "On the complexity of the core over coalition structures",
      "author" : [ "Gianluigi Greco", "Enrico Malizia", "Luigi Palopoli", "Francesco Scarcello" ],
      "venue" : "IJCAI",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2011
    }, {
      "title" : "Strategic cooperation in cost sharing games",
      "author" : [ "Martin Hoefer" ],
      "venue" : "Int. J. Game Theory,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2013
    }, {
      "title" : "Limitations of cross-monotonic cost-sharing schemes",
      "author" : [ "Nicole Immorlica", "Mohammad Mahdian", "Vahab S. Mirrokni" ],
      "venue" : "ACM Transactions on Algorithms,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2008
    }, {
      "title" : "Mechanisms for (mis)allocating scientific credit",
      "author" : [ "Jon M. Kleinberg", "Sigal Oren" ],
      "venue" : "In Proceedings of the 43rd ACM Symposium on Theory of Computing,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2011
    }, {
      "title" : "Combinatorial auctions with decreasing marginal utilities",
      "author" : [ "Benny Lehmann", "Daniel J. Lehmann", "Noam Nisan" ],
      "venue" : "Games and Economic Behavior,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2006
    }, {
      "title" : "Bitcoin mining pools: A cooperative game theoretic analysis",
      "author" : [ "Yoad Lewenberg", "Yoram Bachrach", "Yonatan Sompolinsky", "Aviv Zohar", "Jeffrey S. Rosenschein" ],
      "venue" : "In Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2015
    }, {
      "title" : "Price of anarchy for greedy auctions",
      "author" : [ "Brendan Lucier", "Allan Borodin" ],
      "venue" : "In Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2010
    }, {
      "title" : "On the core of the multicommodity flow game",
      "author" : [ "Evangelos Markakis", "Amin Saberi" ],
      "venue" : "Decision support systems,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2005
    }, {
      "title" : "Minimal subsidies in expense sharing games",
      "author" : [ "Reshef Meir", "Yoram Bachrach", "Jeffrey S. Rosenschein" ],
      "venue" : "In Algorithmic Game Theory - Third International Symposium,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2010
    }, {
      "title" : "Incremental cost sharing: Characterization by coalition strategy-proofness",
      "author" : [ "Hervé Moulin" ],
      "venue" : "Social Choice and Welfare,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 1999
    }, {
      "title" : "Strategyproof sharing of submodular costs: budget balance versus efficiency",
      "author" : [ "Hervé Moulin", "Scott Shenker" ],
      "venue" : "Economic Theory,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2001
    }, {
      "title" : "Graphs and cooperation in games",
      "author" : [ "Roger B Myerson" ],
      "venue" : "Mathematics of operations research,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 1977
    }, {
      "title" : "Quantifying inefficiency in cost-sharing mechanisms",
      "author" : [ "Tim Roughgarden", "Mukund Sundararajan" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 2009
    }, {
      "title" : "Coalitional game theory for communication networks",
      "author" : [ "Walid Saad", "Zhu Han", "Mérouane Debbah", "Are Hjørungnes", "Tamer Başar" ],
      "venue" : "Signal Processing Magazine, IEEE,",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2009
    }, {
      "title" : "The nucleolus of a characteristic function game",
      "author" : [ "David Schmeidler" ],
      "venue" : "SIAM Journal on applied mathematics,",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 1969
    }, {
      "title" : "Approximating the least core value and least core of cooperative games with supermodular costs",
      "author" : [ "Andreas S. Schulz", "Nelson A. Uhan" ],
      "venue" : "Discrete Optimization,",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2013
    }, {
      "title" : "Quasi-cores in a monetary economy with nonconvex preferences",
      "author" : [ "Lloyd S Shapley", "Martin Shubik" ],
      "venue" : "Econometrica: Journal of the Econometric Society,",
      "citeRegEx" : "43",
      "shortCiteRegEx" : "43",
      "year" : 1966
    }, {
      "title" : "Submodularity in combinatorial optimization",
      "author" : [ "Jan Vondrák" ],
      "venue" : "PhD thesis, Citeseer,",
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "Cooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40].",
      "startOffset" : 172,
      "endOffset" : 191
    }, {
      "referenceID" : 27,
      "context" : "Cooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40].",
      "startOffset" : 172,
      "endOffset" : 191
    }, {
      "referenceID" : 31,
      "context" : "Cooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40].",
      "startOffset" : 172,
      "endOffset" : 191
    }, {
      "referenceID" : 37,
      "context" : "Cooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40].",
      "startOffset" : 172,
      "endOffset" : 191
    }, {
      "referenceID" : 39,
      "context" : "Cooperative Coalition Formation The question of how a group of agents should divide the value they generate has inspired an extensive body of research spanning many fields [7, 28, 32, 38, 40].",
      "startOffset" : 172,
      "endOffset" : 191
    }, {
      "referenceID" : 4,
      "context" : "Core is well understood, implicit in the papers that study this notion is the underlying belief that there are infinite copies of one single project [5,12], which is often not realistic.",
      "startOffset" : 149,
      "endOffset" : 155
    }, {
      "referenceID" : 11,
      "context" : "Core is well understood, implicit in the papers that study this notion is the underlying belief that there are infinite copies of one single project [5,12], which is often not realistic.",
      "startOffset" : 149,
      "endOffset" : 155
    }, {
      "referenceID" : 0,
      "context" : "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.",
      "startOffset" : 169,
      "endOffset" : 175
    }, {
      "referenceID" : 1,
      "context" : "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.",
      "startOffset" : 169,
      "endOffset" : 175
    }, {
      "referenceID" : 12,
      "context" : "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.",
      "startOffset" : 195,
      "endOffset" : 203
    }, {
      "referenceID" : 20,
      "context" : "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.",
      "startOffset" : 195,
      "endOffset" : 203
    }, {
      "referenceID" : 5,
      "context" : "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.",
      "startOffset" : 227,
      "endOffset" : 233
    }, {
      "referenceID" : 7,
      "context" : "Indeed, models featuring selfish agents choosing from a finite set of distinct strategies are the norm in many real-life phenomena: social or technological coordination [1, 2], opinion formation [13, 21], and party affiliation [6, 8] to name a few.",
      "startOffset" : 227,
      "endOffset" : 233
    }, {
      "referenceID" : 9,
      "context" : "For example, in the classic setting with a single valuation v(S), the welfare maximization problem is often trivial (complete partition when v is subadditive), and the stabilizing core payments are exactly the dual variables to the allocation LP [10].",
      "startOffset" : 246,
      "endOffset" : 250
    }, {
      "referenceID" : 37,
      "context" : "One could also take the Myersonian view [38] that ‘communication is required for negotiation’ and imagine that all the agents choosing project k (Sk ∪ T ) together collaborate to improve their payments.",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 28,
      "context" : "Specifically, as is standard in cost-sharing literature [29,39], we consider relaxing one of the two requirements for core stability while retaining the other one.",
      "startOffset" : 56,
      "endOffset" : 63
    }, {
      "referenceID" : 38,
      "context" : "Specifically, as is standard in cost-sharing literature [29,39], we consider relaxing one of the two requirements for core stability while retaining the other one.",
      "startOffset" : 56,
      "endOffset" : 63
    }, {
      "referenceID" : 9,
      "context" : "In the identical projects literature, the solution having the smallest value of α is known as the Multiplicative Least-Core [10].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 6,
      "context" : "This generalization offers a natural interpretation: the central authority can subsidize the agents to ensure high welfare, as is often needed in other settings such as public projects or academic funding [7].",
      "startOffset" : 205,
      "endOffset" : 208
    }, {
      "referenceID" : 3,
      "context" : "In the literature, this parameter β has been referred to as the Cost of Stability [4,35].",
      "startOffset" : 82,
      "endOffset" : 88
    }, {
      "referenceID" : 34,
      "context" : "In the literature, this parameter β has been referred to as the Cost of Stability [4,35].",
      "startOffset" : 82,
      "endOffset" : 88
    }, {
      "referenceID" : 19,
      "context" : "In particular, for general subadditive valuations, one can use the 2-approximation algorithm of Feige [20] and obtain a (4, 4)-Core.",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 17,
      "context" : "As is standard in the literature [18], we assume that our subadditive functions are specified in terms of a demand oracle (see Section 2 for more details).",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 19,
      "context" : "Valuation Function Class Our Results: (α, c)-Core Lower Bound for c Subadditive (4, 4) 2 [20] Anonymous Subadditive (2, 2) 2 [20] Fractionally Subadditive (XoS) (1 + , e e−1 ) e e−1 [18] Submodular (1 + , e e−1 ) and (1, 2) e e−1 [45]",
      "startOffset" : 89,
      "endOffset" : 93
    }, {
      "referenceID" : 19,
      "context" : "Valuation Function Class Our Results: (α, c)-Core Lower Bound for c Subadditive (4, 4) 2 [20] Anonymous Subadditive (2, 2) 2 [20] Fractionally Subadditive (XoS) (1 + , e e−1 ) e e−1 [18] Submodular (1 + , e e−1 ) and (1, 2) e e−1 [45]",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 17,
      "context" : "Valuation Function Class Our Results: (α, c)-Core Lower Bound for c Subadditive (4, 4) 2 [20] Anonymous Subadditive (2, 2) 2 [20] Fractionally Subadditive (XoS) (1 + , e e−1 ) e e−1 [18] Submodular (1 + , e e−1 ) and (1, 2) e e−1 [45]",
      "startOffset" : 182,
      "endOffset" : 186
    }, {
      "referenceID" : 8,
      "context" : "Ties to Combinatorial Auctions with Item Bidding We conclude by pointing out a close relationship between our setting and simultaneous auctions where buyers bid on each item separately [9,14,17].",
      "startOffset" : 185,
      "endOffset" : 194
    }, {
      "referenceID" : 13,
      "context" : "Ties to Combinatorial Auctions with Item Bidding We conclude by pointing out a close relationship between our setting and simultaneous auctions where buyers bid on each item separately [9,14,17].",
      "startOffset" : 185,
      "endOffset" : 194
    }, {
      "referenceID" : 16,
      "context" : "Ties to Combinatorial Auctions with Item Bidding We conclude by pointing out a close relationship between our setting and simultaneous auctions where buyers bid on each item separately [9,14,17].",
      "startOffset" : 185,
      "endOffset" : 194
    }, {
      "referenceID" : 2,
      "context" : "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an α-core.",
      "startOffset" : 120,
      "endOffset" : 131
    }, {
      "referenceID" : 3,
      "context" : "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an α-core.",
      "startOffset" : 120,
      "endOffset" : 131
    }, {
      "referenceID" : 40,
      "context" : "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an α-core.",
      "startOffset" : 120,
      "endOffset" : 131
    }, {
      "referenceID" : 42,
      "context" : "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an α-core.",
      "startOffset" : 120,
      "endOffset" : 131
    }, {
      "referenceID" : 3,
      "context" : "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an α-core.",
      "startOffset" : 165,
      "endOffset" : 173
    }, {
      "referenceID" : 6,
      "context" : "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an α-core.",
      "startOffset" : 165,
      "endOffset" : 173
    }, {
      "referenceID" : 34,
      "context" : "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an α-core.",
      "startOffset" : 165,
      "endOffset" : 173
    }, {
      "referenceID" : 9,
      "context" : "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an α-core.",
      "startOffset" : 209,
      "endOffset" : 219
    }, {
      "referenceID" : 41,
      "context" : "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an α-core.",
      "startOffset" : 209,
      "endOffset" : 219
    }, {
      "referenceID" : 42,
      "context" : "The non-existence of the core in many important settings has prompted researchers to devise several natural relaxations [3,4,41,43]: of these, the Cost of Stability [4,7,35], and the Multiplicative Least-Core [10,42,43] are the solution concepts that are directly analogous to our notion of an α-core.",
      "startOffset" : 209,
      "endOffset" : 219
    }, {
      "referenceID" : 14,
      "context" : "Although cooperative games traditionally do not involve any optimization, a number of papers have studied well-motivated games where the valuation or cost function (c(S)) is derived from an underlying combinatorial optimization problem [15,26,28,34].",
      "startOffset" : 236,
      "endOffset" : 249
    }, {
      "referenceID" : 25,
      "context" : "Although cooperative games traditionally do not involve any optimization, a number of papers have studied well-motivated games where the valuation or cost function (c(S)) is derived from an underlying combinatorial optimization problem [15,26,28,34].",
      "startOffset" : 236,
      "endOffset" : 249
    }, {
      "referenceID" : 27,
      "context" : "Although cooperative games traditionally do not involve any optimization, a number of papers have studied well-motivated games where the valuation or cost function (c(S)) is derived from an underlying combinatorial optimization problem [15,26,28,34].",
      "startOffset" : 236,
      "endOffset" : 249
    }, {
      "referenceID" : 33,
      "context" : "Although cooperative games traditionally do not involve any optimization, a number of papers have studied well-motivated games where the valuation or cost function (c(S)) is derived from an underlying combinatorial optimization problem [15,26,28,34].",
      "startOffset" : 236,
      "endOffset" : 249
    }, {
      "referenceID" : 14,
      "context" : "For example, in the vertex cover game [15, 19] where each edge is an agent, c(S) is the size of the minimum cover for the edges in S.",
      "startOffset" : 38,
      "endOffset" : 46
    }, {
      "referenceID" : 18,
      "context" : "For example, in the vertex cover game [15, 19] where each edge is an agent, c(S) is the size of the minimum cover for the edges in S.",
      "startOffset" : 38,
      "endOffset" : 46
    }, {
      "referenceID" : 25,
      "context" : "For many such problems, core payments can be computed almost directly using LP Duality [26,28,34].",
      "startOffset" : 87,
      "endOffset" : 97
    }, {
      "referenceID" : 27,
      "context" : "For many such problems, core payments can be computed almost directly using LP Duality [26,28,34].",
      "startOffset" : 87,
      "endOffset" : 97
    }, {
      "referenceID" : 33,
      "context" : "For many such problems, core payments can be computed almost directly using LP Duality [26,28,34].",
      "startOffset" : 87,
      "endOffset" : 97
    }, {
      "referenceID" : 3,
      "context" : "In the cooperative game theory literature, our setting is perhaps closest to the work studying coalitional structures where instead of forming the grand coalition, agents are allowed to arbitrarily partition themselves [4,27] or form overlapping coalitions [12].",
      "startOffset" : 219,
      "endOffset" : 225
    }, {
      "referenceID" : 26,
      "context" : "In the cooperative game theory literature, our setting is perhaps closest to the work studying coalitional structures where instead of forming the grand coalition, agents are allowed to arbitrarily partition themselves [4,27] or form overlapping coalitions [12].",
      "startOffset" : 219,
      "endOffset" : 225
    }, {
      "referenceID" : 11,
      "context" : "In the cooperative game theory literature, our setting is perhaps closest to the work studying coalitional structures where instead of forming the grand coalition, agents are allowed to arbitrarily partition themselves [4,27] or form overlapping coalitions [12].",
      "startOffset" : 257,
      "endOffset" : 261
    }, {
      "referenceID" : 11,
      "context" : ", threshold task games [12] or coalitional skill games [5].",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 4,
      "context" : ", threshold task games [12] or coalitional skill games [5].",
      "startOffset" : 55,
      "endOffset" : 58
    }, {
      "referenceID" : 15,
      "context" : "Recently, there has been a lot of interest in designing cost-sharing mechanisms that satisfy strategy-proofness in settings where a service is to be provided to a group of agents who hold private values for the same [16, 37].",
      "startOffset" : 216,
      "endOffset" : 224
    }, {
      "referenceID" : 36,
      "context" : "Recently, there has been a lot of interest in designing cost-sharing mechanisms that satisfy strategy-proofness in settings where a service is to be provided to a group of agents who hold private values for the same [16, 37].",
      "startOffset" : 216,
      "endOffset" : 224
    }, {
      "referenceID" : 35,
      "context" : "A powerful relationship between our work and the body of strategy-proof mechanisms was discovered by Moulin [36] who showed that a natural class of ‘cross-monotonic cost sharing schemes’ can be used to design mechanisms that are both core-stable (CS) and strategy-proof (SP).",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 24,
      "context" : "This has led to the design of beautiful SP+CS mechanisms for several combinatorially motivated problems with a single identical project or service [25, 39].",
      "startOffset" : 147,
      "endOffset" : 155
    }, {
      "referenceID" : 38,
      "context" : "This has led to the design of beautiful SP+CS mechanisms for several combinatorially motivated problems with a single identical project or service [25, 39].",
      "startOffset" : 147,
      "endOffset" : 155
    }, {
      "referenceID" : 1,
      "context" : "Finally, we briefly touch upon the large body of literature in non-transferable utility games that (like us) study coalition formation with a finite number of asymmetric projects [2, 11, 13,23].",
      "startOffset" : 179,
      "endOffset" : 193
    }, {
      "referenceID" : 10,
      "context" : "Finally, we briefly touch upon the large body of literature in non-transferable utility games that (like us) study coalition formation with a finite number of asymmetric projects [2, 11, 13,23].",
      "startOffset" : 179,
      "endOffset" : 193
    }, {
      "referenceID" : 12,
      "context" : "Finally, we briefly touch upon the large body of literature in non-transferable utility games that (like us) study coalition formation with a finite number of asymmetric projects [2, 11, 13,23].",
      "startOffset" : 179,
      "endOffset" : 193
    }, {
      "referenceID" : 22,
      "context" : "Finally, we briefly touch upon the large body of literature in non-transferable utility games that (like us) study coalition formation with a finite number of asymmetric projects [2, 11, 13,23].",
      "startOffset" : 179,
      "endOffset" : 193
    }, {
      "referenceID" : 17,
      "context" : "The reader is asked to refer to [18, 20, 31, 44] for alternative definitions of the XoS class and an exposition on how both these classes arise naturally in many interesting applications.",
      "startOffset" : 32,
      "endOffset" : 48
    }, {
      "referenceID" : 19,
      "context" : "The reader is asked to refer to [18, 20, 31, 44] for alternative definitions of the XoS class and an exposition on how both these classes arise naturally in many interesting applications.",
      "startOffset" : 32,
      "endOffset" : 48
    }, {
      "referenceID" : 30,
      "context" : "The reader is asked to refer to [18, 20, 31, 44] for alternative definitions of the XoS class and an exposition on how both these classes arise naturally in many interesting applications.",
      "startOffset" : 32,
      "endOffset" : 48
    }, {
      "referenceID" : 43,
      "context" : "The reader is asked to refer to [18, 20, 31, 44] for alternative definitions of the XoS class and an exposition on how both these classes arise naturally in many interesting applications.",
      "startOffset" : 32,
      "endOffset" : 48
    }, {
      "referenceID" : 29,
      "context" : "Anonymous Subadditive Functions In project assignment settings in the literature modeling a number of interesting applications [30, 35], it is reasonable to assume that the value from a project depends only on the number of users working on that project.",
      "startOffset" : 127,
      "endOffset" : 135
    }, {
      "referenceID" : 34,
      "context" : "Anonymous Subadditive Functions In project assignment settings in the literature modeling a number of interesting applications [30, 35], it is reasonable to assume that the value from a project depends only on the number of users working on that project.",
      "startOffset" : 127,
      "endOffset" : 135
    }, {
      "referenceID" : 17,
      "context" : "In particular, when dealing with a subadditive function v, it is typical to assume that we are provided with a demand oracle that when queried with a vector of payments p, returns a set T ⊆ N that maximizes the quantity v(T )−∑i∈T pi [18].",
      "startOffset" : 234,
      "endOffset" : 238
    }, {
      "referenceID" : 17,
      "context" : "For example, it is well-known [18] that one cannot obtain any reasonable approximation algorithm for subadditive functions (better than O( √ N)) in the absence of demand queries.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 17,
      "context" : "We conclude this discussion by reiterating that demand oracles are an extremely standard tool used in the literature to study combinatorial valuations; almost all of the papers [18,20,25] studying Subadditive or XoS functions take the presence of a demand oracle for granted.",
      "startOffset" : 177,
      "endOffset" : 187
    }, {
      "referenceID" : 19,
      "context" : "We conclude this discussion by reiterating that demand oracles are an extremely standard tool used in the literature to study combinatorial valuations; almost all of the papers [18,20,25] studying Subadditive or XoS functions take the presence of a demand oracle for granted.",
      "startOffset" : 177,
      "endOffset" : 187
    }, {
      "referenceID" : 24,
      "context" : "We conclude this discussion by reiterating that demand oracles are an extremely standard tool used in the literature to study combinatorial valuations; almost all of the papers [18,20,25] studying Subadditive or XoS functions take the presence of a demand oracle for granted.",
      "startOffset" : 177,
      "endOffset" : 187
    }, {
      "referenceID" : 30,
      "context" : "Proof: The proof uses the popular greedy half-approximation algorithm for submodular welfare maximization due to [31].",
      "startOffset" : 113,
      "endOffset" : 117
    }, {
      "referenceID" : 19,
      "context" : "We use this black-box in conjunction with the algorithm of Feige [20] to obtain a (4, 4)-Core stable solution, i.",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 17,
      "context" : "Although the primal LP contains an exponential number of variables, the dual LP can be solved using the Ellipsoid method where the demand oracle serves as a separation oracle [18].",
      "startOffset" : 175,
      "endOffset" : 179
    }, {
      "referenceID" : 19,
      "context" : "The best-known approximation algorithms for many popular classes of valuations use LP-based rounding techniques; of particular interest to us is the 2-approximation for Subadditive valuations [20], and e e−1 -approximation for XoS valuations [18].",
      "startOffset" : 192,
      "endOffset" : 196
    }, {
      "referenceID" : 17,
      "context" : "The best-known approximation algorithms for many popular classes of valuations use LP-based rounding techniques; of particular interest to us is the 2-approximation for Subadditive valuations [20], and e e−1 -approximation for XoS valuations [18].",
      "startOffset" : 242,
      "endOffset" : 246
    }, {
      "referenceID" : 24,
      "context" : "explicitly make use of the optimum LP solution [25].",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 19,
      "context" : "For general subadditive functions, the only known poly-time constant-factor approximation is the rather intricate randomized LP rounding scheme proposed in [20].",
      "startOffset" : 156,
      "endOffset" : 160
    }, {
      "referenceID" : 29,
      "context" : "Such functions are frequently assumed in coalition formation and project assignment settings [30].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 19,
      "context" : "To the best of our knowledge, the only previously known approach that achieves a 2-approximation for anonymous subadditive functions is the LP-based rounding algorithm for general subadditive functions [20].",
      "startOffset" : 202,
      "endOffset" : 206
    }, {
      "referenceID" : 32,
      "context" : "In addition, our greedy algorithm also possesses other ‘nice structural properties’ that may be of use in other settings such as mechanism design [33].",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 17,
      "context" : "For instance, for XoS valuations, we can compute a (1 + )-core using Demand and XoS oracles (see [18] for a treatment of XoS oracles), whereas without these oracles, we can still compute a ( e e−1)-core.",
      "startOffset" : 97,
      "endOffset" : 101
    }, {
      "referenceID" : 17,
      "context" : "Unfortunately, it is known that the optimum solution cannot be computed efficiently for either of these classes unless P=NP [18].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 8,
      "context" : "In recent years, the field of Auction Design has been marked by a paradigm shift towards ‘simple auctions’; one of the best examples of this is the growing popularity of Simultaneous Combinatorial Auctions [9, 14, 17], where the buyers submit a single bid for each item.",
      "startOffset" : 206,
      "endOffset" : 217
    }, {
      "referenceID" : 13,
      "context" : "In recent years, the field of Auction Design has been marked by a paradigm shift towards ‘simple auctions’; one of the best examples of this is the growing popularity of Simultaneous Combinatorial Auctions [9, 14, 17], where the buyers submit a single bid for each item.",
      "startOffset" : 206,
      "endOffset" : 217
    }, {
      "referenceID" : 16,
      "context" : "In recent years, the field of Auction Design has been marked by a paradigm shift towards ‘simple auctions’; one of the best examples of this is the growing popularity of Simultaneous Combinatorial Auctions [9, 14, 17], where the buyers submit a single bid for each item.",
      "startOffset" : 206,
      "endOffset" : 217
    }, {
      "referenceID" : 23,
      "context" : "In this paper, we also study the slightly less stringent weak no-overbidding assumption considered in [24] and [22] which states that ‘a player’s total bid for her winning set is at most her valuation for that set’.",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 21,
      "context" : "In this paper, we also study the slightly less stringent weak no-overbidding assumption considered in [24] and [22] which states that ‘a player’s total bid for her winning set is at most her valuation for that set’.",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 8,
      "context" : "Finally, to model buyers who overbid by small amounts, we focus on the following natural relaxation of no-overbidding known as γ-conservativeness that was defined by Bhawalkar and Roughgarden [9].",
      "startOffset" : 192,
      "endOffset" : 195
    }, {
      "referenceID" : 8,
      "context" : "(Conservative Bids) [9] For a given buyer k ∈ P, a bid vector bk is said to be γ-conservative if for all T ⊆ N , we have ∑i∈T bk(i) ≤ γ · vk(T ).",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 8,
      "context" : "Existence and Computation of Equilibrium Although simultaneous auctions enjoy several desirable properties like good Price of Anarchy [9, 14], their applicability is limited by both existential and computational barriers.",
      "startOffset" : 134,
      "endOffset" : 141
    }, {
      "referenceID" : 13,
      "context" : "Existence and Computation of Equilibrium Although simultaneous auctions enjoy several desirable properties like good Price of Anarchy [9, 14], their applicability is limited by both existential and computational barriers.",
      "startOffset" : 134,
      "endOffset" : 141
    }, {
      "referenceID" : 16,
      "context" : "always exists for simple valuations like XoS, it may not be possible to actually compute one [17].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 8,
      "context" : "For more general subadditive (and even anonymous) valuations, Nash equilibria without overbidding may not even exist [9], and whether or not they exist cannot be determined without exponential communication [17].",
      "startOffset" : 117,
      "endOffset" : 120
    }, {
      "referenceID" : 16,
      "context" : "For more general subadditive (and even anonymous) valuations, Nash equilibria without overbidding may not even exist [9], and whether or not they exist cannot be determined without exponential communication [17].",
      "startOffset" : 207,
      "endOffset" : 211
    }, {
      "referenceID" : 16,
      "context" : "In light of these impossibility results and the known barriers to actually compute a (no-overbidding) equilibrium [17], we argue that in many auctions, it seems reasonable to consider α-approximate Nash equilibrium that guarantee that buyers’ utilities cannot improve by more than a factor α when they change their bids.",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 16,
      "context" : "One can contrast this result to an algorithm by [17] that computes an exact Nash equilibrium in pseudo-polynomial time, i.",
      "startOffset" : 48,
      "endOffset" : 52
    } ],
    "year" : 2015,
    "abstractText" : "Consider a setting where selfish agents are to be assigned to coalitions or projects from a set P. Each project k ∈ P is characterized by a valuation function; vk(S) is the value generated by a set S of agents working on project k. We study the following classic problem in this setting: “how should the agents divide the value that they collectively create?”. One traditional approach in cooperative game theory is to study core stability with the implicit assumption that there are infinite copies of one project, and agents can partition themselves into any number of coalitions. In contrast, we consider a model with a finite number of non-identical projects; this makes computing both high-welfare solutions and core payments highly non-trivial. The main contribution of this paper is a black-box mechanism that reduces the problem of computing a near-optimal core stable solution to the purely algorithmic problem of welfare maximization; we apply this to compute an approximately core stable solution that extracts one-fourth of the optimal social welfare for the class of subadditive valuations. We also show much stronger results for several popular sub-classes: anonymous, fractionally subadditive, and submodular valuations, as well as provide new approximation algorithms for welfare maximization with anonymous functions. Finally, we establish a connection between our setting and the well-studied simultaneous auctions with item bidding; we adapt our results to compute approximate pure Nash equilibria for these auctions.",
    "creator" : "LaTeX with hyperref package"
  }
}