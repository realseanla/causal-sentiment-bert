{
  "name" : "1705.05326.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Constrained Bayesian Networks: Theory, Optimization, and Applications",
    "authors" : [ "Paul Beaumont" ],
    "emails" : [ "m.huthu@imperial.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords: Bayesian Belief Network. Imprecise Probabilities. Lack of Prior Data. NonLinear Optimization. Confidence Building in Nuclear Arms Control."
    }, {
      "heading" : "1 Introduction",
      "text" : "Bayesian Networks (BN) [36, 37, 35] are a prominent, well established, and widely used formalism for expressing discrete probability distributions in terms of directed, acyclic graphs (DAG) that encode conditional independence assumptions of distributions. Bayesian Networks have a wide range of applications – for example, trouble shooting [12], design of experiments [30, 28], and digital forensics to support legal reasoning [38]. Their graph-based formalism and automated support for probabilistic inference seem to lower adaption hurdles for a diverse set of users with different technical backgrounds. Bayesian Networks are also appealing since we may combine, within the same Bayesian Network, different aspects such as subjective beliefs expressed in probabilities, implicit trust assumptions reflected in a bias of information processing or the combinatorial logic of a process. Probabilistic inference for such combinations is supported, including belief updates based on observed evidence.\nBayesian Networks also come with methodological support for learning an appropriate graph structure as well as appropriate prior probability values at nodes in such graphs from\nar X\niv :1\n70 5.\n05 32\n6v 1\n[ cs\n.A I]\n1 5\nM ay\n2 01\n7\npre-existing data (see for example [29, 19]). The appropriateness of chosen prior probability values may depend on a variety of factors: the quality and quantity of data used for learning these values or the trust we place in experts who determine such values subjectively – to give two examples. We would therefore like reassurance that the prior distributions represented by such values are robust enough in that small changes to such values only result in small changes of posterior distributions of interest. This naturally leads to the consideration of robust Bayesian statistics [9, 10].\nA popular idea here is to approximate prior probabilities with intervals and to then calculate – somehow – the intervals that correspond to posterior probabilities. A good conceptual explanation of this is Good’s black box model [26, 27], in which interval information of priors is submitted into a black box that contains all the usual methods associated with precise computations in Bayesian Networks, and where the box then outputs intervals of posteriors without limiting any interpretations or judgments on those output intervals.\nOur engagement with a problem owner in arms control made us realize the benefits of Good’s black box model and made us identify opportunities for extending it to increase the confidence that users from such problem domains can place in models and their robustness. Specifically, we want to be able to\nR1 re-interpret compactly a BN as a possibly infinite set of BNs over the same graph, with robustness being analyzable over that re-interpretation\nR2 add logical constraints to capture domain knowledge or dependencies, and reflect constraints in robustness analyses in a coherent manner\nR3 compare models, within a composition context, to determine any differences in the robustness that they may offer for supporting decision making\nR4 parametrize the use of such a box so that it can produce outputs for any quantitative measure of interest definable as an arithmetic term\nR5 retain the “blackness” of the box so that the user neither has to see nor has to understand its inner workings\nR6 interpret outputs of the black box within the usual methodology of Bayesian Networks in as far as this may be possible.\nWe believe that these requirements are desired or apt in a wide range of problem domains, in addition to the fact that they should enhance usability of such a methodology in practice. We develop constrained Bayesian Networks in this paper and show that they meet the above requirements. This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15]. Concretely, we allow prior probabilities to be arithmetic expressions that may contain variables, and we enrich this model with logical constraints expressed in the theory of the reals.\nWe draw comparisons to related work, including Credal Networks [16, 22, 33] and Constraint Networks [24]. We then highlight similarities, differences, and complementary value of our approach to this previous work.\nContributions and methodology of the paper We develop a formal syntax and semantics of constrained Bayesian Networks which denote an empty, finite or infinite set of Bayesian Networks over the same directed acyclic graph. We support this concept with a composition operator in which two or more constrained Bayesian Networks with different or “overlapping” graphs may be combined for cross-model analysis, subject to constraints that are an optional parameter of that composition. We formulate a three-valued semantics of the theory of the reals over constrained BNs that captures the familiar duality of satisfiability and validity but over the set of Bayesian Networks that a constrained Bayesian Network denotes. This semantics is used to reduce the computation of its judgments to satisfiability checks in the first-order logic over the reals. We then apply that reduction to design optimization algorithms that can compute, for any term definable in that logic, infima and suprema up to a specified accuracy – for example for terms that specify the meaning of marginal probabilities symbolically. These optimization algorithms and their term parameter allow us to explore or verify the robustness of a constrained Bayesian Network including, but not limited to, the robustness of posterior distributions. We demonstrate the use of such extended robustness analyses on a non-trivial case study in the domain of arms control. We also report a tool prototype that we have implemented and used to conduct these analyses; it uses an SMT solver as a feasibility checker to implement these optimization algorithms; and it adapts an open-source package for Bayesian inference to symbolic computations.\nOur principal theoretical contribution is the introduction of the concept of a Constrained Bayesian Network itself, as well as its intuitive yet formal semantics. Our theoretical results, such as those for computational complexity and algorithm design, follow rather straightforwardly from these definitions. This is because the latter allow us to appeal directly to existing results from the existential theory of the reals and optimization based thereupon.\nOur main practical contribution is the successful integration of a number of disparate techniques and approaches into a coherent semantic framework and tool prototype that supports a range of modelling and analysis capabilities, and does so in a highly automated manner."
    }, {
      "heading" : "2 Background on Bayesian Networks",
      "text" : "A Bayesian Network (BN) is a graph-based statistical model for expressing and reasoning about probabilistic uncertainty. The underlying graph is directed and acyclic, a DAG. Nodes in this DAG represent random variables defined by discrete probability distributions that are also a function of the random variables represented by the parent nodes in the DAG. In other words, a random variable is conditioned on the random variables of its parent nodes.\nWe can use a BN to compute probabilities for events of interest over these random variables. Bayesian inference also allows us to revise such probabilities when additional observations of “evidence” have been made.\nFigure 1 shows a simple BN, which is part of the folklore of example Bayesian Networks. It depicts the possible causes of wet grass on two neighbours’ lawns. For example, the probabilities of Holmes’ Grass Wet is conditioned on its parents’ output – whether It Rains and Holmes’ Sprinkler is turned On or Off. The probability of Holmes’ Grass Wet = T, given that Holmes’ Sprinkler = Off, Rain = F, for instance, is computed to be 0.05, and is formally\nstated as: ppHolmes’ Grass Wet = T | Sprinkler = Off, Rain = Fq “ 0.05\nThis approach naturally gives cause to computations of the “overall” probability of an event happening, referred to as the marginal probability. In the Bayesian approach, the Junction Tree Algorithm (JTA) (see e.g. Chapter 6 in [6] for further details) may be used to revise a marginal of a BN because of “hard”, respectively “soft”, evidence – the definite, respectively probabilistic, observation of an additional or new event.\nWe now formalize BNs and use this below to enrich BNs with modeling and reasoning capabilities that realize the aforementioned requirements.\nDefinition 1 1. A Bayesian network (BN) is a pair pG, πq where G is a finite, directed, acyclic graph G “ pN,Eq of nodes N and edge relation E Ă N ˆN , and where π is a tuple pπnqnPN of formal probability tables.\n2. The formal probability table πn is defined as follows. Let pntpnq “ tn1 P N | pn1, nq P Eu be the (possibly empty) set of parents of n in DAG G and On the set of outcomes of the random variable at node n. Then πn is a discrete probability distribution, a function πn of type ` ś n1PpntpnqOn1 ˘ ˆOn Ñ r0, 1s such that its mass ř e πnpeq equals 1.\nAbove, it is understood that ś n1PHOn1 equals t˚u; in that case, πn has type isomorphic to On Ñ r0, 1s."
    }, {
      "heading" : "3 Constrained Bayesian Networks",
      "text" : "Informally, a constrained BN is obtained from a BN by replacing one or more probabilities in its probability tables with symbolic expressions, and by adding constraints for variables used in these expressions or in quantitative terms of interest, and for variables that refer to marginal probabilities of interest. We write BCX for constrained BN with set of constraints C and variable set X.\nTo illustrate, in Figure 2 the probability tables for two nodes Sprinkler and Rain of the BN in Figure 1 are made symbolic with a variable x to obtain a constrained BN. This allows us to model strict uncertainty (also known as Knightian uncertainty) in the actual value of such probabilities. Our approach allows variables to be shared across such tables, as x is shared across the tables for Sprinkler and Rain. This is certainly useful, e.g., to express that a certain subjective probability is twice as likely as another one.\nWe use variables mpH and mpW to refer to marginal probabilities\nppHolmes’ Grass Wet = Trueq (1) ppHolmes’ Grass Wet = True | Watson’s Grass Wet = Trueq (2)\nrespectively. The constraints we then consider are 0 ď x ď 1, to ensure that symbolic expressions still specify probability distributions, as well as the symbolic meaning of the marginal probabilities mpH and mpW which are captured in two non-linear equations in x as\nmpH “ 0.495˚x˚x` 0.5˚x˚p´0.95˚x` 0.95q ` 0.7˚x˚p´0.5˚x` 1q ` 1.0˚p´0.5˚x` 1q˚p´0.05˚x` 0.05q (3)\nmpW ˚p0.35˚x˚x` 0.025˚x˚p´0.95˚x` 0.95q ` 0.7˚x˚p´x˚0.5` 1q ` 0.025˚x˚p´0.05˚x` 0.05q ` 0.05˚p´0.95˚x` 0.95q˚p´x˚0.5` 1q ` 0.05˚p´x˚0.5` 1q˚p´0.05˚x` 0.05qq “ p0.3465˚x˚x` 0.025˚x˚p´0.95˚x` 0.95q ` 0.49˚x˚p´x˚0.5` 1q ` 0.05˚p´x˚0.5` 1q˚p´0.05˚x` 0.05qq (4)\nThe above equations are constructed through symbolic interpretations of computations of marginals, for example of the Junction Tree Algorithm, and subsequent elimination of\nt ::“ c | mp | x | t` t | t ˚ t ϕ ::“ true | t ď t | t ă t | ϕ | ϕ^ ϕ φ ::“ ϕ | Dx : φ | φ | φ^ φ\nFigure 3: BNF grammars for real-valued terms t, constraints ϕ, and queries φ where x are variables from set Xx, c are constant reals, mp are variables from set Xmp denoting marginal probabilities, and true denotes logical truth\ndivision operators. The latter computes a normal form of rational terms from which these equations are easily derived."
    }, {
      "heading" : "3.1 Theoretical Foundations",
      "text" : "We begin the formal development by defining grammars for symbolic expressions that occur in probability tables and for properties that contain such expressions as arguments. Figure 3 shows definitions for real-valued terms t, where c ranges over real constants, and x and mp are real variables ranging over variable sets Xx and Xmp, respectively. The distinction between mp and x is one of modelling intent. Variables mp refer to marginal probabilities of a constrained BN BCX . The meaning of these symbolic marginals is defined via constraints in C. Variables in Xx may occur in symbolic expressions in probability tables of nodes or denote any quantitative measures of interest. We write X “ XxYXmp for the disjoint union of such variable sets.\nConstraints ϕ are quantifier-free formulas built from inequalities over terms t, logical truth constant true, and propositional operators. Queries φ are built out of constraints and first-order quantifiers.\nDefinition 2 We write T rXs for the set of all terms t, CrXs for the set of all constraints ϕ generated in this manner, and we write QrXs for the set of all queries φ generated in this manner from variable set X.\nWe write T , C, and Q whenever X is clear from context and write _, ´, “, ą and so forth for derived logical, arithmetic, and relational operators.\nWe may think of a constrained BN BCX as a BN B in which entries in probability tables of nodes may not only be concrete probabilities but terms t of the grammar in Figure 3 over variable set Xx, and where the BN is enriched with a finite set of constraints C “ tϕi | 1 ď i ď nu. The intuition is that BCX denotes a set of BNs that all have the same graph and the same structure of probability tables but where probability values may be uncertain, modelled as arithmetic terms, and subject to application-specific or analysis-specific constraints. The only difference in two BNs from that set may be in the real number entries in those probability tables, and those real numbers are instantiations of the specified arithmetic terms such that all constraints are met. We formalize this:\nDefinition 3 A constrained BN of type pXx, Xmpq – denoted as X “ Xx Y Xmp by abuse of notation – is a triple pG,C, πq where G “ pN,Eq is a finite DAG, C a finite set of constraints from CrXs, and π a tuple pπnqnPN of symbolic probability tables with On as the\nset of outcomes of random variable at node n:\nπn : `\nź\nn1Ppntpnq\nOn1 ˘ ˆOn Ñ T rXxs\nNote that a symbolic probability table has the same input type as a formal probability table, but its output type is a set of terms not the unit interval. Let us first define syntactic restrictions for constrained BNs.\nDefinition 4 1. A constrained BN pG,C, πq of type X is well-formed if\n(a) X “ Xx YXmp equals the set of variables that occur in C (b) all mp in Xmp have exactly one defining equation mp “ t or mp˚ t “ t1 in C where\nneither t nor t1 contain variables from Xmp.\n2. When G and π are determined by context, we refer to a well-formed, constrained BN pG,C, πq of type X as BCX .\nItem 1(a) says that all variables in X occur in some constraint from C. Item 1(b) ensures all variables mp that model marginal probabilities have a defined meaning in C. Note that item 1(b) is consistent with having other constraints on such variables in C, for example a constraint saying that 0.1 ď mp ď x ˚ y. These items create a two-level term language, with variables in Xx informing meaning of variables in Xmp.\nA sound, constrained BN has a semantic requirement about its concretizations, which we now formalize using assignments for quantifier-free formulas.\nDefinition 5 1. An assignment α is a function α : X Ñ R. For c in R and x in X, assignment αrx ÞÑ cs equals α except at x, where it outputs c.\n2. The meaning αptq of term t in T under α, as well as the judgment α |ù φ for all φ in Q, are defined in Figure 4.\nNote that αptq extends α : X Ñ R to type T rXs Ñ R. The judgment α |ù φ is satisfaction of first-order logic over the reals. We use these judgments to define the set of concretizations of a well-formed, constrained BN:\nDefinition 6 Let BCX “ pG,C, πq be a well-formed, constrained BN where G “ pN,Eq. Let α : X Ñ R be an assignment.\n1. We write BCXrαs for the BN pG, πrαsq that forgets C from BCX and has formal probability table πrαsn for each node n with πrαsn “ λe : αpπnpeqq.\n2. The set “ |BCX | ‰ of BNs that BCX denotes, its set of concretizations, is\n“ |BCX | ‰ “ tBCXrαs | α : X Ñ R and α |ù ľ ϕ1PC ϕ1u (5)\nNote that the formal probability table πrαsn computes πrαsnpeq as αptq where t is the term πnpeq in T rXxs. We can now define sound constrained BNs.\nDefinition 7 Let BCX “ pG,C, πq be a well-formed, constrained BN. Then BCX is sound if for all BCXrαs that are concretizations of BCX we have, for all nodes n and inputs e of πrαsn, that πrαsnpeq is in r0, 1s and ř e πrαsnpeq “ 1.\nSoundness is saying that all concretizations of a well-formed, constrained BN are actually BNs: for each such BCXrαs and node n in it, πrαsn is a discrete probability distribution.\nAssumption 1 All constrained BNs used in this paper are sound.\nIt is important to know whether “ |BCX | ‰ is non-empty.\nDefinition 8 A constrained BCX is consistent iff “ |BCX | ‰ “ H.\nThe techniques developed in the next Section 3.2 will also allow us to decide whether a constrained BN is consistent."
    }, {
      "heading" : "3.2 Semantic Judgments",
      "text" : "How should we best reason about a set of BNs “ |BCX | ‰\n? We propose two semantic judgments that allow us to explore worst-case and best-case properties of BCX . A judicious combination of these judgments also enables us to express optimizations over the imprecision and probabilistic uncertainty inherent in BCX , whilst reflecting any application-specific or analysis-specific constraints. Both semantic judgments rest on a satisfaction relation between concretization BNs and queries. We define this formally.\nDefinition 9 Let BCX be a constrained BN. For all φ in Q, the two semantic judgments |ùmust and |ùmay are defined as\nBCX |ùmustφ iff for all BCXrαs in BCX we have α |ù φ (6) BCX |ùmayφ iff for some BCXrαs in BCX we have α |ù φ (7)\nThe definition in (6) allows us to discover invariants : truth of BCX |ùmustφ implies that φ holds no matter what concrete instance in “\n|BCX | ‰\nthe modeller may face, a form of worst-case reasoning. Dually, the truth of BCX |ùmayφ in (7) implies it is possible that the modeller faces a BN in “\n|BCX | ‰ that satisfies φ, a form of best-case reasoning. We may formalize this duality.\nTheorem 1 For all constrained BNs BCX and φ in Q we have\n1. BCX |ùmustφ iff not BCX |ùmay φ\n2. BCX |ùmayφ iff not BCX |ùmust φ\n3. BCX |ùmustφ1 ^ φ2 iff (BCX |ùmustφ1 and BCX |ùmustφ2)\n4. BCX |ùmayφ1 _ φ2 iff (BCX |ùmayφ1 or BCX |ùmayφ2)\nWe illustrate this formalization of constrained BNs with an example.\nExample 1 The constrained BN from Figures 1 and 2 is sound and consistent. Consider the query ϕH being mpH ă 0.3 where we use variable mpH to denote the marginal probability ppHolmes’ Grass Wet = Trueq. We mean to compute whether BCX |ùmustϕH and BCX |ùmayϕH hold for this constrained BN. We conclude that BCX |ùmustϕH does not hold: ppHolmes’ Grass Wet = Trueq equals 0.35255 for αpxq “ 0.3 and so αpmpHq “ 0.35255 as well, and we have α |ù Ź\nϕ1PC ϕ 1 and 0.35255 ę 0.3. On the other hand, BCX |ùmayϕH holds\nsince for α1pxq “ 0.1 we have α1 |ù Ź ϕ1PC ϕ 1 and α1pmpHq “ 0.15695 is less than or equal to 0.3. Observing additional hard evidence that Watson’s grass is wet, we similarly evaluate judgments BCX |ùmayϕ and BCX |ùmustϕ when ϕ contains mpW which refers to marginal\nppHolmes’ Grass Wet = True | Watson’s Grass Wet = Trueq"
    }, {
      "heading" : "3.3 Consistent constrained BNs",
      "text" : "It is important to understand how the semantic judgments |ùmay and |ùmust relate to consistent or inconsistent constrained BNs. We can characterize consistency through properties of these semantic judgments:\nTheorem 2 Let BCX be a constrained BN. Then the following are all equivalent:\n1. BCX |ùmaytrue holds.\n2. BCX is consistent.\n3. For all φ in Q, we have that BCX |ùmustφ implies BCX |ùmayφ.\n4. For all φ in Q, we have that BCX |ùmayφ_ φ holds.\n5. For all φ in Q, we have that BCX |ùmustφ^ φ does not hold.\nWe stress that it is vital to check the consistency of BCX prior to relying on any findings of its further analysis. If BCX is inconsistent, then “ |BCX | ‰\nis empty and so BCX |ùmustφ holds trivially for all φ in Q since the universal quantification of its defining semantics in (6) ranges over the empty set. Not detecting such inconsistency may thus lead to unintended and flawed reasoning. In our tool, this is a non-issue as it uses these judgments within optimization algorithms that either report a concretization as witness or report a discovered inconsistency.\nConsistency checking is NP-hard: checking the satisfiability of constraints in logic C is NP-hard. And so this hardness is inherited for any notion of size of a constrained BN that includes the sum of the sizes of all its constraints."
    }, {
      "heading" : "3.4 Reducing |ùmay and |ùmust to satisfiability checking",
      "text" : "Our case studies involving constrained BNs suggest that it suffices to consider elements of C, i.e. to consider formulas of Q that are quantifier-free. The benefit of having the more expressive logic Q, however, is that its quantifiers allow us to reduce the decisions for BCX |ùmayϕ and BCX |ùmustϕ for quantifier-free formulas ϕ to satisfiability checking, respectively validity checking in the logic Q – which we now demonstrate. For sound, constrained BNs BCX , the judgment BCX |ùmayϕ asks whether there is an assignment α : X Ñ R such that α |ù Ź ϕ1PC ϕ 1 and α |ù ϕ both hold. Since C is contained in Q, we may capture this meaning within the logic Q itself as a satisfiability check. Let set X equal tx1, . . . , xnu. Then, asking whether α |ù Ź\nϕ1PC ϕ 1 and α |ù ϕ hold, asks whether the formula in (8) of logic Q is satisfiable:\nDx1 : . . . : Dxn : ϕ^ ľ ϕ1PC ϕ1 (8)\nDefinition 10 For a constrained BN BCX and ϕ in C, we write ExpBCX , ϕq to denote the formula defined in (8).\nNote that ExpBCX , ϕq depends on BCX : namely on its set of variables X and constraint set C, the latter reflecting symbolic meanings of marginal probabilities. Let us illustrate this by revisiting Example 1.\nExample 2 For ϕH as in Example 1 with type X “ txuY tmpHu, the formula we derive for BCX |ùmayϕH is\nDmpH : Dx : pmpH ă 0.3q ^ p0.1 ď xq ^ px ď 0.3q ^ (9) p0.5 ˚ x` p1´ 0.5 ˚ xq “ 1q ^ px` p1´ xq “ 1q ^ pmpH “ tq\nwhere t is the term on the righthand side of the equation in (3).\nWe can summarize this discussion, where we also appeal to the first item of Theorem 1 to get a similar characterization for |ùmust.\nTheorem 3 Let BCX be a constrained BN and ϕ in C. Then we have:\n1. Formula ExpBCX , ϕq in (8) is in Q and in the existential fragment of Q.\n2. Truth of BCX |ùmayϕ is equivalent to the satisfiability of ExpBCX , ϕq in Q.\n3. BCX |ùmayϕ can be decided in PSPACE in the size of formula ExpBCX , ϕq.\n4. BCX |ùmustϕ can be decided in PSPACE in the size of formula ExpBCX , ϕq.\nThis result of deciding semantic judgments in polynomial space pertains to the size of formulas ExpBCX , ϕq and ExpBCX , ϕq, and these formulas contain equations that define the meaning of marginals symbolically. There is therefore an incentive to simplify such symbolic expressions prior to their incorporation into C and these formulas, and we do such simplifications in our implementation."
    }, {
      "heading" : "3.5 Constrained Union Operator",
      "text" : "We also want the ability to compare two or more constrained BNs or to discover relationships between them. This is facilitated by a notion of composition of constrained BNs, which we now develop. Consider two constrained BNs BC1X1 and B C2 X2\n. Our intuition for composition is to use a disjoint union of the graphs of each of these constrained BNs such that each node in this unioned DAG still has its symbolic probability table as before. This union operator renames nodes that appear in both graphs so that the union is indeed disjoint. As a set of constraints for the resulting constrained BN, we then consider C1 Y C2.\nIt is useful to make this composition depend on another set of constraints C. The idea is that C can specify known or assumed relationships between these BNs. The resulting composition operator CY defines the composition\nBC1X1 CYBC2X2 (10)\nas the constrained BN with graph and probability tables obtained by disjoint union of the graphs and symbolic probability tables of BC1X1 and B C2 X2\n, where the set of constraints for this resulting constrained BN is now C1 Y C2 Y C.\nThis composition operator has an implicit assumption for being well defined, namely that C does not contain any equations that (re)define the (symbolic) meaning of marginal probabilities given in C1 Y C2.\nWe give an example of such a union of constrained BNs that already illustrates some reasoning capabilities to be developed in this paper:\nExample 3 Figure 5 specifies a constrained BN B C10 X 10\nthat is similar to constrained BN BC0X0 defined in Figure 2 but that models rain with more specificity. Variables y and z are used in symbolic probabilities, and variables mp1H and mp 1 W refer to the marginals in (1) and (2) respectively. The constraint 0.1 ď 5˚y ď 0.3 in C 10 corresponds to the constraint 0.1 ď x ď 0.3 in C0 and so term 5 ˚ y in some way reflects x, that it rains according to BC0X0.\nThe constraint set C that binds the two models together is t2 ˚ z “ xu, which ensures that the probability for the sprinkler to be on is the same in both models. In the constrained\nBN BC0X0 CYBC\n1 0\nX 10 , we want to understand the difference in the marginal probabilities mpW and\nmp1W , expressed by term diff “ mpW ´mp1W . Subtraction ´ and equality “ are derived operations in Q. The methods we will develop in this paper allow us to conclude that the maximal value of diff is in the closed interval r0.134079500198, 0.134079508781s, with diff being 0.134079500198 when\nx “ 0.299999999930 z “ 0.149999999965 y “ 0.020000000003 mpW “ 0.663714285678 mp1W “ 0.529634782614\nSimilarly, we may infer that the minimum of diff is in the closed interval\nr´0.164272228181,´0.164272221575s\nwith diff being ´0.164272221575 when\nx “ 0.100000000093 z “ 0.050000000046 y “ 0.059999999855 mpW “ 0.472086956699 mp1W “ 0.636359183424"
    }, {
      "heading" : "In particular, the absolute value of the difference of the marginal probability (2) in those",
      "text" : "constrained BNs is less than 0.1643, attained for the values just shown.\nThese union operators are symmetric in that BC1X1 CYBC2X2 and B C2 X2 CYBC1X1 satisfy the same judgments |ùmust and |ùmay for all φ in Q. Idempotency won’t hold in general as unions may introduce a new set of constraints C. Associativity holds, assuming all compositions in (11) give rise to sound constrained BNs:\npBC1X1 CYBC2X2q C1YBC3X3 is equivalent to B C1 X1 CYpBC2X2 C1YBC3X3q (11)\nAssumption 2 All composed, constrained BNs BC1X1 CYBC2X2 used in this paper are sound."
    }, {
      "heading" : "3.6 Non-Linear Optimization",
      "text" : "We next relate the judgments |ùmay and |ùmust to optimization problems that seek to minimize or maximize values of terms t of interest in a constrained BN BCX , and where B C X itself may well be the result of a composition of constrained BNs as just described. We define the set of “concretizations” of term t for BCX :\nDefinition 11 Let t be a term whose variables are all in X for a constrained BN BCX . Then t| t |u Ď R is defined as set tαptq | BCXrαs P “ |BCX | ‰ u.\nNote that t| t |u does depend on C and X as well, but this dependency will be clear from context. We can compute approximations of sup t| t |u and inf t| t |u, assuming that these values are finite. To learn that sup t| t |u is bounded above by a real high, we can check whether BCX |ùmustt ď high holds. To learn whether sup t| t |u is bounded below by a real low, we can check whether BCX |ùmaylow ď t holds. Gaining such knowledge involves both judgments |ùmust and |ùmay. So we cannot compute approximations of sup t| t |u directly in the existential fragment of Q but search for approximations by repeatedly deciding such judgments.\nWe want to do this without making any assumptions about the implementation of a decision procedure for logic Q or its existential fragment. This can be accommodated through the use of extended binary search, as seen in Figure 6, to derive an algorithm Sup for computing a closed interval rlow, highs of length at most δ ą 0 such that sup t| t |u is guaranteed to be in rlow, highs. This algorithm has as input a constrained BN BCX with X as set of variables for constraint set C, a term t in T rXs, and a desired accuracy δ ą 0. This algorithm assumes that BXC is consistent and that 0 ă sup t| t |u ă 8. We explain below how we can weaken those assumptions to sup t| t |u ă 8.\nAlgorithm Sup first uses a satisfiability witness α to compute a real value αptq that t can attain for some BCXrαs in “ |BCX | ‰\nsuch that αptq ą 0. It then stores this real value in a cache and increases the value of cache each time it can find a satisfiability witness that makes the value of t at least twice that of the current cache value. Since sup t| t |u ă 8, this while loop terminates. The subsequent assignments to low and high establish an invariant that there is a value in t| t |u that is greater or equal to low, but that there is no value in t| t |u that is greater or equal to high.\nThe second while statement maintains this invariant but makes progress using bisection of the interval rlow, highs. This is achieved by deciding whether there is a value in t| t |u that is greater or equal to the arithmetic mean of low and high. If so, that mean becomes the new value of low, otherwise that mean becomes the new value of high. By virtue of these invariants, the returned closed interval rlow, highs contains sup t| t |u as desired. We capture this formally:\nTheorem 4 Let BCX be a consistent constrained BN and δ ą 0. Let 0 ă sup t| t |u ă 8. Then we have:\n1. Algorithm Suppt, δ, BCXq terminates, sup t| t |u is in the returned closed interval rl, hs of length ď δ, and BCX |ùmayt ě l is true.\n2. Let c be the initial value of cache. Then the algorithm makes at most t2¨log2psup t| t |uq´ log2pcq ´ log2pδq ` 1u satisfiability checks for formulas ExpBCX , t ě rq or ExpBCX , t ą rq,\nSuppt, δ, BCXq t let α : X Ñ R make ExpBCX , t ą 0q true; cache “ αptq; while pExpBCX , t ě 2 ˚ cacheq satisfiableq t let α1 : X Ñ R make ExpBCX , t ě 2 ˚ cacheq true; cache “ α1ptq; u low “ cache; high “ 2 ˚ cache; assert ppExpBCX , t ě lowq satisfiableq&& pExpBCX , t ě highq unsatisfiableqq; while p| high´ low | ą δq t if pExpBCX , t ě low` | high´ low | { 2qq satisfiableq t low “ low` | high´ low | { 2; assert ppExpBCX , t ě lowq satisfiableq&& pExpBCX , t ě highq unsatisfiableqq; u else t high “ low` | high´ low | { 2; assert ppExpBCX , t ě lowq satisfiableq&& ExpBCX , t ě highq unsatisfiableqq; u u return rlow, highs; u\nWe now give an example of using algorithm Sup. Our specifications of optimization algorithms such as that of algorithm Sup in Figure 6 do not return witness information, we omitted such details for sake of simplicity.\nExample 4 For constrained BN BC0X0 of Figure 2, SuppmpW , δ, B C0 X0 q terminates for δ “ 0.000000001 with output r0.663714282364, 0.663714291751s. The value 0.663714282364 is attained when x equals 0.299999999188.\nAn algorithm Infpt, δ, BCXq is defined in Figure 7. It assumes that BCX is consistent and that inf t| t |u is a subset of R`0 and contains a positive real – conditions we will weaken below. In that case, it terminates and returns a closed interval rl, hs such that inf t| t |u is in rl, hs. We prove this formally:\nTheorem 5 Let BCX be a consistent constrained BN and δ ą 0. Let t| t |u Ď R`0 contain a positive real. Then we have:\n1. Algorithm Infpt, δ, BCXq terminates and inf t| t |u is in the returned interval rl, hs such that h´ l ď δ and BCX |ùmayt ď h are true.\nInfpt, δ, BCXq t let α : X Ñ R make ExpBCX , t ą 0q true; cache “ αptq; while pExpBCX , t ď 0.5 ˚ cacheq satisfiable and 0.5 ˚ cache ą δq t let α1 : X Ñ R make ExpBCX , t ď 0.5 ˚ cacheq true; cache “ α1ptq; u if pExpBCX , t ď 0.5 ˚ cacheq satisfiableq t return r0, 0.5 ˚ caches; u low “ 0.5 ˚ cache; high “ cache; assert pExpBCX , t ď lowq unsatisfiableq&& pExpBCX , t ď highq satisfiableqq; while p| high´ low | ą δq t if pExpBCX , t ď low` | high´ low | { 2qq satisfiableq t high “ low` | high´ low | { 2; assert ppExpBCX , t ď lowq unsatisfiableq&& pExpBCX , t ď highq satisfiableqq; u else t low “ low` | high´ low | { 2; assert ppExpBCX , t ď lowq unsatisfiableq&& pExpBCX , t ď highq satisfiableqq; u u return rlow, highs; u\nWe now show how we can relax the conditions of BCX being consistent and of 0 ă sup t| t |u ă 8 to sup t| t |u ă 8. In Figure 8, we see this modified algorithm Sup˚ which relies on both Sup and Inf. It returns a closed interval with the same properties as that returned by Sup but where sup t| t |u only need be finite. We state the correctness of this algorithm formally:\nTheorem 6 Let BCX be a constrained BN, δ ą 0, and sup t| t |u ă 8. Then Sup‹pt, δ, BCXq terminates and its calls to Sup and Inf meet their preconditions. Moreover, it either correctly identifies that BCX is inconsistent, that 0 is the maximum of t| t |u or it returns a closed interval rl, hs such that sup t| t |u is in that interval, h ´ l ď is less than or equal to δ, and BCX |ùmayt ě l holds.\nWe conclude this section by leveraging Sup‹ to an algorithm Inf‹, seen in Figure 9. Algorithm Inf‹ relaxes that t| t |u contains a positive real and is a subset of R`0 to a more general pre-condition ´8 ă inf t| t |u, and it has correct output for inconsistent, constrained BNs. We formalize this:\nSup‹pt, δ, BCXq t if pExpBCX , t ą 0q satisfiableq t return Suppt, δ, BCXq; u\nelseif pExpBCX , t “ 0q satisfiableq t return 0 as maximum for t; u\nelseif pExpBCX , t ă 0q satisfiableq t let rl, hs “ Infp´t, δ, BCXq; return r´h,´ls; u return BCX is inconsistent; u\nFigure 8: Algorithm Sup‹ uses algorithms Sup and Inf and terminates whenever sup t| t |u ă 8. It either recognizing that 0 is the maximum of t| t |u, returns a closed interval rl, hs with h´ l ď δ such that sup t| t |u is in rl, hs, or it detects that BCX is inconsistent\nInf‹pt, δ, BCXq t let x “ Sup‹p´t, δ, BCXq; if px reports that BCX is inconsistentq t return BCX is inconsistent; u elseif px reports 0 as maximum for ´tq t return 0 as minimum for t; u elseif px reports interval rl, hsq t return r´h,´ls; u u\nFigure 9: Algorithm Inf‹ uses algorithm Sup‹ and terminates whenever ´8 ă inf t| t |u. It either recognizes that 0 is the minimum of t| t |u, returns a closed interval rl, hs with h´ l ď δ such that inf t| t |u is in rl, hs, or it detects that BCX is inconsistent\nTheorem 7 Let BCX be a constrained BN, δ ą 0, and t a term with ´8 ă inf t| t |u. Then Inf‹pt, δ, BCXq terminates and either correctly identifies that BCX is inconsistent, that 0 is the minimum of t| t |u or it returns a closed interval rl, hs of length ď δ such that inf t| t |u is in rl, hs and BCX |ùmayt ď h holds.\nLet us revisit Example 3 to illustrate use of Sup‹.\nExample 5 Let C̃0 be C0 Y t0.1 ď x ď 0.2u. For constrained BN BC̃0X0 CYBC\n1 0\nX 10 , we maximise\ndiff using Sup‹pdiff, 0.000000001, BC̃0X0 CYBC\n1 0\nX 10 q, which returns the interval\nr´0.055219501217,´0.0552194960809s\narising from the third case of Sup‹ as both ExpBCX , t ą 0q and ExpBCX , t “ 0q are unsatisfiable, but formula ExpBCX , t ă 0q is satisfiable. It shows that marginal mpW is always smaller than marginal mp1W in this constrained BN, in contrast to the situation of Example 3."
    }, {
      "heading" : "4 Detailed Case Study",
      "text" : "We now apply and evaluate the foundations for constrained BNs on a case study in the context of arms control. Article VI of the Treaty on the Non-Proliferation of Nuclear Weapons (NPT) [1] states that each treaty party\n“undertakes to pursue negotiations in good faith on effective measures relating to cessation of the nuclear arms race at an early date and to nuclear disarmament, and on a treaty on general and complete disarmament under strict and effective international control.”\nOne important aspect of meeting such treaty obligations may be the creation and execution of trustworthy inspection processes, for example to verify that a treaty-accountable item has been made inoperable. Designing such processes is challenging as it needs to guarantee sufficient mutual trust between the inspected and inspecting party in the presence of potentially conflicting interests. Without such trust, the parties might not agree to conduct such inspections.\nThe potential benefit of mathematical models for the design and evaluation of such inspection processes is apparent. Bayesian Networks can capture a form of trust – through an inherent bias of processing imperfect information – and different degrees of beliefs – expressed, e.g., in subjective probabilities. Bayesian Networks can also represent objective data accurately, and their graphical formalism may be understood by domain experts such as diplomats. These are good reasons for exploring Bayesian Networks for modeling and evaluating inspection processes. But Bayesian Networks do not seem to have means of building confidence in their adequacy and utility, especially in this domain in which prior data for learning both graph structure and probabilities at nodes in such a graph are hard to find. We now show how constrained BNs can be used to build such confidence in mathematical models of an inspection process."
    }, {
      "heading" : "4.1 An Arms Control Inspection Process",
      "text" : "Consider the situation of two fictitious nation states. The inspecting nation is tasked with identifying whether an item belonging to the host nation, available to inspect in a controlled inspection facility and declared by the host nation to be a nuclear weapon, is indeed a nuclear weapon. This situation is similar to a scenario that had been explored in the UK/Norway initiative in 2007 [3, 4].\nGiven the nations’ non-proliferation obligations and national security concerns, the design details of the inspected item must be protected: the inspecting nation will have no visual access to the item. Instead the nations agree that the to-be-inspected item contain Plutonium with the isotopic ratio 240Pu:239Pu below a certain threshold value, which they set at 0.1.\nIn order to draw conclusions about whether an item presented for inspection is a weapon, the inspecting nation uses an information barrier (IB) system comprising a HPGe detector and bespoke electronics with well-understood performance characteristics (see Figure 10, [3]) to conduct measurements on the item while the item is concealed in a box. The IB system displays a green light if it detects a gamma-ray spectrum indicative of the presence of Plutonium with the appropriate isotopic ratio; if it does not detect this spectrum for whatever reason, it shows a red light. No other information is provided, and weapon-design information is thus protected [4].\nThe inspecting nation believes that it may be possible for the host nation to spoof a radioactive signal – or in some way provide a surrogate – to fool the detector, or that the host nation may have just placed Plutonium with the appropriate isotopic ratio in the box rather than a weapon. These subjective assessments should be reflected in the mathematical model alongside the error rates of the IB system that reflect the reliability of that device.\nIn order to deter cheating, the inspecting nation is allowed to choose the IBs used in the verification from a pool of such devices provided by the host nation, and may choose one or two IBs to that end. From that same pool of devices, the inspecting nation may take some unused IBs away for authentication – activities designed to assess whether the host nation tampered with the IBs. But the inspecting nation must not inspect any used IBs, to prevent it from exploiting any residual information still present in such used IBs to its advantage.\nThis selection process of IBs is therefore designed to ensure that a nefarious host nation\nis held at risk of detection should it decide to tamper with the IBs used in verification: it would run the risk of one or more tampered IBs being selected for authentication by the inspecting nation. Although such authentication cannot be assumed to be perfect – and this fact, too, should be modelled – the prospect of detection may deter such a host.\nWe model this inspection process through constrained BNs that are abstracted from a sole BN with DAG shown in Figure 11 and based on a design developed by the Arms Control Verification Research group at AWE. This DAG depicts different aspects of the verification procedure in four key areas:\n• the selection of the IBs for inspection or authentication purposes,\n• the workings of the IB in the inspection itself,\n• authentication of (other) IBs, and\n• the combination of these aspects to assess any possibility of cheating overall, be it through IB tampering, surrogate nuclear sources, and so forth.\nThe selection of the IBs starts with the IB pool size; a selection of IBs built by the host nation, from which there will be a Number of IBs picked for authentication and Number of IBs picked for use by the inspecting nation. Should a Number of tampered IBs exist, then the selection process (blind to such a tamper) follows a Hypergeometric distribution and will probabilistically determine whether such tampered IBs make it into use in the verification process, authentication process or neither. The choice of distribution reflects that IBs – once chosen for either verification or authentication – cannot be used for any other purpose.\nThe IBs picked for either authentication or verification help the inspecting nation to judge whether the item under inspection Is a weapon. A weapon or a Surrogate Pu source determine physical nuclear properties about the Isotopic ratio of Plutonium elements. Our mathematical model captures a possible inspector judgment that a surrogate source would only be used if the host felt that it was extremely likely to pass the IBs verification tests. Therefore, any surrogate source would have isotopic properties at least as good as those of a real weapon.\nWe stress that the probabilities chosen for each isotopic ratio, conditioned on whether the item under test is or is not a weapon, are not derived from real-world weapons data, but instead reflect in broad terms that Plutonium with a higher isotopic ratio than the chosen threshold is less likely to be found in a nuclear weapon. A bespoke algorithm is used by the IB system on the collected gamma-ray spectrum to test whether both the Peaks are in the expected locations and the Peak aspect ratio are as expected. If all 5 peaks are present and the Ratio of 240/239 isotopes is acceptable, then one or both of the First IB result or Second IB result are reported, conditional on any tampering and depending on whether or not two IBs are used to test the same item.\nA mathematical model cannot hope to reflect each potential tamper. Therefore, we model authentication as an assessment of the Inspector’s authentication capabilities: the better these are, the more likely the Tamper will be found, and this requires that at least one tampered IB exists and was selected for authentication. This is controlled by the parent nodes: the aforementioned Hypergeometric distribution, and a node Chance of picking a tampered IB for authentication.\nThe mathematical model is drawn together by the overarching question of “Is the Host cheating?”. If so, we then determine a Cheating method, which reflects the understanding of the inspecting nation about the possible ways that the host nation could try to cheat, as outlined above, and the prior beliefs of the inspecting nation about the relative likelihood of the use of each method if the host nation were to be cheating.\nFinally, we check whether a Portal monitor is used to stop transportation of radioactive material – which could be used as a surrogate source – in and out of the facility, although we do not model this aspect in greater detail.\nThe probabilities used in this BN stem from a variety of sources. Some are somewhat arbitrarily selected, as described above, and therefore need means of building confidence in their choice. Probabilities relating to the performance of the IB system are derived from experimental analysis of the UKNI IB [4, 3].\nThe size of the probability tables for nodes of the BN in Figure 11 range from small (a few or tens of entries), to medium (hundreds of entries) and larger ones (thousands of entries). Given that complexity, we refrain from specifying more details on these tables within the paper itself.\nOur evaluation of the methods developed in Section 3 will abstract the BN described above (see Figure 11) into constrained BNs, and demonstrate that these abstractions can inform decision support given the sparsity or lack of prior data that informed its choices of probabilities.\nAssumption 3 For convenience, this case study will not explicitly list or show the constraints that define the meaning of marginals symbolically. These meanings are included in the open-access research code cited on page 34."
    }, {
      "heading" : "4.2 Impact of Cheating Method on Tamper Detection",
      "text" : "We want to understand how the choice of cheating method can impact the probability of detecting a tamper. The uncertainty about what cheating method the host nation will adopt is modelled in a constrained BN BC1X1 that takes the BN from Figure 11 and replaces the probability table for its node Cheating Method as specified in Figure 12. We use variables x, y, and u to denote, respectively, the probability of IB tamper only, Surrogate source tamper only, and both IB tamper and surrogate source tamper. The variable mptf refers to the marginal probability ppWill tamper be found? = Yesq.\nWe compute the interval rl, hs “ r0.197137598548, 0.197137608314s as output of the function call Sup‹pmptf , 0.00000001, BC1X1q. The witness information for the existentially quantified variables x, y, u, and mptf pertains to value l “ 0.197137598548:\nx “ 0.000000010001153 y “ 0.000000010001153 u “ 0.999999979997693\nWe compute the interval rl̃, h̃s “ r5.875158e´09, 1.1750316e´08s as output of function call Inf‹pmptf , 0.00000001, BC1X1q. The witness information is now for the value h̃ “ 1.1750316é 08 of mptf and we get\nx “ 0.000000030265893 y “ 0.999999939468212 u “ 0.000000030265893\nCheating Method\nWe may combine this information, for example to bound the range of values that mptf can possibly attain, as the interval\nrl̃, hs “ r0.000000000587, 0.197137608314s\nWe therefore conclude that this marginal probability can only vary by less than 0.19714 in the given strict uncertainty of the model.\nLet us now ask for what values of x can mptf be within 0.01 of the lower bound l “ 0.197137598548 returned for Sup‹ above. To that end, we consider the constrained BN B\nC11 X1\nwhere C 11 “ C1 Y t| mptf ´ 0.197137598548 | ď 0.01u and compute lower and upper bounds for x in this constrained BN:\nrlx, hxs “ Sup‹px, 0.00000001, BC 1 1\nX1 q “ r0.999999994824, 1.00000000196s\nrl̃x, h̃xs “ Inf‹px, 0.00000001, BC 1 1\nX1 q “ r7.4505805é 09, 1.4901161é 08s\nFrom this we can learn that\n@x : “ p1.4901161é 08 ď x ď 0.999999994824q ^ ľ C1 ‰\nÑ | mptf ´ 0.197137598548 | ď 0.01 (12)\nis logically valid: whenever x is in that value range and all constraints in C1 are satisfied (which is true for all concretizations of BC1X1), then the marginal mptf is within 0.01 of the lower bound for its maximal value.\nRepeating these optimizations above for variables y and u, we determine similar formulas that are logically valid:\n@y : “ p1.209402é 08 ď y ď 0.0507259986533q ^ ľ C1 ‰\nÑ | mptf ´ 0.197137598548 | ď 0.01\n@u : “ p1.4901161é 08 ď u ď 0.999999998164q ^ ľ C1 ‰\nÑ | mptf ´ 0.197137598548 | ď 0.01\nThese results say that the marginal mptf is insensitive to changes to x, which is able to vary across the whole range p0.0, 1.0q without having much impact on the results; the\nAuthentication Capabilities\nsituation is very similar for variable u. For variable y, the range at which mptf is not too sensitive on changes of y is much smaller – just over 0.05. Overall, we conclude that the model remains in the area of highest probability for detecting tampering as long as x or u are large.\nOur analysis shows that the “tamper” cheating method is the one for which there is the highest chance of detecting cheating. However, our results also highlight that unless both tamper and surrogate source, or tamper on its own are used, there are limited ways in which to detect cheating through these nodes. From this we learn that use of a portal monitor is advisable, as any increase in y moves the marginal out of the region of highest probability of detecting cheating, and decreases the chance of cheating being detected otherwise. Related to this is that the range of y gives potential insight into future work required on tamper detection for the inspecting nation. Despite contributing neither to an IB tamper nor detection, y can vary by over 0.05 – over five times that of the movement away from the marginal mptf ’s maximum point by only 0.01. This suggests there are other limiting factors to tamper detection, such as capability, that could be better reflected in a mathematical model."
    }, {
      "heading" : "4.3 Comparing two BN models",
      "text" : "We now illustrate the benefits of composing two constrained BNs (see Section 3.5). Two constrained BNs, BC2X2 and B C12 X 12 , are defined in Figure 13. Both have symbolic and equivalent probability tables for node Authentication Capabilities but consider different hard evidence for the probability of a tamper to be found. In BC2X2 , there is 1 IB machine picked for authentication whereas in B C12 X 12 there are 5 IB machines picked to that end, resulting in the respective marginals\nppWill tamper be found? = Yes | Host cheating = Yes, (13) Number of IBs picked for authentication = 1q\nppWill tamper be found? = Yes | Host cheating = Yes, (14) Number of IBs picked for authentication = 5q\nIn both models, the probability for state “Good” is bounded by 0.6667 so that there is a “gradient” pivoting around Medium capabilities fixed at 0.3333.\nWe seek decision support on how much to prioritise research into IB authentication ca-\npabilities, each of BC2X2 and B C12 X 12 representing a different capability scenario. Of interest here is the change in the likelihood that a tamper will be found. We can simply model this by defining a new term\ndiff “ mptf2 ´mptf 12 (15)\nVariable diff is in Xx for the constrained BN B C2 X2\nCYBC 1 2\nX 12 where the constraint set C for this\ncombination is tdiff “ mptf2 ´mptf 12u. We compute the value of diff for each combination of values px, yq from set\nS “ tp0.0` 0.01 ¨ a, 0.0` 0.01 ¨ bq | 0 ď a, b ď 67u (16)\nand linearly interpolate the result as a surface seen in Figure 14. The linear relationship between the symbolic probabilities of node Authentication Capability to that of its child node Will the tamper be found? make this surface flat.\nWe can now use the method familiar from our earlier analyses to assess the value range of\nterm diff in this composed, constrained BN. The function call Sup‹pdiff, 0.00000001, BC2X2 CYBC\n1 2\nX 12 q\nreturns the interval\nrl, hs “ r0.0711404333363, 0.0711404338663s\nNext, Inf‹pdiff, 0.00000001, BC2X2 CYBC\n1 2\nX 12 q is computed as the interval\nrl̃, h̃s “ r´0.307085548061,´0.307085547533s\nIn particular, the values of diff for all concretizations of BC2X2 CYBC\n1 2\nX 12 lie in the interval\nr´0.307085548061, 0.0711404338663s\nThe blue surface of diff in Figure 14 is mostly negative (below the red plane). This shows that the case of testing 5 IBs for tampers is nearly always better, irrespective of the confidence one may have in one’s ability to find a tamper. This is true, other than for the most extreme cases when there is the least confidence in authentication capabilities when testing five IBs (for y “ 0) and most confidence when testing one (for x “ 0.667).\nLet us next explore a situation in which the inspector believes to have high authentication capabilities, regardless of whether 1 or 5 IBs are picked for authentication. We can easily model this by setting C 1 “ C Y t0.467 ď x, y ď 0.667u and refining the composed model using C 1. We compute the output of Sup‹pdiff, 0.00000001, BC2X2 CY 1 B C12 X 12 q to be the interval\nrl, hs “ r´0.0282766319763,´0.0282766314489s\nand Inf‹pdiff, 0.00000001, BC2X2 CY 1 B C12 X 12 q to be the interval\nrl̃, h̃s “ r´0.141568560141,´0.141568559299s\nNow diff is in r´0.141568560141,´0.0282766314489s and the largest absolute difference between picking 1 and 5 IBs for authentication is greater than 0.14, witnessed when the inspector has a particularly high capability in authenticating 5 IBs, (when y “ 0.667 and mptf 12 “ 0.24932) compared with only inspecting one IB with more moderate capability (when x “ 0.467,mptf2 “ 0.10696).\nA decision maker could vary the use of the above approach in order to weigh the cost of IB production against the cost of developing and employing more advanced authentication capabilities. He or she could also query in detail how the results of such cost-benefit analyses might change as new information is learned or new techniques deployed. This capability might help decision makers to balance their priorities and to gain the best assurance possible within a cost budget that the verification regime they implement is effective."
    }, {
      "heading" : "4.4 Determining equivalent decision support",
      "text" : "We assess the consistency of two different constrained BNs of equal intent of decision support. Constrained BNs BC3X3 and B C13 X 13 are identical to BC1X1 and its symbolic probability table for node Cheating Method as in Figure 12, except that th is an additional variable used to model decision support. Variable set Xmp also changes. For B C3 X3\nwe have Xmp “ tmptf3u and for B\nC13 X 13\nwe set Xmp “ tmptf 13u instead. Variable mptf3 denotes marginal probabilities for hard evidence that Initial Pool Size = 10 IBs in (17), whereas variable mptf 13 denotes a marginal for hard evidence Initial Pool Size = 20 IBs in (18):\nppWill tamper be found? = Yes | Initial Pool Size = 10q (17) ppWill tamper be found? = Yes | Initial Pool Size = 20q (18)\nThese are marginal probabilities that the nation which is authenticating IBs will find a tamper. A decision – for example that an IB has been tampered with – may then be supported if such a marginal is above a certain threshold th. We now want to understand whether the\ntwo constrained BNs would support decisions in the same manner, and for what values or value ranges of th.\nFor any value th, consider the constraint ϕth in Q given by\n“` pth ă mptf3q ^ pmptf 13 ď thq ˘ _ ` pth ă mptf 13q ^ pmptf3 ď thq ˘‰\nWe can now analyze whether both constrained BNs will always support decisions through threshold th by evaluating\nBC3X3 CYBC\n1 3\nX 13 |ùmustϕth (19)\nwhere C equals t0 ă th ă 1u. By Theorem 1, judgment (19) is equivalent to\nnot BC3X3 CYBC\n1 3\nX 13 |ùmay\n` pth ă mptf3q ^ pmptf 13 ď thq ˘ _ ` pth ă mptf 13q ^ pmptf3 ď thq ˘\n(20)\nSetting ϕ1 ” pth ă mptf3q ^ pmptf 13 ď thq and ϕ2 ” pth ă mptf 13q ^ pmptf3 ď thq, the same theorem tells us that (20) is equivalent to\n“ not BC3X3 CYBC\n1 3\nX 13 |ùmayϕ1\n‰ and “ not BC3X3 CYBC\n1 3\nX 13 |ùmayϕ2\n‰\n(21)\nUsing our tool, we determine that ExpBC3X3 CYBC\n1 3\nX 13 , ϕ1q is unsatisfiable and so – by appeal to\nTheorem 3 – the first proof obligation of (21) holds. Similarly, we evaluate the satisfiability of ExpBC3X3 CYBC 1 3 X 13 , ϕ2q. Our tool reports this to be satisfiable and so the two constrained BNs do not always support the same decision. We now want to utilize our non-linear optimization method to compute ranges of the th itself for which both models render the same decision. Understanding such a range will be useful to a modeller as both models are then discovered to be in agreement for all values of th in such a range.\nSince ExpBC3X3 CYBC\n1 3\nX 13 , ϕ1q is unsatisfiable, we use C 1 “ t0 ă th ă 1, ϕ2u which forces truth\nof ϕ2, and compute Sup ‹pth, 0.00000001, BC3X3\nC1YBC 1 3\nX 13 q to maximise expression th. This obtains\nthe interval rl, hs “ r0.259147588164, 0.259147588909s\nComputing Inf‹pth, 0.00000001, BC3X3 C1YBC 1 3 X 13 q outputs the interval\nrl̃, h̃s “ r´9.31322é 10,´4.65661é 10s\nFor the given accuracy δ, the interval rl̃, h̃s may be interpreted as 0. Thus, we can say that for all th in r0, 0.259147588909s the use of either BC3X3 or B C13 X3\ncould support different decisions. More importantly, we now know that both constrained BNs always support the same decision as described above when the value of the threshold th for decision making is greater or equal to 0.2592, say.\nThe range of th for which both models can support different decisions may seem rather large and it may be surprising that it goes down to zero. But this is a function of the chance and capability of finding a tamper in an IB. Intuitively, the models tend to disagree most in situations where the chance of cheating by tampering is highest, when x “ 1, and thus where\nCheating Method\nauthenticating the IB has benefit. Our approach gave a decision maker safe knowledge that any threshold for decision making outside the range r´9.31322é 10, 0.259147588909s would statistically agree and lead to the same decision regarding finding tampers, irrespective of the initial number of IBs – either 10 or 20 – in the pool. Dependent on the nations involved, and the tolerances for decision making they are willing to set, it could be decided – for instance – that building only 10 IBs per inspection would be enshrined in the treaty to avoid unnecessary expense and so forth. This would undoubtedly be an important data-driven decision for diplomats and negotiators to make."
    }, {
      "heading" : "4.5 Symbolic sensitivity analysis",
      "text" : "It is well known that BNs may be sensitive to small changes in probability values in tables of some nodes. Sensitivity analyses have therefore been devised as a means for assessing the degree of such sensitivities and the impact this may have on decision support. See, e.g., the sensitivity value defined in [32, 31].\nWe now leverage such analyses to our approach by computing such sensitivity measures symbolically as terms of the logic Q. Then we may analyze such terms using the methods Sup‹ and Inf‹ as before to understand how such sensitivity measures may vary across concretizations of a constrained BN. We illustrate this capability for constrained BN BC4X4 , which is similar to BC1X1 but has probability table for node Cheating Method as shown in Figure 15. The sensitivity value describes the change in the posterior output of the hypothesis for small variations in the likelihood of the evidence under study. The larger the sensitivity value, the less robust the posterior output of the hypothesis. In other words, a likelihood value with a large sensitivity value is prone to generate an inaccurate posterior output. If the sensitivity value is less than 1, then a small change in the likelihood value has a minimal effect on the result of the posterior output of the hypothesis.\nA modeller may be uncertain about the sensitivity of event Will tamper be found? = Yes to the authentication of IBs if probabilities in node Authentication Capability of the IB were to change. Our tool can compute such a sensitivity value s symbolically for the sensitivity of event Will tamper be found? = Yes to small perturbations in probabilities of node Authentication Capability.\ns = 250.0*(0.000333567254313619*x + 0.171472799414097)* (0.000400681386562896*x + 0.205973332629545)**2* (0.000400681386562899*x + 0.205973332629545)* (0.00133627242418726*x + 0.686921064319534)/ ((0.19713762029366*x + 0.0638269490499437)* (4.01363933844916e-6*x**2 + 0.00412648402564936*x + 1.06062534386303)**2)\nwhere terms PO, Px, POx and PxO are defined as\nPO ” ppAuthentication Capability = Lowq (23) Px ” ppFinding a tamper in IB = Yesq\nPOx ” ppAuthentication Capability = Low | Finding a tamper in IB = Yesq PxO ” ppFinding a tamper in IB = Yes | Authentication Capability = Lowq\nAll three marginals of Authentication Capability are considered using just two functions POx and 1 ´ POx. In (23), PO is a modelling choice that combines the states of Medium and High into one state (1´POx). Term 1´POx accounts for situations in which an inspector is relatively good at authentication, with POx representing situations in which they are less capable. Other modelling choices would lead to a marginally small difference in s.\nOur tool can compute an explicit function of s in variable x, as defined in (22). This symbolic expression for s is depicted in Figure 16 and shown as a function of x in Figure 17. This confirms that as the value of x increases, and thus the probability of “IB tamper only” seen in Figure 15 decreases, the marginal of interest for Will tamper be found? = Yes becomes less sensitive to changes in the probabilities of the node Authentication Capability of IB.\nWe can now determine the worst-case sensitivity value by computing the interval returned by function call Sup‹pts, 0.00000001, BC4X4q as r3.5838265468, 3.5838265475s where ts is the term in the righthand side of the equation in Figure 16 that describes s as a function of x. Thus we learn that this sensitivity cannot be larger than 3.5838265475 for all concretizations of constrained BN BC4X4 . As is evident from the graph, there are no valid values of x where the sensitivity value drops below 1.0 – the aforementioned bound at which a sensitivity score, and therefore its corresponding marginal probability, is deemed to be robust.\nThe output r1.17313380051, 1.17313380116s of Inf‹ps, 0.00000001, BC4X4q confirms this, and shows that s is always above 1.17313380051 for all concretizations of constrained BN BC4X4 . Knowing this may indicate to a decision-maker that potential deviations in the real domain from the model of node Authentication Capability will require close attention, irrespective of the value of x and thus of the perceived marginal probabilities of the states of node Cheating Method."
    }, {
      "heading" : "5 Implementation and Evaluation",
      "text" : ""
    }, {
      "heading" : "5.1 Software Engineering",
      "text" : "The numerical results reported in previous sections were computed by a prototype implementation of the approach developed in this paper. This implementation uses Python to capture a data model for Bayesian Networks and constraints, to formulate marginals of interest, and to interface with the SMT solver Z3 [23]. The latter we use as a decision procedure for logic Q that also returns witness information for all variables. The computation of symbolic meaning of marginals relies on the Junction Tree Algorithm and is achieved through software from an open-source Python package provided in [5].\nPython also supports a lightweight and open-source library for symbolic computation, sympy [34], which we can employ to run the Junction Tree Algorithm in [5] fully symbolically. The generated symbolic expressions are then simplified using a method of sympy before they are put into constraints such as in (3) and added to the SMT solver for analysis."
    }, {
      "heading" : "5.2 Validation and Evaluation",
      "text" : "Some symbolic marginals that we generated for analyses but not reported in our case study were too large to be handled by the SMT solver we used: the string representation of the symbolic meaning was about 25 Megabytes. We performed linear regression on those symbolic expressions and then validated that this approximation has higher precision than the accuracy δ, before defining the meaning of marginal variables as these regressed expressions. Our openaccess research data, discussed on page 34, contains details on these analyses.\nWe evaluated the performance of the symbolic interpretation of the JTA as implemented in\n[5] on randomly generated constrained BNs. This does not evaluate our approach per se, but the manner in which we interpreted an existing inference implementation symbolically. We refer to our open-access data repository for more details on model generation: key parameters are the number of nodes |N |, the number of variables |Xx |, and a random choice of the number of states for each node (between 1 and 10 uniformly at random). Terms in probability tables have form c, x or 1´x for constants c or x in Xx. In generated models, a random node was picked to determine hard evidence – its first state having probability 1. The JTA was run for that hard evidence, and the time to complete it was recorded. These automated test suites ran on an institutional server with 64 Intel Xeon E5/Core i7 processors, on Ubuntu 14.04.\nMany of these tests terminated very quickly. Though, as the number of nodes per graph and the number of states per node increased, the running times increased on some but not all tests. The size of Xx seemed to have a limited effect, possibly indicating that the additional overhead of our approach to running the JTA implementation of [5] symbolically in Python is not huge.\nFigure 18 shows plots for the computation times (in seconds) of 1000 such test cases against the number of nodes, the size of Xx, the number of node states in total (a summation over all nodes) and the average length over all nodes of the outputted marginal text string in characters.\nFor this randomized test suite, there was a small trend for the running times to increase with the size of the DAG. But computations were still quicker for many of the BNs of larger size compared to smaller ones. The size of Xx appears to have little impact on computation time, nor any strong correlation to the length of the computed symbolic marginal. This suggests that use of symbolic probabilities may not in and of itself increase such empirical complexity."
    }, {
      "heading" : "6 Discussion",
      "text" : "Our approach advocates the use of constrained Bayesian Networks as a means of gaining confidence into Bayesian Network modelling and inference in the face of little or no data. A modeler may thus start with a BN, turn it into several constrained BNs and subject them to analysis, and perhaps modify the BN based on such findings. Witness information computed in analyses could, in principle, be fed back into a BN modeling tool so that users can see a concrete BN that would, for example, explain how a marginal of interest can attain a certain value in a constrained BN.\nThe ability to represent witness information as a concrete BN is also a means of testing whether the computation of symbolic meaning of marginals is free of errors. We have indeed conducted such tests to gain confidence into the correctness of our tool and the packages that it depends upon. Note also that errors in the symbolic meaning of marginals are likely to create numerical inconsistencies, so our analyses would detect such an inconsistent, constrained BN.\nThe algorithms that we devised for non-linear optimization made no assumptions about the internal workings of the decision procedure used and its witness information apart from that such results would be semantically correct. Knowledge of such internal details could,\nhowever, be exploited to speed up computation. For example, such a method is used in the SMT solver Z3 to optimize linear objective functions. One could therefore run different methods in parallel or even let them share information in between search iterations.\nOur tool prototype interprets the JTA implementation provided in [5] symbolically, and symbolic meanings of marginal variables may contain divisions. Of course, we could translate away all division operators without changing meaning – to match this with the formal setting of Section 3. We did not do this since our foundations apply equally to Q extended with division, such translations would increase the size of these terms, and the SMT solver we used, Z3, was able to process and reason with such or suitably simplified terms."
    }, {
      "heading" : "7 Related Work",
      "text" : "In [21], it is shown how probabilistic inference in Bayesian Networks can be represented through the evaluation and formal differentiation of a “network polynomial”. The size of the polynomial can be reduced by its representation in an arithmetic circuit, in which evaluation and differentiation are more efficient. It would be of interest to determine whether this work can be extended to make the computation of symbolic marginals generated in our approach more efficient.\nFor Bayesian Networks there are methods for learning the structure of a DAG and for learning the probabilities within nodes of such a graph (see e.g. [29, 19]) – based on existing empirical data. We assumed in this paper that little or no data are available, ruling out the effective use of such learning methods. But our approach is consistent with settings in which plenty of data are available.\nBayesian Networks have tool support such as the software JavaBayes [2], which is able to perform robustness analysis. But this software can neither cope with the Knightian uncertainty of our approach, nor fuse networks of different structures together with non-trivial constraints.\nOur work in [8] reported early attempts of developing the approach presented in this paper: in [8], a much simpler Bayesian Network of a nuclear inspection process is presented and some analyses with preliminary versions of our tool are discussed; but that work offered neither formal foundations nor greater technical details for the methods it used. The more detailed Bayesian Network we studied in Section 4 was discussed in [7], along with a nontechnical summary of our general approach and some of its analysis findings.\nCredal networks – see e.g. [16] – refer to the theory and practice of associating a convex set of probability measures with directed, acyclic graphs. Credal networks are also referred to as the Theory of Imprecise Probabilities [39] or as the Quasi-Bayesian Theory [25].\nThe generalization of probability measures to sets of such measures can accommodate a formal notion of probabilistic independence, rooted in axioms of preferences as developed in [16]. The approach is based on constraints for such convex sets of probability measures. Inference algorithms and their approximations are bespoke for an interpretation of constraints; an interpretation is called an “extension” in [16].\nTo compare this to our approach, we follow Good’s black box model in that our semantics and optimizations reflect Bayesian inference – even though this is done symbolically. Another difference is that a constrained Bayesian Network may have nodes with non-convex sets of\nprobability measures as meaning, for example when logical constraints on variables rule out certain points in intervals. Our approach is also more practical in outlook, since we rely on reductions to known and tried techniques, such as satisfiability checking for the existential theory of the reals. In contrast, theoretical results for Credal Networks range from different evidence propagation and inference methods (see e.g. [17, 20]) to deep relationships to logic programming and its semantics [18].\nIn [11], a methodology is developed for assessing sensitivity of lower and upper probabilities in Credal networks. It is shown that for some classes of parameters in Bayesian networks one may replace the Credal sets of probability measures associated with such parameters with a sole such measure. It would be of interest to determine whether these or similar results are attainable for suitable classes of constrained Bayesian Networks.\nConstraint Networks [24] are graphical representations that are meant to guide solution strategies for constraint satisfaction problems. In our tool prototype, we decoupled the choice of graph structure for a constrained Bayesian Network from the use of strategies for solving satisfiability problems over the existential theory of the reals. It may be beneficial to couple graph structure and satisfiability checking in tool support of our approach that relies on constraint satisfaction solvers."
    }, {
      "heading" : "8 Conclusions",
      "text" : "This work was motivated by the fact that some problem domains have little or no data that one could use to learn the structure of a causal network or the probabilities for nodes within that structure – whatever the reasons for such sparsity of data may be in such a domain. This led us to consider suitable generalizations of Bayesian Networks. Ideally, we wanted a formalism that those who already use Bayesian Networks for modeling and analysis would find easy to adopt. In particular, we sought to preserve – as much as possible – the manner in which probabilistic inference is done in Bayesian Networks. Crucially, we wanted a set of methods whose use could help us to build sufficient confidence into the quality, suitability or robustness of models expressed in such a formalisms in the face of little or no empirical data.\nWe propose constrained Bayesian Networks as such a formalism. The derivation of that concept is a contribution in and of itself, and it used first-order logic and its semantics as well as syntactic criteria for wellformedness. But it also required methods from three-valued logic to define a precise yet intuitive semantics for a constrained BN.\nWe also developed meta-properties of this semantics, including checks for the consistency of a constrained Bayesian Network. These properties were needed to prove the correctness of our optimization algorithms, which can compute suprema or infima of bounded arithmetic terms up to a specific accuracy. These optimization algorithms are non-standard in that they rely on a decision procedure for the theory of reals and in that the optimization problems are generally non-linear and non-convex.\nThe marginals in a constrained Bayesian Network are computed symbolically, but computed in the same manner as the marginals for a Bayesian Network – a concretization of that constrained Bayesian Network. This is appealing as it allows reuse of known and trusted methods such as the Junction Tree Algorithm. But it also creates a potential computational bottleneck with scope for future work that may extend an approach in [21] to our setting.\nWe implemented our approach in a tool prototype, which benefitted from the significant advances in symbolic computation and in the implementation of theorem provers such as SMT solvers. We evaluated this prototype through stress tests and a non-trivial case study in the domain of nuclear arms control. The latter is a domain in which the availability of data is very limited and where any means of building confidence into the trustworthiness of mathematical models are expected to have positive impact on arms reduction efforts.\nWe used this case study to illustrate some pertinent types of analyses of a constrained Bayesian Network that our approach can accommodate: a range analysis that computes infima and suprema for a term of interest to determine their robustness, the comparison of two or more constrained Bayesian Networks to assess modeling impact, the ability to determine ranges of threshold values that would render equivalent decision support, and the symbolic computation of a sensitivity measure for a given node – with the ability to optimize this to understand worst-case sensitivities. We trust that the approach presented in this paper will be useful for other applications in the arms-control domain, as well as in other domains – particularly those with a lack of data.\nAcknowledgements: This work was supported by AWE plc, and in part by the UK Engineering and Physical Sciences Research Council grants EP/N020030/1 and EP/N023242/1.\nOpen Access: The Python and SMT code for the queries and models of this paper and raw SMT analysis results are found in the public data repository\nbitbucket.org/pjbeaumont/beaumonthuthcbns/"
    }, {
      "heading" : "A Mathematical Proofs",
      "text" : "Proof of Theorem 1:\n1. We have that BCX |ùmustφ holds iff for all concretizations BCXrαs of BCX we have that α |ù φ holds iff for all concretizations BCXrαs of BCX we have that α |ù φ does not hold iff BCX |ùmay φ does not hold.\n2. We have that BCX |ùmayφ holds iff there is some concretization BCXrαs of BCX such that α |ù φ holds iff there is some concretization BCXrαs of BCX such that α |ù φ does not hold iff BCX |ùmust φ does not hold.\n3. (a) Let BCX |ùmustφ1 ^ φ2 hold. Let BCXrαs be a concretization of BCX . Then we know that α |ù φ1^φ2 holds. This implies that α |ù φi holds for i “ 1, 2. But then both BCX |ùmustφ1 and BCX |ùmustφ2 hold since BCXrαs was an arbitrary concretization of BCX .\n(b) Let both BCX |ùmustφ1 and BCX |ùmustφ2 hold. Let BCXrαs be a concretization of BCX . Then BCX |ùmustφi implies that α |ù φi holds for i “ 1, 2. Therefore, we get that α |ù φ1 ^ φ2 holds as well. Since BCXrαs was an arbitrary concretization of BCX , this gives us that BCX |ùmustφ1 ^ φ2 holds.\n4. (a) Let BCX |ùmayφ1 _ φ2 hold. Then there is some concretization BCXrαs of BCX such that α |ù φ1 _ φ2 holds. This implies that α |ù φi holds for some i “ 1, 2. But then BCX |ùmayφi holds as claimed.\n(b) Let one of BCX |ùmayφ1 and BCX |ùmayφ2 hold, say BCX |ùmayφi. Then there is some concretization BCXrαs of BCX such that α |ù φi holds. This implies that α |ù φ1_φ2 holds as well. Since BCXrαs is a concretization of BCX , we get that BCX |ùmayφ1 _ φ2 holds.\nProof of Theorem 2:\n• Item 1 implies item 2: Let BCX |ùmaytrue hold. By definition of |ùmay, there then is some concretization BCXrαs of BCX such that α |ù true holds. Therefore the set of concretizations of BCX is non-empty and so B C X is consistent.\n• Item 2 implies item 3: Let BCX be consistent. Suppose that φ is in Q such that BCX |ùmustφ holds. Since BCX is consistent, there is some concretization BCXrαs of BCX . Since BCX |ùmustφ holds, we get that α |ù φ holds. But then we have BCX |ùmayφ be definition of |ùmay.\n• Item 3 implies item 4: Let BCX |ùmustφ imply BCX |ùmayφ for all φ in Q. Let ψ be in Q. We claim that BCX |ùmayψ _ ψ holds. By Theorem 1.4, it suffices to show that BCX |ùmayψ or BCX |ùmay ψ holds. If the former holds, we are done. Otherwise, we have that BCX |ùmayψ does not hold. By Theorem 1.2, this implies that BCX |ùmust ψ holds.\n– Next, we show that BCX has to be consistent: note that B C X |ùmusttrue holds by\nthe definitions of |ùmust and |ù. Therefore, we get that BCX |ùmaytrue holds by item 3 – and we already showed that this implies that BCX is consistent.\nLet BCXrαs be a concretization of BCX , which exists as BCX is consistent. Since we showed BCX |ùmust φ, the latter implies that α |ù φ. But then BCX |ùmay φ follows given the definition of |ùmay.\n• Item 4 implies item 5: Let BCX |ùmayφ_ φ hold for all φ in Q. Let ψ be in Q. Then we have that BCX |ùmayψ _ ψ holds, and we need to show that BCX |ùmustψ ^ ψ does not hold. Proof by contradiction: assume that BCX |ùmustψ^ ψ holds. Since BCX |ùmayψ_ ψ holds, we know that there is some concretization BCXrαs of BCX such that α |ù ψ _ ψ holds. Since BCX |ùmustψ^ ψ holds, we know that BCX |ùmustψ and BCX |ùmust ψ hold by Theorem 1.3. We do a case analysis on the truth of judgment α |ù ψ _ ψ:\n– Let α |ù ψ hold . Since BCX |ùmust ψ holds, this implies that α |ù ψ holds. This contradicts that α |ù ψ holds.\n– Let α |ù ψ hold. Since BCX |ùmustψ holds, this implies that α |ù ψ holds. This contradicts that α |ù ψ holds.\n• Item 5 implies item 1: Let BCX |ùmustφ ^ φ not hold, for all φ in Q. Since true is in Q, we know that BCX |ùmusttrue ^ true does not hold. By definition of |ùmust and |ù, we have that BCX |ùmusttrue holds. By Theorem 1.3 and since BCX |ùmusttrue^ true does not hold, we infer that BCX |ùmust true does not hold. By Theorem 1.2, this implies that BCX |ùmaytrue holds as claimed.\nProof of Theorem 3:\n1. Constraints ϕ1 in C and ϕ are quantifier-free formulas of Q with variables contained in X, which equals tx1, x2, . . . , xnu. Therefore, the formula in (8) is in Q, and contains only existential quantifiers and all in front of the formula.\n2. We prove this claim by structural induction over ϕ:\n• Let ϕ be true. Then ExpBCX , trueq equals Dx1 : . . . : Dxn : true ^ Ź ϕ1PC ϕ 1 and this\nis satisfiable iff there is an assignment α such that α |ù Ź ϕ1PC ϕ 1 and α |ù true both hold (the latter holding by definition) iff there is a concretization BCXrαs of BCX iff B C X is consistent iff (by Theorem 2) B C X |ùmaytrue holds.\n• Let ϕ be t1 ď t2. Then ExpBCX , t1 ď t2q equals Dx1 : . . . : Dxn : pt1 ď t2q ^ Ź ϕ1PC ϕ 1\nand this is satisfiable iff there is an assignment α such that α |ù Ź ϕ1PC ϕ 1 and α |ù\nt1 ď t2 both hold iff there is a concretization BCXrαs of BCX such that α |ù t1 ď t2 holds iff BCX |ùmayt1 ď t2 holds. • Let ϕ be t1 ă t2. Then ExpBCX , t1 ă t2q equals Dx1 : . . . : Dxn : pt1 ă t2q ^ Ź ϕ1PC ϕ 1\nand this is satisfiable iff there is an assignment α such that α |ù Ź ϕ1PC ϕ 1 and α |ù\nt1 ă t2 both hold iff there is a concretization BCXrαs of BCX such that α |ù t1 ă t2 holds iff BCX |ùmayt1 ă t2 holds. • Let ϕ be ψ. Then ExpBCX , ψq equals Dx1 : . . . : Dxn : ψ ^ Ź ϕ1PC ϕ 1 and this\nis satisfiable iff there is an assignment α such that α |ù Ź ϕ1PC ϕ 1 and α |ù ψ\nboth hold iff there is a concretization BCXrαs of BCX such that α |ù ψ holds iff BCX |ùmay ψ holds. • Let ϕ be ϕ1^ϕ2. Then ExpBCX , ϕ1 ^ ϕ2q equals Dx1 : . . . : Dxn : ϕ1^ϕ2^ Ź ϕ1PC ϕ 1\nand this is satisfiable iff there is an assignment α such that α |ù Ź ϕ1PC ϕ 1 and α |ù ϕ1^ϕ2 both hold iff there is a concretization BCXrαs of BCX such that α |ù ϕ1^ϕ2 holds iff BCX |ùmayϕ1 ^ ϕ2 holds.\n3. By the previous item, we may decide BCX |ùmayϕ by deciding whether formula ExpBCX , ϕq is satisfiable. By item 1 above, that formula is in the existential fragment of Q. By [14], deciding the satisfiability (truth) of such formulas is in PSPACE in the size of such formulas.\n4. By Theorem 1.1, we have that BCX |ùmustϕ holds iff BCX |ùmay ϕ does not hold. By item 2 above, the latter is equivalent to ExpBCX , ϕq not being satisfiable. By [14], this can be decided in PSPACE in the size of formula ExpBCX , ϕq.\nProof of Theorem 4: The arguments below make use of Theorems 1 and 3 without explicit reference to them. Note that consistency of BCX and 0 ă sup t| t |u guarantee that the first let statement in Sup can find such a α. In particular, we see that 0 ă cache becomes an invariant and so cache ă 2 ˚ cache is another invariant.\n1. First, we show that the asserts hold prior to the execution of the second while loop. Note that cache is always assigned reals of form ηptq for some concretization BCXrηs of BCX . So when low is initialized with the last updated value of cache, then B C X |ùmayt ď\nlow clearly holds after the first assignment to low (witnessed by the assignment that gave rise to the last value of cache) and prior to its reassignment. By definition of the initial value of high, we have that BCX |ùmayt ě high does not hold after that initial assignment and prior to the reassignment of high. Therefore, both asserts in front of the second while loop hold, and we get that low ď high is an invariant. Second, we show that each iteration of the second while loop preserves the asserts. This is clear as the Boolean guard of the if statement tests for preservation of these asserts, and makes the correct, invariant-preserving assignment accordingly.\nThird, let rl, hs be the returned closed interval. It is clear that h ´ l ď δ holds as required. We argue that sup t| t |u is in rl, hs. Since the asserts hold for l and h, we know that BCX |ùmayt ě l holds, but BCX |ùmayt ě h does not hold. Let c be in t| t |u. Then there is some α with c “ αptq. Since BCX |ùmayt ě h does not hold, we get that αptq ă αphq “ h. Therefore, h is an upper bound of t| t |u which implies sup t| t |u ď h. Since BCX |ùmayt ě l holds, we have some concretization BCXrα1s with α1 |ù t ě l. This means α1ptq ě l. But sup t| t |u ě α1ptq as the latter is an element of t| t |u. Thus, l ď sup t| t |u follows.\n2. Let s be sup t| t |u. For the first while loop, we have at least k iterations if s ě 2k ¨ c, i.e. if s ¨ c´1 ě k, i.e. if k ď log2psq ´ log2pcq. So the real number log2psq ´ log2pcq is an upper bound on the number of iterations of the first while loop.\nTo get an upper bound for the number of iterations of the second while loop, we know that high is of form 2l`1 ¨ c and so low equals 2l ¨ c. But then high´ low equals 2l ¨ c. Since this is monotone in l, we may use the upper bound for the number of iterations of the first while loop as an upper bound of l, to get 2log2psq´log2pcq ¨ c “ s ¨ c´1 ¨ c “ s as an upper bound on the value of | high´ low | before the Boolean guard of the second while is first evaluated. This allows us to derive an upper bound on the number of iterations of the second while loop, since the larger that value is, the more iterations take place. Based on the bisection in each iteration, there are at least k iterations if s ¨ 2´k ą δ, i.e. if k ă log2psq ´ log2pδq. Therefore, the total number of iterations of both while loops combined is plog2psq ´ log2pcqq ` plog2psq ´ log2pδqq. The claim now follows given that each iteration makes exactly one satisfiability check and since there is an initial satisfiability check as well.\nProof of Theorem 5:\n1. The argument is similar to the one for Theorem 4 but there are important differences. Note that cache ą 0 is also here an invariant, guaranteed by the fact that t| t |u contains a positive real. We know that p0.5n ˚ cacheqnPN converges to 0 for any positive constant cache. Since 0 ă δ and since α1ptq ď 0.5 ˚ cache for the α1ptq assigned to cache, there is some n0 such that 0.5\nn0 ˚ cache ď δ. This proves that the first while statement terminates.\n(a) Suppose that the return statement in the line after the first while loop is executed. Then ExpBCX , t ď 0.5 ˚ cacheq is satisfiable and so there is some concretization BCXrαs such that αptq ď 0.5 ˚ cache. But then inf t| t |u ď 0.5 ˚ cache as well. From t| t |u Ď R`0 , we get 0 ď inf t| t |u. Therefore, inf t| t |u is in the returned interval r0, 0.5 ˚ caches and BCX |ùmayt ď 0.5 ˚ cache is true. Moreover, the length of the interval is 0.5 ˚ cache, which must be less than or equal to δ as the first while loop just terminated and the first conjunct of its Boolean guard is true – forcing 0.5 ˚ cache ą δ to be false.\n(b) Otherwise, ExpBCX , t ď 0.5 ˚ cacheq is not satisfiable but the formula ExpBCX , t ď cacheq is satisfiable. From that, it should then be clear that the asserts in front of the second while statement hold when they are reached. That each iteration of the second while statement maintains these two asserts is reasoned similarly as for Sup.\nSo we have that BCX |ùmayt ď h and BCX |ùmustt ą l are invariants. This means that l is a lower bound of t| t |u and αptq ď h for some αptq in t| t |u. But then l ď inf t| t |u ď αptq ď h shows that inf t| t |u is in rl, hs.\n2. Let i be inf t| t |u. We derive an upper bound on the number of iterations for the first while loop. Because we are interested in upper bounds, we may assume that the α1ptq assigned to cache equals 0.5 ¨cache for the current value of cache. We then have at least k iterations if δ ă c ¨ 2´k and i ď c ¨ 2´k. Since we are interested in upper bounds on that number of iterations, we get at least k iterations if both δ ď c ¨ 2´k and i ď c ¨ 2´k hold, i.e. if minpδ, iq ď c ¨ 2´k. But this is equivalent to k ď log2pcq ´ log2pminpi, δqq. We now derive an upper bound on the number of iterations of the second while loop. The initial value of high´low equals cache´0.5¨cache “ 0.5¨cache for the current value of cache when entering that loop. The value of cache is monotonically decreasing during program execution and so c{2 is an upper bound of high´ low. We may therefore use c{2 as initial value of high´ low since this can only increase the number of iterations, for which we seek an upper bound. There are now at least k iterations if pc{2q ¨2´k ą δ which is equivalent to k ă log2pcq ´ 1´ log2pδq. The total number of iterations for both while loops is therefore plog2pcq´log2pminpi, δqqq` plog2pcq ´ 1 ´ log2pδqq “ 2 ¨ log2pcq ´ log2pminpi, δqq ´ 1. From this the claim follows since each iteration has exactly one satisfiability check of the stated form, and there is one more satisfiability check between the first and second while loop.\nProof of Theorem 6:\n1. We do a case analysis:\n(a) If algorithm Sup is called, then consistency of BCX and 0 ă sup t| t |u follow from the Boolean guard that triggered the call. Since sup t| t |u ă 8 is assumed, we get 0 ă sup t| t |u ă 8 and so Sup terminates by Theorem 4.\n(b) If 0 is returned as a maximum, the algorithm clearly terminates and no preconditions are needed.\n(c) If Inf is called, we have to show that t| ´t |u is a subset of R`0 that contains a positive real. Since the first two return statements were not reached, we know that BCX is consistent and t| t |u is a subset of R´. But then t| ´t |u is a subset of R`.\n2. If the algorithm reports that 0 is the maximum for t, then we know that t| t |u cannot contain a positive real (first if-statement), and that it contains 0 (second if-statement). Clearly, this means that 0 is the supremum of t| t |u and so also its maximum as 0 is in t| t |u.\n3. Let Sup‹pt, δ, BCXq return an interval r´h,´ls. Then rl, hs is the interval returned by a call to Infp´t, δ, BCXq. By the first item and Theorem 5, we get that BCX |ùmay ´ t ď h holds, inf t| ´t |u is in rl, hs, and h´l ď δ . Therefore, we conclude that BCX |ùmayt ě ´h holds as claimed. Moreover, since inf t| ´t |u equals ´ sup t| t |u, this implies that sup t| t |u is in the closed interval r´h,´ls, whose length is that of rl, hs and so ď δ.\n4. If the algorithm returns saying thatBCX is inconsistent, then all three formulas ExpBCX , t ą 0q, ExpBCX , t “ 0q, and ExpBCX , t ă 0q are unsatisfiable. But then we know that the three judgments BCX |ùmayt ą 0, BCX |ùmayt “ 0, and BCX |ùmayt ă 0 do not hold, by Theorem 3. This means that BCX is inconsistent: for all concretization B C Xrαs we have that\nα |ù pt ą 0q _ pt “ 0q _ pt ă 0q holds as that query is a tautology over the theory of reals; and then Theorem 3.4 yields a contradiction to BCX being consistent.\nProof of Theorem 7: The correctness of the first two claims in that theorem (inconsistency and minimum) for ´8 ă inf t| t |u follows from the corresponding items of Theorem 6. The general identity inftxi | i P Iu “ ´ supt´xi | i P Iu shows that ´8 ă inftxi | i P Iu iff ´ supt´xi | i P Iu ă 8 and so preconditions are also met. Finally, to see the correctness of Inf‹ when interval rl, hs is returned, note that this means that interval r´h,´ls is returned for the call Sup‹p´t, δ, BCXq and so BCX |ùmay ´ t ě ´h holds by Theorem 6. But this implies that BCX |ùmayt ď h holds as claimed."
    }, {
      "heading" : "B Quantitative Information about the BN of Figure 11",
      "text" : "Table 1 shows quantitative information about the size and complexity of the BN in Figure 11."
    } ],
    "references" : [ {
      "title" : "Bayesian Reasoning and Machine Learning",
      "author" : [ "David Barber" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2012
    }, {
      "title" : "An in-depth case study: modelling an information barrier in Bayesian belief networks",
      "author" : [ "Paul Beaumont", "Edward Day", "Neil Evans", "Sam Haworth", "Michael Huth", "Tom Plant", "Catherine Roberts" ],
      "venue" : "In Journal of the Institute of Nuclear Materials Management,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2016
    }, {
      "title" : "Confidence analysis for nuclear arms control: SMT abstractions of Bayesian Belief Networks",
      "author" : [ "Paul Beaumont", "Neil Evans", "Michael Huth", "Tom Plant" ],
      "venue" : "In Computer Security - ESORICS 2015 - 20th European Symposium on Research in Computer Security, Vienna,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2015
    }, {
      "title" : "Bayesian Robustness, pages 1–32",
      "author" : [ "James O. Berger", "David Ŕıos Insua", "Fabrizio Ruggeri" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2000
    }, {
      "title" : "Exploiting Bayesian Network Sensitivity Functions for Inference in Credal Networks",
      "author" : [ "Janneke H. Bolt", "Jasper De Bock", "Silja Renooij" ],
      "venue" : "In ECAI 2016 - 22nd European Conference on Artificial Intelligence,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2016
    }, {
      "title" : "Decision-theoretic troubleshooting: A framework for repair and experiment",
      "author" : [ "John S. Breese", "David Heckerman" ],
      "venue" : "Proceedings of the Twelfth Annual Conference on Uncertainty in Artificial Intelligence, Reed College,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1996
    }, {
      "title" : "Model checking partial state spaces with 3-valued temporal logics",
      "author" : [ "Glenn Bruns", "Patrice Godefroid" ],
      "venue" : "In Computer Aided Verification, 11th International Conference,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1999
    }, {
      "title" : "The complexity of Robot Motion Planning",
      "author" : [ "J.F. Canny" ],
      "venue" : "PhD thesis, MIT,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1988
    }, {
      "title" : "Abstract interpretation: past, present and future",
      "author" : [ "Patrick Cousot", "Radhia Cousot" ],
      "venue" : "In Joint Meeting of the Twenty-Third EACSL Annual Conference on Computer Science Logic (CSL) and the Twenty-Ninth Annual ACM/IEEE Symposium on Logic in Computer Science (LICS), CSL-LICS ’14,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2014
    }, {
      "title" : "Inference with Separately Specified Sets of Probabilities in Credal Networks",
      "author" : [ "Fabio Gagliardi Cozman", "Jose C.F. da Rocha" ],
      "venue" : "Proceedings of the Eighteenth conference on Uncertainty in artificial intelligence,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2002
    }, {
      "title" : "The Structure and Complexity of Credal Semantics",
      "author" : [ "Fábio Gagliardi Cozman", "Denis Deratani Mauá" ],
      "venue" : "In Proc. of the Third International Workshop on Probabilistic Logic Programming,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2016
    }, {
      "title" : "Polyhedral aspects of score equivalence in Bayesian network structure learning",
      "author" : [ "James Cussens", "David Haws", "Milan Studeny" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2015
    }, {
      "title" : "Evidence Propagation in Credal Networks: An Exact Algorithm Based on Separately Specified Sets of Probability",
      "author" : [ "José Carlos Ferreira da Rocha", "Fábio Gagliardi Cozman" ],
      "venue" : "In Advances in Artificial Intelligence, 16th Brazilian Symposium on Artificial Intelligence,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2002
    }, {
      "title" : "A differential approach to inference in Bayesian networks",
      "author" : [ "Adnan Darwiche" ],
      "venue" : "J. ACM,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2003
    }, {
      "title" : "The inferential complexity of Bayesian and credal networks",
      "author" : [ "Cassio Polpo de Campos", "Fábio Gagliardi Cozman" ],
      "venue" : "Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2005
    }, {
      "title" : "An Efficient SMT Solver",
      "author" : [ "Leonardo De Moura", "Nikolaj Bjørner. Z" ],
      "venue" : "In Proceedings of the Theory and Practice of Software, 14th International Conference on Tools and Algorithms for the Construction and Analysis of Systems,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2008
    }, {
      "title" : "Quasi-Bayesian behaviour: A more realistic approach to decision making",
      "author" : [ "F.J. Giron", "S. Rios" ],
      "venue" : "Trabajos de Estadistica Y de Investigacion Operativa,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1980
    }, {
      "title" : "Could a machine make probability judgments",
      "author" : [ "Irving John Good" ],
      "venue" : "Computation and Automation,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1959
    }, {
      "title" : "Degrees of Belief",
      "author" : [ "Irving John Good" ],
      "venue" : "In Encyclopedia of Statistical Sciences,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1982
    }, {
      "title" : "Bayesian methods for elucidating genetic regulatory networks",
      "author" : [ "Alexander J. Hartemink", "David K. Gifford", "Tommi S. Jaakkola", "Richard A. Young" ],
      "venue" : "IEEE Intelligent Systems,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2002
    }, {
      "title" : "A Tutorial on Learning With Bayesian Networks",
      "author" : [ "David Heckerman" ],
      "venue" : "Technical Report MSR-TR-95-06,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1995
    }, {
      "title" : "Experimental design of time series data for learning from dynamic Bayesian networks",
      "author" : [ "C. David Page Jr.", "Irene M. Ong" ],
      "venue" : "In Biocomputing",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2006
    }, {
      "title" : "Sensitivity analysis of Bayesian networks used in forensic investigations",
      "author" : [ "Michael Y.K. Kwan", "Richard E. Overill", "Kam-Pui Chow", "Hayson Tse", "Frank Y.W. Law", "Pierre K.Y. Lai" ],
      "venue" : "In Advances in Digital Forensics VII - 7th IFIP WG 11.9 International Conference on Digital Forensics,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2011
    }, {
      "title" : "Sensitivity analysis for probability assessments in Bayesian networks",
      "author" : [ "Kathryn Blackmond Laskey" ],
      "venue" : "IEEE Trans. Systems, Man, and Cybernetics,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 1995
    }, {
      "title" : "Probabilistic inference in credal networks: New complexity results",
      "author" : [ "Denis Deratani Mauá", "Cassio Polpo De Campos", "Alessio Benavoli", "Alessandro Antonucci" ],
      "venue" : "J. Artif. Int. Res.,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2014
    }, {
      "title" : "Sympy: Symbolic computing in python",
      "author" : [ "Aaron Meurer", "Christopher P. Smith", "Mateusz Paprocki", "Ondrej Cert́ık", "Matthew Rocklin", "Amit Kumar", "Sergiu Ivanov", "Jason K. Moore", "Sartaj Singh", "Thilina Rathnayake", "Sean Vig", "Brian E. Granger", "Richard P. Muller", "Francesco Bonazzi", "Harsh Gupta", "Shivam Vats", "Fredrik Johansson", "Fabian Pedregosa", "Matthew J. Curry", "Ashutosh Saboo", "Isuru Fernando", "Sumith Kulal", "Robert Cimrman", "Anthony M. Scopatz" ],
      "venue" : "PeerJ PrePrints,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2016
    }, {
      "title" : "Probabilistic Reasoning in Expert Systems: Theory and Algorithms",
      "author" : [ "Richard E. Neapolitan" ],
      "venue" : null,
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 1990
    }, {
      "title" : "Bayesian networks: A model of self-activated memory for evidential reasoning",
      "author" : [ "J. Pearl" ],
      "venue" : "Technical Report CSD-850021,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 1985
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
      "author" : [ "Judea Pearl" ],
      "venue" : null,
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 1988
    }, {
      "title" : "Reasoning about evidence using Bayesian networks. In Advances in Digital Forensics VIII - 8th IFIP WG",
      "author" : [ "Hayson Tse", "Kam-Pui Chow", "Michael Y.K. Kwan" ],
      "venue" : "International Conference on Digital Forensics,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 27,
      "context" : "Bayesian Networks (BN) [36, 37, 35] are a prominent, well established, and widely used formalism for expressing discrete probability distributions in terms of directed, acyclic graphs (DAG) that encode conditional independence assumptions of distributions.",
      "startOffset" : 23,
      "endOffset" : 35
    }, {
      "referenceID" : 28,
      "context" : "Bayesian Networks (BN) [36, 37, 35] are a prominent, well established, and widely used formalism for expressing discrete probability distributions in terms of directed, acyclic graphs (DAG) that encode conditional independence assumptions of distributions.",
      "startOffset" : 23,
      "endOffset" : 35
    }, {
      "referenceID" : 26,
      "context" : "Bayesian Networks (BN) [36, 37, 35] are a prominent, well established, and widely used formalism for expressing discrete probability distributions in terms of directed, acyclic graphs (DAG) that encode conditional independence assumptions of distributions.",
      "startOffset" : 23,
      "endOffset" : 35
    }, {
      "referenceID" : 5,
      "context" : "Bayesian Networks have a wide range of applications – for example, trouble shooting [12], design of experiments [30, 28], and digital forensics to support legal reasoning [38].",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 21,
      "context" : "Bayesian Networks have a wide range of applications – for example, trouble shooting [12], design of experiments [30, 28], and digital forensics to support legal reasoning [38].",
      "startOffset" : 112,
      "endOffset" : 120
    }, {
      "referenceID" : 19,
      "context" : "Bayesian Networks have a wide range of applications – for example, trouble shooting [12], design of experiments [30, 28], and digital forensics to support legal reasoning [38].",
      "startOffset" : 112,
      "endOffset" : 120
    }, {
      "referenceID" : 29,
      "context" : "Bayesian Networks have a wide range of applications – for example, trouble shooting [12], design of experiments [30, 28], and digital forensics to support legal reasoning [38].",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 20,
      "context" : "pre-existing data (see for example [29, 19]).",
      "startOffset" : 35,
      "endOffset" : 43
    }, {
      "referenceID" : 11,
      "context" : "pre-existing data (see for example [29, 19]).",
      "startOffset" : 35,
      "endOffset" : 43
    }, {
      "referenceID" : 3,
      "context" : "This naturally leads to the consideration of robust Bayesian statistics [9, 10].",
      "startOffset" : 72,
      "endOffset" : 79
    }, {
      "referenceID" : 17,
      "context" : "A good conceptual explanation of this is Good’s black box model [26, 27], in which interval information of priors is submitted into a black box that contains all the usual methods associated with precise computations in Bayesian Networks, and where the box then outputs intervals of posteriors without limiting any interpretations or judgments on those output intervals.",
      "startOffset" : 64,
      "endOffset" : 72
    }, {
      "referenceID" : 18,
      "context" : "A good conceptual explanation of this is Good’s black box model [26, 27], in which interval information of priors is submitted into a black box that contains all the usual methods associated with precise computations in Bayesian Networks, and where the box then outputs intervals of posteriors without limiting any interpretations or judgments on those output intervals.",
      "startOffset" : 64,
      "endOffset" : 72
    }, {
      "referenceID" : 25,
      "context" : "This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 15,
      "context" : "This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 2,
      "context" : "This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15].",
      "startOffset" : 181,
      "endOffset" : 184
    }, {
      "referenceID" : 6,
      "context" : "This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15].",
      "startOffset" : 215,
      "endOffset" : 219
    }, {
      "referenceID" : 8,
      "context" : "This development is informed by advances made in areas of Symbolic Computation [34] and Automated Theorem Proving [23] (with its applications to Non-Linear, Non-Convex Optimization [8]), Three-Valued Model Checking [13], and Abstract Interpretation [15].",
      "startOffset" : 249,
      "endOffset" : 253
    }, {
      "referenceID" : 14,
      "context" : "We draw comparisons to related work, including Credal Networks [16, 22, 33] and Constraint Networks [24].",
      "startOffset" : 63,
      "endOffset" : 75
    }, {
      "referenceID" : 24,
      "context" : "We draw comparisons to related work, including Credal Networks [16, 22, 33] and Constraint Networks [24].",
      "startOffset" : 63,
      "endOffset" : 75
    }, {
      "referenceID" : 0,
      "context" : "Chapter 6 in [6] for further details) may be used to revise a marginal of a BN because of “hard”, respectively “soft”, evidence – the definite, respectively probabilistic, observation of an additional or new event.",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 1,
      "context" : "Figure 11: A BN [7] which details aspects of an arms inspection process.",
      "startOffset" : 16,
      "endOffset" : 19
    }, {
      "referenceID" : 23,
      "context" : ", the sensitivity value defined in [32, 31].",
      "startOffset" : 35,
      "endOffset" : 43
    }, {
      "referenceID" : 22,
      "context" : ", the sensitivity value defined in [32, 31].",
      "startOffset" : 35,
      "endOffset" : 43
    }, {
      "referenceID" : 23,
      "context" : "The sensitivity value [32, 31] is defined in this instance as",
      "startOffset" : 22,
      "endOffset" : 30
    }, {
      "referenceID" : 22,
      "context" : "The sensitivity value [32, 31] is defined in this instance as",
      "startOffset" : 22,
      "endOffset" : 30
    }, {
      "referenceID" : 15,
      "context" : "This implementation uses Python to capture a data model for Bayesian Networks and constraints, to formulate marginals of interest, and to interface with the SMT solver Z3 [23].",
      "startOffset" : 171,
      "endOffset" : 175
    }, {
      "referenceID" : 25,
      "context" : "Python also supports a lightweight and open-source library for symbolic computation, sympy [34], which we can employ to run the Junction Tree Algorithm in [5] fully symbolically.",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 13,
      "context" : "In [21], it is shown how probabilistic inference in Bayesian Networks can be represented through the evaluation and formal differentiation of a “network polynomial”.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 20,
      "context" : "[29, 19]) – based on existing empirical data.",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 11,
      "context" : "[29, 19]) – based on existing empirical data.",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 2,
      "context" : "Our work in [8] reported early attempts of developing the approach presented in this paper: in [8], a much simpler Bayesian Network of a nuclear inspection process is presented and some analyses with preliminary versions of our tool are discussed; but that work offered neither formal foundations nor greater technical details for the methods it used.",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 2,
      "context" : "Our work in [8] reported early attempts of developing the approach presented in this paper: in [8], a much simpler Bayesian Network of a nuclear inspection process is presented and some analyses with preliminary versions of our tool are discussed; but that work offered neither formal foundations nor greater technical details for the methods it used.",
      "startOffset" : 95,
      "endOffset" : 98
    }, {
      "referenceID" : 1,
      "context" : "The more detailed Bayesian Network we studied in Section 4 was discussed in [7], along with a nontechnical summary of our general approach and some of its analysis findings.",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 16,
      "context" : "Credal networks are also referred to as the Theory of Imprecise Probabilities [39] or as the Quasi-Bayesian Theory [25].",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 9,
      "context" : "[17, 20]) to deep relationships to logic programming and its semantics [18].",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 12,
      "context" : "[17, 20]) to deep relationships to logic programming and its semantics [18].",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 10,
      "context" : "[17, 20]) to deep relationships to logic programming and its semantics [18].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 4,
      "context" : "In [11], a methodology is developed for assessing sensitivity of lower and upper probabilities in Credal networks.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 13,
      "context" : "But it also creates a potential computational bottleneck with scope for future work that may extend an approach in [21] to our setting.",
      "startOffset" : 115,
      "endOffset" : 119
    } ],
    "year" : 2017,
    "abstractText" : "We develop the theory and practice of an approach to modeling and probabilistic inference in causal networks that is suitable when application-specific or analysis-specific constraints should inform such inference or when little or no data for the learning of causal network structure or probability values at nodes are available. Constrained Bayesian Networks generalize a Bayesian Network such that probabilities can be symbolic, arithmetic expressions and where the meaning of the network is constrained by finitely many formulas from the theory of the reals. A formal semantics for constrained Bayesian Networks over first-order logic of the reals is given, which enables non-linear and non-convex optimization algorithms that rely on decision procedures for this logic, and supports the composition of several constrained Bayesian Networks. A non-trivial case study in arms control, where few or no data are available to assess the effectiveness of an arms inspection process, evaluates our approach. An open-access prototype implementation of these foundations and their algorithms uses the SMT solver Z3 as decision procedure, leverages an open-source package for Bayesian inference to symbolic computation, and is evaluated experimentally.",
    "creator" : "LaTeX with hyperref package"
  }
}