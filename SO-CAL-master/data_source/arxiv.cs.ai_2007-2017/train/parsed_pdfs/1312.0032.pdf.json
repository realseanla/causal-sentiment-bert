{
  "name" : "1312.0032.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Thomas Lukasiewicz", "Maria Vanina Martinez", "Cristian Molinaro", "Livia Predoiu", "Gerardo I. Simari", "G.I. Simari" ],
    "emails" : [ "gerardo.simari}@cs.ox.ac.uk", "cmolinaro@dimes.unical.it" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The use of preferences in query answering, both in traditional databases and in ontologybased data access, has recently received much attention due to its many real-world applications. In particular, in recent times, there has been a huge change in the way data is created and consumed, and users have largely moved to the Social Web, a system of platforms used to socially interact by sharing data and collaborating on tasks.\nIn this paper, we tackle the problem of preference-based query answering in Datalog+/– ontologies assuming that the user must rely on subjective reports to get a complete picture and make a decision. This kind of situation arises all the time on the Web; for instance, when searching for a hotel, users provide some basic information and receive a list of answers to choose from, each associated with a set of subjective reports (often called reviews) written by other users to tell everyone about their experience. The main problem with this setup, however, is that users are often overwhelmed and frustrated, because they cannot decide which reviews to focus on and which ones to ignore, since it is likely that, for instance, a very negative (or positive) review may have been produced on the basis of a feature that is completely irrelevant to the querying user. ar X\niv :1\n31 2.\n00 32\nv1 [\ncs .A\nI] 2\n9 N\nov 2\n01 3\nWe study a formalization of this process and its incorporation into preference-based query answering in Datalog+/– ontologies, proposing the use of trust and relevance measures to select the best reports to focus on, given the user’s initial preferences, as well as novel ranking algorithms to obtain a user-tailored answer. The main contributions of this paper can be briefly summarized as follows.\n– We present an approach to preference-based top-k query answering in Datalog+/– ontologies, given a collection of subjective reports. Here, each report contains scores for a list of features, its author’s preferences among the features, as well as additional information. Theses pieces of information of every report are then aggregated, along with the querying user’s trust into each report, to a ranking of the query results relative to the preferences of the querying user. – We present a basic approach to ranking the query results, where each atom is associated with the average of the scores of all reports, and every report is ranked with the average of the scores of each feature, weighted by the report’s trust values and the relevance of the feature and of the report for the querying user. – We then present an alternative approach to ranking the query results, where we first select the most relevant reports for the querying user, adjust the scores by the trust measure, and compute a single score for each atom by combining the scores computed in the previous step, weighted by the relevance of the features. – We present algorithms for preference-based top-k (atomic) query answering in Datalog+/– ontologies under both rankings. We also prove that, under suitable assumptions, the two algorithms run in polynomial time in the data complexity. – Finally, we also propose and discuss a more general form of reports, which are associated with sets of atoms rather than single atoms.\nThe rest of this paper is organized as follows. In Section 2, we provide some preliminaries on Datalog+/– and the used preference models. Section 3 then defines subjective reports, along with their trust measures and their relevance. In Section 4, we introduce the two rankings of query results, along with top-k query answering algorithms under these rankings and data tractability results. Section 5 then presents more general subjective reports. In Section 6, we discuss related work. Finally, the concluding Section 7 summarizes the main results of this paper and gives an outlook on future research."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "First, we briefly recall some basics on Datalog+/– [7], namely, on relational databases and (Boolean) conjunctive queries ((B)CQs) (along with tuple- and equality-generating dependencies (TGDs and EGDs, respectively) and negative constraints), the chase procedure, and ontologies in Datalog+/–. We also define the used preference models.\nDatabases and Queries. We assume (i) an infinite universe of (data) constants ∆ (which constitute the “normal” domain of a database), (ii) an infinite set of (labeled) nulls ∆N (used as “fresh” Skolem terms, which are placeholders for unknown values, and can thus be seen as variables), and (iii) an infinite set of variables V (used in queries, dependencies, and constraints). Different constants represent different values (unique\nname assumption), while different nulls may represent the same value. We assume a lexicographic order on ∆∪∆N , with every symbol in ∆N following all symbols in ∆. We denote by X sequences of variablesX1, . . . , Xk with k> 0. We assume a relational schemaR, which is a finite set of predicate symbols (or simply predicates). A term t is a constant, null, or variable. An atomic formula (or atom) a has the form P (t1, ..., tn), where P is an n-ary predicate, and t1, ..., tn are terms. We say that a is ground iff every ti belongs to ∆.\nA database (instance) D for a relational schema R is a (possibly infinite) set of atoms with predicates fromR and arguments from∆. A conjunctive query (CQ) overR has the formQ(X) = ∃YΦ(X,Y), whereΦ(X,Y) is a conjunction of atoms (possibly equalities, but not inequalities) with the variables X and Y, and possibly constants, but no nulls. A CQ is atomic iff Φ(X,Y) is a single atom and Y= ∅ (i.e., there are no existentially quantified variables). A Boolean CQ (BCQ) over R is a CQ of the form Q(), i.e., all variables are existentially quantified, often written as the set of all its atoms without quantifiers, when there is no danger of confusion. Answers to CQs and BCQs are defined via homomorphisms, which are mappings µ : ∆ ∪ ∆N ∪ V → ∆ ∪∆N ∪ V such that (i) c∈∆ implies µ(c)= c, (ii) c∈∆N implies µ(c)∈∆∪∆N , and (iii) µ is naturally extended to atoms, sets of atoms, and conjunctions of atoms. The set of all answers to a CQQ(X)=∃YΦ(X,Y) overD, denotedQ(D), is the set of all tuples t over∆ for which there exists a homomorphism µ : X∪Y→∆∪∆N such that µ(Φ(X,Y))⊆D and µ(X)= t. The answer to a BCQ Q() over a database D is Yes, denoted D |=Q, iff Q(D) 6= ∅.\nGiven a relational schema R, a tuple-generating dependency (TGD) σ is a firstorder formula of the form ∀X∀YΦ(X,Y)→ ∃ZΨ(X,Z), where Φ(X,Y) and Ψ(X, Z) are conjunctions of atoms overR (without nulls), called the body and the head of σ, denoted body(σ) and head(σ), respectively. Such σ is satisfied in a database D for R iff, whenever there exists a homomorphism h that maps the atoms of Φ(X,Y) to atoms of D, there exists an extension h′ of h that maps the atoms of Ψ(X,Z) to atoms of D. All sets of TGDs are finite here. Since TGDs can be reduced to TGDs with only single atoms in their heads, in the sequel, every TGD has w.l.o.g. a single atom in its head. A TGD σ is guarded iff it contains an atom in its body that contains all universally quantified variables of σ. The leftmost such atom is the guard atom (or guard) of σ. A TGD σ is linear iff it contains only a single atom in its body. As set of TGDs is guarded (resp., linear) iff all its TGDs are guarded (resp., linear).\nQuery answering under TGDs, i.e., the evaluation of CQs and BCQs on databases under a set of TGDs is defined as follows. For a database D for R, and a set of TGDs Σ onR, the set of models of D and Σ, denoted mods(D,Σ), is the set of all (possibly infinite) databases B such that (i) D⊆B and (ii) every σ ∈Σ is satisfied in B. The set of answers for a CQ Q to D and Σ, denoted ans(Q,D,Σ) (or, for KB =(D,Σ), ans(Q,KB)), is the set of all tuples t such that t ∈ Q(B) for all B ∈mods(D,Σ). The answer for a BCQQ toD andΣ is Yes, denotedD∪Σ |=Q, iff ans(Q,D,Σ) 6= ∅. Note that query answering under general TGDs is undecidable [2], even when the schema and TGDs are fixed [6]. Decidability and tractability in the data complexity of query answering for the guarded case follows from a bounded tree-width property.\nA negative constraint (or simply constraint) γ is a first-order formula of the form ∀XΦ(X)→⊥, where Φ(X) (called the body of γ) is a conjunction of atoms over R (without nulls). Under the standard semantics of query answering of BCQs in Datalog+/– with TGDs, adding negative constraints is computationally easy, as for each constraint ∀XΦ(X)→⊥, we only have to check that the BCQ ∃XΦ(X) evaluates to false in D under Σ; if one of these checks fails, then the answer to the original BCQ Q is true, otherwise the constraints can simply be ignored when answering the BCQ Q.\nAn equality-generating dependency (EGD) σ is a first-order formula of the form ∀XΦ(X) →Xi=Xj , where Φ(X), called the body of σ and denoted body(σ), is a conjunction of atoms over R (without nulls), and Xi and Xj are variables from X. Such σ is satisfied in a databaseD forR iff, whenever there is a homomorphism h such that h(Φ(X,Y))⊆D, it holds that h(Xi)=h(Xj). Adding EGDs over databases with TGDs along with negative constraints does not increase the complexity of BCQ query answering as long as they are non-conflicting [7]. Intuitively, this ensures that, if the chase (see below) fails (due to strong violations of EGDs), then it already fails on the database, and if it does not fail, then whenever “new” atoms are created in the chase by the application of the EGD chase rule, atoms that are logically equivalent to the new ones are guaranteed to be generated also in the absence of the EGDs, guaranteeing that EGDs do not influence the chase with respect to query answering.\nWe usually omit the universal quantifiers in TGDs, negative constraints, and EGDs, and we implicitly assume that all sets of dependencies and/or constraints are finite.\nThe Chase. The chase was first introduced to enable checking implication of dependencies, and later also for checking query containment. By “chase”, we refer both to the chase procedure and to its output. The TGD chase works on a database via so-called TGD chase rules (see [7] for an extended chase with also EGD chase rules).\nTGD Chase Rule. Let D be a database, and σ a TGD of the form Φ(X,Y) → ∃ZΨ(X, Z). Then, σ is applicable to D iff there exists a homomorphism h that maps the atoms of Φ(X,Y) to atoms of D. Let σ be applicable to D, and h1 be a homomorphism that extends h as follows: for each Xi ∈ X, h1(Xi) = h(Xi); for each Zj ∈ Z, h1(Zj) = zj , where zj is a “fresh” null, i.e., zj ∈ ∆N , zj does not occur in D, and zj lexicographically follows all other nulls already introduced. The application of σ on D adds to D the atom h1(Ψ(X,Z)) if not already in D.\nThe chase algorithm for a database D and a set of TGDs Σ consists of an exhaustive application of the TGD chase rule in a breadth-first (level-saturating) fashion, which outputs a (possibly infinite) chase for D and Σ. Formally, the chase of level up to 0 of D relative to Σ, denoted chase0(D,Σ), is defined as D, assigning to every atom in D the (derivation) level 0. For every k> 1, the chase of level up to k of D relative to Σ, denoted chasek(D,Σ), is constructed as follows: let I1, . . . , In be all possible images of bodies of TGDs in Σ relative to some homomorphism such that (i) I1, . . . , In⊆ chasek−1(D,Σ) and (ii) the highest level of an atom in every Ii is k− 1; then, perform every corresponding TGD application on chasek−1(D,Σ), choosing the applied TGDs and homomorphisms in a (fixed) linear and lexicographic order, respectively, and assigning to every new atom the (derivation) level k. The chase of D relative toΣ, denoted chase(D,Σ), is defined as the limit of chasek(D,Σ) for k→∞.\nThe (possibly infinite) chase relative to TGDs is a universal model, i.e., there exists a homomorphism from chase(D,Σ) onto everyB ∈mods(D,Σ) [7]. This implies that BCQs Q over D and Σ can be evaluated on the chase for D and Σ, i.e., D∪Σ |= Q is equivalent to chase(D,Σ) |= Q. For guarded TGDsΣ, such BCQsQ can be evaluated on an initial fragment of chase(D,Σ) of constant depth k · |Q|, which is possible in polynomial time in the data complexity.\nDatalog+/– Ontologies. A Datalog+/– ontology KB =(D,Σ), whereΣ=ΣT ∪ΣE∪ ΣNC, consists of a database D, a set of TGDs ΣT , a set of non-conflicting EGDs ΣE , and a set of negative constraints ΣNC. We say that KB is guarded (resp., linear) iff ΣT is guarded (resp., linear). The following example illustrates a simple Datalog+/– ontology, which is used in the sequel as a running example.\nExample 1. Consider the following simple ontology KB = (D,Σ), where:\nΣ = {σ1 : hotel(H)→ accom(H), σ2 : apartment(A)→ accom(A), σ3 : bb(B)→ accom(B), σ4 : apthotel(A)→ hotel(A), σ5 : hostel(H)→ ∃B bed(B,H), σ6 : hotel(H)→ ∃R room(R,H), σ7 : bb(B)→ ∃R room(R,B)}\nand D= {hotel(h1), hotel(h2), locatedIn(h1, oxford), locatedIn(h2, oxfordCenter), hostel(hs1), bb(bb1), apartment(a1), apthotel(a2), locatedIn(a2, oxfordCenter)}.\nThis ontology models a very simple accommodation booking domain, which could be used as the underlying model in an online system. Accommodations can be either hotels, bed and breakfasts, hostels, apartments, or aparthotel. The database D provides some instances for each kind of accommodation, as well as some location facts.\nPreference Models. We now briefly recall some basic concepts regarding the representation of preferences. We assume the following sets, giving rise to the logical language used for this purpose: ∆Pref ⊆ ∆ is a finite set of constants, RPref ⊆ R is finite set of predicates, and VPref ⊆ V is an infinite sets of variables. These sets give rise to a corresponding Herbrand base consisting of all possible ground atoms that can be formed, which we denote with HPref, while H is the Herbrand base for the ontology. Clearly, we have HPref ⊆ H, meaning that preference relations are defined over a subset of the possible ground atoms.\nA preference relation over set S is any binary relation ⊆ S × S. Here, we are interested in strict partial orders (SPOs), which are irreflexive and transitive relations— we consider these to be the minimal requirements for a useful preference relation. One possible way of specifying such a relation is the preference formula framework of [9]. We use SPOs(S) to denote the set of all possible strict partial orders over a set S.\nFinally, the rank of an element in a preference relation is defined inductively as follows: (i) rank(a, ) = 1 iff there is no b such that b a; and (ii) rank(a, ) = k+1 iff rank(a, ) = 1 after eliminating from all elements of rank at most k."
    }, {
      "heading" : "3 Subjective Reports",
      "text" : "Let KB be a Datalog+/– ontology, a = p(c1, ..., cm) be a ground atom such that KB |= a, and F = (f1, ..., fn) be a tuple of features associated with the predicate p, each of which has a domain dom(fi) = [0, 1]∪{−}. We sometimes slightly abuse notation and use F to also denote the set of features {f1, ..., fn}.\nDefinition 1. A report for a ground atom a is a triple (E, P , I), whereE ∈ dom(f1)× ...×dom(fn), P is an SPO over the elements of F , and I is a set of pairs (key, value).\nIntuitively, reports are evaluations of an entity of interest (atom a) provided by observers. In a report (E, P , I), E specifies a “score” for each feature, P indicates the relative importance of the features to the report’s observer, and I (called information register) contains general information about the report itself and who provided it. Reports will be analyzed by a user, who has his own strict partial order, denoted PU , over the set of features. The following is a simple example involving hotel ratings.\nExample 2. Consider again the accommodation domain from Example 1, and let the features for predicate hotel be F = (location, cleanliness, price, breakfast, internet); in the following, we abbreviate these features as loc, cl, pri, br, and net, respectively.\nAn example of a report for hotel(h1) is r1 =(〈1, 0, 0.4, 0.1, 1〉, P1 , I1), where P1 is given by the graph in Fig. 1 (left side); PU (the user’s SPO) is shown in the same figure (right side). Finally, let I1 be a register with fields age, nationality, and type of traveler, with data I1.age = 34, I1.nationality = Italian, and I1.type = Business.\nThe set of all reports available is denoted with Reports. In the following, we use Reports(a) to denote the set of all reports that are associated with a ground atom a. Given a tuple of features F , we use SPOs(F) to denote the set of all SPOs over F ."
    }, {
      "heading" : "3.1 Trust Measures over Reports",
      "text" : "A user analyzing a set of reports may decide that certain opinions within a given report may be more trustworthy than others. For instance, returning to our running example, the score given for the location feature of hotel(h1) might be considered more trustworthy than the ones given for price or breakfast, e.g., because the report declared the\nformer to be among the most preferred features, while the latter are among the least preferred ones, cf. Figure 1 (left). Another example could be a user that is generally untrustworthy of reports on feature cleanliness, because he has learned that people are in general much more critical than he is when it comes to evaluating that aspect of a hotel, or of reports on feature price by business travelers because they do not use their own money to pay. Formally, we have the following definition of trust measure.\nDefinition 2. A trust measure is any function τ : Reports→ [0, 1]n.\nNote that trust measures do not depend on the user’s own preferences over F (in PU ); rather, for each report (E, P , I), they give a measure of trust to each of the n scores in E depending on P and I . The following shows an example of a trust measure.\nExample 3. Consider again our running example and suppose that the user defines a trust measure τ , which assigns trust values to a report r = (E, P , I) as follows:\nτ(r) =\n{ 0.25 · ( 2−(rank(f1, P )−1), ..., 2−(rank(fn, P )−1) ) if I.nationality 6= Italian;(\n2−(rank(f1, P )−1), ..., 2−(rank(fn, P )−1) )\notherwise.\nFor r1 from Example 2 and the SPO in Fig. 1 (left side), we get 2−(rank(loc, P1 )−1) = 2−(rank(net, P1 )−1) = 1, 2−(rank(cl, P1 )−1) = 0.5, and 2−(rank(pri, P1 )−1) = 0.25."
    }, {
      "heading" : "3.2 Relevance of Reports",
      "text" : "The other aspect of importance that a user must consider when analyzing reports is how relevant they are to his/her own preferences. For instance, a report given by someone who has preferences that are completely opposite to those of the user should be considered less relevant than one given by someone whose preferences only differ in a trivial aspect. This is inherently different from the trust measure described above, since trust is computed without taking into account the preference relation given by the user issuing the query. Formally, we define relevance measures as follows.\nDefinition 3. A relevance measure is any function ρ : Reports× SPOs(F)→ [0, 1].\nThus, a relevance measure takes as input a report (E, P , I) and an SPO P ′ and gives a measure of how relevant the report is relative to P ′ ; this is determined on the basis of P and P ′ , and can also take I into account.\nExample 4. Consider again the running example, and suppose that the user assigns relevance to a report r = (E, P , I) according to the function\nρ(r, PU ) = 2 −\n∑ fi∈F |rank(fi, P )−rank(fi, PU )|.\nFrom Fig. 1, e.g., we have that ρ(r1, PU ) = 2−1∗(0+1+1+0+1) = 0.125. Alternatively, a relevance measure comparing the SPO P of a report (E, P , I) with the user’s SPO PU (thus, in this case, information in I is ignored by the relevance measure) might be defined as follows. The relevance measure checks to what extent the\ntwo SPOs agree on the relative importance of the features in F . Formally, let P1 and P2 be SPOs over F . We define a measure of similarity of P1 and P2 as follows:\nsim(P1, P2) =\n∑ 16i<j6n sim(fi, fj , P1, P2)\nn(n− 1)/2 ,\nwhere\nsim(fi, fj , P1, P2) =  1 if (fi, fj) ∈ P1 ∩ P2 or (fj , fi) ∈ P1 ∩ P2 1 if (fi, fj) 6∈ P1 ∪ P2 and (fj , fi) 6∈ P1 ∪ P2 0.5 if ((fi, fj) ∈ P1∆P2 and (fj , fi) 6∈ P1 ∪ P2) or\n((fj , fi) ∈ P1∆P2 and (fi, fj) 6∈ P1 ∪ P2) 0 if (fi, fj) ∈ P1 ∪ P2 and (fj , fi) ∈ P1 ∪ P2 .\nHere, ∆ is used to denote the symmetric difference (i.e., A∆B = A ∪B −A ∩B). In the definition of sim(fi, fj , P1, P2),\n– the first condition refers to the case where P1 and P2 are expressing the same order between fi and fj , – the second condition refers to the case where both P1 and P2 are not expressing any order between fi and fj , – the third condition refers to the case where one of P1 and P2 is expressing an order between fi and fj and the other is not expressing any order, – the last condition refers to the case where P1 and P2 are expressing opposite orders between fi and fj .\nClearly, sim(P1, P2) is 1 when P1 and P2 agree on everything, and 0 when P1 and P2 agree on nothing. Finally, we define a relevance measure by ρ((E, P , I), P ′) = sim( P , P ′) for every report (E, P , I) ∈ Reports and SPO P ′∈ SPOs(F)."
    }, {
      "heading" : "4 Query Answering based on Subjective Reports",
      "text" : "To produce a ranking based on the basic components presented in Section 3, we must first develop a way to combine them in a principled manner. More specifically, the problem that we address is the following. The user is given a Datalog+/– ontology KB and has an atomic query Q(X) of interest. The user also supplies an SPO PU over the set of features F . The answers to an atomic query Q(X) = p(X) over KB in atom form are defined as {p(t) | t ∈ ans(Q(X),KB)}; we still use ans(Q(X),KB) to denote the set of answers in atom form. Recall that in our setting, each ground atom b such that KB |= b is associated with a (possibly empty) set of reports. As we consider atomic queries, then each ground atom a ∈ ans(Q(X),KB) is an atom entailed by KB and thus it is associated with a set of reports Reports(a). Furthermore, each report r ∈ Reports(a) is associated with a trust score τ(r). We want to rank the ground atoms in Ans(Q(X),KB); that is, we want to obtain a set {〈ai, scorei〉 | ai ∈ ans(Q(X),KB)} where scorei for ground atom ai takes into account:\n– the set of reports Reports(ai) associated with ai; – the trust score τ(r) associated with each report r ∈ Reports(ai); and – the SPO PU over F provided by the user issuing the query."
    }, {
      "heading" : "4.1 A Basic Approach",
      "text" : "A first approach to solving this problem is Algorithm RepRank-Basic in Fig. 2. A score for each atom is computed as the average of the scores of the reports associated with the atom, where the score of a report r = (E, P , I) is computed as follows:\n– we first compute the average of the scores E[i] weighted by the trust value for E[i] and a value measuring how important feature fi is for the user issuing the query (this value is given by rank(fi, PU )); – then, we multiply the value computed in the previous step by ρ(r, PU ), which gives a measure of how relevant r is w.r.t. PU .\nThe following is an example of how Algorithm RepRank-Basic works.\nExample 5. Consider again the setup from the running example, where we have the Datalog+/– ontology from Example 1, the set Reports of the reports depicted in Fig. 3, the SPO PU from Fig. 1 (right), the trust measure τ defined in Example 3, and the relevance measure ρ introduced in Example 4. Finally, let Q(X) = hotel(X).\nAlgorithm RepRank-Basic iterates through the set of answers (in atom form) to the query, which in this case consists of {hotel(h1), hotel(h2)}. For atom hotel(h1), the algorithm iterates through the set of corresponding reports, which is Reports(hotel(h1)) = {r1, r2, r3}, and maintains the accumulated score after processing each report. For r1, the score is computed as (cf. line 6):\n0.125 ∗ 1 5 ∗ ( 1 ∗ 1 1 + 0 ∗ 0.5 1 + 0.4 ∗ 0.25 2 + 0.1 ∗ 0.25 3 + 1 ∗ 1 2 ) = 0.03895 .\nThe score for hotel(h1) after processing the three reports is approximately 0.05746. Analogously, assuming Reports(hotel(h2))= {r4, r5, r6}, the score for hotel(h2) is approximately 0.0589. Therefore, the top-2 answer to Q is 〈hotel(h2), hotel(h1)〉.\nThe following result states the time complexity of Algorithm RepRank-Basic. As long as both query answering and the computation of the trust and relevance measures can be done in polynomial time, RepRank-Basic can also be done in polynomial time.\nProposition 1. The worst-case time complexity of Algorithm RepRank-Basic is O(m∗ log m+(n+ | PU |)+m∗Reportsmax ∗(fτ +fρ+n)+fans(Q(X),KB)), where m = |ans(Q(X),KB)|, Reportsmax = max{|Reports(a)| : a ∈ ans(Q(X),KB)}, fτ (resp. fρ) is the worst-case time complexity of τ (resp. ρ), and fans(Q(X),KB) is the data complexity of computing ans(Q(X),KB).\nIn the next section, we explore an alternative approach to applying the trust and relevance measures to top-k query answering."
    }, {
      "heading" : "4.2 A Different Approach to using Trust and Relevance",
      "text" : "A more complex approach consists of using the trust and relevance scores provided by the respective measures in a more fine-grained manner. One way of doing this is via the following steps (more details on each of them are given shortly):\n1. Keep only those reports that are most relevant to the user issuing the query, that is, those reports that are relevant enough to PU according to a relevance measure ρ; 2. consider the most relevant reports obtained in the previous step and use the trust measure given by the user to produce scores adjusted by the trust measure; and 3. for each atom, compute a single score by combining the scores computed in the previous step with PU .\nThe first step can simply be carried out by checking, for each report r, if ρ(r, PU ) is above a certain given threshold. One way of doing the second step is described in Algorithm SummarizeReports (Fig. 4), which takes a trust measure τ , a set of reports Reports (for a certain atom), and a function collFunc. The algorithm processes each report in the input sets by building a histogram of average (trust-adjusted) reported values for each of the n features with ten possible “buckets” (of course, this can be easily generalized to any number of buckets); for each report, the algorithm applies the trust measure to update each feature’s histogram. Once all of the reports are processed, the last step is to collapse the histograms into a single value—this is done by applying the collFunc function, which could simply be defined as the computation of a weighted average for each feature. This single value is finally used to produce the output, which is a tuple of n scores. The following example illustrates how SummarizeReports works.\nExample 6. Let us adopt again the setup from Example 5. Suppose we want to keep only those reports for which the relevance score is above 0.1 (as per the first step of our more complex approach). Recall that the set of answers to Q is {hotel(h1), hotel(h2)} and there are six associated reports. Among them, we keep only reports r1, r2, r4, and r5. Algorithm SummarizeReports will have Reports = {r1, r2} when called for hotel(h1). The histograms built during this call are as follows:\n– loc: value 0.95 in bucket [0.9, 1]; – cl: value 1 in bucket [0.5, 0.6] and value 0.3 in bucket [0.9, 1]; – pri: value 0.8 in bucket [0.2, 0.3) and value 0.2 in bucket [0.5, 0.6); – br: value 0.1 in bucket [0.2, 0.3) and value 0.5 in bucket [0.5, 0.6); and – net: value 0.6 in bucket [0.6, 0.7) and value 1 in bucket [0.9, 1].\nAssuming that function collFunc disregards the values in the bucket corresponding to the lowest trust value (if more than one bucket is non-empty), and takes the average of the rest, we have the following result tuple as the output of SummarizeReports: (0.95, 0.3, 0.2, 0.5, 1). Analogously, we have tuple (0.85, 0.1, 0.1, 0.4, 1) for tuple hotel(h2) after calling SummarizeReports with Reports = {r4, r5}.\nThe following proposition states the time complexity of Algorithm SummarizeReports. As long as the trust measure and the collFunc function can be computed in polynomial time, Algorithm SummarizeReports is polynomial time too.\nProposition 2. The worst-case time complexity of Algorithm SummarizeReports is O(|Reports| ∗ (fτ + n) + n ∗ fcollFunc), where fτ (resp. fcollFunc) is the worst-case time complexity of τ (resp. collFunc).\nThe following example explores a few different ways in which function collFunc used in Algorithm SummarizeReports might be defined.\nExample 7. One way of computing collFunc is shown in Example 6. There can be other reasonable ways of collapsing the histogram for a feature into a single value. E.g., collFunc might compute the average across all buckets ignoring the trust measure so that no distinction is made among buckets, i.e., collFunc(hists[i]) = ∑10 b=1 hists[i](b)\n10 . Alternatively, the trust measure might be taken into account by giving a weight wb to each bucket b (e.g., the weights might be set in such a way that buckets corresponding to higher trust scores have a higher weight, that is, weighti < weightj for i < j). In this case, the histogram might be collapsed as follows collFunc(hists[i]) =∑10\nb=1 wb∗hists[i](b) 10 . We may also want to apply the above strategies but ignoring the first k buckets (for which the trust score is lower). Function collFunc can also be extended so that the number of elements associated with a bucket is taken into account.\nThus, the second step discussed above gives n scores (adjusted by the trust measure) for each ground atom. Recall that the third (and last) step of the approach adopted in this section is to compute a score for each atom by combining the scores computed in the previous step with PU . One simple way of doing this is to compute the weighted average of such scores where the weight of the i-th score is the inverse of the rank of feature fi in PU .\nAlgorithm RepRank-Hist (Figure 5) is the complete algorithm that combines the three steps discussed thus far. The following continues the running example to show the result of applying this algorithm.\nExample 8. Let us adopt once again the setup from Example 5, but this time applying Algorithm RepRank-Hist. Suppose collFunc is the one discussed in Example 6 and thus Algorithm SummarizeReports returns the scores (0.95, 0.3, 0.2, 0.5, 1) for hotel(h1) and the scores (0.85, 0.1, 0.1, 0.4, 1) for hotel(h2). Algorithm RepRankHist computes a score for each atom by performing a weighted average of the scores in these tuples, which results in:\n〈hotel(h1), 2.0166〉 and 〈hotel(h2), 1.6333〉.\nTherefore, the top-2 answer to query Q is 〈hotel(h1), hotel(h2)〉.\nNote that the results from Examples 5 and 8 differ in the way they order the two tuples; this is due to the way in which relevance and trust scores are used in each algorithm—the more fine-grained approach adopted by Algorithm RepRank-Hist allows it to selectively use both kinds of values to generate a more informed result.\nProposition 3. The worst-case time complexity of Algorithm RepRank-Hist is: O(m∗log m+(n+| PU |)+m∗(Reportsmax∗fρ+fsum+n)+fans(Q(X),KB)), where\nm = |ans(Q(X),KB)|, Reportsmax = max{|Reports(a)| : a ∈ ans(Q(X),KB)}, fρ is the worst-case time complexity of ρ, fsum is the worst-case time complexity of Algorithm SummarizeReports as per Proposition 2, and fans(Q(X),KB) is the data complexity of computing ans(Q(X),KB).\nAs a corollary to Propositions 1 and 3, we have the following result.\nTheorem 1. If the input ontology belongs to the guarded fragment of Datalog+/–, then Algorithms RepRank-Basic and RepRank-Hist run in polynomial time in the data complexity.\nThus far, we have considered atomic queries. As each ground atom a such that KB |= a is associated with a set of reports and every ground atom b in ans(Q(X),KB) is such that KB |= b, then reports can be associated with query answers in a natural way. We now introduce a class of queries more general than the class of atomic queries for which the same property holds. A simple query is a conjunctive query Q(X) = ∃YΦ(X,Y) where Φ(X,Y) contains exactly one atom of the form p(X), called distinguished atom (i.e., an atom whose variables are the query’s free variables). For instance, Q(X) = hotel(X)∧ locatedIn(X, oxford) is a simple query where hotel(X) is the distinguished atom. The answers to a simple query Q(X) over KB in atom form are defined as {p(t) | t ∈ ans(Q(X),KB)} where the distinguished atom is of the form p(X); we still use ans(Q(X),KB) to denote the set of answers in atom form. Clearly, for each atom a in ans(Q(X),KB), it is the case that KB |= a."
    }, {
      "heading" : "5 Towards more General Reports",
      "text" : "In the previous section we considered the setting where reports are associated with ground atoms a such that KB |= a. This setup is limited, since it does not allow to express the fact that certain reports may apply to whole sets of atoms—this is necessary to model certain kinds of opinions often found in reviews, such as “accommodations in Oxford are expensive”. We now generalize the framework presented in Sections 3 and 4 to contemplate this kind of reports.\nDefinition 4. A generalized report (g-report, for short) is a pair gr = (r,Q(X)), where r is a report and Q(X) is a simple query, called the descriptor of gr.\nWe denote with g-Reports the universe of g-reports. Intuitively, given an ontology KB , a g-report (r,Q(X)) is used to associate report r with every atom a in ans(Q(X),KB)— recall that KB |= a and thus general reports allow us to assign a report to a set of atoms entailed by KB .\nClearly, a report for a ground atom a as defined in Definition 1 is a special case of a g-report in which the only answer to the descriptor is a.\nExample 9. Consider our running example from the accommodations domain and suppose we want to associate a certain report r with all accommodations in the city of Oxford. This can be expressed with a g-report (r,Q(X)) where Q(X) = accom(X) ∧ locatedIn(X, oxford) with descriptor accom(X).\nIntuitively, a g-report gr = (r,Q(X)) is a report associated with a set of atoms, i.e., the set of atoms in ans(Q(X),KB)). A simple way of handling this generalization would be to associate report r with every atom in this set. Note that, as in the nongeneralized case, it might be the case that two or more g-reports assign two distinct reports to the same ground atom. E.g., we may have a g-report (r,Q(X)), whereQ(X) =\naccom(X) ∧ locatedIn(X, oxford), expressing that r applies to all accommodations in Oxford, and another g-report (r′, Q′(X)), where Q′(X) = accom(X) ∧ hotel(X), expressing that r′ applies to all accommodations that are hotels. In our running example, we would simply associate both r and r′ to accom(hi), accom(h2), and accom(a2).\nIn the approach just described, the reports coming from different g-reports are treated in the same way—they all have the same impact on the common atoms. Another possibility is to determine when a g-report is in some sense more specific than another and take such a relationship into account (e.g., more specific g-reports should a greater impact when computing the ranking over atoms). We consider this kind of scenario in the following section.\nLeveraging the Structural Properties of Ontologies\nWe now study two kinds of structure that can be leveraged from knowledge contained in the ontology. The first is based on the notion of hierarchies, which are useful in capturing the influence of reports in “is-a” type relationships. As an example, given a query requesting a ranking over hotels in Oxfordshire, a report for all hotels in Oxford should have a higher impact on the calculation of the ranking than a report for all accommodations in the UK—in particular, the latter might be ignored altogether since it is too general. The second kind of structure is based on identifying subset relationships between the atoms associated with the descriptors in g-reports. For instance, a report for all hotels in Oxford is more general than a report for all hotels in Oxford city center, since the former is a superset of the latter.\nIn the following, we define a partial order among reports based on these notions. We begin by defining hierarchical TGDs.\nDefinition 5. A set of linear TGDs ΣT is said to be hierarchical iff for every p(X)→ ∃Yq(X,Y) ∈ ΣT we have that features(p) ⊆ features(q) and there does not exist database D over R and TGD in ΣT of the form p′(X) → ∃Yr(X,Y) such that p(X) and p′(X) share ground instances relative to D.\nIn the rest of this section, we assume that all ontologies contain a (possibly empty) subset of hierarchical TGDs. Furthermore, given ontology KB = (D,Σ) where ΣH ⊆ Σ is a set of hierarchical TGDs, and two ground atoms a, b, we say that a is-a b iff chase({a}, ΣH) |= b. For instance, in Example 1, set {σ1, σ2, σ3, σ4} ⊆ Σ is a hierarchical set of TGDs (assuming that the conditions over the features hold).\nGiven tuples of features F and F ′ such that F ⊆ F ′ and vectors E and E′ over the domains of F and F ′, respectively, we say that E′ is a particularization of E, denoted E′ = part(E) iff E′[f ] = E[f ] if f ∈ F ∩ F ′ and E′[f ] = − otherwise.\nDefinition 6. Let KB = (D,Σ) be a Datalog+/– ontology, a be a ground atom such that KB |= a, and gr = (r,Q(X)) be a g-report with r = (E, P , I). If there exists a ground atom b ∈ Ans(Q(X),KB) such that a is-a b then we say that g-report gr′ = ((E′, P , I), a), with E′ = part(E), is a specialization of gr for a.\nClearly, a g-report is always a specialization of itself for every atom in the answers to its descriptor.\nExample 10. Let F1 be the set of features for predicate hotel presented in Example 2, and let F2 = 〈loc, cl, pri, br, net, kfac〉 be the set of features for predicate apthotel, where kfac denotes “kitchen facilities”.\nLet gr=(r1, Q(X)) be a g-report, where r1 is the report from Figure 3 andQ(X) = hotel(X) ∧ locatedIn(X, oxford). If we consider a = apthotel(a2) and b = hotel(a2), clearly we have that b ∈ Ans(Q(X),KB) and a is-a b. Therefore, a specialization of gr for a is gr′ = ((E′, P1 , I1), a), where E′ = 〈1, 0, 0.4, 0.1, 1,−〉.\nDefinition 7. Given g-reports gr1 = (r1, Q1(X1)) and gr2 = (r2, Q2(X2)), we say that gr1 is more general than gr2, denoted gr2 v gr1, iff either (i) Ans(Q2(X2),KB) ⊆ Ans(Q1(X1),KB); or (ii) for each a ∈ Ans(Q2(X2),KB) there exists b ∈ Ans(Q1(X1), KB) such that a is-a b. If gr1 v gr2 and gr2 v gr1, we say that gr1 and gr2 are equivalent, denoted gr1 ≡ gr2.\nExample 11. Consider the g-reports in Figure 6 and the database in the running example with the addition of atoms hotel(h3) and locatedIn(h3, cambridge). We then have: – gr1 v gr4 since {hotel(h2), hotel(a2)} ⊆ {hotel(h1), hotel(h2), hotel(a2)}; – gr1 v gr3 since for atom apthotel(a2) (the only answer for the descriptor in gr3) there exists atom hotel(a2) in the answer to descriptor in gr1 and apthotel(a2) is-a hotel(a2); and – gr4 is incomparable to all other reports, since neither condition from Definition 7 is satisfied.\nThe “more general than” relationship between g-reports is useful for defining a partial order for the set of reports associated with a given ground atom. This partial order can be defined as follows: gr1 ∼ gr2 iff gr1 ≡ gr2 and gr1 gr2 iff gr1 v gr2. Here, a ∼ b denotes the equivalence between a and b.\nDefinition 8. A weighting function for g-reports is any function ω : g-Reports→ [0, 1] such that: (i) if gr1 gr2 then ω(gr1) > ω(gr2); and (i) if gr1 ∼ gr2 then ω(gr1) = ω(gr2).\nFor example, one possible weighting function is defined as ω(gr) = 2−rank(gr, )+1."
    }, {
      "heading" : "6 Related Work",
      "text" : "The study of preferences has been carried out in many disciplines; in computer science, the developments that are most relevant to our work is in the incorporation of preferences into query answering mechanisms. To date (and to our knowledge), the state\nof the art in this respect is centered around relational databases and, recently, in ontological languages for the Semantic Web [13]. The seminal work in preference-based query answering was that of [12], in which the authors extend the SQL language to incorporate user preferences. The preference formula formalism was introduced in [9] as a way to embed a user’s preferences into SQL. An important development in this line of research is the well-known skyline operator, which was first introduced in [3]. A recent survey of preference-based query answering formalisms is provided in [15]. Studies of preferences related to our approach have also been done in classical logic programming [10,11] as well as answer set programming frameworks [4].\nThe present work can be considered as a further development of the PrefDatalog+/– framework presented in [13], where we develop algorithms to answer skyline queries, and their generalization to k-rank queries, over classical Datalog+/– ontologies. The main difference between PrefDatalog+/– and the work presented here is that PrefDatalog+/– assumes that a model of the user’s preferences are given at the time the query is issued. On the other hand, we make no such assumption here; instead, we assume that the user only provides some very basic information regarding their preferences over certain features, and that they have access to a set of reports provided by other users in the past. In a sense, this approach is akin to building an ad hoc model on the fly at query time and using it to provide a ranked list of results.\nFinally, this work is closely connected to the study and use of provenance in information systems and, in particular, the Semantic Web and social media [14,1]. Provenance information describes the history of data and information in its life cycle. Research in provenance distinguishes between data and workflow provenance [5]. The former explores the data flow within (typically, database) applications in a fine-grained way, while the latter is coarse-grained and does not consider the flow of data within the involved applications. In this work, we propose a new kind of provenance that is closely related to data provenance, but does not fit into the why, how, and where provenance framework typically considered in data provenance research [8]. We take into account (in a fine-grained way) where evaluations and reports within a social media system are coming from (i.e., information about who has issued the report and what his/her preferences were) and use this information to allow users to make informed and provenance-based decisions. To our knowledge, this is the first study of a direct application of provenance of reports of this kind found in online reviews to query answering."
    }, {
      "heading" : "7 Summary and Outlook",
      "text" : "In this paper, we have studied the problem of preference-based query answering in Datalog+/– ontologies under the assumption that the user’s preferences are informed by a set of subjective reports representing opinions of others—such reports model the kind of information found, e.g., in online reviews of products, places, and services. We have first introduced a basic approach, in which reports are assigned to ground atoms. We have proposed two ranking algorithms using trust and relevance functions in order to model the different impact that reports should have on the user-specific ranking by taking into account the differences and similarities between the user’s preferences over basic features and those of the person writing the report, as well as the person’s self-\nreported characteristics (such as age, gender, etc.). As a generalization, we have then extended reports to apply to entire sets of atoms so that they can model more general opinions. Apart from the naive approach of simply replicating the general report for each individual atom that it pertains to, we have proposed a way to use the information in the knowledge base to assign greater weights to more specific reports.\nMuch work remains to be done in this line of research, for instance, exploring conditions over the trust and relevance functions to allow pruning of reports, applying more sophisticated techniques to judging the impact of generalized reports, and the application of existing techniques to allow the obtention of reports from the actual information available in reviews on the Web. We also plan to implement our algorithms and evaluate them over synthetic and real-world data. Finally, another topic for future research is to formally investigate the relationship between well-known data provenance frameworks and the preference-based provenance framework presented in this paper. Acknowledgments. This work was supported by the UK EPSRC grant EP/J008346/1 (“PrOQAW”), an EU (FP7/2007-2013) Marie-Curie Intra-European Fellowship, the ERC grant 246858 (“DIADEM”), and a Yahoo! Research Fellowship."
    } ],
    "references" : [ {
      "title" : "Provenance Data in Social Media",
      "author" : [ "G. Barbier", "Z. Feng", "P. Gundecha", "H. Liu" ],
      "venue" : "Morgan and Claypool",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "The implication problem for data dependencies",
      "author" : [ "C. Beeri", "M.Y. Vardi" ],
      "venue" : "Proc. of ICALP.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1981
    }, {
      "title" : "The skyline operator",
      "author" : [ "S. Börzsönyi", "D. Kossmann", "K. Stocker" ],
      "venue" : "Proc. of ICDE.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Preferences, contexts and answer sets",
      "author" : [ "G. Brewka" ],
      "venue" : "Proc. of ICLP.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "The providence of provenance",
      "author" : [ "P. Buneman" ],
      "venue" : "Proc. of BNCOD.",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Taming the infinite chase: Query answering under expressive relational constraints",
      "author" : [ "A. Calı̀", "G. Gottlob", "M. Kifer" ],
      "venue" : "Proc. of KR.",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "A general Datalog-based framework for tractable query answering over ontologies",
      "author" : [ "A. Calı̀", "G. Gottlob", "T. Lukasiewicz" ],
      "venue" : "J. Web Sem. 14",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Provenance in databases: Why, how and where",
      "author" : [ "J. Cheney", "L. Chiticariu", "Tan", "W.-C." ],
      "venue" : "Foundation and Trends in Databases 1(4)",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Preference formulas in relational queries",
      "author" : [ "J. Chomicki" ],
      "venue" : "TODS 28(4)",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Preference logic programming",
      "author" : [ "K. Govindarajan", "B. Jayaraman", "S. Mantha" ],
      "venue" : "Proc. of ICLP.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Preference queries in deductive databases",
      "author" : [ "K. Govindarajan", "B. Jayaraman", "S. Mantha" ],
      "venue" : "New Generation Computing 19(1)",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Preferences: Putting more knowledge into queries",
      "author" : [ "M. Lacroix", "P. Lavency" ],
      "venue" : "Proc. of VLDB. Volume 87.",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1987
    }, {
      "title" : "Preference-based query answering in Datalog+/– ontologies",
      "author" : [ "T. Lukasiewicz", "M.V. Martinez", "G.I. Simari" ],
      "venue" : "Proc. of IJCAI.",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "The foundations for provenance on the Web",
      "author" : [ "L. Moreau" ],
      "venue" : "Found. Trends Web Sci. 2(2/3)",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A survey on representation, composition and application of preferences in database systems",
      "author" : [ "K. Stefanidis", "G. Koutrika", "E. Pitoura" ],
      "venue" : "TODS 36(3)",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "First, we briefly recall some basics on Datalog+/– [7], namely, on relational databases and (Boolean) conjunctive queries ((B)CQs) (along with tuple- and equality-generating dependencies (TGDs and EGDs, respectively) and negative constraints), the chase procedure, and ontologies in Datalog+/–.",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 1,
      "context" : "Note that query answering under general TGDs is undecidable [2], even when the schema and TGDs are fixed [6].",
      "startOffset" : 60,
      "endOffset" : 63
    }, {
      "referenceID" : 5,
      "context" : "Note that query answering under general TGDs is undecidable [2], even when the schema and TGDs are fixed [6].",
      "startOffset" : 105,
      "endOffset" : 108
    }, {
      "referenceID" : 6,
      "context" : "Adding EGDs over databases with TGDs along with negative constraints does not increase the complexity of BCQ query answering as long as they are non-conflicting [7].",
      "startOffset" : 161,
      "endOffset" : 164
    }, {
      "referenceID" : 6,
      "context" : "The TGD chase works on a database via so-called TGD chase rules (see [7] for an extended chase with also EGD chase rules).",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 6,
      "context" : ", there exists a homomorphism from chase(D,Σ) onto everyB ∈mods(D,Σ) [7].",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 8,
      "context" : "One possible way of specifying such a relation is the preference formula framework of [9].",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 0,
      "context" : ", fn) be a tuple of features associated with the predicate p, each of which has a domain dom(fi) = [0, 1]∪{−}.",
      "startOffset" : 99,
      "endOffset" : 105
    }, {
      "referenceID" : 0,
      "context" : "A trust measure is any function τ : Reports→ [0, 1].",
      "startOffset" : 45,
      "endOffset" : 51
    }, {
      "referenceID" : 0,
      "context" : "A relevance measure is any function ρ : Reports× SPOs(F)→ [0, 1].",
      "startOffset" : 58,
      "endOffset" : 64
    }, {
      "referenceID" : 0,
      "context" : "Algorithm SummarizeReports(τ,Reports, collFunc) Input: Trust measure τ , set of reports Reports, and function collFunc that collapses histograms to values in [0, 1].",
      "startOffset" : 158,
      "endOffset" : 164
    }, {
      "referenceID" : 0,
      "context" : "9, 1]} and values of type [0, 1], where n = |F| (we use values 1, .",
      "startOffset" : 26,
      "endOffset" : 32
    }, {
      "referenceID" : 0,
      "context" : ", fn}, user preferences PU , trust measure τ , relevance measure ρ, relThresh ∈ [0, 1], function collFunc that collapses histograms to values in [0, 1], set of reports Reports, k > 1.",
      "startOffset" : 80,
      "endOffset" : 86
    }, {
      "referenceID" : 0,
      "context" : ", fn}, user preferences PU , trust measure τ , relevance measure ρ, relThresh ∈ [0, 1], function collFunc that collapses histograms to values in [0, 1], set of reports Reports, k > 1.",
      "startOffset" : 145,
      "endOffset" : 151
    }, {
      "referenceID" : 0,
      "context" : "A weighting function for g-reports is any function ω : g-Reports→ [0, 1] such that: (i) if gr1 gr2 then ω(gr1) > ω(gr2); and (i) if gr1 ∼ gr2 then ω(gr1) = ω(gr2).",
      "startOffset" : 66,
      "endOffset" : 72
    }, {
      "referenceID" : 12,
      "context" : "of the art in this respect is centered around relational databases and, recently, in ontological languages for the Semantic Web [13].",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 11,
      "context" : "The seminal work in preference-based query answering was that of [12], in which the authors extend the SQL language to incorporate user preferences.",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 8,
      "context" : "The preference formula formalism was introduced in [9] as a way to embed a user’s preferences into SQL.",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 2,
      "context" : "An important development in this line of research is the well-known skyline operator, which was first introduced in [3].",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 14,
      "context" : "A recent survey of preference-based query answering formalisms is provided in [15].",
      "startOffset" : 78,
      "endOffset" : 82
    }, {
      "referenceID" : 9,
      "context" : "Studies of preferences related to our approach have also been done in classical logic programming [10,11] as well as answer set programming frameworks [4].",
      "startOffset" : 98,
      "endOffset" : 105
    }, {
      "referenceID" : 10,
      "context" : "Studies of preferences related to our approach have also been done in classical logic programming [10,11] as well as answer set programming frameworks [4].",
      "startOffset" : 98,
      "endOffset" : 105
    }, {
      "referenceID" : 3,
      "context" : "Studies of preferences related to our approach have also been done in classical logic programming [10,11] as well as answer set programming frameworks [4].",
      "startOffset" : 151,
      "endOffset" : 154
    }, {
      "referenceID" : 12,
      "context" : "The present work can be considered as a further development of the PrefDatalog+/– framework presented in [13], where we develop algorithms to answer skyline queries, and their generalization to k-rank queries, over classical Datalog+/– ontologies.",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 13,
      "context" : "Finally, this work is closely connected to the study and use of provenance in information systems and, in particular, the Semantic Web and social media [14,1].",
      "startOffset" : 152,
      "endOffset" : 158
    }, {
      "referenceID" : 0,
      "context" : "Finally, this work is closely connected to the study and use of provenance in information systems and, in particular, the Semantic Web and social media [14,1].",
      "startOffset" : 152,
      "endOffset" : 158
    }, {
      "referenceID" : 4,
      "context" : "Research in provenance distinguishes between data and workflow provenance [5].",
      "startOffset" : 74,
      "endOffset" : 77
    }, {
      "referenceID" : 7,
      "context" : "In this work, we propose a new kind of provenance that is closely related to data provenance, but does not fit into the why, how, and where provenance framework typically considered in data provenance research [8].",
      "startOffset" : 210,
      "endOffset" : 213
    } ],
    "year" : 2013,
    "abstractText" : "The use of preferences in query answering, both in traditional databases and in ontology-based data access, has recently received much attention, due to its many real-world applications. In this paper, we tackle the problem of top-k query answering in Datalog+/– ontologies subject to the querying user’s preferences and a collection of (subjective) reports of other users. Here, each report consists of scores for a list of features, its author’s preferences among the features, as well as other information. Theses pieces of information of every report are then combined, along with the querying user’s preferences and his/her trust into each report, to rank the query results. We present two alternative such rankings, along with algorithms for top-k (atomic) query answering under these rankings. We also show that, under suitable assumptions, these algorithms run in polynomial time in the data complexity. We finally present more general reports, which are associated with sets of atoms rather than single atoms.",
    "creator" : "LaTeX with hyperref package"
  }
}