{
  "name" : "1605.04218.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Anytime Inference in Valuation Algebras",
    "authors" : [ "Abhishek Dasgupta", "Samson Abramsky" ],
    "emails" : [ "abhishek.dasgupta@cs.ox.ac.uk", "samson.abramsky@cs.ox.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keywords: Approximation; Anytime algorithms; Resourcebounded computation; Generic inference; Valuation algebras; Local computation; Binary join trees."
    }, {
      "heading" : "1 Introduction",
      "text" : "The inference problem is one of the most-important and well-studied problems in the field of statistics and machine learning. Inference can be considered as the (1) combination of information from various sources, which could be in the form of probability distributions from a probabilistic graphical model [12], belief functions in DempsterShafer theory [3, 8] or tables in a relational database; and (2) subsequent focusing or projection to variables of interest, which corresponds to projection for variables in probabilistic graphical models, or a query in the relational database. Our work is based on the theory of generic inference [17] which abstracts and generalises the inference problem across these different areas.\nThe utility of generic inference can be understood as an analogue to sorting, which is agnostic to the specific data type, as long as there is a total order. Generic inference generalises inference algorithms by abstracting the essential components of information in an algebraic structure. In [13], an algorithm was defined which solved the inference problem on Bayesian networks, using a technique called local computation. It was noted in [23] that the same algorithm could be used to solve the inference problem on belief functions, and a sufficient set of axioms were proposed for an algebraic framework that is necessary for the generic inference algorithm. This was extended by Kohlas into a theory of valuation algebras, and a computer implementation of inference over valuation algebras along with concrete instantiations was developed in [16].\n1 Department of Computer Science, University of Oxford, e-mail: abhishek.dasgupta@cs.ox.ac.uk 2 Department of Computer Science, University of Oxford, e-mail: samson.abramsky@cs.ox.ac.uk\nGeneric inference as formulated in [17] solves the inference problem in the exact case. As exact inference is an #P-hard problem [25], in practice, we need frameworks for approximate inference. Approximation schemes exist for specific instances of valuation algebras (probability potentials [2], belief potentials [6]); as well as for the generic case [5], but there is no such generic framework for anytime inference. In this paper, we extend the approximate inference framework in [5] to support anytime inference.\nIn anytime algorithms, instead of an algorithm terminating after an unspecified amount of time with a specific accuracy, we are able to tune the accuracy via a parameter passed to the algorithm. The algorithm can also be designed to be interruptible, gradually improving its accuracy until terminated by the user. Such algorithms are important in online learning where new data is being streamed in [24], in intelligent systems, decision making under uncertainty [7] and robotics [28] where due to the limitation of interacting in real-time there may not be sufficient time to compute an exact solution. We shall consider interruptible anytime algorithms which can be interrupted at any time and the approximation can be improved by resuming the algorithm. This affords the greatest flexibility from the user’s perspective, with applications of such algorithms to real-time systems such as sensor networks and path planning.\nTable 1 notes the previous work done in the area of inference algorithms, in both the generic case and for the specific case of probability potentials, and situates our work in context.\nWe note that the successive rows in the above table refine upon the previous one, and include it; the approximate inference framework can also perform exact inference, and the anytime inference framework presented here gives an approximate solution which incrementally improves with time, converging on the solution obtained from exact inference given sufficient time.\nThis article is divided into the following sections. Section 2 reviews the framework of valuation algebras and ordered valuation algebras. Section 3 introduces our extension to ordered valuation algebras to support anytime inference, and proves soundness and completeness theorems for anytime inference. Section 4 describes instances of the framework, including its application to anytime inference in semiringinduced valuation algebras. Section 5 gives a complexity analysis of the algorithm. Section 6 shows implementation results of anytime inference on a Bayesian network. Section 7 concludes.\nar X\niv :1\n60 5.\n04 21\n8v 1\n[ cs\n.A I]\n1 3\nM ay\n2 01\n6"
    }, {
      "heading" : "2 Valuation Algebras",
      "text" : "Valuation algebras are the core algebraic structure in the theory of generic inference. In a valuation algebra, we consider the various pieces of information in an inference problem (conditional probability distributions, belief potentials, relational database tables, etc.) as elements in an algebraic structure with a set of axioms. We review the axioms of valuation algebra [17] below, preceded by some remarks on notation.\nAll operations in the valuation algebra are defined on elements denoted by lowercase Greek letters: φ ,ψ, . . .. We can think of a valuation as the information contained by the possible values of a set of variables, which are denoted by Roman lowercase letters (with possible subscripts): x,y, . . . and denote sets of variables by uppercase letters: S,T, . . .. Each valuation refers to the information contained in a set of variables which we call the domain of a valuation, denoted by d(φ) for a valuation φ . For a finite set of variables D, ΦD denotes the set of valuations φ for which d(φ) = D. Thus, the set of all possible valuations for a countable set of variables V is\nΦ = ⋃\nD⊆V ΦD (1)\nIf D̂ = P f (V ) the finite powerset of V , and Φ the set of valuations with domains in D̂; we define the following operations on 〈Φ, D̂〉: (i) labeling: Φ → D̂;φ 7→ d(φ) (ii) combination: Φ × Φ 7→ Φ;(φ ,ψ) 7→ φ ⊗ ψ (iii) projection: Φ× D̂→Φ;(φ ,X) 7→ φ↓X for X ⊆ d(φ)\nThese are the basic operations of a valuation algebra. Using the view of valuations as pieces of information which refer to questions as valuations, the labelling operation tells us which set of variables the valuation refers to; the combination operation aggregates the information, and the projection operation focuses the information on a particular question (query) of interest. Projection is also referred to as focusing or marginalization. The following axioms are then imposed on 〈Φ, D̂〉:\n(A1) Commutative semigroup: Φ is associative and commutative under ⊗\n(A2) Labeling: For φ ,ψ ∈Φ, d(φ ⊗ψ) = d(φ)∪d(ψ). (A3) Projection: For φ ∈ Φ,X ∈ D̂ and X ⊆ d(φ), d(φ↓X ) = X . Alternatively this is equivalent to the following elimination operation, φ↓X = φ−(d(φ)\\X) where all the variables except those in X are eliminated.\n(A4) Transitivity: For φ ∈Φ and X ⊆ Y ⊆ d(φ), (φ↓Y )↓X = φ↓X . (A5) Combination: For φ ,ψ ∈ Φ with d(φ) = X , d(ψ) = Y and\nZ ∈ D such that X ⊆ Z ⊆ X ∪Y , (φ ⊗ψ)↓Z = φ ⊗ψ↓Z∩Y . (A6) Domain: For φ ∈Φ with d(φ) = X , φ↓X = φ .\nFor the intuitive reading of these axioms, we refer the reader to [17, 23].\nBefore proceeding to approximate inference, we formally define the inference problem:\nDefinition 1. The inference problem is the task of computing\nφ↓X = (φ1⊗·· ·⊗φr)↓X (2)\nfor a given knowledgebase {φ1, . . . ,φr} ⊆Φ; domain X is the query for the inference problem.\nNext we consider approximate inference. Existing approximation schemes, like the mini-bucket scheme [2] are either not general enough or do not provide a reliable measure of the approximation and\nhow to improve the approximation in an anytime algorithm. In this article, we have used the ordered valuation algebra framework defined in [5] as a basis for constructing an anytime algorithm. We thus review the extra axioms of the ordered valuation algebra framework, which introduces the notion of a partial order into the valuation algebra, and defines a partial combination operator ⊗t to construct approximate inference algorithms.\nFirstly we define a relation which represents an information ordering. If φ ,φ ′ are two valuations, then φ φ ′ means that φ is more complete than φ ′. Intuitively, the information contained in φ is more informative and a better approximation than the information contained by φ ′; generally this means φ ′ has a more compact or sparse representation than φ . Furthermore, we assume that this relation is a partial order. It is also reasonable to assume that approximations are only valid for valuations with equal domains; thus φ φ ′ implies d(φ) = d(φ ′) for all φ ,φ ′ ∈ Φ. Thus actually defines separate completeness relations D for each sub-semigroup ΦD.\nWe also impose the condition of each sub-semigroup ΦD having a zero element, denoted by nD, where φ ⊗ nD = nD⊗ φ = nD. For notational simplicity we shall also denote the neutral element by ∅ (without a subscript), denoting the appropriate neutral element corresponding to a particular domain.\nAn ordered valuation algebra is still a valuation algebra, so it retains all the axioms (A1)-(A6) introduced previously. The additional axioms are about how behaves under combination and marginalization:\n(A7) Partial order: There is a partial order on Φ such that φ φ ′ implies d(φ) = d(φ ′) for all φ ,φ ′ ∈Φ.\n(A8) Zero element: We assume that the zero element for the combination operation, nD is the least element of the approximation order D for all D⊆V . Also, since zero elements for a particular domain are unique, nD1 ⊗nD2 = nD1∪D2 for D1,D2 ⊆V . Also, n ↓D′ D = nD′ for all D′ ⊆ D.\n(A9) Combination preserves partial order: If φ1,φ ′1,φ2,φ ′ 2 ∈Φ are valuations such that φ1 φ ′1 and φ2 φ ′2, then φ1⊗φ2 φ ′1⊗φ ′2 (A10) Marginalisation preserves partial order: If φ ,φ ′ ∈ Φ are valuations such that φ φ ′, then φ↓D φ ′↓D for all D ⊆ d(φ) = d(φ ′).\nDefinition 2. The time-bounded combination operator [5] ⊗t : Φ×Φ→ Φ is used to approximate the exact computation during the propagation phase. ⊗t performs a partial combination of two valuations within time t units, where t ∈R+. The following properties are satisfied by ⊗t :\n(R1) φ1⊗φ2 φ1⊗t φ2.\n(R2) φ1⊗t ′ φ2 φ1⊗t φ2 for all t ′ > t.\n(R3) φ1⊗0 φ2 = nd(φ1)∪d(φ2).\n(R4) φ1⊗∞ φ2 = φ1⊗φ2.\nDefinition 3. Such a system 〈Φ,V, ,d,⊗,↓,⊗t〉 of valuations Φ, variables V , a completeness relation and a time-bounded combination operation ⊗t is called an ordered valuation algebra, if the labeling operations d, combination ⊗ and marginalization ↓ satisfy (A1)-(A10).\nDefinition 4. A binary join tree (BJT) N = 〈V,E〉 corresponding to a knowledgebase {φ1, . . . ,φr} is a covering junction tree for the\ninference problem, constructed in a manner such that the tree is binary. The valuations in the knowledgebase form the leaves of the tree, thus |V (N)| = 2r− 1, |E(N)| = 2r− 2, while the query X ⊆ d(root(N)). Inference takes place by message passing in the BJT (for details of the algorithm, see [22, 5]). In the next section we shall modify this message passing algorithm to cache partial valuations for anytime inference."
    }, {
      "heading" : "3 Anytime Ordered Valuation Algebras",
      "text" : "In this section, we augment ordered valuation algebras in a structure we refer to as anytime ordered valuation algebras. We introduce the extension, and in the following section give examples of anytime ordered valuation algebras. The primary purpose of introducing anytime ordered valuation algebras is to develop an anytime inference algorithm within the framework of generic inference. Such extensions preserve the generic structure of valuation algebras, but add restrictions to simplify or add features to the inference algorithm; in another instance, valuation algebras were extended to weighted valuation algebras to study communication complexity [18].\nBefore defining anytime ordered valuation algebras, we define a couple of prerequisites; the composition operation and a truncation function.\nDefinition 5. The composition operator,⊕ : Φ×Φ→Φ;(φ ′,φ ′′) 7→ φ combines valuations φ ′ and φ ′′ into a valuation φ more complete than either (φ φ ′,φ φ ′′). This is not to be confused with the combination operation ⊗ which generally combines valuations from different domains. The valuations being composed belong to the same approximation order D, where D = d(φ ′) = d(φ ′′) = d(φ). It is natural in this context to consider whether composition should be a supremum operation. However, this cannot be assumed in general.\nDefinition 6. The truncation function ρ : Φ×R+ → Φ performs a truncation of the information contained in the valuation, according to the real valued parameter. Also, ρ is defined to be monotonically increasing with the real valued parameter, thus ρ(φ ,k) ρ(φ ,k′) whenever k ≥ k′.\nThe time-bounded combination operation ⊗t can be recast such that truncation of the original pair of valuations followed by exact combination is equivalent to doing a time-bounded combination:\nφ1⊗t φ2 = ρ(φ1,k1)⊗ρ(φ2,k2) (3)\nThe parameters k1,k2 determining the truncated portions of φ1,φ2 will be important later in defining the partial valuations which will be used in the refinement algorithm for anytime inference. As k1,k2 are parameters that depend on the particular valuations φ1,φ2 and the time t, this assumes a function K(φ1,φ2, t) = (k1,k2).\nFollowing these two definitions, we extend the system of axioms (A1-A10) for ordered valuation algebras, with the properties (P1) and (P2):\n(P1) The combination operation ⊗ distributes over ⊕:\n(φ ′1⊕φ ′′1 )⊗ (φ ′2⊕φ ′′2 ) = (φ ′1⊗φ ′2)⊕ (φ ′1⊗φ ′′2 )⊕ (φ ′′1 ⊗φ ′2)⊕ (φ ′′1 ⊗φ ′′2 )︸ ︷︷ ︸ REFINE′(φ ′1,φ ′′1 ,φ ′2,φ ′′2 )\n(4)\nHere, φ ′1⊗ φ ′2 = ρ(φ1,k1)⊗ρ(φ2,k2) is a truncated valuation of the exact combined valuation φ1⊗φ2; REFINE′ is the part of the exact valuation that needs to be composed with the truncated valuation φ ′1 ⊗ φ ′2 to complete the valuation. We also use the time-bounded operation REFINE′t for the same operation bounded by a time t, with an analogous definition in terms of truncation functions as ⊗t in equation 3:\nREFINE′t(φ ′ 1,φ ′′ 1 ,φ ′ 2,φ ′′ 2 ) = REFINE ′(φ ′1,ρ(φ ′′ 1 ,k1),φ ′ 2,ρ(φ ′′ 2 ,k2))\n(5) where the parameters k1,k2 are obtained from an assumed function K′(φ1,φ ′1,φ ′ 2,φ ′′ 2 , t) = (k1,k2).\n(P2) The projection operation ↓ distributes over ⊕:\n(φ ′⊕φ ′′)↓D = φ ′↓D⊕φ ′′↓D,D⊆ d(φ). (6)\nWe can now formally define the anytime ordered valuation algebra.\nDefinition 7. An anytime ordered valuation algebra is an ordered valuation algebra 〈V,Φ,d,⊗,↓,⊗t , 〉 with the additional operations of composition ⊕ and the function ρ , making the structure 〈V,Φ,d,ρ,⊗,↓,⊕,⊗t , 〉, which satisfies properties (P1) and (P2).\nWe show by construction that the composition operator ⊕ : Φ×Φ→ Φ with (P1, P2) along with the truncation function ρ : Φ×R+→Φ is sufficient to construct a refinement algorithm to improve the accuracy of a valuation.\nTo describe a refinement algorithm to improve upon the result provided by INWARD(N, t), we need to cache the partial valuations at each step so that we can use REFINE′ to improve upon them. We use a modified version of the propagation algorithm [22, 5], where τ and τ̄ store the partial and complementary partial valuations respectively for a particular BJT node, where the complementary partial valuation ρ̄(φ ,k) is such that ρ̄(φ ,k)⊕ρ(φ ,k)= φ . In the following procedures, ∆(n) = d(n)\\d(P(n)) is the set of variables to be eliminated as we propagate messages to the parent node. To get the solution to the inference problem at the final step, we also define ∆(root(N)) = d(root(N))\\X where X is the query. There are r valuations in the knowledgebase resulting in r−1 combination steps in the BJT. P(n) is the parent of n, φ(n) is the valuation at node n, φs(n) is the message from n to P(n); L(n),R(n) are the left and right nodes of n respectively and\nnext(N) = {n ∈ N : φs(n) = nil,φs(L(n)) 6= nil,φs(R(n)) 6= nil} (7)\nBoth INWARD(N, t) and REFINE(N, t) return valuations which are the (approximate) solution to the inference problem.\n1: procedure INWARD(N, t) 2: s← r−1; 3: initialise timer to t units. 4: for all n ∈ leaves(N) do φs(n)← φ(n)−∆(n) 5: while next(N) 6= /0 do 6: select n ∈ next(N) 7: (k1,k2)← K(φs(L(n)),φs(R(n)), t/s) 8: φ(n)← φs(L(n))⊗t/s φs(R(n)) 9: τ(L(n))← ρ(φs(L(n)),k1)\n10: τ(R(n))← ρ(φs(R(n)),k2) 11: τ̄(L(n))← ρ̄(φs(L(n)),k1)"
    }, {
      "heading" : "12: τ̄(R(n))← ρ̄(φs(R(n)),k2)",
      "text" : "13: φs(n)← φ(n)−∆(n) 14: s← s−1 15: t← timer() 16: end while 17: return φs(root(N)) 18: end procedure\nWe can use the cached partial valuations in τ and τ̄ to define the refinement algorithm that follows in a similar manner to the algorithm in [6].\n1: procedure REFINE(N, t) 2: initialise timer to t units 3: s← r−1 4: while next(N) 6= /0 do 5: select n ∈ next(N) 6: (k1,k2)← K′(τ(L(n)), τ̄(L(n)),τ(R(n)), τ̄(R(n)), t/s) 7: ν ← REFINE′t/s(τ(L(n)), τ̄(L(n)),τ(R(n)), τ̄(R(n))) 8: t← timer() 9: τ(L(n))← τ(L(n))⊕ρ(τ̄(L(n)),k1)\n10: τ(R(n))← τ(R(n))⊕ρ(τ̄(R(n)),k2) 11: τ̄(L(n))← ρ̄(τ̄(L(n)),k1) 12: τ̄(R(n))← ρ̄(τ̄(R(n)),k2) 13: φ(n)← φ(n)⊕ν 14: τ̄(n)← τ̄(n)⊕ν−∆(n) 15: s← s−1 16: end while 17: return φs(root(N)) 18: end procedure\nThis procedure refines the existing valuations in the binary join tree N, taking at most time t units. We ensure that the algorithm is interruptible in lines 9–12 using appropriate caching of partial valuations. A diagram of the truncation of a valuation is shown below to illustrate anytime refinement.\nφk φk φ(exact) uncomputed\nHere, and in the following proof, the notation φ k := ρ(φ ,k) and φk := ρ̄(φ ,k). We shall also abbreviate the notation τ(L(n)) as τL and τ̄(L(n)) as τ̄L (accordingly for R(n)), and τ̄(n) as τ̄ . The shaded region φ k is the part that has already been combined, while φk represents the cached part that has not been combined yet. The dotted region represents the part of φ that is yet uncomputed, due to truncated messages from child nodes; line 14 in REFINE(N, t) shrinks the uncomputed portion by extending τ̄ .\nTheorem 1 (Soundness of anytime inference). If φ[t0,t1,...,t j ] is the valuation returned after the following invocations:[ INWARD(N0, t0 > 0), REFINE(N1, t1), . . . , REFINE(N j, t j) ] , where Nk+1 is the modified BJT with the cached valuations after step k, then φ[t0] φ[t0,t1] ·· · φ[t0,t1,...,t j ] ·· · φ where φ is the exact valuation. The sequence becomes strictly increasing (upto the exact\nvaluation) if ti > tε for all i > 0 where tε is the minimum time required for the refinement to update one valuation.\nProof. We split the proof into two parts: (S1) proving that the sequence of valuations returned from successive calls to REFINE are partially ordered and (S2) showing the upper bound is the exact valuation, to which the partial valuations converge after a finite time.\nProving (S1) is trivial; for each node, φ is updated once (line 13), thus φ ′ = (φ ⊕ν) φ , where φ ′ is the valuation at node n after a call to REFINE. Using transitivity of the partial order, we obtain (S1). In the case when ti > tε , at least one valuation is updated, resulting in ν ∅, which gives φ ′ φ .\nTo prove (2) we shall note the following statements\n(T1) (φk)m = (φ k+m)k\n(T2) φ k⊕φk = φ\n(T3) φ k⊕ (φk)m = φ k+m\n(T4) (φk)m = φk+m\nFor notational simplicity, only for the following proof, we denote φψ := φ ⊗ψ and + :=⊕.\nSince each node is only updated once, we can consider a particular node; let’s denote by φ the valuation at node n after INWARD(N, t0). If (k1,k2) are the parameters obtained from K′ in REFINE(N1, t1) then the updated valuation φ ′ = φ + τLτ̄k2R + τ̄ k1 L τR + τ̄ k1 L τ̄ k2 R , where φ = τLτR.\nHere we note that we can replace (τ̄L,R)k with their exact counterpart (τ̄∞L,R)\nk, where we use the τ̄∞ to denote the exact valuation. This can be done as the truncation function is invariant under extension of the valuation to incorporate previously uncomputed information. Following this, we shall drop the superscript and use τ̄L to denote τ̄∞L .\nThen if we consider a subsequent call, REFINE(N2, t2), φ ′′ = φ ′+ τ ′Lτ̄ ′m2 R + τ̄ ′m1 L τ ′ R + τ̄ ′m1 L τ̄ ′m2 R . where the additional prime indicates the the value for this iteration, and (m1,m2) are the parameters obtained from K′.\nFrom lines 9–12 in REFINE we get: τ ′L = τL + τ̄ k1 L , τ ′ R = τR + τ̄ k2 R ,\nτ̄ ′L = (τ̄L)k1 , τ̄ ′ R = (τ̄R)k2\nExpanding φ ′′ we get:\nφ ′′ = τLτR + τLτ̄k2R + τ̄ k1 L τR + τ̄ k1 L τ̄ k2 R\n+ (τL + τ̄k1L )(τ̄R,k2) m2 +(τ̄L,k1) m1(τR + τ̄k2R )+(τ̄L,k1) m1(τ̄R,k2) m2\n= τLτR + τLτ̄k2R + τ̄ k1 L τR + τ̄ k1 L τ̄ k2 R + τL(τ̄R,k2) m2\n+(τ̄k1L )(τ̄R,k2) m2 +(τ̄L,k1) m1 τR +(τ̄L,k1)τ̄ k2 R +(τ̄L,k1) m1(τ̄R,k2) m2\n= τLτR + τLτ̄k2+m2R + τ̄ k1+m1 L τR + τ̄ k1+m1 L τ̄ k2+m2 R\nHere we use (T1,T3) to simplify the expression. Note that this is the same form as φ ′ = φ + τLτ̄k2R + τ̄ k1 L τR + τ̄ k1 L τ̄ k2 R , with k1 → k1 +m1, k2 → k2 +m2. Thus, subsequent calls to REFINE will always result in φ having the same form by induction. From the definition of the truncation function, φ k φ k′ for k ≥ k′, from which (S1) follows as well, by preservation of partial order under combination and composition. To show (S2) we note that for finite valuations, there exists k, such that φ k = φ . As the exponent is monotonically increasing with subsequent calls to REFINE, we shall eventually get φ[t0,t1,...,t j ] = τLτR + τLτ̄R + τ̄LτR + τ̄Lτ̄R = (τL + τ̄L)(τR + τ̄R), the\nexact valuation at node n. Thus, we shall eventually get the exact valuation at the root after finite invocations of REFINE.\nTheorem 2 (Completeness of anytime inference). If φ[t0,t] is the valuation returned after the following invocations: [INWARD(N, t0 > 0), REFINE(N′, t)], where N′ is the modified BJT with the cached valuations after the call to INWARD(N, t0), then there exists a T such that for all t ≥ T φ[t0,t] = φ = ( ⊗ ψ∈Φ ψ)↓X , the exact solution to the inference problem.\nProof. We consider two cases:\nCase 1: INWARD(N, t0) has performed exact inference.\nWe shall show that REFINE(N, t) is a null operation which does not change φ ,τ, τ̄; then the statement of the theorem follows if we set T = t0.\nφ ′ = φ ⊕ν (line 13), so if we show ν =∅, we are done.\nν = REFINE′t/s(τL, τ̄L,τR, τ̄R), but τ̄L = τ̄R =∅ as τ̄ represents the partial valuation that has not been combined, which is null for the exact inference case. Thus ν =∅.\nCase 2: INWARD(N, t0) gives a partial result.\nIn general, ν is also a partial valuation due to the time restriction. Since we are operating on finite datasets, the combination operation at a particular node in REFINE′ takes a finite amount of time, say tn. Thus REFINE′tn at a node n is the exact refinement, making φ(n) exact after line 13, and thus m(root(N)) is exact after completion of the propagation. So we set T = ∑n∈V tn to get the time bound, such that for all t ≥ T we get the exact result."
    }, {
      "heading" : "4 Instances of anytime ordered valuation algebras",
      "text" : "In the following sections, we describe instances of anytime ordered valuation algebras. Specifically we show that the important class of semiring induced valuation algebras, [9], can be considered as anytime ordered valuation algebras. We also remark on the application of our framework to belief potentials."
    }, {
      "heading" : "4.1 Semiring induced valuation algebras",
      "text" : "Semiring induced valuation algebras are a subclass of valuation algebras with several useful instances like probability potentials and disjunctive normal forms. We use the definition of semiring induced valuation algebras from [9] and review the following standard notation. The semiring is denoted by A = 〈A,+,×〉 with the semiring operations +,× on a set A, where +,× are assumed to be commutative and associative, with × distributing over +. Lowercase letters like x are variables, with a corresponding finite set of values for x, called the frame of x and denoted by Ωx. Each Ωx also has an associated total order on its elements. If the frame has two elements, then it is the frame of a binary variable. If the binary elements represent true and false, then we call the variable propositional. For a domain D⊆V where V is the set of all variables in the system, the corresponding set of possible values becomes the Cartesian product ΩD = ∏{Ωx : x ∈ D}, whose elements x ∈ΩD are called D-configurations or D-tuples. For a subset D′ ⊆ D, x↓D′ ∈ ΩD′ is the projection of x to D′. Where D\nis empty, we use the convention that the frame is a singleton set: Ωφ = { }. Any set of D-configurations can be ordered using a lexicographical order.\nDefinition 8. An A -valuation φ with domain D associates a value in A with each configuration x ∈ΩD, i.e. φ is a function φ : ΩD→ A.\nThe set of all such A -valuations with a domain D is denoted by ΦD, and the union of all such sets with D ⊆ V is the set of all A -valuations Φ. The operations +,× on A then induce a valuation algebra structure on 〈Φ,P f (V )〉 where P f (V ) is the finite powerset of the set of variables V [9, Theorem 2], using the following definitions of combination and projection:\n1. Combination: ⊗ : Φ×Φ→Φ defined for x ∈Ωd(φ)∪d(ψ) by\nφ ⊗ψ(x) = φ(x↓d(φ))×ψ(x↓d(ψ)) (8)\n2. Projection: ↓: Φ×D→Φ defined for all φ ∈Φ and T ⊆ d(φ) for x ∈ΩT by\nφ↓T (x) = ∑ z∈Ωd(φ): z↓T=x φ(z) (9)\nTheorem 3. Semiring induced valuation algebras, provided the underlying semiring has a zero element, form an ordered valuation algebra.\nProof. To show semiring induced valuation algebras are an ordered valuation algebra, we have to show (A7-A10):\n(A7) The preorder is defined by φ φ ′ iff φ(x) A φ ′(x) for all x ∈Ωd(φ), where A is the preorder on the semiring [9, Prop. 1, p1362] defined as b A a iff a = b or there exists c such that a+c = b, with d(φ) = d(φ ′) as it only makes sense to compare valuations on the same domain. However we need a partial order for this axiom, which is possible if the additive monoid is positive, has a zero element and is cancellative:\nLemma 4. The preorder defined on a positive, cancellative, commutative monoid, 〈A,+〉 with a zero element, is a partial order.\nProof. A preorder implies a b iff a+ c = b. For a partial order, we need asymmetry: if a b and b a, then a = b.\na b implies there exists c such that a+ c = b; similarly there exists d such that b+d = a; substituting gives us b+d + c = b+0, the cancellative property implies d+ c = 0 and the positivity property implies c = d = 0, implying a = b, and we have a partial order.\n(A8) Zero element: Most common instances of semiring induced valuation algebras have a zero element. Specifically semirings with zero elements induce valuation algebras with the zero element nD such that nD(x) = 0 for all x ∈ΩD.\n(A9, A10) Combination and marginalisation preserve partial order. This follows from the fact that × and + preserve partial order in the underlying semiring structure.\nHaving shown that semiring induced valuation algebras satisfy the ordered valuation algebra axioms (A7–A10) provided the underlying semiring has a zero element and the additive commutative monoid is\ncancellative and positive, we proceed to define the composition and truncation functions for semiring induced valuation algebras.\n1. We denote the composition operator on semiring induced valuation algebras as (φ ⊕φ ′)(x) = φ(x)+φ ′(x), d(φ) = d(φ ′) 2. The function ρ is defined on the semiring induced valuation algebra as ρ(φ ,k) = the first k (lexicographically ordered on x) elements of graph(φ); where graph(φ) = {(x,φ(x)) | x ∈Ωd(φ)}. For efficient implementation, we only store (x,φ(x)) where φ(x) 6= 0. In case the semiring has a total order (as in the case of probability potentials), we order the configurations in decreasing weight order: [(xi,φ(xi)), . . .] where φ(xi)≥ φ(x j) for i≤ j.\nWe also define the time-bounded combination operation φ1 ⊗t φ2, where Lφ1 = [(x1,φ1(x1)), . . .], and Lφ2 = [(y1,φ2(y1)), . . .]. xy denotes the configuration in Ωd(φ1)∪d(φ2) such that (xy)\n↓d(φ1) = x and (xy)↓d(φ2) = y.\nWe define helper functions INSERT, which inserts a combination into the configuration space provided there is a common support and COMBINE-EXTEND which incrementally adds combinations into the configuration and updates the state, going from the state ρ(φ1, i)⊗ ρ(φ2, j) to ρ(φ1, i+ i′)⊗ρ(φ2, j+ j′). Finally we define COMBINE which performs the combination operation within the allocated time constraint.\n1: function INSERT(φ1,φ2, i, j,L) 2: x = Lφ1 ;y = Lφ2 3: if x↓D1∩D2i = y ↓D1∩D2 r then 4: insert [xiy j,φ1(xi)×φ2(y j)] into L. 5: end if 6: end function\n1: function COMBINE-EXTEND(φ1,φ2,〈i, j,L〉, i′, j′) 2: for k← 1 to i+ i′ do 3: for m← j to j+ j′ do 4: INSERT(φ1,φ2,k,m,L) 5: end for 6: end for 7: for k← i to i+ i′ do 8: for m← 1 to j+ j′ do 9: INSERT(φ1,φ2,k,m,L)\n10: end for 11: end for 12: return 〈i, j,L〉 13: end function\n1: function COMBINE(φ1,φ2, t) 2: L← 〈〉; i← 1; j← 1;n1← |Lφ1 |;n2← |Lφ2 | 3: initialise timer to t units 4: while timer()> 0 and i≤ n1 and j ≤ n2 do 5: 〈i, j,L〉 ← COMBINE-EXTEND(φ1,φ2,〈i, j,L〉,0,1) 6: if not timer()> 0 then 7: break 8: end if 9: 〈i, j,L〉 ← COMBINE-EXTEND(φ1,φ2,〈i, j,L〉,1,0)\n10: end while 11: if i > n1 then\n12: m← j+1 13: while timer()> 0 and m≤ n2 do 14: 〈i, j,L〉 ← COMBINE-EXTEND(φ1,φ2,〈i, j,L〉,0,1) 15: m← m+1 16: end while 17: else 18: m← i+1 19: while timer()> 0 and m≤ n1 do 20: 〈i, j,L〉 ← COMBINE-EXTEND(φ1,φ2,〈i, j,L〉,1,0) 21: m← m+1 22: end while 23: end if 24: return valuation corresponding to L 25: end function\nTheorem 5. Semiring induced valuation algebras, provided the underlying semiring has a zero element, along with the composition operator and the truncation function defined above form an anytime ordered valuation algebra.\nProof. Semiring induced valuation algebras form an ordered valuation algebra as shown in Theorem 3. To show that they also constitute an anytime ordered valuation algebra, we have to show properties (P1, P2), i.e. combination and projection distribute over ⊕:\n(P1) If p1 = p′1⊕ p′′1 and p2 = p′2⊕ p′′2 then we have to show that: p1⊗ p2 = (p′1⊗ p′2)⊕ (p′1⊗ p′′2)⊕ (p′′1⊗ p′2)⊕ (p′′1⊗ p′′2).\nLHS applied to x is p1(x↓S)× p2(x↓T ), where d(p1) = S and d(p2) = T .\nRHS is (p′1(x ↓S)× p′2(x↓T ))+(p′1(x↓S)× p′′2(x↓T ))+\n(p′′1(x ↓S)× p′2(x↓T ))+(p′′1(x↓S)× p′′2(x↓T ))\n= (p′1(x ↓S)+ p′′1(x ↓S))× (p′2(x↓S)+ p′′2(x↓T ) = LHS using distributivity of×over + .\n(P2) We have to show that if p = p′⊕ p′′ that p↓D = p′↓D⊕ p′′↓D, where D ⊆ d(p). The LHS applied to x is p↓D(x) = ∑z↓D=x p(z) = ∑z↓D=x(p′⊕ p′′)(z), and the RHS is\n(p′↓D⊕ p′′↓D)(x) = p′↓D(x)+ p′′↓D(x)) = ∑\nz↓D=x p′(z)+ ∑ z↓D=x p′′(z) = ∑ z↓D=x (p′⊕ p′′)(z)\nwhere we use the associativity and commutativity of +.\nAs stated earlier, several common instances of valuation algebra can be considered as semiring induced. We present a couple of important examples below:\nExample 1. Probability potentials are semiring induced valuation algebras on R+ with the semiring operations being the arithmetic addition and multiplication. Also known as arithmetic potentials, these describe (unnormalised) probability distributions, and thus inference in probabilistic graphical models.\nExample 2. Disjunctive normal forms (abbreviated as DNF) are of the form α1∨α2 · · ·∨αn where αi is of the form x1∧x2∧·· ·∧xk and x j is a literal; either a logical variable or its negation. All frames are binary reflecting true and false values respectively. DNF potentials\nare induced by the semiring with + and × being defined as a+b = max(a,b) and a×b=min(a,b); which are equivalent to the definition of logical-or and logical-and.\nThere are many other examples of semiring induced valuation algebras, a detailed introduction to which can be found in [9]. In certain cases, the valuation algebra induced by the semiring has the idempotent property, i.e. φ ⊗φ = φ ; then we may use more efficient architectures for local computation such as the Lauritzen-Spiegelhalter architecture [10].\nIt is also pertinent to mention that for DNF potentials, one can alternately consider the valuation algebra over the formulae itself instead of the models [11], which simplifies computation extensively. This alternative representation is also an anytime ordered valuation algebra, but we have omitted the proof for the purposes of brevity."
    }, {
      "heading" : "4.2 Belief functions",
      "text" : "Belief potentials are a generalisation of probability potentials to subsets of the configuration space in Dempster-Shafer’s theory of evidence [21]. The advantage of belief potentials over standard probability theory is in their ability to express partially available information in a manner not possible in probability theory. This is the reason for the usage of belief functions in sensor network literature, which involves fusion of information from various sources [14, 4, 20, 27].\nFor the instance of belief functions, with the composition operator defined as [φ ⊕φ ′]m(A) = [φ ]m(A)+ [φ ′]m(A), where [φ ]m is the mass function associated with the belief function φ , our framework specialises to anytime inference in belief potentials as described in [6].\nTheorem 6. Belief functions, along with the composition operator defined above, and the truncation operation ρ(φ ,k) as the potential that contains the k focal sets of φ with the highest masses, form an anytime ordered valuation algebra.\nProof. Belief functions already form an ordered valuation algebra [5], as well as permit anytime inference [6]. The anytime inference algorithm in [6] turns out to be a specific case of the generic anytime inference framework presented in this article. In particular if we denote⊕ :=+ in their notation, and the truncation function ρ(φ ,k) := ρk(φ) then [6, Theorem 9,10] shows that belief functions also form an anytime ordered valuation algebra according to the axioms in Section 3."
    }, {
      "heading" : "5 Complexity Analysis",
      "text" : "The anytime inference algorithm presented in Section 3 hides the time complexity of approximate inference by restricting the accuracy of the valuations. While we don’t have an explicit control over the accuracy, we can improve it by allocating more time to the refinement algorithm. In this section, we take an alternative approach of focussing on accuracy and estimating the time complexity, which also allows us to use a tuning parameter which scales from zero accuracy (null valuations) to the valuation obtained after exact inference.\nSince complexity of exact (and approximate) inference depends upon the complexity of the combination operation (usually the more\ntime-consuming operation among combination and focussing), we consider the specific instance of semiring-induced valuation algebras. As there are n valuations, φ1, . . . ,φn, the resulting BJT N will have 2n−1 nodes, n of which are the valuations themselves at the leaves of the tree. We denote the maximum frame size of a variable in the semiring induced valuation algebra as m := max{|Ωx|,x ∈V}. As we are representing semiring induced valuations in memory in terms of a tuple of the configuration and its associated value, the number of words required to represent the configuration is a key component in the time and communication complexity. The upper bound on the size of the configuration space for a valuation is thus m|d(φ)|.\nDefinition 9. The approximation parameter k is a tunable parameter that goes from 0 to mω , where ω is the treewidth of the binary join tree N.\nmω is the maximum size of the configuration space that we have to process during the inward or outward propagation phase of the Shenoy-Shafer algorithm. Now we can define the following.\nDefinition 10. The approximate combination operation⊗k : Φ×Φ→ Φ is defined as combining the elements of the configuration space of the valuations in a semiring-induced valuation algebra, until we get k resultant elements.\nLemma 7. The complexity of the approximate combination operator ⊗k is O(k).\nProof. The worst-case scenario is when the configuration spaces are independent (no variables in common). Then there is no requirement for common support and we can take the pairwise multiplication of the elements of the configuration space, till we get k elements, giving us O(k) complexity.\nThe INWARD-APPROX(N,k) algorithm is defined similarly to the INWARD algorithm, with the instances of the time-bound combination operator ⊗t replaced by the approximate combination operator ⊗k. In the following, K(φ ,ψ,k) returns (k1,k2) such that ρ(φ ,k1)⊗ρ(ψ,k2) has at most k elements.\nfunction INWARD-APPROX(N,k) for all n ∈ leaves(N) do φs(n)← φ(n)−∆(n) while next(N) 6= /0 do\nselect n from next(N) (k1,k2)← K(φs(L(n)),φs(R(n)),k) φ(n)← φs(L(n))⊗k φs(R(n)); φs(n)← φ(n)−∆(n) τ(L(n))← ρ(φs(L(n)),k1) τ(R(n))← ρ(φs(R(n)),k2) τ̄(L(n))← ρ̄(φs(L(n)),k1) τ̄(R(n))← ρ̄(φs(R(n)),k2) φs(n)← φ(n)−∆(n) s← s−1\nend while end function\nTheorem 8. The time complexity of INWARD-APPROX(N,k) in the Shenoy-Shafer architecture, with the approximation parameter of k, given that there are n valuations in the knowledgebase is O((n−1)k).\nProof. There are n−1 combinations as the number of combinations in the binary join tree is the same as the number of non-leaf nodes. As each combination has a complexity of O(k), we get a complexity of O((n− 1)k). Projection has a complexity of O(k) as there are k elements in the configuration space, so at most k− 1 summations, which is the case when we are marginalising to the null set (equivalent to eliminating all the variables), thus it does not change the asymptotic complexity.\nWe get the same time complexity for an analogous REFINE-APPROX algorithm, with a modification to lines 6–7 of REFINE to combine at most k elements.\nMatching in the exact inference case. In the exact inference case, the complexity is known to be in the class #P-hard. In the discussion on complexity [17], Kohlas and Pouly derive the estimate O(|V |. f (ω)) where ω is the treewidth, with f (x) = mx for the case of semiring induced valuation algebras with variables having a upper bound frame size of m. |V | is the number of vertices in the join tree. Substituting |V | = n,k = mω in the time complexity O(n− 1)k and taking k = mω , we get the same time complexity as the exact inference case; thus the approximate time complexity obtained in terms of the approximation parameter k gives us a transition from k = 0 (null valuations, obtained when we set the t = 0 in INWARD(N, t)) to k = mω , the exact inference case.\nEstimation of accuracy from elapsed time. It can be useful to derive an estimate of the accuracy of a valuation given the elapsed time of the algorithm in specific cases. Here, we shall consider the example of probability potentials. The time-bound combination operator combines the configurations with the largest weight first so that we get diminishing returns; the accuracy also depends on the sparsity of the probability potential. For simplicity we consider uniform distributions, where the weights are uniformly distributed in the configuration space. Then we can state the following:\nLemma 9. The fractional error estimate compared to the exact probability potential is\nε(t) = 1−max ( 1, t\nmω c(n−1)\n) (10)\nwhere ω is the treewidth, c is the constant time required to combine two elements in the configuration space, and n is the number of valuations in the knowledgebase.\nProof. As each configuration has an uniform weight, the accuracy of combination at the root node (which is the solution to the inference problem obtained from the inward propagation algorithm) is directly proportional to the allocated time which is on average t/(n− 1) as there are n− 1 combinations. Considering that each combination takes c units, and in the worst-case each configuration has weight 1/mω (for a normalised potential; for unnormalised, this introduces a constant factor which is cancelled out by considering a fractional error estimate), we get the fractional error estimate as above.\nAs can be easily seen, ε(0) = 1, and ε(O((n−1).mω )) = 0 where O((n−1).mω ) is the exact inference time complexity."
    }, {
      "heading" : "6 Implementation",
      "text" : "We implemented the anytime inference algorithm using the Python programming language, on a Core i5 CPU with 4GB RAM. While we have shown anytime inference in a Bayesian network here, the framework, being generic, can be applied to other valuation algebras which satisfy the necessary axioms.\nThe figure shows progress of anytime inference on the CHILD dataset, which was used as a case study for exact inference in [1]. The progress is shown as a function of the fractional error estimate with time units (the actual total time for the series of successive refinements, up to the exact valuation is < 10s):\nε(t) = 1− ∑ Lφt\n∑Lφ (11)\nHere the sum is over the weights of the configurations Lφ of a valuation φ ; φt is the valuation obtained at the root after time t, and φ is the exact valuation. As expected, the fractional error estimate converges to zero as we obtain the exact valuation."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this work, we have shown that we can construct anytime algorithms for generic classes of valuation algebras, provided certain conditions are satisfied. We have also shown that the important subclass of semiring induced valuation algebras admit an anytime inference algorithm as they meet the aforementioned conditions. This is useful as semiring induced valuation algebras include important valuation algebra instances like probability potentials, DNF potentials and relational algebras, among others.\nFrom a broader perspective, the advantage of operating in the generic framework of valuation algebras has been addressed before [17]; we can target a large class of problems using a unified framework; the inference or projection problem can be found in various forms: Fourier transforms, linear programming and constraint satisfaction problems. Enriching the valuation algebra structure through extensions is thus useful. Anytime inference in particular has a wide spectrum of applications. We also plan to study the applicability of our framework across these various domains in future work.\nWe are currently working on implementation of other instances of anytime ordered valuation algebras, as well as conducting a complexity analysis of the algorithm in a distributed setting using the Bulk Synchronous Parallel [26] model."
    } ],
    "references" : [ {
      "title" : "Probabilistic networks and expert systems, exact computational methods for Bayesian networks",
      "author" : [ "Robert G Cowell", "A Philip Dawid", "Steffen L Lauritzen", "David J Spiegelhalter" ],
      "venue" : "series: information science and statistics,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2007
    }, {
      "title" : "Bucket elimination: A unifying framework for probabilistic inference’, in Learning in graphical models, 75–104",
      "author" : [ "Rina Dechter" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1998
    }, {
      "title" : "A generalization of Bayesian inference",
      "author" : [ "Arthur P Dempster" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Methodological),",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1968
    }, {
      "title" : "A neural network classifier based on Dempster-Shafer theory’, Systems, Man and Cybernetics, Part A: Systems and Humans",
      "author" : [ "Thierry Denoeux" ],
      "venue" : "IEEE Transactions on,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2000
    }, {
      "title" : "Ordered valuation algebras: a generic framework for approximating inference",
      "author" : [ "Rolf Haenni" ],
      "venue" : "International Journal of Approximate Reasoning,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2004
    }, {
      "title" : "Resource bounded and anytime approximation of belief function computations",
      "author" : [ "Rolf Haenni", "Norbert Lehmann" ],
      "venue" : "International Journal of Approximate Reasoning,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2002
    }, {
      "title" : "An anytime algorithm for decision making under uncertainty",
      "author" : [ "Michael C Horsch", "David Poole" ],
      "venue" : "Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1998
    }, {
      "title" : "Dempster’s rule as seen by little colored balls",
      "author" : [ "Audun Jøsang", "Simon Pope" ],
      "venue" : "Computational Intelligence,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "Semiring induced valuation algebras: Exact and approximate local computation algorithms",
      "author" : [ "Juerg Kohlas", "Nic Wilson" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2008
    }, {
      "title" : "Information algebras: Generic structures for inference",
      "author" : [ "Jürg Kohlas" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2003
    }, {
      "title" : "Propositional information systems",
      "author" : [ "Jürg Kohlas", "Rolf Haenni", "Serafı́n Moral" ],
      "venue" : "Journal of Logic and Computation,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1999
    }, {
      "title" : "Probabilistic Graphical Models: Principles and Techniques, Adaptive Computation and Machine Learning",
      "author" : [ "Daphne Koller", "Nir Friedman" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2009
    }, {
      "title" : "Readings in uncertain reasoning’, chapter Local Computations with Probabilities on Graphical Structures and Their Application to Expert Systems, 415–448",
      "author" : [ "S.L. Lauritzen", "D.J. Spiegelhalter" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1990
    }, {
      "title" : "Dempster-Shafer theory for sensor fusion in autonomous mobile robots",
      "author" : [ "Robin R Murphy" ],
      "venue" : "Robotics and Automation, IEEE Transactions on,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1998
    }, {
      "title" : "Reverend Bayes on inference engines: a distributed hierarchical approach, Cognitive Systems Laboratory, School of Engineering and Applied Science, University of California",
      "author" : [ "J. Pearl" ],
      "venue" : "Los Angeles,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1982
    }, {
      "title" : "NENOK – A software architecture for generic inference",
      "author" : [ "Marc Pouly" ],
      "venue" : "International Journal on Artificial Intelligence Tools,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2010
    }, {
      "title" : "Generic Inference: A Unifying Theory for Automated Reasoning, Wiley-Blackwell",
      "author" : [ "Marc Pouly", "Juerg Kohlas" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2011
    }, {
      "title" : "Minimizing communication costs of distributed local computation",
      "author" : [ "Marc Pouly", "Jürg Kohlas" ],
      "venue" : "Technical report,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2005
    }, {
      "title" : "Anytime anyspace probabilistic inference",
      "author" : [ "Fabio Tozeto Ramos", "Fabio Gagliardi Cozman" ],
      "venue" : "International Journal of Approximate Reasoning,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2005
    }, {
      "title" : "Combination of evidence in Dempster- Shafer theory, volume 4015",
      "author" : [ "Kari Sentz", "Scott Ferson" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2002
    }, {
      "title" : "Binary join trees for computing marginals in the Shenoy-Shafer architecture",
      "author" : [ "Prakash P Shenoy" ],
      "venue" : "International Journal of approximate reasoning,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1997
    }, {
      "title" : "Axioms for probability and belieffunction propagation",
      "author" : [ "Prakash P Shenoy", "Glenn Shafer" ],
      "venue" : "Classic Works of the Dempster-Shafer Theory of Belief Functions,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2008
    }, {
      "title" : "Anytime classification using the nearest neighbor algorithm with applications to stream mining’, in Data Mining, 2006. ICDM’06",
      "author" : [ "Ken Ueno", "Xiaopeng Xi", "Eamonn Keogh", "Dah-Jye Lee" ],
      "venue" : "Sixth International Conference on,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2006
    }, {
      "title" : "The complexity of enumeration and reliability problems",
      "author" : [ "Leslie G Valiant" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1979
    }, {
      "title" : "A bridging model for parallel computation",
      "author" : [ "Leslie G. Valiant" ],
      "venue" : "Commun.  ACM,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1990
    }, {
      "title" : "Alert confidence fusion in intrusion detection systems with extended Dempster-Shafer theory",
      "author" : [ "Dong Yu", "Deborah Frincke" ],
      "venue" : "Proceedings of the 43rd annual Southeast regional conference-Volume",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2005
    }, {
      "title" : "Using anytime algorithms in intelligent systems",
      "author" : [ "Shlomo Zilberstein" ],
      "venue" : "AI magazine,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1996
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "In this article we construct an anytime inference algorithm based on principles introduced in the theory of generic inference; and in particular, extending the work done on ordered valuation algebras [5].",
      "startOffset" : 200,
      "endOffset" : 203
    }, {
      "referenceID" : 11,
      "context" : "Inference can be considered as the (1) combination of information from various sources, which could be in the form of probability distributions from a probabilistic graphical model [12], belief functions in DempsterShafer theory [3, 8] or tables in a relational database; and (2) subsequent focusing or projection to variables of interest, which corresponds to projection for variables in probabilistic graphical models, or a query in the relational database.",
      "startOffset" : 181,
      "endOffset" : 185
    }, {
      "referenceID" : 2,
      "context" : "Inference can be considered as the (1) combination of information from various sources, which could be in the form of probability distributions from a probabilistic graphical model [12], belief functions in DempsterShafer theory [3, 8] or tables in a relational database; and (2) subsequent focusing or projection to variables of interest, which corresponds to projection for variables in probabilistic graphical models, or a query in the relational database.",
      "startOffset" : 229,
      "endOffset" : 235
    }, {
      "referenceID" : 7,
      "context" : "Inference can be considered as the (1) combination of information from various sources, which could be in the form of probability distributions from a probabilistic graphical model [12], belief functions in DempsterShafer theory [3, 8] or tables in a relational database; and (2) subsequent focusing or projection to variables of interest, which corresponds to projection for variables in probabilistic graphical models, or a query in the relational database.",
      "startOffset" : 229,
      "endOffset" : 235
    }, {
      "referenceID" : 16,
      "context" : "Our work is based on the theory of generic inference [17] which abstracts and generalises the inference problem across these different areas.",
      "startOffset" : 53,
      "endOffset" : 57
    }, {
      "referenceID" : 12,
      "context" : "In [13], an algorithm was defined which solved the inference problem on Bayesian networks, using a technique called local computation.",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 21,
      "context" : "It was noted in [23] that the same algorithm could be used to solve the inference problem on belief functions, and a sufficient set of axioms were proposed for an algebraic framework that is necessary for the generic inference algorithm.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 15,
      "context" : "This was extended by Kohlas into a theory of valuation algebras, and a computer implementation of inference over valuation algebras along with concrete instantiations was developed in [16].",
      "startOffset" : 184,
      "endOffset" : 188
    }, {
      "referenceID" : 16,
      "context" : "uk Generic inference as formulated in [17] solves the inference problem in the exact case.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 23,
      "context" : "As exact inference is an #P-hard problem [25], in practice, we need frameworks for approximate inference.",
      "startOffset" : 41,
      "endOffset" : 45
    }, {
      "referenceID" : 1,
      "context" : "Approximation schemes exist for specific instances of valuation algebras (probability potentials [2], belief potentials [6]); as well as for the generic case [5], but there is no such generic framework for anytime inference.",
      "startOffset" : 97,
      "endOffset" : 100
    }, {
      "referenceID" : 5,
      "context" : "Approximation schemes exist for specific instances of valuation algebras (probability potentials [2], belief potentials [6]); as well as for the generic case [5], but there is no such generic framework for anytime inference.",
      "startOffset" : 120,
      "endOffset" : 123
    }, {
      "referenceID" : 4,
      "context" : "Approximation schemes exist for specific instances of valuation algebras (probability potentials [2], belief potentials [6]); as well as for the generic case [5], but there is no such generic framework for anytime inference.",
      "startOffset" : 158,
      "endOffset" : 161
    }, {
      "referenceID" : 4,
      "context" : "In this paper, we extend the approximate inference framework in [5] to support anytime inference.",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 22,
      "context" : "Such algorithms are important in online learning where new data is being streamed in [24], in intelligent systems, decision making under uncertainty [7] and robotics [28] where due to the limitation of interacting in real-time there may not be sufficient time to compute an exact solution.",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 6,
      "context" : "Such algorithms are important in online learning where new data is being streamed in [24], in intelligent systems, decision making under uncertainty [7] and robotics [28] where due to the limitation of interacting in real-time there may not be sufficient time to compute an exact solution.",
      "startOffset" : 149,
      "endOffset" : 152
    }, {
      "referenceID" : 26,
      "context" : "Such algorithms are important in online learning where new data is being streamed in [24], in intelligent systems, decision making under uncertainty [7] and robotics [28] where due to the limitation of interacting in real-time there may not be sufficient time to compute an exact solution.",
      "startOffset" : 166,
      "endOffset" : 170
    }, {
      "referenceID" : 16,
      "context" : "inference generic probability potentials exact [17] [15] approximate [5] loopy belief propagation, [2] anytime [our work] [19]",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 14,
      "context" : "inference generic probability potentials exact [17] [15] approximate [5] loopy belief propagation, [2] anytime [our work] [19]",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 4,
      "context" : "inference generic probability potentials exact [17] [15] approximate [5] loopy belief propagation, [2] anytime [our work] [19]",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 1,
      "context" : "inference generic probability potentials exact [17] [15] approximate [5] loopy belief propagation, [2] anytime [our work] [19]",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 18,
      "context" : "inference generic probability potentials exact [17] [15] approximate [5] loopy belief propagation, [2] anytime [our work] [19]",
      "startOffset" : 122,
      "endOffset" : 126
    }, {
      "referenceID" : 16,
      "context" : "We review the axioms of valuation algebra [17] below, preceded by some remarks on notation.",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 16,
      "context" : "For the intuitive reading of these axioms, we refer the reader to [17, 23].",
      "startOffset" : 66,
      "endOffset" : 74
    }, {
      "referenceID" : 21,
      "context" : "For the intuitive reading of these axioms, we refer the reader to [17, 23].",
      "startOffset" : 66,
      "endOffset" : 74
    }, {
      "referenceID" : 1,
      "context" : "Existing approximation schemes, like the mini-bucket scheme [2] are either not general enough or do not provide a reliable measure of the approximation and how to improve the approximation in an anytime algorithm.",
      "startOffset" : 60,
      "endOffset" : 63
    }, {
      "referenceID" : 4,
      "context" : "In this article, we have used the ordered valuation algebra framework defined in [5] as a basis for constructing an anytime algorithm.",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 4,
      "context" : "The time-bounded combination operator [5] ⊗t : Φ×Φ→ Φ is used to approximate the exact computation during the propagation phase.",
      "startOffset" : 38,
      "endOffset" : 41
    }, {
      "referenceID" : 20,
      "context" : "Inference takes place by message passing in the BJT (for details of the algorithm, see [22, 5]).",
      "startOffset" : 87,
      "endOffset" : 94
    }, {
      "referenceID" : 4,
      "context" : "Inference takes place by message passing in the BJT (for details of the algorithm, see [22, 5]).",
      "startOffset" : 87,
      "endOffset" : 94
    }, {
      "referenceID" : 17,
      "context" : "Such extensions preserve the generic structure of valuation algebras, but add restrictions to simplify or add features to the inference algorithm; in another instance, valuation algebras were extended to weighted valuation algebras to study communication complexity [18].",
      "startOffset" : 266,
      "endOffset" : 270
    }, {
      "referenceID" : 20,
      "context" : "We use a modified version of the propagation algorithm [22, 5], where τ and τ̄ store the partial and complementary partial valuations respectively for a particular BJT node, where the complementary partial valuation ρ̄(φ ,k) is such that ρ̄(φ ,k)⊕ρ(φ ,k)= φ .",
      "startOffset" : 55,
      "endOffset" : 62
    }, {
      "referenceID" : 4,
      "context" : "We use a modified version of the propagation algorithm [22, 5], where τ and τ̄ store the partial and complementary partial valuations respectively for a particular BJT node, where the complementary partial valuation ρ̄(φ ,k) is such that ρ̄(φ ,k)⊕ρ(φ ,k)= φ .",
      "startOffset" : 55,
      "endOffset" : 62
    }, {
      "referenceID" : 5,
      "context" : "We can use the cached partial valuations in τ and τ̄ to define the refinement algorithm that follows in a similar manner to the algorithm in [6].",
      "startOffset" : 141,
      "endOffset" : 144
    }, {
      "referenceID" : 8,
      "context" : "Specifically we show that the important class of semiring induced valuation algebras, [9], can be considered as anytime ordered valuation algebras.",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 8,
      "context" : "We use the definition of semiring induced valuation algebras from [9] and review the following standard notation.",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 8,
      "context" : "There are many other examples of semiring induced valuation algebras, a detailed introduction to which can be found in [9].",
      "startOffset" : 119,
      "endOffset" : 122
    }, {
      "referenceID" : 9,
      "context" : "φ ⊗φ = φ ; then we may use more efficient architectures for local computation such as the Lauritzen-Spiegelhalter architecture [10].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 10,
      "context" : "It is also pertinent to mention that for DNF potentials, one can alternately consider the valuation algebra over the formulae itself instead of the models [11], which simplifies computation extensively.",
      "startOffset" : 155,
      "endOffset" : 159
    }, {
      "referenceID" : 13,
      "context" : "This is the reason for the usage of belief functions in sensor network literature, which involves fusion of information from various sources [14, 4, 20, 27].",
      "startOffset" : 141,
      "endOffset" : 156
    }, {
      "referenceID" : 3,
      "context" : "This is the reason for the usage of belief functions in sensor network literature, which involves fusion of information from various sources [14, 4, 20, 27].",
      "startOffset" : 141,
      "endOffset" : 156
    }, {
      "referenceID" : 19,
      "context" : "This is the reason for the usage of belief functions in sensor network literature, which involves fusion of information from various sources [14, 4, 20, 27].",
      "startOffset" : 141,
      "endOffset" : 156
    }, {
      "referenceID" : 25,
      "context" : "This is the reason for the usage of belief functions in sensor network literature, which involves fusion of information from various sources [14, 4, 20, 27].",
      "startOffset" : 141,
      "endOffset" : 156
    }, {
      "referenceID" : 5,
      "context" : "For the instance of belief functions, with the composition operator defined as [φ ⊕φ ′]m(A) = [φ ]m(A)+ [φ ′]m(A), where [φ ]m is the mass function associated with the belief function φ , our framework specialises to anytime inference in belief potentials as described in [6].",
      "startOffset" : 272,
      "endOffset" : 275
    }, {
      "referenceID" : 4,
      "context" : "Belief functions already form an ordered valuation algebra [5], as well as permit anytime inference [6].",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 5,
      "context" : "Belief functions already form an ordered valuation algebra [5], as well as permit anytime inference [6].",
      "startOffset" : 100,
      "endOffset" : 103
    }, {
      "referenceID" : 5,
      "context" : "The anytime inference algorithm in [6] turns out to be a specific case of the generic anytime inference framework presented in this article.",
      "startOffset" : 35,
      "endOffset" : 38
    }, {
      "referenceID" : 16,
      "context" : "In the discussion on complexity [17], Kohlas and Pouly derive the estimate O(|V |.",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 0,
      "context" : "The figure shows progress of anytime inference on the CHILD dataset, which was used as a case study for exact inference in [1].",
      "startOffset" : 123,
      "endOffset" : 126
    }, {
      "referenceID" : 16,
      "context" : "From a broader perspective, the advantage of operating in the generic framework of valuation algebras has been addressed before [17]; we can target a large class of problems using a unified framework; the inference or projection problem can be found in various forms: Fourier transforms, linear programming and constraint satisfaction problems.",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 24,
      "context" : "We are currently working on implementation of other instances of anytime ordered valuation algebras, as well as conducting a complexity analysis of the algorithm in a distributed setting using the Bulk Synchronous Parallel [26] model.",
      "startOffset" : 223,
      "endOffset" : 227
    } ],
    "year" : 2016,
    "abstractText" : "The novel contribution of this work is the construction of anytime algorithms in a generic framework, which automatically gives us instantiations in many useful domains. We also show that semiring induced valuation algebras, an important subclass of valuation algebras are amenable to anytime inference. Anytime inference, and inference algorithms in general have been a well-researched area in the last few decades. Inference is an important component in most pattern recognition and machine learning algorithms; it also shares theoretical connections with other branches of computer science like theorem-proving. Anytime inference is important in applications with limited space, for efficiency reasons, such as in continuous learning and robotics. In this article we construct an anytime inference algorithm based on principles introduced in the theory of generic inference; and in particular, extending the work done on ordered valuation algebras [5].",
    "creator" : "LaTeX with hyperref package"
  }
}