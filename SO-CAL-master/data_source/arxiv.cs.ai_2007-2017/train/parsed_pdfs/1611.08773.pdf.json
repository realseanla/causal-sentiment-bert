{
  "name" : "1611.08773.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Embedded Bandits for Large-Scale Black-Box Optimization",
    "authors" : [ "Abdullah Al-Dujaili", "S. Suresh" ],
    "emails" : [ "aldujail001@e.ntu.edu.sg,", "ssundaram@ntu.edu.sg" ],
    "sections" : [ {
      "heading" : "Introduction",
      "text" : "Problem. This paper is concerned with the large-scale black-box optimization problem given a finite number of function evaluations. Mathematically, the problem has the form:\nminimize f(x) subject to x ∈ X , (1)\nwhere f : X ⊆ Rn → R and n 102. Without loss of generality, it is assumed that X = [−1, 1]n, and there exists at least one global optimizer x∗ whose objective value is denoted by f∗, i.e., minx∈X f(x) = f(x∗) = f∗. Solving the optimization problem (1) is notoriously difficult as the sole source of information about its objective function f is available through a black-box or an oracle, which one can query\nCopyright c© 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nfor the value of f at a specific solution (point ) x ∈ X . Highorder information (e.g., derivatives) are unavailable symbolically nor numerically or are tedious to compute compared to zero-order information—i.e., point-wise function evaluations. Thus, the task is to find the (or one) optimal solution x∗ ∈ X to (1) or a good approximation using a finite number v of function evaluations, which is commonly referred to as the evaluation budget. The quality of the returned solution x(v) ∈ X after v function evaluations, denoted by f∗v , is assessed by the regret,\nr(v) = f∗v − f∗ . (2) Besides the aforementioned challenging nature of black-box problems, the high dimensionality n of the decision space X poses another challenge towards finding the global optimum. Despite their witnessed success, the effectiveness of most black-box optimization algorithms is restricted to moderate dimensions (typically, n < 100) and they do not scale well to high-dimensional (say, n 102) problems. As the dimensionality increases, the number of evaluations (sampled points) required to cover X increases exponentially.\nDespite the curse of dimensionality, it has been noted that for artificial intelligence (AI) applications, most dimensions of certain classes of the associated optimization problems do not affect the objective function significantly. In other words, such problems have low effective dimensionality, e.g., hyper-parameter optimization for neural and deep belief networks (Bergstra and Bengio 2012).\nRelated Work. The literature on black-box optimization is huge and we only highlight here works that are closely related to the paper’s contribution. The bulk of algorithmic work on large-scale black-box optimization has been following one of two approaches: decomposition and embedding.\nDecomposition algorithms break the problem into several subproblems, and solutions for the original problem are recognized in a coordinated manner. In (Kandasamy, Schneider, and Póczos 2015), Bayesian optimization was scaled to high-dimensional problems whose objectives have an additive structure. i.e., the function f is the sum of several sub-functions with smaller dimensions, such that no two sub-functions share one or more variables. On the other hand, Friesen and Domingos (2015) proposed to decompose the function into approximately locally independent sub-functions and optimize them separately. Chen et\nar X\niv :1\n61 1.\n08 77\n3v 1\n[ cs\n.A I]\n2 7\nN ov\n2 01\n6\nal. (2010) addressed interdependent sub-functions and proposed to consider all entries of the decision vector x independent and discover their relations gradually. In general, decomposition methods employ axis-aligned decomposability, which may limit their applicability.\nEmbedding algorithms exploit the assumption/empirical observation of low effective dimensionality. Chen, Krause, and Castro (2012) presented a variable selection method to discover the effective axis-aligned subspace, while Djolonga, Krause, and Cevher (2013) sought to learn the effective subspace using a low-rank matrix recovery technique. In (Carpentier, Munos, and others 2012), compressed sensing was applied to deal with linear-bandit problems with a high degree of sparsity. Recent works—motivated by the empirical success of random search in leveraging low effective dimensionality without knowing which variables are important (Bergstra and Bengio 2012)—presented random embedding techniques based on the random matrix theory (Wang et al. 2013; Kaban, Bootkrajang, and Durrant 2013) and provided probabilistic theoretical guarantees. In (Qian and Yu 2016), the Simultaneous Optimistic Optimization (SOO) algorithm (Munos 2011) was scaled via random embedding. Problems, whose all dimensions are effective but many of them have a small bounded effect, were addressed in (Qian, Hu, and Yu 2016) where the random embedding technique was incorporated in a sequential framework. In general, random embedding methods employ multiple runs to substantiate the probabilistic theoretical performance.\nOur Contributions. This paper aims to tackle large-scale black-box optimization (1) based on the random embedding technique. Previous propositions put the technique in a framework of multiple runs—be it parallel (Qian and Yu 2016) or sequential (Qian, Hu, and Yu 2016)—to maximize the performance guarantee. In this paper, we seek to break away from the multiple-run framework and follow the optimism in the face of uncertainty principle, or so-called optimistic optimization. To this end, we incorporate the random embedding technique in a stochastic hierarchical bandit setting and present EMBEDDEDHUNTER: an algorithmic instance of the sought approach. Similar to other optimistic methods, EMBEDDEDHUNTER iteratively expands a partitioning tree over a low-dimensional space Y based on randomly projecting sampled points to the original highdimensional space X once or more times. This approach is motivated by the proof that the mean variation in the objective function f value for a point y ∈ Y projected randomly to f ’s decision spaceX is bounded for objective functions that are Lipschitz-continuous. EMBEDDEDHUNTER’s regret (2) is upper bounded in terms of the number of iterations required to expand near-optimal nodes in the (effective) low-dimensional space based on the Lipschitz continuity assumption and that random embedding can preserve local distance.\nThe rest of the paper is organized as follows. First, a formal motivation is presented, followed by an introduction to EMBEDDEDHUNTER. Then, the algorithm’s finite-time performance is studied and complemented by an empirical validation. Towards the end, the paper is concluded."
    }, {
      "heading" : "Optimistic Optimization Meets Random Embeddings",
      "text" : "Optimistic methods, i.e., methods that implement the optimism in the face of uncertainty principle have proved to be viable for black-box optimization. Such a principle finds its foundations in the machine learning field addressing the exploration-vs.-exploitation dilemma, known as the multi-armed bandit problem. Within the context of function optimization, optimistic approaches formulate the complex problem of optimization (1) over the space X as a hierarchy of simple bandit problems (Kocsis and Szepesvári 2006) in the form of space-partitioning tree search. At step t, the algorithm optimistically expands a leaf node (partitions the corresponding subspace) that may contain the global optimum. Previous empirical studies have shown that optimistic methods—e.g., SOO (Munos 2011) and NMSO (Al-Dujaili and Suresh 2016)—are not suitable for problems with high dimensionality.\nRandom embedding has emerged as a practical tool for large-scale optimization with an experimental success and probabilistic theoretical guarantees. It assumes the problem (1) has an implicit low effective dimension d much lower than the explicit (original) dimension n. In essence, for an optimizer x∗ ∈ X = [−1, 1]n and a random matrix A ∈ Rn×d whose entries are sampled independently from a normal distribution, there exists a point y∗ ∈ Y = [−d/η, d/η]d such that its Euclidean random projection to X , PX (Ay∗), is x∗ with a probability at least 1 − η where η ∈ (0, 1). That is to say, f(PX (Ay∗)) = f(x∗) = f∗. The Euclidean random projection of the ith coordinate [y]i to [X ]i is defined as follows.\n[PX (Ay)]i =   \n1, if [y]i ≥ 1; −1, if [y]i ≤ −1; [Ay]i otherwise.\n(3)\nThe reader can refer to (Wang et al. 2013; Qian and Yu 2016) for more details and a formal treatment of the above.\nIt was shown that is possible to scale up optimistic methods via random embedding (Qian and Yu 2016; Qian, Hu, and Yu 2016). Nevertheless, one can observe that it has been applied in a multiple-run framework, where (multiple) M random embeddings are applied on the same lowdimensional search space Y in parallel or sequentially to increase the success rate 1 − ηM , ignoring the relationship among the function f values at the multiple projections in X of a single point y ∈ Y . In Theorem 1, we show that a relationship can be established for Lipschitz functions. Prior to that, let us introduce some notation and state the Lipschitz condition formally.\nNotation. Let N denote the Gaussian distribution with zero mean and 1/n variance, and {Ap}p ⊆ Rn×d, with d n, be a sequence of realization matrices of the random matrix A whose entries are sampled independently from N . Furthermore, let gP (y) be a random (stochastic) function such that gP (y) def = f(PX (Ay)) and gp(y) = f(PX (Apy)) is a realization (deterministic) function, where y ∈ Y ⊆ Rd. On the other hand, let us define `(x1,x2) as L · ||x1 − x2||,\nwhere || · || denotes the L2-norm. The expectation of a random variable X is denoted by E[X]. Assumption 1. f is Lipschitz-continuous, i.e., ∀x1,x2 ∈ X , |f(x1)− f(x2)| ≤ L · ||x1 − x2|| , (4) where L > 0 is the Lipschitz constant.\nTheorem 1 (Mean absolute difference for gP (y)). ∀y ∈ Y ⊆ Rd, we have E[|gp(y)− gq(y)|] ≤ √ 8 · L · ||y|| .\nProof. From Assumption 1, we have\nE[|gp(y)− gq(y)|] =E[|f(PX (Apy))− f(PX (Aqy))|] ≤L · E[||PX (Apy)− PX (Aqy)||] .\nFrom the definition of the Euclidean projection (3):\nE[|gp(y)− gq(y)|] ≤L · E[||Apy −Aqy||]\nThus, from Cauchy’s inequality, we have\nE[|gp(y)− gq(y)|] ≤L · ||y|| · E[||Ap −Aq||]\n≤L · ||y|| · √ 8\nn · √ max(n, d) (5)\n≤ √\n8 · L · ||y|| , where (5) is derived from (Hansen 1988).\nTheorem 1 says that the variation in the function f values at points in X projected randomly from the same lowdimensional point y ∈ Y is bounded on the order of the point’s norm ||y||. Indeed, the d-dimensional zero vector (center of Y) will always give the same function value (zero variation), regardless of the random matrix used. As a result, one is motivated to project a point y multiple times proportional to its norm in search for the optimal solution x∗. Next, we provide EMBEDDEDHUNTER: a novel scalable optimistic algorithm that exploits the above result."
    }, {
      "heading" : "EMBEDDEDHUNTER",
      "text" : "EMBEDDEDHUNTER is a space-partitioning tree-search algorithm that constructs iteratively finer and finer partitions of the (effective) low-dimensional space Y in a hierarchical fashion looking for the global optimum. The hierarchical partitioning can be represented by a K-ary tree T , where nodes of the same depth h correspond to a partition of Kh subspaces/cells. i.e., the ith node at depth h, denoted by (h, i), corresponds to the subspace/cell Yh,i such that Y = ∪0≤i<KhYh,i. To each node (h, i), a base point yh,i (center of Yh,i) is assigned at which f is evaluated once or more times. That is to say, for every new evaluation of the node (h, i), yh,i is randomly projected to f ’s decision space X via a random matrix (3) and gets evaluated. To expand/split a node, the corresponding cell is partitioned into K subscells along one of Y’s coordinates, one coordinate at a depth in a sequential manner. Moreover, let the set of leaf nodes of T be denoted as L. Furthermore, one can denote the algorithm’s tree T at step t by Tt. Towards the detailed aspects of the algorithm, some assumptions are made about\nthe hierarchical partitioning in line with Assumption 1 and Theorem 1, relating variations in function f values using the same and different projection matrices, respectively.\nFunction values within the same projection. Based on the Johnson-Lindenstrauss Lemma (Achlioptas 2003; Vempala 2004); for a set of m points {yi}0≤i≤m ⊂ Y and their projections {xi}0≤i≤m ⊂ X via the same matrix, we have `(xi,xj) ≤ (1 + )1/2 · `(yi,yj), where ∈ (0, 1/2] and n > 9 lnm/( 2 − 3)—see (Qian and Yu 2016, Lemma 3).\nIn other words, the random embedding can probably preserve local distance. Thus, from Assumption 1, the difference between the function f values of two points in the lowdimensional space Y—using the same projection matrix—is on the order of their distance in Y . The next assumption exploits the above observation with respect to the optimal cell (node), which is defined as follows. Definition 1 (Optimal cell). A cell Yh,i at depth h ≥ 0 is optimal if there exists a random matrix Ap whose entries are sampled independently from N such that miny∈Yh,i gp(y) = f(x\n∗), where x∗ is a global optimizer of f . We denote such a cell by Yh,i∗pand its node by (h, i∗p). Assumption 2 (Bounded intra-variation). There exists a decreasing sequence δ in h ≥ 0 such that for one (or more) optimal cell(s) Yh,i∗p at depth h, we have\n0 ≤ sup q,y∈Yh,i∗p |gq(yh,i)− gq(y)| ≤ δ(h) .\nAs the hierachical partitioning is performed coordinatewise in a sequential manner, let us link the fact that the cell’s shapes are not skewed in some dimensions with Assumption 2 through the next assumption. Assumption 3 (Well-shaped cells). ∃ m > 0 such that ∀(h, i) ∈ T , Yh,i contains an `-ball of radius mδ(h) centered in yh,i.\nFunction values among different projections. Now, we state another assumption about the optimal cell Yh,i∗p in line with Theorem 1. Assumption 4 (Bounded inter-variation). There exists two non-decreasing sequences λ and τ in y and h, respectively, such that for any depth h ≥ 0, for any optimal cell Yh,i∗p ,\n0 ≤ sup s,t |gs(yh,i∗p)− gt(yh,i∗p)| ≤ λ(yh,i∗p) ,\nand supi∗p λ(yh,i∗p) ≤ τ(h) . Note that λ being bounded by τ in h is due to the nature of the hierarchical partitioning: the maximum norm of base points at depth h is smaller than or equal to those at depth h+1. e.g., at depth h = 0, there is a single node (0, 0) whose base point is the d-dimensional zero vector centered inY . As the tree T goes deeper, more base points farther away from the center—and hence greater norms—are sampled.\nCombining Assumptions 2 and 4 implies that the values of function f , which the optimal node’s base point yh,i∗p can have, are within τ(h) + δ(h) from the global optimum f∗.\nOne can therefore establish a lower confidence bound (commonly referred to as the b-value) on the f values within a cell. Let f∗h,i be the best function f value achieved among yh,i evaluations. Then, the b-value for (h, i) can be written as bh,i def = f∗h,i − τ(h) − δ(h) . With the knowledge of the sequences τ and δ, we can expand nodes whose b-values lower bound f∗, discarding other nodes and striking an efficient balance in exploration-vs-exploitation based on the lowest τ(h) + δ(h) portion of the function space.\nHowever, the knowledge of such sequences (δ, λ, τ ) is not available/known in practice. Thus, we follow an optimistic approach and propose to simulate the knowledge of these sequences via two realization aspects of the algorithm. First, the tree T ’s nodes are visited based on their depths and their base points’ norms: relating the depth-wise and norm-wise visits to the notion of intra-(same projection) and inter-(different projections) exploration-vs.-exploitation dilemmas, respectively. Second, as the tree T is swept across multiple depths and norms, a node (h, i) is expanded only if its f∗h,i is strictly smaller than those of nodes of higher depths and those of nodes at the same depth but of greater or equal base points’ norms.\nBesides motivating the norm-wise traversal described above, Theorem 1 implies evaluating f at the nodes’ base points multiple times—each with a new random projection—in proportion to their norms as larger improvement over the current f value is probable at points with greater norms. A tree T with an odd-numbered partition factorK can seamlessly accommodate this observation because the center child node (h + 1, j) of a node (h, i) shares the same base point as its parent (h, i). Therefore, one can decide whether to evaluate a newly created center child node based on the number of function evaluations that its base point had in its ancestor nodes in relation to its norm.\nIn summary, Algorithm 1 describes EMBEDDEDHUNTER. The algorithm takes four parameters: i). the maximum depth hmax up to which nodes can be expanded, it can be a function of the evaluation budget or the number of iterations similar to other optimistic methods; ii). the partition factor K, which has to be an odd number; iii). η ∈ (0, 1) to specify the bounds of the search space Y from the random projection theory; and iv). a multiplicative factor M to bound the number of past function evaluations at a base point yh,i such that it is not greater thanM ·||yh,i||, simulating Theorem 1’s bound, √ 8 ·L · ||yh,i||. Otherwise, no more evaluation is performed and the node retains its parent’s best achieved function value (performed at Line 9 of the algorithm). For the sake of readability, the following definitions were used in Algorithm 1.\nLt,h def= {(h, i) | 0 ≤ i < Kh, (h, i) ∈ Lt} Γh,t def = {γ ∈ R+0 | ∃(h, i) ∈ Lt,h such that γ = ||yh,i||}\nLjt,h def = {(h, i) | (h, i) ∈ Lt,h, ||yh,i|| = the jth largest element ∈ Γh,t} (6)\nAlgorithm 1 The EMBEDDEDHUNTER Algorithm Input:\nstochastic function gP , search space Y = [−d/η, d/η]d, evaluation budget v.\nInitialization: t← 1, T1 = {(0, 0)}, Evaluate gP (y0,0).\n1: while evaluation budget is not exhausted do 2: νmin ←∞ 3: for l = 0 to min{depth(Tt), hmax} do 4: for j = 1 to |Γl,t| do 5: Select (l, o) = arg min(h,i)∈Ljt,l f ∗ h,i 6: if f∗l,o < νmin then 7: νmin ← f∗l,o 8: Expand (l, o) into its child nodes 9: Evaluate (l, o)’s child nodes by gP\n10: Add (l, o)’s child nodes to Tt 11: end if 12: end for 13: Tt+1 ← Tt 14: t← t+ 1 15: end for 16: end while 17: return f∗v = min(h,i)∈Tt f∗h,i"
    }, {
      "heading" : "Theoretical Analysis",
      "text" : "In this section, we analyze the performance of the EMBEDDEDHUNTER algorithm and upper-bound its regret (2). To derive a bound on the regret, a measure of the quantity of near-optimal points is used, which is closely similar to those in (Bubeck et al. 2009; Al-Dujaili, Suresh, and Sundararajan 2016) and defined after introducing some terminology. For any > 0, define the set of -optimal points as Y def= {y ∈ Y | minp gp(y) ≤ f∗ + } and let g(Y ) def= {minp gp(y) | y ∈ Y } = [f∗, f∗+ ]. Likewise, denote the set of -optimal nodes at depth h whose base points are in Y by I h def = {(h, i) ∈ T | 0 ≤ i < Kh,yh,i ∈ Y }. After t iterations, one can denote the depth of the deepest expanded optimal node by h∗t , where one iteration represents executing the lines 4–14 of Algorithm 1, once.\nDefinition 2. The m-near-optimality dimension is the smallest dm ≥ 0 such that there exists C > 0 such that for any > 0, the maximum number of disjoint `-balls of radius m and center in Y is less than C −dm .\nLet the considered depth after t−1 iterations be h and the depth of the deepest expanded optimal node h∗t−1 be h− 1. At iteration t, EMBEDDEDHUNTER would expand at most |Γh,t| nodes. As the (any) optimal node at depth h is in one of the {Ljt,h}1≤j≤|Γh,t| sets, the optimal node at depth h is not expanded at iteration t if νmin ≤ f∗h,i∗p or if there exists a node (h, i) ∈ Lh,t such that ||yh,i|| ≥ ||yh,i∗p || and f∗h,i ≤ f∗h,i∗p . The latter condition implies f ∗ h,i − f∗ ≤ f∗h,i∗p − f ∗ and by triangular inequality, we have f∗h,i − f∗ ≤ |f∗h,i∗p − gp(yh,i∗p)|+|gp(yh,i∗p)−f∗|. Hence, from Assumption 4 and\nAssumption 2, f∗h,i − f∗ ≤ τ(h) + δ(h). Since τ and δ are non-decreasing and decreasing sequences in h, respectively. One can write τ(h) as a multiple of δ(h), that is, there exists mh ∈ Z+ such that\nf∗h,i − f∗ ≤τ(h) + δ(h) ≤ mh · δ(h) . (7)\nPut it differently, when h∗t−1 = h − 1, the base point of any node at depth h, that is later expanded prior to the optimal node at the same depth, is in the near-optimal space Ymhδ(h). Now, if we assume that prior to any iteration at depth h, νmin ≥ mhδ(h), then by Algorithm 1, it takes at most the next |Imhδ(h)h | iterations at depth h to expand the optimal cell Yh,i∗p . With this observation at hand, the next question follows naturally: how many iterations at other depths ∈ {0, . . . , hmax} are required—at most—to expand the optimal cell Yh,i∗p , and with no assumption on νmin? In the following lemma, we show that the number of iterations required is upper bounded by the number of nodes in supersets of each of {Imhδ(h)h }0≤h≤hmax . The reader can refer to the supplemental material for a pictorial explanation.\nLemma 1. Let depth h ∈ {0, hmax}, m̂ = mhmax and\nth def = hmax ( |Im̂δ(0)0 |+ |I m̂δ(1) 1 |+ · · ·+ |I m̂δ(h) h | ) . (8)\nAfter t ≥ th iterations, the depth of the deepest expanded optimal node is at least h, i.e., h∗t ≥ h.\nProof. Refer to the supplemental material.\nLemma 1 quantifies the number of iterations required to expand an optimal node as a function of the number of m̂δ(h)-optimal nodes. Based on Assumption 3, the following lemma upper bounds the cardinality of such nodes.\nLemma 2. Let depth h ∈ {0, hmax}, we have |Im̂δ(h)h | ≤ C(m̂δ(h))−d̂, where d̂ is defined as the m/m̂-nearoptimality dimension and C the related constant.\nProof. Refer to the supplemental material.\nWith Lemmas 1 and 2 at hand, the finite-time regret (2) of the EMBEDDEDHUNTER algorithm can be linked to the number of iterations as presented in the next theorem.\nTheorem 2. Define h(t) as the smallest h ≥ 0 such that:\nChmax\nh(t)∑\nl=0\n(m̂δ(l))−d̂ ≥ t , (9)\nwhere t is the number of iterations. Then EMBEDDEDHUNTER’s regret is bounded as r(t) ≤ min{τ(h) + δ(h) | h ≤ min(h(t), hmax + 1)} .\nProof. Refer to the supplemental material."
    }, {
      "heading" : "Empirical Analysis",
      "text" : "In this section, the efficacy of the proposed method is empirically validated on a set of scalable functions from the literature: the Ellipsoid, FletcherPowell, Rosenbrock, and Ackley test functions (Molga and Smutnicki 2005), each of which reflects some challenges in black-box optimization, e.g., modality, separability, and conditioning. The proposed optimistic method is also compared with the scaled SOO optimistic algorithm (Munos 2011) within two recently presented methods in the random-embedding multiple-run framework, viz. the Simultaneous Optimistic Optimization with Random Embedding (RESOO) (Qian and Yu 2016) and Simultaneous Optimistic Optimization with Sequential Random Embedding (SRESOO) (Qian, Hu, and Yu 2016) algorithms. With the aim of fully characterizing the algorithms’ performance, five experiments are conducted with respect to (w.r.t) the performance as listed in Table 1.\nExperiment Setup. The compared algorithms were implemented in Python and the test functions were imported from the Optproblems Python package (Wessing 2016). Each algorithm is run 20 times independently per an experiment configuration and the average performance is reported. The experiments were set up as listed in Table 1. The code/data/supplemental materials of this paper will be made available at the project’s website: http://ash-aldujaili.github.io/eh-lsopt.\nResults & Discussion. Results from the five experiments on the four test functions are presented in Figure 1. One can easily appreciate EMBEDDEDHUNTER’s performance w.r.t the compared algorithms.\nConvergence (v). Across all the tested functions, the performance gap between the algorithms grows larger with higher evaluation budget v. With more function evaluations, EMBEDDEDHUNTER is able to further refine its best achieved solution in comparison with the other algorithms.\nScalability (n). As expected, the best solution quality de-\nAlgorithms Problems RESOO SRESOO\nEmbeddedHunter\nEllipsoid ill-conditioned, uni-modal, separable\nFletcherPowell periodic search space, multi-modal, nonseparable\nRosenbrock non-convex, uni-modal, non-separable\nAckley |local minima| ∈ O(en), non-separable\nE x p e ri m e n ts\nConvergence (v)\n101 102 103 104 105 101\n102\n103\n104\n105\n106\nv r e g r e t\n101 102 103 104 105\n104.5\n105\n105.5\nv\nr e g r e t\n101 102 103 104 105\n8.88\n8.9\n8.92\n8.94\n8.96\n8.98\n9\nv\nr e g r e t\n101 102 103 104 105\n100.7\n100.8\n100.9\n101\nv\nr e g r e t\nScalability (n)\n102 103 104 105\n102\n103\n104\n105\n106\nn\nr e g r e t\n102 103 104 105\n105\n106\nn\nr e g r e t\n102 103 104 105\n8.9\n8.92\n8.94\n8.96\nn\nr e g r e t\n102 103 104 105\n100.8\n100.9\nn\nr e g r e t\nEmbeddings Number (M)\n0 5 10 15 20\n102\n103\n104\n105\n106\nM\nr e g r e t\n0 5 10 15 20\n105\n106\nM\nr e g r e t\n0 5 10 15 20\n8.92\n8.94\n8.96\n8.98\nM\nr e g r e t\n0 5 10 15 20\n100.8\n100.9\nM\nr e g r e t\nEffective Dimension (d)\n0 20 40 60 80 101\n102\n103\n104\n105\n106\nd\nr e g r e t\n0 20 40 60 80\n103\n104\n105\n106\n107\n108\nd\nr e g r e t\n0 20 40 60 80\n10−1\n100\n101\n102\nd\nr e g r e t\n0 20 40 60 80\n100.7\n100.8\n100.9\n101\nd\nr e g r e t\nEffective Dimension Knowledge\n0 50 100 150 200 250\n100\n101\n102\n103\n104\n105\n106\nd\nr e g r e t\n0 50 100 150 200 250 100\n102\n104\n106\n108\nd\nr e g r e t\n0 50 100 150 200 250\n10−2\n10−1\n100\n101\n102\nd\nr e g r e t\n0 50 100 150 200 250\n100\n101\nd r e g r e t\nFigure 1: Empirical validation of the EMBEDDEDHUNTER algorithm on a set of commonly-used test optimization problems in comparison with recent large-scale techniques namely RESOO and SRESOO. Each data point of an algorithm’s curve represents the mean performance of its 20 runs w.r.t. the experimental configuration considered.\ngrades with the problem’s explicit dimensionality n. Nevertheless, the performance of SRESOO looks robust yet poorer than that of EMBEDDEDHUNTER and RESOO.\nEmbedding Number (M ). Allocating more independent runs seems to be effective for RESOO’s and of lesser effect to SRESOO’s performance. As M approaches v, both the algorithms act as random search optimizers. This is not the case for EMBEDDEDHUNTER, which uses M as a multiplicative factor to bound the number of evaluations a base point yh,i can have up to M · ||yh,i||. EMBEDDEDHUNTER uses M as an estimate of Theorem 1’s bound factor √ 8 · L. Thus, there’s a sweet-spot value for each function, which explains the regret’s variations for each function in M .\nEffective Dimension (d). The results validate the assumption of low effective dimensionality for the suitability of random embedding technique for large-scale problems. It does\nnot scale well with higher effective dimensionality and the algorithms’ performance gap reduces w.r.t. the same.\nKnowledge of the Effective Dimension. This experiment investigated the performance of low-dimensional embedding irrespective of the effective dimension—be it higher or lower (see Table 1). As the mismatch between the two quantities increases, the performance degrades and the gap among the algorithms reduces."
    }, {
      "heading" : "Conclusion",
      "text" : "This paper has presented the EMBEDDEDHUNTER algorithm, a different approach to random embedding for largescale black-box optimization. While the bulk of random embedding techniques in the literature employ the multiple-run paradigm sampling a new random projection for each run to maximize the probabilistic guarantee of convergence to\nthe optimal solution, EMBEDDEDHUNTER looks for the optimal solution by building stochastic hierarchical bandits (socalled a tree) over a low-dimensional search space Y , where stochasticity has shown to be proportional on average with the norm of the nodes’ base points.\nThe distinctive advantage of EMBEDDEDHUNTER is that its search tree implicitly ranks Y’s regions via its depth/norm-wise visits and allocates the evaluation budget accordingly. Indeed, other algorithms (e.g., RESOO) may evaluate Y’s center–which is a zero vector–M times in its M independent tree searches/projections. This is inefficient as M evaluations are spent generating the same function value, whereas EMBEDDEDHUNTER evaluates the zero vector once and reserves the rest (M − 1) evaluations to points with greater norms, exploring more values in the function space.\nThe finite-time analysis of the algorithm has characterized its performance in terms of the regret as a function of the number of iterations. Besides its theoreticallyproven performance, the numerical experiments have validated EMBEDDEDHUNTER’s efficacy and robustness with regard to recent random-embedding methods.\nAcknowledgments The research was partially supported by the ST Engineering - NTU Corporate Lab, Singapore, through the NRF corporate lab@universty scheme."
    }, {
      "heading" : "A.3 On the Generality of Assumption 1",
      "text" : "The class of functions that satisfies the Lipschitz condition is very broad. In fact, it has been shown in [2, 1] that among the Lipschitz-continuous functions are convex/concave functions over a closed domain and continuously differentiable functions.\nA.4 Visual Description and Proof of Lemma 1 Consider Figure 1, where all nodes at depth h = 0 have been expanded with out loss of generality. One can see that if all the nodes in Im1δ(1)1 have been expanded, then in later iterations at depth h = 1 nodes from Lt,1 \\ Im1δ(1)1 will be expanded. As a result, prior to iterations at depth h = 2, the minimum value, νmin can have, is f∗ +m1δ(1). Since τ is non-decreasing in h, m1 ≤ m2 and it is possible that there exists some node (h, i) in Im2δ(2)2 such that νmin ≤ f∗h,i ≤ f∗ +m2δ(2), and hence it will not be expanded. In other words, we are certain that all the nodes in Im2δ(2)2 will be expanded if νmin—prior to any iteration at depth h = 2—is greater than f∗ + m2δ(2). In the light of this observation, the following lemma is deduced.\nLemma 1. Let depth h ∈ {0, hmax}, m̂ = mhmax and\nth def = hmax ( |Im̂δ(0)0 |+ |I m̂δ(1) 1 |+ · · ·+ |I m̂δ(h) h | ) . (1)\nAfter t ≥ th iterations, the depth of the deepest expanded optimal node is at least h, i.e., h∗t ≥ h. Proof. First, the lemma holds trivially for h = 0 as h∗t ≥ 0. For h > 0, the proof is presented by induction. To this end, let the lemma holds for all h ≤ ĥ < hmax, and we need to show it holds for ĥ + 1. Assume that tĥ+1 iterations have been performed, that is to say, the present iteration is t ≥ tĥ+1. As t ≥ tĥ+1 ≥ tĥ, the induction assumption implies that h∗t ≥ ĥ. Furthermore, the induction assumption implies that νmin > m̂δ(ĥ) prior to any iteration at depth ĥ + 1 because all the nodes in {Im̂δ(h)h }0≤h≤ĥ have been expanded in previous iterations. From Eq. (7) of the main paper and the definition of Imĥ+1δ(ĥ+1)\nĥ+1 , we are certain that h∗t ≥ ĥ + 1\nif all the nodes in Imĥ+1δ(ĥ+1) ĥ\nhave expanded. To guarantee their expansions, we need an additional total number of iterations across all depths greater than or equal to\n|Im̂δ(ĥ+1) ĥ+1 | ≥ |Imĥ+1δ(ĥ+1) ĥ+1 | (see Figure 1) times the tree depth hmax (one iteration per depth). In total, the number of iterations is equal to tĥ+1 and thus h ∗ t ≥ ĥ+ 1."
    }, {
      "heading" : "A.5 Proof of Lemma 2",
      "text" : "Lemma 2. Let depth h ∈ {0, hmax}, we have |Im̂δ(h)h | ≤ C(m̂δ(h))−d̂, where d̂ is defined as the m/m̂-near-optimality dimension and C the related constant.\nProof. The proof is made by contradiction. To this end, assume there exists some h ∈ {0, hmax} such that |Im̂δ(h)h | > C(m̂δ(h))−d̂. On the one hand, the definition\n2\n3\nof Im̂δ(h)h indicates that their base points are in Ym̂δ(h). On the other hand, Assumption 3 of the main paper indicates that cells of nodes at depth h contain a ball of radius mδ(h) = mm̂ · m̂δ(h). Since the cells are disjoint and from Definition 2 of the main paper, we have a contradiction with d̂ being the m/m̂-near-optimality dimension."
    }, {
      "heading" : "A.6 Proof of Theorem 2",
      "text" : "Theorem 2. (r(t) for EMBEDDEDHUNTER) Let us define h(t) as the smallest h ≥ 0 such that:\nChmax\nh(t)∑\nl=0\n(m̂δ(l))−d̂ ≥ t (2)\nwhere t is the number of iterations. Then the regret of EMBEDDEDHUNTER is bounded as:\nr(t) ≤ min{τ(h) + δ(h) | h ≤ min(h(t), hmax + 1)} . (3)\nProof. From the definition of h(t) and Lemma 2, a bound on th(t)−1 of Eq. (1) can be written as follows.\nth(t)−1 = hmax\nh(t)−1∑\nl=0\n|Im̂δ(l)l |\n≤ Chmax h(t)−1∑\nl=0\n(m̂δ(l))−d̂\n< t .\nThen, by Lemma 1 and the fact that EMBEDDEDHUNTER does not expand nodes beyond hmax, h∗t ≥ min(h(t) − 1, hmax). Thus, we know that the optimal branch of nodes {Yh,i∗p}0≤h≤min(h(t),hmax+1) have been visited and evaluated at least once and for which the best function value achieved among {f∗h,i∗p}0≤h≤min(h(t),hmax+1) is at most min{τ(h) + δ(h) | h ≤ min(h(t), hmax + 1)} away from the optimal value f∗. Therefore, the regret of the algorithm is upper bounded as in Eq. 3."
    } ],
    "references" : [ {
      "title" : "Modifications of the Direct Algorithm",
      "author" : [ "J.M. Gablonsky" ],
      "venue" : "PhD thesis, North Carolina State University,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2001
    }, {
      "title" : "Global optimization in action: continuous and Lipschitz optimization: algorithms, implementations and applications, volume 6",
      "author" : [ "János Pintér" ],
      "venue" : "Springer Science & Business Media,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1995
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "Random embedding has been applied with empirical success to large-scale black-box optimization problems with low effective dimensions. This paper proposes the EMBEDDEDHUNTER algorithm, which incorporates the technique in a hierarchical stochastic bandit setting, following the optimism in the face of uncertainty principle and breaking away from the multiple-run framework in which random embedding has been conventionally applied similar to stochastic black-box optimization solvers. Our proposition is motivated by the bounded mean variation in the objective value for a low-dimensional point projected randomly into the decision space of Lipschitz-continuous problems. In essence, the EMBEDDEDHUNTER algorithm expands optimistically a partitioning tree over a low-dimensional—equal to the effective dimension of the problem—search space based on a bounded number of random embeddings of sampled points from the low-dimensional space. In contrast to the probabilistic theoretical guarantees of multiple-run randomembedding algorithms, the finite-time analysis of the proposed algorithm presents a theoretical upper bound on the regret as a function of the algorithm’s number of iterations. Furthermore, numerical experiments were conducted to validate its performance. The results show a clear performance gain over recently proposed random embedding methods for large-scale problems, provided the intrinsic dimensionality is low. Introduction Problem. This paper is concerned with the large-scale black-box optimization problem given a finite number of function evaluations. Mathematically, the problem has the form: minimize f(x) subject to x ∈ X , (1) where f : X ⊆ R → R and n 10. Without loss of generality, it is assumed that X = [−1, 1], and there exists at least one global optimizer x∗ whose objective value is denoted by f∗, i.e., minx∈X f(x) = f(x∗) = f∗. Solving the optimization problem (1) is notoriously difficult as the sole source of information about its objective function f is available through a black-box or an oracle, which one can query Copyright c © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. for the value of f at a specific solution (point ) x ∈ X . Highorder information (e.g., derivatives) are unavailable symbolically nor numerically or are tedious to compute compared to zero-order information—i.e., point-wise function evaluations. Thus, the task is to find the (or one) optimal solution x∗ ∈ X to (1) or a good approximation using a finite number v of function evaluations, which is commonly referred to as the evaluation budget. The quality of the returned solution x(v) ∈ X after v function evaluations, denoted by f∗ v , is assessed by the regret, r(v) = f∗ v − f∗ . (2) Besides the aforementioned challenging nature of black-box problems, the high dimensionality n of the decision space X poses another challenge towards finding the global optimum. Despite their witnessed success, the effectiveness of most black-box optimization algorithms is restricted to moderate dimensions (typically, n < 100) and they do not scale well to high-dimensional (say, n 10) problems. As the dimensionality increases, the number of evaluations (sampled points) required to cover X increases exponentially. Despite the curse of dimensionality, it has been noted that for artificial intelligence (AI) applications, most dimensions of certain classes of the associated optimization problems do not affect the objective function significantly. In other words, such problems have low effective dimensionality, e.g., hyper-parameter optimization for neural and deep belief networks (Bergstra and Bengio 2012). Related Work. The literature on black-box optimization is huge and we only highlight here works that are closely related to the paper’s contribution. The bulk of algorithmic work on large-scale black-box optimization has been following one of two approaches: decomposition and embedding. Decomposition algorithms break the problem into several subproblems, and solutions for the original problem are recognized in a coordinated manner. In (Kandasamy, Schneider, and Póczos 2015), Bayesian optimization was scaled to high-dimensional problems whose objectives have an additive structure. i.e., the function f is the sum of several sub-functions with smaller dimensions, such that no two sub-functions share one or more variables. On the other hand, Friesen and Domingos (2015) proposed to decompose the function into approximately locally independent sub-functions and optimize them separately. Chen et ar X iv :1 61 1. 08 77 3v 1 [ cs .A I] 2 7 N ov 2 01 6 al. (2010) addressed interdependent sub-functions and proposed to consider all entries of the decision vector x independent and discover their relations gradually. In general, decomposition methods employ axis-aligned decomposability, which may limit their applicability. Embedding algorithms exploit the assumption/empirical observation of low effective dimensionality. Chen, Krause, and Castro (2012) presented a variable selection method to discover the effective axis-aligned subspace, while Djolonga, Krause, and Cevher (2013) sought to learn the effective subspace using a low-rank matrix recovery technique. In (Carpentier, Munos, and others 2012), compressed sensing was applied to deal with linear-bandit problems with a high degree of sparsity. Recent works—motivated by the empirical success of random search in leveraging low effective dimensionality without knowing which variables are important (Bergstra and Bengio 2012)—presented random embedding techniques based on the random matrix theory (Wang et al. 2013; Kaban, Bootkrajang, and Durrant 2013) and provided probabilistic theoretical guarantees. In (Qian and Yu 2016), the Simultaneous Optimistic Optimization (SOO) algorithm (Munos 2011) was scaled via random embedding. Problems, whose all dimensions are effective but many of them have a small bounded effect, were addressed in (Qian, Hu, and Yu 2016) where the random embedding technique was incorporated in a sequential framework. In general, random embedding methods employ multiple runs to substantiate the probabilistic theoretical performance. Our Contributions. This paper aims to tackle large-scale black-box optimization (1) based on the random embedding technique. Previous propositions put the technique in a framework of multiple runs—be it parallel (Qian and Yu 2016) or sequential (Qian, Hu, and Yu 2016)—to maximize the performance guarantee. In this paper, we seek to break away from the multiple-run framework and follow the optimism in the face of uncertainty principle, or so-called optimistic optimization. To this end, we incorporate the random embedding technique in a stochastic hierarchical bandit setting and present EMBEDDEDHUNTER: an algorithmic instance of the sought approach. Similar to other optimistic methods, EMBEDDEDHUNTER iteratively expands a partitioning tree over a low-dimensional space Y based on randomly projecting sampled points to the original highdimensional space X once or more times. This approach is motivated by the proof that the mean variation in the objective function f value for a point y ∈ Y projected randomly to f ’s decision spaceX is bounded for objective functions that are Lipschitz-continuous. EMBEDDEDHUNTER’s regret (2) is upper bounded in terms of the number of iterations required to expand near-optimal nodes in the (effective) low-dimensional space based on the Lipschitz continuity assumption and that random embedding can preserve local distance. The rest of the paper is organized as follows. First, a formal motivation is presented, followed by an introduction to EMBEDDEDHUNTER. Then, the algorithm’s finite-time performance is studied and complemented by an empirical validation. Towards the end, the paper is concluded. Optimistic Optimization Meets Random Embeddings Optimistic methods, i.e., methods that implement the optimism in the face of uncertainty principle have proved to be viable for black-box optimization. Such a principle finds its foundations in the machine learning field addressing the exploration-vs.-exploitation dilemma, known as the multi-armed bandit problem. Within the context of function optimization, optimistic approaches formulate the complex problem of optimization (1) over the space X as a hierarchy of simple bandit problems (Kocsis and Szepesvári 2006) in the form of space-partitioning tree search. At step t, the algorithm optimistically expands a leaf node (partitions the corresponding subspace) that may contain the global optimum. Previous empirical studies have shown that optimistic methods—e.g., SOO (Munos 2011) and NMSO (Al-Dujaili and Suresh 2016)—are not suitable for problems with high dimensionality. Random embedding has emerged as a practical tool for large-scale optimization with an experimental success and probabilistic theoretical guarantees. It assumes the problem (1) has an implicit low effective dimension d much lower than the explicit (original) dimension n. In essence, for an optimizer x∗ ∈ X = [−1, 1] and a random matrix A ∈ Rn×d whose entries are sampled independently from a normal distribution, there exists a point y∗ ∈ Y = [−d/η, d/η] such that its Euclidean random projection to X , PX (Ay∗), is x∗ with a probability at least 1 − η where η ∈ (0, 1). That is to say, f(PX (Ay∗)) = f(x∗) = f∗. The Euclidean random projection of the ith coordinate [y]i to [X ]i is defined as follows.",
    "creator" : "LaTeX with hyperref package"
  }
}