{
  "name" : "1511.05506.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "МЕТОДОВ НЕЙРОУПРАВЛЕНИЯ" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "А.Н. Чернодуб, Д.А. Дзюба // Проблемы программирования, 2011, № 2, с. 79-94. A.N. Chernodub, D.A. Dziuba // Problems in programming, 2011, No. 2, pp. 79-94.\nОБЗОР МЕТОДОВ НЕЙРОУПРАВЛЕНИЯ\nРассматриваются методы применения нейронных сетей для решения задач управления динамическими объектами. Для каждого вида нейроуправления приводятся схемы соединения нейросетей внутри системы управления и детально описываются процедуры их обучения. Анализируются преимущества и недостатки описанных методов.\nВведение\nНейроуправление динамическими\nобъектами является новым перспективным направлением, находящимся на стыке таких дисциплин, как автоматическое управление, искусственный интеллект, нейрофизиология. Нейронные сети обладают рядом уникальных свойств, которые делают их мощным инструментом для создания систем управления: способностью к обучению на примерах и обобщению данных, способностью адаптироваться к изменению свойств объекта управления и внешней среды, пригодностью для синтеза нелинейных регуляторов, высокой устойчивость к повреждениям своих элементов в силу изначально заложенного в нейросетевую архитектуру параллелизма. В литературе описаны многочисленные примеры практического применения нейронных сетей для решения задач управление самолетом [1–3], автомобилем [4], горнообогатительным процессом [5], скоростью вращения вала двигателя [6], электропечью [7], турбогенератором [8], сварочным аппаратом [9], пневмоцилиндром [10].\nПо-видимому, идея применения\nнейронных сетей для управления динамическими объектами впервые была высказана У. Видроу [11] еще в 1964 г., однако интенсивные исследования этого направления развернулись лишь в конце 80-х годов прошлого века. Один из первых обзоров в области нейроуправления (1992 г.) упоминает 5 методов обучения нейросети для непосредственного управления объектом. С тех пор количество методов нейроуправление многократно увеличилось, по-\nявились новые решения на основе многомодульного подхода и приближенного динамического программирования.\nВ ходе развития нейроуправления,\nисследовались различные способы построения нейроконтроллеров с применением различных типов нейронных сетей: линейных типа «Адалина» [12], многослойных персептронов [13], рекуррентных сетей [14], сетей радиальных базисных функций [1] и др. Наилучшие результаты получены при использовании многослойных персептронов с линиями задержек [8], [15], [16]. Сформировались два основных направления в применения нейронных сетей внутри синтезируемых регуляторов: прямые методы, основанные на непосредственном управлении объектом с помощью нейронной сети, и непрямые методы, когда нейронная сеть используется для выполнения вспомогательных функций управления, таких как фильтрация шума или идентификация динамического объекта. В зависимости от числа нейронных сетей, составляющих нейроконтроллер, системы нейроуправления могут быть одномодульными или многомодульными. Схемы нейроуправления, которые применяются совместно с традиционными контроллерами, называются гибридными.\nКлючевой проблемой при решении\nзадач управления динамическими объектами является реализация модели инверсной динамики управляемого объекта. Аналитическое решение этой задачи не всегда возможно, поскольку требуется обращение причинно-следственных зависимостей по-\nведения реального объекта. Применение нейронных сетей позволяет находить приближенные решения этой задачи путем обучения сети на примерах управления реальным объектом. При использовании прямых методов нейроуправленяия, в частности, в методе обобщенного инверсного нейроуправления [7], [15], [17–20] это достигается путем непосредственного обучения нейронной сети на примерах поведения управляемого объекта. Однако, используемые для такого обучения последовательности примеров, полученные путем обращения результатов наблюдения реальных объектов часто содержат противоречия, резко снижающие качество обучения нейронной сети. Для решения этой проблемы предложен ряд методов. В методе специализированного инверсного нейроуправления [15], [17–21] , [22] и некоторых версиях систем адаптивной критики [3] проблема обучения инверсной динамике решается путем аппроксимации аналитической модели управляемого объекта и вычисления локальных значений якобиана для различных областей пространства состояний. В методе обратного распространения ошибки через прямой нейроэмулятор для формирования линеаризованной модели инверсной динамики объекта используется обычная схема обратного распространения ошибки, применяемая для обучения многослойных персептронов. В системах многомодульного нейроуправлении эта же задача решается путем разделения пространства состояний объекта на локальные области, в которых инверсные модели представлены однозначными функциями. Для каждой такой области выделяется отдельный нейронный модуль [20], [23]. Перспективными для моделирования инверсной динамики могут оказаться новые типы нейронных сетей, позволяющие моделировать многозначные функции, в частности, вероятностные сети Бишопа на основе смесей гауссовских моделей (Mixture Density Networks) [24].\n1. Структура системы управления динамическими\nобъектами\nВ задачах нейроуправления для\nпредставления объекта управления используют модель черного ящика, в котором наблюдаемыми являются текущие значения входа и выхода. Состояние объекта считается недоступным для внешнего наблюдения, хотя размерность вектора состояний обычно считается фиксированной. Динамику поведения объекта управления можно представить в дискретном виде:\n)),(),(()1( kukSkS  (1)\n)),(()1( kSky  (2)\nгде NkS )( – значение N -мерного век-\nтора состояния объекта на k -м такте; Pku )( – значение P -мерного вектора\nуправления; Vky  )1( – значение\nV -мерного выхода объекта управления на такте 1k .\nОбщая схема управления динами-\nческим объектом показана на рис.1.\nРис. 1. Общая схема управления\nпо обратной связи\nДля оценки вектора состояния ди-\nнамического объекта порядка может быть использована модель нелинейной авторегрессии с дополнительными входными сигналами (NARX) [25]:\n.\n)(\n...\n)2(\n)1(\n)(\n...\n)1(\n)(\n)(\n           \n\n           \n\n\n\n\n\n\n\nQku\nku\nku\nNky\nky\nky\nkS\n(3)\nРис. 2. Схема подражающего нейроуправления: слева – режим обучения\nнейронной сети; справа – режим управления\nНа практике, это соотношение\nобычно используют без ретроспективных управляющих входов:\n.\n)(\n...\n)1(\n)(\n)(\n     \n\n     \n\n\n \nNky\nky\nky\nkS\n(4)\nСостояние динамического объекта\nможно также представить мгновенным снимком его фазовой траектории:\n.\n)(\n...\n)'(\n)(\n)(\n)(     \n\n\n     \n\n\nNky\nky\nky\nkS\n(5)\nПри описании конкретных схем\nнейроуправления мы будем отдавать предпочтение модели (4). На схемах для ввода в контроллер задержанных данных обратной связи будет использоваться модуль линии задержек «TDL» (Tapped Delay Line). Для упрощения мы будем рассматривать только одноканальные системы управления (SISO), однако приводящиеся соотношения могут использоваться и для многоканальных систем (MIMO). Для этого следует лишь заменить в формулах скалярные переменные на входе и выходе объекта управления векторными.\n2. Подражающее нейроуправление\nНазвание «подражающее нейро-\nуправление» (Neurocontrol learning based on mimic, Controller Modeling, Supervised Learning Using an Existing Controller) [11], [19–21] охватывает системы нейроуправления, в которых нейроконтроллер обуча-\nется на примерах динамики обычного контроллера по обратной связи, построенного, например, на основе обычной пропорционально-интегрально-дифференциальной (ПИД) схемы управления. Схема подражающего нейроуправления показана на рис. 2. После обучения нейронная сеть в точности воспроизводит функции исходного контроллера. В качестве примеров динамики контроллера может быть использована запись поведения человекаоператора. Обучающая выборка для нейронной сети формируется следующим образом.\nОбычный контроллер по обратной\nсвязи (или человек-оператор) управляет объектом управления в штатном режиме. Значения величин на входе и выходе контролера протоколируются, и на основе протокола формируется обучающая выборка для нейроной нейроной сети M iii TPU 1},{  , содержащая M пар зна-\nчений входа iP и ожидаемых реакций iT нейросети:\n,])()1([ Ti iSirP  (6)\n).(iuTi  (7)\nПосле обучения с помощью, напри-\nмер, метода обратного распространения ошибки, нейронная сеть подключается вместо исходного контроллера. Полученный нейроконтроллер может заменить человека в управлении устройством, а также быть более выгодным экономически, чем исходный контроллер. Основным недостатком этого метода является необходимость в предварительно настроенном исходном контроллере, что не всегда представляется возможным. Кроме того, полученный путем обучения нейроконтроллер в принципе не может обеспечить лучшее\nРис. 3. Схема обобщенного инверсного нейроуправления: слева – режим обучения\nинверсного нейроэмулятора; справа – режим управления объектом\nкачество управления, чем копируемый контроллер. Поэтому, сейчас подражающее нейроуправление применяют, в основном, для первичного обучения нейронной сети с использованием других методов для последующего дообучения нейроконтроллера.\n3. Инверсное нейроуправление При инверсном нейроуправлении формирование инверсной модели объекта управления осуществляется путем обучения нейронной сети. Известно несколько разновидностей такого нейроуправления.\nОбобщенное инверсное нейро-\nуправление (Generalized Inverse Neurocontrol, Direct Inverse Neurocontrol) [7], [15], [17–20], предусматривает обучение сети в режиме офф-лайн, на основе записанных траекторий поведения динамического объекта. Для получения таких траекторий, на объект управления в качестве управляющего сигнала подают некоторый случайный процесс. Значения управляющих сигналов и ответных реакций объекта протоколируют и на этой основе формируют обучающую выборку M\niii TPU 1},{  :\n,])1()([ Ti iSiyP  (8)\n).(iuTi  (9)\nВ ходе обучения, нейронная сеть\nдолжна уловить и запомнить зависимость\nзначений управляющего сигнала )1( ku от последуюшего значения реакции объекта управления )(ky , находящегося перед\nэтим в состоянии )1( kS . Для обучения\nнейронной сети используют метод обрат-\nного распространения ошибки (см. [24, 25]). Эту нейронную сеть называют «инверсный нейроэмулятор».\nПри управлении объектом, инверс-\nный нейроэмулятор подключается как контроллер, причем возможны два способа подключения: замкнутый и разомкнутый.\nПри замкнутом подключении, схема\nкоторого показана на рис. 3 слева, на вход нейроконтроллера подаются текущие значения уставки и вектора состояния объекта управления, поступающего по цепи обратной связи:\n.])()1([)( TkSkrkx  (10)\nБлагодаря стабилизирующему вли-\nянию обратной связи, достигается достаточно высокое качество управления динамическим объектом. В работе [47] представлена вариация обобщенного инверсного управления, в которой в качестве уставки вместо одного целевого значения подается целевая траектория на L тактов\nвперед: ])(...)2()1([ Lkrkrkr  .\nПри разомкнутом подключении на\nвход нейроконтроллера поступают только значения уставки с задержками: TNkrkrkrkx )]1(..)()1([)(  (11)\nПри этом предполагается, что\nсформированная при обучении инверсная модель объекта управления является адекватной, следовательно сигнал управления, выдаваемый нейронной сетью, обеспечит переход объекта в положение, заданное уставкой. Разомкнутая система нейроуправления обладает высоким быстродействием, поскольку на вход нейроконтроллера не поступает значение текущего со-\nстояния объекта управления, обработка которого требует значительных ресурсов. Однако, из-за отсутствия обратной связи качество такого управления оказывается низким [20].\nДостоинством обобщенного ин-\nверсного нейроуправления является обучения нейроконтроллера в режиме оффлайн и отсутствие необходимости в точной математической модели объекта управления. К недостаткам следует отнести сложность формирования обучающей выборки из-за необходимости тщательного подбора идентифицирующего случайного процесса, подаваемого на вход системы, а также низкое качество работы в тех случаях, когда инверсия объекта управления оказывается неоднозначной функцией. Неоднозначность приводит к наличию противоречий в обучающей выборке, заводящих в тупик процесс обучения нейронной сети.\nСпециализированное инверсное\nнейроуправление (Specialised Inverse Neurocontrol) [15], [17–22], позволяет обучать инверсный нейроконтроллер в режиме он-лайн, используя ошибку отклонения положения объекта от уставки yre  . Схема подключения нейронной\nсети к объекту управления показана на рис. 3, справа. На вход сети поступает вектор\n.])()1([)( TkSkrkx  (12)\nВ ответ нейронная сеть генерирует\nуправляющий сигнал )(ku , который при-\nводит объект управления в положение\n)1( ky . Далее вычисляется ошибка рабо-\nты нейроконтроллера\n).1()1()(  kykrke (13)\nКоррекция весовых коэффициентов\nнейронной сети выполняется по методу наискорейшего спуска:\n),()()1( kwkwkw \n(14)\n. )(\n)(\n)(\n)1( )()(\nkw\nku\nku\nky kekw\n\n\n\n  \n(15)\nЗдесь  — параметр скорости обу-\nчения нейронной сети. Величина производной в правой части формулы (14)\n)(\n)(\nkw\nku\n\n вычисляется по методу обратного\nраспространения ошибки. Производная\n)(\n)1(\nku\nky\n\n представляет собой якобиан\nобъекта управления, значение которого можно найти аналитически по заданной математической модели объекта управления. Однако, на практике, для получения приемлемого качества управления часто бывает достаточно вычислить лишь знак якобиана [22], [25]. Итерации коррекции значений коэффициентов w продолжаются до достижения приемлемого качества управления.\nПлюсом данного подхода является\nболее высокое качество управления по сравнению с обобщенным методом инверсного нейроуправления. Его существенным недостатком является необходимость знания точной математической модели объекта управления, требуемой для обучения нейроконтроллера.\nМетод обратного пропуска ошиб-\nки через прямой нейроэмулятор (Backpropagation Through Time, Internal Model Control) [17], [19], [20], [26–28] основан на идее применения тандема из двух нейронных сетей, одна из которых выполняет функцию контроллера, а вторая прямого нейроэмулятора, который обучается моделировать динамику объекта управления (рис. 4). В процессе обучения нейроконтроллера, текущая ошибка управления пропускается через нейроэмулятор в обратном направлении.\nПри обучении прямого нейроэмуля-\nтора, на вход объекта управления подается случайный управляющий сигнал u , изменяющий положение объекта управления y ,\nи формируется обучающая выборка M iii TPU 1},{  :\n,)]1()([ T i iSiuP  (16)\n).(iyTi  (17)\nОбучение прямого нейроэмулятора\nвыполняется в режиме офф-лайн. Нейроэмулятор считается обученным, если при одинаковых значениях на входах нейро\nРис. 4. Метод обратного пропуска ошибки через прямой нейроэмулятор: слева – схема\nобучения прямого нейроэмулятора; cправа – схема обучения нейроконтроллера\nэмулятора и реального объекта, отличие между значениями их выходов становится незначительным. После завершения обучения прямого нейроэмулятора, проводится обучение нейроконтроллера. Обучение выполняется в режиме он-лайн по такой же схеме, как и в случае инверсного специализированного нейроуправления. Сначала (на такте k ) на вход нейроконтроллера поступает желаемое положение объекта\nуправления для следующего такта )1( kr .\nНейроконтроллер генерирует сигнал\nуправления )(ku , который поступает на\nвходы объекта управления и нейроэмулятора. В результате, управляемый объект переходит в положение )1( ky , а нейро-\nэмулятор генерирует реакцию )1(ˆ ky .\nДалее вычисляется ошибка управления\n)1()1(ˆ)(  kykyke и пропускается в\nобратном направлении по правилу обратного распространения. Весовые коэффициенты связей нейроэмулятора при этом не корректируются. Механизм обратного прохождения ошибки через прямой нейроэмулятор реализует локальную инверсную модель в текущей точке пространства состояний объекта управления. Пройдя через нейроэмулятор, ошибка далее распространяется через нейроконтроллер, но теперь ее прохождение сопровождается коррекцией весовых коэффициентов нейроконтроллера. Нейроэмулятор при этом выполняет функции дополнительных слоев нейроной сети нейроконтроллера, в которых веса связей не корректируются.\n4. Прогнозирующее нейроуправление Метод обучения нейроконтролле-\nров, при котором минимизируется отклонение текущего положения объекта управления от уставки для каждого такта, не всегда обеспечивает наилучшее интегральное качество управления, оцениваемое выражением:\n.))()(( 1 2 \n K\nk\nkykrIAE (18)\nПричин тому несколько. Во-первых,\nкачество управления ухудшается из-за свойства запаздывания минимум на один такт, общего для систем управления по обратной связи. Во-вторых, если для достижения целевого положения нужно несколько тактов, нейроконтроллер, стремясь минимизировать текущую ошибку, может выдать чрезмерно сильный управляющий сигнал, что ведет к перерегулированию.\nПрогнозирующее модельное нейро-\nуправление (NN Predictive Control , Model Predictive Control, Neural Generalized Predictive Control) [17], [29], [30–33] минимизирует функционал стоимости интегральной ошибки, прогнозируемой на\n),max( 32 LLL  , 210 LL  тактов\nвперед:\n \n2\n1\n2)()( L\nLi\nikekQ\n.))1()(( 2 0 2   L i ikuiku\n(19)\nРис. 5. Схема прогнозирующего\nмодельного нейроуправления\nЗдесь e – ошибка выхода системы,  –\nвклад изменения управляющего сигнала в общий функционал стоимости Q . Схема\nпоказана на рис. 5. Для прогнозирования будущего поведения системы и вычисления ошибок используется прямой нейроэмулятор, обученный так же, как в случае обратного распространения ошибки через прямой нейроэмулятор (см. рис. 4, слева). Примечательность этого метода состоит в том, что в нем отсутствует обучаемый нейроконтроллер. Его место занимает оптимизационный модуль, работающий в режиме реального времени, в котором может быть использован сиплексметод [31] или квази-Ньютоновский алгоритм [32].\nОптимизационный модуль получа-\nет на такте k целевую траекторию на L тактов вперед, а если ее нет, то L раз дублирует значение текущей уставки )1( kr и\nиспользует это в качестве целевой траектории. Далее, для выбора оптимального управляющего воздействия, вычисления происходят во внутреннем цикле системы нейроуправления (его итерации обозначены как j ). За время одного такта управле-\nния оптимизационный модуль подает на вход нейроэмулятора серию различных воздействий ),(ˆ jtku  , где t – глубина\nпрогнозирования, 10  Lt , получает различные варианты поведения системы\n),1(ˆ jtky  , вычисляет функцию стои-\nмости по формуле (19) и определяет наилучшую стратегию управления\n}),1(ˆ;...;),1(ˆ),(ˆ{ 21 LjLkujkujkuST  в смысле минимизации функционала стоимости (19). В итоге, на объект подается\nуправляющий сигнал ),(ˆ)( 1jkuku  . На\nследующем такте стратегия ST пересчитывается заново.\nМинусом систем прогнозирующего\nмодельного нейроуправления является невозможность их применения в системах с большой частотой дискретизации, так как оптимизационный алгоритм, работающий в режиме реального времени, за время одного такта не будет успевать находить наилучшую стратегию действий.\nМетоды нейроуправления на ос-\nнове адаптивной критики (Adaptive Critics), которые также известны как «Приближенное динамическое программирование» (Approximated Dynamic Programming, ADP), в последние годы весьма популярны [3], [8], [16], [33–35]. Подобно системам прогнозирующего модельного управления, системы адаптивной критики выбирают управляющий сигнал на основе оценок ошибок будущего с бесконечным горизонтом:\n.)()( 0\n2 \n  i\ni ikekJ \n(20)\nЗдесь  – коэффициент забывания, 10   ;\n)(ke – ошибка, вычисляемая по формуле\n(13). Система включает два нейронных модуля: нейроконтроллер и модуль критики. Нейроконтроллер обучают минимизировать функционал стоимости )(kJ , кото-\nрый играет ту же роль, что и ошибка )(ke в методах обучения по ошибке обратной связи. Модуль критики выполняет аппроксимацию значений функции стоимости.\nНа рис. 6, слева показана схема ра-\nботы системы адаптивной критики в режиме управления объектом. На вход нейроконтроллера поступает вектор TkSkrkx )]()1([)(  , вызывающий появ-\nление на его выходе сигнала управления\n)(ku , в результате чего объект управления\nпереходит в положение )1( ky . Далее\nпроизводится вычисление значения те-\nкущей ошибки управления )(ke .\nМодуль критики, получая на входе\nвектор TkSkukrkz )]()()1([)(  , про-\nизводит оценку функции стоимости )(kJ .\nНа следующем такте процесс повторяется:\nРис. 6. Схема адаптивной критики: слева – этап управления; справа – этап обучения\nвычисляются новые значения )1( ke и\n)1( kJ .\nОбучение системы нейроуправле-\nния происходит в режиме он-лайн и состоит из двух этапов: обучения модуля критики и обучения нейроконтроллера. Сначала, рассчитывается ошибка временной разности )(k :\n).(ˆ)1(ˆ)()( kJkJkek  \n(21)\nЗатем по методу наискорейшего\nспуска выполняется коррекция веса свя-\nзей для модуля критики CRITICw :\n. )(\n)( )()( 1\nkw\nkJ kkw\nCRITIC\nCRITIC \n  \n(22)\nЗначение градиента )(\n)(\nkw\nkJ\nCRITIC\n рас-\nсчитывается по методу обратного распространения ошибки. Коррекция веса связей\nнейроконтроллера CONTROLw производит-\nся аналогично:\n. )(\n)(\n)(\n)( )( 2\nkw\nku\nku\nkJ kw\nCONTROL\nCONTROL \n\n\n  \n(23)\nЗначение производной находят\nпутем обратного распространения величины через модуль критики, а значение градиента – путем обратного распространения ошибки через модуль контроллера. Коррекция весов продолжается, пока система не достигнет требуемого уровня качества управления. Таким образом, на каждом шаге улучшается закон управления, путем обучения нейроконтроллера (Policy Iteration), а также повышается способность системы оценивать ситуацию, путем обучения критика (Value Iteration).\nКонкретная схема построения си-\nстемы адаптивной критики может отличаться от вышеописанной, носящей название Heuristic Dynamic Programming (HDP). В методе DHP (Dual Heuristic\nProgramming), где модуль критики вычисляет производную функционала глобаль-\nной стоимости t\nJ\n\n , а в методе GDHP\n(Global Dual Heuristic Programming) вычисляются как сам функционал функции\nстоимости J , так и его производная t\nJ\n\n .\nИзвестны модификации метода, в которых модуль критики принимает решения исключительно на основе управляющего сигнала )(ku [35]. Они имеют\nприставкуAD («Action Dependent»): ADHDP, ADDHP, ADGDHP. В некоторых версиях адаптивной критики модуль критики состоит из двух частей: собственно, модуля критики и прямого нейроэмулятора. Последний выдает предсказания поведение объекта управления, на основе которых критик формирует оценку функции\nстоимости J . Такие версии носят название «основанные на модели» («Model based»). Систематическое описание существующих разновидностей систем адаптивной критики представлено в [3].\nПопулярность систем адаптивной\nкритики объясняется наличием развитой теоретической базы в виде теории динамического программирования Беллмана, а также их способностью сходиться к оптимальному или близкому к оптимальному управлению [35].\n`\n5. Многомодульное нейроyправление\nМногомодульные нейросистемы,\nпостроенные по типу комитетов экспертов [25], получили значительное распространение в системах распознавания, позже они дали толчок развитию многомодульных систем нейроуправления. В рамках многомодульного подхода, исходная задача разделяется на отдельные подзадачи,\nРис. 7. Схема многомодульного нейроуправления на основе пар прямых и инверсных\nмоделей: слева – этап переоценки коэффициентов ответственности модулей;\ncправа – этап коллективного управления\nкоторые решают отдельные модули. Финальное решение выполняет шлюзовая сеть на основе частных решений модулейэкспертов.\nСистемы многомодульного нейро-\nуправления на основе локальных инверсных моделей (Incremental Clustered Control Networks) [20], [23], состоят из множества линейных нейроконтроллеров и шлюзового модуля. Каждый из линейных нейроконтроллеров представляет нейронную сеть Адалина [25], обученную управлять в пределах локальной области пространства состояний объекта:\n.\n);(\n...\n);( 1111\n   \n\n   \n\n\n\n\nlLlLlLlN\nllll\nl\ndydy\ndydy\nLS\nЗдесь L – количество модулей-\nэкспертов. Преимуществом линейных сетей перед многослойными персептронами состоит в том, что их поведение проще анализировать, а также они быстрее обучаются. Это особенно важно для анализа устойчивости синтезируемой системы управления. Для формирования линейных нейроконтроллеров могут применяться различные методы: обобщенное инверсное нейроуправление, специализированное инверсное нейроуправление, метод обратного пропуска ошибки через нейроэмулятор.\nПосле того, как локальные линей-\nные нейроконтроллеры были обучены, производится обучение шлюзовой сети.\nОна обучается по входной оценке состояния управляемого объекта )(kS находить\nлокальную область пространства состоя-\nний jLS такую, что jLSkS )( и выдавать\nна объект управления сигнал )(ku j , сгене-\nрированный локальным линейным нейроконтроллером, соответствующим этому локальному участку. Недостатком этого метода является необходимость в большом количестве примеров для обучения нейроконтроллеров, распределенных во всех областях пространства состояний управляемого объекта.\nМетод многомодульного нейроупра-\nвления на основе пар прямых и инверсных моделей (Multiple Paired Forward and Inverse Models, Multiple Switched Models), [36–40] показан на рис. 7. В отличие от метода нейроуправления на основе локальных инверсных моделей, в котором поведение системы формируется при обучении, и в ходе управления не корректируется, данный метод предусматривает корректировку поведения нейронных модулей на каждом такте нейроуправления. Для этого, каждый модуль включает два нейроэмулятора: прямой и инверсный. Обучение прямого нейроэмулятора производится по схеме метода обратного пропуска ошибки через прямой нейроэмулятор, показанной на рис. 4, слева. Инверсный нейроэмулятора обучается по схеме обобщенного инверсного нейроуправления, показанной рис. 3, слева. Предполагается, что каждая пара нейроэмуляторов обучается на своем примере динамики объекта управления\nи специализируется именно на нем. Поэтому, если прямой нейроэмулятор правильно предсказывает динамику объекта управления, то соответствующий ему инверсный нейроэмулятор хорошо управляет объектом. Предполагается также, что применяющиеся для обучения пар эмуляторов траектории состояний управляемого объекта существенно отличаются между собой.\nРабота системы на каждом такте\nвключает два этапа: 1) переоценки коэффициентов ответственности модулей и 2) коллективного управления модулями на основе вычисленных коэффициентов ответственности. Общая схема работы системы нейроуправления, состоящей из L модулей, показана на рис. 7. На первом этапе, на вход прямого нейроэмулятора каждого из модулей поступает сигнал )1( ku , соответствующий значению\nуправления на предыдущем такте, а также вектор предыдущего состояния )1( kS ,\nхарактеризующий предыдущее положение управляемого объекта. По входным данным, каждый прямой нейроэмулятор производит свою оценку текущего положения\nобъекта )}(ˆ;...;)(ˆ{ 1 kyky L , после чего вычисляются ошибки оценок предвидения для всех модулей системы:\n,)}(;...;)({ 1 keke L )(ˆ)()( kykyke ll  , .1 Ll \n(24)\nНа основе ошибок предвидения,\nрассчитываются коэффициенты предвиде-\nния )}(;...;)({ 1 kk L ,  – масштабирующая константа:\n,\n)/)(exp(\n)/)(exp( )(\n1\n22\n22\n \n\n \nL\nj\nj\nl l\nke\nke k\n\n \n.1 1  \n L j j\n(25)\nНа этапе управления, инверсный\nнейроэмулятор l -го модуля действует по схеме обобщенного инверсного нейроуправления. На его вход поступают значе-\nние уставки )(kr и оценки текущего со-\nстояния объекта )1( kS , вызывая реакцию\n)(kul . Итоговый управляющий сигнал )(ku представляет собой взвешенную сум-\nму управляющих сигналов отдельных модулей, при этом управляющий сигнал каждого модуля обеспечивает вклад, пропорциональный коэффициенту предвидения соответствующего модуля:\n.)()()( 1  \n L\nl\nll kukku \n(26)\nВ некоторых системах, вместо этой\nформулы при выборе текущего управляющего модуля применяют принцип «победитель получает все» [35, 36]. Впрочем, проблема выбора способа декомпозиции задачи на подзадачи характерна для многомодульного подхода вообще.\nСущественным минусом систем\nмногомодульного нейроуправления является непрозрачная процедура разделения обучающей выборки на подвыборки для обучения прямых и инверсных нейроэмуляторов разных модулей.\n6. Гибридное нейроуправление Гибридными называют системы нейроуправления, в которых нейронные сети работают совместно с обычными контроллерами, ПИД-регуляторами или другими типами контроллеров.\nГибридное нейро-ПИД управле-\nние (NNPID Auto-tuning, Neuromorphic PID Self-tuning) [9], [17], [41, 43] позволяет осуществлять самонастройку ПИДрегулятора в режиме он-лайн с использованием нейронных сетей.\nУправление с использованием\nПИД-контроллера основано на минимизации ошибки обратной связи. Вырабатываемый контроллером сигнал управления представляет взвешенную сумму пропорциональной, интегральной и дифференциальной частей:\n. )(\n)()()( 3 0 21 dt\ntde KdeKteKtu\nt\n  \n(27)\nКоэффициенты 1K , 2K , 3K получаются\nпри настройке ПИД-контроллера, которая может быть выполнена вручную по правилу Зиглера – Никольса, правилу Коэна – Куна или другими методами [43], либо с использованием нейронной сети, как показано на рис. 8.\nРис. 9. Схема гибридного\nпараллельного нейроуправления\nРис. 8. Схема гибридного нейро-ПИД\nуправления\nОбученная система нейроуправле-\nния действует следующим образом. На такте k нейронная сеть получает уставку )1( kr и генерирует коэффициенты\nуправления ПИД-контроллера )(1 kK ,\n)(2 kK , )(3 kK , которые поступают на\nПИД-контроллер вместе со значением те-\nкущей ошибки обратной связи )(ke , вы-\nчисляемой по формуле (11). ПИДконтроллер рассчитывает управляющий сигнал )(ku по формуле:\n ))1()()(()1()( 1 kekekKkuku\n )()(()()( 32 kekKkekK )),2()1(2  keke\n(28)\nприменяемой для дискретных ПИДконтроллеров и подает его на объект управления.\nОбучение нейросети происходит в\nрежиме реального времени по ошибке обратной связи, методом наискорейшего спуска:\n. )(\n)(\n)(\n)(\n)(\n)1( )()(\nkw\nkK\nkK\nku\nku\nky kekw\n\n\n\n\n\n   (29)\nЗдесь TkKkKkKkK )]()()([)( 321 –\nвектор выходов нейронной сети, поступающий на ПИД-контроллер.\n \n \n\n\n\n \n\n)2()(2)(\n)(\n)1()( )(\nkekeke\nke\nkeke\nK\nku\ni\nпри i = 1;\nпри i = 2; (30)\nпри i = 3.\nГрадиенты вычисляют методом\nобратного распространения ошибки. Якобиан находится аналитически, на основе математической модели объекта управления. Плюсами использования этого подхода является упрощение эксплуатации вследствие устранения процедуры настройки ПИД-контроллера вручную. Кроме того, в случае применения нейронной сети с нелинейными активационными функциями, ПИД-контроллер фактически\nпревращается в нелинейный контроллер, что потенциально обеспечивает более высокое качество управления нелинейными динамическими объектами. Обратная сторона медали – сложность оценки устойчивости полученного нелинейного контроллера. Также минусом является необходимость в точной математической модели объекта управления, необходимой для вычисления якобиана объекта управления. Эту трудность можно обойти, используя прямой нейроэмулятор и действуя по методу обратного распространения ошибки через прямой нейроэмулятор.\nМетоды гибридного параллель-\nного нейроуправления (Parallel Neurocontrol, Stable Direct Adaptive Control, NARMA L2 Feedback Linearization Control, Additive Feedforward Control) [7], [17], [29] предусматривают параллельное использование нейроконтроллеров и обычных контроллеров для управления динамическими объектами. Соответствующая схема показана на рис. 9. При этом нейроконтроллер и обычный контроллер, в роли которого выступает, например, ПИДконтроллер, получают одинаковые значения уставки.\nВозможны следующие варианты\nсовместного подключения обычного контроллера и нейроконтроллера:\n1) к объекту управления подключа-\nется обычный контроллер, после чего нейроконтроллер обучается управлять уже замкнутой обычным контроллером систе-\nмой. После обучения нейроконтроллера, он подключается к системе, а управляющие сигналы обоих контроллеров суммируются;\n2) нейроконтроллер учится управ-\nлять объектом управления, после обучения\nРис. 10. Схема метода нейросетевой\nфильтрации внешних возмущений\nначинает функционировать в штатном режиме. Далее, для управления замкнутой нейроконтроллером системой настраивается обычный контроллер. После настройки обычного контроллера, он подключается к системе, управляющий сигнал обоих контроллеров суммируется;\n3) области действия обычного кон-\nтроллера и нейроконтроллера разграничиваются. Например, в пространстве состояний объекта управления для нейроконтроллера выделяется отдельная область\nLS :\n.\n);(\n...\n);( 1111\n   \n\n   \n\n\n\n\nNNNN dydy\ndydy\nLS\nПри этом, обычный контроллер\nрассчитывается на управление объектом вне этой области пространства состояния. При параллельной работе обоих контроллеров, управляющий сигнал поступает на объект либо от нейроконтроллера, если текущее состояние системы находится в пределах области LS , либо, в противном случае, от обычного контроллера.\nГибридное параллельное нейро-\nуправление представляет компромиссное решение для внедрения нейроуправления в промышленность и перехода от обычных контроллеров к нейросетевым.\n7. Вспомогательное нейроуправление Нейронные сети могут решать раз-\nличные вспомогательные задачи, возникающие в ходе управления динамическим объектом. Качество управления контроллера можно повысить и сделать траекторию движения объекта управления более гладкой при использовании метода нейросетевой фильтрации внешних возмущений (Adaptive Inverse Control, Adaptive Inverse Control based on Linear and Nonlinear Adaptive Filtering, Internal Model Control) [7], [12, 13], [18]. Изначально, эта схема была предложена Б. Видроу для использования совместно с нейроконтроллерами, обученными по методу обобщенноинверсного нейроуправления [12]. В более поздней работе [13] им были применены нейроконтроллеры, обученные по методу\nобратного распространения ошибки через прямой нейроэмулятор. В принципе, нейросетевую фильтрацию ошибок можно использовать для повышения качества работы контроллера любого типа, не обязательно нейросетевого. Схема работы такой подсистемы показана на рис. 10. В ней используется две предварительно обученных нейронных сети: инверсный нейроэмулятор, обученный так же, как это делается в методе обобщенного инверсного нейроуправления (рис. 3, слева) и прямой нейроэмулятор, обученный так же, как это делается в методе обратного распространения ошибки через прямой нейроэмулятор (рис. 4, слева).\nПусть на объект управления посту-\nпает управляющий сигнал )(ˆ kuFIN , явившийся результатом суммирования сигнала контроллера )(ˆ ku и корректирующего\nсигнала системы фильтрации внешних возмущений )(ˆ kuCORR , вычисленного на предыдущем такте. Сигнал )(ˆ kuFIN направляется на прямой нейроэмулятор объекта управления, а реакция прямого нейроэму-\nлятора )(ˆ ky сравнивается с реальным по-\nложением системы )(ky . Разница этих ве-\nличин )(ke трактуется как нежелательное\nотклонение системы, вызванное внешним возмущением. Для подавления нежела-\nтельного эффекта, сигнал )(ke поступает\nна инверсный нейроэмулятор, который рассчитывает корректирующий сигнал )1(ˆ kuCORR для корректировки управляющего сигнала нейроконтроллера )1(ˆ ku на\nследующем такте. Для использования этого метода, объект управления должен об-\nРис. 11. Схема нейроуправления\nс эталонной моделью\nладать обращаемой динамикой, а также необходимо иметь адекватную математическую или имитационную модель объекта управления для обучения прямого и инверсного нейроэмуляторов.\nНейроуправление с эталонной\nмоделью (Model Reference Adaptive Control, Neural Adaptive Control) [11], [15], [18], [26] – вариант нейроуправления по методу обратного распространения ошибки через прямой нейроэмулятор, с дополнительно внедренной в схему эталонной моделью (Reference Model). Это делается в целях повышения устойчивости переходного процесса: в случае, когда переход объекта в целевое положение за один такт невозможен, траектория движения и время осуществления переходного процесса становятся плохо прогнозируемыми величинами и могут привести к нежелательным режимам работы системы. Схема нейроуправления с эталонной моделью показана на рис. 11.\nДля уменьшения этой неопреде-\nленности, между уставкой и нейроконтроллером вводится эталонная модель, представляющая собой, как правило, линейную динамическую систему невысокого порядка, которую можно легко аналитически проверить на устойчивость. В ходе как обучения, так и управления, эталонная модель получает на вход уставку r и генерирует опорную траекторию r , которая дальше поступает на нейроконтроллер в качестве новой уставки, которую нужно выполнить. Эталонная модель подбирается таким образом, чтобы генерируемая ею опорная траектория на каждом такте была достижима для объекта управления. Хотя под системой нейроуправления по эталонной модели чаще всего подразумевается именно система конструкции К. Нарендры и К. Пасарати [26], нет принципиальных ограничений против применения эталонных моделей совместно с си-\nстемами нейроуправления других типов, например, обобщенного инверсного нейроуправления или специализированного инверсного нейроуправления.\nК. Кришнакумаром и др. [2], [42]\nпредложена оригинальная модификация нейроуправления с адаптируемой эталонной моделью для создания аварийноустойчивой системы управления летательным аппаратом. В качестве контроллера используется классический неадаптируемый ПИД-контроллер, а эталонная модель представляет система нейроуправления типа адаптивной критики, способная менять свое поведение в ходе полета, генерируя на выходе для отслеживания контроллером различные опорные траектории. Эталонная модель дообучается в режиме он-лайн путем минимизации среднеквадратичной ошибки отклонения траектории движения объекта управления от целевой траектории. Такую адаптивную систему можно рассматривать как обычный нейроконтроллер типа адаптивной критики, управляющий объединенной динамической системой «ПИД-контроллер + объект управления».\nВыводы За последние 20 лет нейроуправле-\nние получило значительное развитие. Как было обозначено в одном из первых обзоров по тематике нейроуправления [21] в качестве перспективного направления исследований, доминирующая доля внимания была уделена задачам разработки нейросистем для управления нелинейными динамическими объектами, получено множество примеров успешно работающих систем этого типа. В качестве универсального эффективного метода нейроуправления был заявлен разработанный относительно недавно метод адаптивной критики. Показано, что рекуррентные сети типа NARX наилучшим образом подходят для моделирования динамических систем [44], что привело к их распространению в качестве идентификаторов объектов управления в непрямых и прогнозирующих методах нейроуправления. Вместе с тем, все существующие на сегодняшний день алгоритмы обучения рекуррентных\nнейросетей являются вариациями разработанных в начале 90-х алгоритмов BPTT и RTRL [45], обучение которых проходит сравнительно медленно и требует значительных вычислительных ресурсов.\nВместе с тем, остается ряд нере-\nшенных проблем, мешающих широкому применению систем нейроуправления в индустрии.\n1. Все еще отсутствует универсаль-\nная процедура анализа устойчивости нелинейных нейроконтролеров. Были предложены лишь частные решения для отдельных видов нейроконтроллеров при известной математической модели объекта управления.\n2. Конструкция почти всех схем\nнейроуправления выглядит слишком усложненной из-за наличия нескольких нейросетей и нетривиальной последовательности процедур их обучения. Перспективным направлением исследований является получение унифицированного алгоритма обучения единой управляющей нейросети.\n3. Для дальнейшего развития мето-\nдов нейроуправления, актуальной проблемой остается создание новых моделей динамических нейронных сетей и способов из обучения, так как базовыми блоками построения многих методов нейроуправления являются эмпирически полученные модели прямой или инверсной динамики объекта управления."
    }, {
      "heading" : "1. Li Y., Sundararajan N., Saratchandran P.",
      "text" : "Neuro-controller design for nonlinear fighter aircraft maneuver using fully tuned RBF networks // Automatica. – 2001. – Vol. 37, N 8. – P. 1293 – 1301. 2. Gundy-Burlet K., Krishnakumar K., Limes G., Bryant D. Augmentation of an Intelligent\nFlight Control System for a Simulated C-17 Aircraft // J. of Aerospace Computing, Information, and Communication. – 2004. – Vol. 1, N 12. – P. 526 – 542. 3. Prokhorov D. and Wunsch D. Adaptive Critic Designs // IEEE Transactions on\nNeural Networks. – 1997. – Vol. 8, N 5. – P. 997 – 1007. 4. Архангельский В.И., Богаенко И.Н., Грабовский Г.Г., Рюмшин Н.А. Нейронные се-\nти в системах автоматизации. – К.: Техника, 1999. – 234 c.\n5. Купін А.І. Інтеллектуальна ідентифікація та керування в умовах процесів збагачуваль-\nної технології. – Кривий Ріг: КТУ, 2008. – 204 с. 6. Терехов В.А., Ефимов Д.В., Тюкин И.Ю. Нейросетевые системы управления: Учеб.\nпособие для вузов. – М.: Высш. школа 2002. – 183 с. 7. Dias F.M., Mota A.M. Comparison between Different Control Strategies using Neural\nNetworks // 9th Mediterranean Conference on Control and Automation. – Dubrovnik, Croatia, 2001. 8. Venayagamoorthy G.K., Harley R.G., Wunsch D.C. Implementation of Adaptive Critic-\nbased Neurocontrollers for Turbogenerators in a Multimachine Power System”, IEEE Transactions on Neural Networks. – 2003. – Vol. 14, Issue 5. – P. 1047 – 1064. 9. D’Emilia G., Marrab A., Natalea E. Use of neural networks for quick and accurate auto-\ntuning of PID controller // Robotics and Computer-Integrated Manufacturing. – 2007. – Vol. 23. – P. 170 – 179. 10. Змеу К.В., Марков Н.А., Шипитько И.А., Ноткин Б.С. Безмодельное прогнозирую-\nщее инверсное нейроуправление с регенерируемым эталонным переходным процессом // Интеллектуальные системы. – 2009. – № 3. – С. 109 – 117. 11. Widrow B., Smith F.W. Pattern-recognizing control systems // Proceedings of Computer\nand Information Sciences. – Washington, USA – 1964. – Vol. 12. – P. 288 – 317. 12. Widrow B., Adaptive Inverse Control // Proceedings of the 2nd IFAC Workshop on\nAdaptive Systems in Control and Signal Processing – Lund, Sweden, July 1986. – P. 1 – 5. 13. Widrow B., Plett G.L. Adaptive Inverse Control based on Linear and Nonlinear Adaptive\nFiltering // Proceedings of International Workshop on Neural Networks for Identification, Control, Robotics, and Signal/Image Processing – 21–23 Aug 1996, Venice, Italy. – P. 30 – 38. 14. Zhang Y., Wang J. Recurrent neural networks for nonlinear output regulation // Automatica.\n– 2001. – Vol. 37, N 8. – P. 1161 – 1173.\n15. Psaltis D., Sideris A., Yamamura A.A. A Multilayered Neural Network Controller // IEEE\nControl Systems Magazine – 1988. – Vol. 8, Issue 2. – P. 17 – 21. 16. Редько В.Г., Прохоров Д.В. Нейросетевые адаптивные критики // VI Всероссийская\nнаучно-техническая конференция “Нейроинформатика-2004\". Сборник научных\nтрудов. Часть 2. М.: МИФИ, 2004. – C. 77 – 84. 17. Омату С., Халид М., Юсоф Р. Нейроуправление и его приложения: пер. с англ.\n– М.: ИПРЖР, 2000. – 272 с.\n18. Пупков К.А., Егупов Н.Д. Методы робастного, нейро-нечеткого и адаптивного\nуправления: Учебник. М. : Изд-во МГТУ им. Н.Э. Баумана, 2001. – 744 с. 19. Omidvar O., Elliott D.L. eds. Neural Systems for Control // Academic Press, New York,\n1997. – 272 с.\n20. Ronco E. Incremental Polynomial Controller Networks: Two Self-Organising Non-Linear\nControllers // Ph.D. Disseration Thesis, Glasgow, 1997. – 207 с. 21. Hunt K.J., Sbarbaro D., Zbikowski R., Gawthrop P.J. Neural Networks for Control:\nA Survey // Automatica 28. – 1992. – N 6. – P. 1083 – 1112. 22. Zhang Y., Sen P., Hearn G.F. An on-line trained adaptive controller // IEEE Control\nSystems Magazine. – 1995. – Vol. 15, N 5. – P. 67 – 75. 23. Ronco E., Gawthrop P. J., Hill D. J. Gated modular neural networks for control oriented\nmodeling // Technical Report EE-98009, Laboratory for Dynamic Systems and Control, Sydney, Australia, 1998. 24. Bishop C.M. Pattern Recognition and Machine Learning // Springer, 2006. – 738 с. 25. Хайкин С. Нейронные сети: полный курс / Хайкин С.; пер. с англ. – [2-е изд., испр.]. –\nМ.: Вильямс, 2006. – 1102 с.\n26. Narendra K.S., Parthasarathy K.K. Identification and control of dynamical systems using\nneural networks // IEEE Transactions on Neural Networks. – 1990. – N 1. – P. 4 – 27. 27. Werbos P. Backpropagation through time: what it does and how to do it // Proceedings of\nthe IEEE. – October 1990. – Vol. 78, N. 10. – P. 1550 – 1560. 28. Jordan M.I. and Rumelhart D.E. Forwardmodels: Supervised learning with a distal\nteacher // Cognitive Science – 1990. – Vol. 16. – P. 313 – 355. 29. Hagan M.T., Demuth H.B. Neural networks for control // Proceedings of the American\nControl Conference. – San Diego, USA, 1999. – Vol. 3. – P. 1642 – 1656. 30. Rossiter J.A. Model-based Predictive Control: a Practical Approach // CRC Press, 2003. –\n318 c.\n31. Takahashi Y. Adaptive Predictive Control of Nonlinear Time-Varying System using Neural\nNetwork // Proceedings of the IEEE International Conference on Neural Networks – Na-\ngoya, Japan, 25 – 29 October, 1993. – Vol. 3. – P. 1464 – 1468. 32. Soloway D., Haley P.J. Neural Generalized Predictive Control // Proceedings of the\nIEEE International Symposium on Intelligent Control. – 15 – 18 September 1996. – P. 277 – 281. 33. Lendaris G. G. A Retrospective on Adaptive Dynamic Programming for Control // Pro-\nceedings of International Joint Conference on Neural Networks, Atlanta, USA, June 14-19, 2009 – P. 1750 – 1757. 34. Barto A.G. Reinforcement learning and adaptive critic methods. // Handbook of Intelligent\nControl. – New York: Van Nostrand Reinhold, 1992. – P. 469 – 491. 35. Ferrari S., Stengel R.F. Model-Based Adaptive Critic Designs // Learning and Approxi-\nmated Dynamic Programming, J. Si, A. Barto, W. Powell, and D. Wunsch, Eds. New York: Wiley, 2004, Chapter. 3. 36. Wolpert D.M., Kawato M. Multiple Paired Forward and Inverse Models for Motor Con-\ntrol // Neural Networks. – 1998. – Vol. 11. – Issue 7 – 8. – P. 1317 – 1329. 37. Oyama E., Agah A., MacDorman K.F., Maeda T., Tachi S. A Modular Neural Network Ar-\nchitecture for Inverse Kinematics Model Learning // Neurocomputing. – 2001. – N 38 – 40. – P. 797 – 805. 38. Haruno M., Wolpert D.M., Kawato M. Multiple Paired Forward-Inverse Models for Hu-\nman Motor Learning and Control // Advances in Neural Information Processing Systems. MIT Press, Cambridge, Massachusetts. – 1999. – Vol. 11. – P. 31 – 37. 39. Narendra K.S., Kumpati S., Balakrishnan J., Ciliz K.M. Adaptation and LearningUsing\nMultiple Models, Switching and Tuning // IEEE Control Systems Magazine. – 1996. – Vol. 15, Issue 3. – P. 37 – 51. 40. Kumpati S., Narendra K.S., Balakrishnan J. Adaptive Control Using Multiple Models //\nIEEE Transactions on Automatic Control. – 1997. – Vol. 42, N. 2. – P. 171 – 187. 41. Saiful A., Omatu S. Neuromorphic self-tuning PID controller // Proceedings of IEEE Interna-\ntional Conference on Neural Networks, San Francisco, USA, 1993. – P. 552 – 557. 42. Krishnakumar K., Limes G., Gundy-Burlet K., Bryant D. An Adaptive Critic Approach to\nReference Model Adaptation // Proceedings of 2003 AIAA Guidance, Navigation, and Control Conference, August 11 – 14, Austin, USA. – P. 5790 – 5801. 43. Chang W.D., Hwang R.C., Hsiehc J.G. A multivariable on-line adaptive PID controller\nusing auto-tuning neurons // Engineering Applications of Artificial Intelligence. – 2003. – Vol. 16, Issue 1. – P. 57 – 63. 44. Siegelmann H.T., Horne B.G., Giles C.L. Computational capabilities of recurrent\nNARX neural networks // IEEE Transactions on Systems, MAN and Cybernetics, Part B:Cybernetics. – 1997. – N 27. – Vol. 2. – P. 208 – 215. 45. De Jesus O., Hagan M.T. Backpropagation: Algorithms for a Broad Class of\nDynamic Networks // IEEE Transactions on Neural Networks. – 2007. – N 1, Vol. 18. – P. 14 – 27. 46. Tan Y., De Keyser R. Auto-tuning PID control using neural predictor to compensate large\ntime-delay // Proceedings of the Third IEEE Conference on Control Applications. – 1994. – Vol. 2. – P. 1429 – 1434.\nПолучено 01.12.2010\nОб авторах:\nЧернодуб Артем Николаевич, младший научный сотрудник,\nДзюба Дмитрий Александрович, младший научный сотрудник.\nМесто работы авторов:\nИнститут проблем математических машин и систем НАН Украины, 03680, Киев-187, Проспект Академика Глушкова, 40. Тел.: (044) 526 5548. E-mail: a.chernodub@gmail.com\nddziuba@immsp.kiev.ua"
    } ],
    "references" : [ {
      "title" : "Для дальнейшего развития методов нейроуправления, актуальной проблемой остается создание новых моделей динамических нейронных сетей и способов из обучения, так как базовыми блоками построения многих методов нейроуправления являются эмпирически полученные модели прямой или инверсной динамики объекта управления",
      "author" : [ "Y. Li", "N. Sundararajan", "P. Saratchandran" ],
      "venue" : "Aircraft // J. of Aerospace Computing, Information, and Communication",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2004
    }, {
      "title" : "Comparison between Different Control Strategies using Neural Networks",
      "author" : [ "F.M. Dias", "A.M. Mota" ],
      "venue" : "Mediterranean Conference on Control and Automation",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2001
    }, {
      "title" : "Implementation of Adaptive Criticbased Neurocontrollers for Turbogenerators in a Multimachine Power System",
      "author" : [ "G.K. Venayagamoorthy", "R.G. Harley", "D.C. Wunsch" ],
      "venue" : "IEEE Transactions on Neural Networks",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2003
    }, {
      "title" : "Use of neural networks for quick and accurate autotuning of PID controller // Robotics and Computer-Integrated Manufacturing",
      "author" : [ "G. D’Emilia", "A. Marrab", "E. Natalea" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2007
    }, {
      "title" : "Pattern-recognizing control systems // Proceedings of Computer and Information Sciences",
      "author" : [ "B. Widrow", "F.W. Smith" ],
      "venue" : "Vol. 12. – P",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1964
    }, {
      "title" : "Adaptive Inverse Control",
      "author" : [ "B. Widrow" ],
      "venue" : "Proceedings of the 2nd IFAC Workshop on Adaptive Systems in Control and Signal Processing",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1986
    }, {
      "title" : "Adaptive Inverse Control based on Linear and Nonlinear Adaptive Filtering // Proceedings of International Workshop on Neural Networks for Identification, Control, Robotics, and Signal/Image Processing",
      "author" : [ "B. Widrow", "G.L. Plett" ],
      "venue" : "Venice, Italy. – P",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1996
    }, {
      "title" : "Recurrent neural networks for nonlinear output regulation",
      "author" : [ "Y. Zhang", "J. Wang" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2001
    }, {
      "title" : "A Multilayered Neural Network Controller",
      "author" : [ "D. Psaltis", "A. Sideris", "A.A. Yamamura" ],
      "venue" : "IEEE Control Systems Magazine – 1988. –",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1988
    }, {
      "title" : "eds. Neural Systems for Control",
      "author" : [ "O. Omidvar", "D.L. Elliott" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1997
    }, {
      "title" : "Incremental Polynomial Controller Networks: Two Self-Organising Non-Linear Controllers",
      "author" : [ "E. Ronco" ],
      "venue" : "Ph.D. Disseration Thesis,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1997
    }, {
      "title" : "Neural Networks for Control: A Survey",
      "author" : [ "K.J. Hunt", "D. Sbarbaro", "R. Zbikowski", "P.J. Gawthrop" ],
      "venue" : null,
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 1992
    }, {
      "title" : "An on-line trained adaptive controller // IEEE Control Systems Magazine",
      "author" : [ "Y. Zhang", "P. Sen", "G.F. Hearn" ],
      "venue" : "N 5. – P",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1995
    }, {
      "title" : "Gated modular neural networks for control oriented modeling // Technical Report EE-98009, Laboratory for Dynamic Systems",
      "author" : [ "E. Ronco", "J. Gawthrop P", "J. Hill D" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1998
    }, {
      "title" : "Pattern Recognition and Machine Learning",
      "author" : [ "C.M. Bishop" ],
      "venue" : "с",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2006
    }, {
      "title" : "Identification and control of dynamical systems using neural networks",
      "author" : [ "K.S. Narendra", "K.K. Parthasarathy" ],
      "venue" : "IEEE Transactions on Neural Networks",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1990
    }, {
      "title" : "Backpropagation through time: what it does and how to do it",
      "author" : [ "P. Werbos" ],
      "venue" : "Proceedings of the IEEE. – October",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1990
    }, {
      "title" : "Forwardmodels: Supervised learning with a distal teacher",
      "author" : [ "M.I. Jordan", "D.E. Rumelhart" ],
      "venue" : "Cognitive Science – 1990. – Vol. 16. – P",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1990
    }, {
      "title" : "Neural networks for control",
      "author" : [ "M.T. Hagan", "H.B. Demuth" ],
      "venue" : "Proceedings of the American Control Conference. – San Diego,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1999
    }, {
      "title" : "Model-based Predictive Control: a Practical Approach",
      "author" : [ "J.A. Rossiter" ],
      "venue" : null,
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2003
    }, {
      "title" : "Adaptive Predictive Control of Nonlinear Time-Varying System using Neural Network",
      "author" : [ "Y. Takahashi" ],
      "venue" : "Proceedings of the IEEE International Conference on Neural Networks – Na goya, Japan,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 1993
    }, {
      "title" : "Neural Generalized Predictive Control",
      "author" : [ "D. Soloway", "P.J. Haley" ],
      "venue" : "Proceedings of the IEEE International Symposium on Intelligent Control",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 1996
    }, {
      "title" : "A Retrospective on Adaptive Dynamic Programming for Control",
      "author" : [ "G. Lendaris G" ],
      "venue" : "Proceedings of International Joint Conference on Neural Networks, Atlanta,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2009
    }, {
      "title" : "Reinforcement learning and adaptive critic methods",
      "author" : [ "A.G. Barto" ],
      "venue" : "Handbook of Intelligent Control. – New York: Van Nostrand Reinhold,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 1992
    }, {
      "title" : "Model-Based Adaptive Critic Designs",
      "author" : [ "S. Ferrari", "R.F. Stengel" ],
      "venue" : "Learning and Approximated Dynamic Programming,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2004
    }, {
      "title" : "Multiple Paired Forward and Inverse Models for Motor Control",
      "author" : [ "D.M. Wolpert", "M. Kawato" ],
      "venue" : "Neural Networks. – 1998. – Vol. 11. – Issue",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 1998
    }, {
      "title" : "A Modular Neural Network Architecture for Inverse Kinematics Model Learning // Neurocomputing",
      "author" : [ "E. Oyama", "A. Agah", "K.F. MacDorman", "T. Maeda", "S. Tachi" ],
      "venue" : null,
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2001
    }, {
      "title" : "Multiple Paired Forward-Inverse Models for Human Motor Learning and Control // Advances in Neural Information Processing Systems",
      "author" : [ "M. Haruno", "D.M. Wolpert", "M. Kawato" ],
      "venue" : null,
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 1999
    }, {
      "title" : "Adaptation and LearningUsing Multiple Models, Switching and Tuning // IEEE Control Systems Magazine",
      "author" : [ "K.S. Narendra", "S. Kumpati", "J. Balakrishnan", "K.M. Ciliz" ],
      "venue" : "Issue 3. – P",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 1996
    }, {
      "title" : "Adaptive Control Using Multiple Models",
      "author" : [ "S. Kumpati", "K.S. Narendra", "J. Balakrishnan" ],
      "venue" : "IEEE Transactions on Automatic Control. – 1997. –",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 1997
    }, {
      "title" : "Neuromorphic self-tuning PID controller",
      "author" : [ "A. Saiful", "S. Omatu" ],
      "venue" : "Proceedings of IEEE International Conference on Neural Networks, San Francisco,",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 1993
    }, {
      "title" : "An Adaptive Critic Approach to Reference Model Adaptation",
      "author" : [ "K. Krishnakumar", "G. Limes", "K. Gundy-Burlet", "D. Bryant" ],
      "venue" : "Proceedings of 2003 AIAA Guidance, Navigation, and Control Conference,",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2003
    }, {
      "title" : "A multivariable on-line adaptive PID controller  using auto-tuning neurons",
      "author" : [ "W.D. Chang", "R.C. Hwang", "J.G. Hsiehc" ],
      "venue" : "Engineering Applications of Artificial Intelligence",
      "citeRegEx" : "43",
      "shortCiteRegEx" : "43",
      "year" : 2003
    }, {
      "title" : "Computational capabilities of recurrent NARX neural networks // IEEE Transactions on Systems, MAN and Cybernetics, Part B:Cybernetics",
      "author" : [ "H.T. Siegelmann", "B.G. Horne", "C.L. Giles" ],
      "venue" : "N 27. – Vol. 2. – P",
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 1997
    }, {
      "title" : "Backpropagation: Algorithms for a Broad Class of Dynamic Networks",
      "author" : [ "O. De Jesus", "M.T. Hagan" ],
      "venue" : "IEEE Transactions on Neural Networks",
      "citeRegEx" : "45",
      "shortCiteRegEx" : "45",
      "year" : 2007
    }, {
      "title" : "Auto-tuning PID control using neural predictor to compensate large time-delay",
      "author" : [ "Y. Tan", "R. De Keyser" ],
      "venue" : "Proceedings of the Third IEEE Conference on Control Applications. – 1994. –",
      "citeRegEx" : "46",
      "shortCiteRegEx" : "46",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "В литературе описаны многочисленные примеры практического применения нейронных сетей для решения задач управление самолетом [1–3], автомобилем [4], горнообогатительным процессом [5], скоростью вращения вала двигателя [6], электропечью [7], турбогенератором [8], сварочным аппаратом [9], пневмоцилиндром [10].",
      "startOffset" : 124,
      "endOffset" : 129
    }, {
      "referenceID" : 1,
      "context" : "В литературе описаны многочисленные примеры практического применения нейронных сетей для решения задач управление самолетом [1–3], автомобилем [4], горнообогатительным процессом [5], скоростью вращения вала двигателя [6], электропечью [7], турбогенератором [8], сварочным аппаратом [9], пневмоцилиндром [10].",
      "startOffset" : 235,
      "endOffset" : 238
    }, {
      "referenceID" : 2,
      "context" : "В литературе описаны многочисленные примеры практического применения нейронных сетей для решения задач управление самолетом [1–3], автомобилем [4], горнообогатительным процессом [5], скоростью вращения вала двигателя [6], электропечью [7], турбогенератором [8], сварочным аппаратом [9], пневмоцилиндром [10].",
      "startOffset" : 257,
      "endOffset" : 260
    }, {
      "referenceID" : 3,
      "context" : "В литературе описаны многочисленные примеры практического применения нейронных сетей для решения задач управление самолетом [1–3], автомобилем [4], горнообогатительным процессом [5], скоростью вращения вала двигателя [6], электропечью [7], турбогенератором [8], сварочным аппаратом [9], пневмоцилиндром [10].",
      "startOffset" : 282,
      "endOffset" : 285
    }, {
      "referenceID" : 4,
      "context" : "Видроу [11] еще в 1964 г.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 5,
      "context" : "В ходе развития нейроуправления, исследовались различные способы построения нейроконтроллеров с применением различных типов нейронных сетей: линейных типа «Адалина» [12], многослойных персептронов [13], рекуррентных сетей [14], сетей радиальных базисных функций [1] и др.",
      "startOffset" : 165,
      "endOffset" : 169
    }, {
      "referenceID" : 6,
      "context" : "В ходе развития нейроуправления, исследовались различные способы построения нейроконтроллеров с применением различных типов нейронных сетей: линейных типа «Адалина» [12], многослойных персептронов [13], рекуррентных сетей [14], сетей радиальных базисных функций [1] и др.",
      "startOffset" : 197,
      "endOffset" : 201
    }, {
      "referenceID" : 7,
      "context" : "В ходе развития нейроуправления, исследовались различные способы построения нейроконтроллеров с применением различных типов нейронных сетей: линейных типа «Адалина» [12], многослойных персептронов [13], рекуррентных сетей [14], сетей радиальных базисных функций [1] и др.",
      "startOffset" : 222,
      "endOffset" : 226
    }, {
      "referenceID" : 2,
      "context" : "Наилучшие результаты получены при использовании многослойных персептронов с линиями задержек [8], [15], [16].",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 8,
      "context" : "Наилучшие результаты получены при использовании многослойных персептронов с линиями задержек [8], [15], [16].",
      "startOffset" : 98,
      "endOffset" : 102
    }, {
      "referenceID" : 1,
      "context" : "При использовании прямых методов нейроуправленяия, в частности, в методе обобщенного инверсного нейроуправления [7], [15], [17–20] это достигается путем непосредственного обучения нейронной сети на примерах поведения управляемого объекта.",
      "startOffset" : 112,
      "endOffset" : 115
    }, {
      "referenceID" : 8,
      "context" : "При использовании прямых методов нейроуправленяия, в частности, в методе обобщенного инверсного нейроуправления [7], [15], [17–20] это достигается путем непосредственного обучения нейронной сети на примерах поведения управляемого объекта.",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 9,
      "context" : "При использовании прямых методов нейроуправленяия, в частности, в методе обобщенного инверсного нейроуправления [7], [15], [17–20] это достигается путем непосредственного обучения нейронной сети на примерах поведения управляемого объекта.",
      "startOffset" : 123,
      "endOffset" : 130
    }, {
      "referenceID" : 10,
      "context" : "При использовании прямых методов нейроуправленяия, в частности, в методе обобщенного инверсного нейроуправления [7], [15], [17–20] это достигается путем непосредственного обучения нейронной сети на примерах поведения управляемого объекта.",
      "startOffset" : 123,
      "endOffset" : 130
    }, {
      "referenceID" : 8,
      "context" : "В методе специализированного инверсного нейроуправления [15], [17–21] , [22] и некоторых версиях систем адаптивной критики [3] проблема обучения инверсной динамике решается путем аппроксимации аналитической модели управляемого объекта и вычисления локальных значений якобиана для различных областей пространства состояний.",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 9,
      "context" : "В методе специализированного инверсного нейроуправления [15], [17–21] , [22] и некоторых версиях систем адаптивной критики [3] проблема обучения инверсной динамике решается путем аппроксимации аналитической модели управляемого объекта и вычисления локальных значений якобиана для различных областей пространства состояний.",
      "startOffset" : 62,
      "endOffset" : 69
    }, {
      "referenceID" : 10,
      "context" : "В методе специализированного инверсного нейроуправления [15], [17–21] , [22] и некоторых версиях систем адаптивной критики [3] проблема обучения инверсной динамике решается путем аппроксимации аналитической модели управляемого объекта и вычисления локальных значений якобиана для различных областей пространства состояний.",
      "startOffset" : 62,
      "endOffset" : 69
    }, {
      "referenceID" : 11,
      "context" : "В методе специализированного инверсного нейроуправления [15], [17–21] , [22] и некоторых версиях систем адаптивной критики [3] проблема обучения инверсной динамике решается путем аппроксимации аналитической модели управляемого объекта и вычисления локальных значений якобиана для различных областей пространства состояний.",
      "startOffset" : 62,
      "endOffset" : 69
    }, {
      "referenceID" : 12,
      "context" : "В методе специализированного инверсного нейроуправления [15], [17–21] , [22] и некоторых версиях систем адаптивной критики [3] проблема обучения инверсной динамике решается путем аппроксимации аналитической модели управляемого объекта и вычисления локальных значений якобиана для различных областей пространства состояний.",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 0,
      "context" : "В методе специализированного инверсного нейроуправления [15], [17–21] , [22] и некоторых версиях систем адаптивной критики [3] проблема обучения инверсной динамике решается путем аппроксимации аналитической модели управляемого объекта и вычисления локальных значений якобиана для различных областей пространства состояний.",
      "startOffset" : 123,
      "endOffset" : 126
    }, {
      "referenceID" : 10,
      "context" : "Для каждой такой области выделяется отдельный нейронный модуль [20], [23].",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 13,
      "context" : "Для каждой такой области выделяется отдельный нейронный модуль [20], [23].",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 14,
      "context" : "Перспективными для моделирования инверсной динамики могут оказаться новые типы нейронных сетей, позволяющие моделировать многозначные функции, в частности, вероятностные сети Бишопа на основе смесей гауссовских моделей (Mixture Density Networks) [24].",
      "startOffset" : 246,
      "endOffset" : 250
    }, {
      "referenceID" : 4,
      "context" : "Подражающее нейроуправление Название «подражающее нейроуправление» (Neurocontrol learning based on mimic, Controller Modeling, Supervised Learning Using an Existing Controller) [11], [19–21] охватывает системы нейроуправления, в которых нейроконтроллер обучается на примерах динамики обычного контроллера по обратной связи, построенного, например, на основе обычной пропорционально-интегрально-дифференциальной (ПИД) схемы управления.",
      "startOffset" : 177,
      "endOffset" : 181
    }, {
      "referenceID" : 9,
      "context" : "Подражающее нейроуправление Название «подражающее нейроуправление» (Neurocontrol learning based on mimic, Controller Modeling, Supervised Learning Using an Existing Controller) [11], [19–21] охватывает системы нейроуправления, в которых нейроконтроллер обучается на примерах динамики обычного контроллера по обратной связи, построенного, например, на основе обычной пропорционально-интегрально-дифференциальной (ПИД) схемы управления.",
      "startOffset" : 183,
      "endOffset" : 190
    }, {
      "referenceID" : 10,
      "context" : "Подражающее нейроуправление Название «подражающее нейроуправление» (Neurocontrol learning based on mimic, Controller Modeling, Supervised Learning Using an Existing Controller) [11], [19–21] охватывает системы нейроуправления, в которых нейроконтроллер обучается на примерах динамики обычного контроллера по обратной связи, построенного, например, на основе обычной пропорционально-интегрально-дифференциальной (ПИД) схемы управления.",
      "startOffset" : 183,
      "endOffset" : 190
    }, {
      "referenceID" : 11,
      "context" : "Подражающее нейроуправление Название «подражающее нейроуправление» (Neurocontrol learning based on mimic, Controller Modeling, Supervised Learning Using an Existing Controller) [11], [19–21] охватывает системы нейроуправления, в которых нейроконтроллер обучается на примерах динамики обычного контроллера по обратной связи, построенного, например, на основе обычной пропорционально-интегрально-дифференциальной (ПИД) схемы управления.",
      "startOffset" : 183,
      "endOffset" : 190
    }, {
      "referenceID" : 1,
      "context" : "Обобщенное инверсное нейроуправление (Generalized Inverse Neurocontrol, Direct Inverse Neurocontrol) [7], [15], [17–20], предусматривает обучение сети в режиме офф-лайн, на основе записанных траекторий поведения динамического объекта.",
      "startOffset" : 101,
      "endOffset" : 104
    }, {
      "referenceID" : 8,
      "context" : "Обобщенное инверсное нейроуправление (Generalized Inverse Neurocontrol, Direct Inverse Neurocontrol) [7], [15], [17–20], предусматривает обучение сети в режиме офф-лайн, на основе записанных траекторий поведения динамического объекта.",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 9,
      "context" : "Обобщенное инверсное нейроуправление (Generalized Inverse Neurocontrol, Direct Inverse Neurocontrol) [7], [15], [17–20], предусматривает обучение сети в режиме офф-лайн, на основе записанных траекторий поведения динамического объекта.",
      "startOffset" : 112,
      "endOffset" : 119
    }, {
      "referenceID" : 10,
      "context" : "Обобщенное инверсное нейроуправление (Generalized Inverse Neurocontrol, Direct Inverse Neurocontrol) [7], [15], [17–20], предусматривает обучение сети в режиме офф-лайн, на основе записанных траекторий поведения динамического объекта.",
      "startOffset" : 112,
      "endOffset" : 119
    }, {
      "referenceID" : 14,
      "context" : "[24, 25]).",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 10,
      "context" : "Однако, из-за отсутствия обратной связи качество такого управления оказывается низким [20].",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 8,
      "context" : "Специализированное инверсное нейроуправление (Specialised Inverse Neurocontrol) [15], [17–22], позволяет обучать инверсный нейроконтроллер в режиме он-лайн, используя ошибку отклонения положения объекта от уставки y r e   .",
      "startOffset" : 80,
      "endOffset" : 84
    }, {
      "referenceID" : 9,
      "context" : "Специализированное инверсное нейроуправление (Specialised Inverse Neurocontrol) [15], [17–22], позволяет обучать инверсный нейроконтроллер в режиме он-лайн, используя ошибку отклонения положения объекта от уставки y r e   .",
      "startOffset" : 86,
      "endOffset" : 93
    }, {
      "referenceID" : 10,
      "context" : "Специализированное инверсное нейроуправление (Specialised Inverse Neurocontrol) [15], [17–22], позволяет обучать инверсный нейроконтроллер в режиме он-лайн, используя ошибку отклонения положения объекта от уставки y r e   .",
      "startOffset" : 86,
      "endOffset" : 93
    }, {
      "referenceID" : 11,
      "context" : "Специализированное инверсное нейроуправление (Specialised Inverse Neurocontrol) [15], [17–22], позволяет обучать инверсный нейроконтроллер в режиме он-лайн, используя ошибку отклонения положения объекта от уставки y r e   .",
      "startOffset" : 86,
      "endOffset" : 93
    }, {
      "referenceID" : 12,
      "context" : "Специализированное инверсное нейроуправление (Specialised Inverse Neurocontrol) [15], [17–22], позволяет обучать инверсный нейроконтроллер в режиме он-лайн, используя ошибку отклонения положения объекта от уставки y r e   .",
      "startOffset" : 86,
      "endOffset" : 93
    }, {
      "referenceID" : 12,
      "context" : "Однако, на практике, для получения приемлемого качества управления часто бывает достаточно вычислить лишь знак якобиана [22], [25].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 9,
      "context" : "Метод обратного пропуска ошибки через прямой нейроэмулятор (Backpropagation Through Time, Internal Model Control) [17], [19], [20], [26–28] основан на идее применения тандема из двух нейронных сетей, одна из которых выполняет функцию контроллера, а вторая прямого нейроэмулятора, который обучается моделировать динамику объекта управления (рис.",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 10,
      "context" : "Метод обратного пропуска ошибки через прямой нейроэмулятор (Backpropagation Through Time, Internal Model Control) [17], [19], [20], [26–28] основан на идее применения тандема из двух нейронных сетей, одна из которых выполняет функцию контроллера, а вторая прямого нейроэмулятора, который обучается моделировать динамику объекта управления (рис.",
      "startOffset" : 126,
      "endOffset" : 130
    }, {
      "referenceID" : 15,
      "context" : "Метод обратного пропуска ошибки через прямой нейроэмулятор (Backpropagation Through Time, Internal Model Control) [17], [19], [20], [26–28] основан на идее применения тандема из двух нейронных сетей, одна из которых выполняет функцию контроллера, а вторая прямого нейроэмулятора, который обучается моделировать динамику объекта управления (рис.",
      "startOffset" : 132,
      "endOffset" : 139
    }, {
      "referenceID" : 16,
      "context" : "Метод обратного пропуска ошибки через прямой нейроэмулятор (Backpropagation Through Time, Internal Model Control) [17], [19], [20], [26–28] основан на идее применения тандема из двух нейронных сетей, одна из которых выполняет функцию контроллера, а вторая прямого нейроэмулятора, который обучается моделировать динамику объекта управления (рис.",
      "startOffset" : 132,
      "endOffset" : 139
    }, {
      "referenceID" : 17,
      "context" : "Метод обратного пропуска ошибки через прямой нейроэмулятор (Backpropagation Through Time, Internal Model Control) [17], [19], [20], [26–28] основан на идее применения тандема из двух нейронных сетей, одна из которых выполняет функцию контроллера, а вторая прямого нейроэмулятора, который обучается моделировать динамику объекта управления (рис.",
      "startOffset" : 132,
      "endOffset" : 139
    }, {
      "referenceID" : 18,
      "context" : "Прогнозирующее модельное нейроуправление (NN Predictive Control , Model Predictive Control, Neural Generalized Predictive Control) [17], [29], [30–33] минимизирует функционал стоимости интегральной ошибки, прогнозируемой на",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 19,
      "context" : "Прогнозирующее модельное нейроуправление (NN Predictive Control , Model Predictive Control, Neural Generalized Predictive Control) [17], [29], [30–33] минимизирует функционал стоимости интегральной ошибки, прогнозируемой на",
      "startOffset" : 143,
      "endOffset" : 150
    }, {
      "referenceID" : 20,
      "context" : "Прогнозирующее модельное нейроуправление (NN Predictive Control , Model Predictive Control, Neural Generalized Predictive Control) [17], [29], [30–33] минимизирует функционал стоимости интегральной ошибки, прогнозируемой на",
      "startOffset" : 143,
      "endOffset" : 150
    }, {
      "referenceID" : 21,
      "context" : "Прогнозирующее модельное нейроуправление (NN Predictive Control , Model Predictive Control, Neural Generalized Predictive Control) [17], [29], [30–33] минимизирует функционал стоимости интегральной ошибки, прогнозируемой на",
      "startOffset" : 143,
      "endOffset" : 150
    }, {
      "referenceID" : 22,
      "context" : "Прогнозирующее модельное нейроуправление (NN Predictive Control , Model Predictive Control, Neural Generalized Predictive Control) [17], [29], [30–33] минимизирует функционал стоимости интегральной ошибки, прогнозируемой на",
      "startOffset" : 143,
      "endOffset" : 150
    }, {
      "referenceID" : 20,
      "context" : "Его место занимает оптимизационный модуль, работающий в режиме реального времени, в котором может быть использован сиплексметод [31] или квази-Ньютоновский алгоритм [32].",
      "startOffset" : 128,
      "endOffset" : 132
    }, {
      "referenceID" : 21,
      "context" : "Его место занимает оптимизационный модуль, работающий в режиме реального времени, в котором может быть использован сиплексметод [31] или квази-Ньютоновский алгоритм [32].",
      "startOffset" : 165,
      "endOffset" : 169
    }, {
      "referenceID" : 0,
      "context" : "Методы нейроуправления на основе адаптивной критики (Adaptive Critics), которые также известны как «Приближенное динамическое программирование» (Approximated Dynamic Programming, ADP), в последние годы весьма популярны [3], [8], [16], [33–35].",
      "startOffset" : 219,
      "endOffset" : 222
    }, {
      "referenceID" : 2,
      "context" : "Методы нейроуправления на основе адаптивной критики (Adaptive Critics), которые также известны как «Приближенное динамическое программирование» (Approximated Dynamic Programming, ADP), в последние годы весьма популярны [3], [8], [16], [33–35].",
      "startOffset" : 224,
      "endOffset" : 227
    }, {
      "referenceID" : 22,
      "context" : "Методы нейроуправления на основе адаптивной критики (Adaptive Critics), которые также известны как «Приближенное динамическое программирование» (Approximated Dynamic Programming, ADP), в последние годы весьма популярны [3], [8], [16], [33–35].",
      "startOffset" : 235,
      "endOffset" : 242
    }, {
      "referenceID" : 23,
      "context" : "Методы нейроуправления на основе адаптивной критики (Adaptive Critics), которые также известны как «Приближенное динамическое программирование» (Approximated Dynamic Programming, ADP), в последние годы весьма популярны [3], [8], [16], [33–35].",
      "startOffset" : 235,
      "endOffset" : 242
    }, {
      "referenceID" : 24,
      "context" : "Методы нейроуправления на основе адаптивной критики (Adaptive Critics), которые также известны как «Приближенное динамическое программирование» (Approximated Dynamic Programming, ADP), в последние годы весьма популярны [3], [8], [16], [33–35].",
      "startOffset" : 235,
      "endOffset" : 242
    }, {
      "referenceID" : 24,
      "context" : "сигнала ) (k u [35].",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 0,
      "context" : "Систематическое описание существующих разновидностей систем адаптивной критики представлено в [3].",
      "startOffset" : 94,
      "endOffset" : 97
    }, {
      "referenceID" : 24,
      "context" : "Популярность систем адаптивной критики объясняется наличием развитой теоретической базы в виде теории динамического программирования Беллмана, а также их способностью сходиться к оптимальному или близкому к оптимальному управлению [35].",
      "startOffset" : 231,
      "endOffset" : 235
    }, {
      "referenceID" : 10,
      "context" : "Системы многомодульного нейроуправления на основе локальных инверсных моделей (Incremental Clustered Control Networks) [20], [23], состоят из множества линейных нейроконтроллеров и шлюзового модуля.",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 13,
      "context" : "Системы многомодульного нейроуправления на основе локальных инверсных моделей (Incremental Clustered Control Networks) [20], [23], состоят из множества линейных нейроконтроллеров и шлюзового модуля.",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 25,
      "context" : "Метод многомодульного нейроуправления на основе пар прямых и инверсных моделей (Multiple Paired Forward and Inverse Models, Multiple Switched Models), [36–40] показан на рис.",
      "startOffset" : 151,
      "endOffset" : 158
    }, {
      "referenceID" : 26,
      "context" : "Метод многомодульного нейроуправления на основе пар прямых и инверсных моделей (Multiple Paired Forward and Inverse Models, Multiple Switched Models), [36–40] показан на рис.",
      "startOffset" : 151,
      "endOffset" : 158
    }, {
      "referenceID" : 27,
      "context" : "Метод многомодульного нейроуправления на основе пар прямых и инверсных моделей (Multiple Paired Forward and Inverse Models, Multiple Switched Models), [36–40] показан на рис.",
      "startOffset" : 151,
      "endOffset" : 158
    }, {
      "referenceID" : 28,
      "context" : "Метод многомодульного нейроуправления на основе пар прямых и инверсных моделей (Multiple Paired Forward and Inverse Models, Multiple Switched Models), [36–40] показан на рис.",
      "startOffset" : 151,
      "endOffset" : 158
    }, {
      "referenceID" : 29,
      "context" : "Метод многомодульного нейроуправления на основе пар прямых и инверсных моделей (Multiple Paired Forward and Inverse Models, Multiple Switched Models), [36–40] показан на рис.",
      "startOffset" : 151,
      "endOffset" : 158
    }, {
      "referenceID" : 24,
      "context" : "В некоторых системах, вместо этой формулы при выборе текущего управляющего модуля применяют принцип «победитель получает все» [35, 36].",
      "startOffset" : 126,
      "endOffset" : 134
    }, {
      "referenceID" : 25,
      "context" : "В некоторых системах, вместо этой формулы при выборе текущего управляющего модуля применяют принцип «победитель получает все» [35, 36].",
      "startOffset" : 126,
      "endOffset" : 134
    }, {
      "referenceID" : 3,
      "context" : "Гибридное нейро-ПИД управление (NNPID Auto-tuning, Neuromorphic PID Self-tuning) [9], [17], [41, 43] позволяет осуществлять самонастройку ПИДрегулятора в режиме он-лайн с использованием нейронных сетей.",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 30,
      "context" : "Гибридное нейро-ПИД управление (NNPID Auto-tuning, Neuromorphic PID Self-tuning) [9], [17], [41, 43] позволяет осуществлять самонастройку ПИДрегулятора в режиме он-лайн с использованием нейронных сетей.",
      "startOffset" : 92,
      "endOffset" : 100
    }, {
      "referenceID" : 32,
      "context" : "Гибридное нейро-ПИД управление (NNPID Auto-tuning, Neuromorphic PID Self-tuning) [9], [17], [41, 43] позволяет осуществлять самонастройку ПИДрегулятора в режиме он-лайн с использованием нейронных сетей.",
      "startOffset" : 92,
      "endOffset" : 100
    }, {
      "referenceID" : 32,
      "context" : "при настройке ПИД-контроллера, которая может быть выполнена вручную по правилу Зиглера – Никольса, правилу Коэна – Куна или другими методами [43], либо с использованием нейронной сети, как показано на рис.",
      "startOffset" : 141,
      "endOffset" : 145
    }, {
      "referenceID" : 1,
      "context" : "Методы гибридного параллельного нейроуправления (Parallel Neurocontrol, Stable Direct Adaptive Control, NARMA L2 Feedback Linearization Control, Additive Feedforward Control) [7], [17], [29] предусматривают параллельное использование нейроконтроллеров и обычных контроллеров для управления динамическими объектами.",
      "startOffset" : 175,
      "endOffset" : 178
    }, {
      "referenceID" : 18,
      "context" : "Методы гибридного параллельного нейроуправления (Parallel Neurocontrol, Stable Direct Adaptive Control, NARMA L2 Feedback Linearization Control, Additive Feedforward Control) [7], [17], [29] предусматривают параллельное использование нейроконтроллеров и обычных контроллеров для управления динамическими объектами.",
      "startOffset" : 186,
      "endOffset" : 190
    }, {
      "referenceID" : 1,
      "context" : "нейросетевой фильтрации внешних возмущений (Adaptive Inverse Control, Adaptive Inverse Control based on Linear and Nonlinear Adaptive Filtering, Internal Model Control) [7], [12, 13], [18].",
      "startOffset" : 169,
      "endOffset" : 172
    }, {
      "referenceID" : 5,
      "context" : "нейросетевой фильтрации внешних возмущений (Adaptive Inverse Control, Adaptive Inverse Control based on Linear and Nonlinear Adaptive Filtering, Internal Model Control) [7], [12, 13], [18].",
      "startOffset" : 174,
      "endOffset" : 182
    }, {
      "referenceID" : 6,
      "context" : "нейросетевой фильтрации внешних возмущений (Adaptive Inverse Control, Adaptive Inverse Control based on Linear and Nonlinear Adaptive Filtering, Internal Model Control) [7], [12, 13], [18].",
      "startOffset" : 174,
      "endOffset" : 182
    }, {
      "referenceID" : 5,
      "context" : "Видроу для использования совместно с нейроконтроллерами, обученными по методу обобщенноинверсного нейроуправления [12].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 6,
      "context" : "В более поздней работе [13] им были применены нейроконтроллеры, обученные по методу обратного распространения ошибки через прямой нейроэмулятор.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 4,
      "context" : "Нейроуправление с эталонной моделью (Model Reference Adaptive Control, Neural Adaptive Control) [11], [15], [18], [26] – вариант нейроуправления по методу обратного распространения ошибки через прямой нейроэмулятор, с дополнительно внедренной в схему эталонной моделью (Reference Model).",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 8,
      "context" : "Нейроуправление с эталонной моделью (Model Reference Adaptive Control, Neural Adaptive Control) [11], [15], [18], [26] – вариант нейроуправления по методу обратного распространения ошибки через прямой нейроэмулятор, с дополнительно внедренной в схему эталонной моделью (Reference Model).",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 15,
      "context" : "Нейроуправление с эталонной моделью (Model Reference Adaptive Control, Neural Adaptive Control) [11], [15], [18], [26] – вариант нейроуправления по методу обратного распространения ошибки через прямой нейроэмулятор, с дополнительно внедренной в схему эталонной моделью (Reference Model).",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 15,
      "context" : "Пасарати [26], нет принципиальных ограничений против применения эталонных моделей совместно с системами нейроуправления других типов, например, обобщенного инверсного нейроуправления или специализированного инверсного нейроуправления.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 31,
      "context" : "[2], [42] предложена оригинальная модификация нейроуправления с адаптируемой эталонной моделью для создания аварийноустойчивой системы управления летательным аппаратом.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 11,
      "context" : "Как было обозначено в одном из первых обзоров по тематике нейроуправления [21] в качестве перспективного направления исследований, доминирующая доля внимания была уделена задачам разработки нейросистем для управления нелинейными динамическими объектами, получено множество примеров успешно работающих систем этого типа.",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 33,
      "context" : "Показано, что рекуррентные сети типа NARX наилучшим образом подходят для моделирования динамических систем [44], что привело к их распространению в качестве идентификаторов объектов управления в непрямых и прогнозирующих методах нейроуправления.",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 34,
      "context" : "нейросетей являются вариациями разработанных в начале 90-х алгоритмов BPTT и RTRL [45], обучение которых проходит сравнительно медленно и требует значительных вычислительных ресурсов.",
      "startOffset" : 82,
      "endOffset" : 86
    } ],
    "year" : 2015,
    "abstractText" : null,
    "creator" : "Microsoft® Word 2010"
  }
}