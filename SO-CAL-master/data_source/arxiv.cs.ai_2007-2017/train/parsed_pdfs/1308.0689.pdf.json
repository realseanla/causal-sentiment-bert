{
  "name" : "1308.0689.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "JOHANNES BORGSTRÖMa", "ANDREW D. GORDONb", "MICHAEL GREENBERG", "JAMES MARGETSONd", "JURGEN VAN GAEL", "J. VAN GAEL", "Csoft", "FACTORIE", "Figaro", "HANSEI", "HBC", "IBAL" ],
    "emails" : [ "borgstrom@acm.org", "adg@microsoft.com,", "jfdm1@roundwood.org", "mgree@seas.upenn.edu", "jurgen.vangael@gmail.com" ],
    "sections" : [ {
      "heading" : "1. INTRODUCTION",
      "text" : "In the past 15 years, statistical machine learning has unified many seemingly unrelated methods through the Bayesian paradigm. With a solid understanding of the theoretical foundations, advances in algorithms for inference, and numerous applications, the Bayesian paradigm is now the state of the art for learning from data. The theme of this paper is the idea of expressing Bayesian models as probabilistic programs, which was pioneered by BUGS [14] and is recently gaining in popularity,\n2012 ACM CCS: [Theory of computation]: Semantics and reasoning—Program constructs; [Computing methodologies]: Machine learning—Machine learning approaches.\nKey words and phrases: Probabilistic Programming, Model-based Machine Learning, Programming Languages, Denotational Semantics. ∗ An abridged version of this paper appears in the proceedings of the 20th European Symposium on Programming (ESOP’11), part of ETAPS 2011, held in Saarbrücken, Germany, March 26–April 3, 2011.\nLOGICAL METHODS lIN COMPUTER SCIENCE DOI:10.2168/LMCS-9(3:11)2013\nc© J. Borgström, A. D. Gordon, M. Greenberg, J. Margetson, and J. Van Gael CC© Creative Commons\nwitness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].\nIn particular, we draw inspiration from Csoft [52], an imperative language where programs denote factor graphs [28], data structures that support efficient inference algorithms [25]. Csoft is the native language of Infer.NET [37], a software library for Bayesian reasoning. This paper gives an alternative probabilistic semantics to languages with features similar to those of Csoft.\nBayesian Models as Probabilistic Expressions. Consider a simplified form of TrueSkill [19], a large-scale online system for ranking computer gamers. There is a population of players, each assumed to have a skill, which is a real number that cannot be directly observed. We observe skills only indirectly via a series of matches. The problem is to infer the skills of players given the outcomes of the matches. Here is a concrete example: Alice, Bob, and Cyd are new players."
    }, {
      "heading" : "In a tournament of three games, Alice beats Bob, Bob beats Cyd, and Alice beats Cyd. What are",
      "text" : "their skills? In a Bayesian setting, we represent our uncertain knowledge of the skills as continuous probability distributions. The following probabilistic expression models the situation by generating probability distributions for the players’ skills, given three played games (observations).\n// prior distributions, the hypothesis let skill() = random (Gaussian(10.0,20.0)) let Alice,Bob,Cyd = skill(),skill(),skill() // observe the evidence let performance player = random (Gaussian(player,1.0)) observe (performance Alice > performance Bob) //Alice beats Bob observe (performance Bob > performance Cyd) //Bob beats Cyd observe (performance Alice > performance Cyd) //Alice beats Cyd // return the skills Alice,Bob,Cyd\nA run of this expression goes as follows. We sample the skills of the three players from the prior distribution Gaussian(10.0,20.0). Such a distribution can be pictured as a bell curve centred on the mean 10.0, and gradually tailing off at a rate given by the variance, here 20.0. Sampling from such a distribution is a randomized operation that returns a real number, most likely close to the mean. For each match, the run continues by sampling an individual performance for each of the two players. Each performance is centred on the skill of a player, with low variance, making the performance closely correlated with but not identical to the skill. We then observe that the winner’s performance is greater than the loser’s. An observation observe M always returns (), but represents a constraint that M must be true. A whole run is valid if all encountered observations are true. The run terminates by returning the three skills.\nA classic computational method to compute an approximate posterior distribution of each of the skills is Monte Carlo sampling [31]. We run the expression many times, but keep just the valid runs—the ones where the sampled skills and performances are consistent with the observed outcomes. We then compute the means of the resulting skills by applying standard statistical formulas. In the example above, the posterior distribution of the returned skills moves so that the mean of Alice’s skill is greater than Bob’s, which is greater than Cyd’s. To the best of our knowledge, all prior inference techniques for probabilistic languages with continuous distributions, apart from Csoft and\nrecent versions of IBAL [43], are based on nondeterministic inference using some form of Monte Carlo sampling.\nInference algorithms based on factor graphs [28, 25] are an efficient alternative to Monte Carlo sampling. Factor graphs, used in Csoft, allow deterministic but approximate inference algorithms, which are known to be significantly more efficient than sampling methods, where applicable.\nObservations with zero probability arise naturally in Bayesian models. For example, in the model above, a drawn game would be modelled as the performance of two players being observed to be equal. Since the performances are randomly drawn from a continuous distribution, the probability of them actually being equal is zero, so we would not expect to see any valid runs in a Monte Carlo simulation. (To use Monte Carlo methods, one must instead write that the absolute difference between two drawn performances is less than some small ε .) However, our semantics based on measure theory makes sense of such observations. Our semantics is the first for languages with continuous or hybrid distributions, such as Fun or Imp, that are implemented by deterministic inference via factor graphs.\nPlan of the Paper. We propose Fun: • Fun is a functional language for Bayesian models with primitives for probabilistic sampling and observations (Section 2). • Fun programs have a rigorous probabilistic semantics as measure transformers (Section 3). • Fun has an efficient implementation: our system compiles Fun to Imp (Section 4), a subset of\nCsoft, and then relies on Infer.NET (Section 6). • Fun supports array types and array comprehensions in order to express Bayesian models over\nlarge datasets (Section 5).\nOur main contribution is a framework for finite measure transformer semantics, which supports discrete measures, continuous measures, and mixtures of the two, and also supports observations of zero probability events.\nAs a substantial application, we supply measure transformer semantics for Fun and Imp, and use the semantics to verify the translations in our compiler. Theorem 3.3 establishes agreement with the discrete semantics of Section 2 for Bernoulli Fun. Theorem 4.4 establishes the correctness of the compilation from Fun to Imp.\nWe designed Fun to be a subset of the F# dialect of ML [51], for implementation convenience: F# reflection allows easy access to the abstract syntax of a program. All the examples in the paper have been executed with our system, described in Section 6. We end the paper with a description of related work (Section 7) and some concluding remarks (Section 8).\nAppendix A contains proofs omitted from the main body of the paper. The technical report version of our paper [8] includes additional details, including the code of an F# implementation of measure transformers in the discrete case."
    }, {
      "heading" : "2. BAYESIAN MODELS AS PROBABILISTIC EXPRESSIONS",
      "text" : "We introduce the idea of expressing a probabilistic model as code in a functional language, Fun, with primitives for generating and observing random variables. As an illustration, we first consider a subset, Bernoulli Fun, limited to weighted Boolean choices. We describe in elementary terms an operational semantics for Bernoulli Fun that allows us to compute the conditional probability that the expression yields a given value given that the run was valid.\n2.1. Syntax, Informal Semantics, and Bayesian Reading. Expressions are strongly typed, with types t,u built up from base scalar types b and pair types. We let c range over constant data of scalar type, n over integers, and r over real numbers. We write ty(c) = t to mean that constant c has type t. For each base type b, we define a zero element 0b with 0bool = true, and let 0t∗u = (0t ,0u). We have arithmetic and Boolean operations ⊕ on base types."
    }, {
      "heading" : "Types, Constant Data, and Zero Elements:",
      "text" : "b ::= bool | int | real base type t,u ::= unit | b | (t ∗u) compound type ty(()) = unit ty(true) = ty(false) = bool ty(n) = int ty(r) = real 0bool = true 0int = 0 0real = 0.0\nSignatures of Arithmetic and Logical Operators: ⊗ : b1,b2 → b3 &&, ||,= : bool,bool → bool >,= : int, int → bool +,−,∗,% : int, int → int > : real,real → bool +,−,∗ : real,real → real\nWe have several standard probability distributions as primitive: D : t → u takes parameters in t and yields a random value in u. The names xi below only document the meaning of the parameters. Signatures of Distributions: D : (x1 : b1 ∗ · · · ∗ xn : bn)→ b Bernoulli : (success : real)→ bool Binomial : (trials : int∗ success : real)→ int Poisson : (rate : real)→ int DiscreteUniform : (max : int)→ int Gaussian : (mean : real ∗ variance : real)→ real Beta : (a : real ∗b : real)→ real Gamma : (shape : real ∗ scale : real)→ real\nThe expressions and values of Fun are below. Expressions are in a limited syntax akin to A-normal form, with let-expressions for sequential composition. Fun: Values and Expressions\nV ::= x | c | (V,V ) value M,N ::= expression\nV value V1 ⊗V2 arithmetic or logical operator V.1 left projection from pair V.2 right projection from pair if V then M1 else M2 conditional let x = M in N let (scope of x is N) random (D(V )) primitive distribution observe V observation\nIn the discrete case, Fun has a standard sampling semantics (cf. [41]); the formal semantics for the general case comes later. A run of a closed expression M is the process of evaluating M to a value. The evaluation of most expressions is standard, apart from sampling and observation.\nTo run random (D(V )), where V = (c1, . . . ,cn), choose a value c at random from the distribution D(c1, . . . ,cn) (independently from earlier random choices) and return c.\nTo run observe V , always return (). We say the observation is valid if and only if the value V is some zero element 0b.\nDue to the presence of sampling, different runs of the same expression may yield more than one value, with differing probabilities. Let a run be valid so long as every encountered observation is valid. The sampling semantics of an expression is the conditional probability of returning a particular value, given a valid run. Intuitively, Boolean observations are akin to assume statements in assertion-based program specifications, where runs of a program are ignored if an assumed formula is false."
    }, {
      "heading" : "Example: Two Coins, Not Both Tails",
      "text" : "let heads1 = random (Bernoulli(0.5)) in let heads2 = random (Bernoulli(0.5)) in let u = observe (heads1 || heads2) in (heads1,heads2)\nThe subexpression random (Bernoulli(0.5)) generates true or false with equal likelihood. The whole expression has four distinct runs, each with probability 1/4, corresponding to the possible combinations of Booleans heads1 and heads2. All these runs are valid, apart from the one where heads1 = false and heads2 = false (representing two tails), since observe(false||false) is not a valid observation. The sampling semantics of this expression is a probability distribution assigning probability 1/3 to the values (true, false), (false, true), and (true, true), but probability 0 to the value (false, false).\nThe sampling semantics allows us to interpret an expression as a Bayesian model. We interpret the distribution of possible return values as the prior probability of the model. The constraints on valid runs induced by observations represent new evidence or training data. The conditional probability of a value given a valid run is the posterior probability: an adjustment of the prior probability given the evidence or training data.\nThus, the expression above can be read as a Bayesian model of the problem: I toss two coins. I observe that not both are tails. What is the probability of each outcome? The uniform distribution of two Booleans represents our prior knowledge about two coins, the observe expression represents the evidence that not both are tails, and the overall sampling semantics is the posterior probability of two coins given this evidence.\nNext, we define syntactic conventions and a type system for Fun, define a formal semantics for the discrete subset of Fun, and describe further examples. Our discrete semantics is a warm up before Section 3. There we deploy measure theory to give a semantics to our full language, which allows both discrete and continuous prior distributions.\n2.2. Syntactic Conventions and Monomorphic Typing Rules. We recite our standard syntactic conventions and typing rules.\nWe identify phrases of syntax φ (such as values and expressions) up to consistent renaming of bound variables (such as x in a let-expression). Let fv(φ) be the set of variables occurring free in phrase φ . Let φ {ψ/x} be the outcome of substituting phrase ψ for each free occurrence of variable x in phrase φ . To keep our core calculus small, we treat function definitions as macros with call-by-value semantics. In particular, in examples, we write first-order non-recursive function definitions in the form let f x1 . . . xn = M, and we allow function applications f M1 . . . Mn as expressions. We consider such a function application as being a shorthand for the expression let x1 = M1 in . . . let xn = Mn in M, where the bound variables x1, . . . , xn do not occur free in M1, . . . ,\nMn. We allow expressions to be used in place of values, via insertion of suitable let-expressions. For example, (M1,M2) stands for let x1 = M1 in let x2 = M2 in (x1,x2), and M1 ⊗M2 stands for let x1 = M1 in let x2 = M2 in x1 ⊗ x2, when either M1 or M2 or both is not a value. Let M1;M2 stand for let x = M1 in M2 where x /∈ fv(M2). The notation t = t1 ∗ · · · ∗ tn for tuple types means the following: when n = 0, t = unit; when n = 1, t = t1; and when n > 1, t = t1 ∗ (t2 ∗ · · · ∗ tn). In listings, we rely on syntactic abbreviations available in F#, such as layout conventions (to suppress in keywords) and writing tuples as M1, . . . ,Mn without enclosing parentheses.\nLet a typing environment, Γ, be a list of the form ε ,x1 : t1, . . . ,xn : tn; we say Γ is well-formed and write Γ ⊢ ⋄ to mean that the variables xi are pairwise distinct. Let dom (Γ) = {x1, . . . ,xn} if Γ = ε ,x1 : t1, . . . ,xn : tn. We sometimes use the notation x : t for Γ = ε ,x1 : t1, . . . ,xn : tn where x = x1, . . . ,xn and t = t1, . . . , tn.\nTyping Rules for Fun Expressions: Γ ⊢ M : t\n(FUN VAR) Γ ⊢ ⋄ (x : t) ∈ Γ\nΓ ⊢ x : t\n(FUN CONST) Γ ⊢ ⋄\nΓ ⊢ c : ty(c)\n(FUN PAIR) Γ ⊢V1 : t1 Γ ⊢V2 : t2 Γ ⊢ (V1,V2) : t1 ∗ t2 (FUN OPERATOR) ⊗ : b1,b2 → b3 Γ ⊢V1 : b1 Γ ⊢V2 : b2\nΓ ⊢V1 ⊗V2 : b3 (FUN PROJ1) Γ ⊢V : t1 ∗ t2 Γ ⊢V.1 : t1 (FUN PROJ2) Γ ⊢V : t1 ∗ t2 Γ ⊢V.2 : t2 (FUN IF) Γ ⊢V : bool Γ ⊢ M1 : t Γ ⊢ M2 : t\nΓ ⊢ if V then M1 else M2 : t (FUN LET)\nΓ ⊢ M1 : t1 Γ,x : t1 ⊢ M2 : t2\nΓ ⊢ let x = M1 in M2 : t2\n(FUN RANDOM) D : (x1 : b1 ∗ · · · ∗ xn : bn)→ b\nΓ ⊢V : (b1 ∗ · · · ∗bn) Γ ⊢ random (D(V )) : b\n(FUN OBSERVE) Γ ⊢V : b\nΓ ⊢ observe V : unit\nLemma 2.1. If Γ,x : t,Γ′ ⊢ M : t ′ and Γ ⊢V : t then Γ,Γ′ ⊢ M{V/x} : t ′. Proof. By induction on the derivation of Γ,x : t,Γ′ ⊢ M : t ′. Lemma 2.2. If Γ ⊢ M : t then Γ ⊢ ⋄. Proof. By induction on the derivation of Γ ⊢ M : T . Lemma 2.3 (Unique Types). If Γ ⊢ M : t and Γ ⊢ M : t ′ then t = t ′. Proof. By induction on the structure of M. The proof needs that the result types of the signatures of overloaded binary operators and of distributions are determined by the argument types.\n2.3. Formal Semantics for Bernoulli Fun. Let Bernoulli Fun be the fragment of our calculus where every random expression takes the form random (Bernoulli(c)) for some real c ∈ (0,1), that is, a weighted Boolean choice returning true with probability c, and false with probability 1−c. We show that a closed well-typed expression M induces conditional probabilities PM [value =V | valid], the probability that the value of a valid run of M is V .\nFor this calculus, we inductively define an operational semantics, M →p M′, meaning that expression M takes a step to M′ with probability p. Reduction Relation: M →p M′ where p ∈ (0,1] V1 ⊗V2 →1 ⊗(c1,c2) (V1,V2).1 →1 V1 (V1,V2).2 →1 V2 if true then M1 else M2 →1 M1 if false then M1 else M2 →1 M2 let x =V in M →1 M{V/x} R[M]→p R[M′] if M →p M′ for reduction context R given by R ::= [] | let x =R in M random (Bernoulli(c))→c true random (Bernoulli(c))→1−c false observe V →1 ()\nSince there is no recursion or unbounded iteration in Bernoulli Fun, there are no non-terminating reduction sequences M1 →p1 . . .Mn →pn . . . .\nMoreover, we can prove standard preservation and progress lemmas.\nLemma 2.4 (Preservation). If Γ ⊢ M : t and M →p M′ then Γ ⊢ M′ : t. Proof. By induction on the derivation of M →p M′. Lemma 2.5 (Progress). If ε ⊢M : t and M is not a value then there are p and M′ such that M →p M′. Proof. By induction on the structure of M.\nLemma 2.6 (Determinism). If M →p M′ and M →p′ M′ then p = p′. Proof. By induction on the structure of M.\nLemma 2.7 (Probability). If ε ⊢ M : t then Σ{(p,N)|M→pN}p = 1. Proof. By induction on the structure of M.\nWe consider a fixed expression M such that ε ⊢ M : t. Let the space Ω be the set of all runs of M, where a run is a sequence ω = (M1, . . . ,Mn+1) for n ≥ 0 and p1, . . . , pn such that M = M1 →p1 · · · →pn Mn+1 =V ; we define the functions value(ω) = V and prob(ω) = 1p1 . . . pn, and we define the predicate valid(ω) to hold if and only if whenever M j = R[observe V ] then V = 0b for some zero element 0b. Since M is well-typed, is normalizing, and samples only from Bernoulli distributions, Ω is finite. Let α ,β ⊆ Ω range over events, and let probability PM [α ] = ∑ω∈α prob(ω). Below, we write P [·] for PM [·] when M is clear from the context. Proposition 2.8. The function P [α ] forms a probability distribution, that is, (1) we have P [α ] ≥ 0 for all α , (2) P [Ω] = 1, and (3) P [α ∪β ] = P [α ]+P [β ] if α ∩β =∅. Proof. Item (1) follows from the fact that p≥ 0 whenever M →p N. Item (2) follows from Lemma 2.7, Lemma 2.4, and termination. Item (3) is immediate from the definition.\nTo give the semantics of our expression M we first define the following probabilities and events. Given a value V , value =V is the event value−1(V ) = {ω | value(ω) =V}. Hence, P [value =V ] is the prior probability that a run of M terminates with V . We let the event valid = {ω ∈ Ω | valid(ω)}; hence, P [valid] is the probability that a run is valid.\nIf P [β ] 6= 0, the conditional probability of α given β is\nP [α | β ], P [α ∩β ] P [β ]\nThe semantics of a program M is given by the conditional probability distribution\nPM [value =V | valid] = PM\n[ (value−1(V ))∩ valid ]\nPM [valid] ,\nthe conditional probability that a run of M returns V given a valid run, also known as the posterior probability.\nThe conditional probability PM [value =V | valid] is only defined when PM [valid] is not zero. For pathological choices of M such as observe false or let x = 3 in observe x there are no valid runs, so P [valid] = 0, and P [value =V | valid] is undefined. (This is an occasional problem in practice; Bayesian inference engines such as Infer.NET fail in this situation with a zero-probability exception.)\n2.4. An Example in Bernoulli Fun. The expression below encodes the question: 1% of a population have a disease. 80% of subjects with the disease test positive, and 9.6% without the disease also test positive. If a subject is positive, what are the odds they have the disease? [54]"
    }, {
      "heading" : "Epidemiology: Odds of Disease Given Positive Test",
      "text" : "let has disease = random (Bernoulli(0.01)) let positive result = if has disease\nthen random (Bernoulli(0.8)) else random (Bernoulli(0.096))\nobserve positive result has disease\nFor this expression, we have Ω= {ωtt ,ωt f ,ω f t ,ω f f } where each run ωc1c2 corresponds to the choice has disease = c1 and positive result = c2. The probability of each run is: • prob(ωtt) = 0.01×0.8 = 0.008 (true positive) • prob(ωt f ) = 0.01×0.2 = 0.002 (false negative) • prob(ω f t) = 0.99×0.096 = 0.09504 (false positive) • prob(ω f f ) = 0.99×0.904 = 0.89496 (true negative) The semantics P [value = true | valid] here is the conditional probability of having the disease, given that the test is positive.\nHere P [valid] = prob(ω f t) + prob(ωtt) and P [value = true∩ valid] = prob(ωtt), so we have P [value = true | valid] = 0.008/(0.008+0.09504) = 0.07764. So the likelihood of disease given a positive test is just 7.8%, less than one might think.\nThis example illustrates inference on an explicit enumeration of the runs in Ω. The size of Ω is exponential in the number of random expressions, so although illustrative, this style of inference does not scale up. As we explain in Section 4, our implementation strategy is to translate Fun\nexpressions to the input language of an existing inference engine based on factor graphs, permitting efficient approximate inference."
    }, {
      "heading" : "3. SEMANTICS AS MEASURE TRANSFORMERS",
      "text" : "We cannot generalize the operational semantics of the previous section to continuous distributions, such as random (Gaussian(1,1)), since the probability of any particular sample is zero. A further difficulty is the need to observe events with probability zero, a common situation in machine learning. For example, consider the naive Bayesian classifier, a common, simple probabilistic model. In the training phase, it is given objects together with their classes and the values of their pertinent features. Below, we show the training for a single feature: the weight of the object. The zero probability events are weight measurements, assumed to be normally distributed around the class mean. The outcome of the training is the posterior weight distributions for the different classes."
    }, {
      "heading" : "Naive Bayesian Classifier, Single Feature Training:",
      "text" : "let wPrior() = random (Gaussian(0.5,1.0)) let Glass,Watch,Plate = wPrior(),wPrior(),wPrior() let weight objClass objWeight = observe (objWeight−(random (Gaussian(objClass,1.0)))) weight Glass .18; weight Glass .21 weight Watch .11; weight Watch .073 weight Plate .23; weight Plate .45 Watch,Glass,Plate\nAbove, the call to weight Glass .18 modifies the distribution of the variable Glass. The example uses observe (x−y) to denote that the difference between the weights x and y is 0. The reason for not instead writing x=y is that conditioning on events of zero probability without specifying the random variable they are drawn from is not in general well-defined, cf. Borel’s paradox [21]. To avoid this issue, we instead observe the random variable x−y of type real, at the value 0. (Our compiler does permit the expression observe (x=y), as sugar for observe (x−y)).\nTo give a formal semantics to such observations, as well as to mixtures of continuous and discrete distributions, we turn to measure theory, following standard sources [6, 48]. Two basic concepts are measurable spaces and measures. A measurable space is a set of values equipped with a collection of measurable subsets; these measurable sets generalize the events of discrete probability. A measure is a function that assigns a positive size to each measurable set; finite measures, which assign a finite size to each measurable set, generalize probability distributions.\nWe work in the usual mathematical metalanguage of sets and total functions. To machine-check our theory, one might build on a recent formalization of measure theory and Lebesgue integration in higher-order logic [35].\n3.1. Types as Measurable Spaces. In the remainder of the paper, we let Ω range over sets of possible outcomes; in our semantics Ω will range over B= {true, false}, Z, R, and finite Cartesian products of these sets. A σ -algebra over Ω is a set M ⊆ P(Ω) which (1) contains ∅ and Ω, and (2) is closed under complement and countable union and intersection. A measurable space is a pair (Ω,M) where M is a σ -algebra over Ω; the elements of M are called measurable sets. We use the notation σΩ(S), when S ⊆ P(Ω), for the smallest σ -algebra over Ω that is a superset of S; we may omit Ω when it is clear from context. Given two measurable spaces (Ω1,M1) and (Ω2,M2), we\ncan compute their product as (Ω1,M1)× (Ω2,M2), (Ω1 ×Ω2,σΩ1×Ω2{A×B | A ∈M1,B ∈M2}) If (Ω,M) and (Ω′,M′) are measurable spaces, then the function f : Ω → Ω′ is measurable if and only if for all A ∈ M′, f−1(A) ∈ M, where the inverse image f−1 : P(Ω′) → P(Ω) is given by f−1(A), {ω ∈ Ω | f (ω) ∈ A}. We write f−1(x) for f−1({x}) when x ∈ Ω′.\nWe give each first-order type t an interpretation as a measurable space T[[t]] , (Vt ,Mt) below. We identify closed values of type t with elements of Vt , and write () for ∅, the unit value."
    }, {
      "heading" : "Semantics of Types as Measurable Spaces:",
      "text" : "T[[unit]] = ({()},{{()},∅}) T[[bool]] = (B,P(B)) T[[int]] = (Z,P(Z)) T[[real]] = (R,σR({[a,b] | a,b ∈ R})) T[[t ∗u]] = T[[t]]×T[[u]]\nThe set σR({[a,b] | a,b ∈ R}) in the definition of T[[real]] is the Borel σ -algebra on the real line, which is the smallest σ -algebra containing all closed (and open) intervals. Below, we write f : t → u to denote that f : Vt → Vu is measurable, that is, that f−1(B) ∈Mt for all B ∈Mu.\n3.2. Finite Measures. A measure µ on a measurable space (Ω,M) is a function M→ R+∪{∞} that is countably additive, that is, µ(∅) = 0 and if the sets A0,A1, . . . ∈M are pairwise disjoint, then µ(∪iAi) = ∑i µ(Ai). We write |µ |, µ(Ω). A finite measure µ is a measure µ satisfying |µ | 6= ∞; a σ -finite measure µ is a measure such that Ω = A0 ∪A1 ∪ . . . with µ(Ai) 6= ∞. All the measures we consider in this paper are σ -finite.\nLet M t be the set of finite measures on the measurable space T[[t]]. Additionally, a finite measure µ on (Ω,M) is a probability measure when |µ | = 1. We do not restrict M t to just probability measures, although one can obtain a probability measure from a non-zero finite measure by normalizing with 1/|µ |. We make use of the following constructions on measures. • Given a function f : t → u and a measure µ ∈ M t, there is a measure µ f−1 ∈ M u given by (µ f−1)(B), µ( f−1(B)). • Given a finite measure µ and a measurable set B, we let µ |B(A) , µ(A∩B) be the restriction of µ to B. • We can add two measures on the same set as (µ1 +µ2)(A), µ1(A)+µ2(A). • We can multiply a measure by a positive constant as (r ·µ)(A), r ·µ(A). • The (independent) product (µ1 ×µ2) of two (σ -finite) measures is also definable [6, Sec. 18], and\nsatisfies (µ1 ×µ2)(A×B) = µ1(A) ·µ2(B). • If µi is a measure on ti for i ∈ {1,2}, we let the disjoint sum µ1 ⊕ µ2 be the measure on t1 + t2\ndefined as A1 ⊎A2 7→ µ1(A1)+µ2(A2). • Given a measure µ on the measurable space T[[t]], a measurable set A ∈Mt and a function f : t →\nreal, we write ∫ A f dµ or equivalently ∫ A f (x)dµ(x) for standard (Lebesgue) integration. This integration is always well-defined if µ is finite and f is non-negative and bounded from above. • Given t, we let λt be the “standard” measure on T[[t]] built from independent products and disjoint sums of the Lebesgue measure on real and the counting measure on discrete b. We often omit t when it is clear from the context. (We also use λ -notation for functions, but we trust any ambiguity is easily resolved.) • Given a measure µ on a measurable space T[[t]] we call a function µ̇ : t → real a density for µ iff µ(A) = ∫\nA µ̇ dλ for all A ∈M.\nStandard Distributions. Given a closed well-typed Fun expression random (D(V )) of base type b, we define a corresponding finite measure µD(V ) on measurable space T[[b]], via its density D(V ) = µ̇D(V ). In the discrete case, we first define the probability mass function, written D(V ) c, and then define the measure µD(V ) as a summation. Masses D(V ) c and Measures µD(V ) for Discrete Probability Distributions:\nBernoulli(p) true , p if 0 ≤ p ≤ 1, 0 otherwise Bernoulli(p) false , 1− p if 0 ≤ p ≤ 1, 0 otherwise Binomial(n, p) i ,\n( i n ) pi/n! if 0 ≤ p ≤ 1, 0 otherwise DiscreteUniform(m) i , 1/m if 0 ≤ i < m, 0 otherwise Poisson(l) n , e−lln/n! if l,n ≥ 0, 0 otherwise µD(V )(A), ∑i D(V ) ci if A = ⋃ i{ci} for pairwise disjoint ci\nIn the continuous case, we first define the probability density function D(V ) r and then define the measure µD(V ) as an integral. Below, we write G for the standard Gamma function, which on naturals n satisfies G(n) = (n−1)!. Densities D(V ) r and Measures µD(V ) for Continuous Probability Distributions:\nGaussian(m,v) r , e−(r−m) 2/2v/ √ 2πv if v > 0, 0 otherwise Gamma(s, p) r , rs−1e−pr ps/G(s) if r,s, p > 0, 0 otherwise Beta(a,b) r , ra−1(1− r)b−1G(a+b)/(G(a)G(b)) if a,b > 0 and 0 ≤ r ≤ 1, 0 otherwise µD(V )(A), ∫ A D(V )dλ where λ is the Lebesgue measure on R\nThe Dirac δ measure is defined on the measurable space T[[b]] for each base type b, and is given by δc(A), 1 if c ∈ A, 0 otherwise.\nConditional density. The notion of density can be generalized as follows, yielding an unnormalized counterpart to conditional probability. Given a measurable function p : t → u, we consider two families of events on t. Firstly, events Ec , {x ∈ Vt | p(x) = c} where c ranges over Vu. Secondly, rectangles Rd , {x ∈ Vt | x ≤ d} where d ranges over Vt and ≤ is the coordinate-wise partial order (that on pair types satisfies (a,b) ≤ (c,d) iff a ≤ c and b ≤ d, that on int and real is the standard ordering, and that only relates equal booleans).\nGiven a finite measure µ on T[[t]] and c ∈ Vu, we let Fc : t → R be defined by the limit below (following [13])\nFc(d), lim i→∞ µ(Rd ∩ p−1(Bi))/λu(Bi) (3.1) if the limit exists and is the same for all sequences {Bi} of closed sets converging regularly to c. On points d where no unique limit exists, we let\nFc(d), inf{Fc(d′) | d ≤ d′∧d 6= d′∧Fc(d′) defined} where we let inf ∅ , ∞. If Fc is bounded, we define Dµ [·||p = c] ∈ R (the µ-density at Ec) as the finite measure on T[[t]] with (unnormalized) cumulative distribution function Fc, that is, Dµ [Rd ||p = c] = Fc(d). (If Fc is not bounded, it is not the distribution function of a finite measure.)\nAs examples of this definition, when u is discrete we have that Dµ [A||p = c] = µ(A ∩ {x | p(x) = c}), so discrete density amounts to filtering. In the continuous case, if Vt = R×Rk, p =\nλ (x,y).(x− c) and µ has a continuous density µ̇ then\nFc(a,b) = lim i→∞ µ(R(a,b)∩ p−1(Bi)) λR(Bi)\n= lim i→∞\n∫\n(R(a,b)∩p−1(Bi))µ̇(x,y)dλt(x,y)\nλR(Bi)\n= ∫\n{y|(c,y)∈R(a,b)} µ̇(c,y)dλ Rk (y) when a 6= c by continuity.\nWhen a = c the limit may not be unique, in which case we have\nFc(c,b) = inf{Fc(d′) | (c,b) ≤ d′}\n= ∫\n{y|(a,y)∈R(a,b)} µ̇(a,y)dλRk (y) by monotonicity of Fc and continuity.\nWe then get\nDµ [A||p = c] = ∫\n{y|(c,y)∈A} µ̇(c,y)dλRk (y). (3.2)\nOne case when conditional density may not be defined is when the conditioning event is at a discontinuity of the density function: let t = real ∗ real, p(x,y) = x, and µ̇(x,y) = 1 if 0 ≤ x,y ≤ 1, otherwise 0. Then F1(x,y) = 0 if x < 1 or y ≤ 0, and otherwise the limit (3.1) is not unique. Thus F1(1,0) = ∞, so F1 is not bounded and Dµ [·||p = 1] is undefined. For more examples, see Section 3.5.\nThere exists a more declarative approach to Dµ . For A ∈Mt , we let νA(B) = µ(A∩ p−1(B)); this measure is said to be absolutely continuous (wrt. λu) if νA(B) = 0 whenever λu(B) = 0. If µ is outer regular, i.e. µ(A) = inf{µ(G) | A ⊂ G,G open} for all A, and νA is absolutely continuous, the defining limit (3.1) exists almost everywhere [13], that is, there is a set C with µ(C) = 0 such that c ∈ C if Fc(d) is undefined. Then, Dµ [A||p = c] is a version of the Radon-Nikodym derivative of νA(B) (wrt. λu). For all B ∈Mu, conditional density thus satisfies the equation\nµ(A∩ p−1(B)) = ∫\nB Dµ [A||p = x] dλu(x). (3.3)\nThe existence of a family of finite measures Dµ [ · ||p = c] on T[[t]] satisfying equation (3.3) above is guaranteed in certain situations, e.g., when µ p−1 has density d at c we may take Dµ as a version of the regular conditional probability µ [· | p = c] (see for instance [6, Theorem 33.3]) scaled by d. However, if µ(p−1(c)) = 0 the value of Dµ [A||p = c] may not be uniquely defined, since two versions of Dµ [ · ||p = · ] may differ on a null set. In order to avoid this ambiguity we have given an explicit construction that works for many useful cases.\n3.3. Measure Transformers. We will now recast some standard theorems of measure theory as a library of combinators, that we will later use to give semantics to probabilistic languages. A measure transformer is a partial function from finite measures to finite measures. We let t ❀ u be the set of partial functions M t → M u. We use the combinators on measure transformers listed below in the formal semantics of our languages. The definitions of these combinators occupy the remainder of this section. We recall that µ denotes a measure and A a measurable set, of appropriate types."
    }, {
      "heading" : "Measure Transformer Combinators:",
      "text" : "pure ∈ (t → u)→ (t ❀ u) >>> ∈ (t1 ❀ t2)→ (t2 ❀ t3)→ (t1 ❀ t3) choose ∈ (t → bool)→ (t ❀ u)→ (t ❀ u)→ (t ❀ u) extend ∈ (t → M u)→ (t ❀ (t ∗u)) observe ∈ (t → b)→ (t ❀ t)\nLifting a Function to a Measure Transformer. To lift a pure measurable function to a measure transformer, we use the combinator pure ∈ (t → u) → (t ❀ u). Given f : t → u, we let pure f µ A , µ f−1(A), where µ is a measure on T[[t]] and A is a measurable set from T[[u]] (cf. [6, Eqn 13.7]).\nSequential Composition of Measure Transformers. To sequentially compose two measure transformers we use standard function composition, defining >>>∈ (t1 ❀ t2)→ (t2 ❀ t3)→ (t1 ❀ t3) as T >>>U ,U ◦T .\nConditional Choice between two Measure Transformers. The combinator choose ∈ (t → bool)→ (t ❀ u) → (t ❀ u) → (t ❀ u) makes a choice between two measure transformers, parametric on a predicate p. Intuitively, choose p TT TF µ first splits Vt into two sets depending on whether or not p is true. For each equivalence class, we then run the corresponding measure transformer on µ restricted to the class. Finally, the resulting finite measures are added together, yielding a finite measure. If p−1(true) = B we let choose p TT TF µ A = TT(µ |B)(A)+TF(µ |Vt\\B)(A).\nExtending Domain of a Measure. The combinator extend ∈ (t → M u)→ (t ❀ (t ∗u)) extends the domain of a measure using a function yielding measures. It is reminiscent of creating a dependent pair, since the distribution of the second component depends on the value of the first. For extend m to be defined, we require that for every A ∈Mu, the function fA , λx.m(x)(A) is measurable, nonnegative and bounded from above. In particular, this holds for all A if m is measurable and m(x) always is a (sub-)probability distribution, which is always the case in our semantics for Fun. We let extend m µ AB , ∫\nVt m(x)({y | (x,y) ∈ AB})dµ(x), where we integrate over the first component (call it x) with respect to the measure µ , and the integrand is the measure under m(x) of the set {y | (x,y) ∈ AB} for each x (cf. [6, Ex. 18.20]).\nObservation as a Measure Transformer. The combinator observe ∈ (t → b)→ (t ❀ t) conditions a measure over T[[t]] on the event that an indicator function of type t → b is zero. Here observation is unnormalized conditioning of a measure on an event. If defined, we let observe p µ A , Dµ [A||p = 0b]. As an example, if p : t → bool is a (measurable) predicate on values of type t, we have observe p µ A = µ(A∩{x | p(x) = true}). Notice that observe p µ A can be greater than µ(A) when p : t → real (cf. the naive Bayesian classifier on page 9), for which reason we cannot restrict ourselves to (sub-)probability measures. For examples, see Equation (3.2) and Section 3.5.\n3.4. Measure Transformer Semantics of Fun. In order to give a compositional denotational semantics of Fun programs, we give a semantics to open programs, later to be placed in some closing context. Since observations change the distributions of program variables, we may draw a parallel to while programs. There, a program can be given a denotation as a function from variable valuations to a return value and a variable valuation. Similarly, we give semantics to an open Fun term by mapping a measure over assignments to the term’s free variables to a joint measure of the term’s return value and assignments to its free variables. This choice is a generalization of the (discrete) semantics of pWHILE [4]. This contrasts with Ramsey and Pfeffer [46], where the semantics of an open program takes a variable valuation and returns a (monadic computation yielding a) distribution of return values.\nFirst, we define a data structure for an evaluation environment assigning values to variable names, and corresponding operations. Given an environment Γ = x1:t1, . . . ,xn:tn, we let S〈Γ〉 be the set of states, or finite maps s = {x1 7→ c1, . . . ,xn 7→ cn} such that for all i = 1, . . . ,n, ty(ci) = ti. We let T[[S〈Γ〉]] , T[[unit∗ t1 ∗ · · · ∗ tn]] be the measurable space of states in S〈Γ〉. We define dom(s) , {x1, . . . ,xn}. We define the following operators."
    }, {
      "heading" : "Auxiliary Operations on States and Pairs:",
      "text" : "add x (s,c), s∪{x 7→ c} if ty(c) = t and x /∈ dom(s), s otherwise. lookup x s , s(x) if x ∈ dom(s), () otherwise. drop X s , {(x 7→ c) ∈ s | x /∈ X} fst((x,y)) , x snd((x,y)) , y\nWe write s|X for drop (dom(s) \\X) s. We apply these combinators to give a semantics to Fun programs as measure transformers. We assume that all bound variables in a program are different from the free variables and each other. Below, V[[V ]] s gives the valuation of V in state s, and A[[M]] gives the measure transformer denoted by M."
    }, {
      "heading" : "Measure Transformer Semantics of Fun:",
      "text" : "V[[x]] s , lookup x s V[[c]] s , c V[[(V1,V2)]] s , (V[[V1]] s,V[[V2]] s)\nA[[V ]], pure λ s.(s,V[[V ]] s) A[[V1 ⊗V2]], pure λ s.(s,⊗(V[[V1]] s,V[[V2]] s)) A[[V.1]] , pure λ s.(s,fst(V[[V ]] s)) A[[V.2]] , pure λ s.(s,snd(V[[V ]] s))\nA[[if V then M else N]], choose (λ s.V[[V ]] s) A[[M]] A[[N]] A[[random (D(V ))]], extend λ s.µD(V[[V ]] s) A[[observe V ]], (observe λ s.V[[V ]] s)>>> pure λ s.(s,()) A[[let x = M in N]],A[[M]]>>> pure (add x) >>>A[[N]]>>> pure λ (s,y).((drop {x} s),y)\nA value expression V returns the valuation of V in the current state, which is left unchanged. Similarly, binary operations and projections have a deterministic meaning given the current state. An if V expression runs the measure transformer given by the then branch on the states where V evaluates true, and the transformer given by the else branch on all other states, using the combinator choose. A primitive distribution random (D(V )) extends the state measure with a value drawn from the distribution D, with parameters V depending on the current state. An observation observe V modifies the current measure by restricting it to states where V is zero. It is implemented with the observe\ncombinator, and it always returns the unit value. The expression let x = M in N intuitively first runs M and binds its return value to x using add. After running N, the binding is discarded using drop.\nLemma 3.1. If s : S〈Γ〉 and Γ ⊢V : t then V[[V ]] s ∈ Vt . Lemma 3.2. If Γ ⊢ M : t then A[[M]] ∈ S〈Γ〉❀ (S〈Γ〉 ∗ t).\nThe measure transformer semantics of Fun is hard to use directly, except in the case of Bernoulli Fun where they can be directly implemented: a naive implementation of M〈S〈Γ〉〉 is as a map assigning a probability to each possible variable valuation. If there are N variables, each sampled from a Bernoulli distribution, in the worst case there are 2N paths to be explored in the computation, each of which corresponds to a variable valuation. Our direct implementation of the measure transformer semantics, described in the technical report version of our paper [8], explicitly constructs the valuation. It works fine for small examples but would blow up on large datasets. In this simple case, the measure transformer semantics of closed programs also coincides with the sampling semantics.\nTheorem 3.3. Suppose ε ⊢ M : t for some M in Bernoulli Fun. If µ =A[[M]] δ() and ε ⊢V : t then PM [value =V | valid] = µ({((),V )})/|µ |. Proof. We add a construct to give a semantics to open Bernoulli Fun expressions. Let init(M,µ) stand for M starting in an initial probability measure µ on S〈Γ〉. Let init(M,µ)→ps M{V1/x1 · · ·Vn/xn} when s= {xi 7→Vi | i= 1..n} ∈ S〈Γ〉 and ps = µ({s′ | s′|fv(M) = s|fv(M)}). In particular, if M is closed, then init(M,δ())→1 M, so init(M,δ()) has the same traces as M but for an additional (valid) initial step.\nBy induction on the derivation of Γ ⊢ M : t, we prove that if Γ ⊢ M : t and ε ⊢ V : t and µ ∈ M〈S〈Γ〉〉, then ν(S〈Γ〉× {V}) = PN [valid∩ value =V ] and ν(S〈Γ〉 ×Vt) = PN [valid], where ν = A[[M]] µ and N = init(M,µ).\nThen, for closed M we get PM [value =V | valid] = PM [valid∩ value =V ]/PM [valid] = ν({((),V )})/ν({()}×Vt).\n3.5. Discussion of the Semantics. In this section we discuss some small examples that are illustrative of the semantics of the observe primitive. The first example highlights the difference between discrete observations and observations on continuous types.\nThe subsequent examples contrast our definition of observe with some alternative definitions. The second example deals with the definition of discrete observations, that is shown to coincide with the filtering semantics of Bernoulli Fun, unlike two alternative semantics. In the third example, we treat continuous observations, showing that distributing an observation into both branches of an if statement yields the same result, in contrast to an alternative semantics of observations as computing (normalized) conditional probability distributions.\nIn the fourth example, we show an example of model comparison that depends on the unnormalized nature of observations. In the fifth example, we show a well-typed Fun program with an observation (of a derived random variable) that failed to be well-defined in the original semantics of observation.\nDiscrete versus continuous observations. As an example to highlight the difference between continuous and discrete observations, we first consider the following program, which observes that a normally distributed random variable is zero. The resulting distribution of the return value x is a point mass at 0.0, as expected. The measure of {0.0} in this distribution is Gaussian(0.0,1.0) 0.0 ≈ 0.4."
    }, {
      "heading" : "Continuous Observation:",
      "text" : "let x = random (Gaussian(0.0, 1.0)) in let = observe x in x\nThe second program instead observes that a Boolean variable is true. This has zero probability of occurring, and since the Boolean type is discrete, the resulting measure is the zero measure. Discrete Observation:\nlet x = random (Gaussian(0.0, 1.0)) in let b = (x==0.0) in let = observe b in x\nThese examples show the need for observations at real type, as well as at type bool. (This also clearly distinguishes observe from assume in assertional programming.)\nDiscrete Observations amount to filtering. A consequence of Theorem 3.3 is that our measure transformer semantics is a generalization of the sampling semantics for discrete probabilities. For this theorem to hold, it is critical that observe denotes unnormalized conditioning (filtering). Otherwise programs that perform observations inside the branches of conditional expressions would have undesired semantics. As the following example shows, the two program fragments observe (x=y ) and if x then observe (y=true) else observe (y=false) would have different measure transformer semantics although they have the same sampling semantics.\nSimple Conditional Expression: Mif let x = random (Bernoulli(0.5)) let y = random (Bernoulli(0.1)) if x then observe (y=true) else observe (y=false) y\nIn the sampling semantics, the two valid runs are when x and y are both true (with probability 0.05), and both false (with probability 0.45), so we have P [true | valid] = 0.1 and P [false | valid] = 0.9.\nIf, instead of the unnormalized definition observe p µ A = µ(A∩{x | p(x)}), we had either of the normalizing definitions\nobserve p µ A = µ(A∩{x | p(x)}) µ({x | p(x)}) or |µ | µ(A∩{x | p(x)})\nµ({x | p(x)}) then A[[Mif]] δ() {true}=A[[Mif]] δ() {false}, which would invalidate the theorem.\nLet M′ = Mif with observe (x = y) substituted for the conditional expression. With the actual or either of the flawed definitions of observe we have A[[M′]] δ() {true}= (A[[M′]] δ() {false})/9.\nContinuous Observations are not normalizing. As in the discrete case, continuous observations do not renormalize the resulting measure. In the program below, the variables x and y are independent: observing x at a given value amounts to scaling the measure of y by some fixed amount. Simple Continuous Observation: Mobs let x = random (Gaussian(0.0, 1.0)) let y = random (Gaussian(0.0, 1.0)) observe (x−1.0) y\nThe resulting distribution µy of y is the normal distribution, scaled by a factor Gaussian(0.0,1.0) 1.0≈ 0.24. In particular, µy({y ∈R : y >−1})/|µy| ≈ 0.16. Below, we let ν be the joint distribution of x and y before the observation.\nIf we replace the observation by an if statement that performs the same observation in each branch, the resulting distribution is unchanged. Let M′ = Mobs with the conditional expression N :=if x+y>0 then observe (x−1.0) else observe (x−1.0) substituted for observe (x−1.0). Let A= {(x,y) ∈R2 : x+y> 0} and B=R2\\A. We have A[[N]]ν = choose p T T ν = T (ν |A)+T (ν |B) where p= λx,y.(x+y> 0) and T = observe λx, .(x−1). Since the definition of observe λx, .(x− 1)µ =Dµ [·||x = 1] is linear in µ (where defined) and ν = ν |A +ν |B, we have A[[Mobs]] =A[[M′]].\nHowever, if observations always yielded probability distributions, and if statements reweighted the result of each branch by the probability that that branch was taken, the above equality would not hold. In M′, the branch condition x+y>0 is true with probability 0.5 a priori. This reweighting semantics would after the observation of x=1 give the same probability to 1+y>0 (the left branch being taken) and 1+y<0 (the right branch being taken). In contrast, the original program Mobs yields P [1+y<0]≈ 0.16.\nMedical trial. As another example, let us consider a simple Bayesian evaluation of a medical trial [37]. We assume a trial group of nTrial persons, of which cTrial were healthy at the end of the trial, and a control group of nControl persons, of which cControl were healthy at the end of the trial. Below, Beta(1.0,1.0) is the uniform distribution on the interval [0.0,1.0]. We return the posterior distributions of the likelihood that a member of the trial group (pTrial) and a member of the control group (pControl) is healthy at the end of the trial."
    }, {
      "heading" : "Medical Trial:",
      "text" : "let medicalTrial nTrial nControl cTrial cControl = let pTrial = random(Beta(1.0,1.0)) observe (cTrial == random (Binomial(nTrial,pTrial))); let pControl = random(Beta(1.0,1.0)) observe (cControl == random (Binomial(nControl,pControl))); pTrial, pControl\nWe can then compare this model to one where the treatment is ineffective, that is, where the members of the trial group and the control group have the same probability of becoming healthy. Also here we give a uniform prior to the probability that the treatment is effective; the posterior distribution of this variable will depend on the Bayesian evidence for the different models, that is, the ratio between the probabilities of the observed outcome in the two models. This way of performing model comparison critically depends on the unnormalized nature of discrete observations as filtering."
    }, {
      "heading" : "Model Selection:",
      "text" : "let modelSelection nTrial nControl cTrial cControl = let pEffective = random(Beta(1.0,1.0)) if random(Bernoulli(pEffective)) then\nmedicalTrial nTrial nControl cTrial cControl ()\nelse let pAll = random(Beta(1.0,1.0)) observe (cTrial == random (Binomial(nTrial,pAll))) observe (cControl == random (Binomial(nControl,pAll)))\npEffective\nObservation of Derived Variable. The following example, due to Chung-Chieh Shan, highlighted regularity problems with our original definition of observation [8]. Observation of Derived Variable:\nlet x = random (Beta(1.0, 1.0)) in let y = x − 0.5 in observe y; x.\nIntuitively, this program should yield a point mass at x=0.5, y=0. In our semantics, if µ is the measure before the observation (when starting from δ()) we have\nF0(x,y) = 1 if x > 0.5 and y > 0\nF0(x,y) = 0 if x < 0.5 or y < 0\nOtherwise, we have F0(x,y) = inf{F0(x′,y′) | x′ ≥ x∧y′ ≥ y}= 1 so Dµ [A||y = 0] = 1 iff (0.5,0) ∈A and otherwise 0; in particular we have Dµ [x = 0.5||y = 0] = 1.\nThe original definition of observation simply applied the limit of Equation (3.1) to any A (not only to rectangles Rd). Then the density of any null set would be 0, and in particular we would have Dµ [x = 0.5||y = 0] = 0. This would contradict countable additivity, since |Dµ [·||y = 0]| = 1 but Dµ [x1 < |x−0.5| ≤ x2||y = 0] = 0 when 0 < x1 < x2."
    }, {
      "heading" : "4. SEMANTICS BY COMPILATION TO CSOFT",
      "text" : "A naive implementation of the measure transformer semantics of the previous section would work directly with measures of states, whose size even in the discrete case could be exponential in the number of variables in scope. For large models, this becomes intractable. In this section, we instead give a semantics to Fun programs by translation to the simple imperative language Imp. We consider Imp to be a sublanguage of Csoft; the Csoft program is then evaluated by Infer.NET by constructing a suitable factor graph [28], whose size will be linear in the size of the program. The implementation advantage of translating F# to Csoft, over simply generating factor graphs directly [32], is that the translation preserves the structure of the input model (including array processing in our full language), which can be exploited by the various inference algorithms supported by Infer.NET.\n4.1. Imp: An Imperative Core Calculus. Imp is an imperative language, based on the static single assignment (SSA) intermediate form. It is a sublanguage of Csoft, the input language of Infer.NET [37]. A composite statement C is a sequence of statements, each of which either stores the result of a primitive operation in a location, observes the contents of a location to be zero, or branches on the value of a location. Imp shares the base types b with Fun, but has no tuples."
    }, {
      "heading" : "Syntax of Imp:",
      "text" : "l, l′, . . . location (variable) in global store E,F ::= c | l | (l ⊗ l) expression I ::= statement\nl ← E assignment l s←− D(l1, . . . , ln) random assignment observeb l observation if l then C1 else C2 conditional local l : b in C local declaration (scope of l is C)\nC ::= nil | I | (C;C) composite statement\nWhen making an observation observeb, we make explicit the type b of the observed location. In a local declaration, local l : b in C, the location l is bound, with scope C. Next, we derive an extended form of local, which introduces a sequence of local variables."
    }, {
      "heading" : "Extended Form of local:",
      "text" : "local Σ in C , local l1 : b1 in . . . local ln : bn in C where Σ = ε , l1 : b1, . . . , ln : bn\nThe typing rules for Imp are standard. We consider Imp typing environments Σ to be a special case of Fun environments Γ, where variables (locations) always map to base types. If Σ = ε , l1 : b1, . . . , ln : bn, we say Σ is well-formed and write Σ ⊢ ⋄ to mean that the locations li are pairwise distinct. The judgment Σ ⊢ E : b means that the expression E has type b in the environment Σ. The judgment Σ ⊢C : Σ′ means that the composite statement C is well-typed in the initial environment Σ, yielding additional bindings Σ′."
    }, {
      "heading" : "Judgments of the Imp Type System:",
      "text" : "Σ ⊢ ⋄ environment Σ is well-formed Σ ⊢ E : b in Σ, expression E has type b Σ ⊢C : Σ′ given Σ, statement C assigns to Σ′"
    }, {
      "heading" : "Typing Rules for Imp Expressions and Commands:",
      "text" : "(IMP CONST) Σ ⊢ ⋄\nΣ ⊢ c : ty(c)\n(IMP LOC) Σ ⊢ ⋄ (l:b) ∈ Σ\nΣ ⊢ l : b\n(IMP OP) Σ ⊢ l1 : b1 Σ ⊢ l2 : b2 ⊗ : b1,b2 → b3\nΣ ⊢ l1 ⊗ l2 : b3\n(IMP ASSIGN) Σ ⊢ E : b l /∈ dom(Σ)\nΣ ⊢ l ← E : (ε , l:b)\n(IMP RANDOM) D : (x1 : b1, . . . ,xn : bn)→ b l /∈ dom(Σ)\nΣ ⊢ l1 : b1 · · · Σ ⊢ ln : bn Σ ⊢ l s←− D(l1, . . . , ln) : (ε , l:b)\n(IMP OBSERVE) Σ ⊢ l : b\nΣ ⊢ observeb l : ε\n(IMP SEQ) Σ ⊢C1 : Σ′ Σ,Σ′ ⊢C2 : Σ′′\nΣ ⊢C1;C2 : Σ′,Σ′′\n(IMP NIL) Σ ⊢ ⋄\nΣ ⊢ nil : ε (IMP IF) Σ ⊢ l : bool Σ ⊢C1 : Σ′ Σ ⊢C2 : Σ′\nΣ ⊢ if l then C1 else C2 : Σ′\n(IMP LOCAL) Σ ⊢C : Σ′ (l : b) ∈ Σ′ Σ ⊢ local l : b in C : (Σ′ \\{l : b})\nTo treat sequences of local variables, we use the shuffle product Σ1 +Σ2 of two environments, defined below."
    }, {
      "heading" : "Typing Rule for Extended Form of local:",
      "text" : "(SH EMP)\nε ∈ ε + ε\n(SH LEFT) Σ ∈ Σ1 +Σ2 Σ,x : b ⊢ ⋄ (Σ,x : b) ∈ (Σ1,x : b)+Σ2\n(SH RIGHT) Σ ∈ Σ1 +Σ2 Σ,x : b ⊢ ⋄ (Σ,x : b) ∈ Σ1 +(Σ2,x : b)\n(IMP LOCALS) Σ ⊢C : Σ′1 Σ′1 ∈ Σ1 +Σ′ Σ ⊢ local Σ1 in C : Σ′\nLemma 4.1. (1) If Σ,Σ′ ⊢ ⋄ then dom(Σ)∩dom(Σ′) =∅. (2) If Σ ⊢ E : b then Σ ⊢ ⋄ and fv(E)⊆ dom(Σ). (3) If Σ ⊢C : Σ′ then Σ,Σ′ ⊢ ⋄.\n4.2. Measure Transformer Semantics of Imp. A compound statement C in Imp has a semantics as a measure transformer I[[C]] generated from the set of combinators defined in Section 3. An Imp program does not return a value, but is solely a measure transformer on states S〈Σ〉❀ S〈Σ,Σ′〉 (where Σ is a special case of Γ). Interpretation of Statements: I[[C]],I[[I]] : S〈Σ〉❀ S〈Σ,Σ′〉 I[[nil]], pure id I[[C1;C2]], I[[C1]]>>> I[[C2]]\nI[[l ← c]], pure λ s.add l (s,c) I[[l ← l′]], pure λ s.add l (s,lookup l′ s) I[[l ← l1 ⊗ l2]], pure λ s.add l (s,⊗(lookup l1 s,lookup l2 s))) I[[l s←− D(l1, . . . , ln)]], extend (λ s.µD(lookup l1 s,...,lookup ln s))>>> pure (add l) I[[observeb l]], observe λ s.lookup l s I[[if l then C1 else C2]], choose (λ s.lookup l s) I[[C1]] I[[C2]] I[[local l : b in C]], I[[C]]>>> pure (drop {l})\nLemma 4.2. If Σ ⊢C : Σ′ then A[[M]] ∈ S〈Σ〉❀ S〈Σ,Σ′〉."
    }, {
      "heading" : "Semantics of Extended Form of local:",
      "text" : "I[[local Σ in C]], I[[C]]>>> pure (drop (dom(Σ)))\n4.3. Translating from Fun to Imp. The translation from Fun to Imp is a mostly routine compilation of functional code to imperative code. The main point of interest is that Imp locations only hold values of base type, while Fun variables may hold tuples. We rely on patterns p and layouts ρ to track the Imp locations corresponding to Fun environments."
    }, {
      "heading" : "Notations for the Translation from Fun to Imp:",
      "text" : "p ::= l | () | (p, p) pattern: group of Imp locations to represent Fun value ρ ::= (xi 7→ pi)i∈1..n layout: finite map from Fun variables to patterns Σ ⊢ p : t in environment Σ, pattern p represents Fun value of type t Σ ⊢ ρ : Γ in environment Σ, layout ρ represents environment Γ\nρ ⊢ M ⇒C, p given ρ , expression M translates to C and pattern p"
    }, {
      "heading" : "Typing Rules for Patterns Σ ⊢ p : t and Layouts Σ ⊢ ρ : Γ:",
      "text" : "(PAT LOC) Σ ⊢ ⋄ (l : t) ∈ Σ Σ ⊢ l : t (PAT UNIT) Σ ⊢ ⋄ Σ ⊢ () : unit (PAT PAIR) Σ ⊢ p1 : t1 Σ ⊢ p2 : t2 Σ ⊢ (p1, p2) : t1 ∗ t2 (LAYOUT) locs(ρ) = dom(Σ) Σ ⊢ ⋄ dom(ρ) = dom(Γ) Σ ⊢ ρ(x) : t ∀(x : t) ∈ Γ\nΣ ⊢ ρ : Γ\nThe rule (PAT LOC) represents values of base type by a single location. The rules (PAT UNIT) and (PAT PAIR) represent products by a pattern for their corresponding components. The rule (LAYOUT) asks that each entry in Γ is assigned a pattern of suitable type by layout ρ .\nThe translation rules below depend on some additional notations. We say p∈Σ if every location in p is in Σ. Let locs(ρ) =\n⋃{fv(ρ(x)) | x ∈ dom(ρ)}, and let locs(C) be the environment listing the set of locations assigned by a command C. Rules for Translation: p ∼ p′ and p ← p′ and p ⊢ M ⇒C, p () ∼ () l ∼ l′ p1 ∼ p′1 ∧ p2 ∼ p′2 ⇒ (p1, p2)∼ (p′1, p′2) () ← () , nil (p1, p2)← (p′1, p′2), p1 ← p′1; p2 ← p′2 (TRANS VAR)\nρ ⊢ x ⇒ nil,ρ(x) (TRANS CONST) c 6= () l /∈ locs(ρ) ρ ⊢ c ⇒ (l ← c), l (TRANS UNIT)\nρ ⊢ () ⇒ nil, () (TRANS OPERATOR) ρ ⊢V1 ⇒C1, l1 ρ ⊢V2 ⇒C2, l2 l /∈ locs(ρ)∪ locs(C1)∪ locs(C2) locs(C1)∩ locs(C2) =∅ ρ ⊢V1 ⊗V2 ⇒ (C1;C2; l ← l1 ⊗ l2), l (TRANS PAIR) ρ ⊢V1 ⇒C1, p1 ρ ⊢V2 ⇒C2, p2 locs(C1)∩ locs(C2) =∅ ρ ⊢ (V1,V2)⇒ (C1;C2),(p1, p2) (TRANS PROJ1) ρ ⊢V ⇒C,(p1, p2)\nρ ⊢V.1 ⇒C, p1\n(TRANS PROJ2) ρ ⊢V ⇒C,(p1, p2)\nρ ⊢V.2 ⇒C, p2 (TRANS IF) ρ ⊢V1 ⇒C1, l (locs(ρ)∪ locs(C1)∪ locs(C2)∪ locs(C3))∩ fv(p) =∅ ρ ⊢ M2 ⇒C2, p2 C′2 = local locs(C2) in (C2; p ← p2) p2 ∼ p ρ ⊢ M3 ⇒C3, p3 C′3 = local locs(C3) in (C3; p ← p3) p3 ∼ p ρ ⊢ (if V1 then M2 else M3)⇒ (C1; if l then C′2 else C′3), p (TRANS OBSERVE)\nρ ⊢V ⇒C, l b is the type of V ρ ⊢ observe V ⇒ (C;observeb l), ()\n(TRANS RANDOM) ρ ⊢V ⇒C, p l /∈ locs(ρ)∪ locs(C)\nρ ⊢ random (D(V ))⇒ (C; l s←− D(p)), l\n(TRANS LET) ρ ⊢ M1 ⇒C1, p1 x /∈ dom(ρ) ρ{x 7→ p1} ⊢ M2 ⇒C2, p2 ρ ⊢ let x = M1 in M2 ⇒ (local (locs(C1)\\ fv(p1)) in C1);C2, p2\nIn general, a Fun term M translates under a layout ρ to a series of commands C and a pattern p. The commands C mutate the global store so that the locations in p correspond to the value that M returns. The simplest example of this is in (TRANS CONST): the constant expression c translates to an Imp program that writes c into a fresh location l. The pattern that represents this return value is l itself. The (TRANS VAR) and (TRANS UNIT) rules are similar. In both rules, no commands are run. For variables, we look up the pattern in the layout ρ ; for unit, we return the unit location. Translation of pairs (TRANS PAIR) builds each of the constituent values and constructs a pair pattern.\nMore interesting are the projection operators. Consider (TRANS PROJ1); the second projection is translated similarly by (TRANS PROJ2). To find V.1, we run the commands to generate V , which we know must return a pair pattern (p1, p2). To extract the first element of this pair, we simply need to return p1. Not only would it not be easy to isolate and run only the commands to generate the values that go in p1, it would be incorrect to do so. For example, the Fun expressions constructing the second element of V may observe values, and hence have non-local effects.\nThe translation for conditionals (TRANS IF) is somewhat subtle. First, we run the translated branch condition. The return value of the translated branches is reassigned to a pattern p of fresh locations: using a shared output pattern allows us to avoid the φ nodes common in SSA compilers. We use the Imp derived form where the local variables of the then and else branches of the conditional are restricted. Instead, both branches write to a fresh shared target p, in order to preserve well-typedness (Proposition 4.3).\nThe rule (TRANS OBSERVE) translates observe by running the commands to generate the value for V and then observing the pattern. (This pattern l can only be a location, and not of the form () or (p1, p2), as observations are only possible on values of base type.)\nThe rule (TRANS RANDOM) translates random sampling in much the same way. By D(p), we mean the flattening of p into a list of locations and passing it to the distribution constructor D.\nFinally, the rule (TRANS LET) translates let statements by running both expressions in sequence. We translate M2, the body of the let, with an extended layout, so that C2 knows where to find the values written by C1, in the pattern p1. Here the local variables of the let-bound expression are restricted using local.\nProposition 4.3. Suppose Γ ⊢ M : t and Σ ⊢ ρ : Γ. (1) There are C and p such that ρ ⊢ M ⇒C, p. (2) Whenever ρ ⊢ M ⇒C, p, there is Σ′ such that Σ ⊢C : Σ′ and Σ,Σ′ ⊢ p : t.\nProof. By induction on the typing of M (Appendix A.1).\nWe define operations lift and restrict to translate between Fun variables (S〈Γ〉) and Imp locations (S〈Σ〉).\nlift ρ , λ s.flatten{ρ(x) 7→ V[[x]] s | x ∈ dom(ρ)} restrict ρ , λ s.{x 7→ V[[ρ(x)]] s | x ∈ dom(ρ)}\nWe let flatten take a mapping from patterns to values to a mapping from locations to base values. Given these notations, we state that the compilation of Fun to Imp preserves the measure transformer semantics, modulo a pattern p that indicates the locations of the various parts of the return value in the typing environment; an environment mapping ρ , which does the same translation for the initial typing environment; and superfluous variables, removed by restrict.\nTheorem 4.4. If Γ ⊢ M : t and Σ ⊢ ρ : Γ and ρ ⊢ M ⇒C, p then: A[[M]] = pure (lift ρ)>>> I[[C]]>>> pure (λ s. (restrict ρ s,V[[p]] s)).\nProof. By induction on the typing of M (Appendix A.2)."
    }, {
      "heading" : "5. ADDING ARRAYS AND COMPREHENSIONS",
      "text" : "To be useful for machine learning, our language must support large datasets. To this end, we extend Fun and Imp with arrays and comprehensions. We offer three examples, after which we present the formal semantics, which is based on unrolling.\n5.1. Comprehension Examples in Fun. Earlier, we tried to estimate the skill levels of three competitors in head-to-head games. Using comprehensions, we can model skill levels for an arbitrary number of players and games:"
    }, {
      "heading" : "TrueSkill:",
      "text" : "let trueskill (players:int[]) (results:(bool∗int∗int)[]) = let skills = [for p in players →random (Gaussian(10.0,20.0))] for (w,p1,p2) in results do\nlet perf1 = random (Gaussian(skills.[p1], 1.0)) let perf2 = random (Gaussian(skills.[p2], 1.0)) if w // win? then observe (perf1 > perf2) // first player won else observe (perf1 = perf2) // draw\nskills\nFirst, we create a prior distribution for each player: we assume that skills are normally distributed around 10.0, with variance 20.0. Then we look at each of the results—this is the comprehension. The result of the head-to-head matches is an array of triples: a Boolean and two indexes. If the Boolean is true, then the first index represents the winner and the second represents the loser. If the Boolean is false, then the match was a draw between the two players. The probabilistic program walks over the results, and observes that either the first player’s performance—normally distributed around their skill level—was greater than the second’s performance, or that the two players’ performances were equal. Returning skills after these observations allows us to inspect the posterior distributions. Our original example can be modelled with players = [0;1;2] (IDs for Alice, Bob, and Cyd, respectively) and results = [(true,0,1);(true,1,2);(true,0,2)].\nAs another example, we can generalize the simple Bayesian classifier of Section 3 to arrays of categories and measurements, as follows:\nBayesian Inference Over Arrays:\nlet trainF (catIds:int[]) (trainData:(int∗real)[]) fMean fVariance = let priors = [for cid in catIds →random (Gaussian(fMean,fVariance))] for (cid,m) in trainData do observe (m − random (Gaussian(priors.[cid],1.0))) priors let catIds:int[] = (∗ ... ∗) let trainingData:(int∗real)[] = (∗ ... ∗)\nThe function trainF is a probabilistic program for training a naive Bayesian classifier on a single feature. Each category of objects—modelled by the array catIds—is given a normally distributed prior on the weight of objects in that category; we store these in the priors array. Then, for each measurement m of some object of category cid in the trainingData array, we observe that m is normally distributed according to the prior for that category of object. We then return the posterior distributions, which have been appropriately modified by the observed weights. We can train using this model by issuing a command such as trainF catIds trainingData 20.0 5.0, which runs inference to compute for each category its posterior distribution for this feature.\nAs a third example, consider the adPredictor component of the Bing search engine, which estimates the click-through rates for particular users on advertisements [17]. We describe a probabilistic program that models (a small part of) adPredictor. Without loss of generality, we use only two features to make our prediction: the advertiser’s listing and the phrase used for searching. In the real system, many more (undisclosed) features are used for prediction.\nadPredictor in F#:\nlet read lines filename count line = (∗ ... ∗) [<RegisterArray>] let imps = (∗ ... ∗) [<ReflectedDefinition>] let probit b x =\nlet y = random (Gaussian(x,1.0)) observe (b == (y > 0.0))\n[<ReflectedDefinition>] let ad predictor (listings:int[]) (phrases:int[]) impressions =\nlet lws = [for l in listings →random (Gaussian(0.0,0.33))] let pws = [for p in phrases →random (Gaussian(0.0,0.33))] for (clicked,lid,pid) in Array.toList impressions do\nprobit clicked (lws.[lid] + pws.[pid]) lws,pws\nThe read lines function loads data from a file on disk. The data are formatted as newline-separated records of comma-separated values. There are three important values in each record: a field that is 1 if the given impression lead to a click, and a 0 otherwise; a field that is the database ID of the listing shown; a field that is the part of the search phrase that led to the selection of the listing. We preprocess the data in three ways, which are elided in the code above. First, we convert the 1/0-valued Boolean to a true/false-valued Boolean. Second, we normalize the listing IDs so that they begin at 0, that is, so that we can use them as array indexes. Third, we collect unique phrases and assign them fresh, 0-based IDs. We define imps—a list of advertising impressions (a listing ID and a phrase ID) and whether or not the ad was clicked—in terms of this processed data. The [<RegisterArray>] attribute on the definition of imps instructs the compiler to simply evaluate this F# expression, yielding a deterministic constant. Finally, ad predictor defines the model. We use the [<ReflectedDefinition>] attribute on ad predictor to mark it as a probabilistic program, which should be compiled and sent to Infer.NET. Suppose we have stored the collated listing and phrase IDs in ls and ps, respectively; we can train on the impressions by calling ad predictor ls ps imps.\n5.2. Formalizing Arrays and Comprehensions in Fun. We introduce syntax for arrays in Fun, and give interpretations of this extended syntax in terms of the core languages, essentially by treating arrays as tuples and by unfolding iterations. We work with non-empty zero-indexed arrays of statically known size (representing, for example, statically known experimental data).\nThere are three array operations: array literals, indexing, and array comprehension. First, let R be a set of ranges r. Ranges allow us to differentiate arrays of different sizes. Moreover, limitations in the implementation of Infer.NET disallow nested iterations on the same range. Here we disallow nested iterations altogether—they are not needed for our examples and they would significantly complicate the formalization. We assign sizes to ranges using the function |·| : R → Z+. In the metalanguage, arrays over range r correspond to tuples of length |r|."
    }, {
      "heading" : "Extended Syntax of Fun:",
      "text" : "t ::= · · · | t[r] type M,N ::= · · · | expression\n[V1; . . . ;Vn] array literal V1.[V2]r indexing [for x inr V → M] comprehension\nFirst, we add arrays as a type: t[r] is an array of elements of type t over the range r. In the array type t[r], we require that the type t contains no array type t ′[r′], that is, we do not consider nested arrays. Indexing, V1.[V2]r, extracts elements out of an array, where the index V2 is computed modulo the size |r| of the array V1. A comprehension [for x inr V → M] maps over an array V , producing a new array where each element is determined by evaluating M with the corresponding element of array V bound to x. To simplify the formalization, we here require that the body M of the comprehension contains neither array literals nor comprehensions. We attach the range to indexing and comprehensions so that the measure transformer semantics can be given simply; the range can be inferred easily, and need not be written by the programmer. We elide the range in our code examples. We here do not distinguish comprehensions that produce values—like the one that produces skills—and those that do not—like the one that observes player performances according to results. For the sake of efficiency, our implementation does distinguish these two uses. In some of the code examples, we write for x in V do M to mean [for x inr V → M]. We do so only when M has type unit and we intend to ignore the result of the expression. We encode arrays as tuples. For all n > 0, we define πn(M,N) with M : tn and N : int and if N%n = i we expect πn((V0, . . . ,Vn−1),N) =Vi. Derived Types and Expressions for Arrays in Fun:\nπ1(M,N) := M πn(M,N) := if N%n== 0 then M.1 else πn−1(M.2,N −1) for n > 1 t[r] := t |r| where t1 := t and tn+1 := t ∗ tn\n[V0; ...;Vn−1] := (V0, . . . ,Vn−1) V1[V2]r := π|r|(V1,V2) for x inr V → M :=\nlet y0 = (let x = π|r|(V,0) in M) in · · · let y|r|−1 = (let x = π|r|(V, |r|−1) in M) in (y0; . . . ;y|r|−1) where y1, . . . ,y|r| are fresh for M and V .\nOur derived forms for arrays yield programs whose size grows linearly with the data over which they compute—we implement V [i]r with O(|r|) projections. To avoid this problem, our implementation takes advantage of support for arrays in the Infer.NET factor graph library (see Section 5.3).\nThe static semantics of these new constructs is straightforward; we give the derived rules for (FUN ARRAY), (FUN INDEX), and (FUN FOR). By adding these as derived forms in Fun, we do not need to extend Imp at all. On the other hand, our formalization does not reflect that our implementation preserves the structure of array comprehensions when going to Infer.NET."
    }, {
      "heading" : "Extended Typing Rules for Fun Expressions: Γ ⊢ M : t",
      "text" : "(FUN ARRAY) Γ ⊢Vi : t ∀i ∈ 0..n−1 Γ ⊢ [V0; . . . ;Vn−1] : t[rn] (FUN INDEX) Γ ⊢V1 : t[r] Γ ⊢V2 : int Γ ⊢V1[V2]r : t (FUN FOR) Γ ⊢V : t[r] Γ,x : t ⊢ M : t ′ Γ ⊢ [for x inr V → M] : t ′[r]\nThe rule (FUN ARRAY) uses the notation rn for the concrete range of size n; we assume there is a unique such range for each n > 0. This rule can be derived using repeated applications of (FUN PAIR). The rule (FUN INDEX) checks that the array V1 is non-empty array and the index V2 is an integer; the actual index is the value of V2 modulo the size of the array, as in the meta-language. We can derive this rule for a given n by induction on n, using repeated applications of (FUN IF); we use (FUN PROJ1) in the then case and (FUN PROJ2) in the else case. The rule (FUN FOR) requires that the source expression V is an array, and that the body M is well-typed assuming a suitable type for x. We can derive (FUN FOR) using repeated applications of (FUN LET), with (FUN PAIR) to type the final result.\n5.3. Arrays in Imp. We now sketch our structure-preserving implementation strategy. We work in a version of Imp with arrays and iteration over ranges, and we extend both the assignment form and expressions to permit array indexing. Inside the body of an iteration over a range, the name of the range can be used as an index."
    }, {
      "heading" : "Extended Syntax of Imp:",
      "text" : "E ::= . . . | l[l′] | l[r] expression I ::= · · · | statement\nl[r]← E assignment to array item for r do C iteration over ranges\nWe require that every occurrence of an index r is inside an iteration for r do C. Inside such an iteration, every assignment to an array variable must be at index r. We also extend patterns to include range indexed locations, and write (p1, p2)[r] for (p1[r], p2[r]).\nOur compiler translates comprehensions over variables of array type as an iteration over the translation of the body of the comprehension. We add to ρ the fact that the comprehension variable corresponds to the array variable indexed by the range. We invent a fresh array result pattern p′, and assign the result of the translated body to p′[r]. Finally, we hide the local variables of the translation of the body of the comprehension, in order to avoid clashes in the unrolling semantics of the loop. This compilation corresponds to the rule (TRANS FOR) below. In particular, the sizes of ranges are never needed in our compiler, so compilation is not data dependent.\nCompilation of comprehensions:\n(TRANS FOR) ρ{x 7→ ρ(z)[r]} ⊢ M ⇒C, p p[r] ∼ p′ (locs(ρ)∪ locs(C))∩ fv(p′) =∅\nρ ⊢ [for x inr z → M]⇒ for r do local locs(C) in (C; p′[r]← p), p′"
    }, {
      "heading" : "6. IMPLEMENTATION EXPERIENCE",
      "text" : "We implemented a compiler from Fun to Imp in F#. We wrote two backends for Imp: an exact inference algorithm based on a direct implementation of measure transformers for discrete measures, and an approximating inference algorithm for continuous measures, using Infer.NET [37]. The translation of Section 4 formalizes our translation of Fun to Imp. Translating Imp to Infer.NET is relatively straightforward, and amounts to a syntax-directed series of calls to Infer.NET’s object-oriented API.\nThe frontend of our compiler takes (a subset of) actual F# code as its input. To do so, we make use of F#’s reflected definitions, which allow programmatic access to ASTs. This implementation strategy is advantageous in several ways. First, there is no need to design new syntax, or even write a parser. Second, all inputs to our compiler are typed ASTs of well typed F# programs. Third, a single file can contain both ordinary F# code as well as reflected definitions. This allows a single module to both read and process data, and to specify a probabilistic model for inference from the data.\nFunctions computing array values containing deterministic data are tagged with an attribute RegisterArray, to signal to the compiler that they do not need to be interpreted as Fun programs. Reflected definitions later in the same file are typed with respect to these registered definitions and then run in Infer.NET with the pre-processed data; we further discuss this idea below.\nBelow follows some statistics on a few of the examples we have implemented. The number of lines of code includes F# code that loads and processes data from disk before loading it into Infer.NET. The times are based on an average of three runs. All of the runs are on a four-core machine with 4GB of RAM. The Naive Bayes program is the naive Bayesian classifier of the earlier examples. The Mixture model is another clustering/classification model. TrueSkill and adPredictor were described earlier. TrueSkill spends the majority of its time (64%) in Infer.NET, performing inference. AdPredictor spends most of the time in pre-processing (58%), and only 40% in inference. The time spent in our compiler is negligible, never more than a few hundred milliseconds."
    }, {
      "heading" : "Summary of our Basic Test Suite:",
      "text" : "LOC Observations Variables Time Naive Bayes 28 9 3 <1s\nMixture 33 3 3 <1s TrueSkill 68 15,664 84 6s\nadPredictor 78 300,752 299,594 3m30s\nIn summary, our implementation strategy allowed us to build an effective prototype quickly and easily: the entire compiler is only 2079 lines of F#; the Infer.NET backend is 600 lines; the discrete backend is 252 lines. Our implementation, however, is only a prototype, and has limitations. Our discrete backend is limited to small models using only finite measures. Infer.NET supports only a limited set of operations on specific combinations of probabilistic and deterministic arguments. It would be useful in the future to have an enhanced type system able to detect errors arising from illegal combinations of operators in Infer.NET. The reflected definition facility is somewhat limited in F#. In the adPredictor example on page 24, a call to Array.toList is required because F# does not\nreflect definitions that contain comprehensions over arrays—only lists. (The F# to Fun compiler discards this extra call as a no-op, so there is no runtime overhead.)"
    }, {
      "heading" : "7. RELATED WORK",
      "text" : "Formal Semantics of Probabilistic Languages. There is a long history of formal semantics for probabilistic languages with sampling primitives, often combined with recursive computation. One of the first semantics is for Probabilistic LCF [49], which augments the core functional language LCF with weighted binary choice, for discrete distributions. (Apart from its inclusion of observations, Bernoulli Fun is a first-order terminating form of Probabilistic LCF.) Kozen [27] develops a probabilistic semantics for while-programs augmented with random assignment. He develops two provably equivalent semantics; one more operational, and the other a denotational semantics using partially ordered Banach spaces. Imp is simpler than Kozen’s language, as Imp has no unbounded while-statements, so the semantics of Imp need not deal with non-termination. On the other hand, observations are not present in Kozen’s language, although discrete observations can be encoded using possibly non-terminating while loops.\nJones and Plotkin [22] investigate the probability monad, and apply it to languages with discrete probabilistic choice. Ramsey and Pfeffer [46] give a stochastic λ -calculus with a measure-theoretic semantics in the probability monad, and provide an embedding within Haskell; they do not consider observations. We can generalize the semantics of observe to the stochastic λ -calculus as filtering in the probability monad (yielding what we may call a sub-probability monad), as long as the events that are being observed are discrete. In their notation, we can augment their language with a failure construct defined by P[[fail]]ρ = µ0 where we define µ0(A) = 0 for all measurable sets A. Then, we can define observe v = (if v = true then () else fail). However, as discussed in Section 3.5, zeroprobability observations of real variables do not translate easily to the probability monad, as the following example shows. Let N be an expression denoting a continuous distribution, for example, random (Gaussian(0.0,1.0)), and let f x = observe x. Suppose there is a semantics for [[f x]]{x 7→ r} for real r in the probability monad. The probability monad semantics of the program let x = N in f x of the stochastic λ -calculus is [[N]] ≫= λy.[[f x]]{x 7→ y}, which yields the measure µ(A) = ∫\nR (M[[[[f x]]{x 7→ y}]])(A) dM[N](y). Here the probability (M[[[[f x]]{x 7→ y}]])(A) is zero except when y = 0, where it is some real number. Since the N-measure of y = 0 is zero, the whole integral is zero for all A (in particular µ(R) = 0), whereas the intended semantics is that x is constrained to be zero with probability 1 (so in particular µ(R) = 1).\nThe probabilistic concurrent constraint programming language Probabilistic cc of Gupta, Jagadeesan, and Panangaden [18] is also intended for describing probability distributions using independent sampling and constraints. Our use of observations loosely corresponds to constraints on random variables in Probabilistic cc. In the finite case, Probabilistic cc also relies on a sampling semantics with observation (constraints) denoting filtering. To admit continuous distributions, Probabilistic cc adds general fixpoints and defines the semantics of a program as the limit of finite unrollings of its fixpoints, if defined. This can lead to surprising results, such as that the distribution resulting from observing that two apparently uniform distributions are equal may not itself be uniform. In contrast, we work directly with standard distributions and have a less syntactic semantics of observation that appears to be easier to anticipate.\nMcIver and Morgan [33] develop a theory of abstraction and refinement for probabilistic while programs, based on weakest preconditions. They reject a subdistribution transformer semantics in order to admit demonic nondeterminism in the language.\nWe conjecture that Fun and Imp could in principle be conferred semantics within a probabilistic language supporting general recursion, by encoding discrete observations by placing the whole program within a conditional sampling loop, and by encoding Gaussian and other continuous distributions as repeated sampling using recursive functions. Still, dealing with recursion would be a non-trivial development, and would raise issues of computability. Ackerman, Freer, and Roy [2] show the uncomputability of conditional distributions in general, establishing limitations on constructive foundations of probabilistic programming. We chose when formulating the semantics of Fun and Imp to include some distributions as primitive, and to exclude recursion; compared to encodings within probabilistic languages with recursion, this choice has the advantage of compositionality (rather than relying on a global sampling loop) and of admitting a direct (if sometimes approximate) implementation (via message-passing algorithms on factor graphs, with efficient implementations of primitive distributions).\nRecent work on semantics of probabilistic programs within interactive theorem provers includes the mechanization of measure theory [20] and Lebesgue integration [35] in HOL, and a framework for proofs of randomized algorithms in Coq [3] which also allows for discrete observations.\nProbabilistic Languages for Machine Learning. Koller et al. [26] proposed representing a probability distribution using first-order functional programs with discrete random choice, and proposed an inference algorithm for Bayesian networks and stochastic context-free grammars. Observations happen outside their language, by returning the distributions P [A∧B] ,P [A∧¬B],P [¬A] which can be used to compute P [B | A]. Their work was subsequently developed by Pfeffer into the language IBAL [43], which has observations and uses a factor graph semantics, but only works with discrete datatypes.\nPark et al. [41] propose λ◦, the first probabilistic language with formal semantics applied to actual machine learning problems involving continuous distributions. The formal basis is sampling functions, which uniformly supports both discrete and continuous probability distributions, and inference is by Monte Carlo importance sampling methods. The calculus λ◦ enables conditional sampling via fixpoints and rejection, and its implementation allows discrete observations only.\nHANSEI [24, 23] is an embedding of a probabilistic language as a programming library in OCaml, based on explicit manipulation of discrete probability distributions as lists, and sampling algorithms based on coroutines. HANSEI uses an explicit fail statement, which is equivalent to observe false and so cannot be used for conditioning on zero probability events. Infer.NET [37] is a software library that implements the approximate deterministic algorithms expectation propagation [38] and variational message passing [53], as well as Gibbs sampling, a nondeterministic algorithm. Infer.NET models are written in a probabilistic subset of C#, known as Csoft [52]. Csoft allows observe on zero probability events, but does not have a continuous semantics other than as factor graphs and is currently only implemented as an internal language of Infer.NET. This paper gives a higher-level semantics of Csoft (or Imp) programs as distribution transformers.\nAlthough there are many Bayesian modelling languages, Csoft and IBAL are the only previous languages implemented by a compilation to factor graphs. Probabilistic Scheme [45] is a probabilistic form of the untyped functional language Scheme, limited to discrete distributions, and with a construct for reifying the distribution induced by a thunk as a value. Church [15] is another probabilistic form of Scheme, equipped with conditional sampling and a mechanism of stochastic memoization. In MIT-Church, queries are implemented using Markov chain Monte Carlo methods. WinBUGS [39] is a popular implementation of the BUGS language [14] for explicitly describing distributions suitable for MCMC analysis.\nFACTORIE [32] is a Scala library for explicitly constructing factor graphs. Blaise [7] is a software library for building MCMC samplers in Java, that supports compositional construction of sophisticated probabilistic models, and decouples the choice of inference algorithm from the specification of the distribution.\nA recent paper [16] based on Fun describes a model-learner pattern which captures common probabilistic programming patterns in machine learning, including various sorts of mixture models.\nOther Uses of Probabilistic Languages. Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1]. A recent monograph on semantics for labelled Markov processes [40] focuses on bisimulation-based equational reasoning. The syntax and semantics of Imp is modelled on the probabilistic language pWhile [4] without observations.\nErwig and Kollmansberger [12] describe a library for probabilistic functional programming in Haskell. The library is based on the probability monad, and uses a finite representation suitable for small discrete distributions; the library would not suffice to provide a semantics for Fun or Imp with their continuous and hybrid distributions. Their library has similar functionality to that provided by our combinators for discrete distributions listed in the technical report."
    }, {
      "heading" : "8. CONCLUSION",
      "text" : "We advocate probabilistic functional programming with observations and comprehensions as a modelling language for Bayesian reasoning. We developed a system based on the idea, invented new formal semantics to establish correctness, and evaluated the system on a series of typical inference problems.\nOur direct contribution is a rigorous semantics for a probabilistic programming language with zero-probability observations on continuous variables. We have shown that probabilistic functional programs with iteration over arrays, but without the complexities of general recursion, are a concise representation for complex probability distributions arising in machine learning. An implication of our work for the machine learning community is that probabilistic programs can be written directly within an existing declarative language (Fun—a subset of F#), linked by comprehensions to large datasets, and compiled down to lower level Bayesian inference engines.\nFor the programming language community, our new semantics suggests some novel directions for research. What other primitives are possible—non-generative models, inspection of distributions, on-line inference on data streams? Can we verify the transformations performed by machine learning compilers such as Infer.NET compiler for Csoft? What is the role of type systems for such probabilistic languages? Avoiding (discrete) zero probability exceptions, and ensuring that we only generate Csoft programs suitable for our back-end, are two possibilities, but we expect there are more.\nAcknowledgements. We gratefully acknowledge discussions with and comments from Ralf Herbrich, Oleg Kiselyov, Tom Minka, Aditya Nori, Robert Simmons, Nikhil Swamy, Dimitrios Vytiniotis and John Winn. Chung-Chieh Shan highlighted an issue with our original definition of observation. The comments by the anonymous reviewers were most helpful, in particular regarding the definition of conditional density."
    }, {
      "heading" : "APPENDIX A. DETAILED PROOFS",
      "text" : "Our proofs are structured as follows. • Appendix A.1 gives a proof of Proposition 4.3. • Appendix A.2 gives a proof of Theorem 4.4.\nA.1. Proof of Proposition 4.3. We begin with a series of lemmas.\nLemma A.1 (Pattern agreement weakening). If Σ ⊢ p : t and Σ,Σ′ ⊢ ⋄, then Σ,Σ′ ⊢ p : t. Proof. By induction on t.\nLemma A.2 (Expression and statement heap weakening). (1) If Σ ⊢ E : b and Σ,Σ′ ⊢ ⋄, then Σ,Σ′ ⊢ E : b (2) If Σ ⊢ I : Σ′ and Σ,Σ′,Σ′′ ⊢ ⋄, then Σ,Σ′′ ⊢ I : Σ′ (3) If Σ ⊢C : Σ′ and Σ,Σ′,Σ′′ ⊢ ⋄, then Σ,Σ′′ ⊢C : Σ′. Proof. By induction on E , I, and C, respectively.\nLemma A.3 (Pattern agreement uniqueness). If Σ ⊢ p : t and Σ′ ⊢ p′ : t then p ∼ p′. Proof. By induction on t.\nLemma A.4 (Pattern creation). If Σ ⊢ p : t then there exists Σ′ such that Σ,Σ′ ⊢ ⋄ and Σ′ ⊢ p′ : t and dom(Σ′) = fv(p′).\nProof. By induction on t, and the assumption that there always exist new, globally fresh locations.\nLemma A.5 (Pattern assignment). If Σ ⊢ p : t and Σ′ ⊢ p′ : t and Σ,Σ′ ⊢ ⋄, then Σ ⊢ p′ ← p : Σ′′, where Σ′′ ⊆ Σ′. Proof. By induction on t. • (t = unit) Trivial: p′ ← p = nil, so Σ′′ = ε ⊆ Σ′. • (t = bool) Σ ⊢ l : bool and Σ′ ⊢ l′ : bool, so l : bool ∈ Σ and l′ : bool ∈ Σ′. So l : bool ⊢ l′ ← l : (l′ : bool)⊆ Σ′. • (t = int) Similar. • (t = real) Similar. • (t = t1 ∗ t2) Σ ⊢ p1, p2 : t1 ∗ t2 and Σ′ ⊢ p′1, p′2 : t1 ∗ t2. Both Σ and Σ′ factor into contexts that type\np1 and p2 (resp. p′1 and p ′ 2) individually; call them Σ1 and Σ2 (resp. Σ′1 and Σ′2). By the IHs, we have Σ1 ⊢ p′1 ← p1 : Σ′′1 ⊆ Σ′1 and Σ2 ⊢ p′2 ← p2 : Σ′′2 ⊆ Σ′2. We can then see Σ ⊢ p′1 ← p1; p′2 ← p2 : Σ′′1 ,Σ′′2 ⊆ Σ′1,Σ′2.\nThe purpose of this subsection is to prove the following. Restatement of Proposition 4.3 Suppose Γ ⊢ M : t and Σ ⊢ ρ : Γ. (1) There are C and p such that ρ ⊢ M ⇒C, p. (2) Whenever ρ ⊢ M ⇒C, p, there is Σ′ such that Σ ⊢C : Σ′ and Σ,Σ′ ⊢ p : t. Proof. By induction on the typing of M, leaving Σ and ρ general. (FUN VAR) Γ ⊢ x : t. For (1), we have C = nil and p = ρ(x). For (2), let Σ′ = ε . By assumption,\nΣ,Σ′ ⊢ ρ(x) : t and Σ ⊢ nil : Σ′ immediately.\n(FUN CONST) Γ ⊢ c : ty(c). For (1), we have: l 6∈ locs(ρ) ty(c) = b for some base type b ρ ⊢ c ⇒ l ← c, l\nFor (2), let Σ′ = l : ty(c). We have Σ,Σ′ ⊢ l : ty(c) and Σ ⊢ l ← c : Σ′. (FUN OPERATOR) Γ ⊢V1 ⊗V2 : b3, where ⊗ has type b1 ∗b2 → b3. By inversion and the IH:\nΓ ⊢V1 : b1 ρ ⊢V1 ⇒C1, l1 (IH1) ∃Σ1 (IH2)\nΣ,Σ1 ⊢ l1 : b1 Σ ⊢C1 : Σ1\nΓ ⊢V2 : b2 ρ ⊢V2 ⇒C2, l2 (IH2) ∃Σ2 (IH2)\nΣ,Σ2 ⊢ l2 : b2 Σ ⊢C2 : Σ2\nWe have for (1), by (TRANS OPERATOR): ρ ⊢V1 ⊗V2 ⇒C1;C2; l ← l1 ⊗ l2, l. Let Σ′ = Σ1,Σ2, l : b3 ⊢ ⋄. By weakening we find for (2): Σ,Σ′ ⊢ l : b3 and Σ ⊢C1;C2; l ← l1 ⊗ l2 : Σ′.\n(FUN PAIR) Γ ⊢ (M1,M2) : t1 ∗ t2. By inversion and the IH: Γ ⊢ M1 : t1 ρ ⊢ M1 ⇒CM1 , p1 (IH1) ∃Σ1 (IH2)\nΣ,Σ1 ⊢ p1 : t1 Σ ⊢CM1 : Σ1\nΓ ⊢ M2 : t2 ρ ⊢ M2 ⇒CM2 , p2 (IH1) ∃Σ2 (IH2)\nΣ,Σ2 ⊢ p2 : t2 Σ ⊢CM2 : Σ2\nWe have for (1): ρ ⊢ (M1,M2)⇒CM1 ;CM2 ,(p1, p2). Let Σ′ = Σ1,Σ2 ⊢ ⋄. By weakening we find for (2): Σ,Σ′ ⊢ (p1, p2) : t1 ∗ t2 and Σ ⊢CM1 ;CM2 : Σ′.\n(FUN PROJ1) Γ ⊢ M.1 : t1. By inversion and the IH: Γ ⊢ M : t1 ∗ t2 ρ ⊢ M ⇒CM, p (IH1) ∃Σ′ (IH2)\nΣ,Σ′ ⊢ p : t1 ∗ t2 Σ ⊢ M : S′\nBy inversion, p = (p1, p2), such that Σ,Σ′ ⊢ p1 : t1 and Σ,Σ′ ⊢ p2 : t2. We now have ρ ⊢ M.1 ⇒ CM, p1 for (1). We use Σ′ to show Σ,Σ′ ⊢ p1 : t1 and Σ ⊢CM : Σ′ for (2).\n(FUN PROJ2) Γ ⊢ M.2 : t2. Analogous to the previous case.\n(FUN IF) Γ ⊢ if M1 then M2 else M3 : t. We have: Γ ⊢ M1 : bool ρ ⊢ M1 ⇒CM1 , p1 (IH1) ∃Σ1 (IH2)\nΣ,Σ1 ⊢ p1 : bool Σ ⊢CM1 : Σ1\nΓ ⊢ M2 : t ρ{x 7→ pl} ⊢ M2 ⇒CM2 , p2 (IH1) ∃Σ2 (IH2)\nΣ,Σ2 ⊢ p2 : t Σ ⊢CM2 : Σ2\nΓ ⊢ M3 : t ρ{x 7→ pr} ⊢ M3 ⇒CM3 , p3 (IH1) ∃Σ3 (IH2)\nΣ,Σ3 ⊢ p3 : t Σ ⊢CM3 : Σ3\nBy inversion, p1 = l and Σ,Σ1 ⊢ l : bool. By pattern agreement uniqueness (Lemma A.3), p2 ∼ p3. Let Σp′ ⊢ p′ : t, for dom(Σp′) = f v(p) (by Lemma A.4). We have (locs(ρ)∪ locs(C1)∪ locs(C2)∪ locs(C3))∩ f v(p) =∅. We also have p′ ∼ p2 and p′ ∼ p3. We now have for (1):\nρ ⊢ if M1 then M2 else M3 ⇒ CM1 ; if l then local locs(C2) in CM2 ; [[p ′ ← p2]] else local locs(C3) in CM3 ; [[p′ ← p3]], p′\nFinally, let Σ f = Σ2 ∩ Σ3 ∩ Σp′ ⊢ ⋄ and Σ′ = Σ1,Σ f ⊢ ⋄. By pattern assignment, we can see Σ f ⊢ [[p′ ← p2]] and Σ f ⊢ [[p′ ← p3]]. By weakening (Lemmas A.1, and A.2) we have what we need for (2):\nΣ,Σ′ ⊢ p′ : t Σ ⊢CM1 ; if l then ... else ... : Σ′\n(FUN LET) Γ ⊢ let x = M1 in M2 : t2. We have: Γ ⊢ M1 : t1 ρ ⊢ M1 ⇒CM1 , p1 (IH1) ∃Σ1 (IH2)\nΣ,Σ1 ⊢ p1 : t1 Σ ⊢CM1 : Σ1\nΓ,x : T1 ⊢ M2 : t2 Next, note that Σ,Σ1 ⊢ ρ{x 7→ p1} : Γ,x : T1. We can now apply the IH to M2’s typing derivation to see:\nρ{x 7→ p1} ⊢ M2 ⇒CM2 , p2 (IH1) ∃Σ2 (IH2)\nΣ,Σ2 ⊢ p2 : t2 Σ ⊢CM2 : Σ2\nFirst, we have: ρ ⊢ let x = M1 in M2 ⇒ (local (locs(CM1) \\ fv(p1)) in CM1);CM2 , p2 for (1). For (2), let Σ′1 = Σ1|fv(p1) and Σ′ = Σ′1,Σ2 ⊢ ⋄. By weakening, we find Σ,Σ′ ⊢ p2 : t2 and Σ ⊢ (local (locs(CM1)\\ fv(p1)) in CM1);CM2 : Σ′.\n(FUN OBSERVE) Γ ⊢ observeb E : unit. By the IH, with Σ′ = ε from IH2.\n(FUN RANDOM) Γ ⊢ random(D(V )) : bn+1. We have: D : (x1 : b1 ∗ ...∗ xn : bn)→ bn+1 Γ ⊢V : (b1 ∗ ...∗bn)\nWe have, by the IH: ρ ⊢V ⇒C, p (IH1) ∃Σ′ (IH2)\nΣ,Σ′ ⊢ p : t (∗) Σ ⊢C : Σ′\nSo ρ ⊢ random(D(V )) ⇒ C; l s←− D(p), l, for (1). We find (2) by (*) and by (Imp Seq), (Imp Random), and the IH Σ ⊢C; l : Σ′, l, where Σ′, l ⊢ l : bn+1.\nA.2. Proof of Theorem 4.4. We use the following lemma.\nLemma A.6 (Value equivalence). If Γ ⊢V : t and Σ ⊢ ρ : Γ and ρ ⊢V ⇒C, p then I[[C]] = pure f , where f is either id or a series of (independent) calls to add :\nf = λ s. add l1(add l2(...(add ln(s,cn))...,c2),c1) where each of the li are distinct, and\nA[[V ]] = pure (lift ρ)>>> I[[C]] >>> pure (λ s. restrict ρ s,V[[p]] s)\nProof. By induction on the derivation of Γ ⊢V : t. (FUN VAR) Γ ⊢ x : t, so x : t ∈ Γ and Σ ⊢ ρ(x) : t. We have ρ ⊢ x ⇒ nil,ρ(x), so f = id.\nA[[x]] = pure (λ s. (s,V[[x]] s)) = pure (λ s. (s,lookup x s)) = pure (λ s. (restrict ρ(lift ρ),V[[p]] (lift ρ s))) = lift ρ >>> (λ s. (restrict ρ s,V[[p]] s)) = lift ρ >>> pure id >>> (λ s. (restrict ρ s,V[[p]] s)) = lift ρ >>>A[[x]] >>> (λ s. (restrict ρ s,V[[p]] s))\n(FUN CONST) Γ ⊢ c : ty(c). We have ρ ⊢ c ⇒ l ← c, l, so f = λ s. add l (s,c). A[[c]]\n= pure (λ s. s,c) = pure (λ s. restrict ρ(lift ρ s),V[[l]] (add l (lift ρ s,c))) = pure (lift ρ)>>> pure (λ s. restrict ρ s,V[[l]] (add l (s,c))) = pure (lift ρ)>>> pure (λ s. add l (s,c)) >>> pure (λ s. restrict ρ s,V[[l]] s) = pure (lift ρ)>>> I[[l ← c]]>>> pure (λ s. restrict ρ s,V[[l]] s)\n(FUN PAIR) Γ ⊢ (V1,V2) : t1 ∗ t2. We have ρ ⊢V1,V2 ⇒C1;C2,(p1, p2). By the IH, I[[C1]] = pure f1 and I[[C2]] = pure f2, where f1 and f2 are either id or add s. We also have:\nA[[Vi]] = pure (λ s. s,V[[Vi]] s) = pure (lift ρ)>>> I[[Ci]]>>> pure (λ s. restrict ρ s,V[[pi]] s) = pure (lift ρ)>>> pure fi >>> pure (λ s. restrict ρ s,V[[pi]] s) = pure (λ s. restrict ρ( fi(lift ρ s)),V[[pi]] ( fi (lift ρ s))) = pure (λ s. s,V[[pi]] ( fi (lift ρ s)))\nSo V[[Vi]] s = V[[pi]] ( fi(lift ρ s)). Let f = f1; f2. We derive: A[[V1,V2]]\n= pure (λ s. s,(V[[V1]] s,V[[V2]] s)) = pure (λ s. s,(V[[p1]] ( f1 (lift ρ s)),V[[p2]] ( f2 (lift ρ s))) by weakening/independence = pure (λ s. s,(V[[p1]] (( f1; f2)(lift ρ s)),V[[p2]] (( f1; f2)(lift ρ s))) = pure (λ s. restrict ρ ( f1; f2(lift ρ s)), (V[[p1]] (( f1; f2)(lift ρ s)),V[[p2]] (( f1; f2)(lift ρ s))) = pure (lift ρ)>>> pure ( f1; f2)>>> pure (λ s. restrict ρ s,(V[[p1]] s,V[[p2]] s)) = pure (lift ρ)>>> I[[C1]]>>> I[[C2]]>>> pure (λ s. restrict ρ s,V[[(p1, p2)]] s) = pure (lift ρ)>>> I[[C1;C2]]>>> pure (λ s. restrict ρ s,V[[(p1, p2)]] s)\nRestatement of Theorem 4.4 Γ ⊢ M : t and Σ ⊢ ρ : Γ and ρ ⊢ M ⇒C, p then: A[[M]] = pure (lift ρ)>>> I[[C]]>>> pure (λ s. (restrict ρ s,V[[p]] s))\nProof. By induction on Γ ⊢ M : t. (FUN VAR) By the value lemma. (FUN CONST) By the value lemma. (FUN PAIR) By the value lemma. (FUN OPERATOR) Γ ⊢V1⊗V2 : b3 and ρ ⊢V1⊗V2 ⇒ (C1;C2; l ← l1 ⊗ l2), l. We have A[[V1⊗V2]] =\npure (λ s. s,⊗(V[[V1]] s,V[[V2]] s)). By the value lemma (Lemma A.6): A[[Vi]]\n= pure (λ s. s,V[[Vi]] s) = pure (lift ρ)>>> I[[Ci]]>>> pure (λ s. restrict ρ s,V[[li]] s) = pure (lift ρ)>>> pure fi >>> pure (λ s. restrict ρ s,V[[li]] s) = pure (λ s. restrict ρ ( fi (lift ρ s)),V[[li]] ( fi (lift ρ s))) = pure (λ s. s,V[[li]] ( fi(lift ρ s))) = pure (λ s. s,V[[li]] (( f1; f2)(lift ρ s)) by weakening/independence\nSo V[[Vi]] s = V[[li]] (( f1; f2)(lift ρ s)). We derive: A[[V1 ⊗V2]]\n= pure (λ s. s,V[[V1]] s⊗V[[V2]] s) = pure (λ s. s,⊗(V[[l1]] (( f1; f2)(lift ρ s)),V[[l2]] (( f1; f2)(lift ρ s)))) = pure (lift ρ)>>> pure ( f1; f2)>>> pure (λ s. restrict ρ s,⊗(V[[l1]] s,V[[l2]] s)))) = pure (lift ρ)>>> I[[C1]]>>> I[[C2]]>>> pure (λ s. restrict ρ s,⊗(V[[l1]] s,V[[l2]] s)))) = pure (lift ρ)>>> I[[C1]]>>> I[[C2]]>>> I[[l ← l1 ⊗ l2]]>>> pure (λ s. restrict ρ s,V[[l]] s))) = pure (lift ρ)>>> I[[C1;C2; l ← l1 ⊗ l2]]>>> pure (λ s. restrict ρ s,V[[l]] s)))\n(FUN PROJ1) Γ ⊢V.1 : t1 and Γ ⊢V : t1 ∗ t2. We have ρ ⊢V ⇒C,(p1, p2) and ρ ⊢V.1 ⇒C, p1. By the value lemma as before, we can conclude V[[V ]] s = V[[(p1, p2)]] ( f (lift ρ s)). Therefore:\nA[[V.1]] = pure (λ s. s,fst V[[V ]] s) = pure (λ s. s,fst (V[[(p1, p2)]] ( f (lift ρ s))) = pure (λ s. s,V[[p1]] ( f (lift ρ s)) = pure (lift ρ)>>> pure f >>> pure (λ s. restrict ρ s,V[[p1]] s) = pure (lift ρ)>>> I[[C]]>>> pure (λ s. restrict ρ s,V[[p1]] s)\n(FUN PROJ2) Symmetric to Proj1.\n(FUN IF) Γ ⊢ if V1 then M2 else M3 : t. We have: ρ ⊢ ...⇒C1; if l1 then local locs(C2) in C2; p ← 2 else local locs(C3) in C3; p ← p3, p\nOur IHs are: A[[Mi]] = pure (lift ρ)>>> I[[Ci]]>>> pure (λ s. restrict ρ s,V[[pi]] s). By the value lemma we have I[[V1]] = pure f1 for some f1 such that V[[V1]] s = V[[l1]] ( f1(lift ρ s)). We now calculate (at length):\nA[[if V1 then M2 else M3]] = choose (λ s. V[[V1]] s) A[[M2]] A[[M3]]\n= choose (λ s. V[[l1]] ( f1 (lift ρ s))) (pure (lift ρ)>>> I[[C2]]>>> pure (λ s. restrict ρ s,V[[p2]] s)) (pure (lift ρ)>>> I[[C3]]>>> pure (λ s. restrict ρ s,V[[p3]] s))\n= pure (lift ρ)>>> choose (λ s.V[[l1]] ( f1 s)) (I[[C2]]>>> pure (λ s. restrict ρ s,V[[p2]] s)) (I[[C3]]>>> pure (λ s. restrict ρ s,V[[p3]] s))\n= pure (lift ρ)>>> choose (λ s.V[[l1]] ( f1 s)) (I[[C2]]>>> I[[p ← p2]]>>> pure (λ s. restrict ρ s,V[[p]] s)) (I[[C3]]>>> I[[p ← p3]]>>> pure (λ s. restrict ρ s,V[[p]] s))\n= pure (lift ρ)>>> choose (λ s.V[[l1]] ( f1 s)) (I[[C2]]>>> I[[p ← p2]]>>> pure (drop locs(C2))>>> pure (λ s. restrict ρ s,V[[p]] s)) (A[[C3]]>>>A[[p ← p3]]>>> pure (drop locs(C3))>>> pure (λ s. restrict ρ s,V[[p]] s))\n= pure (lift ρ)>>> (choose (λ s.V[[l1]] ( f1 s)) (A[[C2]]>>>A[[p ← p2]]>>> pure (drop locs(C2))) (A[[C3]]>>>A[[p ← p3]]>>> pure (drop locs(C3))))>>>\npure (λ s. restrict ρ s,V[[p]] s)\n= pure (lift ρ)>>>A[[C1]]>>> (choose (λ s.V[[l1]] s) (A[[C2; p ← p2]]>>> pure (drop locs(C2))) (A[[C3; p ← p3]]>>> pure (drop locs(C3))))>>>\npure (λ s. restrict ρ s,V[[p]] s) = pure (lift ρ)>>>A[[C1]]>>> (choose (λ s.V[[l1]] s)\n(A[[local locs(C2) in C2; p ← p2]]) (A[[local locs(C3) in C3; p ← p3]]))>>>\npure (λ s. restrict ρ s,V[[p]] s) (FUN LET) Γ ⊢ let x = M1 in M2 : t2; by inversion, Γ ⊢ M1 : t1 and Γ,x : t1 ⊢ M2 : t2.\nLet ρ ′ = ρ{x 7→ p1} and Σ1 = (locs(C1)\\ fv(p1)). We have: ρ ⊢ M1 ⇒C1, p1 ρ ′ ⊢ M2 ⇒C2, p2 ρ ⊢ let x = M1 in M2 ⇒ (local Σ1 in C1);C2, p2\nAs our IHs:\nA[[M1]] = pure (lift ρ)>>>A[[C1]]>>> pure (λ s. restrict ρ s,V[[p1]] s) A[[M2]] = pure (lift ρ ′)>>>A[[C2]]>>> pure (λ s. restrict ρ ′s,V[[p2]] s)\nWe derive: A[[let x = M1 in M2]]\n= A[[M1]]>>> pure (add x) >>>A[[M2]]>>> pure (λ s,y. drop x s,y) = pure (lift ρ)>>>A[[C1]]>>> pure (λ s. restrict ρ s,V[[p1]] s)>>> pure (add x)>>>\nA[[M2]]>>> pure (λ s,y. drop x s,y) = pure (lift ρ)>>>A[[C1]]>>> pure (λ s. restrict ρ s,V[[p1]] s)>>>\npure (add x)>>> pure (lift ρ ′)>>> A[[C2]]>>> pure (λ s. restrict ρ ′s,V[[p2]] s)>>> pure (λ s,y. drop x s,y) = pure (lift ρ)>>>A[[C1]]>>> pure (drop (dom(Σ1)))>>> A[[C2]]>>> pure (λ s. restrict ρ ′s,V[[p2]] s)>>> pure (λ s,y. drop x s,y) = pure (lift ρ)>>>A[[C1]]>>> pure (drop (dom(Σ1)))>>> A[[C2]]>>> pure (λ s. restrict ρ s,V[[p2]] s)\n= pure (lift ρ)>>>A[[(local Σ1 in C1);C2]]>>> pure (λ s. restrict ρ s,V[[p2]] s) (FUN RANDOM) Γ ⊢ random(D(V )) : b, where D : (b1, ...,bn) → bn+1,Γ ⊢ V : (b1, ...,bn). We\nhave ρ ⊢ V ⇒ C, p and ρ ⊢ D(V )⇒ C; l ← D(p), l. By the value lemma, A[[C]] = pure f and V[[V ]] s = V[[p]] ( f (lift ρ s)). We derive:\nA[[random(D(V ))]] = extend (λ s. µD(V[[V ]] s)) = extend (λ s. µD(p( f (lift ρ s)))) = pure (lift ρ)>>> extend (λ s. µD(p( f s)))>>> pure (λ s,v. restrict ρ s,v) = pure (lift ρ)>>> pure f >>> extend (λ s. µD(V[[p]] s))>>> pure (λ s,v. restrict ρ s,v) = pure (lift ρ)>>>A[[C]]>>> extend (λ s. µD(V[[p]] s))>>> pure (λ s,v. restrict ρ s,v) = pure (lift ρ)>>>A[[C]]>>> extend (λ s. µD(V[[p]] s))>>>\npure (add l)>>> pure (λ s. restrict ρ s,V[[l]] s) = pure (lift ρ)>>>A[[C; l ← D(p)]]>>> pure (λ s. restrict ρ s,V[[l]] s)\n(FUN OBSERVE) Γ ⊢ observe V : unit and Γ ⊢V : b for some base type b. We have ρ ⊢V ⇒C, l. By the value lemma: A[[C]] = pure f and V[[V ]] s = V[[l]] ( f (lift ρ s)).\nA[[observe V ]] = observe (λ s. V[[V ]] s)>>> pure (λ s. (s,()) = observe (λ s. l( f (lift ρ s)))>>> pure (λ s. s,()) = pure (lift ρ)>>> observe (λ s. V[[l]] ( f s))>>> pure (λ s. restrict ρ s,() s) = pure (lift ρ)>>> pure f >>> observe (λ s. V[[l]] s)>>> pure (λ s. restrict ρ s,() s) = pure (lift ρ)>>>A[[C]]>>> observe (λ s. V[[l]] s)>>> pure (λ s. restrict ρ s,() s) = pure (lift ρ)>>>A[[C;observe l]]>>> pure (λ s. restrict ρ s,() s)"
    } ],
    "references" : [ {
      "title" : "Reconciling two views of cryptography (the computational soundness of formal encryption)",
      "author" : [ "M. Abadi", "P. Rogaway" ],
      "venue" : "J. Cryptology, 15(2):103–127,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Noncomputable conditional distributions",
      "author" : [ "N.L. Ackerman", "C.E. Freer", "D.M. Roy" ],
      "venue" : "LICS, pages 107–116,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Proofs of randomized algorithms in Coq",
      "author" : [ "P. Audebaud", "C. Paulin-Mohring" ],
      "venue" : "Science of Computer Programming, 74(8):568–589,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Formal certification of code-based cryptographic proofs",
      "author" : [ "G. Barthe", "B. Grégoire", "S.Z. Béguelin" ],
      "venue" : "POPL, pages 90–101. ACM,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A type theory for probability density functions",
      "author" : [ "S. Bhat", "A. Agarwal", "R.W. Vuduc", "A.G. Gray" ],
      "venue" : "J. Field and M. Hicks, editors, POPL, pages 545–556. ACM,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Probability and Measure",
      "author" : [ "P. Billingsley" ],
      "venue" : "Wiley, 3rd edition,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Composable Probabilistic Inference with Blaise",
      "author" : [ "K.A. Bonawitz" ],
      "venue" : "PhD thesis, MIT,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Measure transformer semantics for Bayesian machine learning",
      "author" : [ "J. Borgström", "A.D. Gordon", "M. Greenberg", "J. Margetson", "J. Van Gael" ],
      "venue" : "European Symposium on Programming (ESOP’11), volume 6602 of LNCS, pages 77–96. Springer,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Probabilistic databases: diamonds in the dirt",
      "author" : [ "N.N. Dalvi", "C. Ré", "D. Suciu" ],
      "venue" : "Commun. ACM, 52(7):86–94,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Markov logic",
      "author" : [ "P. Domingos", "S. Kok", "D. Lowd", "H. Poon", "M. Richardson", "P. Singla" ],
      "venue" : "L. De Raedt, P. Frasconi, K. Kersting, and S. Muggleton, editors, Probabilistic inductive logic programming, pages 92–117. Springer-Verlag, Berlin, Heidelberg,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Functional pearls: Probabilistic functional programming in Haskell",
      "author" : [ "M. Erwig", "S. Kollmansberger" ],
      "venue" : "J. Funct. Program., 16(1):21–34,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "On the definition of probability densities and sufficiency of the likelihood map",
      "author" : [ "D.A.S. Fraser", "P. McDunnough", "A. Naderi", "A. Plante" ],
      "venue" : "J. Probability and Mathematical Statistics, 15:301–310,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "A language and program for complex Bayesian modelling",
      "author" : [ "W.R. Gilks", "A. Thomas", "D.J. Spiegelhalter" ],
      "venue" : "The Statistician, 43:169–178,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Church: a language for generative models",
      "author" : [ "N. Goodman", "V.K. Mansinghka", "D.M. Roy", "K. Bonawitz", "J.B. Tenenbaum" ],
      "venue" : "Uncertainty in Artificial Intelligence (UAI’08), pages 220–229. AUAI Press,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "A modellearner pattern for Bayesian reasoning",
      "author" : [ "A.D. Gordon", "M. Aizatulin", "J. Borgström", "G. Claret", "T. Graepel", "A. Nori", "S. Rajamani", "C. Russo" ],
      "venue" : "POPL, pages 403–416,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Web-scale Bayesian click-through rate prediction for sponsored search advertising in Microsoft’s Bing search engine",
      "author" : [ "T. Graepel", "J.Q. Candela", "T. Borchert", "R. Herbrich" ],
      "venue" : "International Conference on Machine Learning, pages 13–20,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Stochastic processes as concurrent constraint programs",
      "author" : [ "V. Gupta", "R. Jagadeesan", "P. Panangaden" ],
      "venue" : "POPL, pages 189–202,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "TrueSkilltm: A Bayesian skill rating system",
      "author" : [ "R. Herbrich", "T. Minka", "T. Graepel" ],
      "venue" : "Advances in Neural Information Processing Systems (NIPS’06), pages 569–576,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Formal verification of probabilistic algorithms",
      "author" : [ "J. Hurd" ],
      "venue" : "PhD thesis, University of Cambridge, 2001. Available as University of Cambridge Computer Laboratory Technical Report UCAM–CL–TR–566, May",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Probability Theory: The Logic of Science, chapter 15.7 The Borel-Kolmogorov paradox, pages",
      "author" : [ "E.T. Jaynes" ],
      "venue" : "CUP,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2003
    }, {
      "title" : "A probabilistic powerdomain of evaluations",
      "author" : [ "C. Jones", "G.D. Plotkin" ],
      "venue" : "Logic in Computer Science (LICS’89), pages 186–195. IEEE Computer Society,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "Embedded probabilistic programming",
      "author" : [ "O. Kiselyov", "C. Shan" ],
      "venue" : "Domain-Specific Languages, pages 360–384,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Monolingual probabilistic programming using generalized coroutines",
      "author" : [ "O. Kiselyov", "C. Shan" ],
      "venue" : "Uncertainty in Artificial Intelligence (UAI’09),",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Probabilistic Graphical Models",
      "author" : [ "D. Koller", "N. Friedman" ],
      "venue" : "The MIT Press,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Effective Bayesian inference for stochastic programs",
      "author" : [ "D. Koller", "D.A. McAllester", "A. Pfeffer" ],
      "venue" : "AAAI/IAAI, pages 740–747,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Semantics of probabilistic programs",
      "author" : [ "D. Kozen" ],
      "venue" : "Journal of Computer and System Sciences, 22(3):328–350,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 1981
    }, {
      "title" : "Factor graphs and the sum-product algorithm",
      "author" : [ "F.R. Kschischang", "B.J. Frey", "H.-A. Loeliger" ],
      "venue" : "IEEE Transactions on Information Theory, 47(2):498–519,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Quantitative analysis with the probabilistic model checker PRISM",
      "author" : [ "M.Z. Kwiatkowska", "G. Norman", "D. Parker" ],
      "venue" : "Quantitative Aspects of Programming Languages (QAPL 2005), volume 153(2) of ENTCS, pages 5–31,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Quantifying information flow",
      "author" : [ "G. Lowe" ],
      "venue" : "CSFW, pages 18–31. IEEE Computer Society,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Information Theory, Inference, and Learning Algorithms",
      "author" : [ "D.J.C. MacKay" ],
      "venue" : "CUP,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Factorie: Probabilistic programming via imperatively defined factor graphs",
      "author" : [ "A. McCallum", "K. Schultz", "S. Singh" ],
      "venue" : "Advances in Neural Information Processing Systems (NIPS’09), pages 1249–1257,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Abstraction, refinement and proof for probabilistic systems",
      "author" : [ "A. McIver", "C. Morgan" ],
      "venue" : "Monographs in computer science. Springer,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Privacy integrated queries: an extensible platform for privacy-preserving data analysis",
      "author" : [ "F. McSherry" ],
      "venue" : "SIGMOD Conference, pages 19–30. ACM,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "On the formalization of the Lebesgue integration theory in HOL",
      "author" : [ "T. Mhamdi", "O. Hasan", "S. Tahar" ],
      "venue" : "Interactive Theorem Proving (ITP 2010),",
      "citeRegEx" : "35",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Blog: Probabilistic models with unknown objects",
      "author" : [ "B. Milch", "B. Marthi", "S.J. Russell", "D. Sontag", "D.L. Ong", "A. Kolobov" ],
      "venue" : "L. P. Kaelbling and A. Saffiotti, editors, IJCAI, pages 1352–1359. Professional Book Center,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Software available from http://research.microsoft.com/infernet",
      "author" : [ "T. Minka", "J. Winn", "J. Guiver", "A. Kannan" ],
      "venue" : "Infer.NET 2.3,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2009
    }, {
      "title" : "Expectation Propagation for approximate Bayesian inference",
      "author" : [ "T.P. Minka" ],
      "venue" : "Uncertainty in Artificial Intelligence (UAI’01), pages 362–369. Morgan Kaufmann,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Bayesian Modeling Using WinBUGS",
      "author" : [ "I. Ntzoufras" ],
      "venue" : "Wiley,",
      "citeRegEx" : "39",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Labelled Markov processes",
      "author" : [ "P. Panangaden" ],
      "venue" : "Imperial College Press,",
      "citeRegEx" : "40",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A probabilistic language based upon sampling functions",
      "author" : [ "S. Park", "F. Pfenning", "S. Thrun" ],
      "venue" : "POPL, pages 171– 182. ACM,",
      "citeRegEx" : "41",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "IBAL: A probabilistic rational programming language",
      "author" : [ "A. Pfeffer" ],
      "venue" : "B. Nebel, editor, International Joint Conference on Artificial Intelligence (IJCAI’01), pages 733–740. Morgan Kaufmann,",
      "citeRegEx" : "42",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "The design and implementation of IBAL: A general-purpose probabilistic language",
      "author" : [ "A. Pfeffer" ],
      "venue" : "L. Getoor and B. Taskar, editors, Introduction to Statistical Relational Learning. MIT Press,",
      "citeRegEx" : "43",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Practical probabilistic programming",
      "author" : [ "A. Pfeffer" ],
      "venue" : "P. Frasconi and F. A. Lisi, editors, Inductive Logic Programming (ILP 2010), volume 6489 of Lecture Notes in Computer Science, pages 2–3. Springer,",
      "citeRegEx" : "44",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Report on the probabilistic language scheme",
      "author" : [ "A. Radul" ],
      "venue" : "Proceedings of the 2007 symposium on Dynamic languages (DLS’07), pages 2–10. ACM,",
      "citeRegEx" : "45",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Stochastic lambda calculus and monads of probability distributions",
      "author" : [ "N. Ramsey", "A. Pfeffer" ],
      "venue" : "POPL, pages 154–165,",
      "citeRegEx" : "46",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Distance makes the types grow stronger: A calculus for differential privacy",
      "author" : [ "J. Reed", "B.C. Pierce" ],
      "venue" : "ICFP, pages 157–168,",
      "citeRegEx" : "47",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A First Look at Rigorous Probability Theory",
      "author" : [ "J.S. Rosenthal" ],
      "venue" : "World Scientific, 2nd edition,",
      "citeRegEx" : "48",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Probabilistic LCF",
      "author" : [ "N. Saheb-Djahromi" ],
      "venue" : "Mathematical Foundations of Computer Science (MFCS), volume 64 of LNCS, pages 442–451. Springer,",
      "citeRegEx" : "49",
      "shortCiteRegEx" : null,
      "year" : 1978
    }, {
      "title" : "AutoBayes program synthesis system users manual",
      "author" : [ "J. Schumann", "T. Pressburger", "E. Denney", "W. Buntine", "B. Fischer" ],
      "venue" : "Technical Report NASA/TM–2008–215366, NASA Ames Research Center,",
      "citeRegEx" : "50",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Expert F",
      "author" : [ "D. Syme", "A. Granicz", "A. Cisternino" ],
      "venue" : "Apress,",
      "citeRegEx" : "51",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Probabilistic programming with Infer.NET",
      "author" : [ "J. Winn", "T. Minka" ],
      "venue" : "Machine Learning Summer School lecture notes, available at http://research.microsoft.com/~minka/papers/mlss2009/,",
      "citeRegEx" : "52",
      "shortCiteRegEx" : "52",
      "year" : 2009
    }, {
      "title" : "Variational message passing",
      "author" : [ "J.M. Winn", "C.M. Bishop" ],
      "venue" : "Journal of Machine Learning Research, 6:661–694,",
      "citeRegEx" : "53",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "An intuitive explanation",
      "author" : [ "E.S. Yudkowsky" ],
      "venue" : "Bayesian reasoning,",
      "citeRegEx" : "54",
      "shortCiteRegEx" : "54",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "The theme of this paper is the idea of expressing Bayesian models as probabilistic programs, which was pioneered by BUGS [14] and is recently gaining in popularity,",
      "startOffset" : 121,
      "endOffset" : 125
    }, {
      "referenceID" : 48,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 9,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 6,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 104,
      "endOffset" : 107
    }, {
      "referenceID" : 34,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 13,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 50,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 30,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 42,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 167,
      "endOffset" : 171
    }, {
      "referenceID" : 22,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 180,
      "endOffset" : 184
    }, {
      "referenceID" : 40,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 201,
      "endOffset" : 205
    }, {
      "referenceID" : 39,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 210,
      "endOffset" : 214
    }, {
      "referenceID" : 16,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 233,
      "endOffset" : 237
    }, {
      "referenceID" : 10,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 243,
      "endOffset" : 247
    }, {
      "referenceID" : 43,
      "context" : "witness the following list of probabilistic programming languages: AutoBayes [50], Alchemy [11], Blaise [7], BLOG [36], Church [15], Csoft [52], FACTORIE [32], Figaro [44], HANSEI [24], HBC [10], IBAL [42], λ◦ [41], Probabilistic cc [18], PFP [12], and Probabilistic Scheme [45].",
      "startOffset" : 274,
      "endOffset" : 278
    }, {
      "referenceID" : 50,
      "context" : "In particular, we draw inspiration from Csoft [52], an imperative language where programs denote factor graphs [28], data structures that support efficient inference algorithms [25].",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 26,
      "context" : "In particular, we draw inspiration from Csoft [52], an imperative language where programs denote factor graphs [28], data structures that support efficient inference algorithms [25].",
      "startOffset" : 111,
      "endOffset" : 115
    }, {
      "referenceID" : 23,
      "context" : "In particular, we draw inspiration from Csoft [52], an imperative language where programs denote factor graphs [28], data structures that support efficient inference algorithms [25].",
      "startOffset" : 177,
      "endOffset" : 181
    }, {
      "referenceID" : 35,
      "context" : "NET [37], a software library for Bayesian reasoning.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 17,
      "context" : "Consider a simplified form of TrueSkill [19], a large-scale online system for ranking computer gamers.",
      "startOffset" : 40,
      "endOffset" : 44
    }, {
      "referenceID" : 29,
      "context" : "A classic computational method to compute an approximate posterior distribution of each of the skills is Monte Carlo sampling [31].",
      "startOffset" : 126,
      "endOffset" : 130
    }, {
      "referenceID" : 41,
      "context" : "recent versions of IBAL [43], are based on nondeterministic inference using some form of Monte Carlo sampling.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 26,
      "context" : "Inference algorithms based on factor graphs [28, 25] are an efficient alternative to Monte Carlo sampling.",
      "startOffset" : 44,
      "endOffset" : 52
    }, {
      "referenceID" : 23,
      "context" : "Inference algorithms based on factor graphs [28, 25] are an efficient alternative to Monte Carlo sampling.",
      "startOffset" : 44,
      "endOffset" : 52
    }, {
      "referenceID" : 49,
      "context" : "We designed Fun to be a subset of the F# dialect of ML [51], for implementation convenience: F# reflection allows easy access to the abstract syntax of a program.",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 7,
      "context" : "The technical report version of our paper [8] includes additional details, including the code of an F# implementation of measure transformers in the discrete case.",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 39,
      "context" : "[41]); the formal semantics for the general case comes later.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 52,
      "context" : "If a subject is positive, what are the odds they have the disease? [54]",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 19,
      "context" : "Borel’s paradox [21].",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 5,
      "context" : "To give a formal semantics to such observations, as well as to mixtures of continuous and discrete distributions, we turn to measure theory, following standard sources [6, 48].",
      "startOffset" : 168,
      "endOffset" : 175
    }, {
      "referenceID" : 46,
      "context" : "To give a formal semantics to such observations, as well as to mixtures of continuous and discrete distributions, we turn to measure theory, following standard sources [6, 48].",
      "startOffset" : 168,
      "endOffset" : 175
    }, {
      "referenceID" : 33,
      "context" : "To machine-check our theory, one might build on a recent formalization of measure theory and Lebesgue integration in higher-order logic [35].",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 11,
      "context" : "Given a finite measure μ on T[[t]] and c ∈ Vu, we let Fc : t → R be defined by the limit below (following [13]) Fc(d), lim i→∞ μ(Rd ∩ p(Bi))/λu(Bi) (3.",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 11,
      "context" : "1) exists almost everywhere [13], that is, there is a set C with μ(C) = 0 such that c ∈ C if Fc(d) is undefined.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 3,
      "context" : "This choice is a generalization of the (discrete) semantics of pWHILE [4].",
      "startOffset" : 70,
      "endOffset" : 73
    }, {
      "referenceID" : 44,
      "context" : "This contrasts with Ramsey and Pfeffer [46], where the semantics of an open program takes a variable valuation and returns a (monadic computation yielding a) distribution of return values.",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 7,
      "context" : "Our direct implementation of the measure transformer semantics, described in the technical report version of our paper [8], explicitly constructs the valuation.",
      "startOffset" : 119,
      "endOffset" : 122
    }, {
      "referenceID" : 35,
      "context" : "As another example, let us consider a simple Bayesian evaluation of a medical trial [37].",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 7,
      "context" : "The following example, due to Chung-Chieh Shan, highlighted regularity problems with our original definition of observation [8].",
      "startOffset" : 124,
      "endOffset" : 127
    }, {
      "referenceID" : 26,
      "context" : "NET by constructing a suitable factor graph [28], whose size will be linear in the size of the program.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 30,
      "context" : "The implementation advantage of translating F# to Csoft, over simply generating factor graphs directly [32], is that the translation preserves the structure of the input model (including array processing in our full language), which can be exploited by the various inference algorithms supported by Infer.",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 35,
      "context" : "NET [37].",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 15,
      "context" : "As a third example, consider the adPredictor component of the Bing search engine, which estimates the click-through rates for particular users on advertisements [17].",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 35,
      "context" : "NET [37].",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 47,
      "context" : "One of the first semantics is for Probabilistic LCF [49], which augments the core functional language LCF with weighted binary choice, for discrete distributions.",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 25,
      "context" : ") Kozen [27] develops a probabilistic semantics for while-programs augmented with random assignment.",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 20,
      "context" : "Jones and Plotkin [22] investigate the probability monad, and apply it to languages with discrete probabilistic choice.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 44,
      "context" : "Ramsey and Pfeffer [46] give a stochastic λ -calculus with a measure-theoretic semantics in the probability monad, and provide an embedding within Haskell; they do not consider observations.",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 16,
      "context" : "The probabilistic concurrent constraint programming language Probabilistic cc of Gupta, Jagadeesan, and Panangaden [18] is also intended for describing probability distributions using independent sampling and constraints.",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 31,
      "context" : "McIver and Morgan [33] develop a theory of abstraction and refinement for probabilistic while programs, based on weakest preconditions.",
      "startOffset" : 18,
      "endOffset" : 22
    }, {
      "referenceID" : 1,
      "context" : "Ackerman, Freer, and Roy [2] show the uncomputability of conditional distributions in general, establishing limitations on constructive foundations of probabilistic programming.",
      "startOffset" : 25,
      "endOffset" : 28
    }, {
      "referenceID" : 18,
      "context" : "Recent work on semantics of probabilistic programs within interactive theorem provers includes the mechanization of measure theory [20] and Lebesgue integration [35] in HOL, and a framework for proofs of randomized algorithms in Coq [3] which also allows for discrete observations.",
      "startOffset" : 131,
      "endOffset" : 135
    }, {
      "referenceID" : 33,
      "context" : "Recent work on semantics of probabilistic programs within interactive theorem provers includes the mechanization of measure theory [20] and Lebesgue integration [35] in HOL, and a framework for proofs of randomized algorithms in Coq [3] which also allows for discrete observations.",
      "startOffset" : 161,
      "endOffset" : 165
    }, {
      "referenceID" : 2,
      "context" : "Recent work on semantics of probabilistic programs within interactive theorem provers includes the mechanization of measure theory [20] and Lebesgue integration [35] in HOL, and a framework for proofs of randomized algorithms in Coq [3] which also allows for discrete observations.",
      "startOffset" : 233,
      "endOffset" : 236
    }, {
      "referenceID" : 24,
      "context" : "[26] proposed representing a probability distribution using first-order functional programs with discrete random choice, and proposed an inference algorithm for Bayesian networks and stochastic context-free grammars.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 41,
      "context" : "Their work was subsequently developed by Pfeffer into the language IBAL [43], which has observations and uses a factor graph semantics, but only works with discrete datatypes.",
      "startOffset" : 72,
      "endOffset" : 76
    }, {
      "referenceID" : 39,
      "context" : "[41] propose λ◦, the first probabilistic language with formal semantics applied to actual machine learning problems involving continuous distributions.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 22,
      "context" : "HANSEI [24, 23] is an embedding of a probabilistic language as a programming library in OCaml, based on explicit manipulation of discrete probability distributions as lists, and sampling algorithms based on coroutines.",
      "startOffset" : 7,
      "endOffset" : 15
    }, {
      "referenceID" : 21,
      "context" : "HANSEI [24, 23] is an embedding of a probabilistic language as a programming library in OCaml, based on explicit manipulation of discrete probability distributions as lists, and sampling algorithms based on coroutines.",
      "startOffset" : 7,
      "endOffset" : 15
    }, {
      "referenceID" : 35,
      "context" : "NET [37] is a software library that implements the approximate deterministic algorithms expectation propagation [38] and variational message passing [53], as well as Gibbs sampling, a nondeterministic algorithm.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 36,
      "context" : "NET [37] is a software library that implements the approximate deterministic algorithms expectation propagation [38] and variational message passing [53], as well as Gibbs sampling, a nondeterministic algorithm.",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 51,
      "context" : "NET [37] is a software library that implements the approximate deterministic algorithms expectation propagation [38] and variational message passing [53], as well as Gibbs sampling, a nondeterministic algorithm.",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 50,
      "context" : "NET models are written in a probabilistic subset of C#, known as Csoft [52].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 43,
      "context" : "Probabilistic Scheme [45] is a probabilistic form of the untyped functional language Scheme, limited to discrete distributions, and with a construct for reifying the distribution induced by a thunk as a value.",
      "startOffset" : 21,
      "endOffset" : 25
    }, {
      "referenceID" : 13,
      "context" : "Church [15] is another probabilistic form of Scheme, equipped with conditional sampling and a mechanism of stochastic memoization.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 37,
      "context" : "WinBUGS [39] is a popular implementation of the BUGS language [14] for explicitly describing distributions suitable for MCMC analysis.",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 12,
      "context" : "WinBUGS [39] is a popular implementation of the BUGS language [14] for explicitly describing distributions suitable for MCMC analysis.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 30,
      "context" : "FACTORIE [32] is a Scala library for explicitly constructing factor graphs.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 6,
      "context" : "Blaise [7] is a software library for building MCMC samplers in Java, that supports compositional construction of sophisticated probabilistic models, and decouples the choice of inference algorithm from the specification of the distribution.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 14,
      "context" : "A recent paper [16] based on Fun describes a model-learner pattern which captures common probabilistic programming patterns in machine learning, including various sorts of mixture models.",
      "startOffset" : 15,
      "endOffset" : 19
    }, {
      "referenceID" : 8,
      "context" : "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 27,
      "context" : "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 32,
      "context" : "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].",
      "startOffset" : 173,
      "endOffset" : 181
    }, {
      "referenceID" : 45,
      "context" : "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].",
      "startOffset" : 173,
      "endOffset" : 181
    }, {
      "referenceID" : 28,
      "context" : "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].",
      "startOffset" : 200,
      "endOffset" : 204
    }, {
      "referenceID" : 0,
      "context" : "Probabilistic languages with formal semantics find application in many areas apart from machine learning, including databases [9], model checking [29], differential privacy [34, 47], information flow [30], and cryptography [1].",
      "startOffset" : 223,
      "endOffset" : 226
    }, {
      "referenceID" : 38,
      "context" : "A recent monograph on semantics for labelled Markov processes [40] focuses on bisimulation-based equational reasoning.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 3,
      "context" : "The syntax and semantics of Imp is modelled on the probabilistic language pWhile [4] without observations.",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 10,
      "context" : "Erwig and Kollmansberger [12] describe a library for probabilistic functional programming in Haskell.",
      "startOffset" : 25,
      "endOffset" : 29
    } ],
    "year" : 2013,
    "abstractText" : "The Bayesian approach to machine learning amounts to computing posterior distributions of random variables from a probabilistic model of how the variables are related (that is, a prior distribution) and a set of observations of variables. There is a trend in machine learning towards expressing Bayesian models as probabilistic programs. As a foundation for this kind of programming, we propose a core functional calculus with primitives for sampling prior distributions and observing variables. We define measure-transformer combinators inspired by theorems in measure theory, and use these to give a rigorous semantics to our core calculus. The original features of our semantics include its support for discrete, continuous, and hybrid measures, and, in particular, for observations of zero-probability events. We compile our core language to a small imperative language that is processed by an existing inference engine for factor graphs, which are data structures that enable many efficient inference algorithms. This allows efficient approximate inference of posterior marginal distributions, treating thousands of observations per second for large instances of realistic models.",
    "creator" : "LaTeX with hyperref package"
  }
}