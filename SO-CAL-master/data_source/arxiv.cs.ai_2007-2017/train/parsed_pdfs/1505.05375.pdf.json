{
  "name" : "1505.05375.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Towards Large-scale Inconsistency Measurement",
    "authors" : [ "Matthias Thimm" ],
    "emails" : [ "thimm@uni-koblenz.de" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 5.\n05 37\n5v 1\n[ cs\n.A I]\n2 0\nM ay\n2 01\n5"
    }, {
      "heading" : "1 Introduction",
      "text" : "Inconsistency measurement [2] is a subfield of Knowledge Representation and Reasoning (KR) that is concerned with the quantitative assessment of the severity of inconsistencies in knowledge bases. Consider the following two knowledge bases K1 and K2 formalized in propositional logic:\nK1 = {a, b ∨ c,¬a ∧ ¬b, d} K2 = {a,¬a, b,¬b}\nBoth knowledge bases are classically inconsistent as for K1 we have {a,¬a ∧ ¬b} |=⊥ and for K2 we have, e. g., {a,¬a} |=⊥. These inconsistencies render the knowledge bases useless for reasoning if one wants to use classical reasoning techniques. In order to make the knowledge bases useful again, one can either use nonmonotonic/paraconsistent reasoning techniques [11, 12] or one revises the knowledge bases appropriately to make them consistent [4]. Looking again at the knowledge bases K1 and K2 one can observe that the severity of their inconsistency is different. In K1, only two out of four formulas (a and ¬a∧¬b) are participating in making K1 inconsistent while for K2 all formulas contribute to its inconsistency. Furthermore, for K1 only two propositions (a and b) participate in a conflict and using, e. g., paraconsistent reasoning one could still infer meaningful statements about c and d. For K2 no such statement can be made. This leads to the assessment that K2 should be regarded more inconsistent than K1. Inconsistency measures can be used to quantitatively assess the inconsistency of knowledge bases and to provide a guide for how to repair them, cf. [3]. Moreover, they can be used as an analytical tool to assess the quality of knowledge representation. For example, one simple inconsistency measure is to take the number of minimal inconsistent subsets (MIs) as an indicator for the inconsistency: the more MIs a knowledge base contains, the\n1 This paper has also been published in the Proceedings of the 37th German Conference on Artificial Intelligence (KI 2014) 2 Institute for Web Science and Technologies, University of Koblenz-Landau, Germany, thimm@uni-koblenz.de\nmore inconsistent it is. For K1 we have then 1 as its inconsistency value and for K2 we have 2.\nIn this paper, we consider the computational problems of inconsistency measurement, particularly with respect to scalable inconsistency measurement on large knowledge bases, as they appear in, e. g., Semantic Web applications. To this end we present a novel inconsistency measure Ihs that approximates the η-inconsistency measure from [8] and is particularly apt to be applied to large knowledge bases. This measure is based on the notion of a hitting set which (in our context) is a minimal set of classical interpretations such that every formula of a knowledge base is satisfied by at least one element of the set. In order to investigate the problem of measuring inconsistency in large knowledge bases we also present a stream-based processing framework for inconsistency measurement. More precisely, the contributions of this paper are as follows:\n1. We present a novel inconsistency measure Ihs based on hitting sets and show how this measure relates to other measures and, in particular, that it is a simplification of the η-inconsistency measure [8] (Section 3). 2. We formalize a theory of inconsistency measurement in streams and provide approximations of several inconsistency measures for the streaming case (Section 4). 3. We conduct an extensive empirical study on the behavior of those inconsistency measures in terms of runtime, accuracy, and scalability. In particular, we show that the stream variants of Ihs and of the contension measure Ic are effective and accurate for measuring inconsistency in the streaming setting and, therefore, in large knowledge bases (Section 5).\nWe give necessary preliminaries for propositional logic and inconsistency measurement in Section 2 and conclude the paper with a discussion in Section 6. Proofs of technical results can be found in Appendix A."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "Let At be a propositional signature, i. e., a (finite) set of propositions, and let L(At) be the corresponding propositional language, constructed using the usual connectives ∧ (and), ∨ (or), and ¬ (negation). We use the symbol ⊥ to denote contradiction. Then a knowledge base K is a finite set of formulas K ⊆ L(At). Let K(At) be the set of all knowledge bases. We write K instead of K(At) when there is no ambiguity regarding the signature. Semantics to L(At) is given by interpretations ω : At → {true, false}. Let Int(At) denote the set of all interpretations for At. An interpretation ω satisfies (or is a model of) an atom a ∈ At, denoted by ω |= a (or ω ∈ Mod(a)), if and only if ω(a) = true. Both |= and Mod(·) are extended to arbitrary formulas, sets, and knowledge bases as usual.\nInconsistency measures are functions I : K → [0,∞) that aim at assessing the severity of the inconsistency in a knowledge base K,\ncf. [3]. The basic idea is that the larger the inconsistency in K the larger the value I(K). However, inconsistency is a concept that is not easily quantified and there have been a couple of proposals for inconsistency measures so far, see e. g. [8, 10, 1, 2, 5, 13]. There are two main paradigms for assessing inconsistency [5], the first being based on the (number of) formulas needed to produce inconsistencies and the second being based on the proportion of the language that is affected by the inconsistency. Below we recall some popular measures from both categories but we first introduce some necessary notations. Let K ∈ K be some knowledge base.\nDefinition 1. A set M ⊆ K is called minimal inconsistent subset (MI) of K if M |=⊥ and there is no M ′ ⊂ M with M ′ |=⊥. Let MI(K) be the set of all MIs of K.\nDefinition 2. A formula α ∈ K is called free formula of K if there is no M ∈ MI(K) with α ∈ M . Let Free(K) denote the set of all free formulas of K.\nWe adopt the following definition of a (basic) inconsistency measure from [3].\nDefinition 3. A basic inconsistency measure is a function I : K → [0,∞) that satisfies the following three conditions:\n1. I(K) = 0 if and only if K is consistent, 2. if K ⊆ K′ then I(K) ≤ I(K′), and 3. for all α ∈ Free(K) we have I(K) = I(K \\ {α}).\nThe first property (also called consistency) of a basic inconsistency measure ensures that all consistent knowledge bases receive a minimal inconsistency value and every inconsistent knowledge base receive a positive inconsistency value. The second property (also called monotony) states that the value of inconsistency can only increase when adding new information. The third property (also called free formula independence) states that removing harmless formulas from a knowledge base—i. e., formulas that do not contribute to the inconsistency—does not change the value of inconsistency. For the remainder of this paper we consider the following selection of inconsistency measures: the MI measure IMI, the MIc measure IMIc , the contension measure Ic, and the η measure Iη , which will be defined below, cf. [3, 8]. In order to define the contension measure Ic we need to consider three-valued interpretations for propositional logic [12]. A three-valued interpretation υ on At is a function υ : At → {T, F,B} where the values T and F correspond to the classical true and false, respectively. The additional truth value B stands for both and is meant to represent a conflicting truth value for a proposition. The function υ is extended to arbitrary formulas as shown in Table 1. Then, an interpretation υ satisfies a formula α, denoted by υ |=3 α if either υ(α) = T or υ(α) = B.\nFor defining the η-inconsistency measure [8] we need to consider probability functions P of the form P : Int(At) → [0, 1] with ∑\nω∈Int(At) P (ω) = 1. Let P(At) be the set of all those probability functions and for a given probability function P ∈ P(At) define the probability of an arbitrary formula α via P (α) = ∑\nω|=α P (ω).\nDefinition 4. Let IMI, IMIc , Ic, and Iη be defined via\nIMI(K) = |MI(K)|,\nIMIc(K) = ∑\nM∈MI(K)\n1\n|M | ,\nIc(K) = min{|υ −1(B)| | υ |=3 K},\nIη(K) = 1−max{ξ | ∃P ∈ P(At) : ∀α ∈ K : P (α) ≥ ξ}\nThe measure IMI takes the number of minimal inconsistent subsets of a knowledge base as an indicator for the amount of inconsistency: the more minimal inconsistent subsets the more severe the inconsistency. The measure IMIc refines this idea by also taking the size of the minimal inconsistent subsets into account. Here the idea is that larger minimal inconsistent subsets indicate are less severe than smaller minimal inconsistent subsets (the less formulas are needed to produce an inconsistency the more “obvious” the inconsistency). The measure Ic considers the set of three-valued models of a knowledge base (which is always non-empty) and uses the minimal number of propositions with conflicting truth value as an indicator for inconsistency. Finally, the measure Iη (which always assigns an inconsistency value between 0 and 1) looks for the maximal probability one can assign to every formula of a knowledge base. All these measures are basic inconsistency measures as defined in Definition 3.\nExample 1. For the knowledge bases K1 = {a, b ∨ c,¬a ∧ ¬b, d} and K2 = {a,¬a, b, ¬b} from the introduction we obtain IMI(K1) = 1, IMIc(K1) = 0.5, Ic(K1) = 2, Iη(K1) = 0.5, IMI(K2) = 2, IMIc(K2) = 1, Ic(K2) = 2, Iη(K2) = 0.5.\nFor a more detailed introduction to inconsistency measures see e. g. [2, 3, 8] and for some recent developments see e. g. [1, 7].\nAs for computational complexity, the problem of computing an inconsistency value wrt. any of the above inconsistency measures is at least FNP-hard3 as it contains a satisfiability problem as a sub problem."
    }, {
      "heading" : "3 An Inconsistency Measure based on Hitting Sets",
      "text" : "The basic idea of our novel inconsistency measure Ihs is inspired by the measure Iη which seeks a probability function that maximizes the probability of all formulas of a knowledge base. Basically, the measure Iη looks for a minimal number of models of parts of the knowledge base and maximizes their probability in order to maximize the probability of the formulas. By just considering this basic idea we arrive at the notion of a hitting set for inconsistent knowledge bases.\nDefinition 5. A subset H ⊂ Int(At) is called a hitting set of K if for every α ∈ K there is ω ∈ H with ω |= α. H is called a cardminimal hitting set if it is minimal wrt. cardinality. Let hK be the cardinality of any card-minimal hitting set (define hK = ∞ if there does not exist a hitting set of K).\nDefinition 6. The function Ihs : K → [0,∞] is defined via Ihs(K) = hK − 1 for every K ∈ K.\nNote, that if a knowledge base K contains a contradictory formula (e. g. a ∧ ¬a) we have Ihs(K) = ∞. In the following, we assume that K contains no such contradictory formulas.\nExample 2. Consider the knowledge base K3 defined via\nK3 = {a ∨ d, a ∧ b ∧ c, b,¬b ∨ ¬a, a ∧ b ∧ ¬c, a ∧ ¬b ∧ c}\nThen {ω1, ω2, ω3} ⊂ Int(At) with ω1(a) = ω1(b) = ω1(c) = true, ω2(a) = ω2(c) = true, ω1(b) = false, and ω3(a) = ω3(b) = true, ω3(c) = false is a card-minimal hitting set for K3 and therefore Ihs(K3) = 2. Note that for the knowledge bases K1 and K2 from Example 1 we have Ihs(K1) = Ihs(K2) = 1.\n3 FNP is the generalization of the class NP to functional problems.\nProposition 1. The function Ihs is a (basic) inconsistency measure.\nThe result below shows that Ihs also behaves well with some more properties mentioned in the literature [5, 13]. For that, we denote with At(F ) for a formula or a set of formulas F the set of propositions appearing in F . Furthermore, two knowledge bases K1, K2 are semiextensionally equivalent (K1 ≡σ K2) if there is a bijection σ : K1 → K2 such that for all α ∈ K1 we have α ≡ σ(α).\nProposition 2. The measure Ihs satisfies the following properties:\n• If α ∈ K is such that At(α) ∩ At(K \\ {α}) = ∅ then Ihs(K) = Ihs(K \\ {α}) (safe formula independence). • If K ≡σ K′ then Ihs(K) = Ihs(K′) (irrelevance of syntax). • If α |= β and α 6|=⊥ then Ihs(K ∪ {α}) ≥ Ihs(K ∪ {β})\n(dominance).\nThe measure Ihs can also be nicely characterized by a consistent partitioning of a knowledge base.\nDefinition 7. A set Φ = {Φ1, . . . ,Φn} with Φ1 ∪ . . . ∪ Φn = K and Φi ∩ Φj = ∅ for i, j = 1, . . . , n, i 6= j, is called a partitioning of K. A partitioning Φ = {Φ1, . . . ,Φn} is consistent if Φi 6|=⊥ for i = 1, . . . , n. A consistent partitioning Φ is called card-minimal if it is minimal wrt. cardinality among all consistent partitionings of K.\nProposition 3. A consistent partitioning Φ is a card-minimal partitioning of K if and only if Ihs(K) = |Φ| − 1.\nAs Ihs is inspired by Iη we go on by comparing these two measures.\nProposition 4. Let K be a knowledge base. If ∞ > Ihs(K) > 0 then\n1− 1\nIhs(K) < Iη(K) ≤ 1−\n1\nIhs(K) + 1\nNote that for Ihs(K) = 0 we always have Iη(K) = 0 as well, as both are basic inconsistency measures.\nCorollary 1. If Iη(K1) ≤ Iη(K2) then Ihs(K1) ≤ Ihs(K2).\nHowever, the measures Iη and Ihs are not equivalent as the following example shows.\nExample 3. Consider the knowledge bases K1 = {a,¬a} and K2 = {a, b,¬a ∨ ¬b}. Then we have Ihs(K1) = Ihs(K2) = 1 but Iη(K1) = 0.5 > 1/3 = Iη(K2).\nIt follows that the order among knowledge bases induced by Iη is a refinement of the order induced by Ihs. However, Ihs is better suited for approximation in large knowledge bases than Iη , cf. the following section.\nThe idea underlying Ihs is also similar to the contension inconsistency measure Ic. However, these measures are not equivalent as the following example shows.\nExample 4. Consider the knowledge bases K1 and K2 given as\nK1 = {a ∧ b ∧ c,¬a ∧ ¬b ∧ ¬c} K2 = {a ∧ b,¬a ∧ b, a ∧ ¬b}\nThen we have Ihs(K1) = 2 < 3 = Ihs(K2) but Ic(K1) = 3 > 2 = Ic(K2)."
    }, {
      "heading" : "4 Inconsistency Measurement in Streams",
      "text" : "In the following, we discuss the problem of inconsistency measurement in large knowledge bases. We address this issue by using a stream-based approach of accessing the formulas of a large knowledge base. Formulas of a knowledge base then need to be processed one by one by a stream-based inconsistency measure. The goal of this formalization is to obtain stream-based inconsistency measures that approximate given inconsistency measures when the latter would have been applied to the knowledge base as a whole. We first formalize this setting and, afterwards, provide concrete approaches for some inconsistency measures."
    }, {
      "heading" : "4.1 Problem Formalization",
      "text" : "We use a very simple formalization of a stream that is sufficient for our needs.\nDefinition 8. A propositional stream S is a function S : N → L(At). Let S be the set of all propositional streams.\nA propositional stream models a sequence of propositional formulas. On a wider scope, a propositional stream can also be interpreted as a very general abstraction of the output of a linked open data crawler (such as LDSpider [6]) that crawls knowledge formalized as RDF (Resource Description Framework) from the web, enriched, e. g. with OWL semantics. We model large knowledge bases by propositional streams that indefinitely repeat the formulas of the knowledge base. For that, we assume for a knowledge base K = {φ1, . . . , φn} the existence of a canonical enumeration Kc = 〈φ1, . . . , φn〉 of the elements of K. This enumeration can be arbitrary and has no specific meaning other than to enumerate the elements in an unambiguous way.\nDefinition 9. Let K be a knowledge base and Kc = 〈φ1, . . . , φn〉 its canonical enumeration. The K-stream SK is defined as SK(i) = φ(imod n)+1 for all i ∈ N.\nGiven a K-stream SK and an inconsistency measure I we aim at defining a method that processes the elements of SK one by one and approximates I(K).\nDefinition 10. A stream-based inconsistency measure J is a function J : S× N → [0,∞).\nDefinition 11. Let I be an inconsistency measure and J a streambased inconsistency measure. Then J approximates (or is an approximation of ) I if for all K ∈ K we have limi→∞ J (SK, i) = I(K)."
    }, {
      "heading" : "4.2 A Naive Window-based Approach",
      "text" : "The simplest form of implementing a stream-based variant of any algorithm or function is to use a window-based approach, i. e., to consider at any time point a specific excerpt from the stream and apply the original algorithm or function on this excerpt. For any propositional stream S let Si,j (for i ≤ j) be the knowledge base obtained by taking the formulas from S between positions i and j, i. e., Si,j = {S(i), . . . ,S(j)}.\nDefinition 12. Let I be an inconsistency measure, w ∈ N ∪ {∞}, and g some function g : [0,∞) × [0,∞) → [0,∞) with g(x, y) ∈ [min{x, y},max{x, y}]. We define the naive window-based measure Jw,gI : S× N → [0,∞) via\nJ w,gI (S , i) =\n{\n0 if i = 0 g(I(Smax{0,i−w},i),J w,gI (S , i− 1)) otherwise\nfor every S and i ∈ N.\nThe function g in the above definition is supposed to be an aggregation function that combines the new obtained inconsistency value I(Smax{0,i−w},iK ) with the previous value J w,g I (S , i−1). This function can be ,e. g., the maximum function max or a smoothing function gα(x, y) = αx + (1 − α)y for some α ∈ [0, 1] (for every x, y ∈ [0,∞)).\nProposition 5. Let I be an inconsistency measure, w ∈ N ∪ {∞}, and g some function g : [0,∞) × [0,∞) → [0,∞) with g(x, y) ∈ [min{x, y},max{x, y}]. 1. If w is finite then J w,gI is not an approximation of I. 2. If w = ∞ and g(x, y) > min{x, y} if x 6= y then J w,gI is an\napproximation of I. 3. J w,gI (SK, i) ≤ I(K) for every K ∈ K and i ∈ N.\n4.3 Approximation Algorithms for Ihs and Ic The approximation algorithms for Ihs and Ic that are presented in this subsection are using concepts of the programming paradigms of simulated annealing and genetic programming [9]. Both algorithms follow the same idea and we will only formalize the one for Ihs and give some hints on how to adapt it for Ic.\nThe basic idea for the stream-based approximation of Ihs is as follows. At any processing step we maintain a candidate set C ∈ 2Int(At) (initialized with the empty set) that approximates a hitting set of the underlying knowledge base. At the beginning of a processing step we make a random choice (with decreasing probability the more formulas we already encountered) whether to remove some element of C. This action ensures that C does not contain superfluous elements. Afterwards we check whether there is still an interpretation in C that satisfies the currently encountered formula. If this is not the case we add some random model of the formula to C. Finally, we update the previously computed inconsistency value with |C| − 1, taking also some aggregation function g (as for the naive window-based approach) into account. In order to increase the probability of successfully finding a minimal hitting set we do not maintain a single candidate set C but a (multi-)set Cand = {C1, . . . , Cm} for some previously specified parameter m ∈ N and use the average size of these candidate hitting sets.\nDefinition 13. Let m ∈ N, g some function g : [0,∞)× [0,∞) → [0,∞) with g(x, y) ∈ [min{x, y},max{x, y}], and f : N → [0, 1] some monotonically decreasing function with limn→∞ f(n) = 0. We define Jm,g,fhs via\nJm,g,fhs (S , i) =\n{\n0 if i = 0 update\nm,g,f hs (S(i)) otherwise\nfor every S and i ∈ N. The function updatem,g,fhs is depicted in Algorithm 1.\nAt the first call of the algorithm updatem,g,fhs the value of currentV alue (which contains the currently estimated inconsistency value) is initialized to 0 and the (mulit-)set Cand ⊆ 2Int(At)\nAlgorithm 1 updatem,g,fhs (form)\n1: Initialize currentV alue and Cand 2: N = N + 1 3: newV alue = 0 4: for all C ∈ Cand do 5: rand ∈ [0, 1] 6: if rand < f(N) then 7: Remove some random ω from C 8: if ¬∃ω ∈ C : ω |= form then 9: Add random ω ∈ Mod(form) to C\n10: newV alue = newV alue+ (|C| − 1)/|Cand|\n11: currentV alue = g(newV alue, currentV alue) 12: return currentV alue\n(which contains a population of candidate hitting sets) is initialized with m empty sets. The function f can be any monotonically decreasing function with limn→∞ f(n) = 0 (this ensures that at any candidate C reaches some stable result). The parameter m increases the probability that at least one of the candidate hitting sets attains the global optimum of a card-minimal hitting set.\nAs Jm,g,fhs is a random process we cannot show that J m,g,f hs is an approximation of Ihs in the general case. However, we can give the following result.\nProposition 6. For every probability p ∈ [0, 1), g some function g : [0,∞)× [0,∞) → [0,∞) with g(x, y) ∈ [min{x, y},max{x, y}] and g(x, y) > min{x, y} if x 6= y, a monotonically decreasing function f : N → [0, 1] with limn→∞ f(n) = 0, and K ∈ K there is m ∈ N such that with probability greater or equal p it is the case that\nlim i→∞\nJm,g,fhs (SK, i) = Ihs(K)\nThis result states that Jm,g,fhs indeed approximates Ihs if we choose the number of populations large enough. In the next section we will provide some empirical evidence that even for small values of m results are satisfactory.\nBoth Definition 13 and Algorithm 1 can be modified slightly in order to approximate Ic instead of Ihs, yielding a new measure Jm,g,fc . For that, the set of candidates Cand contains three-valued interpretations instead of sets of classical interpretations. In line 7, we do not remove an interpretation from C but flip some arbitrary proposition from B to T or F . Similarly, in line 9 we do not add an interpretation but flip some propositions to B in order to satisfy the new formula. Finally, the inconsistency value is determined by taking the number of B-valued propositions. For more details see the implementations of both Jm,g,fhs and J m,g,f c , which will also be discussed in the next section."
    }, {
      "heading" : "5 Empirical Evaluation",
      "text" : "In this section we describe our empirical experiments on runtime, accuracy, and scalability of some stream-based inconsistency measures. Our Java implementations4 have been added to the Tweety Libraries for Knowledge Representation [14].\n4 IMI, IMIc , Iη , J w,g I :\nhttp://mthimm.de/r?r=tweety-inc-commons Ic, Ihs: http://mthimm.de/r?r=tweety-inc-pl J\nm,g,f hs : http://mthimm.de/r?r=tweety-stream-hs\nJ m,g,f c : http://mthimm.de/r?r=tweety-stream-c Evaluation framework: http://mthimm.de/r?r=tweety-stream-eval"
    }, {
      "heading" : "5.1 Evaluated Approaches",
      "text" : "For our evaluation, we considered the inconsistency measures IMI, IMIc , Iη , Ic, and Ihs. We used the SAT solver lingeling5 for the sub-problems of determining consistency and to compute a model of a formula. For enumerating the set of MIs of a knowledge base (as required by IMI and IMIc ) we used MARCO6. The measure Iη was implemented using the linear optimization solver lp solve7. The measures IMI, IMIc , and Iη were used to define three different versions of the naive window-based measure J w,gI (with w = 500, 1000, 2000 and g = max). For the measures Ic and Ihs we tested each three versions of their streaming variants Jm,g0.75 ,f1c and J m,g0.75 ,f1 hs (with m = 10, 100, 500) with f1 : N → [0, 1] defined via f1(i) = 1/(i + 1) for all i ∈ N and g0.75 is the smoothing function for α = 0.75 as defined in the previous section."
    }, {
      "heading" : "5.2 Experiment Setup",
      "text" : "For measuring the runtime of the different approaches we generated 100 random knowledge bases in CNF (Conjunctive Normal Form) with each 5000 formulas (=disjunctions) and 30 propositions. For each generated knowledge base K we considered its K-stream and processing of the stream was aborted after 40000 iterations. We fed the K-stream to each of the evaluated stream-based inconsistency measures and measured the average runtime per iteration and the total runtime. For each iteration, we set a time-out of 2 minutes and aborted processing of the stream completely if a time-out occurred.\nIn order to measure accuracy, for each of the considered approaches we generated another 100 random knowledge bases with specifically set inconsistency values8, used otherwise the same settings as above, and measured the returned inconsistency values.\nTo evaluate the scalability of our stream-based approach of Ihs we conducted a third experiment9 where we fixed the number of propositions (60) and the specifically set inconsistency value (200) and varied the size of the knowledge bases from 5000 to 50000 (with steps of 5000 formulas). We measured the total runtime up to the point when the inconsistency value was within a tolerance of ±1 of the expected inconsistency value.\nThe experiments were conducted on a server with two Intel Xeon X5550 QuadCore (2.67 GHz) processors with 8 GB RAM running SUSE Linux 2.6.\n5 http://fmv.jku.at/lingeling/ 6 http://sun.iwu.edu/˜mliffito/marco/ 7 http://lpsolve.sourceforge.net 8 The sampling algorithms can be found at http://mthimm.de/r?r=tweety-sampler 9 We did the same experiment with our stream-based approach of Ic but do not report the results due to the similarity to Ihs and space restrictions."
    }, {
      "heading" : "5.3 Results",
      "text" : "Our first observation concerns the inconsistency measure Iη which proved to be not suitable to work on large knowledge bases10. Computing the value Iη(K) for some knowledge base K includes solving a linear optimization problem over a number of variables which is (in the worst-case) exponential in the number of propositions of the signature. In our setting with |At| = 30 the generated optimization problem contained therefore 230 = 1073741824 variables. Hence, even the optimization problem itself could not be constructed within the timeout of 2 minutes for every step. As we are not aware of any more efficient implementation of Iη , we will not report on further results for Iη in the following.\nAs for the runtime of the naive window-based approaches of IMI and IMIc and our stream-based approaches for Ic and Ihs see Table 2. There one can see that Jw,gIMI and J w,g IMIc on the one hand, and Jm,g,fc and J m,g,f hs on the other hand, have comparable runtimes, respectively. The former two have almost identical runtimes, which is obvious as the determination of the MIs is the main problem in both their computations. Clearly, Jm,g,fc and J m,g,f hs are significantly faster per iteration (and in total) than J w,gIMI and J w,g IMIc\n, only very few milliseconds for the latter and several hundreds and thousands of milliseconds for the former (for all variants of m and w). The impact of increasing w for Jm,g,fc and J m,g,f hs is expectedly linear while the impact of increasing the window size w for J w,gIMI and J w,gIMIc is exponential (this is also clear as both solve an FNPhard problem).\nAs for the accuracy of the different approaches see Figure 1 (a)– (d). There one can see that both Jm,g,fhs and J m,g,f c (Figures 1a and 1b) converge quite quickly (almost right after the knowledge base has been processed once) into a [−1, 1] interval around the actual inconsistency value, where Jm,g,fc is even closer to it. The naive window-based approaches (Figures 1c and 1d) have a comparable bad performance (this is clear as those approaches cannot see all MIs at any iteration due to the limited window size). Surprisingly, the impact of larger values of m for Jm,g,fhs and J m,g,f c is rather small in terms of accuracy which suggests that the random process of our algorithm is quite robust. Even for m = 10 the results are quite satisfactory.\nAs for the scalability of Jm,g0.75 ,f1hs see Figure 1e. There one can observe a linear increase in the runtime of all variants wrt. the size of the knowledge base. Furthermore, the difference between the variants is also linearly in the parameter m (which is also clear as each population is an independent random process). It is noteworthy, that\n10 More precisely, our implementation of the measure proved to be not suitable for this setting\nthe average runtime for J 10,g0.75 ,f1hs is about 66.1 seconds for knowledge bases with 50000 formulas. As the significance of the parameter m for the accuracy is also only marginal, the measure J 10,g0.75 ,f1hs is clearly an effective and accurate stream-based inconsistency measure."
    }, {
      "heading" : "6 Discussion and Conclusion",
      "text" : "In this paper we discussed the issue of large-scale inconsistency measurement and proposed novel approximation algorithms that are effective for the streaming case. To the best of our knowledge, the computational issues for measuring inconsistency, in particular with respect to scalability problems, have not yet been addressed in the literature before. One exception is the work by Ma and colleagues [10] who present an anytime algorithm that approximates an inconsistency measure based on a 4-valued paraconsistent logic (similar to the contension inconsistency measure). The algorithm provides lower and upper bounds for this measure and can be stopped at any point in time with some guaranteed quality. The main difference between our framework and the algorithm of [10] is that the latter needs to process the whole knowledge base in each atomic step and is therefore not directly applicable for the streaming scenario. The empirical evaluation [10] also suggests that our streaming variant of Ihs is much more performant as Ma et al. report an average runtime of their algorithm of about 240 seconds on a knowledge base with 120 formulas and 20 propositions (no evaluation on larger knowledge bases is given) while our measure has a runtime of only a few seconds for knowledge bases with 5000 formulas with comparable accuracy11 . A deeper comparison of these different approaches is planned for future work.\nOur work showed that inconsistency measurement is not only a theoretical field but can actually be applied to problems of reasonable size. In particular, our stream-based approaches of Ihs and Ic are accurate and effective for measuring inconsistencies in large knowledge bases. Current and future work is about the application of our work on linked open data sets [6]."
    }, {
      "heading" : "A Proofs of technical results",
      "text" : "Proposition 1. The function Ihs is a (basic) inconsistency measure.\nProof. We have to show that properties 1.), 2.), and 3.) of Definition 3 are satisfied.\n1. If K is consistent there is a ω ∈ Int(At) such that ω |= α for every α ∈ K. Therefore, H = {ω} is a card minimal hitting set and we have hK = 1 and therefore Ihs(K) = 0. Note that for inconsistent K we always have hK > 1. 2. Let K ⊆ K′ and let H be a card-minimal hitting set of K′. Then H is also a hitting set of K (not necessarily a card-minimal one). Therefore, we have hK ≤ hK′ and Ihs(K) ≤ Ihs(K\n′). 3. Let α ∈ Free(K) and define K′ = K \\ {α}. Let H be a card-\nminimal hitting set of K′ and let ω ∈ H . Furthermore, let K′′ ⊆ K′ be the set of all formulas such that ω |= β for all β ∈ K′′. It follows that K′′ is consistent. As α is a free formula it follows that K′′ ∪ {α} is also consistent (otherwise there would be a minimal inconsistent subset of K′′ containing α). Let ω′ be a model of K′′ ∪ {α}. Then H ′ = (H \\ {ω}) ∪ {ω′} is a hitting set of K and due to 2.) also card-minimal. Hence, we have hK′ = hK and Ihs(K ′) = Ihs(K).\nProposition 2. The measure Ihs satisfies the following properties:\n• If α ∈ K is such that At(α) ∩ At(K \\ {α}) = ∅ then Ihs(K) = Ihs(K \\ {α}) (safe formula independence). • If K ≡σ K′ then Ihs(K) = Ihs(K′) (irrelevance of syntax). • If α |= β and α 6|=⊥ then Ihs(K ∪ {α}) ≥ Ihs(K ∪ {β})\n(dominance).\nProof.\n• This is satisfied as safe formula independence follows from free formula independence, cf. [5, 13]. • Let H be a card-minimal hitting set of K. So, for every α ∈ K we have ω ∈ H with ω |= α. Due to α ≡ σ(α) we also have ω |= σ(α) and, thus for very β ∈ K′ we have ω ∈ H with ω |= β. So H is also a hitting set of K′. Minimality follows from the fact that σ is a bijection. • Let H be a card-minimal hitting set of K1 = K ∪ {α} and let ω ∈ H be such that ω |= α. Then we also have that ω |= β and H is also a hitting set of K2 = K ∪ {β}. Hence, hK1 ≥ hK2 and Ihs(K1) ≥ Ihs(K2).\nProposition 3. A consistent partitioning Φ is a card-minimal partitioning of K if and only if Ihs(K) = |Φ| − 1.\nProof. Let Φ = {Φ1, . . . ,Φn} be a consistent partitioning and let ωi ∈ Int(At) be such that ωi |= Φi (for i = 1, . . . , n). Then {ω1, . . . , ωn} is a hitting set of K and we have hK ≤ |Φ|. With the same idea one obtains a consistent partitioning Φ from every hitting set H of K and thus hK ≥ |Φ′| for every card-minimal partitioning of K. Hence, Ihs(K) = |Φ|− 1 for every card-minimal partitioning Φ of K.\nProposition 4. Let K be a knowledge base. If ∞ > Ihs(K) > 0 then\n1− 1\nIhs(K) < Iη(K) ≤ 1−\n1\nIhs(K) + 1\nProof. For the right inequality, let H be a card-minimal hitting set of K, i. e., we have Ihs(K) = |H | − 1. Define a probability function P : Int(At) → [0, 1] via P (ω) = 1/|H | for every ω ∈ H and P (ω′) = 0 for every ω′ ∈ Int(At)\\H (note that P is indeed a probability function). As H is a hitting set of K we have that P (φ) ≥ 1/|H | for every φ ∈ K as at least one model of φ gets probability 1/|H | in P . So we have Iη ≤ 1 − 1/|H | = 1 − 1/(Ihs(K) + 1). For the left inequality we only sketch a proof. Assume that Iη(K) ≤ 1/2, then we have to show that Ihs(K) < 2 which is equivalent to Ihs(K) ≤ 1 as the co-domain of Ihs is a subset of the natural numbers. If Iη(K) ≤ 1/2 then there is a probability function P with P (φ) ≥ 1/2 for all φ ∈ K. Let ΓP = {ω ∈ Int(At) | P (ω) > 0} and observe ∑\nω∈ΓP P (ω) = 1. Without loss of generality assume\nthat P (ω) = P (ω′) for all ω, ω′ ∈ ΓP 12. Then every φ ∈ K has to be satisfied by at least half of the interpretations in ΓP in order for P (φ) = ∑\nω∈ΓP ,ω|=φ P (ω) ≥ 1/2 to hold. Then due to combinato-\nrial reasons there have to be ω1, ω2 ∈ ΓP such that either ω1 |= φ or ω2 |= φ for every φ ∈ K. Therefore, {ω1, ω2} is a hitting set and we have Ihs(K) ≤ 1. By analogous reasoning we obtain Ihs(K) ≤ 2 if Iη(K) ≤ 2/3 (and therefore P (φ) ≥ 1/3 for all φ ∈ K) and the general case Ihs(K) ≤ i if Iη(K) ≤ (i− 1)/i and, thus, the claim. Note finally that Iη(K) = 1 if and only if K contains a contradictory formula which is equivalent to Ihs(K) = ∞ and thus ruled out.\nCorollary 1. If Iη(K1) ≤ Iη(K2) then Ihs(K1) ≤ Ihs(K2).\nProof. We show the contraposition of the claim, so assume Ihs(K1) > Ihs(K2) which is equivalent to Ihs(K1) ≥ Ihs(K2)+1 as the co-domain of Ihs is a subset of the natural numbers. By Proposition 4 we have\nIη(K1) > 1− 1\nIhs(K1) ≥ 1−\n1\nIhs(K2) + 1 ≥ Iη(K2)\nwhich yields Iη(K1) > Iη(K2).\nProposition 5. Let I be an inconsistency measure, w ∈ N, and g some function g : [0,∞) × [0,∞) → [0,∞) with g(x, y) ∈ [min{x, y},max{x, y}].\n1. If w is finite then J w,gI is not an approximation of I.\n12 Otherwise let k ∈ Q ∩ [0, 1] be the least common denominator of all P (ω), ω ∈ ΓP , and replace in ΓP every ω by k duplicates of ω with probability P (ω)/k each; for that note that P can always be defined using only rational numbers, cf. [8]\n2. If w = ∞ and g(x, y) > min{x, y} if x 6= y then J w,gI is an approximation of I. 3. J w,gI (SK, i) ≤ I(K) for every K ∈ K and i ∈ N.\nProof.\n1. Assume K is a minimal inconsistent set with |K| > w. Then I(Smax{0,i−w},i) = 0 for all i > 0 (as every subset of K is consistent) and J w,gI (S , i) = 0 for all i > 0 as well. As I is an inconsistency measure it holds I(K) > 0 and, hence, J w,gI does not approximate I. 2. If w = ∞ we have I(Smax{0,i−w},i) = I(K) for all i > i0 for some i0 ∈ N. As g(x, y) > min{x, y} the value I(K) will be approximated by J w,gI eventually. 3. This follows from the fact that I is a basic inconsistency measure and therefore satisfies I(K) ≤ I(K′) for K ⊆ K′.\nProposition 6. For every probability p ∈ [0, 1), g some function g : [0,∞)× [0,∞) → [0,∞) with g(x, y) ∈ [min{x, y},max{x, y}] and g(x, y) > min{x, y} if x 6= y, a monotonically decreasing function f : N → [0, 1] with limn→∞ f(n) = 0, and K ∈ K there is m ∈ N such that with probability greater or equal p it is the case that limi→∞ J m,g,f hs (SK, i) = Ihs(K).\nSketch. Consider the evolution of single candidate set C1 ∈ Cand during the iterated execution of updatem,g,fhs (form), initialized with the empty set ∅. Furthermore, let Ĉ be a card-minimal hitting set of K. In every iteration the probability of selecting one ω ∈ Ĉ to be added to C1 is greater zero as at least one ω ∈ Ĉ is a model of the current formula. Furthermore, the probability of not removing any interpretation ω′ ∈ C1 is also greater zero as f is monotonically decreasing (ignoring the very first step). Therefore, the probability p1 that C1 evolves to Ĉ (and is not modified thereafter) is greater zero. Furthermore, the evolution of each candidate set Ci ∈ Cand is probabilistically independent of all other evolutions and by considering more candidate sets, i. e., by setting the value m large enough, more candidate sets will evolve to some card-minimal hitting set of K and the average cardinality of the candidate sets approximates Ihs(K) + 1."
    } ],
    "references" : [ {
      "title" : "Distance-based Measures of Inconsistency",
      "author" : [ "J. Grant", "A. Hunter" ],
      "venue" : "Proceedings of the 12th Europen Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU’13), pp. 230–241, ",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Measuring inconsistency in knowledgebases",
      "author" : [ "John Grant", "Anthony Hunter" ],
      "venue" : "Journal of Intelligent Information Systems,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2006
    }, {
      "title" : "Measuring consistency gain and information loss in stepwise inconsistency resolution",
      "author" : [ "John Grant", "Anthony Hunter" ],
      "venue" : "Proc. of the 11th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "A Textbook of Belief Dynamics",
      "author" : [ "S.O. Hansson" ],
      "venue" : "Kluwer Academic Publishers",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "On the measure of conflicts: Shapley inconsistency values",
      "author" : [ "Anthony Hunter", "Sebastien Konieczny" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2010
    }, {
      "title" : "LDSpider: An open-source crawling framework for the web of linked data",
      "author" : [ "Robert Isele", "Jürgen Umbrich", "Chris Bizer", "Andreas Harth" ],
      "venue" : "Proceedings of 9th International Semantic Web Conference (ISWC",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2010
    }, {
      "title" : "Inconsistency measurement thanks to mus decomposition",
      "author" : [ "Said Jabbour", "Yue Ma", "Badran Raddaoui" ],
      "venue" : "Proc. of the 13th Int. Conference on Autonomous Agents and Multiagent Systems,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2014
    }, {
      "title" : "A Theory of Inconsistency",
      "author" : [ "Kevin M. Knight" ],
      "venue" : "Ph.D. dissertation, University Of Manchester,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2002
    }, {
      "title" : "Genetic Algorithms and Simulated Annealing",
      "author" : [ "D. Lawrence" ],
      "venue" : "Pitman Publishing",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 1987
    }, {
      "title" : "An anytime algorithm for computing inconsistency measurement",
      "author" : [ "Yue Ma", "Guilin Qi", "Guohui Xiao", "Pascal Hitzler", "Zuoquan Lin" ],
      "venue" : "in Knowledge Science, Engineering and Management,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2009
    }, {
      "title" : "Bridges from Classical to Nonmonotonic Logic",
      "author" : [ "D. Makinson" ],
      "venue" : "College Publications",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Logic of Paradox",
      "author" : [ "G. Priest" ],
      "venue" : "Journal of Philosophical Logic, 8, 219– 241, ",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1979
    }, {
      "title" : "Inconsistency measures for probabilistic logics",
      "author" : [ "Matthias Thimm" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Inconsistency measurement [2] is a subfield of Knowledge Representation and Reasoning (KR) that is concerned with the quantitative assessment of the severity of inconsistencies in knowledge bases.",
      "startOffset" : 26,
      "endOffset" : 29
    }, {
      "referenceID" : 10,
      "context" : "In order to make the knowledge bases useful again, one can either use nonmonotonic/paraconsistent reasoning techniques [11, 12] or one revises the knowledge bases appropriately to make them consistent [4].",
      "startOffset" : 119,
      "endOffset" : 127
    }, {
      "referenceID" : 11,
      "context" : "In order to make the knowledge bases useful again, one can either use nonmonotonic/paraconsistent reasoning techniques [11, 12] or one revises the knowledge bases appropriately to make them consistent [4].",
      "startOffset" : 119,
      "endOffset" : 127
    }, {
      "referenceID" : 3,
      "context" : "In order to make the knowledge bases useful again, one can either use nonmonotonic/paraconsistent reasoning techniques [11, 12] or one revises the knowledge bases appropriately to make them consistent [4].",
      "startOffset" : 201,
      "endOffset" : 204
    }, {
      "referenceID" : 2,
      "context" : "[3].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "To this end we present a novel inconsistency measure Ihs that approximates the η-inconsistency measure from [8] and is particularly apt to be applied to large knowledge bases.",
      "startOffset" : 108,
      "endOffset" : 111
    }, {
      "referenceID" : 7,
      "context" : "We present a novel inconsistency measure Ihs based on hitting sets and show how this measure relates to other measures and, in particular, that it is a simplification of the η-inconsistency measure [8] (Section 3).",
      "startOffset" : 198,
      "endOffset" : 201
    }, {
      "referenceID" : 2,
      "context" : "[3].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[8, 10, 1, 2, 5, 13].",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 9,
      "context" : "[8, 10, 1, 2, 5, 13].",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 0,
      "context" : "[8, 10, 1, 2, 5, 13].",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 1,
      "context" : "[8, 10, 1, 2, 5, 13].",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 4,
      "context" : "[8, 10, 1, 2, 5, 13].",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 12,
      "context" : "[8, 10, 1, 2, 5, 13].",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 4,
      "context" : "There are two main paradigms for assessing inconsistency [5], the first being based on the (number of) formulas needed to produce inconsistencies and the second being based on the proportion of the language that is affected by the inconsistency.",
      "startOffset" : 57,
      "endOffset" : 60
    }, {
      "referenceID" : 2,
      "context" : "We adopt the following definition of a (basic) inconsistency measure from [3].",
      "startOffset" : 74,
      "endOffset" : 77
    }, {
      "referenceID" : 2,
      "context" : "[3, 8].",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 7,
      "context" : "[3, 8].",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 11,
      "context" : "In order to define the contension measure Ic we need to consider three-valued interpretations for propositional logic [12].",
      "startOffset" : 118,
      "endOffset" : 122
    }, {
      "referenceID" : 7,
      "context" : "For defining the η-inconsistency measure [8] we need to consider probability functions P of the form P : Int(At) → [0, 1] with",
      "startOffset" : 41,
      "endOffset" : 44
    }, {
      "referenceID" : 0,
      "context" : "For defining the η-inconsistency measure [8] we need to consider probability functions P of the form P : Int(At) → [0, 1] with",
      "startOffset" : 115,
      "endOffset" : 121
    }, {
      "referenceID" : 1,
      "context" : "[2, 3, 8] and for some recent developments see e.",
      "startOffset" : 0,
      "endOffset" : 9
    }, {
      "referenceID" : 2,
      "context" : "[2, 3, 8] and for some recent developments see e.",
      "startOffset" : 0,
      "endOffset" : 9
    }, {
      "referenceID" : 7,
      "context" : "[2, 3, 8] and for some recent developments see e.",
      "startOffset" : 0,
      "endOffset" : 9
    }, {
      "referenceID" : 0,
      "context" : "[1, 7].",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 6,
      "context" : "[1, 7].",
      "startOffset" : 0,
      "endOffset" : 6
    }, {
      "referenceID" : 11,
      "context" : "Table 1 Truth tables for propositional three-valued logic [12].",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 4,
      "context" : "The result below shows that Ihs also behaves well with some more properties mentioned in the literature [5, 13].",
      "startOffset" : 104,
      "endOffset" : 111
    }, {
      "referenceID" : 12,
      "context" : "The result below shows that Ihs also behaves well with some more properties mentioned in the literature [5, 13].",
      "startOffset" : 104,
      "endOffset" : 111
    }, {
      "referenceID" : 5,
      "context" : "On a wider scope, a propositional stream can also be interpreted as a very general abstraction of the output of a linked open data crawler (such as LDSpider [6]) that crawls knowledge formalized as RDF (Resource Description Framework) from the web, enriched, e.",
      "startOffset" : 157,
      "endOffset" : 160
    }, {
      "referenceID" : 0,
      "context" : ", the maximum function max or a smoothing function gα(x, y) = αx + (1 − α)y for some α ∈ [0, 1] (for every x, y ∈ [0,∞)).",
      "startOffset" : 89,
      "endOffset" : 95
    }, {
      "referenceID" : 8,
      "context" : "The approximation algorithms for Ihs and Ic that are presented in this subsection are using concepts of the programming paradigms of simulated annealing and genetic programming [9].",
      "startOffset" : 177,
      "endOffset" : 180
    }, {
      "referenceID" : 0,
      "context" : "Let m ∈ N, g some function g : [0,∞)× [0,∞) → [0,∞) with g(x, y) ∈ [min{x, y},max{x, y}], and f : N → [0, 1] some monotonically decreasing function with limn→∞ f(n) = 0.",
      "startOffset" : 102,
      "endOffset" : 108
    }, {
      "referenceID" : 0,
      "context" : "3: newV alue = 0 4: for all C ∈ Cand do 5: rand ∈ [0, 1] 6: if rand < f(N) then 7: Remove some random ω from C 8: if ¬∃ω ∈ C : ω |= form then 9: Add random ω ∈ Mod(form) to C",
      "startOffset" : 50,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "For every probability p ∈ [0, 1), g some function g : [0,∞)× [0,∞) → [0,∞) with g(x, y) ∈ [min{x, y},max{x, y}] and g(x, y) > min{x, y} if x 6= y, a monotonically decreasing function f : N → [0, 1] with limn→∞ f(n) = 0, and K ∈ K there is m ∈ N such that with probability greater or equal p it is the case that",
      "startOffset" : 191,
      "endOffset" : 197
    }, {
      "referenceID" : 0,
      "context" : "75 ,f1 hs (with m = 10, 100, 500) with f1 : N → [0, 1] defined via f1(i) = 1/(i + 1) for all i ∈ N and g0.",
      "startOffset" : 48,
      "endOffset" : 54
    }, {
      "referenceID" : 9,
      "context" : "One exception is the work by Ma and colleagues [10] who present an anytime algorithm that approximates an inconsistency measure based on a 4-valued paraconsistent logic (similar to the contension inconsistency measure).",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 9,
      "context" : "The main difference between our framework and the algorithm of [10] is that the latter needs to process the whole knowledge base in each atomic step and is therefore not directly applicable for the streaming scenario.",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 9,
      "context" : "The empirical evaluation [10] also suggests that our streaming variant of Ihs is much more performant as Ma et al.",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 5,
      "context" : "Current and future work is about the application of our work on linked open data sets [6].",
      "startOffset" : 86,
      "endOffset" : 89
    } ],
    "year" : 2017,
    "abstractText" : "We investigate the problem of inconsistency measurement on large knowledge bases by considering stream-based inconsistency measurement, i. e., we investigate inconsistency measures that cannot consider a knowledge base as a whole but process it within a stream. For that, we present, first, a novel inconsistency measure that is apt to be applied to the streaming case and, second, stream-based approximations for the new and some existing inconsistency measures. We conduct an extensive empirical analysis on the behavior of these inconsistency measures on large knowledge bases, in terms of runtime, accuracy, and scalability. We conclude that for two of these measures, the approximation of the new inconsistency measure and an approximation of the contension inconsistency measure, large-scale inconsistency measurement is feasible.",
    "creator" : "LaTeX with hyperref package"
  }
}