{
  "name" : "1602.07362.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "The Possibilities and Limitations of Private Prediction Markets",
    "authors" : [ "Rachel Cummings", "David M. Pennock", "Jennifer Wortman Vaughan" ],
    "emails" : [ "rachelc@caltech.edu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Betting markets of various forms—including the stock exchange [Grossman, 1976], futures markets [Roll, 1984], sports betting markets [Gandar et al., 1999], and markets at the racetrack [Thaler and Ziemba, 1988]—have been shown to successfully collect and aggregate information. Over the last few decades, prediction markets designed specifically for the purpose of elicitation and aggregation, have yielded useful predictions in domains as diverse as politics [Berg et al., 2001], disease surveillance [Polgreen et al., 2007], and entertainment [Pennock et al., 2002].\nThe desire to aggregate and act on the strategically valuable information dispersed among employees has led many companies to experiment with internal prediction markets. An internal corporate market could be used to predict the launch date of a new product or the product’s eventual success. Among the first companies to experiment with internal markets were Hewlett-Packard, which implemented real-money markets, and Google, which ran markets using its own internal currency that could be exchanged for raffle tickets or prizes [Plott and Chen, 2002, Cowgill and Zitzewitz, 2015]. More recently, Microsoft, Intel, Ford,\n∗Computing and Mathematical Sciences, California Institute of Technology. Email: rachelc@caltech.edu Supported in part by a Simons Award for Graduate Students in Theoretical Computer Science. Much of this research was done while R. Cummings was at Microsoft Research. †Microsoft Research. Email: dpennock@microsoft.com ‡Microsoft Research. Email: jenn@microsoft.com\nar X\niv :1\n60 2.\n07 36\n2v 1\n[ cs\n.G T\n] 2\n4 Fe\nb 20\n16\nGE, Siemens, and others have engaged in similar experiments [Berg and Proebsting, 2009, Charette, 2007, Cowgill and Zitzewitz, 2015].\nProponents of internal corporate markets often argue that the market structure helps in part because, without it, “business practices... create incentives for individuals not to reveal their information” [Plott and Chen, 2002]. However, even with a formal market structure in place, an employee might be hesitant to bet against the success of their team for fear of insulting her coworkers or angering management. If an employee has information that is unfavorable to the company, she might choose not to report it, leading to predictions that are overly optimistic for the company and ultimately contributing to an “optimism bias” in the market similar to the bias in Google’s corporate markets discovered by Cowgill and Zitzewitz [2015].\nTo address this issue, we consider the problem of designing private prediction markets. A private market would allow participants to engage in the market and contribute to the accuracy of the market’s predictions without fear of having their information or beliefs revealed. The goal is to provide participants with a form of “plausible deniability.” Although participants’ trades or wagers should together influence the market’s behavior and predictions, no single participant’s actions should have too much influence over what others can observe. We formalize this idea using the popular notion of differential privacy [Dwork et al., 2006, Dwork and Roth, 2014], which can be used to guarantee that any participant’s actions cannot be inferred from observations.\nWe begin by designing a private analog of the weighted score wagering mechanisms first introduced by Lambert et al. [2008]. A wagering mechanism allows bettors to each specify a belief about the likelihood of a future event and a corresponding monetary wager. These wagers are then collected by a centralized operator and redistributed among bettors in such a way that more accurate bettors receive higher rewards. Lambert et al. [2008] showed that the class of weighted score wagering mechanisms, which are built on the machinery of proper scoring rules [Gneiting and Raftery, 2007], is the unique set of wagering mechanisms to satisfy a set of desired properties such as budget balance, truthfulness, and anonymity. We design a class of wagering mechanisms with randomized payments that maintain the nice properties of weighted score wagering mechanisms in expectation while additionally guaranteeing -joint differential privacy in the bettors’ reported beliefs. We discuss the trade-offs that exist between the privacy of the mechanism (captured by the parameter ) and the sensitivity of a bettor’s payment to her own report, and show how to set the parameters of our mechanisms to achieve a reasonable level of the plausible deniability desired in practice.\nWe next address the problem of running private dynamic prediction markets. We consider the setting in which traders buy and sell securities with values linked to future events. For example, a market might offer a security worth $1 if Microsoft Bing’s market share increases in 2016 and $0 otherwise. A risk neutral trader who believes that the probability of Bing’s market share increasing is p would profit from buying this security at any price less than $p or (short) selling it at any price greater than $p. The market price of the security is thought to reflect traders’ collective beliefs about the likelihood of this event. We focus on cost-function prediction markets [Chen and Pennock, 2007, Abernethy et al., 2013] such as Hanson’s popular logarithmic market scoring rule [Hanson, 2003]. In a cost-function market, all trades are placed through an automated market maker, a centralized algorithmic agent that is always willing to buy or sell securities at some current market price that depends on the history of trade via a potential function called the cost function. We ask whether it is possible for a market maker to price trades according to a noisy cost function in a way that maintains traders’ privacy without allowing traders to make unbounded profit off of the noise. Unfortunately, we show that under general assumptions, it is impossible for a market maker to achieve bounded loss and -differential privacy without allowing the privacy guarantee to degrade very quickly as the number of trades grows. In particular, the quantity e must grown faster than linearly in the number of trades, making such markets impractical in settings in which privacy is valued. We suggest several avenues for future research aimed at circumventing this lower bound.\nThere is very little prior work on the design of private prediction markets, and to the best of our knowledge, we are the first to consider privacy for one-shot wagering mechanisms. Most closely related to our work is the recent paper of Waggoner et al. [2015] who consider a setting in which each of a set of selfinterested agents holds a private data point consisting of an observation x and corresponding label y. A firm would like to purchase the agents’ data in order to learn a function to accurately predict the labels of new\nobservations. Building on the mathematical foundations of cost-function market makers, Waggoner et al. propose a mechanism that provides incentives for the agents to reveal their data to the firm in such a way that the firm is able to solve its prediction task while maintaining the agents’ privacy. The authors mention that similar ideas can be applied to produce privacy-preserving prediction markets, but their construction requires knowing the number of trades that will occur in advance to appropriately set parameters. The most straightforward way of applying their techniques to prediction markets results in a market maker falling in the class covered by our impossibility result, suggesting that such techniques cannot be used to derive a privacy-preserving market with bounded loss when the number trades is unknown."
    }, {
      "heading" : "2 Tools from Differential Privacy",
      "text" : "We formalize privacy using the now-standard notion of differential privacy, which was introduced by Dwork et al. [2006]. The most basic version of differential privacy is used to measure the privacy of a randomized algorithm’s output when given as input a database D with n entries from some input domain I. Differential privacy is often studied in settings in which the n entries are provided by n agents, each of whom would like to keep their entry private. Two databases D and D′ are said to be neighboring if they differ only in a single entry. Differential privacy requires that the distribution of the algorithm’s output given D is “close to” the distribution of its output given any neighboring database D′. For these definitions, it is enough to view an “algorithm” as a randomized function mapping inputs to outputs; we are not concerned with the precise way in which the outputs are computed. In the following definitions, we restrict to real-valued outputs for consistency with the algorithms used in this paper.\nDefinition 1 (Differential Privacy [Dwork et al., 2006]). For any , δ ≥ 0, an algorithm M : In → R is ( , δ)-differentially private if for every pair of neighboring databases D,D′ ∈ In and every subset S ⊆ R,\nPr[M(D) ∈ S] ≤ e Pr[M(D′) ∈ S] + δ.\nIf δ = 0, we say that M is -differentially private.\nAs approaches 0, it becomes increasingly more difficult to distinguish neighboring databases, leading to a higher level of privacy. As grows large, the privacy guarantee grows increasingly weak. There is generally no consensus about what constitutes a “good” value of , and the strength of the guarantee needed may depend on the application. We discuss this point more later in the context of our results.\nWe sometimes abuse terminology and say that a random variable (such as a bettor’s profit) is differentially private. This should be taken to mean that the algorithm used to compute the value of the random variable is differentially private.\nIn the context of mechanism design, differential privacy is often too strong of a notion. Suppose, for example, that the algorithm M outputs a vector of prices that each of n agents will pay based on their joint input. While we may want the price that agent i pays to be differentially private in the input of the other agents, it is natural to allow it to be more sensitive to changes in i’s own input. To capture this idea, Kearns et al. [2014] defined the notion of joint differential privacy. Call two neighboring databases D and D′ i-neighbors if they differ only in the ith entry. Suppose that M now outputs one element for each agent i ∈ {1, . . . , n} and let M(D)−i denote the vector of outputs to all agents excluding agent i. Then joint differential privacy is defined as follows.\nDefinition 2 (Joint Differential Privacy [Kearns et al., 2014]). For any , δ ≥ 0, an algorithmM : In → Rn is ( , δ)-joint differentially private if for every i ∈ {1, . . . , n}, for every pair of i-neighbors D,D′ ∈ In, and for every subset S ⊆ Rn−1,\nPr[M(D)−i ∈ S] ≤ e Pr[M(D′)−i ∈ S] + δ.\nIf δ = 0, we say that M is -joint differentially private.\nJoint differential privacy is still a strong requirement. It protects the privacy of any agent i from arbitrary coalitions; even if all other agents shared their private output, they would still not be able to learn too much about the input of agent i.\nOne useful tool for proving joint differential privacy is the billboard lemma [Hsu et al., 2014]. The idea behind the billboard lemma is quite intuitive and simple. Imagine that we display some message publicly so that it is viewable by all n agents, as if posted on a billboard, and suppose that the algorithm to compute this message is -differentially private. If each agent i’s output M(D)i is computable from this public message along with i’s own private input, thenM is -joint differentially private. A more formal statement and proof are given in Hsu et al. [2014].\nThe definitions above assume the input database D is fixed. Differential privacy has also been considered for streaming algorithms [Chan et al., 2011, Dwork et al., 2010]. Let N = {1, 2, 3, . . .}. Following Chan et al. [2011], a stream σ ∈ IN is a string of countable length of elements in I, where σt ∈ I denotes the element at position or time t and σ1,...,t ∈ It is the length t prefix of the stream σ. Two streams σ and σ′ are said to be neighbors if they differ at exactly one time t.\nA streaming algorithm M is said to be unbounded if it accepts streams of indefinite length, that is, if for any stream σ ∈ IN, M(σ) ∈ RN. In contrast, a streaming algorithm is T -bounded if it accepts only streams of length at most T . Dwork et al. [2010] consider only T -bounded streaming algorithms. Since we consider unbounded streaming algorithms, we use a more appropriate definition of differential privacy for streams adapted from Chan et al. [2011]. For unbounded streaming algorithms, it can be convenient to let the privacy guarantee degrade as the input stream grows in length. Chan et al. [2011] implicitly allow this in some of their results; see, for example, Corollary 4.5 in their paper. For clarity and preciseness, we explicitly capture this in our definition. Here and throughout the paper we use R+ to denote the nonnegative reals. Definition 3 (Differential Privacy for Streams). For any non-decreasing function : N → R+ and any δ ≥ 0, a streaming algorithm M : IN → RN is ( (t), δ)-differentially private if for every pair of neighboring streams σ, σ′ ∈ IN, for every t ∈ N, and for every subset S ⊆ Rt,\nPr[M(σ1,...,t) ∈ S] ≤ e (t)Pr[M(σ′1,...,t) ∈ S] + δ.\nIf δ = 0, we say that M is (t)-differentially private. Note that we allow to grow with t, but require that δ stay constant. In principle, one could also allow δ to depend on the length of the stream. However, allowing δ to increase would likely be unacceptable in scenarios in which privacy is considered important. In fact, it is more typical to require smaller values of δ for larger databases since for a database of size n, an algorithm could be considered ( , δ)-private for δ on the order of 1/n even if it fully reveals a small number of randomly chosen database entries [Dwork and Roth, 2014]. Since we use this definition only when showing an impossibility result, allowing δ to decrease in t would not strengthen our result."
    }, {
      "heading" : "3 Private Wagering Mechanisms",
      "text" : "We begin with the problem of designing a one-shot wagering mechanism that incentivizes bettors to truthfully report their beliefs while maintaining their privacy. A wagering mechanism allows a set of bettors to each specify a belief about a future event and a monetary wager. Wagers are collected by a centralized operator and redistributed to bettors in such a way that bettors with more accurate predictions are more highly rewarded. Lambert et al. [2008] showed that the class of weighted score wagering mechanisms (WSWMs) is the unique class of wagering mechanisms to satisfy a set of desired axioms such as budget balance and truthfulness. In this section, we show how to design a randomized wagering mechanism that achieves -joint differential privacy while maintaining the nice properties of WSWMs in expectation."
    }, {
      "heading" : "3.1 Standard wagering mechanisms",
      "text" : "Wagering mechanisms, introduced by Lambert et al. [2008], are mechanisms designed to allow a centralized operator to elicit the beliefs of a set of bettors without taking on any risk. In this paper we focus on binary\nwagering mechanisms, in which each bettor i submits a report pi ∈ [0, 1] specifying how likely she believes it is that a particular event will occur, along with a wager mi ≥ 0 specifying the maximum amount of money that she is willing to lose. After all reports and wagers have been collected, all parties observe the realized outcome ω ∈ {0, 1} indicating whether or not the event occurred. Each bettor i then receives a payment that is a function of the outcome and the reports and wagers of all bettors. This idea is formalized as follows.\nDefinition 4 (Wagering Mechanism [Lambert et al., 2008]). A wagering mechanism for a set of bettors N = {1, . . . , n} is specified by a vector Π of (possibly randomized) profit functions, Πi : [0, 1]n×Rn+×{0, 1} → R, where Πi(p,m, ω) denotes the total profit to bettor i when the vectors of bettors’ reported probabilities and wagers are p and m and the realized outcome is ω. It is required that Πi(p,m, ω) ≥ −mi for all p, m, and ω, which ensures that no bettor loses more than her wager.\nThere are two minor differences between the definition presented here and that of Lambert et al. [2008]. First, for convenience, we use Πi to denote the total profit to bettor i (i.e., her payment from the mechanism minus her wager), unlike Lambert et al. [2008], who use Πi to denote the payment only. While this difference is inconsequential, we mention it to avoid confusion. Second, all previous work on wagering mechanisms has restricted attention to deterministic profit functions Πi. Since randomization is necessary to attain privacy, we open up our study to randomized profit functions.\nLambert et al. [2008] defined a set of desirable properties or axioms that deterministic wagering mechanisms should arguably satisfy. Here we adapt those properties to potentially randomized wagering mechanisms, making the smallest modifications possible to maintain the spirit of the axioms. Four of the properties (truthfulness, individual rationality, normality, and monotonicity) were originally defined in terms of expected profit with the expectation taken over some true or believed distribution over the outcome ω. We allow the expectation to be over the randomness in the profit function as well. Sybilproofness was not initially defined in expectation; we now ask that this property hold in expectation with respect to the randomness in the profit function. We define anonymity in terms of the distribution over all bettors’ profits, and ask that budget balance hold for any realization of the randomness in Π.\n(a) Budget balance: The operator makes no profit or loss, i.e., ∀p ∈ [0, 1]n, ∀m ∈ Rn+, ∀ω ∈ {0, 1}, and for any realization of the randomness in Π, ∑n i=1 Πi(p,m, ω) = 0.\n(b) Anonymity: Profits do not depend on the identify of the bettors. That is, for any permutation of the bettors σ, ∀p ∈ [0, 1]n, ∀m ∈ Rn+, ∀ω ∈ {0, 1}, the joint distribution over profit vectors {Πi(p,m, ω)}i∈N is the same as the joint distribution over profit vectors {Πσ(i) ( (pσ−1(i))i∈N , (mσ−1(i))i∈N , ω ) }i∈N .\n(c) Truthfulness: Bettors uniquely maximize their expected profit by reporting the truth. That is, ∀i ∈ N , ∀p−i ∈ [0, 1]n−1, ∀m ∈ Rn+, ∀p∗, pi ∈ [0, 1] with pi 6= p∗,\nEω∼p∗ [ Πi((p ∗,p−i),m, ω) ] > Eω∼p∗ [ Πi((pi,p−i),m, ω) ] .\n(d) Individual rationality: Bettors prefer participating to not participating. That is, ∀i ∈ N , ∀mi > 0, for all p∗ ∈ [0, 1], there exists some pi ∈ [0, 1] such that ∀p−i ∈ [0, 1]n−1, ∀m−i ∈ Rn−1+ , Eω∼p∗ [ Πi((pi,p−i),m, ω) ] ≥\n0.\n(e) Normality:1 If any bettor j changes her report, the change in the expected profit to any other bettor i with respect to a fixed belief p∗ is the opposite sign of the change in expected payoff to j. That is, ∀i, j ∈ N , i 6= j, ∀p,p′ ∈ [0, 1]n with p′k = pk for all k 6= j, ∀p∗ ∈ [0, 1], ∀m ∈ Rn+,\nE[Πj(p,m, ω)] < E[Πj(p′,m, ω)] =⇒ E[Πi(p,m, ω)] ≥ E[Πi(p′,m, ω)].\nAll expectations are taken w.r.t. ω ∼ p∗ and the randomness in the mechanism. 1Lambert et al. [2015] and Chen et al. [2014] used an alternative definition of normality for wagering mechanisms that essentially requires that if, from some agent i’s perspective, the prediction of agent j improves, then i’s expected profit decreases. This form of normality also holds for our mechanism.\n(f) Sybilproofness: Profits remain unchanged as any subset of players with the same reports manipulate user accounts by merging accounts, creating fake identities, or transferring wagers. That is, ∀S ⊂ N , ∀p with pi = pj for all i, j ∈ S, ∀m,m′ ∈ Rn+ with mi = m′i for i /∈ S and ∑ i∈S mi = ∑ i∈S m ′ i,\n∀ω ∈ {0, 1}, two conditions hold: E [Πi(p,m, ω)] = E [Πi(p,m′, ω)] ∀i /∈ S,∑ i∈S E [Πi(p,m, ω)] = ∑ i∈S E [Πi(p,m′, ω)] .\n(g) Monotonicity The magnitude of a bettor’s expected profit (or loss) increases as her wager increases. That is, ∀i ∈ N , ∀p ∈ [0, 1]n, ∀m ∈ Rn+, ∀Mi > mi, ∀p∗ ∈ [0, 1], either 0 < Eω∼p∗ [Πi(p, (mi,m−i), ω)] < Eω∼p∗ [Πi(p, (Mi,m−i), ω)] or 0 > Eω∼p∗ [Πi(p, (mi,m−i), ω)] > Eω∼p∗ [Πi(p, (Mi,m−i), ω)].\nPreviously studied wagering mechanisms [Lambert et al., 2008, Chen et al., 2014, Lambert et al., 2015] achieve truthfulness by incorporating strictly proper scoring rules [Savage, 1971] into their profit functions. Scoring rules reward individuals based on the accuracy of their predictions about random variables. For a binary random variable, a scoring rule s maps a prediction or report p ∈ [0, 1] and an outcome ω ∈ {0, 1} to a score. A strictly proper scoring rule incentivizes a risk neutral agent to report her true belief.\nDefinition 5 (Strictly proper scoring rule [Savage, 1971]). A function s : [0, 1] × {0, 1} → R ∪ {−∞} is a strictly proper scoring rule if for all p, q ∈ [0, 1] with p 6= q, Eω∼p[s(p, ω)] > Eω∼p[s(q, ω)].\nOne common example is the Brier scoring rule [Brier, 1950], defined as s(p, ω) = 1− (p−ω)2. Note that for the Brier scoring rule, s(p, x) ∈ [0, 1] for all p and ω. Any strictly proper scoring rule with a bounded range can be scaled to have range [0, 1].\nThe WSWMs incorporate proper scoring rules, assigning each bettor a profit based on how her score compares to the wager-weighted average score of all bettors, as in Algorithm 1. Lambert et al. [2008] showed that the set of WSWMs satisfy the seven axioms above and is the unique set of deterministic mechanisms that simultaneously satisfy budget balance, anonymity, truthfulness, normality, and sybilproofness.\nAlgorithm 1 Weighted-score wagering mechanisms [Lambert et al., 2008]\nParameters: number of bettors n, strictly proper scoring rule s with range in [0, 1] Solicit reports p and wagers m Realize state ω for i = 1, . . . , n do\nPay bettor i Πi(p,m, ω) = mi ( s(pi, ω)− ∑ j∈N mjs(pj , ω)∑\nj∈N mj ) end for"
    }, {
      "heading" : "3.2 Adding privacy",
      "text" : "We would like our wagering mechanism to protect the privacy of each bettor i, ensuring that the n− 1 other bettors cannot learn too much about i’s report from their own realized profits, even if they collude. Note that paying each agent according to an independent scoring rule would easily achieve privacy, but would fail budget balance and sybilproofness. We formalize our desire to add privacy to the other good properties of weighted score wagering mechanisms using joint differential privacy.\n(h) -joint differential privacy: The vector of profit functions satisfies -joint differential privacy, i.e., ∀i ∈ N , ∀p ∈ [0, 1]n, ∀p′i ∈ [0, 1], ∀m ∈ Rn+, ∀ω ∈ {0, 1}, and ∀S ⊂ R n−1 + , Pr[Π−i((pi,p−i),m, ω) ∈\nS] ≤ e Pr[Π−i((p′i,p−i),m, ω) ∈ S].\nThis definition requires only that the report pi of each bettor i be kept private, not the wager mi. Private wagers would impose more severe limitations on the mechanism, even if wagers are restricted to lie in a bounded range; see Section 3.3.2 for a discussion. Note that if bettor i’s report pi is correlated with his wager mi, as might be the case for a Bayesian agent [Lambert et al., 2015], then just knowing mi could reveal information about pi. In this case, differential privacy would guarantee that other bettors can infer no more about pi after observing their profits than they could from observing mi alone. If bettors have immutable beliefs as assumed by Lambert et al. [2008], then reports and wagers are not correlated and mi reveals nothing about pi.\nUnfortunately, it is not possible to jointly obtain properties (a)–(h) with any reasonable mechanism. This is due to an inherent tension between budget balance and privacy. This is easy to see. Budget balance requires that a bettor i’s profit is the negation of the sum of profits of the other n− 1 bettors, i.e., Πi(p,m, ω) = − ∑ j 6=i Πj(p,m, ω). Therefore, under budget balance, the other n − 1 bettors could always collude to learn bettor i’s profit exactly. In order to obtain privacy, it would therefore be necessary for bettor i’s profit to be differentially private in her own report, resulting in profits that are almost entirely noise. This is formalized in the following theorem. We omit a formal proof since it follows immediately from the argument described here.\nTheorem 1. Let Π be the vector of profit functions for any wagering mechanism that satisfies both budget balance and -joint differential privacy for any > 0. Then for all i ∈ N , Πi is -differentially private in bettor i’s report pi.\nSince it is unsatisfying to consider mechanisms in which a bettor’s profit is not sensitive to her own report, we require only that budget balance hold in expectation over the randomness of the profit function. An operator who runs many markets may be content with such a guarantee as it implies that he will not lose money on average.\n(a′) Budget balance in expectation: The operator neither makes a profit nor a loss in expectation, i.e., ∀p ∈ [0, 1]n, ∀m ∈ Rn+, ∀ω ∈ {0, 1}, ∑n i=1 E [Πi(p,m, ω)] = 0."
    }, {
      "heading" : "3.3 Private weighted score wagering mechanisms",
      "text" : "Motivated by the argument above, we seek a wagering mechanism that simultaneously satisfies properties (a′) and (b)–(h). Keeping Theorem 1 in mind, we would also like the wagering mechanism to be defined in such a way that each bettor i’s profit is sensitive to her own report pi. Sensitivity is difficult to define precisely, but loosely speaking, we would like it to be the case that 1) the magnitude of E [Πi(p,m, ω)] varies sufficiently with the choice of pi, and 2) there is not too much noise or variance in a bettor’s profit, i.e., Πi(p,m, ω) is generally not too far from E [Πi(p,m, ω)].\nA natural first attempt would be to employ the standard Laplace Mechanism [Dwork and Roth, 2014] on top of a WSWM, adding independent Laplace noise to each bettor’s profit. The resulting profit vector would satisfy -joint differential privacy, but since Laplace random variables are unbounded, a bettor could lose more than her wager. Adding other forms of noise does not help; to obtain differential privacy, the noise must be unbounded [Dwork et al., 2006]. Truncating a bettor’s profit to lie within a bounded range after noise is added could achieve privacy, but would result in a loss of truthfulness as the bettor’s expected profit would no longer be a proper scoring rule.\nInstead, we take a different approach. Like the WSWM, our private wagering mechanism, formally defined in Algorithm 2, rewards each bettor based on how good his score is compared with an aggregate measure of how good bettors’ scores are on the whole. However, this aggregate measure is now calculated in a noisy manner. That is, instead of comparing a bettor’s score to a weighted average of all bettors’ scores, the bettor’s score is compared to a weighted average of random variables that are equal to bettors’ scores in expectation. As a result, each bettor’s profit is, in expectation, equal to the profit she would receive using a WSWM, scaled down by a parameter α to ensure that no bettor ever loses more than her wager, as stated in the following lemma. The proof, which simply shows that for each i, E[xi(pi, ω)] = αs(pi, ω), is in the appendix.\nAlgorithm 2 Private wagering mechanism\nParameters: num bettors n, privacy param , strictly proper scoring rule s with range in [0, 1] Fix α = 1− e− and β = e− Solicit reports p and wagers m Realize state ω for i = 1, . . . , n do\nIndependently draw random variable xi(pi, ω) such that\nxi(pi, ω) = { 1 w.p. αs(pi,ω)+β1+β −β w.p. 1−αs(pi,ω)1+β\nend for for i = 1, . . . , n do\nPay bettor i Πi(p,m, ω) = mi ( αs(pi, ω)− ∑ j∈N mjxj(pj , ω)∑\nj∈N mj ) end for\nLemma 1. For any number of bettors n > 0 with reports p ∈ [0, 1]n and wagers m ∈ Rn+, for any setting of the privacy parameter > 0, for any outcome ω ∈ {0, 1}, the expected value of bettor i’s profit Πi(p,m, ω) under the private wagering mechanism with scoring rule s is equal to bettor i’s profit under a WSWM with scoring rule αs.\nUsing this lemma, we show that this mechanism does indeed satisfy joint differential privacy as well as the other desired properties.\nTheorem 2. The private wagering mechanism satisfies (a′) budget balance in expectation, (b) anonymity, (c) truthfulness, (d) individual rationality, (e) normality, (f) sybilproofness, (g) monotonicity, and (h) -joint differential privacy.\nProof. Any WSWM satisfies budget balance in expectation (by satisfying budget balance), truthfulness, individual rationality, normality, sybilproofness, and monotonicity Lambert et al. [2008]. Since these properties are defined in terms of expected profit, Lemma 1 implies that the private wagering mechanism satisfies them too.\nAnonymity is easily observed since profits are defined symmetrically for all bettors. Finally we show -joint differential privacy. We first prove that each random variable xi(pi, ω) is - differentially private in bettor i’s report pi which implies that the noisy aggregate of scores is private in all bettors’ reports. We then apply the billboard lemma (see Section 2) to show that the profit vector Π satisfies joint differential privacy.\nTo show that xi(pi, ω) is differentially private in pi, for each of the two values that xi(pi, ω) can take on we must ensure that the ratio of the probability it takes this value under any report p and the probability it takes this value under any alternative report p′ is bounded by e . Fix any ω ∈ {0, 1}. Since s has range in [0, 1],\nPr(xi(p, ω) = 1) Pr(xi(p′, ω) = 1) = αs(p, ω) + β αs(p′, ω) + β ≤ α+ β β =\n1− e− + e−\ne− = e ,\nPr(xi(p, ω) = −β) Pr(xi(p′, ω) = −β) = 1− αs(p, ω) 1− αs(p′, ω) ≤ 1 1− α = 1 1− (1− e− ) = e .\nThus xi(pi, ω) is -differentially private in pi. By Theorem 4 of McSherry [2009], the vector (x1(p1, ω), . . . , xn(pn, ω)) (and thus any function of this vector) is -differentially private in the vector p, since each xi(pi, ω) does not depend on the reports of anyone but i. Since we view the wagers mi as constants, the quantity∑ j∈N mjxj(pj , ω)/ ∑ j∈N mj is also -differentially private in the reports p. Call this quantity X.\nTo apply the billboard lemma, we can imagine the operator publicly announcing the quantity X to the bettors. Given access to X, each bettor is able to calculate her own profit Πi(p,m, ω) using only her own input and the values α and ω. The billboard lemma implies that the vector of profits is -joint differentially private."
    }, {
      "heading" : "3.3.1 Sensitivity of the mechanism",
      "text" : "Having established that our mechanism satisfies properties (a′) and (b)–(h), we next address the sensitivity of the mechanism in terms of the two facets described above: range of achievable expected profits and the amount of noise in the profit function. This discussion sheds light on how to set in practice.\nThe first facet is quantified by Lemma 1. As α grows, the magnitude of bettors’ expected profits grows, and the range of expected profits grows as well. When α approaches 1, the range of expected profits achievable through the private wagering mechanism approaches that of a standard WSWM with the same proper scoring rule.\nUnfortunately, since α = 1− e− , larger values of α imply larger values of the privacy parameter . This gives us a clear tradeoff between privacy and magnitude of expected payments. Luckily, in practice, it is probably unnecessary for to be very small for most markets. A relatively large value of can still give bettors plausible deniability. For example, setting = 1 implies that a bettor’s report can only change the probability of another bettor receiving a particular profit by a factor of roughly 2.7 and leads to α ≈ 0.63, a tradeoff that may be considered acceptable in practice.\nThe second facet is quantified in the following theorem, which states that as more money is wagered by more bettors, each bettor’s realized profit approaches its expectation. The bound depends on ‖m‖2/‖m‖1. If all wagers are equal, this quantity is equal to 1/ √ n and bettors’ profits approach their expectations as n grows. This is not the case at the other extreme, when there are a small number of bettors with wagers much larger than the rest. The proof, which uses Hoeffding’s inequality to bound the difference between the quantity mjxj(pj , ω) and its expectation, is in the appendix.\nTheorem 3. For any δ ∈ [0, 1], any > 0, any number of bettors n > 0, any vectors of reports p ∈ [0, 1]n and wagers m ∈ Rn+, with probability at least 1−δ, for all i ∈ N , the profit Πi output by the private wagering mechanism satisfies\n|Πi(p,m, ω)− E[Πi(p,m, ω)]| ≤ mi ( ‖m‖2 ‖m‖1 (1 + β) √ ln (2/δ) 2 ) .\nThe following corollary shows that if all wagers are bounded in some range [L,U ], profits approach their expectations as the number of bettors grows.\nCorollary 1. Fix any L and U , 0 < L < U . For any δ ∈ [0, 1], any > 0, any n > 0, any vectors of reports p ∈ [0, 1]n and wagers m ∈ [L,U ]n, with probability at least 1− δ, for all i ∈ N , the profit Πi output by the private wagering mechanism satisfies\n|Πi(p,m, ω)− E[Πi(p,m, ω)]| ≤ mi ( U√ nL (1 + β) √ ln (2/δ) 2 ) ."
    }, {
      "heading" : "3.3.2 Keeping wagers private",
      "text" : "Property (h) requires that bettors’ reports be kept private but does not guarantee private wagers. The same tricks used in our private wagering mechanism could be applied to obtain a privacy guarantee for both reports and wagers if wagers are restricted to lie in a bounded range [L,U ], but this would come with a great loss in sensitivity. Under the most straightforward extension, the parameter α would need to be set to (L/U)(1− e− /n) rather than (1− e− ), greatly reducing the scale of achievable profits and thus making the mechanism impractical in most settings.\nLoosely speaking, the extra factor of L/U stems from the fact that a bettor’s effect on the profit of any other bettor must be roughly the same whether he wagers the maximum amount or the minimum. The poor dependence on n is slightly more subtle. We created a private-belief mechanism by replacing each bettor j’s score s(pj , ω) in the WSWM with a random variable xj(pj , ω) that is -differentially private in pj . To obtain private wagers, we would instead need to replace the full term mjs(pj , ω)/ ∑ k∈N mk with a random variable for each j. This term depends on the wagers of all n bettors in addition to pj . Since each bettor’s profit would depend on n such random variables, achieving -joint differential privacy would require that each random variable be /n-differentially private in each bettor’s wager.\nWe believe that sacrifices in sensitivity are unavoidable and not merely an artifact of our techniques and analysis, but leave a formal lower bound to future work."
    }, {
      "heading" : "4 Limits of Privacy with Cost-Function Market Makers",
      "text" : "In practice, prediction markets are often run using dynamic mechanisms that update in real time as new information surfaces. We now turn to the problem of adding privacy guarantees to continuous-trade markets. We focus our attention on cost-function prediction markets, in which all trades are placed through an automated market maker [Hanson, 2003, Chen and Pennock, 2007, Abernethy et al., 2013]. The market maker can be viewed as a streaming algorithm that takes as input a stream of trades and outputs a corresponding stream of market states from which trade prices can be computed. Therefore, the privacy guarantees we seek are in the form of Definition 3. We ask whether it is possible for the automated market maker to price trades according to a cost function while maintaining (t)-differential privacy without opening up the opportunity for traders to earn unbounded profits, leading the market maker to experience unbounded loss. We show a mostly negative result: to achieve bounded loss, the privacy term e (t) must grow faster than linearly in t, the number of rounds of trade.\nFor simplicity, we state our results for markets over a single binary security, though we believe they extend to cost-function markets over arbitrary security spaces."
    }, {
      "heading" : "4.1 Standard cost-function market makers",
      "text" : "We consider a setting in which there is a single binary security that traders may buy or sell. After the outcome ω ∈ {0, 1} has been revealed, a share of the security is worth $1 if ω = 1 and $0 otherwise. A cost-function prediction market for this security is fully specified by a convex function C called the cost function. Let xt be the number of shares that are bought or sold by a trader in the tth transaction; positive values of xt represent purchases while negative values represent (short) sales. The market state\nafter the first t − 1 trades is summarized by a single value qt = ∑t−1 τ=1 xτ , and the tth trader is charged C(qt + xt) − C(qt) = C(qt+1) − C(qt). Thus the cost function can be viewed as a potential function, with C(qt+1)−C(0) capturing the amount of money that the market maker has collected from the first t trades. The instantaneous price at round t, denoted pt, is the price per share of purchasing an infinitesimally small quantity of shares: pt = C\n′(qt). This framework is summarized in Algorithm 3. The most common cost-function market maker is Hanson’s log market scoring rule (LMSR) [Hanson, 2003]. The cost function for the single-security version of LMSR can be written as C(q) = b log(e(q+a)/b + 1) where b > 0 is a parameter controlling the rate at which prices change as trades are made and a controls the initial market price at state q = 0. The instantaneous price at any state q is C ′(q) = e(q+a)/b/(e(q+a)/b + 1).\nUnder mild conditions on C, all cost-function market makers satisfy several desirable properties, including natural notions of no-arbitrage and information incorporation [Abernethy et al., 2013]. We refer to any cost function C satisfying these mild conditions as a standard cost function. Although the market maker subsidizes trade, crucially its worst-case loss is bounded. This ensures that the market maker does not go bankrupt, even if traders are perfectly informed. Formally, there exists a finite bound B such that for any T , any sequence of trades x1, . . . , xT , and any outcome ω ∈ {0, 1},\nqT+1 · 1(ω = 1)− (C(qT+1)− C(0)) ≤ B,\nAlgorithm 3 Cost-function market maker (parameters: cost function C)\nInitialize: q1 = 0 for t = 1, 2, . . . do\nUpdate instantaneous price pt = C ′(qt) A trader buys xt ∈ R shares and pays C(qt + xt)− C(qt) Update market state qt+1 = qt + xt\nend for Realize outcome ω if ω = 1 then\nfor t = 1, 2, . . . do Market maker pays xt to the trader from round t\nend for end if\nwhere 1 is the indicator function that is 1 if its argument is true and 0 otherwise. The first term on the left-hand side is the amount that the market maker must pay (or collect from) traders when ω is revealed. The second is the amount collected from traders. For the LMSR with initial price p1 = 0.5 (a = 0), the worst-case loss is b log(2)."
    }, {
      "heading" : "4.2 The noisy cost-function market maker",
      "text" : "Clearly the standard cost-function market maker does not ensure differential privacy. The amount that a trader pays is a function of the market state, the sum of all past trades. Thus anyone observing the stream of market prices could infer the exact sequence of past trades. To guarantee privacy while still approximating cost-function pricing, the marker maker would need to modify the sequence of published prices (or equivalently, market states) to ensure that such information leakage does not occur.\nIn this section, we define and analyze a noisy cost-function market maker. The noisy market maker prices trades according to a cost function, but uses a noisy version of the market state in order to mask the effect of past trades. In particular, the market maker maintains a noisy market state q′t = qt + ηt, where qt is the true sum of trades and ηt is a (random) noise term. The cost of trade xt is C(q ′ t + xt) − C(q′t), with the instantaneous price now pt = C ′(q′t). Since the noise term ηt must be large enough to mask the trade xt, we limit trades to be some maximum size k. A trader who would like to buy or sell more than k shares must do this over multiple rounds. The full modified framework is shown in Algorithm 4. For now we allow the noise distribution D to depend arbitrarily on the history of trade. This framework is general; the natural adaptation of the privacy-preserving data market of Waggoner et al. [2015] to the single security prediction market setting would result in a market maker of this form, as would a cost-function market that used existing private streaming techniques for bit counting [Chan et al., 2011, Dwork et al., 2010] to keep noisy, private counts of trades.\nIn this framework, we can interpret the market maker as implementing a noise trader in a standard costfunction market. Under this interpretation, after a (real) trader purchases xt shares at state q ′ t, the market state momentarily moves to q′t+xt = qt+ηt+xt = qt+1+ηt. The market maker, acting as a noise trader, then effectively “purchases” ηt+1−ηt shares at this state for a cost of C((qt+1 +ηt)+(ηt+1−ηt))−C(qt+1 +ηt) = C(qt+1 +ηt+1)−C(qt+1 +ηt), bringing the market state to qt+1 +ηt+1 = q′t+1. The market maker makes this trade regardless of the impact on its own loss. These noise trades obscure the trades made by real traders, opening up the possibility of privacy.\nHowever, these noisy trades also open up the opportunity for traders to profit off of the noise. For the market to be practical, it is therefore important to ensure that the property of bounded worst-case loss is maintained. For the noisy cost-function market maker, for any sequence of T trades x1, . . . , xT , any outcome\nAlgorithm 4 Noisy cost-function market maker (parameters: cost function C, distribution D over noise {ηt}, maximum trade size k)\nInitialize: q1 = 0 Draw η1 and set q ′ 1 = η1 for t = 1, 2, . . . do Update instantaneous price pt = C\n′(q′t) A trader buys xt ∈ [−k, k] shares and pays C(q′t + xt)− C(q′t) Update true market state qt+1 = qt + xt Draw ηt+1 and update noisy market state q ′ t+1 = qt+1 + ηt+1\nend for Realize outcome ω if ω = 1 then\nfor t = 1, 2, . . . do Market maker pays xt to the trader from round t\nend for end if\nω ∈ {0, 1}, and any fixed noise values η1, . . . , ηT , the loss of the market maker is\nLT (x1, . . . , xT , η1, . . . , ηT , ω) ≡ qT+1 · 1(ω = 1)− T∑ t=1 (C(q′t + xt)− C(q′t)) .\nAs before, the first term is the (possibly negative) amount that the market maker pays to traders when ω is revealed, and the second is the amount collected from traders (which no longer telescopes). Unfortunately, we cannot expect this loss to be bounded for any noise values; the market maker could always get extremely unlucky and draw noise values that traders can exploit. Instead, we consider a relaxed version of bounded loss which holds in expectation with respect to the noise values ηt.\nIn addition to this relaxation, one more modification is necessary. Note that traders can (and should) base their actions on the current market price. Therefore, if our loss guarantee only holds in expectation with respect to noise values ηt, then it is no longer sufficient to give a guarantee that is worst case over any sequences of trades. Instead, we allow the sequence of trades to depend on the realized noise, introducing a game between traders and the market maker. To formalize this, we imagine allowing an adversary to control the traders. We define the notion of a strategy for this adversary.\nDefinition 6 (Trader strategy). A trader strategy s is a set of (possibly randomized) functions s = {s1, s2, . . .}, with each st mapping a history of trades and noisy market states (x1, . . . , xt−1, q′1, . . . , q′t) to a new trade xt for the trader at round t.\nLet S be the set of all strategies. With this definition in place, we can formally define what it means for a noisy cost-function market maker to have bounded loss.\nDefinition 7 (Bounded loss for a noisy cost-function market maker). A noisy cost-function market maker with cost function C and distribution D over noise values η1, η2, . . . is said to have bounded loss if there exists a finite B such that for all strategies s ∈ S, all times T ≥ 1, and all ω ∈ {0, 1},\nE [LT (x1, . . . , xT , η1, . . . , ηT , ω)] ≤ B,\nwhere the expectation is taken over the market’s noise values η1, η2, . . . distributed according to D and the (possibly randomized) actions x1, x2, . . . of a trader employing strategy s. In this case, the loss of the market maker is said to be bounded by B. The noisy cost-function market maker has unbounded loss if no such B exists.\nIf the noise values were deterministic, this definition of worst-case loss would correspond to the usual one, but because traders react intelligently to the specific realization of noise, we must define worst-case loss in game-theoretic terms."
    }, {
      "heading" : "4.3 Limitations on privacy",
      "text" : "By effectively acting as a noise trader, a noisy cost-function market maker can partially obscure trades. Unfortunately, the amount of privacy achievable through this technique is limited. In this section, we show that in order to simultaneously maintain bounded loss and achieve (t)-differential privacy, the quantity e (t) must grow faster than linearly as a function of the number of rounds of trade. Before stating our result, we explain how to frame the market maker setup in the language of differential privacy. Recall from Section 2 that a differentially private unbounded streaming algorithm M takes as input a stream σ of arbitrary length and outputs a stream of values that depend on σ in a differentially private way. In the market setting, the stream σ corresponds to the sequence of trades x = (x1, x2, . . .). We think of the noisy cost-function market maker (Algorithm 4) as an algorithm M that, on any stream prefix (x1, . . . , xt), outputs the noisy market states (q ′ 1, . . . , q ′ t+1).\n2 The goal is to find a market maker such that M is (t)-differentially private.\nOne might ask whether it is necessary to allow the privacy guarantee to diminish as the the number of trades grows. When considering the problem of calculating noisy sums of bit streams, for example, Chan et al. [2011] are able to maintain a fixed privacy guarantee as their stream grows in length by instead allowing the accuracy of their counts to diminish. This approach doesn’t work for us; we cannot achieve bounded loss yet allow the market maker’s loss to grow with the number of trades.\nOur result relies on one mild assumption on the distribution D over noise. In particular, we require that the noise ηt+1 be chosen independent of the current trade xt.\n3 We refer to this as the trade-independent noise assumption. The distribution of ηt+1 may still depend on the round t, the history of trade x1, . . . , xt−1, and the realizations of past noise terms, η1, . . . , ηt. This assumption is needed in the proof only to rule out unrealistic market makers that are specifically designed to monitor and infer the behavior of the specific adversarial trader that we consider, and the result likely holds even without it. However, it is not a terribly restrictive assumption as most standard ways of generating noise could be written in this form. For example, Chan et al. [2011] and Dwork et al. [2010] show how to maintain a noisy count of the number of ones in a stream of bits. Both achieve this by computing the exact count and adding noise that is correlated across time but independent of the data. If similar ideas were used to choose the noise term in our setting, the trade-independent noise assumption would be satisfied. The noise employed in the mechanism of Waggoner et al. [2015] also satisfies this assumption. Our impossibility result then implies that their market would have unbounded loss if a limit on the number of rounds of trade were not imposed. To obtain privacy guarantees, Waggoner et al. must assume that the number of trades is known in advance and can therefore be used to set relevant market parameters.\nWe now state the main result.\nTheorem 4. Consider any noisy cost-function market maker using a standard convex cost function C that is nonlinear in some region, a noise distribution D satisfying the trade-independent noise assumption, and a bound k > 0 on trade size. If the market maker satisfies bounded loss, then it cannot satisfy ( (t), δ)differential privacy for any function such that e (t) = O(t) with any constant δ ∈ [0, 1).\nThis theorem rules out bounded loss with (t) = log(mt) for any constant m > 0. It is open whether it is possible to achieve (t) = m log(t) (and therefore e (t) = tm) for some m > 1, but such a guarantee would likely be insufficient in most practical settings.\nNote that with unbounded trade size (i.e., k = ∞), our result would be trivial. A trader could change the market state (and hence the price) by an arbitrary amount in a single trade. To provide differential privacy, the noisy market state would then have to be independent of past trades. The noisy market price would not be reflective of trader beliefs, and the noise added could be easily exploited by traders to improve their profits. By imposing a bound on trade size, we only strengthen our negative result.\n2Announcing q′t allows traders to infer the instantaneous price pt = C ′(q′t). It is equivalent to announcing pt in terms of information revealed as long as C is strictly convex in the region around q′t. 3The proof can be extended easily to the more general case in which the calculation of ηt+1 is differentially private in xt; we make the slightly stronger assumption to simplify presentation.\nWhile the proof of Theorem 4 is quite technical, the intuition is simple. We consider the behavior of the noisy cost-function market maker when there is a single trader trading in the market repeatedly using a simple trading strategy. This trader chooses a target state q∗. Whenever the noisy market state q′t is less than q∗ (and so pt < p\n∗ ≡ C ′(q∗)), the trader purchases shares, pushing the market state as close to q∗ as possible. When the noisy state q′t is greater than q ∗ (so pt > p ∗), the trader sells shares, again pushing the state as close as possible to q∗. Each trade makes a profit for the trader in expectation if it were the case that ω = 1 with probability p∗. Since there is only a single trader, this means that each such trade would result in an expected loss with respect to p∗ for the market maker. Unbounded expected loss for any p∗ implies unbounded loss in the worst case—either when ω = 0 or ω = 1. The crux of the proof involves showing that in order achieve bounded loss against this trader, the amount of added noise ηt cannot be too big as t grows, resulting in a sacrifice of privacy.\nTo formalize this intuition, we first give a more precise description of the strategy s∗ employed by the single trader we consider.\nDefinition 8 (Target strategy). The target strategy s∗ with target q∗ ∈ R chosen from a region in which C is nonlinear is defined as follows. For all rounds t,\ns∗t (x1, . . . , xt−1, q ′ 1, . . . , q ′ t) = { min{q∗ − q′t, k} if q′t ≤ q∗, −min{q′t − q∗, k} otherwise.\nAs described above, if ω = 1 with probability p∗, a trader following this target strategy makes a nonnegative expected profit on every round of trade. Furthermore, this trader makes an expected profit of at least some constant χ > 0 on each round in which the noisy market state q′t is more than a constant distance γ from q∗. The market maker must subsidize this profit, taking an expected loss with respect to p∗ on each round. These ideas are formalized in Lemma 2, which lower bounds the expected loss of the market maker in terms of the probability of q′t falling far from q ∗. In this statement, DC denotes the Bregman divergence 4 of C. The proof is in the appendix.\nLemma 2. Consider a noisy cost-function market maker satisfying the conditions in Theorem 4 with a single trader following the target strategy s∗ with target q∗. Suppose ω = 1 with probability p∗ = C ′(q∗). Then for any γ such that 0 < γ ≤ k,\nE [LT (x1, . . . , xT , η1, . . . , ηT , ω)] ≥ χ T∑ t=1 Pr(|q′t − q∗| ≥ γ)\nwhere the expectation and probability are taken over the randomness in the noise values η1, η2, . . ., the resulting actions x1, x2, . . . of the trader, and the random outcome ω, and where χ = min{DC(q∗+γ, q∗), DC(q∗− γ, q∗)} > 0.\nWe now complete the proof.\nProof of Theorem 4. We will show that bounded loss implies that ( (t), δ)-differential privacy cannot be achieved with e (t) = O(t) for any constant δ ∈ [0, 1).\nThroughout the proof, we reason about the probabilities of various events conditioned on there being a single trader playing a particular strategy. All strategies we consider are deterministic, so all probabilities are taken just with respect to the randomness in the market maker’s added noise (η1, η2, . . .).\nAs described above, we focus on the case in which a single trader plays the target strategy s∗ with target q∗. Define R∗ to be the open region of radius k/4 around q∗, that is, R∗ = (q∗ − k/4, q∗ + k/4). Let q̂ = q∗ + k/2 and let R̂ = (q̂ − k/4, q̂ + k/4). Notice that R∗ and R̂ do not intersect, but from any market state q ∈ R∗ a trader could move the market state to q̂ with a purchase or sale of no more than k shares.\n4The Bregman divergence of a convex function F of a single variable is defined as DF (p, q) = F (p) − F (q) − F ′(q)(p − q). The Bregman divergence is always non-negative. If F is strictly convex, it is strictly positive when the arguments are not equal.\nFor any round t, let st be the strategy in which stτ = s ∗ τ for all rounds τ 6= t, but stt(x1, . . . , xt−1, q′1, . . . , q′t) =\nq̂ − q′t if |q̂ − q′t| ≤ k (otherwise, stt can be defined arbitrarily). In other words, a trader playing strategy st behaves identically to a trader playing strategy s∗ on all rounds except round t. On round t, the trader instead attempts to move the market state to q̂.\nFor any t, the behavior of a trader playing strategy s∗ and a trader playing strategy st are indistinguishable through round t− 1, and therefore the behavior of the market maker is indistinguishable as well. At round t, if it is the case that q′t ∈ R∗ (and therefore |q′t− q∗| ≤ k/4 < k and also |q′t− q̂| ≤ 3k/4 < k), then a trader playing strategy s∗ would purchase q∗ − q′t shares, while a trader playing strategy st would purchase q̂ − q′t. Differential privacy tells us that conditioned on such a state being reached, the probability that q′t+1 lies in any range (and in particular, in R∗) should not be too different depending on which of the two actions the trader takes. More formally, if the market maker satisfies (t)-differential privacy, then for all rounds t,\ne (t) ≥ Pr(q′t+1 ∈ R∗|s = s∗, q′t ∈ R∗)− δ\nPr(q′t+1 ∈ R∗|s = st, q′t ∈ R∗) ≥ Pr(q′t+1 ∈ R∗|s = s∗, q′t ∈ R∗)− δ Pr(q′t+1 6∈ R̂|s = st, q′t ∈ R∗)\n= Pr(q′t+1 ∈ R∗|s = s∗, q′t ∈ R∗)− δ\nPr(q′t+1 6∈ R∗|s = s∗, q′t ∈ R∗) .\nThe first inequality follows from the definition of ( (t), δ)-differential privacy. The second follows from the fact that R∗ and R̂ are disjoint. The last line is a consequence of the trade-independent noise assumption. By simple algebraic manipulation, for all t,\nPr(q′t+1 6∈ R∗|s = s∗, q′t ∈ R∗) ≥ 1− δ\n1 + e (t) . (1)\nWe now further investigate the term on the left-hand side of this equation. For the remainder of the proof, we assume that s = s∗ and implicitly condition on this.\nApplying Lemma 2 with γ = k/4, we find that the expected value of the market maker’s loss after T rounds if ω = 1 with probability p∗ = C ′(q∗) is lower bounded by χ ∑T t=1 Pr(q ′ t 6∈ R∗) for the appropriate constant χ.\nThis implies that for at least one of ω = 1 or ω = 0, E [LT (x1, . . . , xT , η1, . . . , ηT , ω)] ≥ χ ∑T t=1 Pr(q ′ t 6∈ R∗) where the expectation is just over the random noise of the market maker and the resulting actions of the trader. Since we have assumed that the market maker’s loss is bounded, this implies there must exist some loss bound B such that\nB χ ≥ ∞∑ t=1 Pr(q′t 6∈ R∗). (2)\nFix any constant α ∈ (0, 1). Equation 2 implies that for all but finitely many t, Pr(q′t 6∈ R∗) < α, or equivalently, for all but finitely many t, Pr(q′t ∈ R∗) ≥ 1 − α. Call the set of t for which this holds T . Equation 2 also implies that\nB χ ≥ ∞∑ t=1 [ Pr(q′t+1 6∈ R∗|q′t ∈ R∗)Pr(q′t ∈ R∗) + Pr(q′t+1 6∈ R∗|q′t 6∈ R∗)Pr(q′t 6∈ R∗) ] ≥ ∞∑ t=1 Pr(q′t+1 6∈ R∗|q′t ∈ R∗)Pr(q′t ∈ R∗) ≥ (1− α) ∑ t∈T Pr(q′t+1 6∈ R∗|q′t ∈ R∗).\nCombining this with Equation 1 yields∑ t∈T 1− δ 1 + e (t) ≤ B χ(1− α) . (3)\nNow suppose for contradiction that e (t) = O(t). Then by definition, for some constant m > 1 there exists a round τ such that for all t > τ , e (t) ≤ mt. Then∑\nt∈T\n1− δ 1 + e (t)\n≥ ∑\nt∈T ,t>τ\n1− δ 1 + e (t)\n≥ ∑\nt∈T ,t>τ\n1− δ 1 +mt > 1− δ m ∑ t∈T ,t>τ 1 1 + t .\nSince this sum is over all natural numbers t except a finite number, it must diverge, and therefore Equation 3 cannot hold. Therefore, we cannot have e (t) = O(t)."
    }, {
      "heading" : "5 Discussion",
      "text" : "We designed a class of randomized wagering mechanisms that keep bettors’ reports private while maintaining truthfulness, budget balance in expectation, and other desirable properties of weighted score wagering mechanisms. The parameters of our mechanisms can be tuned to achieve a tradeoff between the level of privacy guaranteed and the sensitivity of a bettor’s payment to her own report. Determining how to best make this tradeoff in practice (and more generally, what level of privacy is acceptable in differentially private algorithms) is an open empirical question.\nWhile our results in the dynamic setting are negative, there are several potential avenues for circumventing our lower bound. The lower bound shows that it is not possible to obtain reasonable privacy guarantees using a noisy cost-function market maker when traders may buy or sell fractional security shares, as is typically assumed in the cost function literature. Indeed, the adversarial trader we consider buys and sells arbitrarily small fractions when the market state is close to its target. This behavior could be prevented by enforcing a minimum unit of purchase. Perhaps cleverly designed noise could allow us to avoid the lower bound with this additional restriction. However, based on preliminary simulations of a noisy cost-function market based on Hanson’s LMSR 2003 with noise drawn using standard binary streaming approaches [Dwork et al., 2010, Chan et al., 2011], it appears an adversary can still cause a market maker using these “standard” techniques to have unbounded loss by buying one unit when the noisy market state is below the target and selling one unit when it is above.\nOne could also attempt to circumvent the lower bound by adding a transaction fee for each trade that is large enough that traders cannot profit off the market’s noise. While the fee could always be set large enough to guarantee bounded loss, a large fee would discourage trade in the market and limit its predictive power. A careful analysis would be required to ensure that the fee could be set high enough to maintain bounded loss without rendering the market predictions useless."
    } ],
    "references" : [ {
      "title" : "Efficient market making via convex optimization, and a connection to online learning",
      "author" : [ "Jacob Abernethy", "Yiling Chen", "Jennifer Wortman Vaughan" ],
      "venue" : "ACM Transactions on Economics and Computation,",
      "citeRegEx" : "Abernethy et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Abernethy et al\\.",
      "year" : 2013
    }, {
      "title" : "Hanson’s automated market maker",
      "author" : [ "Henry Berg", "Todd A. Proebsting" ],
      "venue" : "Journal of Prediction Markets,",
      "citeRegEx" : "Berg and Proebsting.,? \\Q2009\\E",
      "shortCiteRegEx" : "Berg and Proebsting.",
      "year" : 2009
    }, {
      "title" : "Results from a dozen years of election futures markets research",
      "author" : [ "Joyce E. Berg", "Robert Forsythe", "Forrest D. Nelson", "Thomas A. Rietz" ],
      "venue" : "Handbook of Experimental Economic Results",
      "citeRegEx" : "Berg et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Berg et al\\.",
      "year" : 2001
    }, {
      "title" : "Verification of forecasts expressed in terms of probability",
      "author" : [ "Glenn W. Brier" ],
      "venue" : "Monthly Weather Review,",
      "citeRegEx" : "Brier.,? \\Q1950\\E",
      "shortCiteRegEx" : "Brier.",
      "year" : 1950
    }, {
      "title" : "Private and continual release of statistics",
      "author" : [ "T.-H. Hubert Chan", "Elaine Shi", "Dawn Song" ],
      "venue" : "ACM Transactions on Information and System Security,",
      "citeRegEx" : "Chan et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Chan et al\\.",
      "year" : 2011
    }, {
      "title" : "An internal futures market",
      "author" : [ "Robert Charette" ],
      "venue" : "Information Management,",
      "citeRegEx" : "Charette.,? \\Q2007\\E",
      "shortCiteRegEx" : "Charette.",
      "year" : 2007
    }, {
      "title" : "A utility framework for bounded-loss market makers",
      "author" : [ "Yiling Chen", "David M. Pennock" ],
      "venue" : "In Proc. of the Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Chen and Pennock.,? \\Q2007\\E",
      "shortCiteRegEx" : "Chen and Pennock.",
      "year" : 2007
    }, {
      "title" : "Removing arbitrage from wagering mechanisms",
      "author" : [ "Yiling Chen", "Nikhil R. Devanur", "David M. Pennock", "Jennifer Wortman Vaughan" ],
      "venue" : "In Proceedings of the 15th ACM Conference on Economics and Computation,",
      "citeRegEx" : "Chen et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2014
    }, {
      "title" : "Corporate prediction markets: Evidence from google, ford, and firm x",
      "author" : [ "Bo Cowgill", "Eric Zitzewitz" ],
      "venue" : "Review of Economic Studies,",
      "citeRegEx" : "Cowgill and Zitzewitz.,? \\Q2015\\E",
      "shortCiteRegEx" : "Cowgill and Zitzewitz.",
      "year" : 2015
    }, {
      "title" : "The algorithmic foundations of differential privacy",
      "author" : [ "Cynthia Dwork", "Aaron Roth" ],
      "venue" : "Foundations and Trends in Theoretical Comp. Sci.,",
      "citeRegEx" : "Dwork and Roth.,? \\Q2014\\E",
      "shortCiteRegEx" : "Dwork and Roth.",
      "year" : 2014
    }, {
      "title" : "Calibrating noise to sensitivity in private data analysis",
      "author" : [ "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith" ],
      "venue" : "In Proceedings of the 3rd Conference on Theory of Cryptography,",
      "citeRegEx" : "Dwork et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2006
    }, {
      "title" : "Differential privacy under continual observation",
      "author" : [ "Cynthia Dwork", "Moni Naor", "Toniann Pitassi", "Guy N. Rothblum" ],
      "venue" : "In Proceedings of the 42nd ACM Symposium on Theory of Computing,",
      "citeRegEx" : "Dwork et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2010
    }, {
      "title" : "Informed traders and price variations in the betting market for professional basketball games",
      "author" : [ "John M. Gandar", "William H. Dare", "Craig R. Brown", "Richard A. Zuber" ],
      "venue" : "Journal of Finance,",
      "citeRegEx" : "Gandar et al\\.,? \\Q1999\\E",
      "shortCiteRegEx" : "Gandar et al\\.",
      "year" : 1999
    }, {
      "title" : "Strictly proper scoring rules, prediction, and estimation",
      "author" : [ "Tilmann Gneiting", "Adrian E. Raftery" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Gneiting and Raftery.,? \\Q2007\\E",
      "shortCiteRegEx" : "Gneiting and Raftery.",
      "year" : 2007
    }, {
      "title" : "On the efficiency of competitive stock markets where traders have diverse information",
      "author" : [ "Sanford J. Grossman" ],
      "venue" : "The Journal of Finance,",
      "citeRegEx" : "Grossman.,? \\Q1976\\E",
      "shortCiteRegEx" : "Grossman.",
      "year" : 1976
    }, {
      "title" : "Combinatorial information market design",
      "author" : [ "Robin Hanson" ],
      "venue" : "Information Systems Frontiers,",
      "citeRegEx" : "Hanson.,? \\Q2003\\E",
      "shortCiteRegEx" : "Hanson.",
      "year" : 2003
    }, {
      "title" : "Private matchings and allocations",
      "author" : [ "Justin Hsu", "Zhiyi Huang", "Aaron Roth", "Tim Roughgarden", "Zhiwei Steven Wu" ],
      "venue" : "In Proceedings of the 46th Annual ACM Symposium on Theory of Computing,",
      "citeRegEx" : "Hsu et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Hsu et al\\.",
      "year" : 2014
    }, {
      "title" : "Mechanism design in large games: Incentives and privacy",
      "author" : [ "Michael Kearns", "Mallesh Pai", "Aaron Roth", "Jonathan Ullman" ],
      "venue" : "In Proceedings of the 5th Conference on Innovations in Theoretical Computer Science,",
      "citeRegEx" : "Kearns et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Kearns et al\\.",
      "year" : 2014
    }, {
      "title" : "Self-financed wagering mechanisms for forecasting",
      "author" : [ "Nicolas S. Lambert", "John Langford", "Jennifer Wortman", "Yiling Chen", "Daniel Reeves", "Yoav Shoham", "David M. Pennock" ],
      "venue" : "In Proceedings of the 9th ACM Conference on Electronic Commerce,",
      "citeRegEx" : "Lambert et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Lambert et al\\.",
      "year" : 2008
    }, {
      "title" : "An axiomatic characterization of wagering mechanisms",
      "author" : [ "Nicolas S. Lambert", "John Langford", "Jennifer Wortman Vaughan", "Yiling Chen", "Daniel Reeves", "Yoav Shoham", "David M. Pennock" ],
      "venue" : "Journal of Economic Theory,",
      "citeRegEx" : "Lambert et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lambert et al\\.",
      "year" : 2015
    }, {
      "title" : "Privacy integrated queries: An extensible platform for privacy-preserving data analysis",
      "author" : [ "Frank McSherry" ],
      "venue" : "In Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data,",
      "citeRegEx" : "McSherry.,? \\Q2009\\E",
      "shortCiteRegEx" : "McSherry.",
      "year" : 2009
    }, {
      "title" : "The real power of artificial",
      "author" : [ "David M. Pennock", "Steve Lawrence", "C. Lee Giles", "Finn A. Nielsen" ],
      "venue" : "markets. Science,",
      "citeRegEx" : "Pennock et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Pennock et al\\.",
      "year" : 2002
    }, {
      "title" : "Information aggregation mechanisms: Concept, design and field implementation",
      "author" : [ "Charles Plott", "Kay-Yut Chen" ],
      "venue" : "California Institute of Technology Social Science Working Paper 1131,",
      "citeRegEx" : "Plott and Chen.,? \\Q2002\\E",
      "shortCiteRegEx" : "Plott and Chen.",
      "year" : 2002
    }, {
      "title" : "Using prediction markets to forecast trends in infectious diseases",
      "author" : [ "Philip M. Polgreen", "Forrest D. Nelson", "George R. Neumann" ],
      "venue" : "Clinical Infectious Diseases,",
      "citeRegEx" : "Polgreen et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Polgreen et al\\.",
      "year" : 2007
    }, {
      "title" : "Orange juice and weather",
      "author" : [ "Richard Roll" ],
      "venue" : "The American Economic Review,",
      "citeRegEx" : "Roll.,? \\Q1984\\E",
      "shortCiteRegEx" : "Roll.",
      "year" : 1984
    }, {
      "title" : "Elicitation of personal probabilities and expectations",
      "author" : [ "Leonard J. Savage" ],
      "venue" : "Journal of the American Statistical Association,",
      "citeRegEx" : "Savage.,? \\Q1971\\E",
      "shortCiteRegEx" : "Savage.",
      "year" : 1971
    }, {
      "title" : "Anomalies: Parimutuel betting markets: Racetracks and lotteries",
      "author" : [ "Richard H. Thaler", "William T. Ziemba" ],
      "venue" : "J. of Economic Perspectives,",
      "citeRegEx" : "Thaler and Ziemba.,? \\Q1988\\E",
      "shortCiteRegEx" : "Thaler and Ziemba.",
      "year" : 1988
    }, {
      "title" : "A market framework for eliciting private data",
      "author" : [ "Bo Waggoner", "Rafael Frongillo", "Jacob Abernethy" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "Waggoner et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Waggoner et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 14,
      "context" : "Betting markets of various forms—including the stock exchange [Grossman, 1976], futures markets [Roll, 1984], sports betting markets [Gandar et al.",
      "startOffset" : 62,
      "endOffset" : 78
    }, {
      "referenceID" : 24,
      "context" : "Betting markets of various forms—including the stock exchange [Grossman, 1976], futures markets [Roll, 1984], sports betting markets [Gandar et al.",
      "startOffset" : 96,
      "endOffset" : 108
    }, {
      "referenceID" : 12,
      "context" : "Betting markets of various forms—including the stock exchange [Grossman, 1976], futures markets [Roll, 1984], sports betting markets [Gandar et al., 1999], and markets at the racetrack [Thaler and Ziemba, 1988]—have been shown to successfully collect and aggregate information.",
      "startOffset" : 133,
      "endOffset" : 154
    }, {
      "referenceID" : 26,
      "context" : ", 1999], and markets at the racetrack [Thaler and Ziemba, 1988]—have been shown to successfully collect and aggregate information.",
      "startOffset" : 38,
      "endOffset" : 63
    }, {
      "referenceID" : 2,
      "context" : "Over the last few decades, prediction markets designed specifically for the purpose of elicitation and aggregation, have yielded useful predictions in domains as diverse as politics [Berg et al., 2001], disease surveillance [Polgreen et al.",
      "startOffset" : 182,
      "endOffset" : 201
    }, {
      "referenceID" : 23,
      "context" : ", 2001], disease surveillance [Polgreen et al., 2007], and entertainment [Pennock et al.",
      "startOffset" : 30,
      "endOffset" : 53
    }, {
      "referenceID" : 21,
      "context" : ", 2007], and entertainment [Pennock et al., 2002].",
      "startOffset" : 27,
      "endOffset" : 49
    }, {
      "referenceID" : 22,
      "context" : "create incentives for individuals not to reveal their information” [Plott and Chen, 2002].",
      "startOffset" : 67,
      "endOffset" : 89
    }, {
      "referenceID" : 13,
      "context" : "[2008] showed that the class of weighted score wagering mechanisms, which are built on the machinery of proper scoring rules [Gneiting and Raftery, 2007], is the unique set of wagering mechanisms to satisfy a set of desired properties such as budget balance, truthfulness, and anonymity.",
      "startOffset" : 125,
      "endOffset" : 153
    }, {
      "referenceID" : 15,
      "context" : ", 2013] such as Hanson’s popular logarithmic market scoring rule [Hanson, 2003].",
      "startOffset" : 65,
      "endOffset" : 79
    }, {
      "referenceID" : 0,
      "context" : "GE, Siemens, and others have engaged in similar experiments [Berg and Proebsting, 2009, Charette, 2007, Cowgill and Zitzewitz, 2015]. Proponents of internal corporate markets often argue that the market structure helps in part because, without it, “business practices... create incentives for individuals not to reveal their information” [Plott and Chen, 2002]. However, even with a formal market structure in place, an employee might be hesitant to bet against the success of their team for fear of insulting her coworkers or angering management. If an employee has information that is unfavorable to the company, she might choose not to report it, leading to predictions that are overly optimistic for the company and ultimately contributing to an “optimism bias” in the market similar to the bias in Google’s corporate markets discovered by Cowgill and Zitzewitz [2015]. To address this issue, we consider the problem of designing private prediction markets.",
      "startOffset" : 61,
      "endOffset" : 873
    }, {
      "referenceID" : 0,
      "context" : "GE, Siemens, and others have engaged in similar experiments [Berg and Proebsting, 2009, Charette, 2007, Cowgill and Zitzewitz, 2015]. Proponents of internal corporate markets often argue that the market structure helps in part because, without it, “business practices... create incentives for individuals not to reveal their information” [Plott and Chen, 2002]. However, even with a formal market structure in place, an employee might be hesitant to bet against the success of their team for fear of insulting her coworkers or angering management. If an employee has information that is unfavorable to the company, she might choose not to report it, leading to predictions that are overly optimistic for the company and ultimately contributing to an “optimism bias” in the market similar to the bias in Google’s corporate markets discovered by Cowgill and Zitzewitz [2015]. To address this issue, we consider the problem of designing private prediction markets. A private market would allow participants to engage in the market and contribute to the accuracy of the market’s predictions without fear of having their information or beliefs revealed. The goal is to provide participants with a form of “plausible deniability.” Although participants’ trades or wagers should together influence the market’s behavior and predictions, no single participant’s actions should have too much influence over what others can observe. We formalize this idea using the popular notion of differential privacy [Dwork et al., 2006, Dwork and Roth, 2014], which can be used to guarantee that any participant’s actions cannot be inferred from observations. We begin by designing a private analog of the weighted score wagering mechanisms first introduced by Lambert et al. [2008]. A wagering mechanism allows bettors to each specify a belief about the likelihood of a future event and a corresponding monetary wager.",
      "startOffset" : 61,
      "endOffset" : 1762
    }, {
      "referenceID" : 0,
      "context" : "GE, Siemens, and others have engaged in similar experiments [Berg and Proebsting, 2009, Charette, 2007, Cowgill and Zitzewitz, 2015]. Proponents of internal corporate markets often argue that the market structure helps in part because, without it, “business practices... create incentives for individuals not to reveal their information” [Plott and Chen, 2002]. However, even with a formal market structure in place, an employee might be hesitant to bet against the success of their team for fear of insulting her coworkers or angering management. If an employee has information that is unfavorable to the company, she might choose not to report it, leading to predictions that are overly optimistic for the company and ultimately contributing to an “optimism bias” in the market similar to the bias in Google’s corporate markets discovered by Cowgill and Zitzewitz [2015]. To address this issue, we consider the problem of designing private prediction markets. A private market would allow participants to engage in the market and contribute to the accuracy of the market’s predictions without fear of having their information or beliefs revealed. The goal is to provide participants with a form of “plausible deniability.” Although participants’ trades or wagers should together influence the market’s behavior and predictions, no single participant’s actions should have too much influence over what others can observe. We formalize this idea using the popular notion of differential privacy [Dwork et al., 2006, Dwork and Roth, 2014], which can be used to guarantee that any participant’s actions cannot be inferred from observations. We begin by designing a private analog of the weighted score wagering mechanisms first introduced by Lambert et al. [2008]. A wagering mechanism allows bettors to each specify a belief about the likelihood of a future event and a corresponding monetary wager. These wagers are then collected by a centralized operator and redistributed among bettors in such a way that more accurate bettors receive higher rewards. Lambert et al. [2008] showed that the class of weighted score wagering mechanisms, which are built on the machinery of proper scoring rules [Gneiting and Raftery, 2007], is the unique set of wagering mechanisms to satisfy a set of desired properties such as budget balance, truthfulness, and anonymity.",
      "startOffset" : 61,
      "endOffset" : 2076
    }, {
      "referenceID" : 0,
      "context" : "We focus on cost-function prediction markets [Chen and Pennock, 2007, Abernethy et al., 2013] such as Hanson’s popular logarithmic market scoring rule [Hanson, 2003]. In a cost-function market, all trades are placed through an automated market maker, a centralized algorithmic agent that is always willing to buy or sell securities at some current market price that depends on the history of trade via a potential function called the cost function. We ask whether it is possible for a market maker to price trades according to a noisy cost function in a way that maintains traders’ privacy without allowing traders to make unbounded profit off of the noise. Unfortunately, we show that under general assumptions, it is impossible for a market maker to achieve bounded loss and -differential privacy without allowing the privacy guarantee to degrade very quickly as the number of trades grows. In particular, the quantity e must grown faster than linearly in the number of trades, making such markets impractical in settings in which privacy is valued. We suggest several avenues for future research aimed at circumventing this lower bound. There is very little prior work on the design of private prediction markets, and to the best of our knowledge, we are the first to consider privacy for one-shot wagering mechanisms. Most closely related to our work is the recent paper of Waggoner et al. [2015] who consider a setting in which each of a set of selfinterested agents holds a private data point consisting of an observation x and corresponding label y.",
      "startOffset" : 70,
      "endOffset" : 1401
    }, {
      "referenceID" : 10,
      "context" : "We formalize privacy using the now-standard notion of differential privacy, which was introduced by Dwork et al. [2006]. The most basic version of differential privacy is used to measure the privacy of a randomized algorithm’s output when given as input a database D with n entries from some input domain I.",
      "startOffset" : 100,
      "endOffset" : 120
    }, {
      "referenceID" : 10,
      "context" : "Definition 1 (Differential Privacy [Dwork et al., 2006]).",
      "startOffset" : 35,
      "endOffset" : 55
    }, {
      "referenceID" : 17,
      "context" : "To capture this idea, Kearns et al. [2014] defined the notion of joint differential privacy.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 17,
      "context" : "Definition 2 (Joint Differential Privacy [Kearns et al., 2014]).",
      "startOffset" : 41,
      "endOffset" : 62
    }, {
      "referenceID" : 16,
      "context" : "One useful tool for proving joint differential privacy is the billboard lemma [Hsu et al., 2014].",
      "startOffset" : 78,
      "endOffset" : 96
    }, {
      "referenceID" : 13,
      "context" : "One useful tool for proving joint differential privacy is the billboard lemma [Hsu et al., 2014]. The idea behind the billboard lemma is quite intuitive and simple. Imagine that we display some message publicly so that it is viewable by all n agents, as if posted on a billboard, and suppose that the algorithm to compute this message is -differentially private. If each agent i’s output M(D)i is computable from this public message along with i’s own private input, thenM is -joint differentially private. A more formal statement and proof are given in Hsu et al. [2014]. The definitions above assume the input database D is fixed.",
      "startOffset" : 79,
      "endOffset" : 572
    }, {
      "referenceID" : 4,
      "context" : "Differential privacy has also been considered for streaming algorithms [Chan et al., 2011, Dwork et al., 2010]. Let N = {1, 2, 3, . . .}. Following Chan et al. [2011], a stream σ ∈ IN is a string of countable length of elements in I, where σt ∈ I denotes the element at position or time t and σ1,.",
      "startOffset" : 72,
      "endOffset" : 167
    }, {
      "referenceID" : 4,
      "context" : "Differential privacy has also been considered for streaming algorithms [Chan et al., 2011, Dwork et al., 2010]. Let N = {1, 2, 3, . . .}. Following Chan et al. [2011], a stream σ ∈ IN is a string of countable length of elements in I, where σt ∈ I denotes the element at position or time t and σ1,...,t ∈ I is the length t prefix of the stream σ. Two streams σ and σ′ are said to be neighbors if they differ at exactly one time t. A streaming algorithm M is said to be unbounded if it accepts streams of indefinite length, that is, if for any stream σ ∈ IN, M(σ) ∈ RN. In contrast, a streaming algorithm is T -bounded if it accepts only streams of length at most T . Dwork et al. [2010] consider only T -bounded streaming algorithms.",
      "startOffset" : 72,
      "endOffset" : 686
    }, {
      "referenceID" : 4,
      "context" : "Differential privacy has also been considered for streaming algorithms [Chan et al., 2011, Dwork et al., 2010]. Let N = {1, 2, 3, . . .}. Following Chan et al. [2011], a stream σ ∈ IN is a string of countable length of elements in I, where σt ∈ I denotes the element at position or time t and σ1,...,t ∈ I is the length t prefix of the stream σ. Two streams σ and σ′ are said to be neighbors if they differ at exactly one time t. A streaming algorithm M is said to be unbounded if it accepts streams of indefinite length, that is, if for any stream σ ∈ IN, M(σ) ∈ RN. In contrast, a streaming algorithm is T -bounded if it accepts only streams of length at most T . Dwork et al. [2010] consider only T -bounded streaming algorithms. Since we consider unbounded streaming algorithms, we use a more appropriate definition of differential privacy for streams adapted from Chan et al. [2011]. For unbounded streaming algorithms, it can be convenient to let the privacy guarantee degrade as the input stream grows in length.",
      "startOffset" : 72,
      "endOffset" : 888
    }, {
      "referenceID" : 4,
      "context" : "Differential privacy has also been considered for streaming algorithms [Chan et al., 2011, Dwork et al., 2010]. Let N = {1, 2, 3, . . .}. Following Chan et al. [2011], a stream σ ∈ IN is a string of countable length of elements in I, where σt ∈ I denotes the element at position or time t and σ1,...,t ∈ I is the length t prefix of the stream σ. Two streams σ and σ′ are said to be neighbors if they differ at exactly one time t. A streaming algorithm M is said to be unbounded if it accepts streams of indefinite length, that is, if for any stream σ ∈ IN, M(σ) ∈ RN. In contrast, a streaming algorithm is T -bounded if it accepts only streams of length at most T . Dwork et al. [2010] consider only T -bounded streaming algorithms. Since we consider unbounded streaming algorithms, we use a more appropriate definition of differential privacy for streams adapted from Chan et al. [2011]. For unbounded streaming algorithms, it can be convenient to let the privacy guarantee degrade as the input stream grows in length. Chan et al. [2011] implicitly allow this in some of their results; see, for example, Corollary 4.",
      "startOffset" : 72,
      "endOffset" : 1039
    }, {
      "referenceID" : 9,
      "context" : "In fact, it is more typical to require smaller values of δ for larger databases since for a database of size n, an algorithm could be considered ( , δ)-private for δ on the order of 1/n even if it fully reveals a small number of randomly chosen database entries [Dwork and Roth, 2014].",
      "startOffset" : 262,
      "endOffset" : 284
    }, {
      "referenceID" : 18,
      "context" : "Lambert et al. [2008] showed that the class of weighted score wagering mechanisms (WSWMs) is the unique class of wagering mechanisms to satisfy a set of desired axioms such as budget balance and truthfulness.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 18,
      "context" : "Wagering mechanisms, introduced by Lambert et al. [2008], are mechanisms designed to allow a centralized operator to elicit the beliefs of a set of bettors without taking on any risk.",
      "startOffset" : 35,
      "endOffset" : 57
    }, {
      "referenceID" : 18,
      "context" : "Definition 4 (Wagering Mechanism [Lambert et al., 2008]).",
      "startOffset" : 33,
      "endOffset" : 55
    }, {
      "referenceID" : 18,
      "context" : "There are two minor differences between the definition presented here and that of Lambert et al. [2008]. First, for convenience, we use Πi to denote the total profit to bettor i (i.",
      "startOffset" : 82,
      "endOffset" : 104
    }, {
      "referenceID" : 18,
      "context" : "There are two minor differences between the definition presented here and that of Lambert et al. [2008]. First, for convenience, we use Πi to denote the total profit to bettor i (i.e., her payment from the mechanism minus her wager), unlike Lambert et al. [2008], who use Πi to denote the payment only.",
      "startOffset" : 82,
      "endOffset" : 263
    }, {
      "referenceID" : 18,
      "context" : "There are two minor differences between the definition presented here and that of Lambert et al. [2008]. First, for convenience, we use Πi to denote the total profit to bettor i (i.e., her payment from the mechanism minus her wager), unlike Lambert et al. [2008], who use Πi to denote the payment only. While this difference is inconsequential, we mention it to avoid confusion. Second, all previous work on wagering mechanisms has restricted attention to deterministic profit functions Πi. Since randomization is necessary to attain privacy, we open up our study to randomized profit functions. Lambert et al. [2008] defined a set of desirable properties or axioms that deterministic wagering mechanisms should arguably satisfy.",
      "startOffset" : 82,
      "endOffset" : 618
    }, {
      "referenceID" : 17,
      "context" : "1Lambert et al. [2015] and Chen et al.",
      "startOffset" : 1,
      "endOffset" : 23
    }, {
      "referenceID" : 7,
      "context" : "[2015] and Chen et al. [2014] used an alternative definition of normality for wagering mechanisms that essentially requires that if, from some agent i’s perspective, the prediction of agent j improves, then i’s expected profit decreases.",
      "startOffset" : 11,
      "endOffset" : 30
    }, {
      "referenceID" : 25,
      "context" : ", 2015] achieve truthfulness by incorporating strictly proper scoring rules [Savage, 1971] into their profit functions.",
      "startOffset" : 76,
      "endOffset" : 90
    }, {
      "referenceID" : 25,
      "context" : "Definition 5 (Strictly proper scoring rule [Savage, 1971]).",
      "startOffset" : 43,
      "endOffset" : 57
    }, {
      "referenceID" : 3,
      "context" : "One common example is the Brier scoring rule [Brier, 1950], defined as s(p, ω) = 1− (p−ω).",
      "startOffset" : 45,
      "endOffset" : 58
    }, {
      "referenceID" : 3,
      "context" : "One common example is the Brier scoring rule [Brier, 1950], defined as s(p, ω) = 1− (p−ω). Note that for the Brier scoring rule, s(p, x) ∈ [0, 1] for all p and ω. Any strictly proper scoring rule with a bounded range can be scaled to have range [0, 1]. The WSWMs incorporate proper scoring rules, assigning each bettor a profit based on how her score compares to the wager-weighted average score of all bettors, as in Algorithm 1. Lambert et al. [2008] showed that the set of WSWMs satisfy the seven axioms above and is the unique set of deterministic mechanisms that simultaneously satisfy budget balance, anonymity, truthfulness, normality, and sybilproofness.",
      "startOffset" : 26,
      "endOffset" : 453
    }, {
      "referenceID" : 18,
      "context" : "Algorithm 1 Weighted-score wagering mechanisms [Lambert et al., 2008]",
      "startOffset" : 47,
      "endOffset" : 69
    }, {
      "referenceID" : 19,
      "context" : "Note that if bettor i’s report pi is correlated with his wager mi, as might be the case for a Bayesian agent [Lambert et al., 2015], then just knowing mi could reveal information about pi.",
      "startOffset" : 109,
      "endOffset" : 131
    }, {
      "referenceID" : 18,
      "context" : "Note that if bettor i’s report pi is correlated with his wager mi, as might be the case for a Bayesian agent [Lambert et al., 2015], then just knowing mi could reveal information about pi. In this case, differential privacy would guarantee that other bettors can infer no more about pi after observing their profits than they could from observing mi alone. If bettors have immutable beliefs as assumed by Lambert et al. [2008], then reports and wagers are not correlated and mi reveals nothing about pi.",
      "startOffset" : 110,
      "endOffset" : 427
    }, {
      "referenceID" : 9,
      "context" : "A natural first attempt would be to employ the standard Laplace Mechanism [Dwork and Roth, 2014] on top of a WSWM, adding independent Laplace noise to each bettor’s profit.",
      "startOffset" : 74,
      "endOffset" : 96
    }, {
      "referenceID" : 10,
      "context" : "Adding other forms of noise does not help; to obtain differential privacy, the noise must be unbounded [Dwork et al., 2006].",
      "startOffset" : 103,
      "endOffset" : 123
    }, {
      "referenceID" : 18,
      "context" : "Any WSWM satisfies budget balance in expectation (by satisfying budget balance), truthfulness, individual rationality, normality, sybilproofness, and monotonicity Lambert et al. [2008]. Since these properties are defined in terms of expected profit, Lemma 1 implies that the private wagering mechanism satisfies them too.",
      "startOffset" : 163,
      "endOffset" : 185
    }, {
      "referenceID" : 20,
      "context" : "By Theorem 4 of McSherry [2009], the vector (x1(p1, ω), .",
      "startOffset" : 16,
      "endOffset" : 32
    }, {
      "referenceID" : 15,
      "context" : "The most common cost-function market maker is Hanson’s log market scoring rule (LMSR) [Hanson, 2003].",
      "startOffset" : 86,
      "endOffset" : 100
    }, {
      "referenceID" : 0,
      "context" : "Under mild conditions on C, all cost-function market makers satisfy several desirable properties, including natural notions of no-arbitrage and information incorporation [Abernethy et al., 2013].",
      "startOffset" : 170,
      "endOffset" : 194
    }, {
      "referenceID" : 24,
      "context" : "This framework is general; the natural adaptation of the privacy-preserving data market of Waggoner et al. [2015] to the single security prediction market setting would result in a market maker of this form, as would a cost-function market that used existing private streaming techniques for bit counting [Chan et al.",
      "startOffset" : 91,
      "endOffset" : 114
    }, {
      "referenceID" : 4,
      "context" : "When considering the problem of calculating noisy sums of bit streams, for example, Chan et al. [2011] are able to maintain a fixed privacy guarantee as their stream grows in length by instead allowing the accuracy of their counts to diminish.",
      "startOffset" : 84,
      "endOffset" : 103
    }, {
      "referenceID" : 4,
      "context" : "When considering the problem of calculating noisy sums of bit streams, for example, Chan et al. [2011] are able to maintain a fixed privacy guarantee as their stream grows in length by instead allowing the accuracy of their counts to diminish. This approach doesn’t work for us; we cannot achieve bounded loss yet allow the market maker’s loss to grow with the number of trades. Our result relies on one mild assumption on the distribution D over noise. In particular, we require that the noise ηt+1 be chosen independent of the current trade xt. 3 We refer to this as the trade-independent noise assumption. The distribution of ηt+1 may still depend on the round t, the history of trade x1, . . . , xt−1, and the realizations of past noise terms, η1, . . . , ηt. This assumption is needed in the proof only to rule out unrealistic market makers that are specifically designed to monitor and infer the behavior of the specific adversarial trader that we consider, and the result likely holds even without it. However, it is not a terribly restrictive assumption as most standard ways of generating noise could be written in this form. For example, Chan et al. [2011] and Dwork et al.",
      "startOffset" : 84,
      "endOffset" : 1167
    }, {
      "referenceID" : 4,
      "context" : "When considering the problem of calculating noisy sums of bit streams, for example, Chan et al. [2011] are able to maintain a fixed privacy guarantee as their stream grows in length by instead allowing the accuracy of their counts to diminish. This approach doesn’t work for us; we cannot achieve bounded loss yet allow the market maker’s loss to grow with the number of trades. Our result relies on one mild assumption on the distribution D over noise. In particular, we require that the noise ηt+1 be chosen independent of the current trade xt. 3 We refer to this as the trade-independent noise assumption. The distribution of ηt+1 may still depend on the round t, the history of trade x1, . . . , xt−1, and the realizations of past noise terms, η1, . . . , ηt. This assumption is needed in the proof only to rule out unrealistic market makers that are specifically designed to monitor and infer the behavior of the specific adversarial trader that we consider, and the result likely holds even without it. However, it is not a terribly restrictive assumption as most standard ways of generating noise could be written in this form. For example, Chan et al. [2011] and Dwork et al. [2010] show how to maintain a noisy count of the number of ones in a stream of bits.",
      "startOffset" : 84,
      "endOffset" : 1191
    }, {
      "referenceID" : 4,
      "context" : "When considering the problem of calculating noisy sums of bit streams, for example, Chan et al. [2011] are able to maintain a fixed privacy guarantee as their stream grows in length by instead allowing the accuracy of their counts to diminish. This approach doesn’t work for us; we cannot achieve bounded loss yet allow the market maker’s loss to grow with the number of trades. Our result relies on one mild assumption on the distribution D over noise. In particular, we require that the noise ηt+1 be chosen independent of the current trade xt. 3 We refer to this as the trade-independent noise assumption. The distribution of ηt+1 may still depend on the round t, the history of trade x1, . . . , xt−1, and the realizations of past noise terms, η1, . . . , ηt. This assumption is needed in the proof only to rule out unrealistic market makers that are specifically designed to monitor and infer the behavior of the specific adversarial trader that we consider, and the result likely holds even without it. However, it is not a terribly restrictive assumption as most standard ways of generating noise could be written in this form. For example, Chan et al. [2011] and Dwork et al. [2010] show how to maintain a noisy count of the number of ones in a stream of bits. Both achieve this by computing the exact count and adding noise that is correlated across time but independent of the data. If similar ideas were used to choose the noise term in our setting, the trade-independent noise assumption would be satisfied. The noise employed in the mechanism of Waggoner et al. [2015] also satisfies this assumption.",
      "startOffset" : 84,
      "endOffset" : 1582
    } ],
    "year" : 2016,
    "abstractText" : "We consider the design of private prediction markets, financial markets designed to elicit predictions about uncertain events without revealing too much information about market participants’ actions or beliefs. Our goal is to design market mechanisms in which participants’ trades or wagers influence the market’s behavior in a way that leads to accurate predictions, yet no single participant has too much influence over what others are able to observe. We study the possibilities and limitations of such mechanisms using tools from differential privacy. We begin by designing a private one-shot wagering mechanism in which bettors specify a belief about the likelihood of a future event and a corresponding monetary wager. Wagers are redistributed among bettors in a way that more highly rewards those with accurate predictions. We provide a class of wagering mechanisms that are guaranteed to satisfy truthfulness, budget balance in expectation, and other desirable properties while additionally guaranteeing -joint differential privacy in the bettors’ reported beliefs, and analyze the trade-off between the achievable level of privacy and the sensitivity of a bettor’s payment to her own report. We then ask whether it is possible to obtain privacy in dynamic prediction markets, focusing our attention on the popular cost-function framework in which securities with payments linked to future events are bought and sold by an automated market maker. We show that under general conditions, it is impossible for such a market maker to simultaneously achieve bounded worst-case loss and -differential privacy without allowing the privacy guarantee to degrade extremely quickly as the number of trades grows, making such markets impractical in settings in which privacy is valued. We conclude by suggesting several avenues for potentially circumventing this lower bound.",
    "creator" : "LaTeX with hyperref package"
  }
}