{
  "name" : "1401.3468.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Compiling Uncertainty Away in Conformant Planning Problems with Bounded Width",
    "authors" : [ "Hector Palacios", "Hector Geffner" ],
    "emails" : [ "hlp@ldc.usb.ve", "hector.geffner@upf.edu" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Conformant planning is a form of planning where a goal is to be achieved when the initial situation is not fully known and actions may have non-deterministic effects (Goldman & Boddy, 1996; Smith & Weld, 1998). Conformant planning is computationally harder than classical planning, as even under polynomial restrictions on plan length, plan verification remains hard (Haslum & Jonsson, 1999; Baral, Kreinovich, & Trejo, 2000; Turner, 2002; Rintanen, 2004). While few practical problems are purely conformant, the ability to find conformant plans is needed in contingent planning where conformant situations are a special case and where relaxations into conformant planning yield useful heuristics (Hoffmann & Brafman, 2005).\nThe problem of conformant planning can be formulated as a path-finding problem in belief space where a sequence of actions that map a given initial belief state into a target belief is sought (Bonet & Geffner, 2000). A belief state represents the set of states that are deemed possible, and actions, whether deterministic or not, map one belief state into\nc©2009 AI Access Foundation. All rights reserved.\nanother. This formulation, that underlies most current conformant planners (Hoffmann & Brafman, 2006; Bryce, Kambhampati, & Smith, 2006; Cimatti, Roveri, & Bertoli, 2004) must address two problems: the problem of representing beliefs in a compact way, and the problem of obtaining effective heuristics over beliefs. The first problem has been approached through logical representations that make use of SAT or OBDD technology, that while intractable in the worst case, scale up better than plain state representations. The second problem, on the other hand, has been more complex, with heuristics for searching in belief space not being as successful so far as the heuristics developed for classical planning (Bonet & Geffner, 2001; Hoffmann & Nebel, 2001).\nIn this work, we introduce a different approach to conformant planning where problems are automatically compiled into classical problems and solved by a classical planner. The translation maps sets of literals t about the initial situation and literals L into new literals KL/t that express that if t is true in the initial situation, L must be true. We lay out first a general translation scheme that is sound and then establish the conditions under which the translation is also complete. Also, we show that the complexity of the complete translation is exponential in a parameter of the problem that we call the conformant width, which for most benchmark domains is bounded, implying that the complete translation in those cases is polynomial. The planner based on this translation exhibits good performance in comparison with existing conformant planners and is the basis for T0, the best performing planner in the Conformant Track of the 2006 International Planning Competition.\nThe translation-based approach provides a solution to the two problems faced by conformant planners that search in belief space: the belief representation and the heuristic over beliefs. In the translation-based approach, the beliefs are represented by the literals KL/t that stand for conditionals, a representation that is polynomial and complete for conformant problems with bounded width. In addition, and since belief states are represented as plain states, the heuristic over beliefs is a classical heuristic. From a computational point of view, though, there is no explicit search in belief-space: conformant problems P are converted into classical problems K(P ) at the ’knowledge-level’ (Petrick & Bacchus, 2002), whose solutions, computed by a classical planner, encode the conformant solutions for P .\nOur formulation is limited to conformant problems that are deterministic and where all uncertainty lies in the initial situation. We address nonetheless the issues that must be handled in order to generalize the translation-based approach to non-deterministic domains and report empirical results over non-deterministic domains as well.\nThe paper is organized as follows. We define first the syntax and semantics of conformant planning problems P (Section 2), and consider a simple sound but incomplete translation K0 (Section 3). We then consider a more general translation scheme KT,M where T and M are two parameters, a set of tags t encoding assumptions about the initial situation, and a set of merges m encoding valid disjunctions of tags (Section 4), and analyze several instances of this scheme that follow from particular choices of the sets of tags and merges: a complete but exponential translation KS0 where tags are associated with the possible initial states of the problem (Section 5), and a polynomial translation Ki for a fixed integer i ≥ 0 that is complete for problems with conformant width bounded by i (Section 6). We provide then an alternative explanation for this compact but complete translation by showing that in problems with bounded width, the exponential number of possible initial states S0 includes always a polynomial number of ’critical’ initial states S′0 such that plans\nthat conform with S′0 conform also with S0 (Section 7). We finally present the conformant planner T0 (Section 8), an empirical evaluation of the planner (Section 9), an extension to non-deterministic actions (Section 10), and a discussion of related work (Section 11). This is followed by a brief summary (Section 12) and the formal proofs (Appendix).\nThis work is a revision and extension of the formulation presented by Palacios and Geffner (2007), which in turn is based on ideas first sketched also by Palacios and Geffner (2006)."
    }, {
      "heading" : "2. The Conformant Problem P",
      "text" : "We define next the syntax and semantics of the conformant planning problems considered."
    }, {
      "heading" : "2.1 Syntax",
      "text" : "Conformant planning problems P are represented as tuples of the form P = 〈F, I,O,G〉 where F stands for the fluent symbols in the problem, I is a set of clauses over F defining the initial situation, O stands for a set of (ground) operators or actions a, and G is a set of literals over F defining the goal. Every action a has a precondition Pre(a) given by a set of fluent literals, and a set of conditional effects C → L where C is a set of fluent literals and L is a fluent literal.\nAll actions are assumed to be deterministic and hence all uncertainty lies in the initial situation. Thus, the language for the conformant problem P excluding the uncertainty in the initial situation, is Strips extended with conditional effects and negation. Moreover, if there is no uncertainty in the initial situation, as when all fluents appear in unit clauses in I, P is equivalent to a classical planning problem.\nWe refer to the conditional effects C → L of an action a as the rules associated with a, and sometimes write them as a : C → L. When convenient, we also join several effects associated with the same action and condition as in a : C → L ∧ L′ and write C → L as true→ L when C is empty. Finally, for a literal L, ¬L denotes the complement of L."
    }, {
      "heading" : "2.2 Semantics",
      "text" : "A state s is a truth assignment over the fluents F in P = 〈F, I,O,G〉 and a possible initial state s of P is a state that satisfies the clauses in I.\nFor a state s, we write I(s) to refer to the set of atoms (positive literals) that are true in s, and write P/s to refer to the classical planning problem P/s = 〈F, I(s), O,G〉 which is like the conformant problem P except for the initial state that is fixed to s.\nAn action sequence π = {a0, a1, . . . , an} is a classical plan for P/s if the action sequence π is executable in the state s and results in a goal state sG; i.e., if for i = 0, . . . , n, the preconditions of the action ai are true in si, si+1 is the state that results from doing action ai in the state si, and all goal literals are true in sn+1.\nFinally, an action sequence π is a conformant plan for P iff π is a classical plan for P/s for every possible initial state s of P .\nConformant planning is computationally harder than classical planning, as plan verification remains hard even under polynomial restrictions on plan length (Haslum & Jonsson, 1999; Baral et al., 2000; Turner, 2002; Rintanen, 2004). The most common approach to\nconformant planning is based on the belief state formulation (Bonet & Geffner, 2000). A belief state b is the non-empty set of states that are deemed possible in a given situation, and every action a executable in b, maps b into a new belief state ba. The conformant planning task becomes a path-finding problem in a graph where the nodes are belief states b, the source node b0 is the belief state corresponding to the initial situation, and the target belief states bG are those where the goals are true.\nWe assume throughout that I is logically consistent, so that the set of possible initial states is not empty, and that P itself is consistent, so that the bodies C and C ′ of conflicting effects a : C → L and a : C ′ → ¬L associated with the same action a are mutually exclusive or mutex. For further details on this; see Part B of the Appendix."
    }, {
      "heading" : "3. A Basic Translation K0",
      "text" : "A simple translation of the conformant problem P into a classical problem K(P ) can be obtained by replacing the literals L by literals KL and K¬L aimed at capturing whether L is known to be true and known to be false respectively.\nDefinition 1 (Translation K0). For a conformant planning problem P = 〈F, I,O,G〉, the translation K0(P ) = 〈F ′, I ′, O′, G′〉 is a classical planning problem with\n• F ′ = {KL,K¬L | L ∈ F} • I ′ = {KL | L is a unit clause in I} • G′ = {KL | L ∈ G} • O′ = O but with each precondition L for a ∈ O replaced by KL, and each conditional\neffect a : C → L replaced by a : KC → KL and a : ¬K¬C → ¬K¬L,\nwhere the expressions KC and ¬K¬C for C = L1, L2 . . . are abbreviations of the formulas KL1,KL2 . . . and ¬K¬L1,¬K¬L2 . . . respectively.\nThe intuition behind the translation is simple: first, the literal KL is true in the initial state I ′ if L is known to be true in I; otherwise it is false. This removes all uncertainty from K0(P ), making it into a classical planning problem. In addition, for soundness, each rule a : C → L in P is mapped into two rules: a support rule a : KC → KL, that ensures that L is known to be true when the condition is known to be true, and a cancellation rule a : ¬K¬C → ¬K¬L that guarantees that K¬L is deleted (prevented to persist) when action a is applied and C is not known to be false. The use of support and cancellation rules for encoding the original rules at the ’knowledge-level’ is the only subtlety in the translation.\nThe translation K0(P ) is sound as every classical plan that solves K0(P ) is a conformant plan for P , but is incomplete, as not all conformant plans for P are classical plans for K(P ). The meaning of the KL literals follows a similar pattern: if a plan achieves KL in K0(P ), then the same plan achieves L with certainty in P , yet a plan may achieve L with certainty in P without making the literal KL true in K0(P ).1\nProposition 2 (Soundness of K0(P )). If π is a classical plan for K0(P ), then π is a conformant plan for P .\n1. Formal proofs can be found in the appendix.\nAs an illustration, consider the conformant problem P = 〈F, I,O,G〉 with F = {p, q, r}, I = {q}, G = {p, r}, and actions O = {a, b} with effects\na : q → r , a : p→ ¬p , b : q → p .\nFor this problem, the action sequence π = {a, b} is a conformant plan for P while the action sequence π′ = {a} is not. Indeed, π is a classical plan for P/s for any possible initial state s, while π′ is not a classical plan for the possible initial state s′ where p is true (recall that s is a possible initial state of P if s satisfies I so that neither p nor r are assumed to be initially false in this problem).\nFrom Definition 1, the translationK0(P ) = 〈F ′, I ′, O′, G′〉 is a classical planning problem with fluents F ′ = {Kp,K¬p,Kq,K¬q,Kr,K¬r}, initial situation I ′ = {Kq}, goals G′ = {Kp,Kr}, and actions O′ = {a, b} with effects\na : Kq → Kr , a : Kp→ K¬p , b : Kq → Kp,\nthat encode supports, and effects\na : ¬K¬q → ¬K¬r , a : ¬K¬p→ ¬Kp , b : ¬K¬q → ¬K¬p,\nthat encode cancellations. Proposition 2 implies, for example, that π′ = {a}, which is not a conformant plan for P , cannot be a classical plan for K(P ) either. This is easy to verify, as while the support a : Kq → Kr achieves the goal Kr as Kq is true in I ′, the cancellation a : ¬K¬p → ¬Kp associated with the same action, preserves Kp false for the other goal p.\nWhile the translation K0 is not complete, meaning that it fails to capture all conformant plans for P as classical plans, its completeness can be assessed in terms of a weaker semantics. In the so-called 0-approximation semantics (Baral & Son, 1997), belief states b are represented by 3-valued states where fluents can be true, false, or unknown. In this incomplete belief representation, checking whether an action a is applicable in a belief state b, computing the next belief state ba, and verifying polynomial length plans are all polynomial time operations. In particular, a literal L is true it the next belief state ba iff a) action a has some effect C → L such that all literals in C are true in b, or b) L is true in b and for all effects C ′ → ¬L of action a, the complement of some literal L′ ∈ C ′ is true in b. An action sequence π is then a conformant plan for P according to the 0-approximation semantics if the belief sequence generated by π according to the 0-approximation semantics makes the action sequence applicable and terminates in a belief state where the goals are true. It is possible to prove then that:\nProposition 3 (K0(P ) and 0-Approximation). An action sequence π is a classical plan for K0(P ) iff π is a conformant plan for P according to the 0-approximation semantics.\nThis correspondence is not surprising though as both the 0-approximation semantics and the K0(P ) translation throw away the disjunctive information and restrict the plans to those that make no use of the uncertain knowledge. Indeed, the states s0, s1, . . . generated by the action sequence π = {a0, a1, . . .} over the classical problem K0(P ) encode precisely\nthe literals that are known to be true according to the 0-approximation; namely, L is true at time i according to the 0-approximation iff the literal KL is true in the state si.\nProposition 3 does not mean that the basic translation K0 and the 0-approximation semantics are equivalent but rather that they both rely on equivalent belief representations. The translation K0 delivers also a way to get valid conformant plans using a classical planner. The translation-based approach thus addresses both the representational and the heuristic issues that arise in conformant planning.\nAs an illustration of Proposition 3, given a conformant problem P with I = {p, r} and actions a and b with effects a : p→ q, a : r → ¬v, and b : q → v, the plan π = {a, b} is valid for achieving the goal G = {q, v} according to both K0(P ) and the 0-approximation, while the plan π = {b} is not valid according to either. At the same time, if the initial situation is changed to I = {p∨ q}, neither approach sanctions the plan π = {a} for G = {q}, even if it is a valid conformant plan. For this, some ability to reason with disjunctions is needed.\nAn extension of the basic translation K0 that allows a limited form of disjunctive reasoning is presented by Palacios and Geffner (2006). The extension is based on the introduction of new literals L/Xi used for encoding the conditionals Xi ⊃ L. Below, the basic translation K0 is extended in a different manner that ensures both tractability and completeness over a large class of problems.\n4. General Translation Scheme KT,M\nThe basic translation K0 is extended now into a general translation scheme KT,M where T and M are two parameters: a set of tags t and a set of merges m. We will show that for suitable choices of these two parameters, the translation KT,M , unlike the translation K0, can be both sound and complete.\nA tag t ∈ T is a set (conjunction) of literals L from P whose truth value in the initial situation is not known. The tags t are used to introduce a new class of literals KL/t in the classical problem KT,M (P ) that represent the conditional ’if t is true initially, then L is true’, an assertion that could be written as K(t0 ⊃ L) in a temporal modal logic. We use the notation KL/t rather than L/t as used by Palacios and Geffner (2006), because there is a distinction between ¬KL/t and K¬L/t: roughly ¬KL/t means that the conditional K(t0 ⊃ L) is not true, while K¬L/t means that the conditional K(t0 ⊃ ¬L) is true.\nLikewise, a merge m is a non-empty collection of tags t in T that stands for the Disjunctive Normal Form (DNF) formula ∨ t∈m t. A merge m is valid when one of the tags t ∈ m must be true in I; i.e., when I |=\n∨ t∈m t .\nA merge m for a literal L in P will translate into a ’merge action’ with a single effect∧ t∈m KL/t → KL\nthat captures a simple form of reasoning by cases. While a valid merge can be used for reasoning about any literal L in P , computationally it is convenient (although not logically necessary) to specify that certain merges are to be used with some literals L and not with others. Thus, formally, M is a collection of pairs\n(m,L), where m is a merge and L is a literal in P . Such a pair means that m is a merge for L. We group all the merges m for a literal L in the set ML, and thus, M can be understood as the collection of such sets ML for all L in P . For simplicity, however, except when it may cause a confusion, we will keep referring to M as a plain set of merges.\nWe assume that the collection of tags T always includes a tag t that stands for the empty collection of literals, that we call the empty tag and denote it as ∅. If t is the empty tag, we denote KL/t simply as KL.\nThe translation KT,M (P ) is the basic translation K0(P ) ’conditioned’ with the tags t in T and extended with the actions that capture the merges in M :\nDefinition 4 (Translation KT,M ). Let P = 〈F, I,O,G〉 be a conformant problem, then KT,M (P ) is the classical planning problem KT,M (P ) = 〈F ′, I ′, O′, G′〉 with\n• F ′ = {KL/t,K¬L/t | L ∈ F and t ∈ T}\n• I ′ = {KL/t | I, t |= L}\n• G′ = {KL | L ∈ G}\n• O′ = {a : KC/t→ KL/t, a : ¬K¬C/t→ ¬K¬L/t | a : C → L in P} ∪ {am,L : [ ∧ t∈mKL/t]→ KL ∧XL | L ∈ P,m ∈ML}\nwhere KL is a precondition of action a in KT,M (P ) if L is a precondition of a in P , KC/t and ¬K¬C/t stand for KL1/t,KL2/t, . . . , and ¬K¬L1/t,¬K¬L2/t, . . . respectively, when C = L1, L2, . . ., and XL stands for ∧ L′ K¬L′ with L′ ranging over the literals L′ mutex with L in P .\nThe translation KT,M (P ) reduces to the basic translation K0(P ) when M is empty and T contains only the empty tag. The extra effects XL = ∧ L′ K¬L′ in the merge actions am,L are needed only to ensure that the translation KT,M (P ) is consistent when P is consistent, and otherwise can be ignored. Indeed, if L and L′ are mutex in a consistent P , the invariant KL/t ⊃ K¬L′/t holds in KT,M (P ) for non-empty tags t, and hence a successful merge for L can always be followed by a successful merge for ¬L′. In the rest of the paper we will thus assume that both P and KT,M (P ) are consistent, and ignore such extra merge effects, but we will come back to them in Appendix B for proving the consistency of KT,M (P ) from the consistency of P .\nFor suitable choices of T and M , the translation KT,M (P ) will be sound and complete. Before establishing these results, however, let us make these notions precise.\nDefinition 5 (Soundness). A translation KT,M (P ) is sound if for any classical plan π that solves the classical planning problem KT,M (P ), the plan π′ that results from π by dropping the merge actions is a conformant plan for P .\nDefinition 6 (Completeness). A translation KT,M (P ) is complete if for any conformant plan π′ that solves the conformant problem P , there is a classical plan π that solves the classical problem KT,M (P ) such that π′ is equal to π with the merge actions removed.\nThe general translation scheme KT,M is sound provided that all merges are valid and all tags are consistent (literals in a tag are all true in some possible initial state):\nTheorem 7 (Soundness KT,M (P )). The translation KT,M (P ) is sound provided that all merges in M are valid and all tags in T are consistent.\nUnless stated otherwise, we will assume that all merges are valid and all tags consistent, and will call such translations, valid translations.\nAs a convention for keeping the notation simple, in singleton tags like t = {p}, the curly brackets are often dropped. Thus, literals KL/t for t = {p} are written as KL/p, while merges m = {t1, t2} for singleton tags t1 = {p} and t2 = {q}, are written as m = {p, q}.\nExample. As an illustration, consider the problem of moving an object from an origin to a destination using two actions: pick(l), that picks up an object from a location if the hand is empty and the object is in that location, and drop(l), that drops the object at a location if the object is being held. For making the problem more interesting, let us also assume that the action pick(l) drops the object being held at l if the hand is not empty. These are all conditional effects and there are no action preconditions. Assuming that there is a single object, these effects can be written as:\npick(l) : ¬hold, at(l)→ hold ∧ ¬at(l) pick(l) : hold→ ¬hold ∧ at(l) drop(l) : hold→ ¬hold ∧ at(l) .\nConsider now an instance P of this domain, where the hand is initially empty and the object, initially at either l1 or l2, must be moved to l3; i.e., P = 〈F, I,O,G〉 with\nI = {¬hold , at(l1) ∨ at(l2) , ¬at(l1) ∨ ¬at(l2) , ¬at(l3)}\nand G = {at(l3)} .\nThe action sequence\nπ1 = {pick(l1), drop(l3), pick(l2), drop(l3)}\nis a conformant plan for this problem, where an attempt to pick up the object at location l1 is followed by a drop at the target location l3, ensuring that the object ends up at l3 if it was originally at l1. This is then followed by an attempt to pick up the object at l2 and a drop at l3.\nOn the other hand, the action sequence π2 that results from π1 by removing the first drop action\nπ2 = {pick(l1), pick(l2), drop(l3)}\nis not a conformant plan, since if the object was originally at l1, it would end up at l2 after the action pick(l2). In the notation introduced above, π1 is a classical plan for the classical problem P/s for the two possible initial states s, while π2 is a classical plan for the problem P/s but only for the state s where the object is initially at l2.\nConsider now the classical problem KT,M (P ) = 〈F ′, I ′, O′, G′〉 that is obtained from P when T = {at(l1), at(l2)}2 and M contains the merge m = {at(l1), at(l2)} for the literals hold and at(l3). From its definition, the fluents F ′ in KT,M (P ) are of the form KL/t and K¬L/t for L ∈ {at(l), hold}, l ∈ {l1, l2}, and t ∈ T , while the initial situation I ′ is\nI ′ = {K¬hold,K¬hold/at(l),K¬at(l3),K¬at(l3)/at(l),Kat(l)/at(l),K¬at(l′)/at(l)}\nfor l, l′ ∈ {l1, l2} and l′ 6= l, and the goal G′ is\nG′ = {Kat(l3)} .\nThe effects associated to the actions pick(l) and drop(l) in O′ are the support rules\npick(l) : K¬hold, Kat(l) → Khold ∧K¬at(l) pick(l) : Khold → K¬hold ∧Kat(l) drop(l) : Khold → K¬hold ∧Kat(l)\nfor each one of the three locations l = li, that condition each rule in O with the empty tag, along with the support rules:\npick(l) : K¬hold/at(l′), Kat(l)/at(l′) → Khold/at(l′) ∧K¬at(l)/at(l′) pick(l) : Khold/at(l′) → K¬hold/at(l′) ∧Kat(l)/at(l′) drop(l) : Khold/at(l′) → K¬hold/at(l′) ∧Kat(l)/at(l′)\nthat condition each rule in O with the tags at(l′) ∈ T , for l′ ∈ {l1, l2}. The corresponding cancellation rules are:\npick(l) : ¬Khold, ¬K¬at(l) → ¬K¬hold ∧ ¬Kat(l) pick(l) : ¬K¬hold → ¬Khold ∧ ¬K¬at(l) drop(l) : ¬K¬hold → ¬Khold ∧ ¬K¬at(l)\nand\npick(l) : ¬Khold/at(l′), ¬K¬at(l)/at(l′) → ¬K¬hold/at(l′) ∧ ¬Kat(l)/at(l′) pick(l) : ¬K¬hold/at(l′) → ¬Khold/at(l′) ∧ ¬K¬at(l)/at(l′) drop(l) : ¬K¬hold/at(l′) → ¬Khold/at(l′) ∧ ¬K¬at(l)/at(l′) .\nIn addition, the actions in O′ include the merge actions am,hold and am,at(l3) that follow from the merge m = {at(l1), at(l2)} in M for the literals hold and at(l3):\nam,hold : Khold/at(l1),Khold/at(l2) → Khold am,at(l3) : Kat(l3)/at(l1),Kat(l3)/at(l2) → Kat(l3) .\n2. The empty tag is assumed in every T and thus it is not mentioned explicitly.\nIt can be shown then that the plan\nπ′1 = {pick(l1), drop(l3), pick(l2), drop(l3), am,at(l3)}\nsolves the classical problem KT,M (P ) and hence, from Theorem 7, that the plan π1 obtained from π′1 by dropping the merge action, is a valid conformant plan for P (shown above). We can see how some of the literals in KT,M (P ) evolve as the actions in π′1 are executed:\n0: Kat(l1)/at(l1),Kat(l2)/at(l2) true in I ′ 1: Khold/at(l1),Kat(l2)/at(l2) true after pick(l1) 2: Kat(l3)/at(l1),Kat(l2)/at(l2) true after drop(l3) 3: Kat(l3)/at(l1),Khold/at(l2) true after pick(l2) 4: Kat(l3)/at(l1),Kat(l3)/at(l2) true after drop(l3) 5: Kat(l3) true after merge am,at(l3).\nWe can also verify in the same manner that the action sequence π′2\nπ′2 = {pick(l1), pick(l2), am,hold, drop(l3)}\nis not a classical plan for KT,M (P ), the reason being that the atom Khold/at(l1) holds after the first pick up action but not after the second. This is due to the cancellation rule:\npick(l2) : ¬K¬hold/at(l1)→ ¬Khold/at(l1) ∧ ¬K¬at(l2)/at(l1)\nthat expresses that under the assumption at(l1) in the initial situation, hold and ¬at(l2) are not known to be true after the action pick(l2), if under the same assumption, ¬hold was not known to be true before the action.\n5. A Complete Translation: KS0\nA complete instance of the translation scheme KT,M can be obtained in a simple manner by setting the tags to the possible initial states of the problem P and by having a merge for each precondition and goal literal L that includes all these tags. We call the resulting ’exhaustive’ translation KS0:\nDefinition 8 (Translation KS0). For a conformant problem P , the translation KS0(P ) is an instance of the translation KT,M (P ) where\n• T is set to the union of the empty tag and the set S0 of all possible initial states of P (understood as the maximal sets of literals that are consistent with I), and\n• M is set to contain a single merge m = S0 for each precondition and goal literal L in P .\nThe translation KS0 is valid and hence sound, and it is complete due the correspondence between tags and possible initial states:\nTheorem 9 (Completeness of KS0). If π is a conformant plan for P , then there is a classical plan π′ for KS0(P ) such that π is the result of dropping the merge actions from π′.\nFor problems P whose actions have no preconditions, the argument is simple: if π is a conformant plan for P then π must be a classical plan for P/s for each possible initial state s, but then if π achieves the (goal) literal Gi in P/s for each s, π must achieve the literal KGi/s in KS0(P ) for each s as well, so that π followed by the merge action for Gi, must achieve the literal KGi. In the presence of action preconditions, this argument must be applied inductively on the plan length, but the idea remains the same (see the proof in the appendix for details): a correspondence can be established between the evolution of the fluents L in each problem P/s and the evolution of the fluents KL/s in the problem KS0(P ).\nThe significance of the exhaustive KS0 translation is not only theoretical. There are plenty of conformant problems that are quite hard for current planners even if they involve a handful of possible initial states. An example of this is the Square-Center-n task (Cimatti et al., 2004), where an agent has to reach the center of an empty square grid with certainty, not knowing its initial location. There are four actions that move the agent one unit in each direction, except when in the border of the grid, where they have no effects. In the standard version of the problem, the initial position is fully unknown resulting in n2 possible initial states, yet the problem remains difficult, and actually beyond the reach of most planners, for small values of n, even when the uncertainty is reduced to a pair of possible initial states. The reason is that the agent must locate itself before heading for the goal. The domain Corners-Square-n in Table 1 is a variation of Square-Center-n where the possible initial states are the four corners of the grid.\nTable 1 shows results for a conformant planner based on the KS0(P ) translation that uses FF (Hoffmann & Nebel, 2001) for solving the resulting classical problem, and compares it with two of the planners that entered the Conformant track of the 2006 Int. Planning Competition (Bonet & Givan, 2006): POND (Bryce et al., 2006) and Conformant FF (Hoffmann & Brafman, 2006) (the other two planners in the competition were translationbased: T0, based on the formulation developed in this paper, and K(P ), based on an earlier and more restricted formulation due to Palacios & Geffner, 2006). Clearly, the approach based on the KS0(P ) translation does not scale up to problems with many possible initial states, yet when the number of such states is small, it does quite well."
    }, {
      "heading" : "6. Complete Translations that May be Compact Too",
      "text" : "In order to have complete translations that are polynomial, certain assumptions about the formulas in the initial situation I need to be made. Otherwise, just checking whether a goal is true in I is intractable by itself, and therefore a polynomial but complete translation would be impossible (unless P = NP). We will thus assume that I is in prime implicate (PI) form (Marquis, 2000), meaning that I includes only the inclusion-minimal clauses that it entails but no tautologies. It is known that checking whether a clause follows logically from a formula I in PI form reduces to checking whether the clause is subsumed by a clause in I or is a tautology, and hence is a polynomial operation. The initial situations I in most benchmarks is in PI form or can easily be cast into PI form as they are normally specified by means of a set of non-overlapping oneof(X1, . . . , Xn) expressions that translate into clauses X1 ∨ · · · ∨ Xn and binary clauses ¬Xi ∨ ¬Xj for i 6= j where any resolvent is a tautology."
    }, {
      "heading" : "6.1 Conformant Relevance",
      "text" : "The translation KS0(P ) is complete but introduces a number of literals KL/t that is exponential in the worst case: one for each possible initial state s0. This raises the question: is it possible to have complete translations that are not exhaustive in this sense? The answer is yes and in this section we provide a simple condition that ensures that a translation KT,M (P ) is complete. It makes use of the notion of relevance:3\nDefinition 10 (Relevance). The conformant relevance relation L −→ L′ in P , read L is relevant to L′, is defined inductively as\n1. L −→ L 2. L −→ L′ if a : C → L′ is in P with L ∈ C for some action a in P 3. L −→ L′ if L −→ L′′ and L′′ −→ L′\n4. L −→ L′ if L −→ ¬L′′ and L′′ −→ ¬L′.\nThe first clause stands for reflexivity, the third for transitivity, the second captures conditions that are relevant to the effect, and the fourth, the conditions under which L preempts conditional effects that may delete L′. If we replace 4 by\n4’ L −→ L′ if ¬L→ ¬L′\nwhich is equivalent to 4 in the context of 1–3, the resulting definition is the one by Son and Tu (2006), where the notion of relevance is used to generate a limited set of possible ’partial’ initial states over which the 0-approximation is complete (see Section 11 for a discussion on the relation between tags and partial initial states).\nNotice that according to the definition, a precondition p of an action a is not taken to be ’relevant’ to an effect q. The reason is that we want the relation L −→ L′ to capture the conditions under which uncertainty about L is relevant to the uncertainty about L′. This is why we say this is a relation of conformant relevance. Preconditions must be known to be true in order for an action to be applied, so they do not introduce nor propagate uncertainty into the effects of an action.\nIf we let CI stand for the set of clauses representing uncertainty about the initial situation, namely, the non-unit clauses in I along with the tautologies L∨¬L for complementary literals L and ¬L not appearing as unit clauses in I, the notion of (conformant) relevance can be extended to clauses as follows:\nDefinition 11 (Relevant Clauses). A clause c ∈ CI is relevant to a literal L in P if all literals L′ ∈ c are relevant to L. The set of clauses in CI relevant to L is denoted as CI(L).\nHaving a representation of the uncertainty in the initial situation that is relevant to a literal L, it is possible to analyze the completeness of a translation KT,M in terms of the relation between the merges m for the literals L, on one hand, and the sets of clauses CI(L) that are relevant to L on the other.\n3. While we follow an earlier account (Palacios & Geffner, 2007), many of the definitions and theorems differ in a number of details (for example, the notion of relevance depends on the rules in P but not on the clauses in the initial situation). The changes are aimed at making the resulting formulation simpler and cleaner."
    }, {
      "heading" : "6.2 Covering Translations",
      "text" : "It may appear that a translation KT,M would be complete when the merges m for precondition and goal literals L, understood as the DNF formulas ∨ t∈m t, contain as much information, and thus are equivalent to the CNF formula CI(L) that captures the fragment of the initial situation I that is relevant to L. This intuition is partially correct, but misses one important point; namely that not every DNF formula equivalent to CI(L) will do: the DNF representation captured by the merges must be ’vivid’ enough. For example, if CI(L) is the single clause x ∨ ¬x, completeness requires a tag for x, a tag for ¬x, and a merge m = {x,¬x} for L containing the two tags, even if the clause x ∨ ¬x is a tautology and is thus equivalent to the DNF formula true.\nFor defining the types of tags and merges that are required for completeness then, let us first define the closure S∗ of a set of literals S, relative to a conformant problem P = 〈F, I,O,G〉, as the set of literals that follow from S and I:\nS∗ = {L | I, S |= L} .\nLet us also say that S is consistent if S∗ does not contain a pair of complementary literals. The type of merges m required for precondition and goal literals L are then those that do not only imply CI(L) but that satisfy it as well. The notion of satisfaction associates a consistent set of literals S with the partial truth assignment that is implicit in the closure S∗ of S, and is extended to account for the conditions under which a DNF formula (e.g., a merge for L) satisfies a CNF formula (e.g., CI(L)).\nDefinition 12 (Satisfaction). 1. A consistent set of literals S satisfies a clause L1∨L2∨ · · · ∨ Lm if S∗ contains one of the literals Li, i = 1, . . . ,m.\n2. A consistent set of literals S satisfies a collection of clauses C if S satisfies each clause in C.\n3. A collection S of consistent sets of literals satisfies a collection of clauses C if each set S in S satisfies C.\nThe type of merges required for completeness are then simply the valid merges m that satisfy the set of clauses CI(L). We call them covering merges:\nDefinition 13 (Covering Merges). A valid merge m in a translation KT,M (P ) covers a literal L if m satisfies CI(L).\nFor example, if CI(L) is given by the clauses that result from a oneof(x1, . . . , xn) expression, i.e. x1 ∨ x2 ∨ · · · ∨ xn and ¬xi ∨ ¬xj for all i and j, 1 ≤ i, j ≤ n, i 6= j, then the merge m = {x1, . . . , xn} covers the literal L, as each x∗i not only includes xi but also ¬xj for all j 6= i, and thus x∗i satisfies CI(L).\nIf for a merge m = {t1, . . . , tn}, we denote by m∗ the DNF formula ∨\nti∈m t ∗ i , where each\ntag ti is replaced by its closure t∗i , then it is simple to prove that if m covers the literal L, m∗ entails CI(L). A merge m that covers L is thus a DNF formula that is strong enough to imply the CNF formula CI(L) (through the closure), weak enough to be entailed by I, and vivid enough to satisfy CI(L).\nAs a further illustration, if CI(L) is given by the tautologies p ∨ ¬p and q ∨ ¬q, and I = CI(L), the merge m1 = {p,¬p} implies CI(L) but does not satisfy CI(L). Likewise, the merge m2 = {{p, q}, {¬p,¬q}} satisfies CI(L) but is not entailed by I. Finally, the merge m3 = {{p, q}, {p,¬q}, {¬p, q}, {¬p,¬q}} satisfies CI(L) and is entailed by I, and thus is a valid merge that covers L.\nIf a valid translation KT,M (P ) contains a merge m that covers L for each precondition and goal literal L in P , we say that the translation covers P or just that it is a covering translation:\nDefinition 14 (Covering Translation). A covering translation is a valid translation KT,M (P ) that includes one merge that covers L, for each precondition and goal literal L in P .\nA central result of the paper is that covering translations are complete:\nTheorem 15 (Completeness). Covering translations KT,M (P ) are complete; i.e., if π is a conformant plan for P , then there is a classical plan π′ for KT,M (P ) such that π is π′ with the merge actions removed.\nIn other words, complete translations KT,M (P ) result when the tags and merges in T and M capture the information in the initial situation that is relevant to each precondition and goal literal in a suitable manner.\nTheorem 15 can be used in two ways: for proving the completeness of a translation, by checking that the covering condition holds, and for constructing complete translations, by enforcing the covering condition. In addition, while our interest in this paper is on conformant planning with no optimality guarantees, the theorem is useful for optimal conformant planning as well, whether the cost of plans is defined as their length (action costs equal to 1) or as the sum of non-uniform action costs. In both cases, the theorem ensures that the problem of optimal conformant planning gets mapped into a problem of optimal classical planning provided that the cost of the merge actions in KT,M (P ) is made sufficiently small.\nAs an illustration of Theorem 15, consider the conformant problem P with initial situation I = {x1 ∨ · · · ∨ xm}, goal G = L, and actions ai, i = 1, . . . ,m, each with effect xi → L. The number of possible initial states for this problem is exponential in m, as the disjunction among the xi’s is not exclusive. So, the translation KS0(P ) is complete but exponential in size. On the other hand, consider the translation KT,M (P ) where T = {x1, . . . , xm} and M contains the single valid merge m = {x1, . . . , xm} for L. It is simple to verify that this merge covers the goal L (satisfies CI(L) = I), and hence that the translation KT,M (P ) is covering, and by Theorem 15, complete, while being polynomial in m.\nNotice that testing whether a valid translation KT,M (P ) is a covering translation can be done in polynomial time, as in particular, computing the set of literals t∗ from every tag t in T is a tractable operation provided that I is in PI form; indeed, I, t |= L′ iff I |= t ⊃ L′ iff ¬t ∨ L′ is a tautology or is subsumed by a clause in I.\n6.3 Translation Kmodels\nIt is straightforward to show that the exponential translation KS0 considered in Section 3, where (non-empty) tags stand for the possible initial states, is covering and hence complete\naccording to Theorem 15. It is possible, however, to take further advantage of Theorem 15 for devising a complete translation that is usually more compact. We call it Kmodels.\nDefinition 16. The translation Kmodels(P ) is obtained from the general scheme KT,M (P ) by defining\n• M to contain one merge m for each precondition and goal literal L given by the models of CI(L) that are consistent with I,4 and\n• T to contain the tags in all such merges along with the empty tag.\nThe translation Kmodels is equivalent to KS0 when for all the precondition and goal literals L, CI(L) = I; i.e., when all the clauses in I are relevant to L. Yet, in other cases, the first translation is exponential in the number of variables appearing in one such CI(L) set (the one with the largest number of such variables), while the second is exponential in the number of unknown variables in I. For example, if there are n precondition and goal literals Li, i = 1, . . . , n in P such that for each one, CI(Li) is a unique oneof(xi1, . . . , x i m) expression, the merge for the literal Li in KS0(P ) will contain the mn models of the n one-of expressions in I, while the merge for Li in Kmodels(P ) will just contain the m models of the single oneof(xi1, . . . , x i m) expression in CI(Li). The translation Kmodels can thus be exponentially more compact than the exhaustive KS0 translation while remaining sound and complete:\nTheorem 17. The translation Kmodels(P ) is sound and complete.\nIn the worst case, however, Kmodels is also an exponential translation. We thus consider next polynomial translations and the conditions under which they are complete."
    }, {
      "heading" : "6.4 Conformant Width",
      "text" : "We address now the conditions under which a compact, covering translation can be constructed in polynomial time. For this, we define a structural parameter that we call the conformant width of a problem P , that in analogy to the notion of width used in graphical models (Dechter, 2003), will provide an upper bound on the time and space complexity required for generating a covering translation. More precisely, the complexity of this construction will be exponential in the conformant width of the problem P that cannot exceed the number of fluents in P but can be much lower.\nIn principle, we would like to define the width w(P ) as the maximum tag size required in a translation KT,M (P ) to be a covering translation. Such a definition, however, would not give us the complexity bounds that we want, as just checking the validity of a merge with tags of bounded size is an intractable operation, whether the initial situation I is in prime implicate form or not.5 So we need to define width in a different way. First, let the cover of a set of clauses be defined as follows:\n4. The models of CI(L) are to be understood as conjuntions of literals. 5. The problem of checking whether I entails a DNF formula whose terms may have more than 2 literals\nis coNP-hard even if I is equivalent to true. Indeed, if Φ is a 3-CNF formula; Φ is contradictory iff its negation ¬Φ (which is in 3-DNF) is valid, which in turn is true iff ¬Φ is implied by I. Actually, for a general I in prime implicate form, the problem remains coNP-hard even if the terms of the DNF formula contain at most 2 literals. We thank Pierre Marquis for pointing these results to us.\nDefinition 18 (Cover). The cover c(C) of a set of clauses C, relative to a conformant problem P with initial situation I, is the collection of all minimal sets of literals S consistent with I such that S contains a literal of each clause in C.\nTwo important properties of the cover c(C) of a set of clauses C are that c(C) stands for a DNF formula that is logically equivalent to the CNF formula C given I, and that c(C) can be computed in polynomial time if the size of C is bounded by a constant. Moreover, c(C) not only implies C but satisfies C as well. Thus in particular, if C is the collection of clauses CI(L) that are relevant to the literal L, the cover c(CI(L)) of CI(L) is a valid merge that covers L. From this and the completeness of covering translations, it follows that a complete translation KT,M (P ) can be constructed in polynomial time if the size |CI(L)| of the sets of clauses CI(L) for all precondition and goal literals L in P is bounded. Unfortunately, this condition rarely seems to hold, yet there is a weaker sufficient condition that does: namely, it is often possible to find a subset C of clauses that are either in CI(L) or are tautologies such that c(C) satisfies CI(L) and thus covers the literal L. We thus define the width of the literal L as the size of the smallest such set (cardinality-wise). For this, we denote by C∗I (L) the set of clauses CI(L) extended with tautologies of the form p ∨ ¬p for fluents p such that either p or ¬p appears in CI(L) (if both appear in CI(L) then p∨¬p is in CI(L) from its definition).\nDefinition 19 (Width of Literal). The conformant width of a literal L in P , written w(L), is the size of the smallest (cardinality-wise) set of clauses C in C∗I (L) such that c(C) satisfies CI(L).\nA consequence of this definition is that the width of a literal must lie in the interval 0 ≤ w(L) ≤ n, where n is the number of fluents in P whose status in the initial situation is not known. Indeed, if CI(L) is empty, w(L) = 0, while for any set of clauses CI(L), the cover c(C) of the set C of tautologies in C∗I (L) must satisfy CI(L), and thus w(L) ≤ |C| ≤ n. Similarly, if CI(L) contains a single clause x1 ∨ · · · ∨ xm or the clauses x1 ∨ · · · ∨ xm and ¬xi ∨ ¬xj that correspond to the oneof(x1, . . . , xm) expression, it is simple to prove that w(L) = 1 with the singleton C = {x1∨· · ·∨xm} generating the cover c(C) = {{x1}, . . . , {xn}} that satisfies CI(L). Finally, if CI(L) contains the two tautologies p∨¬p and q∨¬q, w(L) = 2 as the smallest C in C∗I (L) whose cover satisfies CI(L) is CI(L) itself.\nThe width of a problem is the width of the precondition or goal literal with maximum width:\nDefinition 20 (Width of Problem). The conformant width of a problem P , written as w(P ), is w(P ) = maxLw(L), where L ranges over the precondition and goal literals in P .\nWe show below that for problems with bounded width, complete translations can be constructed in polynomial time, and moreover, that almost all existing conformant benchmarks have bounded width, and more precisely, width equal to 1. In such a case, the resulting translations will use tags that are never greater in size than w(P ), so that for problems with width 1, tags will be single literals.\nLike for the (tree)width of graphical models, computing the width of a problem P is exponential in w(P ), so the recognition of problems with small width can be carried out quite efficiently:\nProposition 21 (Determining Width). The width w(P ) of P can be determined in time that is exponential in w(P ).\nIn particular, we can test if w(P ) = 1 by considering one by one each of the sets C that includes a single clause from C∗I (L), verifying whether c(C) satisfies CI(L) or not. If w(P ) 6≤ 1, then the same verification must be carried out by setting C to each set of i clauses in C∗I (L) for increasing values of i. For a fixed value of i, there is a polynomial number of such clause sets C and the verification of each one can be done in polynomial time. Moreover, from the arguments above regarding w(L), w(P ) can never exceed the number of unknown fluents in the problem:\nProposition 22 (Bounds on Width). The width of P is such that 0 ≤ w(P ) ≤ n, where n is the number of fluents whose value in the initial situation is not known."
    }, {
      "heading" : "6.5 Polynomial Translation Ki",
      "text" : "The translation Ki, where the parameter i is a non-negative integer, is an instance of the general KT,M scheme designed to be sound, polynomial for a fixed i, and complete for problems with width w(P ) ≤ i. Thus, for example, the translation K1 is sound, polynomial, and complete for problems with width 1.\nDefinition 23 (Translation Ki). The translation Ki(P ) is obtained from the general scheme KT,M (P ) where\n• M is set to contain one merge m = c(C) for each precondition and goal literal L in P if there is a set C of at most i clauses in C∗I (L) such that m covers L. If no such set exists, one merge m = c(C) for L is created for each set C of i clauses in C∗I (L), and no merges are created for L if C∗I (L) is empty;\n• T is the collection of tags appearing in those merges and the empty tag.\nThe translation Ki(P ) applies to problems P of any width, remaining in all cases exponential in i but polynomial in the number of fluents, actions, and clauses in P . In addition, the translation Ki(P ) is sound, and for problems with width bounded by i, complete.\nTheorem 24 (Properties Ki). For a fixed i, the translation Ki(P ) is sound, polynomial, and if w(P ) ≤ i, covering and complete.\nSoundness is the result of the merges being all valid by construction, as the covers c(C) for any C in C∗I (L) are entailed by C and hence by I. The complexity is polynomial for a fixed i, because there is a polynomial number of clause sets C of size i in C∗I (L), and constructing the cover c(C) for each one of them, is a polynomial operation. Finally, completeness follows from the definition of width: if w(P ) ≤ i, then there is a set of clauses C in C∗I (L) with size |C| no greater than i whose cover satisfies CI(L), and thus M in Ki(P ) must contain a merge m = c(C) for L that covers L.\nNotice that for i = 0, the translation Ki(P ) reduces to the basic K0(P ) translation introduced in Section 3 that has no tags (other than the empty tag) and no merges. Before, we assessed the completeness of this translation in terms of the 0-approximation semantics. Theorem 24 provides an alternative interpretation: the translation K0(P ) is complete for\nproblems P with zero width. These are the problems for which the set of clauses CI(L) relevant to a precondition or goal literal L is empty. This makes precise the intuition mentioned above that the K0(P ) translation is complete for problems where the uncertain information in I is not relevant. In such cases, none of the clauses in the initial situation I make it into the sets of relevant clauses CI(L) for preconditions and goal literals L.\nAs an illustration of Theorem 24, consider again the conformant problem P with initial situation I = {x1 ∨ · · · ∨ xm}, goal G = {L}, and actions ai, i = 1, . . . ,m, each with effect xi → L. For this problem, the singleton set of clauses C = CI(L) = I is such that c(C) = {{x1}, . . . , {xm}} covers CI(L). Then, since there is no other precondition or goal literal, K1(P ) includes the single merge m = c(C) for L with the singleton tags ti = {xi}, that we write simply as m = {x1, . . . , xm}. The translation K1(P ) is polynomial in m, and since w(P ) = 1, by Theorem 24 it is complete. Notice that for this same example, the translations KS0(P ) and Kmodels(P ) are identical and exponential in m (the number of models of I and CI(L))."
    }, {
      "heading" : "6.6 Width of Conformant Benchmarks",
      "text" : "The practical value of the notion of width becomes apparent when the width of existing benchmarks is considered. Table 2 summarizes the width of many of the existing benchmark domains for conformant planning. The domains all depend on certain parameters n or m that capture the size of the instances (e.g., size of a grid, number of objects, etc).6 A domain has a bounded width when its width does not grow with the size of its instances, and has width equal to i when all of its instances have width i regardless of the parameter values.\nAs it can be seen from the table, the width of most existing benchmarks is 1. In all these cases, this means that the sets CI(L) of clauses that are relevant to a precondition or\n6. The names of the parameterized domains in the table do not coincide with the names of the instances as currently used. E.g. Comm-n in IPC5 refers to a Communication instance but not necessarily to an instance with n signals.\ngoal literal L contain a single clause (often a tautology p∨¬p or a disjunction x1∨ . . .∨xm) or a single oneof(x1, . . . , xm) expression (that translates into the disjunction x1 ∨ · · · ∨ xm and clauses ¬xi ∨¬xk). As shown above, w(L), and therefore, w(P ), is equal to 1 in theses cases.\nOn the other extreme are domains such as Blocks, Sortnet, and Adder, all of which have maximal widths; i.e., widths that are equivalent to the number of fluents whose status in the initial situation is not known. This is because all fluents interact through the action conditions (not the preconditions). The numbers for Blocks in Table 2, thus follow from the number of fluents involved; namely, the fluents on(x, y), clear(x), ontable(x), and holding(x).\nFinally, the domains 1-dispose and Look-and-Grab (Palacios & Geffner, 2006, 2007) where m objects with unknown locations in a grid of n by n must be collected by a robot whose gripper can hold one object at a time, have width equal to m, meaning that the width of these domains grows with the number of objects but not with the size of the grid. This is because in this case, the clauses about the possible locations of the m objects are all relevant to the condition ’hand empty’ of the pick up actions.\nLet us point out that the completeness of the translation Ki(P ) for problems P with width w(P ) bounded by i, establishes a correspondence between the conformant plans for P and the classical plans for KT,M (P ). For solving P , however, this correspondence is not needed; it suffices for Ki(P ) to be solvable; a plan for Ki(P ) will then encode a conformant plan for P , even if Ki(P ) does not capture all conformant plans for P . From this perspective, it makes sense to refer to the smallest value of the i parameter for which the classical problem Ki(P ) is solvable, as the effective width of P , denoted we(P ). It turns out that while we(P ) cannot be larger than w(P ), it may be much smaller. An interesting example of this comes from the Sortnet-n domain (Bonet & Geffner, 2000). Sortnet-n is considered a challenging domain in conformant planning with very few planners able to scale up to even small values of n (the number of entries to be sorted in a sorting network). The domain has width n, and in the compact encoding used in IPC5, the input vector is represented by a set of bits, exploiting the fact that sorting vectors of numbers reduces to sorting vector of bits (0’s and 1’s). The domain cannot be solved by the K1 translation that FF reports correctly as unsolvable after a brief unsuccessful search. On the other hand, it is possible to reformulate the domain, replacing the unary high(i) and low(i) predicates by binary predicates less(i, j) that compare two vector entries. We call this reformulation Sort-2-n. While the encoding Sort-n is linear in n, the encoding Sort-2-n is quadratic in n, and in both cases, the problem width is maximum, given by the number of fluents whose status in the initial situation is unknown. Yet, while the more compact Sort-n encoding is not solvable by the K1 translation, K1 suffices to solve the problem over the expanded Sort2-n encoding that actually can also be solved by K0. Thus the effective width of Sort-2-n is 0. Interestingly, provided the K0 translation of Sort-2-n, instances can be solved with up to 20 entries. On the other hand, conformant planners such as Conformant-FF and POND can solve Sort-2-n instances for n no greater than 3."
    }, {
      "heading" : "7. Tags and Initial States",
      "text" : "A deeper understanding of the results above can be obtained by relating tags with possible initial states. By looking more closely at this relation in the context of covering translations, we will be able to answer the question of how a polynomial number of contexts (tags) can play the role of an exponential number of possible initial states in problems with bounded width.\nFor this, let us first recall a notation introduced in Section 2.2, where for a state s, we wrote I(s) to refer to the set of atoms encoding s (i.e, p ∈ I(s) iff p is true in s) and P/s to refer to the classical planning problem P/s = 〈F, I(s), O,G〉 that is like the conformant problem P = 〈F, I,O,G〉 but with the initial state fixed to s.\nLet us now extend this notation and say that an action sequence π conforms with a set of states S given the conformant problem P iff π is a plan for the classical problem P/s for each s ∈ S. Clearly, a conformant plan for P is nothing else but an action sequence that conforms with the set S0 of possible initial states of P , yet the notion of ’conforms’ allows us to abstract away the initial situation I and make precise the notion of a basis:\nDefinition 25 (Basis for P ). A set of states S′ is a basis for a conformant problem P = 〈F, I,O,G〉 if S′ is a subset of the set S0 of possible initial states of P and every plan that conforms with S′ conforms with the set of possible initial states S0.\nIn words, if S′ is a basis for P , it is not necessary to consider all the states in S0 for computing the conformant plans for P ; it suffices to consider just the states in S′. We aim to show that if the width of P is bounded, then P has a polynomial basis S′ even if S0 has exponential size. Moreover, the states s in such a basis are in close correspondence with the tags appearing in a covering translation.\nAs an illustration, consider a problem P with actions ai, i = 1, . . . , n, and effects ai : xi → L. Let G = {L} be the goal and I = {x1 ∨ · · · ∨ xn} the initial situation. The set S0 of all possible initial states are the truth valuations over the xi atoms where at least one of these atoms is true. There are 2n − 1 such states. On the other hand, one can show that the set S′0 of n valuations in which exactly one of these atoms is true provides a basis for P ; i.e., the plans that conform with these n possible initial states, are exactly the plans that conform with the complete set of 2n − 1 possible initial states in S0.\nThe reduction in the number of possible initial states that must be considered for computing conformant plans results from two monotonicity properties that we formulate using the notation rel(s, L) to refer to the set of literals L′ that are true in the state s and are relevant to the literal L:\nrel(s, L) = {L′ | L′ ∈ s and L′ is relevant to L} .\nProposition 26 (Monotonicity 1). Let s and s′ be two states and let π be an action sequence applicable in the classical problems P/s and P/s′. Then if π achieves a literal L in P/s′ and rel(s′, L) ⊆ rel(s, L), π achieves the literal L in P/s.\nProposition 27 (Monotonicity 2). If S and S′ are two collections of states such that for every state s in S and every precondition and goal literal L in P , there is a state s′ in S′ such that rel(s′, L) ⊆ rel(s, L), then if π is a plan for P that conforms with S′, π is a plan for P that conforms with S.\nFrom these properties, it follows that\nProposition 28. S′ is a basis for P if for every possible initial state s of P and every precondition and goal literal L in P , S′ contains a state s′ such that rel(s′, L) ⊆ rel(s, L).\nThis proposition allows us to verify the claim made in the example above that the set S′0, that contains a number of states that is linear in n, is a basis for P that has an exponential number of possible initial states. Indeed, such a problem has no precondition and a single goal literal L, and for every state s that makes more than one atom xi true (these are the literals relevant to L), there is a state s′ in S′0 that makes only one of those atoms true, and hence for which the relation rel(s′, L) ⊆ rel(s, L) holds.\nThe question that we address now is how to build a basis that complies with the condition in Proposition 28 given a covering translation KT,M (P ). For this, let m = {t1, . . . , tn} be a merge in M that covers a precondition or goal literal L, and let S[ti, L] denote the set of possible initial states s of P such that rel(s, L) ⊆ t∗i ; i.e., S[ti, L] contains the possible initial states of P that make all the literals L′ that are relevant to L false, except for those in the closure t∗i of ti. We show first that if I is in prime implicate form, S[ti, L] is a non-empty set:7\nProposition 29. If the initial situation I is in prime implicate form and m = {t1, . . . , tn} is a valid merge that covers a literal L in P , then the set S[ti, L] of possible initial states s of P such that rel(s, L) ⊆ t∗i is non-empty.\nLet then s[ti, L] stand for an arbitrary state in S[ti, L]. We obtain the following result:\nTheorem 30. Let KT,M (P ) be a covering translation for a problem P with an initial situation in PI form, and let S′ stand for the collection of states s[ti, L] where L is a precondition or goal literal of P and ti is a tag in a merge that covers L. Then S′ is a basis for P .\nThis is an important result for three reasons. First, it tells us how to build a basis for P given the tags ti in a covering translation KT,M (P ). Second, it tells us that the size of the resulting basis is linear in the number of precondition and goal literals L and tags ti. And third, it makes the role of the tags ti in the covering translation KT,M (P ) explicit, providing an intuition for why it works: each tag ti in a merge that covers a literal L represents one possible initial state; namely, a state s[ti, L] that makes false all the literals L′ that are relevant to L except those in t∗i . If a plan conforms with those critical states, then it will conform with all the possible initial states by monotonicity (Proposition 27). It follows then in particular that:\nTheorem 31. If P is a conformant planning problem with bounded width, then P admits a basis of polynomial size.\nNamely, conformant problems P with width bounded by a non-negative integer i admit polynomial translations that are complete, because the plans that conform with the possibly exponential number of initial states of P correspond with the plans that conform with\n7. Recall that we are assuming throughout that the initial situation I is logically consistent and that the tags t are consistent with I.\na subset of critical initial states that are polynomial in number (namely, those in the polynomial basis). Thus, one complete polynomial translation for such problems is the Ki translation; another one, is the KS0 translation but with the tags associated with those critical initial states only rather than with all the initial states.\nAs an illustration, for the problem P above with actions ai and effects ai : xi → L, goal G = {L}, and initial situation I = {x1 ∨ · · · ∨ xn}, the K1(P ) translation with tags xi, i = 1, . . . , n, and the merge m = {x1, . . . , xn} for the goal literal L, is a covering translation. Theorem 30 then states that a basis S′ for P results from the collection of states si that make each tag xi true, and all the literals that are relevant to L that are not in x∗i false (i.e., all xk atoms for k 6= i). This is precisely the basis for P that we had above that includes the states that make a single atom xi true for i = 1, . . . , n: the plans that conform with this basis are then exactly the plans that conform with the whole collection of possible initial states of P . This basis has a size that is polynomial in m though, while the number of possible initial states of P is exponential in m."
    }, {
      "heading" : "8. The Planner T0",
      "text" : "The current version of the conformant planner T0 is based on two instances of the general translation scheme KT,M (P ) whose outputs are fed into the classical planner FF v2.3.8 One instance is polynomial but not necessarily complete; the other is complete but not necessarily polynomial. For the incomplete translation, T0 uses K1 that is complete for problems with width no greater than 1, and as argued above, can result in solvable instances for problems of larger widths. For the complete translation, the Kmodels translation is used instead with a simple optimization: if the K1 translation produces a single merge m that covers L, then this merge m is used for L instead of the potentially more complex one determined by Kmodels. This is a mere optimization as the resulting translation remains complete. The other merges in Kmodels, that result from the models of the set of clauses CI(L) that are consistent with I, are computed using the SAT solver relsat v2.20 (Bayardo Jr. & Schrag, 1997). In the current default mode in T0, which is the one used in the experiments below, the two translations K1 and Kmodels are used in sequence: FF is called first upon the output of K1 and if this fails, it is called upon the output of Kmodels. In the experiments below, we indicate the cases when Kmodels was invoked.\nThe translations used in T0 accommodate certain simplifications and two additional actions that capture other types of deductions. The simplifications have to do with the fact that the translations considered are all uniform in the sense that all literals L in P and all rules C → L are ’conditioned’ by each of the tags t in T . From a practical point of view, however, this is not needed. The simplifications address this source of inefficiency. In particular:\n• literals KL/t are not created when the closure t∗ contains no literal relevant to L. In such a case, the invariance KL/t ⊃ KL holds, and thus, every occurrence of the literal KL/t in KT,M (P ) is replaced by KL.\n8. The conformant planner T0 along with all the benchmarks considered in the paper are available at http://www.ldc.usb.ve/∼hlp/software.\n• support rules a : KC/t → KL/t for non-empty tags t are not created when L is not relevant to a literal L′ with a merge that contains t, as in such a case, the literal KL/t cannot contribute to establish a precondition or goal. Similarly, cancellation rules a : ¬K¬C/t → ¬K¬L/t for non-empty tags t are not created when ¬L is not relevant to a literal L′ with a merge that contains t.\n• support and cancellation rules a : KC/t → KL/t and a : ¬K¬C/t → ¬K¬L/t are grouped as a : KC/t→ KL/t∧¬K¬L/t when for every fluent L′ relevant to L, either L′ or ¬L′ is entailed by I and t. In such a case, there is no incomplete information about L given t in the initial situation, and thus the invariant KL/t or K¬L/t holds, and ¬K¬C/t is equivalent to KC/t.\nTwo other types of sound deductive rules are included in the translations:\n• a rule a : KC → KL is added if a : C,¬L→ L is a rule in P for an action a, and no rule in P has the form a : C ′ → ¬L,\n• rules K¬L1, . . . ,K¬Li−1,K¬Li+1, . . . ,K¬Ln → KLi for i = 1, . . . , n are added to a new unique action with no precondition, when L1 ∨ · · · ∨Ln is a static clause in P (a clause in P is static if true in the initial situation and provably true after any action).\nThese rules are versions of the action compilation and static disjunctions rules (Palacios & Geffner, 2006, 2007), and they appear to help in certain domains without hurting in others.\nThe version of T0 reported below does not assume that the initial situation I of P is in prime implicate form but it rather renders it in PI form by running a version of Tison’s algorithm (1967), a computation that in none of the benchmarks solved took more than 48 seconds.\nThe translators in T0 are written in OCaml while the code for parsing the PDDL files is written in C++."
    }, {
      "heading" : "9. Experimental Results",
      "text" : "We considered instances from three sources: the Conformant-FF distribution, the conformant track of the 2006 International Planning Competition (IPC5), and relevant publications (Palacios & Geffner, 2006, 2007; Cimatti et al., 2004). The instances were run on a cluster of Linux boxes at 2.33 GHz with 8GB. Each experiment had a cutoff of 2h or 2.1GB of memory. Times for T0 include all the steps, in particular, computation of prime implicates, translation, and search (done by FF). We also include results from the Conformant Track of the recent 2008 International Planning Competition (IPC6).\nGoals that are not sets of literals but sets of clauses are transformed in T0 in a standard way: each goal clause C : L1 ∨ · · · ∨ Lm is modeled by a new goal atom GC , and a new action that can be executed once is added with rules Li → GC , i = 1, . . . ,m.9\n9. An alternative way to represent such CNF goals is by converting them into DNF first and having an action End map each of its non-mutex terms into a dummy goal LG. This alternative encoding pays off in some cases, such as in the Adder-01 instance that does not get solved in the default CNF goal encoding (see below).\nTable 3 shows data concerning the translation of a group of selected instances. As it can be seen, the number of conditional effects grows considerably in all cases, and sometimes the translation may take several seconds.\nTables 4, 5, 6, 7, and 8, show the plan times and lengths obtained on a number of benchmarks by T0, POND 2.2 (Bryce et al., 2006), Conformant FF (Hoffmann & Brafman, 2006), MBP (Cimatti et al., 2004) and KACMBP (Bertoli & Cimatti, 2002). These last two planners do not accept problems in the standard syntax (based on PDDL), so only a limited number of experiments were performed on them. The general picture is that T0 scales up well in most domains, the exceptions being Square-Center and Cube-Center in Table 5, where KACMBP scales up better, Sortnet in Table 6, where KACMBP and MBP scale up better; and Adder in Table 6, where POND is the only planner able to solve one instance.\nThe problems in Table 4 are encodings from the Conformant-FF repository: Bomb-x-y refers to the Bomb-in-the-toilet problem with x packages, y toilets, and clogging; Logistics-ij-k is a variation of the classical version with uncertainty about initial location of packages; Ring-n is about closing and locking windows in a ring of n rooms without knowing the current room; and Safe-n is about opening a safe with n possible combinations. All these problems have width 1. T0 does clearly best on the last two domains, while in the first two domains, Conformant-FF does well too.\nTable 5 reports experiments on four grid domains: Cube-Center-n refers to the problem of reaching the center of a cube of size n3 from a completely unknown location; SquareCenter-n is similar but involves square with n2 possible locations; Corners-Cube-n and Corners-Square-n are variations of these problems where the set of possible initial locations is restricted to the Cube and Square corners respectively. MBP and KACMBP appear to be effective in these domains, although KACMBP doesn’t scale up well in the corner versions. T0 solves most of the problems, but in the corner versions, the quality of the plans is poor. These problems have also width 1.\nTable 6 reports experiments over problems from the 2006 International Planning Competition (Bonet & Givan, 2006). The domains Coins, Comm and UTS have all width 1. The others have max width given by the number of unknown fluents in the initial situation.\nT0 dominates in all these domains except in Adder where POND is the only planner able to solve an instance, and Sortnet, where MBP and KACMBP do very well, possibly due to use of the cardinality heuristic and OBDD representations. T0 fails on Adder because FF gets lost in the search. Looking at this problem more closely, we found that FF could solve the (translation of the) first instance in less than a minute provided that the CNF goal for this problem is encoded in DNF as explained in footnote 9, page 646. The domains Adder, Blocks, and Sortnet in the table, along with the domain Look-and-Grab in the next table, are the only domains considered where FF run on the K1 translation reports no solution after a brief search, triggering then the use of the complete Kmodels translation. In all the other cases where Kmodels was used, the K1 translation had an unreachable goal fluent and there was no need to try FF on it.\nThe problems reported in Table 7 and Table 8 are variations of a family of grid problems (Palacios & Geffner, 2006, 2007). Dispose is about retrieving objects whose initial location is unknown and placing them in a trash can at a given, known location; Push-to is a variation where objects can be picked up only at two designated positions in the grid to which all objects have to be pushed to: pushing an object from a cell into a contiguous cell moves the object if it is in the cell. 1-Dispose is a variation of Dispose where the robot hand being empty is a condition for the pick up actions to work. As a result, a plan for 1-Dispose has to scan the grid, performing pick ups in every cell, followed by excursions to the trash can, and so on. The plans can get very long (a plan is reported with 1316 actions). Look-and-Grab has an action that picks up the objects that are sufficiently close if any, and after each pickup must dump the objects it collected into the trash before continuing. For the problem P-n-m in the table, n is the grid size and m is the number of objects. For Look-n-Grab, the third parameter is the radius of the action: 1 means that the hand picks up all the objects in the 8 surrounding cells, 2 that that the hand picks up all the objects in the 15 surrounding cells, and so on. The domains in Tables 7 and 8 have width 1 except 1-Dispose and Look-n-Grab. This is because, the hand being empty is a fluent that is relevant to the goal, and clauses about the location of objects are all relevant to ’hand empty’. In all these domains T0 appears to do better than the other planners. The Kmodels translation was triggered only in the instances Look-and-Grab-n-m-r for m > 1 (the width of these instances, as mentioned in Section 6.6, is m, independent of grid size).\nWe also report some additional data in Table 9, comparing the search that results from the use of the FF planner over the classical translations in T0, to the search carried out by Conformant-FF over the original conformant problems. Conformant-FF is a conformant planner built on top of FF that searches explicitly in belief space. The table illustrates the two problems faced by belief-space planners mentioned in the introduction and the handle\nover them that results from the translation-based approach. The belief representation and update problem appears in the overhead of maintaining and evaluating the beliefs, and shows in the number of nodes that are evaluated per second: while CFF evaluates a few hundred nodes per second; FF evaluates several thousands. At the same time, the heuristic used in CFF in the conformant setting, appears to be less informed that the heuristic used by FF over the classical translations. In domains like Square-Center-n, Cube-Center-n, Blocks, and Look-and-Grab, FF needs orders-of-magnitude less nodes than CFF to find a plan, while the oppositive is true in Dispose-n-m where FF evaluates many more nodes than CFF. Nonetheless, even then, due to the overhead involved in carrying the beliefs, FF manages to solve problems that CFF cannot solve. For example, the instance Dispose-8-3 is solved by T0 after evaluating more than half a million nodes, but times out in CFF after evaluating less than three thousand nodes.\nTables 10 and 11 provide details on the results of the Conformant Track of the 2008 International Planning Competition (IPC6) (Bryce & Buffet, 2008), held almost at the time where the original version of this paper was submitted, with planner binaries submitted to the organizers a few months before. The version of T0 in IPC6 was different from the version of T0 used in IPC5, where it was the winning entry, and different also from the version reported in this paper. In relation, to the former, T0 IPC6 was a cleaner but complete reimplementation; in relation to the latter, T0 IPC6 handled problems with width greater than 1 in a different way. As explained in the previous section, the current version of T0, uses K1 as the basic translation regardless of the width of the problem, switching to Kmodels when the search over K1 fails. In the version of T0 at IPC6, the basic translation was a combination of K0 and K1; more precisely, merges for literals L with width w(L) = 1, were generated according to K1, but merges for literals L with width w(L) 6= 1 were not generated at all. The result was that the basic translation in T0 in IPC6 was lighter than the basic translation of the current version of T0 but could fail on problems with width higher than 1 that the latter can solve. Retrospectively, this was not a good choice, but it didn’t have much of an impact on the results. There was however a bug in the program that prevented two width-1 domains, Forest and Dispose, to be recognized as such, and thus resulted in the use of the Kmodels translation, that is complete for all widths, but does not scale up that well.\nThe other two conformant planners entered into IPC6 where CpA(H) and CpA(C); these are belief-space planners that represent beliefs as DNF formulas, and use simple belief-state heuristics for guiding the search (Tran, Nguyen, Pontelli, & Son, 2008, 2009). The belief progression in these planners is done quite effectively, by progressing each term in turn, according to the 0-approximation semantics. The potential blow up comes from the number of terms in the DNF formula encoding the initial belief state. Rather than choosing the terms of the initial belief state as the possible initial states, these planners limit the terms in the DNF formula to a collection of ’partial initial states’ that do not assign any truth value to the literals that are deemed irrelevant. The resulting belief representation is complete but may still result in an exponential number of terms (Son & Tu, 2006). In order to reduce further the number of terms in this initial DNF formula, ’independent’ one-of expressions are combined. For example, two independent one-of clauses oneof(x1, x2) and oneof(y1, y2) which would give rise to 4 possible initial states and DNF terms, are combined into the single one-of expression oneof(x1 ∧ y1, x2 ∧ y2), that results into 2 possible initial\nstates and terms. These one-of expressions are independent when they can be shown not to interact in the problem. The technique appears to be related to the notion of ’critical initial states’ considered in Section 7, where it was shown that plans that conform with all critical initial states must conform also with all possible initial states. The heuristics used by CpA(H) and CpA(C) are combinations of the cardinality heuristic, that measures the number of states in a belief state, the total sum heuristic, that adds the heuristic distances to the goal from each possible state, and the number of satisfied goals, that counts the number of top goals achieved. These heuristics are all very simple, yet they work well on some benchmarks.\nTables 10 and 11 show data obtained from the IPC6 organizers from the planner logs. The first table appears in the IPC6 report (Bryce & Buffet, 2008), where the new domains Forest and Rao’s keys are explained, and shows the number of problems solved by each planner, displaying in bold the planner that did best in each domain. The planner CpA(H), was declared the winner, as it was declared best in three domains (Blocks, Rao’s keys, Dispose), with T0 doing best in two domains (UTS Cycle and Forest), and CpA(C) doing best in one (Adder).\nTable 11 shows additional details on some of the instances; in particular, the total time taken to solve the instance and the length of the plans for each of the three planners.\nIn terms of domain coverage, the planners do similarly on most domains, except in Forest, where T0 solved most of the instances and CPA(H) solved few (8/9 vs. 1/9), and Dispose, where CPA(H) solved most of the instances and T0 solved few (76/90 vs. 20/90).\nIn terms of time and plan quality, CpA(H) and CpA(C) appear to be slightly faster than T0 on Blocks, but produce much longer plans. In Dispose, T0 scales up better than CpA(H) and CpA(C) over the size of the grids, and worse on the number of objects. Indeed, only T0 manages to solve the largest grid but for a single object (Dispose-10-01), and only CpA(H) and CpA(C) solve instances with more than 2 objects in the largest grids. As in most cases, plan lengths produced by T0 are shorter; e.g., the plan for Dispose-04-03 contains 125 actions for T0, 314 for CpA(H), and 320 for CpA(C).\nDispose is actually a domain where the cardinality heuristic does very well in the generation of plans, even if the plans tend to be rather long. As discussed above, in this domain, an agent has to scan a grid collecting a set of objects at unknown locations, and each time\nthe action of picking up an object from a cell that may contain the object is made (except for the first time), the cardinality of the belief state is reduced. Indeed, if initially an object may be at positions p1, p2, . . . , pn, after a pick up at p1, the object can be in positions p2, . . . , pn or in the gripper, after a pick up at p2, the object can be in positions p3, . . . , pn or in the gripper, and so on, each pick up action decreasing the cardinality of the belief state, until becoming a singleton belief where the object must be in the gripper with certainty.\nThe problem with the version of T0 used in IPC6 in the Dispose domain, was not only that FF explores too many states in the search, but as explained above, that it used the expensive Kmodels translation instead of the lighter K1 translation that is complete for this domain that has width 1. With this bug fixed, T0 solves 60 rather than 20 of the 90 Dispose instances, still failing on some of the larger grids with many objects, but producing much shorter plans. For example, Dispose-06-8 is solved with a plan with 470 actions, while CpA(H) and CpA(C) solve it with plans with 2881 and 3693 actions respectively. The same bug surfaced in the Forest domain, but it just prevented the solution of one instance only. Forest, Dispose, and UTS Cycle have all conformant widths equal to 1, while the other domains have all larger widths (see Table 2 for the widths of Blocks and Adder).\nThe second domain in IPC6 where FF got lost in the search was Adder, where indeed, T0 did not solve any instance. The instance that is shown to be solved by T0 in the competition report, appears to be a mistake. Similarly, the fourth instance of blocks, that is reported as solved by CPA(H), may be a mistake too; indeed, no plan for such an instance can be found in the logs, and T0 reports that the goal is unreachable in the Kmodels translation that is complete. According to T0, instance four of Rao’s key is unsolvable too. On the other hand, T0 failed on the larger UTS Cycle and Rao’s key instances during the translation. In the the first, the resulting PDDL’s are too large and can’t be loaded into FF; in the second, the number of init clauses turns out to be quite large (above 300), giving rise to a still larger set of prime implicates (above 5000) that caused the translator to run out of memory. The second instance of Rao’s keys, however, is rather small and T0 didn’t solve it due to a different bug. With this bug fixed, T0 solves it in 0.3 seconds, producing a plan with 53 actions, which compares well with the solutions produced by CpA(H) and CpA(C) in 0.7 and 1.9 seconds, with 85 and 99 steps, respectively."
    }, {
      "heading" : "10. Non-Deterministic Actions",
      "text" : "The translation schemes considered are all limited to problems with deterministic actions only. Nonetheless, as we illustrate below, these schemes can be applied to non-deterministic actions as well provided suitable transformations are included. We cover these transformations briefly as a matter of illustration only.\nConsider a conformant problem P with non-deterministic action effects a : C → oneof(S1, S2, . . . , Sm), where each Si is a set (conjunction) of literals, and the transformed problem P ′, where these effects are mapped into deterministic rules of the form a : C, hi → Si, with the expression oneof(h1, . . . , hm) added to the initial situation of P ′. In P ′, the ’hidden’ hi variables are used for encoding the uncertainty on the possible outcomes Si of the action a.\nIt is easy to show that the non-deterministic conformant problem P and the deterministic conformant problem P ′ are equivalent provided that only plans for P and P ′ are considered where the non-deterministic action a from P are executed at most once. Namely,\na correspondence exists between the conformant plans for P that use such actions at most once with the conformant plans for P ′ that use the same actions at most once too. On the other hand, a conformant plan for P ′ where these actions are done many times will not necessarily represent a conformant plan for P . Indeed, if a non-deterministically moves an agent up or right in a square grid n× n, starting in the bottom left corner, n actions a in a row would leave the agent at either the top left corner or the bottom right corner in P ′, and anywhere at Manhattan distance n from the origin in P. The divergence between P and P ′, however, does not arise if non-deterministic actions are executed at most once.\nBuilding on this idea, a non-deterministic conformant planner can be obtained from a deterministic conformant planner in the following way. For the non-deterministic problem P , let P1 be the problem P ′ above, with the additional constraint that the actions a in P1 arising from the non-deterministic actions in P can be executed at most once. This is easily achieved by adding a precondition enabled(a) to a that is true initially and that a sets to false. Let then P2 represent the deterministic conformant problem where each non-deterministic action a in P is mapped into 2 deterministic actions, each executable only once, and each having its own ’hidden fluents’ h1, . . . , hm with the oneof(h1, . . . , hm) expression in the initial situation. Similarly, let Pi be the deterministic problem that results from encoding each non-deterministic action in P with i deterministic ’copies’.\nFrom this encoding, a simple iterative conformant planner for non-deterministic problems P can be defined in terms of a conformant planner for deterministic problems by invoking the latter upon P1, P2, P3, and so on, until a solution is reported. The reported solution uses each copy of a ’non-deterministic action’ at most once, and thus encodes a solution to the original problem.\nWe have implemented this strategy on top of T0 with an additional refinement that takes advantage of the nature of the KT,M translation, where assumptions about the initial situation are maintained explicitly in tags. Basically, ’non-deterministic’ actions a in Pi are allowed to be executed more than once provided that all the literals KL/hi that depend on a particular outcome of these actions (Si) are erased. This is implemented by means of an additional reset(a) action in Pi whose unconditional effect is enabled(a) (i.e., the action a can then be done again) and whose conditional effects are ¬KL → ¬KL/hi and KL → KL/hi for i = 1, . . . ,m. Namely, literals KL/hi where the truth of L depends on a particular non-deterministic outcome (Si) are erased, except when L is true with no assumptions; i.e. when KL is true. Then non-deterministic actions a can be executed more than once in a plan provided that each occurrence of a, except for the first one, is preceded by a reset(a) action.\nTable 12 compares the resulting non-deterministic planner with MBP and KACMBP on a number of non-deterministic problems considered in the MBP and KACMBP papers. We have just added an additional domain, Slippery Gripper (sgripper), that is similar to classical Gripper where a number of balls have to be moved from room A to B, except that the robot cannot move from A to B directly, but has a non-deterministic move action move(A,C,D) that moves the robot from A to either C or D. A typical plan for moving two balls from A to B is to pick them at A, move to C or D, move from C to B, and from D to B, finally dropping the balls at B.\nFor the deterministic conformant planner (T0) used in the non-deterministic setting we added the following modification: merges are not introduced only for precondition and goal\nliterals but for all literals. The reason is that in this setting it pays to remove the uncertainty of all literals when the reset mechanism is used. Indeed, provided with this simple change and the reset mechanism, in none of the problems we had to move beyond P1 (a single copy of each non-deterministic action) even if in all the domains non-deterministic actions are required many times in the plans (e.g., if there are more than 2 balls in room A).\nAs it can be seen from the table, T0 does better than MBP on these collection of nondeterministic domains, although not as well as KACMBP, in particular, in the NonDetRing and Non-Det-Ring-1Key domains. In any case, the results obtained with T0 on these domains are quite meaningful. In all cases where T0 failed to solved a problem, the reason was that the classical planner (FF) got lost in the search for plans, something that may improve with further advances in classical planning technology."
    }, {
      "heading" : "11. Related Work",
      "text" : "Most recent conformant planners such as CFF, POND, and MBP cast conformant planning as an heuristic search problem in belief space (Bonet & Geffner, 2000). Compact belief representations and informed heuristic functions, however, are critical for making these approach work. As an effective belief representation, these planners use SAT and OBDDs techniques that while intractable in the worst case often exhibit good behavior on average. As heuristics, on the other hand, they use fixed cardinality heuristics that count the number of states that are possible for a given belief state (a tractable operation on OBDD representations) or heuristics obtained from a relaxed planning graph suitably extended to take uncertain information into account. These heuristics appear to work well in some domains but not in others. From this perspective, the translation-based approach provides a handle on the two problems: belief states in P become plain states in the translation KT,M (P ), that is then solved using classical heuristics. We have also established the conditions under which this belief representation is compact and complete.\nA sound but incomplete approach to planning with incomplete information is advanced by Petrick and Bacchus (2002) that represent belief states as formulas. In order to make belief updates efficient though, several approximations are introduced, and in particular, while existing disjunctions can be carried from one belief to the next, no new disjunctions are added. This imposes a limitation on the type of problems that can be handled. The two other limitations of this approach are that domains must be crafted by hand, and that no control information is derived from the domains so that the search for plans is blind. Our approach can be understood as providing a solution to these two problems too: on the one hand, the move to the ’knowledge-level’ is done automatically, on the other, the problem lifted to the knowledge-level is solved by classical planners able to search with control information derived automatically from the new representation.\nA third thread of work related to our approach arises from the so-called 0-approximation semantics (Baral & Son, 1997). In the 0-approximation semantics, belief states b are represented not by sets of states but by a single 3-valued state where fluents can be true, false, or unknown. In Proposition 3 above, a correspondence was established between the plans for P that are conformant according to the 0-approximation semantics and the classical plans for the translation K0(P ), which in turns is an instance of the more general translation Ki(P ) that is complete for problems with width i = 0. The semantics of the translation K0 is thus related to the 0-approximation semantics, yet the K0 translation delivers something more: a computational method for obtaining conformant plans that comply with the 0-approximation semantics using a classical planner.\nThe 0-approximation and the basic K0 translation are too weak for dealing with the existing benchmarks. The translations Ki extend K0 for problems of higher width by replacing the set of fluents KL by fluents KL/t where the tags t encode assumptions about the initial situation. The extensions of the 0-approximation semantics in the context of conformant planning have taken a different form: switching from a single 3-valued state for representing beliefs to sets of 3-valued states, each 3-valued state progressed efficiently and independently of the others (Son, Tu, Gelfond, & Morales, 2005). The initial set of 3-valued states is obtained by forcing states to assign a boolean truth-value (true or false) to a number of fluents. Crucial for this approach to work is the number of such fluents;\nbelief representation and update are exponential in it. The conditions that ensure the completeness of this extension of the 0-approximation semantics can be expressed in terms of a relevance analysis similar to the one underlying our analysis of width (Son & Tu, 2006): the fluents that must be set to true or false in each initial 3-valued state are those appearing in a clause in CI(L) for a precondition or goal literal L. In particular, if in the initial situation there are n tautologies pi∨¬pi, each relevant to a precondition or goal literal L, then the number of initial 3-valued states required for completeness is exponential in n, as each has to make each fluent pi true or false. The difference with our approach can be seen when each of the tautologies pi ∨¬pi is relevant to a unique precondition or goal literal Li. In such a case, the number of 3-valued or ’partial’ states required for completeness remains exponential in n, while the resulting problem has width 1 and thus can be solved with the K1 translation that involves tags with a single literal. In other words, while the tags used in our translation scheme encode the local contexts required by the different literals in the problem, the initial 3-valued states (Son & Tu, 2006) encode their possible combinations in the form of global contexts. These global contexts correspond to the consistent combinations of such local contexts, which may thus be exponential in number even if the problem has bounded width. The planners CpA(H) and CpA(C), discussed above in the context of the Conformant Track of the recent 2008 Int. Planning Competition (IPC6), build on this approach, but reduce the number of partial initial states required using a technique that can replace many one-of expressions by a single one (Tran et al., 2008, 2009); a simplification related to the notion of ’critical’ initial states discussed in Section 7.\nAnother difference with the 3-valued approach (Son et al., 2005; Son & Tu, 2006), is that the translation approach not only addresses the representation of beliefs but also the computation of conformant plans: once a conformant problem P is translated into a problem KT,M (P ), it can be solved by a classical planner. The approaches that have been defined on top of the 0-approximation semantics, like the knowledge-level approach to planning with incomplete information by Petrick and Bacchus (2002), need a way to guide the search for plans in the simplified belief space. While the search by Petrick and Bacchus (2002) is blind (iterative deepening), the search by Son et al. (2005), Son and Tu (2006) is guided by a combination of simple heuristics such as cardinality or subgoal counting."
    }, {
      "heading" : "12. Summary",
      "text" : "While few practical problems are purely conformant, the ability to find conformant plans is needed in contingent settings where conformant situations are an special case. In this paper, we have introduced a new approach to conformant planning where conformant problems P are converted into classical planning problems KT,M (P ) that are then solved by a classical planner. We have also studied the conditions under which this general translation is sound and complete. The translation depends on two parameters: a set of tags, referring to local contexts in the initial situation, and a set of merges that stand for valid disjunctions of tags. We have seen how different translations, such as KS0 and Kmodels, can be obtained from suitable choices of tags and merges, and have introduced a measure of complexity in conformant planning called conformant width, and a translation scheme Ki that is polynomial for a fixed i and complete for problems with width bounded by i. We have also shown that most conformant benchmarks have width 1, have developed a conformant planner T0\nbased on these translations, and have shown that this planner exhibits a good performance in comparison with existing conformant planners. Recently, we have explored the use of these ideas in the more general setting of contingent planning (Albore, Palacios, & Geffner, 2009)."
    }, {
      "heading" : "Acknowledgments",
      "text" : "We thank Alex Albore for help with the syntax of MBP and KACMBP, and Pierre Marquis for kindly answering a question about the complexity of a deductive task. We also thank the anonymous reviewers for useful comments. H. Geffner is partially supported by grant TIN2006-15387-C03-03."
    }, {
      "heading" : "Appendix A. Proofs",
      "text" : "P below stands for a conformant planning problem P = 〈F, I,O,G〉 and KT,M (P ) = 〈F ′, I ′, O′, G′〉 for its translation. Propositions and theorems in the body of the paper appear in the appendix with the same numbers; while new lemmas and propositions have numbers preceded by the letters A and B (for Appendix A and B). The conformant problem P and the classical problems P/s and KT,M (P ) that arise from P are all assumed to be consistent. Consistency issues are important, and they are addressed in more detail in the second part of this appendix where it is shown that if P is consistent, KT,M (P ) is consistent too (Appendix B). For a consistent classical problem P ′, the standard progression lemma applies; namely, a literal L is achieved by an applicable action sequence π+1 = π, a, where π is an action sequence and a is an action iff A) π achieves C for a rule a : C → L in P ′, or B) π achieves L and the negation ¬L′ of a literal L′ in the body C ′ of each rule in P ′ of the form a : C ′ → ¬L (see Theorem B.2 below).\nLemma A.1. Let π be an action sequence applicable in both P and K0(P ). Then if π achieves KL in K0(P ), π achieves L in P .\nProof. By induction on the length of π. If π is empty and π achieves KL in K0(P ), then KL must be in I ′, and hence L must be in I, so that π achieves L in P .\nLikewise, if π+1 = π, a achieves KL in K0(P ) then A) there is rule a : KC → KL in K0(P ), such that π achieves KC in K0(P ); or B) π achieves KL in K0(P ) and for each rule a : ¬K¬C ′ → ¬KL in K0(P ), π achieves K¬L′ in K0(P ) for some L′ in C ′.\nIf A) is true, then P must contain a rule a : C → L, and by inductive hypothesis, π must achieve C in P , and therefore, π+1 = π, a must achieve L in P . If B) is true, by inductive hypothesis, π must achieve L in P along with ¬L′ for some literal L′ in the body C ′ of each rule a : C ′ → ¬L, and thus π+1 = π, a must achieve L in P too.\nLemma A.2. If an action sequence π is applicable in K0(P ), then π is applicable in P .\nProof. If π is empty, this is trivial. Likewise, if π+1 = π, a is applicable in K0(P ), π is applicable in K0(P ), and thus by inductive hypothesis, π is applicable in P . Also since, π, a is applicable in K0(P ), π must achieve the literals KL in K0(P ) for each precondition L of a, but then from Lemma A.1, π must achieve the literals L for the same preconditions in P , and thus, the sequence π+1 = π, a is applicable in P .\nProposition 2 If π is a classical plan for K0(P ), then π is a conformant plan for P .\nProof. Direct from Lemma A.2 once we consider a problem P ′ similar to P but with a new dummy action aG whose preconditions are the goals G of P . Then if π is a plan for K0(P ), π, aG is applicable in K0(P ′), and by Lemma A.2, π, aG is applicable in P ′, which implies that π is applicable in P and achieves G, and thus, that π is a plan for P .\nProposition 3 An action sequence π is a classical plan for K0(P ) iff π is a conformant plan for P according to the 0-approximation semantics.\nProof. Let us say that an action sequence π = a0, . . . , an is 0-applicable in P and 0-achieves a literal L in P if the belief sequence b0, . . . , bn+1 generated according to the 0-approximation semantics is such that the preconditions of the actions ai in π are true in bi, and the goals are true in bn+1 respectively. From the definition of the 0-approximation semantics (and the consistency of P ), an applicable action sequence π thus 0-achieves a literal L in P iff π is empty and L ∈ I, or π = π′, a and A) a : C → L is an effect of P and π′ 0-achieves each literal L′ in C, or B) π′ 0-achieves L and for all effects a : C ′ → ¬L in P , π′ 0-achieves ¬L′ for some L′ ∈ C ′. These, however, are the conditions under which π achieves the literal KL in K0(P ) once ’a sequence 0-achieving a literal L in P ’ is replaced by ’a sequence achieving the literal KL in K0(P )’. Thus, an action sequence π that is applicable in K0(P ) and 0-applicable in P achieves a literal KL in K0(P ) iff π 0-achieves the literal L in P , while π is applicable to K0(P ) iff it is 0-applicable to P , with the last part following from the first using induction on the plan length.\nDefinition A.3. For an action a in P , define a∗ to be the action sequence where a is followed by all merges in KT,M (P ) in arbitrary order. Similarly, if π = a0, . . . , ai is an action sequence in P , define π∗ to be the action sequence π∗ = a∗0, . . . , a ∗ n in KT,M (P ).\nLemma A.4. Let π be an action sequence such that π is applicable in P and π∗ is applicable in a valid translation KT,M (P ). If π∗ achieves KL/t in KT,M (P ), then π achieves L in P/s for all possible initial states s that satisfy t.\nProof. For an empty π, if π∗ achieves KL/t, from the definition of KT,M (P ) and since I |= t ⊃ L, L must be in any such s, and thus π must achieve L in P/s.\nLikewise, if π+1 = π, a and t is not the empty tag, π∗+1 = π ∗, a∗ achieves KL/t in KT,M (P ) iff A) π∗ achieves KC/t in KT,M (P ) for a rule a : KC/t → KL/t in KT,M (P ), or B) π∗ achieves KL/t, and for any rule a : ¬K¬C ′/t → ¬KL/t, π∗ achieves K¬L′/t in KT,M (P ) for some L′ in C ′ (merge actions do not delete positive literals KL/t).\nIf A, by inductive hypothesis, π achieves C in P/s for each possible initial state s that satisfies t, and hence π+1 = π, a achieves L in P/s from the rule a : C → L that must be in P . If B, by inductive hypothesis, π achieves L and ¬L′ in P/s, for some L′ in the body of each rule a : C ′ → ¬L in P , and thus π+1 = π, a achieves L in P/s.\nFor the empty tag t = ∅, a third case must be considered: a merge action ∧\nt′∈mKL/t ′ →\nKL in a∗ may be the cause for the action sequence π∗+1 = π ∗, a∗ achieving KL in KT,M (P ). In such a case, the sequence π∗, a, and hence π∗, a∗, must achieve KL/t′ for each (nonempty) t′ ∈ m in KT,M (P ), and hence from the inductive hypothesis and the two cases above, the sequence π, a must achieve L in P/s for each possible initial state s that satisfies\nany such t′. Yet, since the merge m is valid, all possible initial states s must satisfy one such t′, and thus π must achieve L in P/s for all possible initial states s, that are the initial states that satisfy t = ∅.\nLemma A.5. If π∗ is applicable in a valid translation KT,M (P ), then π is applicable in P .\nProof. If π is empty, this is direct. For π+1 = π, a, if π∗+1 = π ∗, a∗ is applicable in KT,M (P ), then π∗ is applicable in KT,M (P ), achieving KL for each precondition L of a, and hence from the inductive hypothesis, π is applicable in P , and from Lemma A.4, π must achieve L for each precondition L of a, and thus π+1 = π, a is applicable in P .\nTheorem 7 The translation KT,M (P ) is sound provided that all merges in M are valid and all tags in T are consistent.\nProof. Consider the problem P ′ that is similar to P but with a new dummy action aG whose preconditions are the goals G of P . We have then that π∗ is a plan for KT,M (P ) iff π∗1, a ∗ G is applicable in KT,M (P\n′), which from Lemma A.5 implies that π, aG is applicable in P ′, which means that π is a plan for P .\nLemma A.6. Let π be an action sequence such that π is applicable in P and π∗ is applicable in KS0(P ). If π achieves L in P/s for some possible initial state s, π∗ achieves KL/s in KS0(P ).\nProof. If π is empty and π achieves L in P/s, then L ∈ s, and since I |= s ⊃ L, KL/s must be in I ′ and thus π∗ achieves KL/s in KS0(P ).\nLikewise, if π+1 = π, a achieves L in P/s then A) there is rule a : C → L such that π achieves C in P/s; or B) π achieves L and for any rule a : C ′ → ¬L, π achieves ¬L′ in KS0(P ) for some L′ ∈ C ′.\nIf A), by inductive hypothesis, π∗ achieves KC/s in KS0(P ) and, from rule a : KC/s→ KL/s, π∗, a must achieve KL/s, and thus, π∗+1 = π\n∗, a∗ achieves KL/s (merges in a∗ do not delete positive literals KL/t).\nIf B), by inductive hypothesis, π∗ achieves KL/s and K¬L′/s in KS0(P ) for some L′ in the body of each rule a : C ′ → ¬L in P , and therefore π∗, a achieves KL/s, and so does π∗+1 = π ∗, a∗.\nLemma A.7. If π is applicable in P , π∗ is applicable in KS0(P ).\nProof. If π is empty, this is trivial. If π+1 = π, a is applicable in P , then π must be applicable in P and must achieve each precondition L of a in P/s for every possible initial state s, s ∈ S0. From the inductive hypothesis, π∗ must then be applicable in KS0(P ), and from Lemma A.6, it must achieve the literals KL/s for all s ∈ S0, and then, the last merge action with effect ∧ s∈S0 KL/s → KL in π\n∗ must achieve KL, and so does π∗, and therefore, π∗, a∗ is applicable in KS0(P ).\nTheorem 9 If π is a conformant plan for P , then there is a classical plan π′ for KS0(P ) such that π is the result of dropping the merge actions from π′.\nProof. Direct from Lemma A.7 if we consider a problem P ′ similar to P but with a new action aG whose preconditions are the goals G of P . If π is a plan for P , the sequence π, aG is applicable in P ′, and from Lemma A.7, π∗, a∗G is applicable in KS0(P\n′), and thus π∗ is a plan for KS0(P ).\nDefinition A.8. rel(s, L) stands for the set of literals L′ in s that are relevant to L in P :\nrel(s, L) = {L′ | L′ ∈ s and L′ is relevant to L} .\nDefinition A.9. t∗ stands for the deductive closure of t under I:\nt∗ = { L | I, t |= L} .\nTheorem A.10. Let m = {t1, . . . , tn} be a covering merge for a literal L in a valid translation KT,M (P ) for a problem P whose initial situation is in prime implicate form. Then for each tag ti in m there must be a possible initial state s of P such that rel(s, L) ⊆ t∗i .\nProof. Assume otherwise that each state s satisfying I makes true a literal Ls relevant to L such that Ls 6∈ t∗i . If we then take c to be the disjunction of such literals Ls over all the states s that satisfy I, we obtain that I entails c, which since I is in prime implicate form, means that c contains a tautology c′ or is subsumed by a clause c′′ in I. But, in either case, this is a contradiction, as all the literals in c′ or c′′ are relevant to L, and hence t∗i , where ti is part of the covering merge m, must contain a literal in either c′ or c′′, and hence in c.\nLemma A.11. Let π be an action sequence such that π is applicable in P and π∗ is applicable in a covering translation KT,M (P ). Then, if π achieves L in P/s for some possible initial state s and there is a tag t in T such that rel(s, L) ⊆ t∗, π∗ achieves KL/t in KT,M (P ).\nProof. If π is empty and π achieves L in P/s, then L is in s and thus, in rel(s, L). Since rel(s, L) ⊆ t∗, then L ∈ t∗, and thus KL/t is in the initial situation I ′ of KT,M (P ), and π∗ achieves KL/t in KT,M (P ). Likewise, if π+1 = π, a achieves L in P/s, then A) there is a rule a : C → L in P such that π achieves C in P/s, or B) π achieves L in P/s and for each rule a : C ′ → ¬L, π achieves ¬L′ in P/s for some L′ in C ′. If A, by inductive hypothesis, π∗ achieves KC/t, and from the support rule a : KC/t → KL/t in KT,M (P ), π∗, a must achieve KL/t in KT,M (P ), and so must π∗+1 = π\n∗, a∗, as the merges in a∗ cannot delete a positive literal KL/t. If B, by inductive hypothesis, π∗ achieves KL/t, and for each cancellation rule a : ¬K¬C ′/t → ¬KL/t arising from the rule a : C ′ → ¬L in P , π∗ must achieve K¬L′/t for some literal L′ ∈ C ′. This means that π∗, a, and therefore, π∗+1 = π∗, a∗, must achieve KL/t.\nLemma A.12. Let KT,M (P ) be a covering translation of P . Then if π is applicable in P , π∗ is applicable in KT,M (P ).\nProof. If π is empty, this is direct. Else, if π+1 = π, a is applicable in P , then π must be applicable in P where it must achieve each literal L in Pre(a), and therefore, by inductive hypothesis π∗ must be applicable in KT,M (P ). Then, let m = {t1, . . . , tn} be a covering merge for L ∈ Pre(a) in KT,M (P ). From Theorem A.10, for each ti ∈ m there must be a\npossible initial state s such that rel(s, L) ⊆ t∗i , and then from Lemma A.11, π achieving L in P/s implies π∗ achieving KL/ti in KT,M (P ). Since this is true for all ti ∈ m and π achieves L ∈ Pre(a) in P/s for all possible initial states s, then it follows that π∗ achieves KL/ti for all ti ∈ m in KT,M (P ), and therefore that π∗ achieves KL in KT,M (P ) as π∗ ends with a sequence of merges that include the action merge am,L with effect ∧ ti∈mKL/ti → KL. As a result, π∗+1 = π ∗, a∗ is applicable in KT,M (P ).\nTheorem 15 Covering translations KT,M (P ) are complete; i.e., if π is a conformant plan for P , then there is a classical plan π′ for KT,M (P ) such that π is π′ with the merge actions removed.\nProof. The theorem follows trivially from Lemma A.12 by having a problem P ′ that is like P but with an additional, dummy action aG such that the goals G of P are the preconditions of aG. The action sequence π is a plan for P iff the action sequence π, aG is applicable in P ′, which due to Lemma A.12 implies that the action sequence π∗, a∗G is applicable in KT,M (P\n′) which in turn is true iff the action sequence π∗ is a plan for KT,M (P ). The sequence π, in turn, is the sequence π∗ with all the merge actions removed.\nTheorem 17 The translation Kmodels(P ) is sound and complete.\nProof. Direct from the merges m generated by Kmodels for each precondition and goal literals L. Clearly these merges are all valid, their tags are consistent with I, and they cover L (the models of CI(L) all satisfy CI(L)). Thus the result follows from Theorems 7 and 15.\nProposition 21 The width w(P ) of P can be determined in time that is exponential in w(P ).\nProof. If m is the number of clauses in C∗I (L), then there are at most m i sets of clauses C in C∗I (L) such that |C| = i. Each clause in one such set must have at most n literals, where n is the number of fluents in P , and hence, if one literal from each clause in C is collected, we end up with at most ni sets of literals of size no greater than i, some of which are inconsistent with I and some of which are consistent and minimal (no other consistent set in the collection is properly included); both tests being polynomial given that I is in prime implicate form. Thus constructing the cover c(C) for a set of clauses C with |C| = i is exponential in i, while checking whether one such cover satisfies CI(L) is a polynomial operation provided that I is in prime implicate form. Indeed, if c(C) = {t1, . . . , tn}, computing the closures t∗i for each ti ∈ c(C), when I is in PI, and testing whether each t∗i intersects each clause in CI(L) are polynomial operations (the former reducing to checking for each literal L′ whether I |= ¬t∗i ∨ L′). Thus for computing width(L), we generate all sets C of clauses in C∗I (L) with |C| = i, starting with i = 0, increasing i one by one until for one such set, c(C) satisfies CI(L). This computation is exponential in w(L), and the computation over all preconditions and goal literals in P is exponential in w(P ).\nProposition 22 The width of P is such that 0 ≤ w(P ) ≤ n, where n is the number of fluents whose value in the initial situation is not known.\nProof. The inequality 0 ≤ w(P ) is direct as w(L) is defined as the size |C| of the minimal set of clauses C in C∗I (L) such that c(C) satisfies CI(L), and w(P ) = w(L) for some precondition and goal literal L. The inequality w(P ) ≤ n follows by noticing that for the set C of clauses given by the tautologies L′∨¬L′ in C∗I (L), c(C) must satisfy each clause c in CI(L), as each t ∈ c(C) must assign a truth value to each literal in c, and if inconsistent with c, it will be inconsistent with I and thus pruned from c(C). Finally, the max number of such tautologies in C∗I (L) is the number of fluents L ′ such that neither L′ nor ¬L′ are unit clauses in I.\nTheorem 24 For a fixed i, the translation Ki(P ) is sound, polynomial, and if w(P ) ≤ i, covering and complete.\nProof. For soundness, we just need to prove that all merges m in Ki(P ) are valid and that all tags t in Ki(P ) are consistent. The soundness follows from Theorem 7. The merges m for a literal L in Ki(P ) are given by the covers c(C) of collections C of i or less clauses in C∗i (L) and clearly since each model M of I must satisfy C∗I (L), it must satisfy some t ∈ c(C) so that I |= ∨ t∈m t for m = c(C). At the same time, from the definition of the cover c(C), each of these tags t must be consistent with I. For proving that Ki is polynomial for a fixed i, we follow ideas similar to the ones used in the proof of Proposition 21 above, where we have shown that the width of P can be determined in time that is exponential in w(P ) and polynomial in the number of clauses and fluents in P . For a fixed i, the number of sets of clauses C in C∗I (L) with size |C| ≤ i is polynomial, and the complexity of computing the covers c(C) for such sets, and hence, the merges m for L in Ki(P ) is polynomial too. Thus, the whole translation Ki(P ) for a fixed i is polynomial in the number of clauses, fluents, and rules in P .\nFinally, for proving completeness, if w(P ) ≤ i, then w(L) ≤ i for each precondition and goal literal L in P . Therefore, for each such literal L, there is a set C of clauses in C∗I (L) such that c(C) satisfies CI(L). The translation Ki(P ) will then generate a unique merge for L that covers L. Since Ki(P ) is a valid translation, this means that Ki(P ) is a covering translation, that is then complete, by virtue of Theorem 15.\nLemma A.13. If L′ is relevant to L and rel(s, L) ⊆ rel(s′, L), then rel(s, L′) ⊆ rel(s′, L′).\nProof. If L′′ is in rel(s, L′), then L′′ is relevant to L′, and since L′ is relevant to L and the relevance relation is transitive, L′′ is relevant to L. Thus, L′′ is in rel(s, L) and therefore, since rel(s, L) ⊆ rel(s′, L), L′′ is in rel(s′, L). But then L′′ is in s′ and since it is relevant to L′, L′′ is in rel(s′, L′).\nProposition 26 Let s and s′ be two states and let π be an action sequence applicable in the classical problems P/s and P/s′. Then if π achieves a literal L in P/s′ and rel(s′, L) ⊆ rel(s, L), π achieves the literal L in P/s.\nProof. By induction on the length of π. If π is empty, and π achieves a literal L in P/s′, L must be in s′, and since L is relevant to itself, L ∈ rel(s′, L). Then as rel(s′, L) ⊆ rel(s, L), L must be in s, and thus π achieves L in P/s.\nLikewise, if π+1 = π, a achieves L in P/s′ then A) there is rule a : C → L such that π achieves C in P/s′; or B) π achieves L in P/s′ and for any rule a : C ′ → ¬L, π achieves ¬L′ in P/s′ for some L′ ∈ C ′.\nIf A, π must achieve each literal Li ∈ C in P/s′. Since Li is relevant to L and rel(s′, L) ⊆ rel(s, L), by Lemma A.13, rel(s′, Li) ⊆ rel(s, Li). Then, by inductive hypothesis, the plan π must achieve Li in P/s for each Li ∈ C, and thus π+1 = π, a must achieve L in P/s\nIf B, since each such ¬L′ is relevant to L (as L′ is relevant to ¬L), and rel(s′, L) ⊆ rel(s, L), by Lemma A.13, rel(s′,¬L′) ⊆ rel(s,¬L′), and thus by inductive hypothesis, π must achieve ¬L′ in P/s and also L, so that π+1 = π, a must achieve L in P/s.\nLemma A.14. If S and S′ are two collection of states such that for every state s in S and every precondition and goal literal L in P , there is a state s′ in S′ such that rel(s′, L) ⊆ rel(s, L), then if π is applicable in P/S′, π is applicable in P/S.\nProof. By induction on the length of π. If π is empty, it is obvious. If π+1 = π, a is applicable in P/S′, then π is applicable in P/S′ and, by inductive hypothesis, π is applicable in P/S. We need to prove that π achieves the preconditions of action a in P/S.\nFor any L ∈ Prec(a) and any s ∈ S, from the hypothesis, there is a state s′ ∈ S′ such that rel(s′, L) ⊆ rel(s, L). From Proposition 26, and since π achieves L in P/s′, π must achieve L in P/s. Since the argument applies to any s ∈ S, π achieves L in P/S, and thus π+1 = π, a must be applicable in P/S.\nProposition 27 If S and S′ are two collections of states such that for every state s in S and every precondition and goal literal L in P , there is a state s′ in S′ such that rel(s′, L) ⊆ rel(s, L), then if π is a plan for P that conforms with S′, π is a plan for P that conforms with S.\nProof. From Lemma A.14, we consider a problem P ′ similar to P but with a new action aG whose preconditions are the goals G of P . If π is a plan for P that conforms with S′, then the action sequence π, aG is applicable in P ′/S′, and then from the lemma, π, aG is applicable in P ′/S, and thus π must be a plan for P/S\nProposition 28 S′ is a basis for P if for every possible initial state s of P and every precondition and goal literal L in P , S′ contains a state s′ such that rel(s′, L) ⊆ rel(s, L).\nProof. Direct from Proposition 27, by considering S to be the set of possible initial states of P .\nProposition 29 If the initial situation I is in prime implicate form and m = {t1, . . . , tn} is a merge that covers a literal L in P , then the set S[ti, L] of possible initial states s of P such that rel(s, L) ⊆ t∗i is non-empty.\nProof. Direct from Theorem A.10.\nTheorem 30 Let KT,M (P ) be a covering translation and let S′ stand for the collection of states s[ti, L] where L is a precondition or goal literal of P and ti is a tag in a merge m that covers L. Then S′ is a basis for P .\nProof. We show that for every possible initial state s and any precondition and goal literal L, S′ in the theorem contains a state s′ such that rel(s′, L) ⊆ rel(s, L). The result then follows from Proposition 28. Indeed, any such state s must satisfy a tag ti in a covering merge m = {t1, . . . , tn} for L, as these merges are valid. But from Theorem A.10, there must be a possible initial state s′ such that rel(s′, L) ⊆ t∗i , and therefore, rel(s′, L) ⊆ rel(s, L) as s must satisfy t∗i and possibly other literals L ′ that are relevant to L.\nTheorem 31 If P is a conformant planning problem with bounded width, then P admits a basis of polynomial size.\nProof. If w(P ) ≤ i for a fixed i, Ki(P ) is a covering translation with a polynomial number of merges and tags, and in such case, the basis S′ for P defined by Theorem 30 contains a polynomial number of states, regardless of the number of possible initial states."
    }, {
      "heading" : "Appendix B. Consistency",
      "text" : "We have been assuming throughout the paper that the conformant planning problems P and their translations KT,M (P ) are consistent. In this section we make this notion precise, explain why it is needed, and prove that KT,M (P ) is consistent if P is. For the proof, we take into account that the heads KL of the merge actions am,L in KT,M (P ), are extended with the literals K¬L′ for the literals L′ that are mutex with L in P (see Definition 4).\nWe start at the beginning assuming that states are not truth-assignments but sets of literals over the fluents of the language. A state is complete if for every literal L, L or ¬L is in s, and consistent if for no literal both L and ¬L are in s. Complete and consistent states represent truth-assignments over the fluents F and the consistency of P and of the translation KT,M (P ) ensures that all applicable action sequences π map complete and consistent states s into complete and consistent states s′. Once this is guaranteed, complete and consistent states can be referred to simply as states which is what we have done in the paper.\nGiven a complete state s and an action a applicable in s, the next state sa is\nsa = (s \\Del(a, s)) ∪Add(a, s)\nwhere Add(a, s) = {L | a : C → L in P and C ⊆ s}\nand Del(a, s) = {¬L |L ∈ Add(a, s)} .\nIt follows from this that sa is a complete state if s is a complete state, as the action a only ’deletes’ a literal L in s if ¬L is added by a in s. On the other hand, s may be consistent and sa inconsistent, as for example, when there are rules a : C → L and a : C ′ → ¬L such that both C and C ′ are in s. In order to exclude this possibility, ensuring that all reachable states are complete and consistent, and thus represent genuine truth assignments over the fluents in F , a consistency condition on P is needed:\nDefinition B.1 (Consistency). A classical or conformant problem P = 〈F, I,O,G〉 is consistent if the initial situation I is logically consistent and every pair of complementary literals L and ¬L is mutex in P .\nIn a consistent classical problem P , all the reachable states are complete and consistent, and the standard progression lemma used in the preceding proofs holds:\nTheorem B.2 (Progression). An action sequence π+1 = π, a applicable in the complete and consistent state s achieves a literal L in a consistent classical problem P iff A) π achieves the body C of a rule a : C → L in P , or B) π achieves L and for every rule a : C ′ → ¬L, π achieves ¬L′ for a literal L′ in C ′.\nWe will see below that if a conformant problem P is consistent in this sense, so will be any valid translation KT,M (P ). We have tested all the benchmarks considered in this paper for consistency and found all of them to be consistent except for two domains that we have introduced elsewhere: 1-Dispose and Look-and-Grab. In these cases, since the consistency of the classical problem KT,M (P ) cannot be inferred from the consistency of P , it can be checked explicitly using Definition B.1, or similarly, the plans that are obtained from KT,M (P ) can be checked for consistency as indicated in Section 8: the soundness of these plans is ensured provided that they never trigger conflicting effects KL/t and ¬KL/t.10\nProof. The proof of Theorem B.2 does not rest on a particular definition of mutexes, just that mutex atoms are not both true in a reachable state. In a consistent problem P , an applicable action sequence π maps s into a complete and consistent state s′ that represents a truth assignment. Then, the action sequence π+1 = π, a achieves L iff C) L ∈ Add(a, s′) or D) L ∈ s′ and ¬L 6∈ Del(a, s′). Condition A in the theorem, however, is equivalent to C, and Condition B in the theorem, is equivalent to D. Indeed, L 6∈ Del(a, s′) iff for each rule a : C ′ → ¬L there is a literal L′ ∈ C ′ such that L′ 6∈ s′, which, given that s′ is complete and consistent, is true iff ¬L′ ∈ s′ (this is precisely where consistency is needed; else ¬L′ ∈ s′ would not imply L′ 6∈ s′).\nThe notion of mutex used in the definition of consistency expresses a guarantee that a pair of literals is not true in a reachable state. Sufficient and polynomial conditions for mutual exclusivity and other type of invariants have been defined in various papers, here we follow the definition by Bonet and Geffner (1999).\nDefinition B.3 (Mutex Set). A mutex set is a collection R of unordered literals pairs (L,L′) over a classical or conformant problem P such that:\n1. for no pair (L,L′) in R, both L and L′ are in a possible initial state s,\n2. if a : C → L and a : C ′ → L′ are two rules for the same action where (L,L′) is a pair in R, then Pre(a) ∪ C ∪ C ′ is mutex in R, and\n3. if a : C → L is a rule in P for a literal L in a pair (L,L′) in R, then either a) L′ = ¬L, b) Pre(a) ∪ C is mutex with L′ in R, or c) Pre(a) ∪ C implies C ′ in R for a rule a : C ′ → ¬L′ in P ;\n10. The consistency of the two domains, 1-Dispose and Look-and-Grab, can be established however if a definition of mutexes slightly stronger than the one below is used. It actually suffices to change the expression Pre(a) ∪ C in clause 3c) of the definition of mutex sets below by Pre(a) ∪ C ∪ {L′}.\nIn this definition, a pair is said to be mutex in R if it belongs to R, a set of literals S is said to be mutex in R if S contains a pair in R, and a set of literals S is said to imply a set of literals S′ in R when S is mutex in R with the complement ¬L of each literal L in S′ \\S.\nIt easy to verify that if R1 and R2 are mutex sets, their union R1 ∪ R2 is a mutex set, and thus that there is a maximal mutex set for P that we denote as R∗. The pairs in R∗ are just called mutexes. For simplicity and without loss of generality, we will assume that preconditions Pre(a) are empty. Indeed, it is simple to show that the mutexes of a problem P remain the same if preconditions are pushed in as conditions. We also assume that no condition C in a rule C → L in P is mutex, as these rules can be simply pruned. In addition, we assume that no literal L is mutex with a pair of complementary literals L′ and ¬L′, as then L cannot be true in a reachable state, and thus, can be pruned as well.\nThe definition of mutexes is sound, meaning that no pair in a mutex set can be true in a reachable state:\nTheorem B.4. If (L,L′) is a pair in a mutex set R of a classical or conformant problem P , then for no reachable state s in P , {L,L′} ⊆ s.\nProof. We proceed inductively. Clearly, L and L′ cannot be part of a possible initial state, as this is ruled out by the definition of mutex sets. Thus, let us assume as inductive hypothesis that L and L′ are not part of any state s reachable in less than i steps, and let us prove that the same is true for the states s′ = sa that are reachable from s in one step. Clearly if L and L′ belong to s′, then either A) both L and L′ belong to Add(a, s), or B) L belongs to Add(a, s) and L′ belongs to s but not to Del(a, s). We show that this is not possible. For A, P must comprise rules a : C → L and a : C ′ → L′ such that C ∪ C ′ ⊆ s, yet from the definition of mutex sets, C ∪C ′ must be mutex, and from the inductive hypothesis then C ∪ C ′ 6⊆ s. For B, there must be a rule a : C → L with C ⊆ s, but then from L′ ∈ s and the inductive hypothesis, it follows that L′ is not mutex with C in R, and thus, from the mutex set definition, that either L′ = ¬L or C implies C ′ for a rule a : C ′ → ¬L′. In the first case, however, due to the rule a : C → L and C ⊆ s, L′ ∈ Del(a, s), while in the second case, from the completeness of all reachable states, we must have C ′ ⊆ s, and hence L′ ∈ Del(a, s), contradicting B in both cases.\nProvided that the initial situation I of a conformant planning problem P is in prime implicate form, computing the largest mutex set R∗ and testing the consistency of P are polynomial time operations. For the former, one starts with the set of literal pairs and then iteratively drops from this set the pairs that do not comply with the definition until reaching a fixed point (Bonet & Geffner, 1999).\nWe move on now to prove that if a conformant problem P is consistent, so is a valid translation KT,M (P ). The consistency of the classical problems P/s for possible initial states s is direct, as the set of mutexes in P is a subset of the set of mutexes in P/s where the initial situation is more constrained.\nProposition B.5 (Mutex Set RT ). For a valid translation KT,M (P ) of a consistent conformant problem P , define RT to be the set of (unordered) literals pairs (KL/t,KL′/t′) and (KL/t,¬K¬L′/t) where (L,L′) is a mutex in P , and t and t′ are two tags jointly satisfiable with I (I 6|= ¬(t ∪ t′)). Then RT is a mutex set in KT,M (P ).\nIt follows from this that KT,M (P ) is consistent if P is consistent, as then L′ = ¬L is mutex with L in P , and so (KL/t,¬KL/t) must be a mutex in RT .\nTheorem B.6 (Consistency KT,M (P )). A valid translation KT,M (P ) is consistent if P is consistent.\nThe consistency of the translation K0(P ) follows as a special case, as K0(P ) is KT,M (P ) with an empty set of merges M and a set of tags T containing only the empty tag. We are left to prove Proposition B.5.\nProof of Proposition B.5. We must show that the setRT comprised of the pairs (KL/t,KL′/t′) and (KL/t,¬K¬L′/t) for L′ mutex with L in P , and tags t and t′ jointly satisfiable with I, is a set that complies with clauses 1, 2, and 3 of Definition B.3. We go one clause at a time.\n1. No pair in RT can be true initially in KT,M (P ) = 〈F ′, I ′, O′, G′〉 for jointly satisfiable I, t, and t′. Indeed, if both KL/t and KL′/t′ are in I ′ there must be a possible initial state satisfying t and t′ where L and L′ are true in contradiction with L and L′ being mutex in P . Similarly, if KL/t is in I ′ but K¬L′/t not, it must be the case that I |= t ⊃ L and I 6|= t ⊃ ¬L′, so that there must be some possible initial state of P where t, L, and L′ hold, a contradiction with L and L′ being mutex in P too.\n2. If there is an action a with rules for KL/t and KL′/t′ then the rules must be support rules of the form a : KC/t → KL/t and a : KC ′/t′ → KL′/t′ arising from rules a : C → L and a : C ′ → L′ in P .11 Then since L and L′ are mutex in P , C and C ′ must contain literals L1 ∈ C and L2 ∈ C ′ such that (L1, L2) is a mutex in P , and hence (KL1/t,KL2/t′) belongs to RT , so that KC/t and KC ′/t′ are mutex in RT as well.\nSimilarly, if there is an action with rules for KL/t and ¬K¬L′/t for a literal L′ mutex with L in P , the rules must be support and cancellation rules of the form a : KC/t → KL/t a : ¬K¬C ′/t → ¬K¬L′/t, arising from rules a : C → L and a : C ′ → L′ in P . Since L and L′ are mutex in P , C and C ′ must contain literals L1 ∈ C and L2 ∈ C ′ that are mutex in P , and hence RT must contain the pair (KL1/t,¬K¬L2/t), so that KC/t and ¬K¬C ′/t must be mutex in RT .\n3. We are left to show that the set RT given by the pairs (KL/t,KL′/t′) and (KL/t, ¬K¬L′/t) complies with clause 3 in the definition of mutex sets as well. Consider the first class of pairs (KL/t,KL′/t′) and a rule a : KC/t→ KL/t for KL/t arising from a rule a : C → L in P . Since L is mutex with L′ in P , then one of the conditions 3a, 3b, or 3c must hold for the rule a : C → L and L′. If 3a, then L′ = ¬L, and KC/t must imply the body ¬K¬C/t′ of the cancellation rule a : ¬K¬C/t′ → ¬K¬L/t′, as for each literal L1 in C, RT must contain the pair (KL1/t,K¬L1/t′) so that KL1/t implies ¬K¬L1/t′, and KC/t implies ¬K¬C/t′ (case 3c). If 3b, then C and L′ are\n11. The action a cannot be a merge for a literal L′′ mutex with both ¬L and ¬L′, as in such case, L′′ implies that L and L′ that are mutex. Similarly, a cannot be a merge for L as in such a case, L will be mutex with both L′ and ¬L′. For the same reason, a cannot be a merge for L′ either. Thus, the action a above cannot be a merge and must be an action from P .\nmutex in P , and thus C contains a literal L1 mutex with L′ in P . This means that the pair (KL1/t,KL′/t′) is in RT and hence that KC/t is mutex with KL′/t′ in RT (case 3b). Last, if 3c, C implies C ′ in P for a rule a : C ′ → ¬L′, but then KC/t must imply the body ¬K¬C ′/t′ of the cancellation rule a : ¬K¬C ′/t′ → ¬KL′/t′. Indeed, for each literal L1 in both C and C ′, we had above that KL1/t implies ¬K¬L1/t′, while if L2 is a literal in C ′ but not in C, then some literal L3 ∈ C must be mutex with ¬L2 in P , and hence the pair (KL3/t,K¬L2/t′) must be in RT and KL3/t implies then ¬K¬L2/t′ (case 3c) Consider now the same pair (KL/t,KL′/t′) along with a merge action am,L with a rule ∧ ti∈mKL/ti → KL for KL/t = KL (thus t is the empty tag). In this case, since the merge m is valid and t′ is consistent, there must be some ti ∈ m such that ti and t′ are jointly consistent with I. It follows then that (KL/ti,KL′/t′) is a pair in RT and thus that the body of the merge is mutex with KL′/t′ in RT (case 3b). There is no need to consider the pair (KL/t,KL′/t′) along with the rules for KL′/t′, as the literals KL/t and KL′/t′ have the same structure, and thus the same argument above applies, replacing t with t′ and L with L′.\nWe switch now to the second class of pairs (KL/t,¬K/¬L′/t) and the rules a : KC/t→ KL/t for KL/t. Since L and L′ are mutex in P , then conditions 3a, 3b, or 3c must hold. If a, then L′ = ¬L, and in such a case, condition 3c holds in KT,M (P ) as KC/t implies the body KC/t of the rule a : KC/t → K¬L′ (¬L′ = L). If b, C is mutex with L′, and thus there is a literal L1 in C such that L1 and L′ are mutex in P , and therefore KC/t and KL′/t are mutex in RT (case 3b). Finally, if c, C implies C ′ for a rule a : C ′ → ¬L′ in P , then KC/t must imply KC ′/t in RT for a rule a : KC ′/t→ K¬L′/t (case 3c). For the empty tag t, the rule for KL/t may also be a merge, but then due to the extra effects K¬L′ in the merge action for L, the merge for KL is also a merge for K¬L′, and then case 3c holds.\nLast, for the same class of pairs, the only rules for ¬K¬L′/t are cancellation rules of the form a : ¬K¬C ′′/t→ ¬K¬L′/t for a rule a : C ′′ → L′ in P . Since L′ is mutex with L in P , then conditions 3a, 3b, or 3c must hold for the rule a : C ′′ → L′ and L′ in P . If a, then L = ¬L′, and the cancellation rule is then a : ¬K¬C ′′/t→ ¬KL (case 3c). If b, C ′′ is mutex with L, and thus there is a literal L2 in C ′′ such that (L2, L) is a mutex in P , and therefore KL/t implies K¬L2/t in RT , and hence ¬K¬L2/t and ¬K¬C ′′/t imply ¬KL/t in RT (case 3b). Finally, if c, C ′′ implies C ′ for a rule a : C ′ → ¬L in P , and then ¬K¬C ′′/t must imply ¬K¬C ′/t for a rule a : ¬K¬C ′/t → ¬KL/t in RT . Indeed, if LA implies LB in P , ¬LB implies ¬LA in P , and K¬LB/t implies K¬LA/t in RT , and ¬K¬LA/t implies ¬K¬LB/t."
    } ],
    "references" : [ {
      "title" : "A translation-based approach to contingent planning",
      "author" : [ "A. Albore", "H. Palacios", "H. Geffner" ],
      "venue" : "In Proc. 21st Int. Joint Conference on AI (IJCAI-09),",
      "citeRegEx" : "Albore et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Albore et al\\.",
      "year" : 2009
    }, {
      "title" : "Computational complexity of planning and approximate planning in the presence of incompleteness",
      "author" : [ "C. Baral", "V. Kreinovich", "R. Trejo" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Baral et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Baral et al\\.",
      "year" : 2000
    }, {
      "title" : "Approximate reasoning about actions in presence of sensing and incomplete information",
      "author" : [ "C. Baral", "T.C. Son" ],
      "venue" : "In Proc. ILPS",
      "citeRegEx" : "Baral and Son,? \\Q1997\\E",
      "shortCiteRegEx" : "Baral and Son",
      "year" : 1997
    }, {
      "title" : "Using CSP look-back techniques to solve real-world sat instances",
      "author" : [ "R. Bayardo Jr.", "R. Schrag" ],
      "venue" : "In Proc. AAAI,",
      "citeRegEx" : "Jr. and Schrag,? \\Q1997\\E",
      "shortCiteRegEx" : "Jr. and Schrag",
      "year" : 1997
    }, {
      "title" : "Improving heuristics for planning as search in belief space",
      "author" : [ "P. Bertoli", "A. Cimatti" ],
      "venue" : "Proc. AIPS-2002,",
      "citeRegEx" : "Bertoli and Cimatti,? \\Q2002\\E",
      "shortCiteRegEx" : "Bertoli and Cimatti",
      "year" : 2002
    }, {
      "title" : "Planning as heuristic search: New results",
      "author" : [ "B. Bonet", "H. Geffner" ],
      "venue" : "In Proceedings of ECP-99,",
      "citeRegEx" : "Bonet and Geffner,? \\Q1999\\E",
      "shortCiteRegEx" : "Bonet and Geffner",
      "year" : 1999
    }, {
      "title" : "Planning with incomplete information as heuristic search in belief space",
      "author" : [ "B. Bonet", "H. Geffner" ],
      "venue" : "In Proc. of AIPS-2000,",
      "citeRegEx" : "Bonet and Geffner,? \\Q2000\\E",
      "shortCiteRegEx" : "Bonet and Geffner",
      "year" : 2000
    }, {
      "title" : "Planning as heuristic search",
      "author" : [ "B. Bonet", "H. Geffner" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Bonet and Geffner,? \\Q2001\\E",
      "shortCiteRegEx" : "Bonet and Geffner",
      "year" : 2001
    }, {
      "title" : "Results of the conformant track of the 5th int. planning competition",
      "author" : [ "B. Bonet", "B. Givan" ],
      "venue" : "At http://www.ldc.usb.ve/∼bonet/ipc5/docs/results-conformant.pdf",
      "citeRegEx" : "Bonet and Givan,? \\Q2006\\E",
      "shortCiteRegEx" : "Bonet and Givan",
      "year" : 2006
    }, {
      "title" : "International planning competition uncertainty part: Benchmarks and results",
      "author" : [ "D. Bryce", "O. Buffet" ],
      "venue" : "At http://ippc-2008.loria.fr/wiki/images/0/03/Results.pdf",
      "citeRegEx" : "Bryce and Buffet,? \\Q2008\\E",
      "shortCiteRegEx" : "Bryce and Buffet",
      "year" : 2008
    }, {
      "title" : "Planning graph heuristics for belief space search",
      "author" : [ "D. Bryce", "S. Kambhampati", "D.E. Smith" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Bryce et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Bryce et al\\.",
      "year" : 2006
    }, {
      "title" : "Conformant planning via symbolic model checking and heuristic search",
      "author" : [ "A. Cimatti", "M. Roveri", "P. Bertoli" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Cimatti et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Cimatti et al\\.",
      "year" : 2004
    }, {
      "title" : "Constraint Processing",
      "author" : [ "R. Dechter" ],
      "venue" : null,
      "citeRegEx" : "Dechter,? \\Q2003\\E",
      "shortCiteRegEx" : "Dechter",
      "year" : 2003
    }, {
      "title" : "Expressive planning and explicit knowledge",
      "author" : [ "R.P. Goldman", "M.S. Boddy" ],
      "venue" : "In Proc. AIPS-1996,",
      "citeRegEx" : "Goldman and Boddy,? \\Q1996\\E",
      "shortCiteRegEx" : "Goldman and Boddy",
      "year" : 1996
    }, {
      "title" : "Some results on the complexity of planning with incomplete information",
      "author" : [ "P. Haslum", "P. Jonsson" ],
      "venue" : "In Proc. ECP-99, Lect. Notes in AI Vol",
      "citeRegEx" : "Haslum and Jonsson,? \\Q1999\\E",
      "shortCiteRegEx" : "Haslum and Jonsson",
      "year" : 1999
    }, {
      "title" : "Contingent planning via heuristic forward search with implicit belief states",
      "author" : [ "J. Hoffmann", "R. Brafman" ],
      "venue" : "In Proc. 15th Int. Conf. on Automated Planning and Scheduling (ICAPS",
      "citeRegEx" : "Hoffmann and Brafman,? \\Q2005\\E",
      "shortCiteRegEx" : "Hoffmann and Brafman",
      "year" : 2005
    }, {
      "title" : "Conformant planning via heuristic forward search: A new approach",
      "author" : [ "J. Hoffmann", "R. Brafman" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Hoffmann and Brafman,? \\Q2006\\E",
      "shortCiteRegEx" : "Hoffmann and Brafman",
      "year" : 2006
    }, {
      "title" : "The FF planning system: Fast plan generation through heuristic search",
      "author" : [ "J. Hoffmann", "B. Nebel" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Hoffmann and Nebel,? \\Q2001\\E",
      "shortCiteRegEx" : "Hoffmann and Nebel",
      "year" : 2001
    }, {
      "title" : "Consequence finding algorithms",
      "author" : [ "P. Marquis" ],
      "venue" : "Handbook on Defeasible Reasoning and Uncertainty Management Systems,",
      "citeRegEx" : "Marquis,? \\Q2000\\E",
      "shortCiteRegEx" : "Marquis",
      "year" : 2000
    }, {
      "title" : "Compiling uncertainty away: Solving conformant planning problems using a classical planner (sometimes)",
      "author" : [ "H. Palacios", "H. Geffner" ],
      "venue" : "In Proc",
      "citeRegEx" : "Palacios and Geffner,? \\Q2006\\E",
      "shortCiteRegEx" : "Palacios and Geffner",
      "year" : 2006
    }, {
      "title" : "From conformant into classical planning: Efficient translations that may be complete too",
      "author" : [ "H. Palacios", "H. Geffner" ],
      "venue" : "In Proc. ICAPS-07,",
      "citeRegEx" : "Palacios and Geffner,? \\Q2007\\E",
      "shortCiteRegEx" : "Palacios and Geffner",
      "year" : 2007
    }, {
      "title" : "A knowledge-based approach to planning with incomplete information and sensing",
      "author" : [ "R. Petrick", "F. Bacchus" ],
      "venue" : "In Proc. AIPS-02,",
      "citeRegEx" : "Petrick and Bacchus,? \\Q2002\\E",
      "shortCiteRegEx" : "Petrick and Bacchus",
      "year" : 2002
    }, {
      "title" : "Complexity of planning with partial observability",
      "author" : [ "J. Rintanen" ],
      "venue" : "In Proc. ICAPS2004,",
      "citeRegEx" : "Rintanen,? \\Q2004\\E",
      "shortCiteRegEx" : "Rintanen",
      "year" : 2004
    }, {
      "title" : "Conformant graphplan",
      "author" : [ "D. Smith", "D. Weld" ],
      "venue" : "In Proceedings AAAI-98,",
      "citeRegEx" : "Smith and Weld,? \\Q1998\\E",
      "shortCiteRegEx" : "Smith and Weld",
      "year" : 1998
    }, {
      "title" : "Conformant planning for domains with constraints: A new approach",
      "author" : [ "T.C. Son", "P.H. Tu", "M. Gelfond", "A. Morales" ],
      "venue" : "In Proc",
      "citeRegEx" : "Son et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Son et al\\.",
      "year" : 2005
    }, {
      "title" : "On the completeness of approximation based reasoning and planning in action theories with incomplete information",
      "author" : [ "T.C. Son", "P.H. Tu" ],
      "venue" : "In Proc. 10th Int. Conf. on Principles of KR and Reasoning",
      "citeRegEx" : "Son and Tu,? \\Q2006\\E",
      "shortCiteRegEx" : "Son and Tu",
      "year" : 2006
    }, {
      "title" : "Generalized consensus theory and applications to the minimization of boolean circuits",
      "author" : [ "P. Tison" ],
      "venue" : "IEEE Transactions on Computers,",
      "citeRegEx" : "Tison,? \\Q1967\\E",
      "shortCiteRegEx" : "Tison",
      "year" : 1967
    }, {
      "title" : "CPA(C)/(H): Two approximationbased conformant planners",
      "author" : [ "D. Tran", "H. Nguyen", "E. Pontelli", "T.C. Son" ],
      "venue" : "At http://ippc-2008.loria.fr/wiki/images/5/57/Team2CPA.pdf",
      "citeRegEx" : "Tran et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Tran et al\\.",
      "year" : 2008
    }, {
      "title" : "Improving performance of conformant planners: Static analysis of declarative planning domain specifications",
      "author" : [ "D. Tran", "H. Nguyen", "E. Pontelli", "T.C. Son" ],
      "venue" : "In Practical Aspects of Declarative Languages, 11th International Symposium, PADL 2009,Proceedings,",
      "citeRegEx" : "Tran et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Tran et al\\.",
      "year" : 2009
    }, {
      "title" : "Polynomial-length planning spans the polynomial hierarchy",
      "author" : [ "H. Turner" ],
      "venue" : "In JELIA ’02: Proc. of the European Conference on Logics in AI,",
      "citeRegEx" : "Turner,? \\Q2002\\E",
      "shortCiteRegEx" : "Turner",
      "year" : 2002
    } ],
    "referenceMentions" : [ {
      "referenceID" : 29,
      "context" : "Conformant planning is computationally harder than classical planning, as even under polynomial restrictions on plan length, plan verification remains hard (Haslum & Jonsson, 1999; Baral, Kreinovich, & Trejo, 2000; Turner, 2002; Rintanen, 2004).",
      "startOffset" : 156,
      "endOffset" : 244
    }, {
      "referenceID" : 22,
      "context" : "Conformant planning is computationally harder than classical planning, as even under polynomial restrictions on plan length, plan verification remains hard (Haslum & Jonsson, 1999; Baral, Kreinovich, & Trejo, 2000; Turner, 2002; Rintanen, 2004).",
      "startOffset" : 156,
      "endOffset" : 244
    }, {
      "referenceID" : 19,
      "context" : "This work is a revision and extension of the formulation presented by Palacios and Geffner (2007), which in turn is based on ideas first sketched also by Palacios and Geffner (2006).",
      "startOffset" : 70,
      "endOffset" : 98
    }, {
      "referenceID" : 19,
      "context" : "This work is a revision and extension of the formulation presented by Palacios and Geffner (2007), which in turn is based on ideas first sketched also by Palacios and Geffner (2006).",
      "startOffset" : 70,
      "endOffset" : 182
    }, {
      "referenceID" : 1,
      "context" : "Conformant planning is computationally harder than classical planning, as plan verification remains hard even under polynomial restrictions on plan length (Haslum & Jonsson, 1999; Baral et al., 2000; Turner, 2002; Rintanen, 2004).",
      "startOffset" : 155,
      "endOffset" : 229
    }, {
      "referenceID" : 29,
      "context" : "Conformant planning is computationally harder than classical planning, as plan verification remains hard even under polynomial restrictions on plan length (Haslum & Jonsson, 1999; Baral et al., 2000; Turner, 2002; Rintanen, 2004).",
      "startOffset" : 155,
      "endOffset" : 229
    }, {
      "referenceID" : 22,
      "context" : "Conformant planning is computationally harder than classical planning, as plan verification remains hard even under polynomial restrictions on plan length (Haslum & Jonsson, 1999; Baral et al., 2000; Turner, 2002; Rintanen, 2004).",
      "startOffset" : 155,
      "endOffset" : 229
    }, {
      "referenceID" : 19,
      "context" : "An extension of the basic translation K0 that allows a limited form of disjunctive reasoning is presented by Palacios and Geffner (2006). The extension is based on the introduction of new literals L/Xi used for encoding the conditionals Xi ⊃ L.",
      "startOffset" : 109,
      "endOffset" : 137
    }, {
      "referenceID" : 19,
      "context" : "We use the notation KL/t rather than L/t as used by Palacios and Geffner (2006), because there is a distinction between ¬KL/t and K¬L/t: roughly ¬KL/t means that the conditional K(t0 ⊃ L) is not true, while K¬L/t means that the conditional K(t0 ⊃ ¬L) is true.",
      "startOffset" : 52,
      "endOffset" : 80
    }, {
      "referenceID" : 11,
      "context" : "An example of this is the Square-Center-n task (Cimatti et al., 2004), where an agent has to reach the center of an empty square grid with certainty, not knowing its initial location.",
      "startOffset" : 47,
      "endOffset" : 69
    }, {
      "referenceID" : 10,
      "context" : "Planning Competition (Bonet & Givan, 2006): POND (Bryce et al., 2006) and Conformant FF (Hoffmann & Brafman, 2006) (the other two planners in the competition were translationbased: T0, based on the formulation developed in this paper, and K(P ), based on an earlier and more restricted formulation due to Palacios & Geffner, 2006).",
      "startOffset" : 49,
      "endOffset" : 69
    }, {
      "referenceID" : 18,
      "context" : "We will thus assume that I is in prime implicate (PI) form (Marquis, 2000), meaning that I includes only the inclusion-minimal clauses that it entails but no tautologies.",
      "startOffset" : 59,
      "endOffset" : 74
    }, {
      "referenceID" : 25,
      "context" : "which is equivalent to 4 in the context of 1–3, the resulting definition is the one by Son and Tu (2006), where the notion of relevance is used to generate a limited set of possible ’partial’ initial states over which the 0-approximation is complete (see Section 11 for a discussion on the relation between tags and partial initial states).",
      "startOffset" : 87,
      "endOffset" : 105
    }, {
      "referenceID" : 12,
      "context" : "For this, we define a structural parameter that we call the conformant width of a problem P , that in analogy to the notion of width used in graphical models (Dechter, 2003), will provide an upper bound on the time and space complexity required for generating a covering translation.",
      "startOffset" : 158,
      "endOffset" : 173
    }, {
      "referenceID" : 26,
      "context" : "The version of T0 reported below does not assume that the initial situation I of P is in prime implicate form but it rather renders it in PI form by running a version of Tison’s algorithm (1967), a computation that in none of the benchmarks solved took more than 48 seconds.",
      "startOffset" : 170,
      "endOffset" : 195
    }, {
      "referenceID" : 11,
      "context" : "We considered instances from three sources: the Conformant-FF distribution, the conformant track of the 2006 International Planning Competition (IPC5), and relevant publications (Palacios & Geffner, 2006, 2007; Cimatti et al., 2004).",
      "startOffset" : 178,
      "endOffset" : 232
    }, {
      "referenceID" : 10,
      "context" : "2 (Bryce et al., 2006), Conformant FF (Hoffmann & Brafman, 2006), MBP (Cimatti et al.",
      "startOffset" : 2,
      "endOffset" : 22
    }, {
      "referenceID" : 11,
      "context" : ", 2006), Conformant FF (Hoffmann & Brafman, 2006), MBP (Cimatti et al., 2004) and KACMBP (Bertoli & Cimatti, 2002).",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 9,
      "context" : "The data is from Bryce and Buffet (2008)",
      "startOffset" : 17,
      "endOffset" : 41
    }, {
      "referenceID" : 21,
      "context" : "A sound but incomplete approach to planning with incomplete information is advanced by Petrick and Bacchus (2002) that represent belief states as formulas.",
      "startOffset" : 87,
      "endOffset" : 114
    }, {
      "referenceID" : 24,
      "context" : "Another difference with the 3-valued approach (Son et al., 2005; Son & Tu, 2006), is that the translation approach not only addresses the representation of beliefs but also the computation of conformant plans: once a conformant problem P is translated into a problem KT,M (P ), it can be solved by a classical planner.",
      "startOffset" : 46,
      "endOffset" : 80
    }, {
      "referenceID" : 21,
      "context" : "The approaches that have been defined on top of the 0-approximation semantics, like the knowledge-level approach to planning with incomplete information by Petrick and Bacchus (2002), need a way to guide the search for plans in the simplified belief space.",
      "startOffset" : 156,
      "endOffset" : 183
    }, {
      "referenceID" : 21,
      "context" : "The approaches that have been defined on top of the 0-approximation semantics, like the knowledge-level approach to planning with incomplete information by Petrick and Bacchus (2002), need a way to guide the search for plans in the simplified belief space. While the search by Petrick and Bacchus (2002) is blind (iterative deepening), the search by Son et al.",
      "startOffset" : 156,
      "endOffset" : 304
    }, {
      "referenceID" : 21,
      "context" : "The approaches that have been defined on top of the 0-approximation semantics, like the knowledge-level approach to planning with incomplete information by Petrick and Bacchus (2002), need a way to guide the search for plans in the simplified belief space. While the search by Petrick and Bacchus (2002) is blind (iterative deepening), the search by Son et al. (2005), Son and Tu (2006) is guided by a combination of simple heuristics such as cardinality or subgoal counting.",
      "startOffset" : 156,
      "endOffset" : 368
    }, {
      "referenceID" : 21,
      "context" : "The approaches that have been defined on top of the 0-approximation semantics, like the knowledge-level approach to planning with incomplete information by Petrick and Bacchus (2002), need a way to guide the search for plans in the simplified belief space. While the search by Petrick and Bacchus (2002) is blind (iterative deepening), the search by Son et al. (2005), Son and Tu (2006) is guided by a combination of simple heuristics such as cardinality or subgoal counting.",
      "startOffset" : 156,
      "endOffset" : 387
    }, {
      "referenceID" : 5,
      "context" : "Sufficient and polynomial conditions for mutual exclusivity and other type of invariants have been defined in various papers, here we follow the definition by Bonet and Geffner (1999).",
      "startOffset" : 159,
      "endOffset" : 184
    } ],
    "year" : 2009,
    "abstractText" : "Conformant planning is the problem of finding a sequence of actions for achieving a goal in the presence of uncertainty in the initial state or action effects. The problem has been approached as a path-finding problem in belief space where good belief representations and heuristics are critical for scaling up. In this work, a different formulation is introduced for conformant problems with deterministic actions where they are automatically converted into classical ones and solved by an off-the-shelf classical planner. The translation maps literals L and sets of assumptions t about the initial situation, into new literals KL/t that represent that L must be true if t is initially true. We lay out a general translation scheme that is sound and establish the conditions under which the translation is also complete. We show that the complexity of the complete translation is exponential in a parameter of the problem called the conformant width, which for most benchmarks is bounded. The planner based on this translation exhibits good performance in comparison with existing planners, and is the basis for T0, the best performing planner in the Conformant Track of the 2006 International Planning Competition.",
    "creator" : "TeX"
  }
}