{
  "name" : "1509.06849.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Minimum Weight Perfect Matching via Blossom Belief Propagation",
    "authors" : [ "Sungsoo Ahn", "Sejun Park", "Michael Chertkov", "Jinwoo Shin" ],
    "emails" : [ "chertkov@lanl.gov", "ssahn0215@kaist.ac.kr,", "sejun.park@kaist.ac.kr,", "jinwoos@kaist.ac.kr" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Graphical Models (GMs) provide a useful representation for reasoning in a number of scientific disciplines [1, 2, 3, 4]. Such models use a graph structure to encode the joint probability distribution, where vertices correspond to random variables and edges specify conditional dependencies. An important inference task in many applications involving GMs is to find the most-likely assignment to the variables in a GM, i.e., Maximum-A-Posteriori (MAP). Belief Propagation (BP) is a popular algorithm for approximately solving the MAP inference problem and it is an iterative, message passing one that is exact on tree structured GMs. BP often shows remarkably strong heuristic performance beyond trees, i.e., over loopy GMs. Furthermore, BP is of a particular relevance to large-scale problems due to its potential for parallelization [5] and its ease of programming within the modern programming models for parallel computing, e.g., GraphLab [6], GraphChi [7] and OpenMP [8]. ∗M. Chertkov is with the Theoretical Division at Los Alamos National Laboratory, USA. Author’s e-mail: chertkov@lanl.gov †S. Ahn, S. Park and J. Shin are with the Department of Electrical Engineering at Korea Advanced Institute of Science Technology, Republic of Korea. Authors’ e-mails: ssahn0215@kaist.ac.kr, sejun.park@kaist.ac.kr, jinwoos@kaist.ac.kr\nar X\niv :1\n50 9.\n06 84\n9v 1\n[ cs\n.D S]\n2 3\nSe p\n20 15\nThe convergence and correctness of BP was recently established for a certain class of loopy GM formulations of several classical combinatorial optimization problems, including matching [9, 10, 11], perfect matching [12], shortest path [13], independent set [14], network flow [15] and vertex cover [16]. The important common feature of these models is that BP converges to a correct assignment when the Linear Programming (LP) relaxation of the combinatorial optimization is tight, i.e., when it shows no integrality gap. The LP tightness is an inevitable condition to guarantee the performance of BP and no combinatorial optimization instance has been known where BP would be used to solve problems without the LP tightness. On the other hand, in the LP literature, it has been extensively studied how to enforce the LP tightness via solving multiple intermediate LPs that are systematically designed, e.g., via the cutting-plane method [22]. Motivated by these studies, we pose a similar question for BP, “how to enforce correctness of BP, possibly by solving multiple intermediate BPs”. In this paper, we show how to resolve this question for the minimum weight (or cost) perfect matching problem over arbitrary graphs.\nContribution. We develop an algorithm, coined Blossom-BP, for solving the minimum weight matching problem over an arbitrary graph. Our algorithm solves multiple intermediate BPs until the final BP outputs the solution. The algorithm is sequential, where each step includes running BP over a ‘contracted’ graph derived from the original graph by contractions and infrequent expansions of blossoms, i.e., odd sets of vertices. To build such a scheme, we first design an algorithm, coined Blossom-LP, solving multiple intermediate LPs. Second, we show that each LP is solvable by BP using the recent framework [16] that establishes a generic connection between BP and LP. For the first part, cutting-plane methods solving multiple intermediate LPs for the minimum weight matching problem have been discussed by several authors over the past decades [17, 18, 19, 20, 21] and a provably polynomial-time scheme was recently suggested [22]. However, LPs in [22] were quite complex to solve by BP. To address the issue, we design much simpler intermediate LPs that allow utilizing the framework of [16].\nWe prove that Blossom-BP and Blossom-LP guarantee to terminate inO(n2) of BP and LP runs, respectively, where n is the number of vertices in the graph. To establish the polynomial complexity, we show that intermediate outputs of Blossom-BP and Blossom-LP are equivalent to those of a variation of the Blossom-V algorithm [23] which is the latest implementation of the Blossom algorithm due to Kolmogorov. The main difference is that Blossom-V updates parameters by maintaining disjoint tree graphs, while Blossom-BP and Blossom-LP implicitly achieve this by maintaining disjoint cycles, claws and tree graphs. Notice, however, that these combinatorial structures are auxiliary, as required for proofs, and they do not appear explicitly in the algorithm descriptions. Therefore, they are much easier to implement than Blossom-V that maintains complex data structures, e.g., priority queues. To the best of our knowledge, Blossom-BP and Blossom-LP are the simplest possible algorithms available for solving the problem in polynomial time. Our proof implies that in essence, Blossom-BP offers a distributed version of the Edmonds’ Blossom algorithm [24] jumping at once over many sub-steps of Blossom-V with a single BP.\nThe subject of solving convex optimizations (other than LP) via BP was discussed in the literature [25, 26, 27]. However, we are not aware of any similar attempts to solve Integer Programming, via sequential application of BP. We believe that the approach developed in this paper is of a broader interest, as it promises to advance the challenge of designing BP-based MAP solvers for a broader class of GMs. Furthermore, Blossom-LP stands alone as providing an interpretation for the Edmonds’ algorithm in terms of a sequence of tractable LPs. The Edmonds’ original LP formulation contains exponentially many constraints, thus naturally\nsuggesting to seek for a sequence of LPs, each with a subset of constraints, gradually reducing the integrality gap to zero in a polynomial number of steps. However, it remained illusive for decades: even when the bipartite LP relaxation of the problem has an integral optimal solution, the standard Edmonds’ algorithm keeps contracting and expanding a sequence of blossoms. As we mentioned earlier, we resolve the challenge by showing that Blossom-LP is (implicitly) equivalent to a variant of the Edmonds’ algorithm with three major modifications: (a) parameter-update via maintaining cycles, claws and trees, (b) addition of small random corrections to weights, and (c) initialization using the bipartite LP relaxation.\nOrganization. In Section 2, we provide backgrounds on the minimum weight perfect matching problem and the BP algorithm. Section 3 describes our main result – Blossom-LP and Blossom-BP algorithms, where the proof is given in Section 4."
    }, {
      "heading" : "2 Preliminaries",
      "text" : ""
    }, {
      "heading" : "2.1 Minimum weight perfect matching",
      "text" : "Given an (undirected) graph G = (V,E), a matching of G is a set of vertex-disjoint edges, where a perfect matching additionally requires to cover every vertices ofG. Given integer edge weights (or costs) w = [we] ∈ Z|E|, the minimum weight (or cost) perfect matching problem consists in computing a perfect matching which minimizes the summation of its associated edge weights. The problem is formulated as the following IP (Integer Programming):\nminimize w · x subject to ∑ e∈δ(v) xe = 1, ∀v ∈ V, x = [xe] ∈ {0, 1}|E|\n(1)\nWithout loss of generality, one can assume that weights are strictly positive.1 Furthermore, we assume that IP (1) is feasible, i.e., there exists at least one perfect matching in G. One can naturally relax the above integer constraints to x = [xe] ∈ [0, 1]|E| to obtain an LP (Linear Programming), which is called the bipartite relaxation. The integrality of the bipartite LP relaxation is not guaranteed, however it can be enforced by adding the so-called blossom inequalities [23]:\nminimize w · x subject to ∑ e∈δ(v) xe = 1, ∀v ∈ V, ∑ e∈δ(S) xe ≥ 1, ∀S ∈ L, x = [xe] ∈ [0, 1]|E|,\n(2)\nwhere L ⊂ 2V is a collection of odd cycles in G, called blossoms, and δ(S) is a set of edges between S and V \\ S. It is known that if L is the collection of all the odd cycles in G, then LP (2) always has an integral solution. However, notice that the number of odd cycles is exponential in |V |, thus solving LP (2) is computationally intractable. To overcome this complication we are looking for a tractable subset of L of a polynomial size which guarantees the integrality. Our algorithm, searching for such a tractable subset of L is iterative: at each iteration it adds or subtracts a blossom.\n1If some edges have negative weights, one can add the same positive constant to all edge weights, and this does not alter the solution of IP (1)."
    }, {
      "heading" : "2.2 Background on max-product Belief Propagation",
      "text" : "The max-product Belief Propagation (BP) algorithm is a popular heuristic for approximating the MAP assignment in a GM. BP is implemented iteratively; at each iteration t, it maintains four messages {mtα→i(c),mti→α(c) : c ∈ {0, 1}} between every variable zi and every associated α ∈ Fi, where Fi := {α ∈ F : i ∈ α}; that is, Fi is a subset of F such that all α in Fi include the ith position of z for any given z. The messages are updated as follows:\nmt+1α→i(c) = maxzα:zi=c ψα(zα) ∏ j∈α\\i mtj→α(zj) (3)\nmt+1i→α(c) = ψi(c) ∏\nα′∈Fi\\α\nmtα′→i(c). (4)\nwhere each zi only sends messages to Fi; that is, zi sends messages to αj only if αj selects/includes i. The outer-term in the message computation (3) is maximized over all possible zα ∈ {0, 1}|α| with zi = c. The inner-term is a product that only depends on the variables zj (excluding zi) that are connected to α. The message-update (4) from variable zi to factor ψα is a product containing all messages received by ψα in the previous iteration, except for the message sent by zi itself.\nGiven a set of messages {mi→α(c), mα→i(c) : c ∈ {0, 1}}, the so-called BP marginal beliefs are computed as follows:\nbi[zi] = ψi(zi) ∏ α∈Fi mα→i(zi). (5)\nThis BP algorithm outputs zBP = [zBPi ] where\nzBPi =  1 if bi[1] > bi[0] ? if bi[1] = bi[0] 0 if bi[1] < bi[0] .\nIt is known that zBP converges to a MAP assignment after a sufficient number of iterations, if the factor graph is a tree and the MAP assignment is unique. However, if the graph contains loops, the BP algorithm is not guaranteed to converge to a MAP assignment in general."
    }, {
      "heading" : "2.3 Belief propagation for linear programming",
      "text" : "A joint distribution of n (binary) random variables Z = [Zi] ∈ {0, 1}n is called a Graphical Model (GM) if it factorizes as follows: for z = [zi] ∈ Ωn,\nPr[Z = z] ∝ ∏\ni∈{1,...,n} ψi(zi) ∏ α∈F ψα(zα),\nwhere {ψi, ψα} are (given) non-negative functions, the so-called factors; F is a collection of subsets\nF = {α1, α2, ..., αk} ⊂ 2{1,2,...,n}\n(each αj is a subset of {1, 2, . . . , n} with |αj | ≥ 2); zα is the projection of z onto dimensions included in α.2 In particular, ψi is called a variable factor. Assignment z∗ is called\n2For example, if z = [0, 1, 0] and α = {1, 3}, then zα = [0, 0].\na maximum-a-posteriori (MAP) solution if z∗ = arg maxz∈{0,1}n Pr[z]. Computing a MAP solution is typically computationally intractable (i.e., NP-hard) unless the induced bipartite graph of factors F and variables z, so-called factor graph, has a bounded treewidth [28]. The max-product Belief Propagation (BP) algorithm is a popular simple heuristic for approximating the MAP solution in a GM, where it iterates messages over a factor graph. BP computes a MAP solution exactly after a sufficient number of iterations, if the factor graph is a tree and the MAP solution is unique. However, if the graph contains loops, BP is not guaranteed to converge to a MAP solution in general. Due to the space limitation, we provide detailed backgrounds on BP in the supplemental material.\nConsider the following GM: for x = [xi] ∈ {0, 1}n and w = [wi] ∈ Rn,\nPr[X = x] ∝ ∏ i e−wixi ∏ α∈F ψα(xα), (6)\nwhere F is the set of non-variable factors and the factor function ψα for α ∈ F is defined as\nψα(xα) = { 1 if Aαxα ≥ bα, Cαxα = dα 0 otherwise ,\nfor some matrices Aα, Cα and vectors bα, dα. Now we consider the Linear Program (LP) corresponding to this GM:\nminimize w · x subject to ψα(xα) = 1, ∀α ∈ F, x = [xi] ∈ [0, 1]n.\n(7)\nOne observes that the MAP solution for GM (6) corresponds to the (optimal) solution of LP (7) if the LP has an integral solution x∗ ∈ {0, 1}n. Furthermore, the following sufficient conditions relating max-product BP to LP are known [16]:\nTheorem 1 The max-product BP applied to GM (6) converges to the solution of LP (7) if the following conditions hold:\nC1. LP (7) has a unique integral solution x∗ ∈ {0, 1}n, i.e., it is tight.\nC2. For every i ∈ {1, 2, . . . , n}, the number of factors associated with xi is at most two, i.e., |Fi| ≤ 2.\nC3. For every factor ψα, every xα ∈ {0, 1}|α| with ψα(xα) = 1, and every i ∈ α with xi 6= x∗i , there exists γ ⊂ α such that\n|{j ∈ {i} ∪ γ : |Fj | = 2}| ≤ 2\nψα(x ′ α) = 1, where x ′ k = { xk if k /∈ {i} ∪ γ x∗k otherwise .\nψα(x ′′ α) = 1, where x ′′ k = { xk if k ∈ {i} ∪ γ x∗k otherwise ."
    }, {
      "heading" : "3 Main result: Blossom Belief Propagation",
      "text" : "In this section, we introduce our main result – an iterative algorithm, coined Blossom-BP, for solving the minimum weight perfect matching problem over an arbitrary graph, where the algorithm uses the max-product BP as a subroutine. We first describe the algorithm using LP instead of BP in Section 3.1, where we call it Blossom-LP. Its BP implementation is explained in Section 3.2."
    }, {
      "heading" : "3.1 Blossom-LP algorithm",
      "text" : "Let us modify the edge weights: we ← we+ne,where ne is an i.i.d. random number chosen in the interval [ 0, 1|V | ] . Note that the solution of the minimum weight perfect matching problem (1) remains the same after this modification since sum of the overall noise is smaller than 1. The Blossom-LP algorithm updates the following parameters iteratively.\n◦ L ⊂ 2V : a laminar collection of odd cycles in G.\n◦ yv, yS : v ∈ V and S ∈ L.\nIn the above, L is called laminar if for every S, T ∈ L, S ∩ T = ∅, S ⊂ T or T ⊂ S. We call S ∈ L an outer blossom if there exists no T ∈ L such that S ⊂ T . Initially, L = ∅ and yv = 0 for all v ∈ V . The algorithm iterates between Step A and Step B and terminates at Step C.\nBlossom-LP algorithm\nA. Solving LP on a contracted graph. First construct an auxiliary (contracted) graph G† = (V †, E†) by contracting every outer blossom in L to a single vertex, where the weights w† = [w†e : e ∈ E†] are defined as\nw†e = we − ∑\nv∈V :v 6∈V †,e∈δ(v)\nyv − ∑\nS∈L:v(S)6∈V †,e∈δ(S)\nyS , ∀ e ∈ E†.\nWe let v(S) denote the blossom vertex in G† coined as the contracted graph and solve the following LP:\nminimize w† · x subject to ∑ e∈δ(v)\nxe = 1, ∀ v ∈ V †, v is a non-blossom vertex∑ e∈δ(v) xe ≥ 1, ∀ v ∈ V †, v is a blossom vertex x = [xe] ∈ [0, 1]|E †|.\n(8)\nB. Updating parameters. After we obtain a solution x = [xe : e ∈ E†] of LP (8), the parameters are updated as follows:\n(a) If x is integral, i.e., x ∈ {0, 1}|E†| and ∑\ne∈δ(v) xe = 1 for all v ∈ V †, then proceed to the termination step C.\n(b) Else if there exists a blossom S such that ∑\ne∈δ(v(S)) xe > 1, then we choose one of such blossoms and update\nL ← L\\{S} and yv ← 0, ∀ v ∈ S.\nCall this step ‘blossom S expansion’.\n(c) Else if there exists an odd cycle C in G† such that xe = 1/2 for every edge e in it, we choose one of them and update\nL ← L ∪ {V (C)} and yv ← 1\n2 ∑ e∈E(C) (−1)d(e,v)w†e, ∀v ∈ V (C),\nwhere V (C), E(C) are the set of vertices and edges of C, respectively, and d(v, e) is the graph distance from vertex v to edge e in the odd cycle C. The algorithm also remembers the odd cycle C = C(S) corresponding to every blossom S ∈ L.\nIf (b) or (c) occur, go to Step A.\nC. Termination. The algorithm iteratively expands blossoms in L to obtain the minimum weighted perfect matching M∗ as follows:\n(i) Let M∗ be the set of edges in the original G such that its corresponding edge e in the contracted graph G† has xe = 1, where x = [xe] is the (last) solution of LP (8).\n(ii) If L = ∅, output M∗.\n(iii) Otherwise, choose an outer blossom S ∈ L, then update G† by expanding S, i.e. L ← L\\{S}.\n(iv) Let v be the vertex in S covered by M∗ and MS be a matching covering S\\{v} using the edges of odd cycle C(S).\n(v) Update M∗ ←M∗ ∪MS and go to Step (ii).\nWe provide the following running time guarantee for this algorithm, which is proven in Section 4.\nTheorem 2 Blossom-LP outputs the minimum weight perfect matching in O(|V |2) iterations."
    }, {
      "heading" : "3.2 Blossom-BP algorithm",
      "text" : "In this section, we show that the algorithm can be implemented using BP. The result is derived in two steps, where the first one consists in the following theorem.\nTheorem 3 LP (8) always has a half-integral solution x∗ ∈ { 0, 12 , 1 }|E†| such that the collection of its half-integral edges forms disjoint odd cycles.\nProof. For the proof of Theorem 3, once we show the half-integrality of LP (8), it is easy to check that the half-integral edges forms disjoint odd cycles. Hence, it suffices to show that every vertex of the polytope consisting of constraints of LP (8) is always half-integral. To this end, we use the following lemma which is proven in the appendix.\nLemma 4 LetA = [Aij ] ∈ {0, 1}m×m be an invertible 0-1 matrix whose row has at most two non-zero entires. Then, each entry A−1ij of A −1 is in { 0,±1,±12 } .\nConsider a vertex x ∈ [0, 1]|E†| of the polytope consisting of constraints of LP (8). Then, there exists a linear system of equalities such that x is its unique solution where each equality is either xe = 0, xe = 1 or ∑ e∈δ(v) xe = 1. One can plug xe = 0 and xe = 1 into the linear system, reducing it to Ax = b where A is an invertible 0-1 matrix whose column contains at most two non-zero entries. Hence, from Lemma 4, x is half-integral. This completes the proof of Theorem 3.\nNext let us design BP for obtaining the half-integral solution of LP (8). First, we duplicate each edge e ∈ E† into e1, e2 and define a new graphG‡ = (V †, E‡) whereE‡ = {e1, e2 : e ∈ E‡}. Then, we build the following equivalent LP:\nminimize w‡ · x subject to ∑ e∈δ(v)\nxe = 2, ∀ v ∈ V †, v is a non-blossom vertex∑ e∈δ(v) xe ≥ 2, ∀ v ∈ V †, v is a blossom vertex x = [xe] ∈ [0, 1]|E †|,\n(9)\nwhere w‡e1 = w ‡ e2 = w † e. One can easily observe that solving LP (9) is equivalent to solving LP (8) due to our construction of G‡, w‡, and LP (9) always have an integral solution due to Theorem 3. Now, construct the following GM for LP (9):\nPr[X = x] ∝ ∏ e∈E‡ ew ‡ exe ∏ v∈V † ψv(xδ(v)), (10)\nwhere the factor function ψv is defined as\nψv(xδ(v)) =  1 if v is a non-blossom vertex and ∑ e∈δ(v) xe = 2 1 else if v is a blossom vertex and ∑\ne∈δ(v) xe ≥ 2 0 otherwise .\nFor this GM, we derive the following corollary of Theorem 1 proven in the appendix.\nCorollary 5 If LP (9) has a unique solution, then the max-product BP applied to GM (10) converges to it.\nThe uniqueness condition stated in the corollary above is easy to guarantee by adding small random noise corrections to edge weights. Corollary 5 shows that BP can compute the halfintegral solution of LP (8)."
    }, {
      "heading" : "4 Proof of Theorem 2",
      "text" : "First, it is relatively easy to prove the correctness of Blossom-BP, as stated in the following lemma.\nLemma 6 If Blossom-LP terminates, it outputs the minimum weight perfect matching.\nProof. We let x† = [x†e], y‡ = [y‡v, y‡S : v /∈ V †, v(S) /∈ V †] denote the parameter values at the termination of Blossom-BP. Then, the strong duality theorem and the complementary slackness condition imply that\nx†e(w † − y†u − y†v) = 0, ∀e = (u, v) ∈ E†. (11)\nwhere y† be a dual solution of x†. Here, observe that y† and y‡ cover y-variables inside and outside of V †, respectively. Hence, one can naturally define y∗ = [y†v y ‡ u] to cover all yvariables, i.e., yv, yS for all v ∈ V, S ∈ L. If we define x∗ for the output matching M∗ of Blossom-LP as x∗e = 1 if e ∈M∗ and x∗e = 0 otherwise, then x∗ and y∗ satisfy the following complementary slackness condition:\nx∗e ( we − y∗u − y∗v − ∑ S∈L y∗S ) = 0, ∀e = (u, v) ∈ E, y∗S  ∑ e∈δ(S) x∗e − 1  = 0, ∀S ∈ L, where L is the last set of blossoms at the termination of Blossom-BP. In the above, the first equality is from (11) and the definition of w†, and the second equality is because the construction of M∗ in Blossom-BP is designed to enforce ∑ e∈δ(S) x ∗ e = 1. This proves that x\n∗ is the optimal solution of LP (2) and M∗ is the minimum weight perfect matching, thus completing the proof of Lemma 6.\nTo guarantee the termination of Blossom-LP in polynomial time, we use the following notions.\nDefinition 1 Claw is a subset of edges such that every edge in it shares a common vertex, called center, with all other edges, i.e., the claw forms a star graph.\nDefinition 2 Given a graph G = (V,E), a set of odd cycles O ⊂ 2E , a set of clawsW ⊂ 2E and a matching M ⊂ E, (O,W,M) is called cycle-claw-matching decomposition of G if all sets in O∪W ∪{M} are disjoint and each vertex v ∈ V is covered by exactly one set among them.\nTo analyze the running time of Blossom-BP, we construct an iterative auxiliary algorithm that outputs the minimum weight perfect matching in a bounded number of iterations. The auxiliary algorithm outputs a cycle-claw-matching decomposition at each iteration, and it terminates when the cycle-claw-matching decomposition corresponds to a perfect matching. We will prove later that the auxiliary algorithm and Blossom-LP are equivalent and, therefore, conclude that the iteration of Blossom-LP is also bounded.\nTo design the auxiliary algorithm, we consider the following dual of LP (8):\nminimize ∑ v∈V † yv\nsubject to w†e − yv − yu ≥ 0, ∀e = (u, v) ∈ E†, yv(S) ≥ 0, ∀S ∈ L. (12)\nNext we introduce an auxiliary iterative algorithm which updates iteratively the blossom set L and also the set of variables yv, yS for v ∈ V, S ∈ L. We call edge e = (u, v) ‘tight’ if\nwe − yu − yv − ∑\nS∈L:e∈δ(S)\nyS = 0.\nNow, we are ready to describe the auxiliary algorithm having the following parameters.\n◦ G† = (V †, E†), L ⊂ 2V , and yv, yS for v ∈ V, S ∈ L.\n◦ (O,W,M): A cycle-claw-matching decomposition of G†\n◦ T ⊂ G†: A tree graph consisting of + and − vertices.\nInitially, set G† = G and L, T = ∅. In addition, set yv, yS by an optimal solution of LP (12) with w† = w and (O,W,M) by the cycle-claw-matching decomposition of G† consisting of tight edges with respect to [yv, yS ]. The parameters are updated iteratively as follows.\nThe auxiliary algorithm\nIterate the following steps until M becomes a perfect matching:\n1. Choose a vertex r ∈ V † from the following rule.\nExpansion. If W 6= ∅, choose a claw W ∈ W of center blossom vertex c and choose a non-center vertex r in W . Remove the blossom S(c) corresponding to c from L and update G† by expanding it. Find a matching M ′ covering all vertices in W and S(c) except for r and update M ←M ∪M ′.\nContraction. Otherwise, choose a cycle C ∈ O, add and remove it from L and O, respectively. In addition, G† is also updated by contracting C and choose the contracted vertex r in G† and set yr = 0.\nSet tree graph T having r as + vertex and no edge.\n2. Continuously increase yv of every + vertex v in T and decrease yv of − vertex v in T by the same amount until one of the following events occur:\nGrow. If a tight edge (u, v) exists where u is a + vertex of T and v is covered by M , find a tight edge (v, w) ∈M . Add edges (u, v), (v, w) to T and remove (v, w) from M where v, w becomes −,+ vertices of T , respectively.\nMatching. If a tight edge (u, v) exists where u is a + vertex of T and v is covered by C ∈ O, find a matching M ′ that covers T ∪ C. Update M ← M ∪M ′ and remove C from O.\nCycle. If a tight edge (u, v) exists where u, v are + vertices of T , find a cycle C and a matching M ′ that covers T . Update M ←M ∪M ′ and add C to O.\nClaw. If a blossom vertex v(S) with yv(S) = 0 exists, find a claw W (of center v(S)) and a matching M ′ covering T . Update M ←M ∪M ′ and add W toW .\nIf Grow occurs, resume the step 2. Otherwise, go to the step 1.\nNote that the auxiliary algorithm updates parameters in such a way that the number of vertices in every claw in the cycle-claw-matching decomposition is 3 since every − vertex has degree 2. Hence, there exists a unique matchingM ′ in the expansion step. Furthermore, the existence of a cycle-claw-matching decomposition at the initialization can be guaranteed using the complementary slackness condition and the half-integrality of LP (8). We establish the following lemma for the running time of the auxiliary algorithm.\nLemma 7 The auxiliary algorithm terminates in O(|V |2) iterations.\nProof. To this end, let (O,W,M) be the cycle-claw-matching decomposition ofG† andN = |O|+ |W| at some iteration of the algorithm. We first prove that |O|+ |W| does not increase at every iteration. At Step 1, the algorithm deletes an element in either O or W and hence, |O|+ |W| = N − 1. On the other hand, at Step 2, one can observe that the algorithm run into one of the following scenarios with respect to |O|+ |W|:\nGrow. |O|+ |W| = N − 1\nMatching. |O|+ |W| = N − 2\nCycle. |O|+ |W| = N\nClaw. |O|+ |W| = N\nTherefore, the total number of odd cycles and claws at Step 2 does not increase as well. From now on, we define {t1, t2, · · · : ti ∈ Z} to be indexes of iterations when Matching occurs at Step 2, and we call the set of iterations {t : ti ≤ t < ti+1} as the i-th stage. We will show that the length of each stage is O(|V |), i.e., for all i,\n|ti − ti+1| = O(|V |). (13)\nThis implies that the auxiliary algorithm terminates in O(|V |2) iterations since the total number of odd cycles and claws at the initialization is O(|V |) and it decrease by two if Matching occurs. To this end, we prove the following key lemmas, which are proven in the appendix.\nClaim 8 At every iteration of the auxiliary algorithm, there exist no path consisting of tight edges between two vertices v1, v2 ∈ V † where each vi is either a blossom vertex v(S) with yS = 0 or a (blossom or non-blossom) vertex in an odd cycle consisted of tight edges.\nClaim 9 Consider a + vertex v ∈ V † at some iteration of the auxiliary algorithm. Then, at the first iteration afterward where v becomes a − vertex or is removed from V † (i.e., due to the contraction of a blossom), it is connected to an odd cycle C ∈ O via an even-sized alternating path consisting of tight edges with respect to matching M whenever each iteration starts during the same stage. Here, O and M are from the cycle-claw-decomposition.\nNow we aim for proving (13). To this end, we claim the following.\n♠ A + vertex of V † at some iteration cannot be a − one (whenever it appears in V †) afterward in the same stage.\nFor proving ♠, we assume that a + vertex v ∈ V † at the t-th iteration violates ♠ to derive a contradiction, i.e., it becomes a − one in some tree T during t′-th iteration in the same stage. Without loss of generality, one can assume that the vertex v has the minimum value of t′ − t among such vertices violating ♠. We consider two cases: (a) v is always contained in V † afterward in the same stage, and (b) v is removed from V † (at least once, due to the contraction of a blossom containing v) afterward in the same stage. First consider the case (a). Then, due to the assumption of the case (a) and Claim 9, there exist a path P from v to a cycle C ∈ O when the t′-th iteration starts. Then, one can observe that in order to add v to tree T as a − vertex, it must be the first vertex in path P added to T by Grow during the t-iteration. Furthermore, tree T keeps continuing to perform Grow afterward using tight edges of path P without modifying parameter y until Matching occurs, i.e., the new stage\nstarts. This is because Claw and Cycle are impossible to occur before Matching due to Claim 8. Hence, it contradicts to the assumption that t and t′ are in the same stage, and completes the proof of ♠ for the case (a). Now we consider the case (b), i.e., v is removed from V † due to the contraction of a blossom S ∈ L. In this case, the blossom vertex v(S) ∈ V † must be expanded before v becomes a − vertex. However, v(S) becomes a + vertex after contracting S and a − vertex before expanding v(S), i.e., v(S) also violates ♠. This contradicts to the assumption that the vertex v has the minimum value of t′ − t among vertices violating ♠, and completes the proof of ♠. Due to ♠, a blossom cannot expand after contraction in the same stage, where we remind that a blossom vertex becomes a + one after contraction and a − one before expansion. This implies that the number contractions and expansions in the same stage is O(|V |), which leads to (13) and completes the proof of Lemma 7.\nNow we are ready to prove the equivalence between the auxiliary algorithm and the BlossomLP, i.e., prove that the numbers of iterations of Blossom-LP and the auxiliary algorithm are equal. To this end, given a cycle-claw-matching decomposition (O,W,M), observe that one can choose the corresponding x = [xe] ∈ {0, 1/2, 1}|E †| that satisfies constraints of LP (8):\nxe =  1 if e is an edge inW or M 1 2 if e is an edge in O 0 otherwise .\nSimilarly, given a half-integral x = [xe] ∈ {0, 1/2, 1}|E †| that satisfies constraints of LP (8), one can find the corresponding cycle-claw-matching decomposition. Furthermore, one can also define weight w† in G† for the auxiliary algorithm as Blossom-LP does:\nw†e = we − ∑\nv∈V :v 6∈V †,e∈δ(v)\nyv − ∑\nS∈L:v(S)6∈V †,e∈δ(S)\nyS , ∀ e ∈ E†. (14)\nIn the auxiliary algorithm, e = (u, v) ∈ E† is tight if and only if\nw†e − y†u − y†v = 0.\nUnder these equivalences in parameters between Blossom-LP and the auxiliary algorithm, we will use the induction to show that cycle-claw-matching decompositions maintained by both algorithms are equal at every iteration, as stated in the following lemma.\nLemma 10 Define the following notation:\ny† = [yv : v ∈ V †] and y‡ = [yv, yS : v ∈ V, v 6∈ V †, S ∈ L, v(S) /∈ V †],\ni.e., y† and y‡ are parts of y which involves and does not involve in V †, respectively. Then, the Blossom-LP and the auxiliary algorithm update parameters L, y‡ equivalently and output the same cycle-claw-decomposition of G† at each iteration.\nProof. Initially, it is trivial. Now we assume the induction hypothesis that L, y‡ and the cycleclaw-decomposition are equivalent between both algorithms at the previous iteration. First, it is easy to observe that L is updated equivalently since it is only decided by the cycle-clawdecomposition at the previous iteration in both algorithms. Next, it is also easy to check that y‡ is updated equivalently since (a) if we remove a blossom S from L, it is trivial and (b) if\nwe add a blossom S = V (C) for some cycle C to L, y‡ is uniquely decided by C and w† in both algorithms.\nIn the remaining of this section, we will show that once L, y‡ are updated equivalently, the cycle-claw-decomposition also changes equivalently in both algorithms. Observe that G†, w† only depends on L, y‡. In addition, y† maintained by the auxiliary algorithm also satisfies constraints of LP (12). Consider the cycle-claw-matching decomposition (O,W,M) of the auxiliary algorithm, and the corresponding x = [xe] ∈ {0, 1/2, 1}|E\n†| that satisfies constraints of LP (8). Then, x and y† satisfy the complementary slackness condition:\nxe(w † e − y†u − y†v) = 0, ∀e = (u, v) ∈ E†\ny†v(S)  ∑ e∈δ(v(S)) xe − 1  = 0, ∀S ∈ L, where the first equality is because the cycle-claw-matching decomposition consists of tight edges and the second equality is because every claw maintained by the auxiliary algorithm has its center vertex v(S) with yv(S) = 0 for some S ∈ L. Therefore, x is an optimal solution of LP (8), i.e., the cycle-claw-decomposition is updated equivalently in both algorithms. This completes the proof of Lemma 10.\nThe above lemma implies that Blossom-LP also terminates inO(|V |2) iterations due to Lemma 7. This completes the proof of Theorem 2. The equivalence between the half-integral solution of LP (8) in Blossom-LP and the cycle-claw-matching decomposition in the auxiliary algorithm implies that LP (8) is always has a half-integral solution, and hence, one of Steps B.(a), B.(b) or B.(c) always occurs."
    }, {
      "heading" : "5 Conclusion",
      "text" : "The BP algorithm has been popular for approximating inference solutions arising in graphical models, where its distributed implementation, associated ease of programming and strong parallelization potential are the main reasons for its growing popularity. This paper aims for designing a polynomial-time BP-based scheme solving the minimum weigh perfect matching problem. We believe that our approach is of a broader interest to advance the challenge of designing BP-based MAP solvers in more general GMs as well as distributed (and parallel) solvers for large-scale IPs."
    }, {
      "heading" : "A Proof of Lemma 4",
      "text" : "For the proof of Lemma 4, suppose there exists a row in A with one non-zero entry. Then, one can assume that it is the first row of A and A11 = 1 without loss of generality. Hence, A−111 = 1, A −1 1i = 0 for i 6= 1 and the first column of A−1 has only 0 and ±1 entries since each row of A has at most two non-zero entries. This means that one can proceed the proof of Lemma 4 for the submatrix of A deleting the first row and column. Therefore, one can assume that each row of A contains exactly two non-zero entries.\nWe construct a graph G = (V,E) such that\nV = [m] := {1, 2, . . . ,m} and E = {(j, k) : aij = aik = 1 for some i ∈ V },\ni.e., each row Ai[m] = (Ai1, . . . , Aim) and each column A[m]i = (A1i, . . . , Ami)T correspond to an edge and a vertex of G, respectively. Since A is invertible, one can notice that G does not contain an even cycle as well as a path between two distinct odd cycles (including two odd cycles share a vertex). Therefore, each connected component of G has at most one odd cycle. Consider the i-th column A−1[m]i = (A −1 1i , . . . , A −1 mi) T of A−1 and we have\nAi[m]A −1 [m]i = 1 and Aj[m]A −1 [m]i = 0 for j 6= i, (15)\ni.e., A−1[m]i assigns some values on V such that the sum of values on two end-vertices of the edge corresponding to the k-th row of A is 1 and 0 if k = i and k 6= i, respectively.\nLet e = (u, v) ∈ E be the edge corresponding to the i-th row of A.\n• First, consider the case when e is not in an odd cycle of G. Since each component of G contains at most one odd cycle, one can assume that the component of u is a tree in the graph G \\ e. We will find the entries of A−1 satisfying (15). Choose A−1wi = 0 for all vertex w not in the component. and A−1ui = 1. Since the component forms a tree, one can set A−1wi = 1 or − 1 for every vertex w 6= u in the component to satisfy (15). This implies that A−1[m]i consists of 0 and ±1.\n• Second, consider the case when e is in an odd cycle of G. We will again find the entries of A−1 satisfying (15). Choose A−1ui = A −1 vi = 1 2 and A −1 wi = 0 for every vertex w not\nin the component containing e. Then, one can choose A−1[m]i satisfying (15) by assigning A−1wi = 1 2 or − 1 2 for vertex w 6= u, v in the component containing e. Therefore, A −1 [m]i consists of 0 and ±12 .\nThis completes the proof of Lemma 4."
    }, {
      "heading" : "B Proof of Corollary 5",
      "text" : "The proof of Corollary 5 will be completed using Theorem 1. If LP (9) has a unique solution, LP (9) has a unique and integral solution by Theorem 3, i.e., Condition C1 of Theorem 1. LP (9) satisfies Condition C2 as each edge is incident with two vertices. Now, we need to prove that LP (9) satisfies Condition C3 of Theorem 1. Let x∗ be a unique optimal solution of LP (9). Suppose v is a non-blossom vertex and ψv(xδ(v)) = 1 for some xδ(v) 6= x∗δ(v). If xe 6= x ∗ e = 1 for e ∈ δ(v), there exist f ∈ δ(v) such that xf 6= x∗f = 0. Similarly, If xe 6= x∗e = 0 for e ∈ δ(v), there exists f ∈ δ(v) such that xf 6= x∗f = 1. Then, it follows that\nψv(x ′ δ(v)) = 1, where x ′ e′ = { xe′ if e′ /∈ {e, f} x∗e′ otherwise .\nψv(x ′ δ(v)) = 1, where x ′ e′ = { xe′ if e′ ∈ {e, f} x∗e′ otherwise .\nSuppose v is a blossom vertex and ψv(xδ(v)) = 1 for some xδ(v) 6= x∗δ(v). If xe 6= x ∗ e = 1 for e ∈ δ(v), choose f ∈ δ(v) such that xf 6= x∗f = 0 if it exists. Otherwise, choose f = e. Similarly, If xe 6= x∗e = 0 for e ∈ δ(v), choose f ∈ δ(v) such that xf 6= x∗f = 1 if it exists. Otherwise, choose f = e. Then, it follows that\nψv(x ′ δ(v)) = 1, where x ′ e′ = { xe′ if e′ /∈ {e, f} x∗e′ otherwise .\nψv(x ′ δ(v)) = 1, where x ′ e′ = { xe′ if e′ ∈ {e, f} x∗e′ otherwise ."
    }, {
      "heading" : "C Proof of Claim 8",
      "text" : "First observe that w† (see (14) for its definition) is updated only at Contraction and Expansion of Step 1. If Contraction occurs, there exist a cycle C to be contracted before Step 1. Then one can observe that before the contraction, for every vertex v in C, yv is expressed as a linear combination of w†:\nyv = 1\n2 ∑ e∈E(C) (−1)dC(e,v)w†e, (16)\nwhere dC(v, e) is the graph distance from vertex v to edge e in the odd cycle C. Moreover w† is updated after the contraction as{ w†e ← w†e − yv if v is in the cycle C and e ∈ δ(v) w†e ← w†e otherwise . Thus the updated valuew†e can be expressed as a linear combination of the old valuesw† where each coefficient is uniquely determined by G†. One can show the same conclusion similarly when Expansion occurs. Therefore one conclude the following.\n♣ Each value w†e at any iteration can be expressed as a linear combination of the original weight values w where each coefficient is uniquely determined by the prior history in G†.\nTo derive a contradiction, we assume there exist a path P consisting of tight edges between two vertices v1 and v2 where each vi is either a blossom vertex v(S) with yS = 0 or a vertex in an odd cycle consisting of tight edges. Consider the case where v1 and v2 are in cycle C1 and C2 consisting of tight edges, where other cases can be argued similarly. Then one can observe that there exists a linear relationship between yv and yu and w†:\nyv1 + (−1)dP (v2,v1)yv2 = ∑ e∈P (−1)dP (e,v1)w†e (17)\nwhere dP (v2, v1) and dP (e, v1) is the graph distance from v1 to v2 and e, respectively, in the path P . Since v1, v2 are in cycles C1, C2, respectively, we can apply (16). From this observation, (17) and ♣, there exists a linear relationship among the original weight values w, where each coefficient is uniquely determined by the prior history in G†. This is impossible since the number of possible scenarios in the history ofG† is finite, whereas we add continuous random noises to w. This completes the proof of Claim 8."
    }, {
      "heading" : "D Proof of Claim 9",
      "text" : "To this end, suppose that a + vertex v at the t†-th iteration first becomes a − vertex or is removed from V † at the t‡-th iteration where t†, t‡-th iterations are in the same stage. First observe that if v is removed fromG† at the t‡-th iteration, there exist a cycle inO that includes it at the start of the t‡-th iteration, resulting a zero-sized alternating path between such vertex and cycle, i.e., the conclusion of Lemma 9 holds. Now, for the other case, i.e., v becomes a − vertex at the t‡-th iteration, we will prove the following.\nF For any t-th iteration with t† ≤ t < t‡, one of the followings holds:\n1. The vertex v becomes a + vertex during the t-th iteration. Moreover, v either becomes a + vertex during the (t + 1)-th iteration or v becomes connected to some cycle C in O via an even-sized alternating path P consisting of tight edges at the start of (t+ 1)-th iteration.\n2. The vertex v is not in the tree T during the t-th iteration. Moreover, if v is connected to some cycle C in O via an even-sized alternating path P consisting of tight edges at the start of t-th iteration, v remains connected to cycle C in O via an even-sized alternating path P consisted of tight edges at the start of (t + 1)-th iteration, i.e. the algorithm parameters associated with P and C are not updated during the t-th iteration.\nForF − 1, observe that if v becomes a + vertex during the t-th iteration, the iteration terminates with one of the following scenarios:\nI. The iteration terminates with Matching. This contradicts to the assumption that t†, t‡-th iterations are in the same stage, i.e., no Matching occurs during the t-th iteration.\nII. The iteration terminates with Cycle. The vertex v is connected to the cycle newly added to O via an even-sized alternating path consisting of tight edges in tree T at the start of the next (i.e., (t+ 1)-th) iteration.\nIII. The iteration terminates with Claw. The vertex v becomes a + vertex of tree T of the next (i.e., (t + 1)-th) iteration. This is due to the following reasons. After Claw, the algorithm expands the center vertex of newly made claw W by Expansion in the next iteration. Then, there exists an even-sized alternating path PW from r to v consisted of tight edges in the newly constructed tree T . Furthermore, edges in PW are continuously added to T by Grow without modifying parameter y in Step 2 until v becomes a + vertex in T . This is because Claw and Cycle are impossible to occur due to Claim 8.\nForF − 2, in order to derive a contradiction, assume that a vertex v violatesF − 2 at some iteration, i.e. the algorithm parameters associated to the even-sized alternating path P and the cycle C in the statement ofF− 2 are updated during the iteration. Observe that the algorithm parameters are updated due to one of the following scenarios:\nI. The cycle C is contracted. If v is in C, v no longer remains in V † and contradicts to the assumption that v remains in V †. If v is not in C, v becomes a + vertex in tree T after continuously adding edges of P by Grow without modifying parameter y due to Claim 8. This contradicts to the assumption of F − 2 that v is not in tree T during the t-th iteration.\nII. A vertex in C is added to tree T . Then, Matching occurs, i.e. the new stage starts. This contradicts to the assumption that t†, t‡-th iterations are in the same stage.\nIII. An edge in P is added to tree T . Then, there exists a vertex u in P that first became a − vertex among vertices in P , and it either (a) has an even-sized alternating path P ′ to C consisting of tight edges or (b) has an odd-sized alternating path P ′ to v consisting of tight edges. For (a), the edges in P ′ are continuously added to T without modifying parameter y by Claim 8 and Matching occurs. This contradicts to the assumption again. For (b), P ′ are added to T without modifying parameter y due to Claim 8, and v is added to tree T as a + vertex. This contradicts to the assumption ofF− 2 that v is not in tree T during the t-th iteration.\nTherefore, F holds. One can observe that there exists t∗ ∈ (t†, t‡) such that at the t∗-th iteration, v last becomes a + vertex before the t‡-th iteration, i.e. v is not in tree T during t-th iteration for t∗ < t < t‡. Then v is connected to some cycle C in O via an even length alternating path P at (t∗ + 1)-th iteration and such path and cycle remains unchanged during t-th iteration for t∗ < t ≤ t‡ due toF. This completes the proof of Claim 9."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2015,
    "abstractText" : "<lb>Max-product Belief Propagation (BP) is a popular message-passing algorithm for<lb>computing a Maximum-A-Posteriori (MAP) assignment over a distribution represented<lb>by a Graphical Model (GM). It has been shown that BP can solve a number of combinato-<lb>rial optimization problems including minimum weight matching, shortest path, network<lb>flow and vertex cover under the following common assumption: the respective Linear<lb>Programming (LP) relaxation is tight, i.e., no integrality gap is present. However, when<lb>LP shows an integrality gap, no model has been known which can be solved systemati-<lb>cally via sequential applications of BP. In this paper, we develop the first such algorithm,<lb>coined Blossom-BP, for solving the minimum weight matching problem over arbitrary<lb>graphs. Each step of the sequential algorithm requires applying BP over a modified graph<lb>constructed by contractions and expansions of blossoms, i.e., odd sets of vertices. Our<lb>scheme guarantees termination in O(n) of BP runs, where n is the number of vertices<lb>in the original graph. In essence, the Blossom-BP offers a distributed version of the cel-<lb>ebrated Edmonds’ Blossom algorithm by jumping at once over many sub-steps with a<lb>single BP. Moreover, our result provides an interpretation of the Edmonds’ algorithm as<lb>a sequence of LPs.",
    "creator" : "LaTeX with hyperref package"
  }
}