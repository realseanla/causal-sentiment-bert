{
  "name" : "1412.4485.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Query Answering for Greedy Sets of Existential Rules Worst-case Optimal Query Answering for Greedy Sets of Existential Rules and Their Subclasses",
    "authors" : [ "Sebastian Rudolph", "Michaël Thomazo", "Jean-François Baget" ],
    "emails" : [ "sebastian.rudolph@tu-dresden.de", "michael.thomazo@tu-dresden.de", "baget@lirmm.fr", "mugnier@lirmm.fr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "∗. This work has been partially realized while S. Rudolph was working at AIFB, KIT, Germany and M. Thomazo was a Ph.D. student at University Montpellier 2\nar X\niv :1\n41 2.\n44 85\nv1 [\ncs .A\nI] 1\n5 D"
    }, {
      "heading" : "1. Introduction",
      "text" : "Intelligent methods for searching and managing large amounts of data require rich and elaborate schematic “ontological” knowledge. The need for an ontological layer on top of that data, associated with advanced querying mechanisms able to exploit the semantics encoded in ontologies1, has been widely acknowledged both in the knowledge representation (KR) and database communities.\nDeductive databases and KR typically adopt two different perspectives on how to add this ontological layer to the picture of plain query answering (cf. Rudolph, 2014). In deductive databases, this knowledge is considered part of the query, forming a so-called ontologymediated query to be executed on the database. According to the KR perspective, knowledge is encoded in an ontology, and queries are asked to a knowledge base composed of the data and the ontology. In this paper, we will focus on the KR perspective.\nIndeed, ontologies, which typically encode general knowledge about the domain of interest, can be used to infer data that are not explicitely stored, hence palliating incompleteness in databases (Cal̀ı, Lembo, & Rosati, 2003). They can also be used to enrich the vocabulary of data sources, which allows a user to abstract from the specific way data are stored. Finally, when several data sources use different vocabularies, ontologies can be used to align these vocabularies.\nGiven a knowledge base (KB) composed of an ontology and of factual knowledge, and a query, the ontology-based query answering problem consists in computing the set of answers to the query on the KB, while taking implicit knowledge represented in the ontology into account. We make here the simplifying assumption that the ontology and the database use the same vocabulary. Otherwise, mappings have to be defined between both vocabularies, as in the ontology-based data access framework (Poggi, Lembo, Calvanese, De Giacomo, Lenzerini, & Rosati, 2008). As most work in this area, we focus on conjunctive queries (CQs), the basic and most frequent querying formalism in databases.\nIn the Semantic Web area, one of the most prominent fields where KR technology is practically applied, ontological knowledge is often represented by means of formalisms based on description logics (DLs, (Baader, Calvanese, McGuinness, Nardi, & Patel-Schneider, 2007; Rudolph, 2011)). However, DLs are restricted in terms of expressivity in that they usually support only unary and binary predicates and that terminological expressiveness is essentially restricted to tree-like dependencies between the atoms of a formula. Moreover, DL research has traditionally been focusing on so-called standard reasoning tasks about the knowledge base, which are reducible to knowledge base satisfiability, for instance classifying concepts; querying tasks were essentially restricted to ground atom entailment. Answering full conjunctive queries (CQs) over DL knowledge bases has become a subject of research only recently2, turning out to be extremely complex (e.g., for the classical DL ALCI, it is already 2ExpTime-complete, and still NP-complete in the size of the data). Consequently, conjunctive query answering has been particularly studied on less expressive DLs, such as DL-Lite (Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2007) and EL (Baader, 2003; Lutz, Toman, & Wolter, 2009). These DLs are the basis of so-called tractable profiles\n1. In this paper, we reserve the term ontology to general domain knowledge–sometimes also called terminological knowledge–in order to clearly distinguish it from the factual data–or assertional knowledge. 2. CQ answering in the context of DLs was first mentioned by Levy and Rousset (1996), with the first publication focusing on that subject by Calvanese, De Giacomo, and Lenzerini (1998).\nOWL 2 QL and OWL 2 EL of the Semantic Web language OWL 2 (W3C OWL Working Group, 2009; Motik, Cuenca Grau, Horrocks, Wu, Fokoue, & Lutz, 2009a).3\nOn the other hand, querying large amounts of data is the fundamental task in databases. Therefore, the challenge in this domain is now to access data while taking ontological knowledge into account. The deductive database language Datalog allows to express some ontological knowledge. However, in Datalog rules, variables are range-restricted, i.e., all variables in the rule are universally quantified, which does not allow to infer the existence of initially unknown domain individuals (a capability called value invention in databases (Abiteboul, Hull, & Vianu, 1994)). Yet, this feature has been recognized as crucial in an open-world perspective, where it cannot be assumed that all individuals are known in advance.\nTo accommodate the requirements sketched above – value invention and complex relationships – we consider here an extension of first-order function-free Horn rules that allows for existentially quantified variables in the rule heads and thus features value invention. More precisely, these extended rules are of the form Body → Head , where Body and Head are conjunctions of atoms, and variables occurring only in the Head are existentially quantified, hence their name “existential rules” in (Baget, Mugnier, Rudolph, & Thomazo, 2011; Krötzsch & Rudolph, 2011).\nExample 1. Consider the existential rule R = ∀x ( human(x)→ ∃y ( hasParent(x, y) ∧ human(y) )) and a fact F = human(a), where a is a constant. The application of R to F produces new factual knowledge, namely\n∃y0 ( hasParent(a, y0) ∧ human(y0) ) ,\nwhere y0 is a variable denoting an unknown individual. Note that R could be applied again to human(y0), which would lead to create another existentially quantified variable, and so on.\nSuch rules are well-known in databases as Tuple-Generating Dependencies (TGDs) (Beeri & Vardi, 1984) and have been extensively used, e.g., for data exchange (Fagin, Kolaitis, Miller, & Popa, 2005). Recently, the corresponding logical fragment has gained new interest in the context of ontology-based query answering. It has been introduced as the Datalog± framework in (Cal̀ı, Gottlob, & Kifer, 2008; Cal̀ı, Gottlob, & Lukasiewicz, 2009; Cal̀ı, Gottlob, Lukasiewicz, Marnette, & Pieris, 2010), and independently, stemming from graph-based knowledge representation formalisms (Chein & Mugnier, 2009), as ∀∃ rules (Baget, Leclère, Mugnier, & Salvat, 2009; Baget, Leclère, & Mugnier, 2010).\nThis rule-based framework generalizes the core of the lightweight description logics mentioned above, namely DL-Lite and EL.4 Moreover, in the case of the DL-Lite family (Cal-\n3. Beside the profiles based on DL-Lite and EL, there is a third OWL 2 tractable profile, OWL 2 RL, which can be seen as a restriction of Datalog. 4. The DL constructor called existential restriction (∃R.C) is fundamental in these DLs. The logical encoding of an axiom that contains ∃R.C in its right-hand side requires an existentially quantified variable in the corresponding rule head. For instance, the rule from Example 1 can be seen as the logical translation of the DL axiom Human v ∃hasParent.Human.\nvanese et al., 2007), it has been shown that this covering by a Datalog± fragment is done without increasing complexity (Cal̀ı et al., 2009).\nSeveral fundamental decision problems can be associated with conjunctive query answering under existential rules. In this paper, we consider the entailment problem of a Boolean conjunctive query under existential rules, which we are now able to define formally. A Boolean conjunctive query is an existentially closed conjunction of (function-free) atoms. A set of facts has the same form. A knowledge base is composed of a set of facts and a set of existential rules. The entailment problem takes as input a knowledge base and a Boolean conjunctive query and asks if this query is entailed by the knowledge base.\nThe presence of existentially quantified variables in rule heads, associated with arbitrarily complex conjunctions of atoms, makes the entailment problem undecidable (Beeri & Vardi, 1981; Chandra, Lewis, & Makowsky, 1981a). Since the birth of TGDs, and recently within the Datalog± and ∀∃ rule frameworks, various conditions of decidability have been exhibited. Three “abstract” classes have been introduced in (Baget et al., 2010) to describe known decidable behaviors: an obvious condition of decidability is the finiteness of the forward chaining (known as the chase in the TGD framework (Maier, Mendelzon, & Sagiv, 1979; Johnson & Klug, 1984; Beeri & Vardi, 1984)); sets of rules ensuring this condition are called finite expansion sets (fes); a more general condition introduced in (Cal̀ı et al., 2008) accepts infinite forward chaining provided that the facts generated have a bounded treewidth (when seen as graphs); such sets of rules are called bounded-treewidth sets (bts); then decidability follows from the decidability of first-order logic (FOL) classes with the bounded-treewidth model property (Courcelle, 1990). The third condition, giving rise to finite unification sets (fus), relies on the finiteness of (a kind of) backward chaining mechanism, this condition is also known as first-order rewritability. None of these three abstract classes is recognizable, i.e., the problem of deciding whether a given set of rules is fes , bts , or fus is undecidable (Baget et al., 2010).\nIn this paper, we focus on the bts paradigm and its main “concrete” classes. (Pure) Datalog rules (i.e., without existential variables) are fes (thus bts). Guarded (g) rules (Cal̀ı et al., 2008) are inspired by the guarded fragment of FOL (Andréka, van Benthem, & Németi, 1996; Andréka, Németi, & van Benthem, 1998). Their body has an atom, called a guard, that contains all variables from the body. Guarded rules are bts (and not fes). They are generalized by weakly guarded rules (wg), in which the guarding condition is relaxed: only so-called “affected” variables need to be guarded; intuitively, affected variables are variables that are possibly mapped, during the forward chaining process, to newly created variables (Cal̀ı et al., 2008). wg rules include Datalog rules (in which there are no affected variables). Other decidable classes rely on the notion of the frontier of a rule (the set of variables shared between the body and the head of a rule). In a frontier-one rule (fr1), the frontier is restricted to a single variable (Baget et al., 2009). In a frontier-guarded rule (fg), an atom in the body guards the frontier (Baget et al., 2010). Hence, fg rules generalize both guarded rules and fr1 rules. When requiring only affected variables from the frontier to be guarded, we obtain the still decidable class of weakly frontier-guarded rules (wfg), which generalizes both fg and wg classes (Baget et al., 2010). Not considered until now were rule sets obtained by straightforward combinations of the above properties: guarded frontier-one rules (gfr1) as well as weak frontier-one rules (wfr1) and weakly guarded frontier-one rules\n(wgfr1). Table 1 summarizes the considered existential rule fragments with respect to their constraints on frontier variables and guardedness.\nExample 2. We consider the following relations, where the subscripts indicate the arity of the relation: project/3, projectField/2, projectDpt/2, hasManager/2, memberOf/2, isSensitiveField/1 and isCriticalManager/1. Intuitively, project(x, d, z) means that x is a project in department d and is about field z; relations projectField and projectDpt are projections of the project relation; hasManager(x, y) and member(y, d) respectively mean that x is managed by y and y is member of d; relations isSensitiveField and isCriticalManager respectively apply to fields and managers. Let R be the following set of existential rules built on this vocabulary:\n• Decomposition of the relation project into two binary relations R0 = ∀x∀d∀z(project(x, d, z)→ projectDpt(x, d) ∧ projectF ield(x, z)\n• “Every project has a manager” R1 = ∀x∀z(projectF ield(x, z)→ ∃y hasManager(x, y))\n• “Every managed project has some field” R2 = ∀x∀y(hasManager(x, y)→ ∃z projectF ield(x, z))\n• “The manager of a project is a member of the department that owns the project” R3 = ∀x∀y∀d(hasManager(x, y) ∧ projectDpt(x, d)→ memberOf(y, d))\n• “If a manager manages a project in a sensitive field, then (s)he is a critical manager” R4 = ∀x∀y∀z(hasManager(x, y) ∧ projectF ield(x, z) ∧ isSensitiveF ield(z) → isCriticalManager(y))\n• “Every critical manager manages a project in a sensible field” R5 = ∀y(isCriticalManager(y) → ∃x∃z(hasManager(x, y) ∧ projectF ield(x, z) ∧ isSensitiveF ield(z)))\nNote that rules R0, R3 and R4 do not introduce any existential variable. Rules R0, R1, R2 and R5 have an atomic body, hence they are trivially guarded. Rule R4 is not guarded, but it is frontier-one. Hence, if we exclude R3, all rules are frontier-guarded. R3 is not frontier-guarded, since no atom from the body contains both frontier variables y and d; however, we remark that variable d is not affected, i.e., it can never be mapped to a newly created variable (indeed, the only rule able to produce an atom with predicate projectDpt is R0; the variables in this atom come from the body atom with predicate project, which never appears in a rule head, hence can only be mapped to initially present data). Affected frontier-variables are guarded in all rules, hence R is weakly frontier-guarded. R is even weakly frontier-one, since for each rule the frontier contains at most one affected variable.\nContrarily to fes and fus , the definition of bts is not based on a constructive entailment procedure. The complexity of the subclasses g and wg is known and an algorithm for the corresponding entailment problem has been provided (Cal̀ı et al., 2008, 2009). However, this is not the case for the classes gfr1, fr1, fg , wgfr1, wfr1, wfg , and gbts . The aim of this paper is to solve these algorithmic and complexity issues.\nOur contribution is threefold. First, by imposing a restriction on the allowed forwardchaining derivation sequences, we define a subclass of bts , namely greedy bounded-treewidth sets of rules (gbts), which have the nice property of covering the wfg class. gbts are defined by a rather simple condition: when such a set is processed in forward chaining and a rule R is applied, all frontier variables of R which are not mapped to terms from the initial data set must be uniformly mapped to terms introduced by one single previous rule application. The fundamental property satisfied thanks to this condition is that any derivation can be naturally associated with a bounded-width tree decomposition of the derived facts, which can be built in a “greedy manner”, that is, on the fly during the forward chaining process. We also prove that wfg and gbts have essentially the same expressivity.\nSecondly, we provide a generic algorithm for the gbts class, which is worst-case optimal for data complexity, for combined complexity (with or without bound on the arity of involved predicates), and for query complexity. We furthermore show that this algorithm can be slightly adapted to be worse-case optimal for subclasses with smaller complexities.\nThirdly, we classify gfr1, fr1, fg , wgfr1, wfr1, wfg , and gbts with respect to both combined (with and without predicate arity bound) and data complexities. We also consider the case of rules with an acyclic (more precisely, hypergraph-acyclic) body and point out that bodyacyclic fg rules coincide with guarded rules from an expressivity and complexity perspective.\nFig. 1 shows the complexity lines for these classes of rules with three complexity measures, namely combined complexity without or with bound on the predicate arity, and data complexity. Notice in particular that the two direct extensions of guarded rules, i.e., weakly guarded and frontier-guarded rules, do not behave in the same way with respect to the different complexity measures: for data complexity, fg rules remain in PTime, while wg rules are in ExpTime; on the other hand, for bounded-arity combined complexity, fg rules are in 2ExpTime, while wg rules remain in ExpTime. Precise complexity results obtained are given in Tab. 1. All complexities are complete for their class. New results are indicated by a star.\nPaper Organization In Section 2, basic definitions and results about existential rules are recalled. Section 3 introduces the gbts class and specifies its relationships with the wfg\nclass. Section 4 is devoted to an algorithm for entailment with gbts and to the associated complexity results. The next sections consider increasingly simpler classes, namely fg and fr1 (Section 5) and body-acyclic fg/fr1 rules (Section 6); several reductions are provided,\nwhich provide tight lower bounds and allow to completely classify these classes for data and combined complexities. Related work is reviewed in Section 7.\nThis article is an extended version of two papers published at IJCAI 2011 (Baget et al., 2011) and KR 2012 (Thomazo, Baget, Mugnier, & Rudolph, 2012), respectively. It provides detailed proofs of the results presented in these conference papers and benefits from further clarifications concerning the gbts algorithm, stemming from Michaël Thomazo’s PhD thesis (Thomazo, 2013). Furthermore, it contains complexity results for new classes of rules which complement the picture, namely gfr1, wgfr1 and wfr1."
    }, {
      "heading" : "2. Preliminaries",
      "text" : "We assume the reader to be familiar with syntax and semantics of first-order logic. We do not consider functional symbols except constants, hence a term is simply a variable or a constant. An atom is thus of the form p(t1, . . . , tk) where p is a predicate with arity k, and the ti are terms. If not otherwise specified, a conjunction is a finite conjunction of atoms. We denote it by C[x], where x is the set of variables occurring in C.\nA fact is the existential closure of a conjunction.5 A Boolean conjunctive query (CQ) has the same form as a fact. We may also represent conjunctions of atoms, facts, and CQs as sets of atoms. Given an atom or a set of atoms A, we denote by vars(A) the set of variables, and by terms(A) the set of terms, occurring in A. Given conjunctions F and Q, a homomorphism π from Q to F is a substitution of vars(Q) by terms(F ) such that π(Q) ⊆ F (we say that Q maps to F by π). For convenience, we often assume the domain of π extended to terms(Q), by mapping constants to themselves. Given an atom a = p(t1, . . . , tn), we let π(a) = p(π(t1), . . . , π(tn)) and similarly for a set of atoms. First-order semantic entailment is denoted by |=. It is well-known that, given two facts or CQs F and Q, F |= Q iff there is a homomorphism from Q to F .\nDefinition 1 (Existential Rule). An existential rule (or simply rule when not ambiguous) is a first-order formula:\nR = ∀x∀y ( B[x,y]→ ∃zH[y, z] ) ,\nwhere B is a conjunction, called the body of R (also denoted by body(R)), and H is a conjunction called the head of R (denoted by head(R)). The frontier of R, denoted by fr(R), is the set of variables y = vars(B) ∩ vars(H) occurring both in the rule’s body and head.\nNote that an existential rule could be equivalently defined as the formula ∀y(∃xB[x,y]→ ∃zH[y, z]). In the following, we will omit quantifiers since there is no ambiguity.\nA knowledge base (KB) K = (F,R) is composed of a fact (in database terms: a database instance) F and a finite set of rules (in database terms: a TGD set) R. W.l.o.g. we assume that the rules have pairwise disjoint sets of variables. We denote by C the set of constants occurring in (F,R) and by T0 (called the set of “initial terms”) the set vars(F ) ∪ C, i.e.,\n5. Note that hereby we generalize the classical notion of a (ground) fact in order to take existential variables into account. This is in line with the notion of a database instance in database theory, where the existentially quantified variables are referred to as labeled nulls.\nT0 includes not only the terms from F but also the constants occurring in rules. Next, we formally define the problem considered by us.\nDefinition 2 (BCQ-Entailment). The decision problem of entailment of Boolean conjunctive queries under existential rules is defined as follows:\n• Name: BCQ-Entailment\n• Input: A knowledge base K = (F,R) and a Boolean conjunctive query Q.\n• Output: YES iff K |= Q, NO otherwise.\nDepending on which parts of the input are assumed to be fixed, we distinguish the following three complexity notions when investigating BCQ-Entailment:\n• When considering data complexity, we assume R and Q to be fixed, only F (the data) can vary.\n• When investigating query complexity, F and R are fixed and Q may vary.\n• In case of combined complexity, F , R and Q can all change arbitrarily.\nWe now define the fundamental notions of rule application and R-derivation, which we relate to the chase procedure in databases.\nDefinition 3 (Application of a Rule). A rule R is applicable to a fact F if there is a homomorphism π from body(R) to F ; the result of the application of R to F w.r.t. π is a fact α(F,R, π) = F ∪πsafe(head(R)) where πsafe is a substitution of head(R), which replaces each x ∈ fr(R) with π(x), and each other variable with a fresh variable. As α(F,R, π) does not depend on the whole π, but only on π|fr(R) (the restriction of π to fr(R)), we also write α(F,R, π|fr(R)).\nExample 3. Let F = {r(a, b), r(c, d), p(d)} and R = r(x, y) → r(y, z). There are two applications of R to F , respectively by π1 = {x 7→a, y 7→b)} and π2 = {x7→c, y 7→d}. We obtain F1 = α(F,R, π1) = F ∪ {r(b, z1)} and F2 = α(F,R, π2) = F ∪ {r(d, z2)}.\nDefinition 4 (R-Derivation). Let F be a fact and R be a set of rules. An R-derivation (from F to Fk) is a finite sequence (F0 = F ), (R0, π0, F1), . . . , (Rk−1, πk−1, Fk) such that for all 0 ≤ i < k, Ri ∈ R and πi is a homomorphism from body(Ri) to Fi such that Fi+1 = α(Fi, Ri, πi). When only the successive facts are needed, we note (F0 = F ), F1, . . . , Fk.\nThe following theorem essentially stems from earlier results on conceptual graph rules (Salvat & Mugnier, 1996).\nTheorem 1 (Soundness and Completeness of R-Derivations). Let K = (F,R) be a KB and Q be a CQ. Then F,R |= Q iff there exists an R-derivation from F to some Fk such that Fk |= Q.\nIt follows that a breadth-first forward chaining mechanism yields a positive answer in finite time when K |= Q. Let F0 = F be the initial fact. Each step is as follows: (1) check if Q maps by homomorphism to the current fact, say Fi−1 at step i (i > 0): if it is the case, Q has a positive answer; (2) otherwise, produce a fact Fi from Fi−1, by computing all new homomorphisms from each rule body to Fi−1, then performing all corresponding rule applications. A homomorphism to Fi−1 is said to be new if it has not been already computed at a previous step, i.e., it uses at least an atom added at step i− 1. The fact Fk obtained at the end of step k is called the k-saturation of F and is denoted by αk(F,R); we define the saturation of F by R as α∞(F,R) = ∪k≥0αk(F,R).\nPreceding notions are closely related to classical database notions. Forward chaining (with existential rules) is known as the chase (with TGDs) (Maier et al., 1979; Aho, Beeri, & Ullman, 1979). Hence, the notion of an R-derivation corresponds to a chase sequence. The chase is seen as a tool for computing the saturation of a database with respect to a set of TGDs. Several variants of the chase are known, which all produce a result homomorphically equivalent to α∞(F,R). The chase yields a canonical model of (F,R), which is isomorphic to the output of the chase, and has the property of being universal, which means that it maps by homomorphism to any model of (F,R). It follows that (F,R) |= Q if and only if Q maps by homomorphism to α∞(F,R) (Deutsch, Nash, & Remmel, 2008) (and (Baget, Leclère, Mugnier, & Salvat, 2011) in the setting of existential rules).\nWe now formally specify some other notions that we have already introduced informally. A fact can naturally be seen as a hypergraph whose nodes are the terms in the fact and whose hyperedges encode the atoms. The primal graph of this hypergraph has the same set of nodes and there is an edge between two nodes if they belong to the same hyperedge. The treewidth of a fact is defined as the treewidth of its associated primal graph. Given a fact Fi, a derivation S yielding Fi, or a tree decomposition T of Fi, we let atoms(S) = atoms(T) = Fi.\nDefinition 5 (Tree Decomposition and Treewidth of a Fact). Let F be a (possibly infinite) fact. A tree decomposition of F is a (possibly infinite) tree T, with set of nodes B = {B0, . . . , Bk, . . .}, and two functions terms : B → 2terms(F ) and atoms : B → 2F , where:\n1. ⋃ i terms(Bi) = terms(F );\n2. ⋃ i atoms(Bi) = F ;\n3. For each Bi ∈ B holds terms(atoms(Bi)) ⊆ terms(Bi);\n4. For each term e in F , the subgraph of T induced by the nodes Bi with e ∈ terms(Bi) is connected (“Running intersection property”).\nThe width of a tree decomposition T is the size of the largest node of T, minus 1. The treewidth of a fact F is the minimal width among all its possible tree decompositions.\nA set of rules R is called a bounded-treewidth set (bts) if for any fact F there exists an integer b such that the treewidth of any fact F ′ that can be R-derived from F is less or equal to b. The entailment problem is decidable when R is bts (Cal̀ı et al., 2008; Baget et al., 2011). The main argument of the proof, introduced by Cal̀ı et al., relies on the observation that K ∧ ¬Q enjoys the bounded-treewidth model property, i.e, has a model with bounded treewidth when it is satisfiable, i.e., when K 6|= Q. Decidability follows from the decidability\nof the satisfiability problem for classes of first-order formulas having the bounded-treewidth property, a result from Courcelle (Courcelle, 1990). However, the proof of this latter result does not lead (or at least not directly) to an algorithm for BCQ-Entailment under bts rules. We now focus on “concrete” subclasses of bts .\nA rule R is guarded (g) if there is an atom a ∈ body(R) with vars(body(R)) ⊆ vars(a). We call a a guard of the rule. R is weakly guarded (wg) if there is a ∈ body(R) (called a weak guard) that contains all affected variables from body(R). The notion of affected variable is relative to the rule set: a variable is affected if it occurs only in affected predicate positions, which are positions that may contain an existential variable generated by forward chaining (Fagin et al., 2005). More precisely, the set of affected positions w.r.t. R is the smallest set that satisfies the following conditions: (1) if there is a rule head containing an atom with predicate p and an existentially quantified variable in position i, then position (p, i) is affected; (2) if a rule body contains a variable x appearing in affected positions only and x appears in the head of this rule in position (q, j) then (q, j) is affected. The important point is that a rule application necessarily maps non-affected variables to terms from the initial fact (and more generally to T0 in the case where rules may add constants). The g and wg rule classes were described and their complexity was analyzed by Cal̀ı et al. (2008, 2013).\nR is frontier-one (fr1) if |fr(R)| = 1 and it is guarded frontier-one (gfr1) if it is both g and fr1. R is frontier-guarded (fg) if there is a ∈ body(R) with vars(fr(R)) ⊆ vars(a). The weak versions of these classes—weakly frontier-one (wfr1), weakly guarded frontier-one (wgfr1) and weakly frontier-guarded (wfg) rules—are obtained by relaxing the above criteria so that they only need to be satisfied by the affected variables. The syntactic inclusions holding between these bts subclasses are displayed in Fig. 1."
    }, {
      "heading" : "3. Greedy Bounded-Treewidth Sets of Rules",
      "text" : "This section introduces greedy bounded-treewidth sets of rules (gbts). It is pointed out that gbts strictly contains the wfg class. However, in some sense, gbts is not more expressive than wfg : indeed, we exhibit a polynomial translation τ from any KB K = (F,R) to another KB τ(K) = (τ(F ), τ(R)) with τ(R) being wfg , which satisfies the following property: if R is gbts , then K and τ(K) are equivalent. This translation can thus be seen as a polynomial reduction from BCQ-Entailment under gbts to BCQ-Entailment under wfg .\n3.1 Definition of the gbts Class\nIn a greedy derivation, every rule application maps the frontier of the rule in a special way: all the frontier variables that are mapped to terms introduced by rule applications are jointly mapped to variables added by one single previous rule application.\nDefinition 6 (Greedy Derivation). An R-derivation (F0 = F ), . . . , Fk is said to be greedy if, for all i with 0 < i < k, there is j < i such that πi(fr(Ri)) ⊆ vars(Aj) ∪ vars(F0) ∪ C, where Aj = π safe j (head(Rj)).\nNote that, in the above definition, any j < i can be chosen if fr(Ri) is mapped to vars(F0) ∪ C.\nExample 4 (Non-Greedy Derivation). Let R = {R0, R1} where:\nR0 = r1(x, y)→ r2(y, z) and R1 = r1(x, y) ∧ r2(x, z) ∧ r2(y, t)→ r2(z, t)\nLet F0 = {r1(a, b) ∧ r1(b, c)} and S = F0, . . . , F3 with:\nF1 = α(F0, R0, {(y 7→b)}) with A0 = {r2(b, x1)}, F2 = α(F1, R0, {(y 7→c)}) with A1 = {r2(c, x2)}, F3 = α(F2, R1, π2) with π2|fr(R1) = {z 7→x1, t7→x2}\nThen fr(R1) = {z, t} is mapped to newly introduced variables in F3, however, there is no Aj such that {π2(z), π2(t)} ⊆ vars(Aj). Thus S is not greedy.\nAny greedy derivation can be associated with a so-called derivation tree, formally defined below. Intuitively, the root of the tree corresponds to the initial fact F0, and each other node corresponds to a rule application of the derivation. Each node is labeled by a set of terms and a set of atoms. The set of terms assigned to the root is T0, i.e., it includes the constants that are mentioned in rule heads. Moreover, T0 is included in the set of terms of all nodes. This ensures that the derivation tree is a decomposition tree of the associated derived fact.\nDefinition 7 (Derivation Tree). Let S = (F0 = F ), . . . , Fk be a greedy derivation. The derivation tree assigned to S, denoted by DT (S), is a tree T with nodes B = {B0, . . . , Bk, . . .} and two functions terms : B → 2terms(Fk) and atoms : B → 2Fk , defined as follows:\n1. Let T0 = vars(F )∪C. The root of the tree is B0 with terms(B0) = T0 and atoms(B0) = atoms(F ).\n2. For 0 < i ≤ k, let Ri−1 be the rule applied according to homomorphism πi−1 to produce Fi; then terms(Bi) = vars(Ai−1)∪T0 and atoms(Bi) = atoms(Ai−1). The parent of Bi is the node Bj for which j is the smallest integer such that πi−1(fr(Ri−1)) ⊆ terms(Bj).\nThe nodes of DT (S) are also called bags.\nExample 5 (Example 3 contd.). We consider F = {r(a, b), r(c, d), p(d)} and R = r(x, y)→ r(y, z). We build DT (S) for S = (F0 = F ), (R, π1, F1), (R, π2, F2) as depicted in Figure 2. Let B0 be the root of DT (S). (R, π1) yields a bag B1 child of B0, with atoms(B1) = {r(b, z1)} and terms(B1) = {a, b, c, d, z1}. (R, π2) yields a bag B2 with atoms(B2) = {r(d, z2)} and terms(B2) = {a, b, c, d, z2}. fr(R0) = {y} and π2(y) = d, which is both in terms(B0) and terms(B1), B2 is thus added as a child of the highest bag, i.e., B0. R can be applied again, with homomorphisms π3 = {x 7→b, y 7→z1} and π4 = {x7→d, y 7→z2}, which leads to create two bags, B3 and B4, under B1 and B2 respectively. Clearly, applications of R can be repeated indefinitely.\nNote that, in the second point of the definition of a derivation tree, there is at least one j with πi−1(fr(Ri−1)) ⊆ terms(Bj) because S is greedy. The following property is easily checked, noticing that T0 occurs in each bag, which ensures that the running intersection property is satisfied.\nProperty 2. Let S = F0 . . . , Fk be a greedy derivation. Then DT (S) is a tree decomposition of Fk of width bounded by |vars(F )|+ |C|+ max(|vars(head(R))|R∈R).\nDefinition 8 (Greedy Bounded-Treewidth Set of Rules (gbts)). R is said to be a greedy bounded-treewidth set (gbts) if (for any fact F ) any R-derivation (of F ) is greedy.\nThe class gbts is a strict subclass of bts and does not contain fes (e.g., in Example 4: R is fes but not gbts). It is nevertheless an expressive subclass of bts since it contains wfg :\nProperty 3. Any set of wfg rules is gbts.\nProof. Let R be a wfg rule set. Given any R-derivation, consider the application of a rule Ri, with weak frontier-guard g. Let a = πi(g). Either a ∈ F or a ∈ Aj for some j ≤ i. In the first case, πi(fr(Ri)) ⊆ terms(F ) ⊆ vars(F0) ∪ C; in the second case, πi(fr(Ri)) ⊆ terms(Aj) ⊆ vars(Aj) ∪ C. We conclude that R is gbts .\nThe obtained inclusion is strict since there are gbts rule sets which are not wfg as shown in the following example.\nExample 6 (gbts but not wfg). Let R = r1(x, y) ∧ r2(y, z)→ r(x, x′) ∧ r(y, y′) ∧ r(z, z′) ∧ r1(x\n′, y′)∧r2(y′, z′). {R} is gbts, but not wfg (nor fes). First, let us notice that all positions of r1 and r2 are affected, and that x, y and z belong to the frontier of R. Thus, {R} is not wfg . Moreover, let us consider F = {r1(a, b), r1(b, c)}. R is applicable to F , which leads to create r(a, x1), r(b, y1), r(c, z1), r1(x1, y1), and r2(y1, z1), as shown in Fig. 3. R is thus newly applicable, mapping its frontier to x1, y1, and z1. This can be repeated infinitely often, therefore {R} is not fes. Last, the only way to map the body of R to terms that do not belong to an arbitrary initial fact is to map the frontier of R to terms that have been created in the same bag (for instance, to the atoms in A1 in Fig. 3), thus ensuring that {R} is gbts."
    }, {
      "heading" : "3.2 A Translation into Weakly Frontier-Guarded Rules",
      "text" : "Next we will present a translation applicable to any set of existential rules. This translation can be computed in polynomial time, its result is always wfg and it is guaranteed to preserve query answers if the input is gbts .\nThe translation introduces two new predicates: a unary predicate initial and a predicate samebag of higher arity. Intuitively, initial will mark terms from the initial fact F , as well as constants added by rule applications, and samebag will gather terms that are “in the same bag”.\nDefinition 9 (wfg Translation). Let K = (F,R) be a KB. The wfg translation of K is the KB τ(K) = (τ(F ), τ(R)) where τ(F ) = F ∪ {initial(t)|t ∈ terms(F )} and τ(R) = Rsame∪Rtrans, where Rsame and Rtrans are defined as follows (where initial is a fresh unary predicate and samebag is fresh predicate with arity q = max(|terms(head(R))|R∈R) + |T0|):\n• Rsame contains the following rules:\nRsame1 = initial(x)→ samebag(x, . . . , x), Rsame2 = samebag(x1, x2, . . . , xq) ∧ initial(x)→ samebag(x, x2 . . . , xq), one rule of the following type for each 1 ≤ i ≤ q: Rsame3i = samebag(x1, . . . , xi, . . . , xq)→ samebag(xi, . . . , x1, . . . xq), and Rsame4 = samebag(x1, . . . , xq−1, xq)→ samebag(x1, . . . , xq−1, x1).\n• Rtrans contains one translated rule τ(R) for every rule R from R: for some rule R = B[x,y] → H[y, z] with c1, . . . , ck being the constants occurring in H, we let τ(R) = B[x,y] ∧ samebag(y,v)→ H[y, z] ∧ samebag(y, z,w) ∧i:1,...,k initial(ci), where w ⊆ v and v is a set of fresh variables.\nIntuitively, Rules Rsame1 and R same 2 express that the initial terms (as well as constants added by rule applications) are in all bags; rules Rsame3i and rule R same 4 respectively allow any permutation and any duplication of arguments in an atom with predicate samebag. In the translation of the rules from R, the sets of variables v and w are used to fill the atoms with predicate samebag to obtain arity q.\nProperty 4. For any set R of existential rules, τ(R) is wfg .\nProof. Rsame \\ {Rsame2 } is guarded. Rsame2 is fg . No rule affects the position in the unary predicate initial , thus all affected variables in Rsame2 are guarded by the atom with predicate samebag, hence τ(R) is wfg .\nWe next establish that, assuming we do not consider consequences involving initial or samebag , τ(R) is sound with respect to R and it is even complete in case R is gbts .\nProperty 5. For any Boolean CQ Q over the initial vocabulary, if τ(K) |= Q then K |= Q. Moreover, if R is gbts, then the reciprocal holds, i.e., τ(K) and K are equivalent (w.r.t. the initial vocabulary).\nProof. ⇒: Any τ(R)-derivation S ′ from τ(F ) can be turned into an R-derivation S from F by simply ignoring the applications of rules from Rsame and replacing each application of a rule τ(Ri) by an application of the rule Ri with ignoring the atoms with predicate samebag. Moreover, the facts respectively obtained by both derivations are equal on the initial vocabulary (i.e., when considering only the atoms with predicate in the initial vocabulary, and up to a variable renaming).\n⇐: We assume that R is gbts . We show that any R-derivation S = (F0 = F ), F1, . . . , Fk can be turned into a τ(R)-derivation S ′ = (F ′0 = τ(F )), . . . , F ′1, . . . F ′k that satisfies: (a) for all i such that 0 ≤ i ≤ k, Fi and F ′i are equal on the initial vocabulary; and, (b) for all i such that 0 ≤ i < k, F ′i+1 is obtained by applying τ(Ri) with a homomorphism π′i that extends πi. The proof is by induction on the length ` of S. The property is true for ` = 0. Assume it is true for ` = n. Consider the application of Rn with homomorphism πn from body(Rn) to Fn. We note fr(Rn) = {y1 . . . yp} such that body(τ(Rn)) contains the atom samebag(y1, . . . , yp, . . .). Since R is gbts , there is an Aj such that some variables from fr(Rn), say yi1 . . . yim are mapped to vars(Aj), and the remaining variables from fr(Rn), say yim+1 . . . yip are mapped to T0 = vars(F ) ∪ C. The application of τ(Rj) in S ′ has produced a samebag atom s1 that contains πn(yi1) . . . πn(yim) (by induction hypothesis (b)). By applying Rules Rsame3i and Rule R same 4 , we permute, and duplicate if needed (i.e., if some yi1 . . . yim have the same image by π), the arguments in s1 to obtain the atom s2 = samebag(πn(yi1), . . . , πn(yim), . . .). Then, with Rule R same 2 , we add each πn(yij ) for m < j ≤ p (note that F ′n necessarily contains initial(πn(yij ))) and build the atom s3 = samebag(πn(yim+1), . . . , πn(yip), πn(yi1) . . . πn(yim), . . .). Finally, with Rules R same 3i , we permute the p first arguments in s3 to obtain s4 = samebag(πn(y1), . . . , πn(yp), . . .). Since Fn and F ′ n are equal on the initial vocabulary by induction hypothesis (a), the fact obtained from F ′n after application of the previous rules from Rtrans is still equal to Fn on the initial vocabulary. We build π′n by extending πn such that the atom with predicate samebag in body(τ(Rn)) is mapped to s4. Parts (a) and (b) of the induction property are thus satisfied for ` = n+ 1.\n4. An Algorithm for gbts : PatSat We give here an informal high-level description of the PatSat algorithm (for pattern saturation). Due to the existentially quantified variables in rule heads, a forward chaining mechanism does not halt in general. However, as we have seen in the preceding section, for gbts , each sequence of rule applications gives rise to a so-called derivation tree, which is a decomposition tree of the derived fact; moreover, this tree can be built in a greedy way: each rule application produces a new tree node B (called a bag), which contains the atoms created by the rule application, such that the derived fact is the union of all bag atoms from this tree. The derived fact is potentially infinite, but thanks to its tree-like structure, the forward chaining process can be stopped after a finite number of rule applications as some periodic behavior will eventually occur.\nThe PatSat algorithm proceeds in two steps: first, it computes a finite tree, called a (full) blocked tree, which finitely represents all possible derivation trees; second, it evaluates a query against this blocked tree. Building a blocked tree relies on the following notions:\n• bag patterns: Each bag B is associated with a pattern P , which stores all ways of mapping any (subset of any) rule body to the current fact (that is: the intermediate fact associated with the tree at the current stage of the construction process), while using some terms from terms(B). It follows that a rule is applicable to the current fact if and only if one of the bag patterns contains a mapping of its entire rule body. Then, the forward chaining can be performed “on the bag-level” by forgetting about the underlying facts and considering solely the derivation tree decorated with patterns.\nAt each step, patterns are maintained and kept up-to-date by a propagation procedure based on a join operation between the patterns of adjacent bags.\n• an equivalence relation on bags: Thanks to patterns, an equivalence relation can be defined on bags, so that two bags are equivalent if and only if the “same” derivation subtrees can be built under them. The algorithm develops (that is: adds children nodes to) only one node per equivalence class, while the other nodes of that class are blocked (note, however, that equivalence classes evolve during the computation, thus a blocked node can later become non-blocked, and vice-versa). This tree grows until no new rule application can be performed to non-blocked bags: the full blocked tree is then obtained.\n• creation and evolution rules: The equivalence relation that we propose is however not directly computable: the “natural” way to compute would require to have already computed the greedy tree decomposition of the canonical model. In order to compute a full blocked tree, we make use of creation rules and evolution rules. These rules are meant to describe the patterns that may appear in the tree decomposition of the canonical model, as well as the relationships between patterns. For instance, creation rules intuitively state that any bag of pattern P that appears in the tree decomposition of the canonical model has a child of pattern P ′. We propose such rules, and show how to infer new rules in order to get a complete – but finite – description of the tree decomposition of the canonical model.\nA first way to perform query answering is then to consider the query as a rule with a head reduced to a nullary prediate. In that case, it is enough to check if one pattern contains the entire body of this added rule. If one do not want to consider the query as a rule, one has to be more cautious. Indeed, the evaluation of a Boolean conjunctive query against a blocked tree cannot be performed by a simple homomorphism test. Instead, we define the notion of an APT-mapping, which can be seen as a homomorphism to an “unfolding” or “development” of this blocked tree. As the length of the developed paths that is relevant for query answering is bounded with an exponent that depends only on the rule set (more precisely, the exponent is the maximal number of variables shared by the body and the head of a rule), checking if there is an APT-mapping from a conjunctive query to a blocked tree is time polynomial in data complexity and nondeterministically time polynomial in query complexity.\nIn order to illustrate the numerous definitions of this section, we will employ a running example. This example has been designed with the following requirements in mind. First, it should be easy enough to understand. Second, it should illustrate every aspect of our approach, and explain why simpler approaches we could think of are not sufficient. Last, it should not be expressible by means of description logics.\nExample 7 (Running Example). Let us consider Rex = {Rex1 , . . . , Rex7 } defined as follows:\n• Rex1 = q1(x1, y1, z1)→ s(y1, t1) ∧ r(z1, t1) ∧ q2(t1, u1, v1);\n• Rex2 = q2(x2, y2, z2)→ s(y2, t2) ∧ r(z2, t2) ∧ q3(t2, u2, v2);\n• Rex3 = q3(t3, u3, v3)→ h(t3);\n• Rex4 = q2(x4, y4, z4) ∧ s(y4, t4) ∧ r(z4, t4) ∧ h(t4)→ h(x4) ∧ p1(y4) ∧ p2(z4);\n• Rex5 = q1(x5, y5, z5) ∧ s(y5, t5) ∧ r(z5, t5) ∧ h(t5)→ p1(y5) ∧ p2(z5);\n• Rex6 = p1(xp) ∧ i(xp)→ r(xp, yp) ∧ p2(yp) ∧ i(yp);\n• Rex7 = p2(xq) ∧ i(xq)→ s(xq, yq) ∧ p1(yq) ∧ i(yq).\nThe initial fact will be:\nF ex = q1(a, b, c) ∧ q1(d, c, e) ∧ q1(f, g, g) ∧ i(c) ∧ i(g).\nThe subset {Rex1 , Rex2 , Rex3 } is a finite expansion set6. Applying these rules will create some existentially quantified variables. A first interesting phenomenon is that these existential variables allow to infer some new information about the initial terms. Last, Rex4 and Rex5 will generate infinitely many fresh existential variables, which will allow us to illustrate both the blocking procedure and the querying operation. While it can be argued that these rules are slightly complicated, it will allow to illustrate why we cannot block nodes without being careful.\nLet us illustrate this rule set with an example of greedy derivation of F ex under Rex.\nExample 8. Let us consider the following sequence of rule applications:\n• Rex1 is applied to F ex by π1 = {x1 7→a, y1 7→b, z1 7→c}, creating {s(b, t11), r(c, t11), q2(t11, u11, v11)}.\n• Rex2 is applied to α(F ex, Rex1 , π1) by π2 = {x2 7→t11, y2 7→u11, z2 7→v11}, creating {s(u11, t12), r(v11, t 1 2), q3(t 1 2, u 1 2, v 1 2)}\n• Rex3 is applied on the resulting fact by π3 = {x3 7→t21, y3 7→u21, z3 7→v21}, creating a single new atom h(t12).\nThis derivation is greedy, and its derivation tree is represented in Figure 4.\nMore generally, let us take a look at k-saturations of F ex with respect to Rex. On F ex, only Rex1 is applicable by three homomorphisms, creating three sets of three new atoms: {s(b, t11), r(c, t11), q2(t11, u11, v11)}, {s(c, t21), r(e, t21), q2(t21, u21, v21)} and {s(g, t31), r(g, t31), q2(t31, u31, v31)}. α1(F ex,Rex) is equal to the union of F ex and these three sets of atoms. On α1(F\nex,Rex), three new rule applications are possible, each of them mapping the body of Rex2 to one of the atoms with predicate q2. Again, three new sets of atoms are introduced, which are {s(u11, t12), r(v11, t12), q3(t12, u12, v12)}, {s(u21, t22), r(v21, t22), q3(t22, u22, v22)} and {s(u31, t32), r(v31, t32), q3(t32, u32, v32)}. This yields α2(F ex,Rex). On this fact, three new rule applications of Rex3 are possible, which introduce h(t 1 2), h(t 2 2), h(t 3 2). The introduction of these atoms triggers new applications of Rex4 , creating h(t11), h(t 2 1), h(t 3 1), p1(u 1 1), p1(u 2 1), p1(u 3 1), p2(v 1 1), p2(v 2 1), p2(v 3 1). R ex 5 is now triggered, creating p1(b), p2(c), p1(c), p2(e), p1(f), p2(f). The union of all atoms considered so far is equal to α5(F\nex,Rex). Rex6 and Rex7 are now applicable, both mapping their frontier to c and g. They will create infinite branches.\n6. Because, for example, their graph of rule dependency is acyclic (Baget et al., 2009)"
    }, {
      "heading" : "4.1 Patterned Forward Chaining",
      "text" : "This section focuses on bag patterns. For all following considerations, we assume an arbitrary but fixed rule set R which is gbts . We first show that forward chaining can be performed by considering solely the derivation tree endowed with bag patterns. Then we define joins on patterns in order to update them incrementally after each rule application. We last explain why patterns are interesting: they allow to formally capture some notion of “regularity” in a derivation tree, which will be exploited in the next section to finitely represent potentially infinite derivation trees.\nDefinition 10 (Pattern, Patterned Derivation Tree). A pattern of a bag B is a set of pairs (G, π), where G is a conjunction of atoms and π is a partial mapping from terms(G) to terms(B). G and π are possibly empty.\nFor any R-derivation S with derivation tree DT (S), we obtain a patterned derivation tree, noted (DT (S), P ), where P is a function assigning a pattern P (B) to each bag B of DT (S).\nThe patterns that we consider are subsets of the rule bodies in R.\nDefinition 11 (Pattern Soundness and Completeness). Let Fk be a fact obtained via a derivation S and let B be a bag in (DT (S), P ). P (B) is said to be sound w.r.t. Fk if for all (G, π) ∈ P (B), π is extendable to a homomorphism from G to Fk. P (B) is said to be complete w.r.t. Fk (and R), if for any R ∈ R, any sbR ⊆ body(R) and any homomorphism π from sbR to Fk, P (B) contains (sbR, π\n′), where π′ is the restriction of π to the inverse image of the terms of B, i.e., π′ = π|π−1(terms(B)). Finally, (DT (S), P ) is said to be sound and complete w.r.t. Fk if for all its bags B, P (B) is sound and complete w.r.t. Fk.\nProvided that (DT (S), P ) is sound and complete w.r.t. Fk, a rule R is applicable to Fk iff there is a bag in (DT (S), P ) whose pattern contains a pair (body(R),−); then, the bag created by a rule application (R, π) to Fk has parent Bj in DT (S) iff Bj is the bag in (DT (S), P ) with the smallest j such that P (Bj) contains (body(R), π\n′) for some π′ which coincides with π on fr(R), i.e., π|fr(R) = π ′ |fr(R). Patterns are managed as follows: (1) The pattern of B0 is the maximal sound and complete pattern with respect to F ; (2) after each addition of a bag Bi, the patterns of all bags are updated to ensure their soundness and completeness with respect to Fi. It follows that we can define a patterned derivation, where rule applicability is checked on patterns, and the associated sound and complete patterned derivation tree, which can be shown to be isomorphic to the derivation tree associated with the (regular) derivation.\nRemember that our final rationale is to avoid computations on the “fact level”. We will instead incrementally maintain sound and complete patterns by a propagation mechanism on patterns. This is why we need to consider patterns with subsets of rule bodies and not just full rule bodies. We recall that the rules have pairwise disjoint sets of variables.\nDefinition 12 (Elementary Join). Let B1 and B2 be two bags, e1 = (sb 1 R, π1) ∈ P (B1) and e2 = (sb 2 R, π2) ∈ P (B2) where sb1R and sb2R are subsets of body(R) for some rule R. Let V = vars(sb1R) ∩ vars(sb2R). The (elementary) join of e1 with e2, noted J(e1, e2), is defined if for all x ∈ V , π1(x) and π2(x) are both defined and π1(x) = π2(x). Then J(e1, e2) = (sbR, π), where sbR = sb 1 R ∪ sb2R and π = π1 ∪ π′2, where π′2 is the restriction of\nπ2 to the inverse image of terms(B1) (i.e., the domain of π ′ 2 is the set of terms with image in terms(B1)).\nNote that V may be empty. The elementary join is not a symmetrical operation since the range of the obtained mapping is included in terms(B1).\nExample 9. Let us consider the bags B1 and B2 in Figure 4. Let e1 = ({q2(x4, y4, z4)}, π = {x4 7→t11, y4 7→u11, z4 7→v11}) be in the pattern of B1, and e2 = ({s(y4, t4), r(z4, t4), h(t4)}, π′ = {y4 7→u11, z4 7→v11, t4 7→t12}) be in the pattern of B2. The elementary join of e1 with e2 is ({q2(x4, y4, z4), s(y4, t4), r(z4, t4), h(t4)}, π).\nDefinition 13 (Join). Let B1 and B2 be two bags with respective patterns P (B1) = P1 and P (B2) = P2. The join of P1 with P2, denoted J(P1, P2), is the set of all defined J(e1, e2), where e1 = (sb 1 R, π1) ∈ P1, e2 = (sb2R, π2) ∈ P2.\nNote that P1 ⊆ J(P1, P2) since each pair from P1 can be obtained by an elementary join with (∅, ∅). Similarly, J(P1, P2) contains all pairs (G, π) obtained from (G, π2) ∈ P2 by restricting π2 to the inverse image of terms(B1). Note that join preserves soundness, as stated in the following property.\nProperty 6. If P1 and P2 are sound w.r.t. Fi then J(P1, P2) is sound w.r.t. Fi.\nProof. Follows from the definitions: for all (G, π) ∈ J(P1, P2), either (G, π) ∈ P1, or is obtained by restricting an element of P2, or is equal to J(e1, e2) for some e1 = (sb 1 R, π1) ∈ P1 and e2 = (sb 2 R, π2) ∈ P2. In the latter case, let us consider two homomorphisms, h1 and h2 with co-domain Fi, which respectively extend π1 and π2. The union of h1 and h2 is a mapping from terms(G) to Fi (remember that h1 and h2 are equal on the intersection of their domains). Moreover, it is a homomorphism, because every atom in G is mapped to an atom in Fi by h1 or by h2.\nWe consider the step from Fi−1 to Fi in a (patterned) derivation sequence: let Bc be the bag created in this step and let Bp be its parent in (DT (S), P ).\nDefinition 14 (Initial Pattern). The initial pattern of a bag Bc, denoted by Pinit(Bc), is the set of pairs (G, π) such that G is a subset of some rule body of R and π is a homomorphism from G to atoms(Bc).\nExample 10 (Initial Pattern). Let us consider the initial pattern of B2 in Figure 4. The atoms of B2 are:\n{s(u11, t12), r(v11, t12), q3(t12, u12, v12)}.\nFor rules Rex1 , R ex 2 , R ex 6 and R ex 7 , no subset of a rule body maps to the atoms of B2. Thus, they do not contribute to the initial pattern of B2. There is one homomorphism from the body of Rex3 to atoms of B2, and thus its initial pattern contains:\n({q3(t3, u3, v3)}, {t3 7→t12, u3 7→u12, v3 7→v12).\nAs for subsets of the body of Rex4 , there are three elements added to the initial pattern of B2:\n• ({s(y4, t4)}, {y4 7→u11, t4 7→t12}),\n• ({r(z4, t4)}, {t4 7→t12, z4 7→v11}),\n• ({s(y4, t4), r(z4, t4)}, {y4 7→u11, t4 7→t12, z4 7→v11}).\nSimilar elements are added by taking subsets of the body of Rex5 .\nProperty 7 (Soundness of Initial Pattern of Bc w.r.t. Fi). The initial pattern of Bc is sound with respect to Fi.\nProof. For any (G, π) ∈ Pinit(Bc), π is a homomorphism from G to atoms(Bc) ⊆ Fi.\nObviously, if a pattern is sound w.r.t. Fi−1 then it is sound w.r.t. Fi. The following property focus on completeness.\nProperty 8 (Completeness of J(P (Bc), P (Bp)) w.r.t. Fi). Assume that P (Bp) is complete w.r.t. Fi−1 and R. Then J(Pinit(Bc), P (Bp)) is complete w.r.t. Fi.\nProof. Let π be a homomorphism from sbR ⊆ body(R) to Fi, for some rule R. We show that J(Pinit(Bc), P (Bp)) contains (sbR, π\n′), where π′ is the restriction of π to the inverse image of terms(Bc). Let us partition sbR into bi−1, the subset of atoms mapped by π to Fi−1, and bi the other atoms from sbR, which are necessarily mapped by π to Fi \\ Fi−1, i.e., atoms(Bc). If bi is not empty, by definition of the initial pattern, Pinit(Bc) contains (bi, πc), where πc is the restriction of π to terms(bi). If bi−1 is not empty, by hypothesis (completeness of P (Bp) w.r.t. Fi−1), Pp contains (bi−1, πp), where πp is the restriction of π|bi−1 to the inverse image of terms(Bp). If bi−1 or bi is empty, (sbR, π\n′) belongs to J(Pinit(Bc), P (Bp)). Otherwise, consider J((bi, πc), (bi−1, πp)): it is equal to (sbR, π ′).\nProperty 9 (Completeness of Join-Based Propagation). Assume that (DT (S), P ) is complete w.r.t. Fi−1, and P (Bc) is computed by J(Pinit(Bc), P (Bp)). Let d(B) denote the distance of a bag B to Bc in (DT (S), P ). Updating a bag B consists in performing J(P (B), P (B′)), where B′ is the neighbor of B s.t. d(B′) < d(B). Let (DT (S), P ′) be obtained from (DT (S), P ) by updating all patterns by increasing value of d of the corresponding bags. Then (DT (S), P ′) is complete w.r.t. Fi.\nProof. From Property 8, we know that P ′(Bc) is complete w.r.t. Fi. It remains to prove the following property: let P ′(B) be obtained by computing J(P (B), P ′(B′)); if P ′(B′) is complete w.r.t. Fi, then J(P (B), P\n′(B′)) is complete w.r.t. Fi. We partition sbR in the same way as in the proof of Property 8. If one of the subsets is empty, we are done. Otherwise, the partition allows to select an element e1 from P (B) and an element e2 from P ′(B′), and J(e1, e2) is the element we want to find. The crucial point is that if π maps an atom a of sbR to an atom b of Fi \\Fi−1, and b shares a term e with B, then e ∈ terms(Bc), hence, thanks to the running intersection property of a decomposition tree, e ∈ terms(B′), thus (e, π(e)) will be propagated to P ′(B).\nIt follows that the following steps performed at each bag creation (where Bc is introduced as a child of Bp) allow to maintain the soundness and completeness of the patterned derivation tree throughout the derivation:\n1. initialize: compute Pinit(Bc) for the newly created pattern Bc;\n2. update: P ′(Bc) = J(Pinit(Bc), P (Bp));\n3. propagate: first, propagate from P (Bc) to P (Bp), i.e., P ′(Bp) = J(P (Bp), P ′(Bc)); then, for each bag B updated from a bag B′, update its children Bi (for Bi 6= B′) by P ′(Bi) = J(P (Bi), P ′(B)) and its parent Bj by P ′(Bj) = J(P (Bj), P\n′(B)). Iterate this step until every pattern is updated (i.e., P ′(B) is determined for every bag B of the current derivation tree)."
    }, {
      "heading" : "4.2 Bag Equivalence",
      "text" : "We now show how bag patterns allow us to identify a certain kind of regularity in a derivation tree. We first need some technical, but nonetheless natural definitions. We start with the notion of a fusion of the frontier induced by a rule application: given a rule application, it summarizes which frontier terms are mapped to the same term, and if they are mapped to a term of T0 (that is, an initial term or a constant).\nDefinition 15 (Fusion of the Frontier Induced by π). Let R be a rule and V be a set of variables with V ∩ T0 = ∅. Let π be a substitution of fr(R) by T0 ∪ V . The fusion of fr(R) induced by π, denoted by σπ, is the substitution of fr(R) by fr(R) ∪ T0 such that for every variable x ∈ fr(R), if π(x) ∈ V then σπ(x) is the smallest7 variable y of fr(R) such that π(x) = π(y); otherwise σπ(x) = π(x) ∈ T0.\nExample 11. Let us consider Rex2 = q2(x2, y2, z2) → s(y2, t2) ∧ r(z2, t2) ∧ q3(t2, u2, v2). Let π1 = {y2 7→y0, z2 7→y0}. The substitution of the frontier of R2 induced by π1 is defined by σπ1 = {y2 7→y2, z2 7→y2}. Let b be a constant, and π2 be a substitution of the frontier of R1 defined by π2 = {y2 7→b, z2 7→b}. The fusion of the frontier induced by π2 is defined by σπ2 = {y2 7→b, z2 7→b}. Last, if π3 maps y2 and z2 to two different existentially quantified variables, then σπ3 is the identity on the frontier of R2.\nThis notion of fusion is the main tool to define structural equivalence, which is an equivalence relation on the bags of a derivation tree.\nDefinition 16 (Structural Equivalence). Let B and B′ be two bags created by applications (R, πi) and (R, πj), respectively, of the same rule R. B and B\n′ are structurally equivalent, written B ' B′ if the fusions of fr(R) induced by the restrictions of πi and πj to fr(R) are equal.\nWe will see later that structural equivalence is not sufficient to formalize regularity in a derivation tree. However, there is already a strong similarity between structurally equivalent bags: the purpose of Definition 17 is to formalize it.\nDefinition 17 (Natural Bijection). Let B and B′ be two structurally equivalent bags created by applications (R, πi) and (R, πj). The natural bijection from terms(B) to terms(B\n′) (in short from B to B′), denoted ψB→B′, is defined as follows:\n• if x ∈ T0, let ψB→B′(x) = x\n7. We assume variables to be totally ordered (for instance by lexicographic order).\n• otherwise, let orig(x) = {u ∈ vars(head(R))|πsafei (u) = x}. Since B and B′ are structurally equivalent, ∀u, u′ ∈ orig(x), πsafej (u) = πsafej (u′). We define ψB→B′(x) = πsafej (u).\nThe natural bijection is thus an isomorphism between two bags. This natural bijection between structurally equivalent bags gives us a way to partially order patterns, by ensuring that the ranges of partial applications are on the same set of terms.\nDefinition 18 (Pattern Inclusion, Pattern Equivalence). Let B and B′ be two bags, with respective patterns P (B) and P (B′). We say that P (B′) includes P (B), denoted by P (B) v P (B′), if :\n• B and B′ are structurally equivalent, i.e., B ' B′,\n• P (B′) contains all elements from P (B), up to a variable renaming given by the natural bijection: (G, π) ∈ P (B)⇒ (G,ψB→B′ ◦ π) ∈ P (B′).\nWe say that P (B) and P (B′) are equivalent, denoted P (B) ∼ P (B′), if P (B′) v P (B) and P (B) v P (B′). By extension, two bags are said to be equivalent if their patterns are equivalent.\nProperty 10 helps to understand why Definition 18 provides us with a good notion of pattern equivalence, by linking the equivalence of patterns to the applicability of rules on bags having these patterns. Let us note that this property does not hold if we put structural equivalence in place of pattern equivalence.\nProperty 10. Let S be a derivation, and B and B′ two bags of (DT(S), P ) such that P (B) ∼ P (B′). If a rule R is applicable to B by π, then R is applicable to B′ by ψB→B′ ◦π.\nProof. Since R is applicable to B by π, (body(R), π|fr(R)) belongs to P (B). By definition of the equivalence of patterns, (body(R), ψB→B′ ◦ π|fr(R)) belongs to P (B′), which implies that R is applicable to B′.\nWe now present how this equivalence relation will be used to finitely represent the (potentially infinite) set of derived facts. Intuitively, a blocked tree Tb is a subtree (with the same root) of a patterned derivation tree (DT(S), P ) of a sufficiently large derivation sequence S. Additionally every bag in Tb is marked by either “blocked” or “non-blocked”. Assuming that we know which length of derivation is enough, Tb is constructed such that it has the following properties:\n• for each equivalence class appearing in (DT(S), P ), there is exactly one non-blocked node of Tb of that class;\n• if a bag B is blocked in Tb, it is a leaf, i.e., it has no child in Tb (although it may have children in (DT(S), P ));\n• if a bag is non-blocked in Tb, all children of B in (DT(S), P ) are present in Tb.\nDefinition 19 (Blocked Tree). A blocked tree is a structure (Tb,∼), where Tb is an initial segment of a patterned derivation tree and ∼ is the equivalence relation on the bags of Tb such that for each ∼-class, all but one bag are said to be blocked; this non-blocked bag is called the representative of its class and is the only one that may have children.\nA blocked tree Tb can be associated with a possibly infinite set of decomposition trees obtained by iteratively copying its bags. We first define the bag copy operation:\nDefinition 20 (Bag Copy). Let B1 and B2 be structurally equivalent bags with natural bijection ψB1→B2. Let B ′ 1 be a child of B1. Copying B ′ 1 under B2 (according to ψB1→B2) is performed by adding a child B′2 to B2, such that terms(B ′ 2) = {ψB′1→B′2(t) | t ∈ terms(B ′ 1)} and atoms(B′2) = {ψB′1→B′2(a) | a ∈ atoms(B ′ 1)}, where ψB′1→B′2 is defined as follows: for all x ∈ terms(B′1), if x ∈ terms(B1) then ψB′1→B′2(x) = ψB1→B2(x), otherwise ψB′1→B′2(x) is a fresh variable.\nAssume that, in the previous definition, the bag B′1 has been created by (R, π). Then B′2 can be seen as obtained by the fusion of fr(R) induced by the potential application of R to B2 with the homomorphism ψB1→B2 ◦ π. Since the fusions of fr(R) induced by π and ψB1→B2 ◦ π are equal, B′1 and B′2 are structurally equivalent, which justifies the use of ψB′1→B′2 for the bijection.\nStarting from a blocked tree Tb and using iteratively the copy operation when applicable, one can build a possibly infinite set of trees, that we denote by G(Tb). This set contains pairs, whose first element is a tree, and the second element is a mapping from the bags of this tree to the bags of Tb, which encodes which bags of Tb have been copied to create the bags of the generated tree.\nDefinition 21 (Trees Generated by a Blocked Tree). Given a blocked tree Tb, let the set G(Tb) of trees generated by Tb be inductively defined as follows:\n• Let B0 be the root of Tb; the pair ({B0}, {B0 7→B0}) belongs to G(Tb).\n• Given a pair (T, f) ∈ G(Tb), let B be a bag in T, and B′ = f(B); let B′r be the representative of the ∼-class containing B′ (i.e., B′r 6= B′ if B′ is blocked) and let B′c be a child of B′r. If B has no child mapped to B ′ c by f , let Tnew be obtained from\nT by copying B′c under B (according to ψB′r→B), which yields a new bag Bc. Then (Tnew, f ∪ (Bc 7→B′c)) belongs to G(Tb).\nFor each pair (T, f) ∈ G(Tb), T is said to be generated by Tb via f . The tree T is said to be generated by Tb if there exists an f such that T is generated by Tb via f .\nNote that a patterned decomposition tree thus generated is not necessarily a derivation tree, but it is an initial segment of a derivation tree. Among blocked trees, so-called full blocked trees are of particular interest.\nDefinition 22 (Full Blocked Tree). A full blocked tree T∗ (of F and R) is a blocked tree satisfying the two following properties:\n• (Soundness) If T′ is generated by T∗, then there is some T′′ generated by T∗ and an R-derivation S from F such that atoms(T′′) = atoms(DT (S)) (up to fresh variable renaming) and T′ is an initial segment of T′′.\n• (Completeness) For all R-derivations from F , DT (S) is generated by T∗.\nThe procedure outlined above (considering a particular tree prefix of a sufficiently large derivation tree) is however not constructive. We show how to circumvent this problem in the next section."
    }, {
      "heading" : "4.3 Abstract Patterns and Abstract Pattern Saturation",
      "text" : "We now aim at computing a full blocked tree. To this end, we fix a representative for each structural equivalence class, as well as for each (pattern-based) equivalence class. This is the purpose of abstract bags and abstract patterns. We also need to describe on an abstract level how bags of a derivation tree are related to each other: links are introduced to that aim. Having defined these basic components, we will focus on getting structural knowledge about the derivation trees that can be created starting from a fact and a set of rules: creation rules and evolution rules will be defined. In the last step, we use these rules to compute a full blocked tree.\nWe start by defining abstract bags. Each abstract bag can be seen as a canonical representative of a class of the structural equivalence relation. In order to have a uniform presentation, we consider the initial fact as a rule with empty body.\nDefinition 23 (Abstract Bag, Frontier Terms, Generated Variables). Let R be a rule from R and σ a fusion of fr(R). The abstract bag associated with R and σ (notation: B(R, σ)) is defined by terms(B(R, σ)) = σ(terms(head(R))) ∪ T0 and atoms(B(R, σ)) = σ(head(R)). The frontier terms of B(R, σ) are the elements of σ(fr(R)). Variables from terms(B(R, σ)) that are not frontier terms are called generated variables.\nThe notion of the natural bijection between structurally equivalent bags is extended to abstract bags in the straightforward way (note that there is exactly one abstract bag per structural equivalence class).\nExample 12 (Abstract Bag). Let us consider Rex2 = q2(x2, y2, z2) → s(y2, t2) ∧ r(z2, t2) ∧ q3(t2, u2, v2), and three fusions of its frontier, namely: σπ1 = {y2 7→y2, z2 7→y2}, σπ2 = {y2 7→b, z2 7→b} and σπ3 = {y2 7→y2, z2 7→z2}. The abstract bag B(Rex2 , σπ1) associated with Rex2 and σπ1 has as terms {y2, t2, u2, v2} and as atoms {s(y2, t2), r(y2, t2), q3(t2, u2, v2)}. The terms of the abstract bag B(Rex2 , σπ2) are {b, t2, u2, v2}; its atoms are {s(b, t2), r(b, t2), q3(t2, u2, v2)}. For B(Rex2 , σπ3), its terms are {y2, t2, u2, v2, z2} and its atoms are {s(y2, t2), r(z2, t2), q3(t2, u2, v2)}.\nSince abstract bags provide us with a canonical representative for each structural equivalence class, we can now define a canonical representative for each class of equivalent patterns: abstract patterns. To distinguish the abstract bags and patterns from their concrete counterparts, we will denote them by B and P (possibly with subscripts) instead of B and P .\nDefinition 24 (Abstract Pattern, Support). Let R be a set of rules, R be a rule and σ be a fusion of fr(R). An abstract pattern P with support B = B(R, σ) is a set of pairs (G, π) where G is a subset of a rule body (of some rule of R) and π is a partial mapping from terms(G) to terms(B). G and π are possibly empty.\nExample 13 (Abstract Pattern). Let us consider again the initial pattern described in Example 10. This pattern contains the following elements:\n• ({q3(t3, u3, v3)}, {t3 7→t12, u3 7→u12, v3 7→v12}),\n• ({s(y4, t4)}, {t4 7→t12, y5 7→u11}),\n• ({r(z4, t4)}, {t4 7→t12, z4 7→v11}),\n• ({s(y4, t4), r(z4, t4)}, {t4 7→t12, y4 7→u11, t4 7→v11}),\n• ({s(y5, t5)}, {t5 7→t12, y5 7→u11}),\n• ({r(z5, t5)}, {t5 7→t12, z5 7→v11}),\n• ({s(y5, t5), r(z5, t5)}, {t5 7→t12, y5 7→u11, z5 7→v11}).\nThis pattern is associated with a bag equivalent to the abstract bag B(R2, id). Thus, the abstract pattern P associated with this initial pattern contains the same elements, where the mappings are modified by substituting t12 by t2, u 1 2 by u2, v 1 2 by v2, u 1 1 by y2 and v 1 1 by z2.\nDefinition 25 (Initial Abstract Pattern). Let B be an abstract bag. The initial abstract pattern of B, denoted by Pinit(B) is the set of pairs (G, π) such that G is a subset of a rule body and π is a (full) homomorphism from G to atoms(B).\nLet B1 and B2 be two bags of a derivation tree such that B2 is a child of B1. B1 and B2 share some terms. Let us assume that B1 is structurally equivalent to an abstract bag B1 and that B2 is structurally equivalent to an abstract bag B2. If we only state that a bag equivalent to B2 is a child of a bag equivalent to B1, we miss some information about the above mentioned shared terms. Capturing this information is the purpose of the notion of link.\nDefinition 26 (Link). Let B1 and B2 be two abstract bags. A link from B2 to B1 is an injective mapping λ from the frontier terms of B2 to the terms of B1 such that the range of λ has a non-empty intersection with the generated terms of B1.\nPlease note that we define a link from a bag to its parent. It ensures that each bag has exactly one link. We will thus refer without ambiguity to the link of an abstract bag.\nExample 14 (Link). Let us consider Rex1 = q1(x1, y1, z1)→ s(y1, t1)∧r(z1, t1)∧q2(t1, u1, v1) and Rex2 = q2(x2, y2, z2) → s(y2, t2) ∧ r(z2, t2) ∧ q3(t2, u2, v2), and the two abstract bags B1 = B(R1, id) and B2 = B(R2, id). Then λ = {y2 7→u1, z2 7→v1} is a link from B2 to B1.\nWe are also interested in the link that describes a particular situation in a derivation tree, hence the notion of induced link.\nDefinition 27 (Induced Link). Let B1 and B2 be two bags of a derivation tree such that B2 is a child of B1. Let B1 and B2 be two abstract bags such that B1 ' B1 and B2 ' B2. The link induced by B1 and B2 is the mapping λ of the frontier terms of B2 to terms(B1) defined by λ(y) = ψB1→B1(ψB2→B2(y)). We then also say that B2 is linked to B1 by λ.\nPrevious Property 10 states that the pattern of a bag determines the rules that are applicable on it. We will thus gather information relative to the structure of derivation trees by means of “saturation rules” whose intuition is explained by the following example. Note that these rules have nothing to do with existential rules.\nExample 15. Let us consider R1 = r(x1, y1) → s(x1, y1) and R2 = s(x2, y2) → p(x2). Let P1 be the following pattern: {r(x, y), {x 7→a, y 7→b}}. For any bag B of a derivation tree DT(S) such that P1 v P (B). R1 is applicable by mapping x1 to a and y1 to b. This allows to derive s(a, b) (which may be used to apply R2). Thus, the pattern of B in some derivation starting with S contains P2 = {(r(x1, y1), {x1 7→a, y1 7→b}), (s(x2, y2), {x2 7→a, y2 7→b})}. Let us point out that this pattern inclusion is valid in “sufficiently complete” derivations, but not necessarily in the derivation tree of each derivation sequence.\nExample 15 gives the intuition behind evolution rules: it exhibits a case where we can infer that if a bag has a pattern including P1, then its pattern can evolve into a pattern including P2. Such information will be gathered by evolution rules, and will be denoted by P1 P2 with P1 and P2 being the abstract counterparts of P1 and P2, respectively. To deal with the creation of new bags, we design creation rules. They allow us to derive information about the children that a bag with a given pattern must have. Such a rule will be denoted by P1 λ.P2, and intuitively means that rules may be applied to ensure that any bag B1 with pattern P1 has a child B2 with pattern P2 such that the link induced by B1 and B2 is λ and P1 and P2 are again the abstract counterparts of P1 and P2, respectively.\nIn the following, we show how to derive a set of sound creation and evolution rules by means of Properties 11 to 16.\nDefinition 28 (Sound Creation Rule). Let P1,P2 be two abstract patterns, and λ be a link between the support of P2 and the support of P1. A creation rule is a rule of the following form:\nγc : P1 λ.P2.\nγc is sound if for any derivation S, for any bag B1 of (DT(S), P ) such that P1 v P (B1), there exists a derivation S′ extending S with a child B2 of B1 in (DT(S\n′), P ′) linked by λ to B1, and for which P2 v P ′(B2).\nDefinition 29 (Sound Evolution Rule). Let P1,P2 be two abstract patterns. An evolution rule is a rule of the following form:\nγe : P1 P2.\nγe is sound if P1 v P2 and for any derivation S and for any bag B of (DT(S), P ) satisfying P1 v P (B), there exists a derivation S′ extending S with patterned derivation tree (DT(S′), P ′) such that P2 v P ′(B).\nWe now exhibit properties allowing to build sound rules.\nProperty 11. Let P be an abstract pattern with support B, let R be a rule from R, and let π be a mapping from fr(R) to terms(B) such that its range has a non empty intersection\nwith the generated terms in P. Let (body(R), π) be an element of P. Let σ be the fusion of fr(R) induced by π. Then P λ.Pinit(B(R, σ)) is a sound creation rule, where λ is equal to π restricted to {σ(y) | y ∈ fr(R)}.\nProof. Since the range of π has a non-empty intersection with the set of generated terms of B(R, σ), λ is a link from B(R, σ) to the support of P. Moreover, let B be a bag of a derivation tree such that P v P (B). Then (body(R), ψsupport(P)→B ◦ π) ∈ P (B). Thus, R is applicable, by mapping its frontier to terms(B) (and at least one term generated in B is the image of an element of the frontier). Thus B has a child with link λ and with a pattern that includes Pinit(B(R, σ)).\nWe now define the counterpart of elementary joins for abstract patterns. The main difference is that the relationships between terms of different abstract patterns cannot be checked by equality as it was done previously. We thus define abstract elementary joins, where these relationships are specified by the link between two abstract patterns. A link between two patterns is not symmetric: we thus define two join operations, to update either the abstract pattern that is the domain of the link or the abstract pattern that is the range of the link.\nDefinition 30 (Elementary Abstract Upper/Lower Join). Let P1 and P2 be two abstract patterns, and let λ be a link from P2 to P1. Let R be a rule in R and let (sb1, π1) ∈ P1 and (sb2, π2) ∈ P2 for sb1, sb2 ⊆ body(R). The elementary abstract upper and lower joins of (sb1, π1) with (sb2, π2) are defined if π1(x) and λ(π2(x)) are defined and equal for all x ∈ vars(sb1) ∩ vars(sb2). In that case, it is the pair (sb1 ∪ sb2, π) with:\n• π = π1 ∪ λ ◦ π′2, where π′2 is the restriction of π2 to π −1 2 (domain(λ)), for the upper\njoin;\n• π = π2 ∪ λ−1 ◦ π′1, where π′1 is the restriction of π1 to π −1 1 (range(λ)), for the lower\njoin.\nDefinition 31 (Abstract Upper/Lower Join). Let P1 and P2 be two abstract patterns, and let λ be a link from P2 to P1.\nThe abstract upper join of P1 w.r.t. (λ,P2) is the set of all existing elementary abstract upper joins of (sb1, π1) ∈ P1 with (sb2, π2) ∈ P2, where sb1, sb2 ⊆ body(R) for some R ∈ R. It is denoted by Joinu(P1, λ,P2).\nThe abstract lower join of P2 w.r.t. (λ,P1) is the set of all existing elementary abstract lower joins of (sb1, π1) ∈ P1 with (sb2, π2) ∈ P2, where sb1, sb2 ⊆ body(R) for some R ∈ R. It is denoted by Joinl(P1, λ,P2).\nWe now exploit this notion of join in order to define new sound creation and evolution rules.\nProperty 12. If P1 λ.P2 is a sound creation rule, then so is P1 λ.Joinl(P1, λ,P2).\nProof. Let S be a derivation, B1 be a bag of (DT(S), P ) such that P1 v P (B1). Since P1 λ.P2 is sound, there are a derivation S′ with patterned derivation tree (DT(S′), P ′) and a child B2 of B1 in S\n′ linked to B1 by λ such that P2 v P ′(B2). By soundness of join propagation, Join(P ′(B2), P\n′(B1)) v P ′(B2). By monotonicity of the join operation, we obtain that P1 λ.Joinl(P1, λ,P2)) is a sound rule.\nProperty 13. If P1 λ.P2 is a sound creation rule, then P1 Joinu(P1, λ,P2) is a sound evolution rule.\nProof. Similar to the proof of Prop 12.\nProperty 14. If P1 P2 and P2 P3 are sound evolution rules, then P1 P3 is also a sound evolution rule.\nProof. Let S be a derivation, and let B be a bag of (DT(S), P ) such that P1 v P (B). Since P1 P2 is sound, there exists a derivation S′ extending S such that P2 v P ′(B). Since P2 P3 is sound, there exists a derivation S′′ extending S′ such that P3 v P ′′(B). Since S′′ is also a derivation extending S, it holds that P1 P3 is sound.\nProperty 15. If P1 P2 and P1 λ.P3 are sound evolution/creation rules, then P2 λ.P3 is a sound creation rule.\nProof. The property holds by monotonicity of the join operation, and by the condition that P1 P2 being sound implies P1 v P2.\nProperty 16. If P1 λ.P2 and P2 P3 are sound creation/evolution rules, then P1 λ.P3 is a sound creation rule.\nProof. Let S be a derivation, and let B1 be a bag of (DT(S), P ) such that P1 v P (B1). Since P1 λ.P2 is sound, there are a derivation S′ with patterned derivation tree (DT(S′), P ′) and a child B2 of B1 in S\n′ that is linked to B1 by λ such that P2 v P ′(B2). Since P2 P3 is sound, there exists a derivation S′′ extending S′ such that P3 v P ′′(B2). S′′ extends S as well, and thus P1 λ.P3 is a sound creation rule.\nWe call (abstract) pattern saturation the already outlined procedure that builds all creation and evolution rules w.r.t. F and R, obtained via an exhaustive application of all deduction rules displayed in Fig. 5. We now prove that this process terminates.\nProperty 17 (Termination). For any fact F and any gbts set of rules R, abstract pattern saturation terminates.\nProof. There is a finite number of abstract patterns and links between them, and thus a finite number of evolution and creation rules. At each step, the number of created rules can only increase, which shows the termination of pattern saturation.\nFor technical purposes, we will use the rank of an evolution/creation rule.\nDefinition 32 (Rank). The rank of an evolution or a creation rule is the minimum number of deduction rules (Figure 5) necessary to derive that rule.\nThis notion of rank helps us to prove the following technical lemma, that states that the pattern saturation respects some notion of monotonicity: at least as much information can be derived from an abstract pattern P2 as from an abstract pattern P1 if P1 v P2.\nLemma 18. Let P1 and P2 be two abstract patterns such that P1 v P2. For any rule P1 P′1 (resp. P1 λ.P′1) in the pattern saturation, there exists a rule P2 P′2 (resp. P2 λ.P′2) in the pattern saturation such that P′1 v P′2.\nProof. We prove the result by induction on the rank of P1 P′1 (resp. P1 λ.P′1). At rank 0, the result is vacuously true.\n• Let P1 P′1 be a rule of rank n of the pattern saturation. It has been obtained by applying Property 13 or Property 14 to rules of rank strictly smaller than n. Let us first consider that Property 13 has been applied. Let P1 λ.P̃1 be the rule on which Property 13 has been applied. By induction hypothesis, there exists a rule P2 λ.P̃2 in the pattern saturation such that P̃1 v P̃2. By monotonicity of the join operation, it holds that P′1 = Joinu(P1, λ, P̃1) v Joinu(P2, λ, P̃2) = P′2. Thus P2 P′2 is in the pattern saturation and P′1 v P′2. Let us now consider that Property 14 has been used to create P1 P′1. Then, there are two rules of rank strictly smaller than n, namely P1 P′′1 and P′′1 P′1. By induction hypothesis, there is a rule P2 P′′2 in the pattern saturation such that P′′1 v P′′2. We can once again apply the induction hypothesis, and we conclude that there exists a rule P′′2 P′2 in the pattern saturation, where P′1 v P′2. By applying Property 14, we conclude that P2 P′2 is in the pattern saturation.\n• Let γe : P1 λ.P′1 be a rule of rank n of the pattern saturation. It may have been created by application of Properties 11, 12, 15 or 16.\n– If γe has been created by Property 11, then the rule P2 λ.P′1 can also be created thanks to this property, since P1 v P2. – If γe has been created by Property 12, then there is a rule P1 λ.P′′1 of rank strictly smaller than n in the pattern saturation, which has been used to create γe. By induction hypothesis, there is a rule P2 λ.P′′2. We define P′2 = Joinl(P2, λ,P′′2). By monotonicity of the join operation, we have that P′1 = Joinl(P1, λ,P′′1) v Joinl(P2, λ,P′′2) = P′2. By applying Property 12, we create P2 λ.P′2, which shows the claim. – If γe has been created by Property 15, there are two rules P′′1 P1 and P′′1 λ.P′1 of rank strictly less than n in the pattern saturation. Since P′′1 v P1 v P2, we\ncan directly apply the induction hypothesis and state the existence of P2 λ.P′2 with P′1 v P′2. – If γe has been created by Property 16, there exists two rules P1 λ.P′′1 and P′′1 P′1 of rank strictly less than n in the pattern saturation. By induction hypothesis, there exists a rule P2 λ.P′′2 in the pattern saturation, with P′′1 v P′′2. We can once again apply the induction hypothesis, inferring the existence of P′′2 P′2 in the pattern saturation, with P′1 v P′2. By applying Property 16, we infer the existence of P2 λ.P′2, which concludes the proof.\nIn the obtained fixpoint, some rules are redundant. For instance, if there exist two rules P1 λ.P2 and P1 λ.P3, with P2 v P3, then the first rule is implied by the second one. This motivate the definition of most informative rules.\nDefinition 33 (Most informative rules). Let F be a fact and R be a gbts set of rules. The set of most informative rules associated with F and R, denoted by IF,R is the maximal subset of the abstract pattern saturation such that:\n• a creation rule P1 λ.P2 belongs to IF,R if there is no rule in the abstract P1 λ.P2 with P2 6= P3 and P2 v P3;\n• an evolution rule P1 P2 belongs to IF,R if there is no rule P1 P2 in the abstract pattern saturation that satisfies P2 6= P3 and P2 v P3.\nLet us notice that we can without ambiguity speak about the evolution rule of the most informative rule set having a given abstract pattern as left hand side (when it exists), as there is at most one such rule.\nProperty 19. Let F be a fact, R be a gbts set of rules, and P be an abstract pattern. IF,R contains at most one evolution rule and at most one creation rule having P as left-hand side.\nProof. We show that if P λ.P1 and P λ.P2 (resp. P P1 and P P2) belong to the pattern saturation, then there exists P3 with P1 v P3 and P2 v P3 such that P λ.P3 (resp. P P3) belongs to the pattern saturation as well.\nWe assume without loss of generality that P λ.P1 (resp. P P1) is the rule of smallest rank, and we prove the result by induction on that rank. A rule can be of rank 1 if and only if it has been created thanks to Property 11. Since the only way to create a rule of the shape P λ.P1 is to use that property and that other deduction rules may only make the patterns grow, it holds that P1 v P2, and we can take P3 = P2. The results thus holds if the first rule is of rank 1. Let us assume the result to be true for any rule up to rank n, and let us show that it is true as well for any rule of rank k + 1. We first consider creation rules and we distinguish three cases:\n• P λ.P1 has been created by Property 12. We can apply the induction hypothesis on the premises of that deduction rule, say P λ.P′1. There exists thus P′3 such that P λ.P′3 belongs to the pattern saturation and P ′1 v P ′3 and P2 v P ′3. By applying then Property 12, and by monotonicity of the join operation, one get P λ.P3 as desired.\n• P λ.P1 has been created by Property 15. We apply the induction hypothesis on the premise that is a creation rule, which allows us to conclude.\n• P λ.P1 has been created by Property 16. We apply the induction hypothesis on the premise that is a creation rule; Lemma 18 then allows us to conclude.\nWe now consider evolution rules. We distinguish two cases:\n• P P1 has been created by Proposition 13. As in the first case of the creation rules, the result follow by induction hypothesis and monotonicity of the join operation.\n• P P1 has been created by Proposition 14. The result follow by induction hypothesis on the first premise and by Lemma 18.\nWe illustrate pattern saturation by expanding the running example. Writing down absolutely every element of each pattern would impede the ease of reading. We will thus allow ourselves to skip some elements, and focus on the most important ones.\nExample 16. The initial pattern PF of Fex (Example 7) contains the following elements:(q1(x1, y1, z1), {x1 7→a, y1 7→b, z1 7→c}), (q1(x1, y1, z1), {x1 7→d, y1 7→c, z1 7→e}) and (q1(x1, y1, z1), {x1 7→f, y1 7→g, z1 7→g}. By application of Property 11, three novel rules are created: P0 ∅.Pb,c1 , P0 ∅.P c,e 1 and P0 ∅.P g,g 1 , where P b,c 1 , P c,e 1 , and P g,g 1 are described below. The atoms of the abstract bag associated with Pb,c1 are {s(b, t1), r(c, t1), q2(t1, u1, v1)}, and its link is empty (since the whole frontier of Rex1 is mapped to constants). The atoms of the abstract bag associated with Pc,e1 are {s(c, t1), r(e, t1), q2(t1, u1, v1)}, and those of the abstract bag associated with Pg,g1 are {s(g, t1), r(g, t1), q2(t1, u1, v1)}.\nPb,c1 contains the following pairs:\n• ({q2(x2, y2, z2)}, {x2 7→t1, y2 7→u1, z2 7→v1});\n• ({q2(x4, y4, z4)}, {x4 7→t1, y4 7→u1, z4 7→v1});\n• ({s(y4, t4)}, {y4 7→b, t4 7→t1});\n• ({r(z4, t4)}, {z4 7→c, t4 7→t1});\n• ({s(y4, t4), r(z4, t4)}, {y4 7→b, z4 7→c, t4 7→t1});\n• ({s(y5, t5)}, {y5 7→b, t5 7→t1});\n• ({r(z5, t5)}, {z5 7→c, t5 7→t1});\n• ({s(y5, t5), r(z5, t5)}, {y5 7→b, z5 7→c, t5 7→t1}).\nPc,e1 contains the same pairs, except that every occurrence of b is replaced by c and every occurrence of c is replaced by e, whereas Pg,g1 contains the same pairs, except that every occurrence of b is replaced by g and every occurrence of c is replaced by g.\nPb,c1 is graphically represented in Figure 6. These three patterns contain ({q2(x2, y2, z2)}, {x2 7→t1, y2 7→u1, z2 7→v1}), and we thus cre-\nate the three following rules:\ns(b, t1), r(c, t1), q2(t1, u1, v1)\nq2(x2, y2, z2) q2(x4, y4, z4) s(y4, t4)\ns(y5, t5)\nr(z4, t4) r(z5, t5)\nr(z4, t4), s(y4, t4)\nAtoms of the abstract bag:\nr(z5, t5), s(y5, t5)\nt1b\nc u1 v1\nThe element ({q3(t3, u3, v3)}, {t3 7→t2, u3 7→u2, v3 7→v2}) belongs to P2, and thus, we create a rule P2 λ′′.P3), where λ′′ = {t3 7→t2} and P3 contains the following elements:\n• ({h(t4)}, {t4 7→t2}),\n• ({h(t5)}, {t5 7→t2}).\nAt this point, we cannot create any new rule by Property 11. However, Property 13 may be used to derive an evolution of P2. Indeed, since P2 λ′′.P3 has been derived, we can derive P2 P′2 with P′2 = Joinu(P2, λ′′,P3). Note that P′2 is a superset of P2 that additionally contains the following elements:\n• ({s(y4, t4), h(t4)}, {y4 7→y2, t4 7→t2}),\n• ({r(z4, t4), h(t4)}, {z4 7→z2, t4 7→t2}),\n• ({s(y4, t4), r(z4, t4), h(t4)}, {z4 7→z2, y4 7→y2, t4 7→t2}),\n• ({s(y5, t5), h(t5)}, {y5 7→y2, t5 7→t2}),\n• ({r(z5, t5), h(t5)}, {z5 7→z2, t5 7→t2}),\n• ({s(y5, t5), r(z5, t5), h(t5)}, {y5 7→y2, z5 7→z2, t5 7→t2}),\n• ({h(t4)}, {t4 7→t2}),\n• ({h(t5)}, {t5 7→t2}).\nBy Property 16, the following sound rules can then be obtained:\n• Pb,c1 λ′.P′2,\n• Pc,e1 λ′.P′2,\n• Pg,g1 λ′.P′2.\nApplying once more Property 13 yields new sound rules such as:\nPb,c1 P b,c′ 1 ,\nwhere Pb,c ′\n1 is a superset of P b,c 1 that additionally contains, among others, the following\nelement:\n({q2(x4, y4, z4), r(z4, t4), s(y4, t4), h(t4)}, {x4 7→t1, y4 7→u1, z4 7→v1}).\nPlease note that in this case, π = {x4 7→t1, y4 7→u1, z4 7→v1} does not map every variable appearing in the corresponding subset of a rule body. Indeed, t4 is not mapped, since its image by the homomorphism extending π does not belong to the terms relevant to the supporting bag.\nWe skip a part of the further development of this example. It can be checked that at some point, a rule PF P′F is created, where P′F contains the following elements:\n({p1(xp), i(xp)}, {xp 7→g}) ({p2(xq), i(xq)}, {xq 7→g})\nThe following two creation rules are thus sound and relevant:\nP′0 ∅.Pip P′0 ∅.Piq\nwhere Pip contains in particular ({p2(xq), i(xq)}, {xq 7→yp}) and Piq contains ({p1(xp), i(xp)}, {xp 7→yq}). Since the body of Rex6 belongs to Pip, a new creation rule is added: Pip {xp 7→yq}.Pq.\ns(b, t1), r(c, t1), q2(t1, u1, v1)\nAtoms of the abstract bag:\ns(b, t1), r(c, t1), q2(t1, u1, v1) Atoms of the abstract bag:\nLikewise, since the body of Rex7 belongs to Piq, a new creation rule is added: Piq {xq 7→yp}.Pp.\nLast, two recursive rules are added:\nPp {xp 7→yq}.Pq, Pq {xq 7→yp}.Pp."
    }, {
      "heading" : "4.4 Computation of the Full Blocked Tree",
      "text" : "Given a fact, a set of gbts rules and their associated set of most informative rules, Algorithm 1 outputs a full blocked tree for F and R. We start by creating a bag with set of terms T0. This bag is the root of the full blocked tree. We maintain a list of blocked patterns: any bag that is of that pattern and that is not labeled as non-blocked is thus blocked. We then consider the most informative evolution rule having PF = Pinit(B(→ F, ∅)) (i.e., the initial abstract pattern of F ) as left-hand side, say PF → P∗F . We label the root of the full blocked tree with the pattern P∗F .8 We mark this newly created root as being non-blocked. Then, as long as there exist a non-blocked bag B1 and a most informative creation rule P1 λ.P2 with P1 ∼ P (B1) that has not been applied on B1, we apply that rule. To apply it, we add a child B2 to B1 such that P (B2) ∼ P2 and the induced link from B2 to B1 is λ. B2 is considered blocked (i.e., is not marked non-blocked) if there is already a bag B3 with P (B2) ∼ P (B3) in the built structure, and non-blocked otherwise. This procedure halts, since there is a finite number of non-equivalent patterns, and the maximal degree of the built tree is also bounded. It creates a sound blocked tree, since all creation and evolution\n8. Note that, technically, we abuse a abstract pattern as a non-abstract pattern here, but this is not a problem since no safe renaming is necessary for the (pattern of) bag F .\nAlgorithm 1: Creation of a full blocked tree\nData: A fact F , a set of gbts rules R, the set of most informative rules IF,R. Result: T∗b(F,R), a full blocked tree for F and R. define the root of T∗b(F,R) to be BF ; assign to BF a pattern PF ∼ P∗F , such that Pinit(B(→ F, ∅)) P∗F ∈ IF,R ; blocked-patterns := P ∗F ; non-blocked-bags := BF ; next-non-blocked := ∅; while non-blocked-bags 6= ∅ do\nnext-non-blocked := ∅; for B1 ∈ non-blocked-bags do\nP1 := abstract pattern of B1; for all creation rule P1 λ.P2 ∈ IF,R do\nAdd in T∗b(F,R) a child B2 to B1, with induced link λ; Define the pattern of B2 to be P2 ∼ P2; if P2 6∈ blocked-patterns then\nnext-non-blocked-bags := next-non-blocked-bags ∪{B2}; blocked-patterns := blocked-patterns ∪{P2};\nnon-blocked-bags := next-non-blocked;\nreturn T∗b(F,R);\nrules are sound. It also creates a complete blocked tree, and thus a full blocked tree, as will be proven below.\nIntuitively, the following property states that for any derivation tree associated with an R-derivation of F , there exists an isomorphic tree generated by T∗b(F,R).\nProperty 20. Let F be a fact, R be gbts. Let S be an R-derivation of F and let (DT(S), P ) be the according patterned derivation tree with root Broot. Let T∗b(F,R) be the corresponding full blocked tree with pattern-assigning function PT∗b and root B root T∗b . Then there exists a tree decomposition T generated from T∗b(F,R) via a mapping f , such that there exists a bijection g from the bags of (DT(S), P ) to the bags of T that satisfies the following conditions:\n1. g(Broot) = BrootT∗b , i.e., g maps the root of (DT(S), P ) to the root of T∗b(F,R);\n2. P (B) v PT∗b (f(g(B))) for all bags B of (DT(S), P ); 3. for all bags B,B′ of (DT(S), P ) for which B′ is a child of B with induced link λ, g(B′) is a child of g(B) with induced link λ.\nProof. We prove the property by induction on the length of S.\n• If S is the empty derivation, its derivation tree is restricted to a single bag labeled by F . Such a tree can be generated from T∗b(F,R), and the pattern of BrootT∗b is the root of T, is by construction greater than the initial pattern of the original fact.\n• Let us assume that the property is true for all derivations of length n ≥ 0, and let us show that it also holds for any derivation of length n + 1. Let S be a derivation of length n+ 1, and let Sn be its restriction to the n first rule applications. Let Bn+1 be the bag newly created in DT(S), and Bn its parent. By induction hypothesis, there exist g, Tn and fn fulfilling the conditions from 1 to 3 for Sn. Let us consider fn(Bn). By condition 2, we know that P (fn(gn(Bn))) is greater than P (Bn). By Lemma 18, fn(gn(Bn)) has a child B ∗ n+1 whose pattern includes that of Bn+1 and has induced\nlink λ with fn(gn(Bn)). By definition of a tree generated from a blocked tree, it holds that Tn+1 can be generated from T ∗ b(F,R) via fn+1, where:\n– Tn+1 is obtained from Tn by copying B ∗ n+1 under g(Bn); we additionally define\nthis bag as being g(Bn+1);\n– fn+1 is obtained by extending f with fn+1(g(Bn+1)) = B ∗ n+1.\nBy induction hypothesis, it holds that g(Broot) = BrootT ; Condition 1 is thus fulfilled. By construction of g(Bn+1), Condition 3 also. It remains to check Condition 2. This is not trivial, since the patterns of a bag in the fact associated with Sn and with S may be non-equivalent (i.e., the pattern may have “grown”). Let us assume that there exists a bag B∗ such that P (B∗) 6v PT∗b (f(g(B\n∗))). Let us moreover assume that B∗ is (one of) the closest such bag to Bn+1. Let us first notice that it cannot be Bn+1. Indeed, P (Bn+1) is obtained by performing a join operation between its initial pattern and PSn(Bn). By induction hypothesis, P (Bn) v PT∗b (f(g(Bn))). Thus, by Properties 11 and 12, the pattern saturation contains a rule allowing to create a child of g(Bn) whose pattern includes PS(Bn+1) and having induced link λ. Thus B\n∗ is not Bn+1, and by Property 9, P (B ∗) is obtained by performing a join between PSn(B ∗) and P (B∗k), where B ∗ k is the unique bag on the path from Bn+1 to B\n∗ that is either a child or a parent of B∗. Let us consider the case where B∗k is a parent of B\n∗ (the other case is similar). By induction hypothesis, PSn(B ∗) v PT∗b (f(g(B ∗))). By choice of B∗, P (B∗k) v PT∗b (f(g(B ∗ k))). By construction of T ∗ b(F,R) and of its generated tree, there is a rule P1 λ.P2 in the pattern saturation with P1 ∼ PT∗b (f(g(B ∗ k))) and P2 ∼ PT∗b (f(g(B ∗))). Moreover, since this rule is a most informative rule (by construction of T∗b(F,R)), Joinl(P1, λ,P2) v P (f(g(B∗))). However, by monotonicity of the join operation, this would imply that P (B∗) v PT∗b (f(g(B ∗))), hence a contradiction.\nBy preceding observations and Property 20, we are now able to state that Algorithm 1 is correct, as expressed by the next theorem.\nTheorem 21. Algorithm 1 outputs a full blocked tree.\nBefore turning to the more involved querying operation, let us stress that this first algorithm already provides a tight upper-bound for the combined complexity of query answering under gbts rules. Indeed, the problem is already known to be 2ExpTime-hard, since guarded rules - whose 2ExpTime combined complexity was already shown (Cal̀ı et al., 2008), are a particular case of gbts rules.\nTheorem 22. BCQ-Entailment for gbts is in 2ExpTime for combined complexity and in ExpTime for data complexity.\nProof. Let us recall that F,R |= Q holds exactly if F,R ∪ {Q → match} |= match, where match is a fresh, nullary predicate. Note thatR∪{Q→ match} is still gbts since Q→ match is fg . F,R∪ {Q→ match} |= match can be easily checked given T∗b(F,R∪ {Q→ match}) by checking if any of the abstract patterns associated to any of the bags contain some pattern (Q, π) for some π. The computation of the full blocked tree is polynomial in the size of the computed creation/evolution rule set. The number of such rules is polynomial in the number of patterns and in the maximum degree of a derivation tree. The number of patterns is doubly exponential in the data in the worst-case, while the degree is at most exponential. When the rule set (including the query) is fixed, the data complexity falls to ExpTime. Lower bounds for data complexity come from already known complexity results of weakly-guarded rules (Cal̀ı et al., 2008), for instance.\nThe algorithm we proposed is thus worst-case optimal both for combined and data complexities."
    }, {
      "heading" : "4.5 Querying the Full Blocked Tree",
      "text" : "We considered in previous sections the query to be implemented via a rule. This trick allowed to have a conceptually easy querying operation, because it was sufficient to check if some bag of the full blocked tree was labeled by the query and an arbitrary mapping. However, this comes with two drawbacks. The first one is that the query is needed at the time of the construction of the full blocked tree. In scenarios where different queries are evaluated against the same data, one would like to process data and rules independently from the query, and then to evaluate the query on the pre-processed structure. This is not possible if we consider the query to be expressed via a rule. The second drawback of taking the query into account while building the full blocked tree is that it may prevent us from adapting this construction when assumptions are made on the set of rules: can we devise a better algorithm if we have additional knowledge concerning the rule set, for instance, if we know that it is guarded, and not only gbts?\nThis section is devoted to these issues. In the construction of the full blocked tree, we do not consider the query anymore. We still obtain a finite representation of arbitrarily deep patterned derivation trees for F and R, but we cannot just check if a bag is labeled by the query – since the query does not necessarily appear in the considered patterns anymore. A simple homomorphism check is not sufficient either, as can be seen in Example 17 below. To overcome this problem, we introduce a structure called atom-term partition tree (APT). Such a structure is meant to encode a decomposition of the query induced by a homomorphism from that query to a derivation tree. A possible algorithm to check the existence of a homomorphism from a query Q to a derivation tree would be to check if one of the APTs of Q is the structure induced by some homomorphism π, i.e. to validate this APT. APTs and their validation in a derivation tree will be formalized in Section 4.5.1. We are well aware that this definition is more involved than the simple definition of homomorphism. However, our goal will be to validate APTs, not in the potentially ever-growing derivation\ntrees, but in the finite full blocked tree. In that case, APTs will still be used, but we will have to adjust their validation process (Section 4.5.2).\nLet us first stress why the usual homomorphism check is not a suitable operation for querying a full blocked tree. To simplify the presentation, we will restrict the running example in the following way: we only consider rules Rex\n′ 1 = p1(xp) ∧ i(xp) → r(xp, yp) ∧\np2(yp)∧ i(yp) and Rex ′\n2 = p2(xq)∧ i(xq)→ s(xq, yq)∧ p1(yq)∧ i(yq) (this set will be denoted by Rex′), and the initial fact is restricted to i(c) ∧ p1(c) ∧ p2(c) (denoted by F ex ′ ).\nExample 17. Let us consider the following query Qi:\nQi = pi(x) ∧ s(x, y) ∧ r(y, z) ∧ s(z, t) ∧ r(t, u) ∧ r(x, v). If we only look for a homomorphism with atoms belonging to the full blocked tree associated with Rex′ and F ex′ and displayed in Figure 8, we do not find any answer to this query. However, B2 is equivalent to B6, and by considering a derivation tree where B3 would have a corresponding bag below B6 (as B7 in Figure 9), one would find a (correct) mapping of Qi."
    }, {
      "heading" : "4.5.1 Validation of an APT in a Derivation Tree",
      "text" : "Let π be a homomorphism from Q to the atoms of some derivation tree T = DT (S). From π, let us build an arbitrary mapping πaT (out of the many possible ones), defined as follows: for every atom a = p(t1, . . . , tk) of Q, let us choose a bag B of T with π(a) = p(π(t1), . . . , π(tk)) ∈ B, and define πaT (a) = (B, π(a)). Then πaT gives rise to a partitioning of the atoms of Q into atom bags Bagsa(Q) = {Qa1, . . . , Qan}, where two atoms a and b of Q are in the same atom bag Qai if and only if there exists a bag B of T with π a T (a) = (B, π(a)) and πaT (b) = (B, π(b)). On another note, it will turn out to be important, given a term t of Q, to keep track of the bag of T in which the term π(t) appeared first. We note πtT (t) = (B, π(t)) when the term π(t) appears first in the bag B of T . Similar to above, πtT gives rise to a partitioning of the terms of Q into term bags Bagst(Q) = {Qt1, . . . , Qtm}, where two terms u and v of Q are in the same term bag Qti if and only if there exists a bag B with π t T (u) = (B, π(u)) and πtT (v) = (B, π(v)). From πaT and π t T , we then obtain the function πT mapping elements of Bags\na(Q) ∪ Bagst(Q) to bags of T such that\nπT = { Qa 7→ B where πaT (a) = (B, π(a)) for any a ∈ Qa Qt 7→ B′ where πtT (a) = (B′, π(t)) for any t ∈ Qt\nWe can now define the atom-term bags of Q (induced by πaT ) denoted by Bags at(Q). If an atom bag Qa and a term bag Qt have the same image under πT , we obtain an atom-term bag Qat = Qa ∪Qt. If an atom bag Qa (or a term bag Qt) has an image different from the image of any other term bag (or atom bag, respectively) of Q, then it is an atom-term bag by itself.\nFinally, we provide these atom-term bags with a tree structure induced by the tree structure of T . Let Qat1 and Qat2 be two atom-term bags of Q. Then Qat2 is a child of Qat1 iff (i) πT (Q at 2 ) is a descendant of of πT (Q at 1 ) and (ii) there is no atom-term bag Q at 3 of Q such that πT (Q at 3 ) is a descendant of of πT (Q at 1 ) and πT (Q at 2 ) is a descendant of of πT (Q at 3 ). Note that since we only consider connected queries, the structure so created is indeed a tree (it could be a forest with disconnected queries). In what follows, we define an atom-term tree decomposition of a query by such a tree of atom-term bags, independently from T and π.\nDefinition 34 (APT of a Query). Let Q be a query. An atom-term partition of Q is a partition of atoms(Q) ∪ terms(Q) (these sets being called atom-term bags). An atom-term partition tree (APT) of Q is a tree whose nodes form an atom-term partition of Q.\nFigure 10 represents an APT of the example query Qi.\nDefinition 35 ((Valid) APT-Mapping). Let Q be an APT of Q. Let T be a derivation tree. An APT-mapping of Q to T is a tuple Γ = (Π, π1, . . . , πk) where Π is an injective mapping from the atom-term bags of Q to the bags of T and, for each atom-term bag Qati of Q, πi is a substitution from the terms of Qati (by this, we mean the terms of Qati , not the terms appearing in the atoms of Qati ) to the terms that were created in the atoms of Π(Q at i ).\nRemark that if u is a term of Q, then u appears in only one atom-term bag Qati of Q. We can thus define πΓ = ⋃ 1≤i≤k πi.\nFinally, we say that (Π, π1, . . . , πk) is valid when πΓ is a homomorphism from Q to the atoms of T .\nExample 18 (APT-Mapping). We now present a valid APT-Mapping of the APT pictured Figure 10 to the derivation tree represented in Figure 9. We let Π = {Qat0 7→B0, Qat1 7→B4, Qat2 7→B5, Qat3 7→B6, Qat4 7→B7, Qat5 7→B1}. The corresponding mappings are: π0 = {x 7→c}, π1 = {y 7→z1}, π2 = {z 7→z2}, π3 = {t 7→z3}, π4 = {u7→z4}, and π5 = {v 7→y1}. Then, (Π, π1, π2, π3, π4, π5) is a valid APT-mapping of the APT from Figure 10 to the derivation tree from Figure 9.\nProperty 23 (Soundness and Completeness). Let F be a fact, R be a set of gbts rules, and Q be a query. Then F,R |= Q if and only if there exists a derivation sequence S from F to Fk, an APT Q of Q, and a valid APT-mapping from Q to DT (S).\nProof. We successively prove both directions of the equivalence.\n(⇐) Let us suppose that there exists a valid APT-mapping from Q to DT (S). From Definition 35, it follows that there is a homomorphism π from Q to the atoms of DT (S), i.e. a homomorphism π from Q to Fk.\n(⇒) If F,R |= Q, then there is a homomorphism π from Q to some Fk obtained by means of a derivation S from F . As in the construction given before Definition 34, we can choose some mapping πaT of the atoms of Q, and build from this mapping an APT Q of Q. We can then build an APT-mapping (Π, π1, . . . , πk) as follows: Π = πT , and for each Qati of Q, πi is the restriction of π to the terms of Qati . This APT-mapping is valid.\nThis rather long and unnecessarily complicated way to prove the existence of a homomorphism will now be put to good use when querying the full blocked tree, without resorting to its potentially infinite development."
    }, {
      "heading" : "4.5.2 Validation of an APT in a blocked tree",
      "text" : "Hence, let us now consider a blocked tree Tb and some tree (T, f) ∈ G(Tb) generated by it. Let us assume that we have an APT Q of a query Q that corresponds to a mapping to (T, f). Thus, each bag Qati of the APT is mapped to a bag B of T. Intuitively, we represent this mapping on the full blocked tree by mapping Qati to Brep such that Brep = f(B) (i.e., B has been generated by copying Brep). We can enumerate all such mappings: the question is then to validate such a mapping, that is, to check that it actually corresponds to a valid APT-mapping in a tree generated by the full blocked tree.\nDefinition 36 (Valid APT Mapping to a Blocked Tree). Let Q be an APT of a query Q and Γ = (Π, π1, . . . , πk) be an APT-mapping from Q to a blocked tree Tb (where Π maps atom-term bags of Q to bags of the blocked tree). Then Γ is said to be valid if there exists a tree (T, f) ∈ G(Tb) generated from Tb and a mapping Ξ from the atom-term bags of Q to the bags of (T, f) (we then call ((T, f),Ξ) a proof of Γ) such that:\n• if Qat is the root of Q, then Ξ(Qat) = Π(Qat);\n• if Qat′ is a child of Qat in Q, then f(Ξ(Qat′)) = Π(Qat′) and Ξ(Qat′) is a descendant of Ξ(Qat);\n• The ADT mapping (Ξ, π′1, . . . , π′k) is valid in T, where for every atom-term bag Qatj in Q with Ξ(Qatj ) = Bi, we define π′j = ψf(Bi)→Bi ◦ πj.\nExample 19 (APT-Mapping to a Blocked Tree). We now present a valid APT-Mapping of the APT represented Figure 10 to the derivation tree represented in Figure 9. We define Π = {Qat0 7→B0, Qat1 7→B4, Qat2 7→B5, Qat3 7→B6, Qat4 7→B3, Qat5 7→B1}. Here, the only difference with the previous APT-mapping is the image of Qat4 , which is not B7 (which does not exist in the blocked tree), but B3. This is reflected in the definition of the πi: π0 = {x 7→c}, π1 = {y 7→z1}, π2 = {z 7→z2}, π3 = {t7→z3}, π4 = {u7→y2}, and π5 = {v 7→y1}. Then, (Π, π1, π2, π3, π4, π5) is a valid APT-mapping of the APT from Figure 10 to the blocked tree from Figure 8, as witnessed by the derivation tree of Figure 9, where the bag B7 has been generated by B3.\nProperty 24 (Soundness and Completeness). Let F be a fact, R be a set of gbts rules, and Q be a query. Then F,R |= Q if and only if there exists an APT Q of Q, and a valid APT-mapping from Q to the full blocked tree of F and R.\nProof. We successively prove both directions of the equivalence.\n(⇐) Let us suppose that there exists a valid APT-mapping from Q to the full blocked tree Tb of F and R. From Definition 36, there exists a valid APT mapping from Q to a (T, f) generated from Tb, i.e., by Definition 22 a valid APT-mapping from Q to some derivation tree T having T as a prefix. We can conclude thanks to Property 23.\n(⇒) If F,R |= Q, then there is a homomorphism π from Q to some Fk obtained by means of a derivation S from F with derivation tree T = DT (S). As in the construction given before Definition 34, we can chose some mapping πaT of the atoms of Q, and build from this mapping an APT Q of Q. Now, in this particular π, the root of Q can be mapped to any bag B of the derivation tree DT (S). Since B has an equivalent bag B′ in the full blocked tree Tb, there exists another homomorphism π\n′ from Q to some F ′k obtained by means of a derivation S\n′. Let us recompute an APT Q′ (the same result might be obtained). Then (see proof of Property 23), there is a valid APT mapping Γ = (Π, π1, . . . , πk) from Q′ to DT (S′), since DT (S) is a prefix tree of some T generated from Tb. Γ is thus a valid APT mapping from Q to T. Now let us define the mapping Ξ as follows: if Qat is the root of Q, then Ξ(Qat) = Π(Qat), otherwise Ξ(Qat) = f(Π(Qat)). For each term t in the atom term bag Qati of Q such that Ξ(Qati ) = Bj , we define π′i(t) = ψBj→f(Bj) ◦ πi. Let us consider the APT mapping Γ′ = (Ξ, π′1, . . . , π ′ k) from Q to Tb. It is immediate to check that Γ′ is valid."
    }, {
      "heading" : "4.5.3 A bounded validation for APT-mappings",
      "text" : "Although Property 24 brings us closer to our goal to obtain an algorithm for gbts deduction, there is still the need to guess the generated tree (T, f) used to validate an APT-mapping (Definition 36). We will now show that such a generated tree can be built in a backtrackfree manner by an exploration of the APT of the query. Then we establish an upper bound for each validation step (i.e., if we have validated an initial segment Q′ of the APT Q of Q, and Qat ′ is a child of some bag Qat in Q′, how do we validate Q′ ∪ {Qat′}?).\nProperty 25. Let Q be an APT of Q, and Γ be a valid APT-mapping from Q to a blocked tree Tb. Let Q′ be a prefix tree of Q, and Γ′ be the restriction of Γ to Q′. Note that Γ′ is a valid APT-mapping from Q′ to Tb.\nConsider now any proof ((T′, f ′),Ξ′) of Γ′ (see Definition 36).9 Then, there exists a proof ((T′′, f ′′),Ξ′′) of Γ such that ((T′, f ′),Ξ′) is a subproof of ((T′′, f ′′),Ξ′′).\nProof. Let us consider a proof ((T′, f ′),Ξ′) of Γ′. As shown in the proof of Property 24, this proof corresponds to a homomorphism π′ of Q′ to (T′, f ′). Now consider any leaf bag Qat ′ of Q′, that is the root of a tree in Q. Γ and Γ′ can map Qat′ to different bags in (T′, f ′) and (T, f). However, these bags are equivalent (according to Definition 18) to the same bag in Tb. So anything that can be mapped under one of these bags can be mapped in the same way under the other. In particular, the subtree rooted in Qat ′ can be mapped in the same way under the bag of (T′, f ′). This construction leads to a homomorphism π′′ from Q to some (T′′, f ′′) that extends π′. Using again the proof of Property 24, this homomorphism can be used to build a proof ((T′′, f ′′),Ξ′′) of Γ, that is a superproof of ((T′, f ′),Ξ′).\nThis latter property provides us with a backtrack-free algorithm for checking the validity of an APT-mapping. Basically, Algorithm 2 performs a traversal of the APT Q, while verifying whether Γ “correctly joins” each bag of Q with its already “correctly joined” parent.\n9. Note that this proof ((T′, f ′),Ξ′) is not necessarily a subproof of the existing proof ((T, f),Ξ) of Γ (i.e., (T′, f ′) is not necessarily an initial segment of (T, f) and Ξ′ is not necessarily the restriction of Ξ).\nAlgorithm 2: ValidateAPT\nData: A blocked tree Tb, an APT Q, and an APT-mapping Γ from Q to Tb. Result: yes if Γ is valid, no otherwise. Explored := ∅; for i = 1 to |Q| do\nQat := some bag of Q s.t. either (parent(Qat),−) ∈ Explored, or Qat is the root of Q; if joins(Γ, Qat) 6= ∅ then\nExplored := Explored ∪{(Qat, joins(Γ, Qat))}; else\nreturn no;\nreturn yes;\nIt remains now to explain the procedure joins that checks whether a valid APT-mapping of a subtree Q′ of Q can be extended to a child Qat ∈ Q \\ Q′ of some bag of Q′. Let us consider a proof ((T′, f ′),Ξ′) of Γ = (Π, π1, . . . , πk) being a valid APT-mapping of Q′. According to Def. 36 and Prop. 24, it is sufficient to:\n• find a bag Bn that can be obtained by a bag copy sequence B1, . . . , Bn where B1 = Ξ′(parent(Qat)), Bn is a bag equivalent to Π(Q\nat), and for 1 < i ≤ n, Bi is obtained by a bag copy (see Definition 20) under Bi−1. Since Π(Q\nat) and Bn are equivalent, there is a bijection from the terms of Π(Qat) to the terms of Bn, that we denote by ψ.\n• it remains now to check that for every term t appearing in an atom of Qat, t is a term that belongs to a bag Qat ′ in the branch from the root of Q to Qat, and Ξ′(t) = ψ(π(t))\n(where π is the mapping defined in the APT-mapping from the terms of Qat to those of Π(Qat)). In that case, the call to joins returns ψ ◦ π, ensuring that we are able to evaluate the joins of the next bags.\nWe last prove that there exists a “short” proof of every valid APT-mapping.\nProperty 26. Let Q be an APT of Q, and Γ be a valid APT-mapping from Q to a blocked tree Tb. There exists a proof ((T, f),Ξ) of Γ such that for any two bags Q at i and Q at j from Q where Qati is a child of Q at j , the distance between Ξ(Qati) and Ξ(Qatj) in T is at most p×ff , where p is the number of abstract patterns, and f the maximum size of a rule frontier.\nProof. We prove the result by induction on the number of atom-term bags in Q. If Q has only one atom-term bag, the property is trivially true. Let us assume the result to be true for any APT-mapping whose APT is of size n, and let Q be a APT of size n+ 1, and Γ be a valid APT-mapping of Q. Let Qatc be an arbitrary leaf of Q, let Q′ be equal to Q\\ {Qc}, and let Γ′ be the restriction of Γ to Q′. By induction assumption, there exists a proof ((T′, f ′),Ξ′) of Γ′ fulfilling the claimed property. By the proof of Property 25, this proof can be extended to a proof ((T, f),Ξ), such that Qatc is mapped to a descendant of Ξ(Q at p ), where Qatp is the parent of Q at c in Q. Moreover, the provided construction allows to ensure\nthat there are no two distinct bags Bi and Bj on the path from Ξ(Q at p ) to Ξ(Q at c ) fulfilling the following two conditions:\n• f(Bi) = f(Bj);\n• ∀x ∈ Xs, ψBi→f(Bi)(x) = ψBj→f(Bj)(x), where Xs is the image of the set of variables that appear both in Qatc and Q′.\nThen the distance between Ξ(Qatp ) and Ξ(Q at c ) has to be less than p×ff . Indeed, Xs should belong to the frontier of Ξ(Qatc ), by the running intersection property of T. There is at most ff ways of arranging these terms, thus providing the claimed upper-bound."
    }, {
      "heading" : "4.6 Complexity Analysis and Worst-Case Optimal Adaptation to Subclasses",
      "text" : "We provide a worst-case complexity analysis of the proposed algorithm, and present some small modifications that can be adopted in order to make the algorithm worst-case optimal for relevant subclasses of rules. Table 3 provides a summary of the notation used for the complexity analysis."
    }, {
      "heading" : "4.6.1 Complexity of the algorithm",
      "text" : "The overall algorithm deciding whether F,R |= Q can now be sketched as follows:\n• build the full blocked tree Tb of (F,R) (note that this is done independently of the query)\n• for every APT Q of Q, for every APT-mapping Γ of Q to Tb, if ValidateAPT returns yes, return yes (and return no at the end otherwise).\nThe first step is done linearly in the number of evolution and creation rules. There are at most p2 evolution rules, and p2 × bf creation rules. We thus need to upper-bound the number of abstract patterns. There are at most |R| × 2aB subsets of rule bodies, and btB\nmappings from terms of a rule body to terms of a bag. An abstract pattern being a subset of the cartesian product of these two sets, the number of abstract patterns is upper-bounded by\n2|R|×2 aB×btB .\nThe first step is thus done in double exponential time, which drops to a single exponential when the set of rules is fixed. Note that only this first step is needed in the first version of the algorithm, where the query was considered as a rule, which yields the proof of Theorem 22.\nThe second step can be done in NQ ×NΓ ×NV where:\n• NQ is the number of APTs of a query Q of size q, and NQ = O(qq) (the number of partitions on the atoms and terms of Q, times the number of trees that can be built on each of these partitions);\n• NΓ is the number of APT mappings from one APT (of size q) to the full blocked tree. The size of the full blocked tree is O(pbf ) and thus NΓ = O(pq × bfq);\n• NV is the cost of Algorithm 2 that evaluates the validity of the APT. It performs at most q joins, and each one generates at most O(p× ff ) bags (see Property 26).\nThe second step of our algorithm thus operates in O(qq × pq × bfq × q × p× ff ). The querying part is thus polynomial in p (the number of patterns), and simply exponential in q and in f . Since p is in the worst-case double exponential w.r.t. F and R, the algorithm runs in 2ExpTime. Last, given a (nondeterministically guessed) proof of Γ, we can check in polynomial time (if R and F are fixed) that it is indeed a valid one, yielding:\nTheorem 27. CQ entailment for gbts is NP-complete for query complexity.\nThereby, the lower bound comes from the well-known NP-complete query complexity of plain (i.e., rule-free) CQ entailment."
    }, {
      "heading" : "4.6.2 Adaptation to relevant subclasses",
      "text" : "We now show how to adapt the algorithm to the subclasses of gbts that have smaller worstcase complexities. This is done by slightly modifying the construction of the full blocked tree, allowing its size to be simply exponential or even polynomial with respect to the relevant parameters. We consider three cases:\n• (weakly) guarded rules, whose combined complexity in the bounded arity case drops to ExpTime,\n• guarded frontier-one rules, whose combined complexity in the unbounded arity case drops to ExpTime,\n• guarded, frontier-guarded and frontier-1 rules, whose data complexity drops down to PTime.\nFor weakly guarded rules, we change the definition of pattern. Indeed, with this kind of rules, a rule application necessarily maps all the terms of a rule body to terms occurring in a single bag. This holds since every initial term belongs to every bag, and every variable of the rule body that could map to an existentially quantified variable is argument of the guard of the body of the rule. Thus, by storing all the possible mappings of a rule body atom (instead of all partial homomorphisms of a subset of a rule body), we are able to construct any homomorphism from a rule body to the current fact. The equivalence between patterns and the blocking procedure remains unchanged. Since there are at most bw such homomorphisms for an atom, the number of abstract patterns is bounded by 2b w , which is a simple exponential since w is bounded. The algorithm thus runs in exponential time for weakly guarded rules with bounded arity.\nIf we consider only guarded frontier-one rules, the number of possible homomorphisms decreases. Indeed, the set of atoms whose terms are included in a given bag is upper-bounded by aH + s.tH : the atoms that have been created at the creation of the bag, plus atoms that may be created afterwards. However, these atoms must be of the from r(x, . . . , x), since the considered rules are frontier-one, hence at most s.tH . This results in a simply exponential number of patterns, which provides the claimed upper-bound.\nFor frontier-guarded rules (and its subclasses), we slightly modify the construction of the decomposition tree. Indeed, in the original construction, every term of the initial fact is put in every bag of the decomposition tree. However, by putting only the constants appearing in a rule head as well as every instantiation of terms of the head of the rule creating the bag (that is, we do not put all initial terms in every bag), a correct tree decomposition would also be built, and the size of the bags (except for the root) would not be dependent of the initial fact any more. The number of patterns is then upper-bounded by 1 + 2|R|×2 aB×ttBH . When R is fixed, this number is polynomial in the data. Given that Q is fixed, we get the PTime upper-bound.\n5. Matching Lower Complexity Bounds for gbts Subclasses We now provide the missing hardness results to fully substantiate all complexity results displayed in Figure 1 and Table 1.\n5.1 Data Complexity of Guarded Frontier-One Rules is PTime-hard\nPTime hardness for gfr1 rules is not hard to establish and follows from known results (for instance, the description logic EL is subsumed by gfr1 rules and known to have PTime-hard data complexity). For the sake of self-containedness, we will give a direct reduction from one of the prototypical PTime problems: entailment in propositional Horn logic.\nTheorem 28. CQ entailment under constant-free gfr1 rules is PTime-hard for data complexity.\nProof. Given a set H of propositional Horn clauses, we introduce for every propositional atom a occurring therein a constant ca. We also introduce one additional constant nil . Moreover, for every Horn clause C ∈ H with C = a1 ∧ . . .∧ an → a, we introduce constants bC,1, . . . , bC,n and let F consist of entails(bC,1, ca), first(bC,i, cai) for all i ∈ {1, . . . , n}, as\nwell as rest(bC,n,nil), and rest(bC,i, bC,i+1) for all i ∈ {1, . . . , n − 1}, also let F contain entailed(nil). Then the propositional atom a is entailed by H exactly if F,R |= Q with Q = entailed(ca) and R containing the rules:\nfirst(y, z) ∧ entailed(z) ∧ rest(y, z′) ∧ entailed(z′) → entailed(y), entailed(y) ∧ entails(y, z) → entailed(z).\n5.2 Combined Complexity of Guarded Frontier-One Rules is ExpTime-hard\nWe prove ExpTime-hardness of CQ entailment under gfr1 rules by showing that any standard reasoning task in the description logic Role-Bounded Horn-ALC, for which ExpTimehardness is known (Krötzsch, Rudolph, & Hitzler, 2007, 2013), can be polynomially reduced to the considered problem.\nWe start by defining this problem. In order to avoid syntactic overload, we will stick to first-order logic syntax and refrain from using the traditional description-logic-style notation.\nDefinition 37 (Role-Bounded Horn-ALC). Let Pr1 an infinite set of unary predicates and let Pr2 be a finite set of binary predicates. A reduced normalized Horn-ALC[Pr2] terminology T is a set of rules having one of the following shapes (with p1, p2, p3 ∈ Pr1 and r ∈ Pr2):\n(A) p1(x)→ p2(x)\n(B) p1(x) ∧ p2(x)→ p3(x)\n(C) r(x, y) ∧ p1(y)→ p2(x)\n(D) p1(x) ∧ r(x, y)→ p2(y)\n(E) p1(x)→ ∃y.(r(x, y) ∧ p2(y))\nWe refer to the problem of deciding if for some T and p1, p2 ∈ Pr1 holds T |= ∀x(p1(x) → p2(x)) as unary subsumption checking.\nTheorem 29 ((Krötzsch et al., 2013), Section 6.2.). There is a finite set Pr2 such that unary subsumption checking for reduced normalized Horn-ALC[Pr2] terminologies is ExpTimehard.\nThe following corollary is now a straightforward consequence.\nCorollary 30. CQ entailment under constant-free gfr1 rules is ExpTime-hard for combined complexity.\nProof. Clearly, given a reduced normalized Horn-ALC[Pr2] terminology T and p1, p2 ∈ Pr1, the unary subsumption entailment T |= ∀x(p1(x)→ p2(x)) is to be confirmed if and only if F,R |= Q with F = {p1(a)}, R = T and Q = p2(a). The latter can be conceived as a CQ entailment problem of the desired type, since T is a gfr1 rule set.\nNote that our line of argumentation actually does not require the set Pr2 to be fixed, however, this will be a necessary precondition in the next section where we use the same logic, hence we have introduced the logic in this form from the beginning.\n5.3 Data Complexity of Weakly Guarded Frontier-One Rules is ExpTime-hard\nWe will now show that the data complexity for deciding CQ entailment under wgfr1 rules is ExpTime-hard. Again, we obtain the result by showing that a Horn-ALC[Pr2] reasoning problem can be reduced to CQ entailment under wgfr1 rules but this time even with fixed rule set and query.\nDefinition 38. Given a set Pr2, let Rfix be the fixed wgfr1 rule set containing the following rules (where r ranges over all elements of Pr2):\n1. typeA(z1, z2) ∧ in(x, z1)→ in(x, z2)\n2. typeB(z1, z2, z3) ∧ in(x, z1) ∧ in(x, z2)→ in(x, z3)\n3. typeC r(z1, z2) ∧ r(x, y) ∧ in(y, z1)→ in(x, z2)\n4. typeDr(z1, z2) ∧ in(x, z1) ∧ r(x, y)→ in(y, z2)\n5. typeE r(z1, z2) ∧ in(x, z1)→ r(x, y) ∧ in(y, z2)\n6. test(x) ∧ sub(z)→ in(x, z)\n7. test(x) ∧ in(x, z) ∧ super(z)→ match\nGiven a reduced normalized Horn-ALC[Pr2] terminology T , we let FT be the fact containing\n1. typeA(cp1 , cp2) for any R = p1(x)→p2(x) from T ,\n2. typeB(cp1 , cp2 , cp3) for any R = p1(x)∧p2(x)→p3(x) from T ,\n3. typeC r(cp1 , cp2) for any R = r(x, y)∧p1(y)→p2(x) from T ,\n4. typeDr(cp1 , cp2) for any R = p1(x)∧r(x, y)→p2(y) from T , and\n5. typeE r(cp1 , cp2) for any R = p1(x)→∃y.(r(x, y)∧p2(y)) from T .\nAlso, for p1, p2 ∈ Pr1, we let Fp1p2 = {test(a), sub(cp1), super(cp2)}\nThe following property now lists two straightforward observations.\nProperty 31. Rfix is a wgfr1 rule set. FT can be computed in polynomial time and is of polynomial size with respect to T .\nThe next lemma establishes that subsumption in Horn-ALC[Pr2] can be reduced to CQ entailment w.r.t. a fixed wgfr1 rule set.\nLemma 32. Let T be a reduced normalized Horn-ALC[Pr2] terminology and let p1, p2 ∈ Pr1. Then T |= ∀x(p1(x)→ p2(x)) if and only if FT ∪ Fp1p2 ,Rfix |= match.\nProof. We successively prove both directions of the equivalence.\n⇒ Assume to the contrary that FT ∪ Fp1p2 ,Rfix |= match does not hold, thus we find a model of FT ∪ Fp1p2 ,Rfix where match is false. We then can use this model to construct a model of T not satisfying ∀x(p1(x)→ p2(x)) using the following defining equation for every pi ∈ Pr1:\n∀x(pi(x)↔ in(x, cpi)).\nIt can be readily checked that this model indeed satisfies T . Moreover it satisfies p1(a) but not p2(a), therefore ∀x(p1(x)→ p2(x)) does not hold.\n⇐ Assume to the contrary that T |= ∀x(p1(x) → p2(x)) does not hold, i.e. we find a model of T not satisfying ∀x(p1(x) → p2(x)) (i.e., in this model there must be one element e in the extension of p1 but not of p2). We now use this model to define a model of FT ∪Fp1p2 ,Rfix by adding to the domain a new element cpi for every pi ∈ Pr1 and let the interpretation function on the eponymous constants be the identity. The interpretation of the predicates typeA, . . . , typeE is as explicitly stated in FT , the interpretation of the in predicate is defined as the minimal set such that\n∀x(pi(x)↔ in(x, cpi))\nholds for all pi ∈ Pr1. Finally, we let sub hold for cp1 , we let super hold for cp2 , and we let test hold for a, where the constant a is mapped to the domain element e mentioned above. Then it can be easily checked that the obtained model satisfies all of FT ∪ Fp1p2 ,Rfix but not match.\nTheorem 33 (Data Complexity of wgfr1 Rules). BCQ-Entailment under constant-free wgfr1 rules is ExpTime-hard for data complexity.\nProof. By Theorem 29, unary subsumption checking for reduced normalized Horn-ALC[Pr2] terminologies is ExpTime-hard. By Lemma 32 and thanks to Proposition 31, any such problem can be polynomially reduced to a CQ entailment problem F,R |= q for uniform R and q. Consequently, the data complexity of conjunctive query entailment under wgfr1 rules must be ExpTime-hard as well.\n5.4 Combined Complexity of Frontier-One Rules is 2ExpTime-hard\nIn this section, we show that fr1 rules are 2ExpTime-hard for combined complexity no matter whether predicate arity is bounded or not. Our proof reuses the general strategy and many technical tricks from a construction used to show 2ExpTime-hardness for CQ entailment in the DLALCI from (Lutz, 2007). Still, many adaptations were done in order to make the construction fit our language fragment and to simplify unnecessarily complicated parts.\nWe prove the desired result via a reduction of CQ entailment w.r.t. fr1 rules to the word problem of an alternating Turing machine with exponential space, which will be formally introduced next.\nDefinition 39. An alternating Turing machineM, short ATM, is a quadruple (Q,Γ, q0,∆) where:\n• Q is the set of states10, which can be partitioned into existential states Q∃ and universal states Q∀.\n• Γ is a finite alphabet, containing the blank symbol ,\n• q0 ∈ Q is the initial state,\n• ∆ ⊆ Q× Σ×Q× Σ× {L,R} is the transition relation.\nA configuration of an ATM is a word wqw′ where w,w′ ∈ Γ∗ and q ∈ Q. The successor configurations ∆(wqw′) of a configuration wqw′ are defined as:\n∆(wqw′) = {vq′γ′′γ′v′ | w = vγ′′, w′ = γv′, (γ, q, γ′, q′, L) ∈ ∆} ∪ {wγ′q′v′ | w′ = γv′, (γ, q, γ′, q′, R) ∈ ∆} ∪ {wγ′q′ | w′ = , ( , q, γ′, q′, R) ∈ ∆}.\nThe set of indirect successors of a configuration wqw′ is the smallest set of configurations that contains wqw′ and that is closed under the successor relation.\nA halting configuration is of the form wqw′ with ∆(wqw′) = ∅. The set of accepting configurations is the smallest set of configurations such that:\n• wqw′ is accepting if there exists vq′v′ ∈ ∆(wqw′) is accepting in case of q ∈ Q∃,\n• wqw′ is accepting if all vq′v′ ∈ ∆(wqw′) are accepting in case of q ∈ Q∀.\nAn ATM is said to accept a word w ∈ Γ∗, if q0w is accepting. An ATM is exponentially space bounded if for any w ∈ Γ∗, every indirect successor\nvqv′ of q0w satisfies that |vv′| < 2|w|.\nAccording to (Chandra, Kozen, & Stockmeyer, 1981b), there is an exponentially space bounded ATM M∗, whose word problem is 2ExpTime-hard. In order to simplify our argument, we will, however, not directly simulate a run of this Turing machine on a word w. Rather, given M∗ and a word w it is straightforward to construct an ATM M∗w such that M∗ accepts w exactly if M∗w accepts the empty word .11 Clearly, the size of M∗w is polynomially bounded by n = |w|.\nIn the following, we will thus show how, given an exponentially space bounded ATM M and a word w, we can construct a fact F , rule set R and query Q – the size of all being polynomially bounded by n – such that F,R |= q iff M∗w = (Q,Γ, q0,∆) accepts the empty word. Thereby, the minimal model of F and R will contain elements representing the initial and all its (indirect) successor configurations. These configurations will themselves be endowed with a tree structure that stores the content of the exponentially bounded\n10. Q (with possible subscripts) is used for state sets in order to avoid a notational clash with conjunctive queries denoted by Q. 11. Such a machine can be easily obtained: add new states and transitions that first write w to the tape, second go back to the starting position, and third switch to the initial state of the original Turing machine.\nmemory. The most intricate task to be solved will be to model memory preservation from one configuration to its successors.\nWe start by introducing some predicates and their intuitive meaning:\n• conf : unary predicate to distinguish elements representing configurations from other elements;\n• firstconf : unary predicate to denote the initial configuration;\n• transδ with δ ∈ ∆: set of binary predicates. transδ connects a configuration with its successor configuration that was introduced due to δ;\n• stateq with q ∈ Q: set of unary predicates indicating the state of the configuration wqw′;\n• symbolγ with γ ∈ Γ: set of unary predicates indicating the symbol at the heads current position, i.e. symbolγ holds for the configuration wqγw ′;\n• accepting : unary predicate indicating if a configuration is accepting;\n• wire binary predicate used later for memory operations;\n• fw unary predicate used later for memory operations.\nWe are now ready to provide first constituents of the fact F and of the rule set R. We let F contain the facts:\n{conf (init),firstconf (init), stateq0(init)}. (1)\nFor every δ = (q, γ, q′, γ′, D) ∈ ∆ (with D ∈ {L,R}), let R contain:\nstateq(x)∧symbolγ(x)→ transδ(x, y)∧wire(x, u)∧fw(u)∧wire(u, v)∧fw(v)∧wire(v, y) (2) transδ(x, y)→ conf (y)∧stateq′(y) (3)\nClearly, by means of these rules, we create the successor configurations y reached from a transition predicate from given configuration x. The additionally introduced sequence “ wire−→ u wire−→ v wire−→” between x and y will come handy later for memory preservation purposes. Figure 11 displays the structure of the configuration tree thus constructed.\nNext we take care of the implementation of the acceptance condition for configurations. For every q ∈ Q∃ and every δ = (q, γ, q′, γ′, D) ∈ ∆, we add the rule:\ntransδ(x, y) ∧ accept(y)→ accept(x). (4)\nFor every q ∈ Q∀ and γ ∈ Γ, we add the rule:\n∧ δ=(q,γ,q′,γ′,D)∈∆ transδ(x, yδ) ∧ accept(yδ)→ accept(x). (5)\nThis way, as required, acceptance is propagated backward from successors to predecessors.\nConsequently, the query to be posed against the “computation structure” described by our rule set should ask if the initial configuration is accepting, i.e.:\nQ = accept(init). (6)\nNext, we prepare the implementation of the memory access. To this end, we encode the position of the head (that is, the length of the word w) in a configuration wqw′ as an n-digit binary number (note that this allows us to address 2n positions which is sufficient for the required exponential memory). We will use unary predicates hbitk, lbitk with 1 ≤ k ≤ n for the following purpose: hbitk holds for an element representing a configuration wqw\n′, if the kth bit of the configuration’s head position (i.e. the number |w|) expressed in binary format is 1. If the bit is 0, then lbitk holds instead.\nClearly, the initial position of the head is 0 (as we start from configuration q0w), thus for the initial configuration (represented by init) all bits must be 0. Hence we let FM,w contain lbitk(init) for all 1 ≤ k ≤ n.\nIn the course of a state transition δ = (q, γ, q′, γ′, D) ∈ ∆, the head’s position may be increased by one (in case D = R) or decreased by 1 (in case D = L). The next rules implement this behavior, hence given a configuration’s head position, they effectively compute the head position of this configuration’s direct successors. For every δ = (q, γ, q′, γ′, D) ∈ ∆\nwith D = R we let RM,w contain the rules (where k ranges from 1 to n and m ranges from 1 to k):\ntransδ(x, y) ∧ ∧ l≤k hbitl(x) → lbitk(y) (7)\ntransδ(x, y) ∧ lbitk(x) ∧ ∧ l<k hbitl(x) → hbitk(y) (8)\ntransδ(x, y) ∧ lbitk(x) ∧ lbitm(x) → lbitk(y) (9) transδ(x, y) ∧ hbitk(x) ∧ lbitm(x) → hbitk(y) (10)\nand for every δ = (q, γ, q′, γ′, D) ∈ ∆ with D = L we let RM,w contain the rules (ranges of k and m as above):\ntransδ(x, y) ∧ ∧ l≤k lbitl(x) → hbitk(y) (11)\ntransδ(x, y) ∧ hbitk(x) ∧ ∧ l<k lbitl(x) → lbitk(y) (12)\ntransδ(x, y) ∧ hbitk(x) ∧ hbitm(x) → hbitk(y) (13) transδ(x, y) ∧ lbitk(x) ∧ hbitm(x) → lbitk(y) (14)\nIn the next steps, we need to implement the exponential size memory of our Turing machine. At the same time, the memory should be “accessible” by polynomial size rule bodies. Thus we organize the memory as a binary tree of polynomial depth having exponentially (that is 2n) many leaves. Thus, for every configuration element, we create a tree of depth n having the configuration element as root and where the configuration’s tape content is stored in the leaves. We use the following vocabulary:\n• levelk with 0 ≤ k ≤ n: set of unary predicates stating for each node inside the memory tree its depth.\n• leftchild , rightchild : the two (binary) child predicates of the memory tree.\n• child : a (binary) predicate subsuming the two above.\n• entryγ with γ ∈ Γ: set of unary predicates indicating for every leaf of the memory tree the symbol stored there.\nWe now create the memory tree level by level (with k ranging from 1 to n):\nconf (x) → level0(x) (15) levelk−1(x) → leftchild(x, y) ∧ child(x, y) ∧ wired(x, y) ∧ wired(y, x) ∧ levelk(y) (16) levelk−1(x) → rightchild(x, y) ∧ child(x, y) ∧ wired(x, y) ∧ wired(y, x) ∧ levelk(y)(17)\n(18)\nThe leaf nodes of the memory tree thus created (i.e., the elements satisfying leveln) will be made to carry two types of information: (a) the current symbol stored in the corresponding tape cell and (b) the tape cell’s “address” in binary encoding. The latter will be realized as follows: if the kth bit of the binary representation of the address is clear, the leaf node ν will be extended by a structure containing two newly introduced elements ν1 and ν2 which will be connected with ν via the following binary predicates: startk(ν, ν), wired(ν, ν1), wired(ν1, ν2), and endk(ν2, ν). In case the kth bit is set, we will also introduce new elements ν1 and ν2 but they will be connected with ν in a different way, namely: startk(ν, ν1), wired(ν1, ν), wired(ν, ν2), and endk(ν2, ν). The reason for this peculiar way of encoding the address information will become apparent in the sequel. Figure 12 depicts the structure of the memory tree constructed under each configuration tree.\nThe following rules realize the aforementioned address representation, exploiting the fact that the kth address bit will be 0 if the considered leaf node’s ancestor on level k − 1 is connected with the ancestor on level k via leftchild and it will be 0 if the connection is via rightchild . Hence we let RM,w contain the rules (with k ranging from 1 to n as above):\nleftchild(xk−1, xk) ∧ ∧n i=k+1(child(xi−1, xi)) ∧ leveln(xn) →\nstartk(xn, xn) ∧ wired(xn, x′n) ∧ wired(x′n, x′′n) ∧ endk(x′′n, xn) (19) rightchild(xk−1, xk) ∧ ∧n i=k+1(child(xi−1, xi)) ∧ leveln(xn) →\nstartk(xn, x ′ n) ∧ wired(x′n, xn) ∧ wired(xn, x′′n) ∧ endk(x′′n, xn)\n(20)\nOne of the purposes of the previous construction is to mark in each memory tree the leaf corresponding to the current head position by a unary predicate head and all other leaves by another unary predicate nohead . To this end, we encode the head position stored in the configuration elements via the predicates lbitk and hbitk in a “structural way”, similar to our encoding in the leaves:\nlbitk(x) → rootstartk(x, x) (21) hbitk(x) → rootstartk(x, x′) ∧ wired(x′, x) (22)\nFor the assignment of head and nohead to leaf nodes, we now exploit two facts. First, the kth bit of the head address – stored in a configuration element νc – and the kth bit of the address of a leaf node νl of the same configuration element coincide, if there are nodes ν1, . . . , νn−1 such that there is a path\nνc rootstartk−→ ν1 wired−→ . . . wired−→ νn−1 endk−→ νl;\nmoreover, no other two nodes are connected by such a path. Secondly, the kth bit of the two nodes differ if there are nodes ν1, . . . , νn such that there is a path\nνc rootstartk−→ ν1 wired−→ . . . wired−→ νn endk−→ νl;\nmoreover, no other two nodes are connected by such a path (to see this, note that wired goes both ways inside the tree whence it is possible to make a back-and-forth step where necessary).\nThis allows us to assign head to all leaf nodes where a path of the first kind exists for every k as expressed by the following rule:\nn∧ k=1\n( rootstartk(x, xk,1) ∧ ( n−2∧ i=1 wired(xk,i, xk,i+1) ) ∧ endk(xk,n−1, y) ) → head(y). (23)\nLikewise, we can assign nohead to all leaf nodes where a path of the second kind exists for some k, thus we add for every k ranging from 1 to n a separate rule of the following kind:\nrootstartk(x, x1) ∧ ( n−1∧ i=1 wired(xi, xi+1) ) ∧ endk(xn, y)→ nohead(y). (24)\nNow that we have an indicator of the head position in the memory tree, we can enforce that every configuration element is indeed assigned the symbolγ predicate whenever the symbol γ is found at the current head position:\n( n−1∧ i=0 child(xi, xi+1) ) ∧ symbolγ(xn) ∧ head(xn)→ symbolγ(x0). (25)\nThe last bit of the alternating Turing machine functionality that needs to be taken care of is memory evolution: a symbol stored in memory changes according to the transition relation if and only if the head is at the corresponding position. In our encoding this means that for all nohead -assigned leaf nodes of a configuration’s memory tree, their stored symbol has to be propagated to the corresponding leaf nodes of all direct successors’ memory trees. Again we exploit structural properties to connect the corresponding leaf nodes of two subsequent configurations’ memory trees:\nLet νc and ν ′ c be two configuration elements such that ν ′ c represents a direct successor\nof νc. Let νl be a leaf node of νc’s memory tree and let ν ′ l be a leaf node of ν ′ c’s memory tree. Let the kth bit of νl’s address and the kth bit of ν ′ l ’s address coincide. Then – and only then – there are nodes ν1, . . . , ν2n+6 such that there is a path\nνl startk−→ ν1 wired−→ . . . wired−→ ν2n+6 endk−→ ν ′l\nwhere fw holds for νn+3. This justifies to transfer the stored symbol from any non-head-leaf to all leaf nodes to which it is simultaneously connected by such paths for every k:\nn∧ k=1\n( startk(x, xk,1) ∧ ( 2n+5∧ i=1 wired(xk,i, xk,i+1) ) ∧ endk(xk,2n+6, y) ) ∧(\nn∧ k=1 fwd(xk,n+3) ) ∧ symbolγ(x) ∧ nohead(x) → symbolγ(y). (26)\nOf course, we also need to take care to assign the proper symbol (which is determined by the transition by which the current configuration has been reached) to the leaf node of the previous configuration’s head position. To this end, we add for every δ = (q, γ, q′, γ′, D) ∈ ∆ the rule\nhead(x) ∧ n∧ k=1\n( startk(x, xk,1) ∧ ( 2n+5∧ i=1 wired(xk,i, xk,i+1) ) ∧ endk(xk,2n+6, zn) ) ∧(\nn∧ k=1 fwd(xk,n+3)\n) ∧ transδ(z, z0) ∧ ( n−1∧ i=0 child(zi, zi+1) ) → symbolγ(zn). (27)\nFinally, we have to ensure that the initial configuration and its memory tree carry all the necessary information. We have to initialize the head position address to 0 by adding to F the facts\n{lbit1(init), . . . , lbitn(init)}. (28)\nMoreover, all tape cells initially contain the blank symbol , which we achieve by extending R by the rule\nfirstconf (x0) ∧ ( n−1∧ k=0 child(xk, xk+1) ) → symbol (xn). (29)\nConcluding, we have just built F , R and Q with the desired properties. Moreover, R consists of only fr1 rules and does not contain any constant. This concludes our argument that the combined complexity of CQ entailment over fr1 rules is 2ExpTime-hard, even in the case where no constants show up in the rules.\nTheorem 34. Conjunctive query entailment for constant-free fr1 rules with bounded predicate arity is 2ExpTime-hard.\n5.5 Combined Complexity of Weakly Guarded Frontier-One Rules is 2ExpTime-hard\nOur last hardness result will be established along the same lines as the preceding one, namely by a reduction from the word problem of an alternating Turing machine with exponential space. In fact, we will also reuse part of the reduction and arguments presented in the previous section. In particular, we assume everything up to formula (14) as before except for the following modifications:\n• Remove from Rule (2) all atoms built from the predicates wire and fw .\n• Replace the Rule (5) with the following rules:\n– for every δ = (q, γ, q′, γ′, D) ∈ ∆ the rule\ntransδ(x, y) ∧ accept(y)→ acceptδ(x)\n– the rule ∧ δ=(q,γ,q′,γ′,D)∈∆ acceptδ(x)→ accept(x)\nThereby, we introduce a fresh predicate acceptδ for every δ = (q, γ, q ′, γ′, D) ∈ ∆. Clearly this set of rules has the same consequences as the previous Rule (5), however it consists merely of gfr1 rules.\nThis puts the ATM’s “state space” and transition relations into place. Now we turn to the task of encoding the exponential tape. As opposed to the previous encoding, we now exploit that we can use predicates of arbitrary arity. Thus, for every γ ∈ Γ we introduce an n+1-ary predicate ontapeγ where the first n positions are used for the binary encoding of a tape address and the n+1st position contains the configuration element that this tape\ninformation refers to. Our encoding will ensure that the first n positions of these predicates are non-affected. Likewise we will use n+1-ary predicates head and nohead to store for each tape position of a configuration if the ATM’s head is currently in that position or not. For this purpose, we introduce auxiliary constants to encode whether address bits are high, low, or unknown. Thus we add to F the following atoms:\nhigh(1), bit(1), low(0), bit(0).\nNow, for every k we introduce a binary predicate bitk (whose second position is nonaffected) with the intention to let bitk(x, 0) hold whenever lbitk(x) holds and to also have hbitk(x) imply bitk(x, 1), which is achieved by the following two rules:\nlbitk(x) ∧ low(z)→ bitk(x, z),\nhbitk(x) ∧ high(z)→ bitk(x, z).\nMoreover, we make sure that the binary encoding of the head position’s address that we find attached to the configuration elements through the bitk predicates is transferred into the head predicate as stated above:\nconf (x) ∧ n∧ k=1 bitk(x, zk)→ head(z1, . . . , zn, x).\nAdditionally, we make sure that for all other binary addresses z1 . . . zn the according nohead atoms hold, by adding for every i in the range from 1 to n the rule\nconf (x) ∧ biti(x,w) ∧ other(w, zi) n∧ k=1 bit(zk)→ nohead(z1, . . . , zn, x).\nFurthermore, we have to ensure that the symbol γ found at any configuration’s head position (expressed by the corresponding ontapeγ atom) is also directly attached to that configuration by the according unary symbolγ atom:\nhead(z1, . . . , zn, x) ∧ ontapeγ(z1, . . . , zn, x)→ symbolγ(x).\nAlso, the symbol γ′ written to the tape at the previous configuration’s head position as a result of some transition δ can be realized easily:\nhead(z1, . . . , zn, x) ∧ transδ(x, y)→ ontapeγ′(z1, . . . , zn, x)\nOn the other hand, all previous nohead-positions of the tape will keep their symbol, as made sure by the rules (for all γ ∈ Γ):\nnohead(z1, . . . , zn, x) ∧ ontapeγ(z1, . . . , zn, x) ∧ transδ(x, y)→ ontapeγ(z1, . . . , zn, y).\nTo ensure that the initial configuration and its tape carry all the necessary information, we initialize the head position address to 0 by adding to F , as in the previous section, the facts:\n{lbit1(init), . . . , lbitn(init)}. (30)\nTo make sure that all tape cells initially contain the blank symbol , we extend R by the rule:\nfirstconf (x) ∧ n∧ k=1 bit(zk)→ ontape (z1, . . . , zn, x). (31)\nConcluding, we have just built F , R and Q with the desired properties. Moreover, R consists of only wgfr1 rules. Thus we arrive at the desired theorem.\nTheorem 35. The combined complexity of CQ entailment over constant-free wgfr1 rules of unbounded arity is 2ExpTime-hard.\n6. Body-Acyclic fg and fr1 Rules In this section, we study the complexity of frontier-guarded rules with an acyclic body. The acyclicity notion considered here is a slight adaptation of hypergraph acyclicity stemming from database theory. We will show that body-acyclic fg rules coincide with guarded rules: indeed, a body-acyclic fg rule can be linearly rewritten as a set of guarded rules, and a guarded rule is a special case of body-acyclic rule.\nLet us consider the hypergraph naturally associated with a set of atoms S: its set of nodes is in bijection with terms(S) and its multiset of hyperedges is in bijection with S, with each hyperedge being the subset of nodes assigned to the terms of the corresponding atom.\nTo simplify the next notions, we first proceed with some normalization of a set of fg rules, such that all rules have an empty frontier (so-called “disconnected rules” (Baget et al., 2010)) or a “variable-connected” body:\n1. Let R be a fg rule with a non-empty frontier and let B be the hypergraph associated with body(R). Split each node in B assigned to a constant into as many nodes as hyperedges it belongs to (thus each constant node obtained belongs to a single hyperedge); let B′ be the hypergraph obtained; let Cf be the connected component of B′ that contains the frontier guard(s); if there are several frontier guards, they are all in Cf .\n2. Let R0 = B′ \\ Cf → p0, where p0 is a new nullary predicate.\n3. Let Rf = Cf ∪ {p0} → head(R).\nLet (F,R, Q) be an instance of the entailment problem, where R is a set of fg rules. All non-disconnected rules from R are processed as described above, which yields an equivalent set of fg rules. Let us denote this set by Rdisc ∪ R′, where Rdisc is the set of disconnected rules, i.e., initial disconnected rules and obtained rules of form R0. The rules in Rdisc are integrated into F as described in (Baget et al., 2010), which can be performed with\n|Rdisc| calls to an oracle solving the entailment problem for fg rules. Briefly, for each Rd = (Bd, Hd) ∈ Rdisc, it is checked whether F,R′ |= Bd: if yes, Hd is added to F and Rd is removed from Rdisc; the process is repeated until stability of Rdisc. Let F ′ the fact obtained: for any BCQ Q, F,R |= Q iff F ′,R′ |= Q. From now on, we thus assume that all fg rules have a non-empty frontier and their body is “variable-connected”, i.e., the associated hypergraph is connected and cannot be disconnected by the above step 1.\nThe acyclicity of a hypergraph H is usually defined with respect to its so-called dual graph, whose nodes are the hyperedges of H and edges encode non-empty intersections between hyperedges of H. We define below a notion close to the dual graph, that we call decomposition graph of a set of atoms. In a decomposition graph, guarded atoms are grouped together with one of their guard into a single node, and constants are not taken into account in atom intersections (it follows that the associated acyclicity notion is slightly more general than hypergraph acyclicity).\nDefinition 40 (Decomposition Graph). Let S be a set of atoms. A decomposition graph of S is an undirected labeled graph DS = (V,E, atoms, vars), where V is the set of nodes, E is the set of edges, atoms and vars are labeling mappings of nodes and of edges respectively, such that:\n• Let {C1, . . . Cp} be a partition of S such that in each Ci there is an atom that guards the other atoms of Ci, with p being minimal for this property. Then V = {v1, . . . vp} and for 1 ≤ i ≤ p, atoms(vi) = Ci.\n• For 1 ≤ i, j ≤ p, i 6= j, there is an edge vivj if Ci and Cj share a variable; vars(vivj) = vars(Ci) ∩ vars(Cj).\nSeveral decomposition graphs can be assigned to S, however they have all the same structure and the same labeling on edges. The only difference between them comes from the choice of a guard when an atom is guarded by several guards with incomparable sets of variables. Now, considering the decomposition graph instead of the dual graph, the acyclicity of a set of atoms is then defined similarly to that of a hypergraph.\nDefinition 41 (Acyclicity of an Atom Set, Body-Acyclic fg Rule). Let S be a set of atoms and DS be a decomposition graph of S. An edge vivj in DS is said to be removable if there is another path λ between vi and vj in DS such that for each each edge vkvl in λ, vars(vivj) ⊆ vars(vkvl). An acyclic covering of S is a forest obtained from DS by removing removable edges only. S is said to be acyclic if has an acyclic covering. An fg rule R is said to be body-acyclic (ba) if body(R) is acyclic.\nExample 20. Let S = {p1(x), p2(x, u), p2(y, z), p3(y, z, u), p2(u, v), p3(u, v, x)}. DS has set of nodes {v1, v2, v3}, with atoms(v1) = {p1(x), p2(x, u)}, atoms(v2) = {p2(y, z), p3(y, z, u)} and atoms(v3) = {p2(u, v), p3(u, v, x)}, and all edges between these nodes, with vars(v1v2) = vars(v2v3) = {u} and vars(v1v3) = {x, u}. An acyclic covering of S is obtained by removing edge v1v2 or v2v3.\nLet us point out that a set of atoms is acyclic according to the above definition if and only if the associated existentially closed conjunctive formula belongs to the guarded fragment of first-order logic (see acyclic guarded covering in (Kerdiles, 2001) and (Chein &\nMugnier, 2009) for details about this equivalence). Note also that the decomposition graph associated with the body of a guarded rule is restricted to a single node. Thus, guarded rules are trivially ba-fg rules.\nGiven a set of atoms S, checking whether it is acyclic, and if so, outputing one of its acyclic coverings can be performed in linear time (from (Maier, 1983) about the computation of a join tree in databases).\nLet R be a variable-connected ba-fg rule and let T be an acyclic covering of body(R), which is thus a tree. Let {v1, ..., vp} be the nodes in T and let vr be a node such that atoms(vr) contains a frontier guard. T is considered as rooted in vr, which yields a direction of its edges from children to parents: a directed edge (vi, vj) is from a child to its parent. R is translated into a set of guarded rules {R1, . . . Rp} as follows:\n• To each edge (vi, vj) is assigned the atom ai = qi(vars(vivj)), where qi is a new predicate;\n• To each node vi, i 6= r, is assigned the rule: Ri = atoms(vi) ∪ {ak|vk child of vi} → ai\n• To the node vr is assigned the rule: Rr = atoms(vr) ∪ {ak|vk child of vr} → head(R)\nNote that this translation is the identity on guarded rules.\nExample 20 (Contd.) Let R = p1(x) ∧ p2(x, u) ∧ p2(y, z) ∧ p3(y, z, u) ∧ p2(u, v) ∧ p3(u, v, x)→ head(R), with fr(R) = {u, v}. Consider the acyclic covering with set of nodes {v1, v2, v3}, with atoms(v1) = {p1(x), p2(x, u)}, atoms(v2) = {p2(y, z), p3(y, z, u)} and atoms(v3) = {p2(u, v), p3(u, v, x)}, and set of edges {v1v3, v2v3}. On has vars(v1v3) = {u} and vars(v1v3) = {x, u}. v3 is the root. The obtained guarded rules are: R1 = p1(x) ∧ p2(x, u)→ q1(x, u) R2 = p2(y, z) ∧ p3(y, z, u)→ q2(u) R3 = p2(u, v) ∧ p3(u, v, t) ∧ q1(x, u) ∧ q2(u)→ head(R)\nProperty 36. Guarded rules and ba-fg rules are semantically equivalent in the following sense: a guarded rule is a ba-fg rule and any set of ba-fg rules can be translated into a semantically equivalent set of guarded rules.\nThe above translation is polynomial in the size of the rule and arity-preserving. Thus, complexity results on guarded rules apply to ba-fg rules. In particular ba-fg rules are ExpTime-complete for bounded-arity combined complexity, while fg rules are 2ExpTimecomplete.\nActually the ExpTime lower bound already holds for combined complexity with arity bounded by 2. Indeed, standard reasoning in the much weaker description logic reduced normalized Horn-ALC (cf. Section 5.2), which is a fragment of ba-gfr1 rules with maximal arity of 2, is already ExpTime-Hard, as cited in Theorem 29. It follows that ba-gfr1 rules are ExpTime-Hard for bounded-arity in combined complexity. One could have expected bafrontier-1 rules to be simpler than ba-fg rules. In fact, they have the same data complexity\nand the same bounded-arity combined complexity. The only remaining question, for which we have no answer yet, is whether they are simpler in the unbounded arity case.\nFinally, let us point out that the acyclicity of rule bodies alone is not enough to guarantee a lower complexity, and even decidability: that the head of a rule shares variables with only one node of the decomposition graph (thus, that the frontier is guarded) is crucial. Without this assumption, the entailment problem remains undecidable. 12"
    }, {
      "heading" : "7. Related Work",
      "text" : "In this section, discuss the relationship of the existential rule fragments considered here with another major paradigm in logic-based knowledge representation: description logics. Also, we will point out similarities of the techniques applied in the presented algorithm with reasoning approaches established for other logics."
    }, {
      "heading" : "7.1 Relationships to Horn Description Logics and their Extensions",
      "text" : "The relationship of description logics and existential rules has often been recognized. In particular Horn-DLs (Hustadt, Motik, & Sattler, 2005; Krötzsch et al., 2007, 2013) share many properties with existential rules such as the existence of a (homomorphically unique) canonical model. Crucial differences between the two approaches are that (1) as opposed to DLs, existential rules allow for predicates of arity greater than two as well as for the description of non-tree shaped terminological information and (2) as opposed to existential rules, expressive DLs allow for a tighter integration of cardinality constraints to a degree (at least currently) unachieved by existential rules.\nIn the following, we will point out which Horn-DLs are subsumed by which existential rules fragments. We will refrain from providing full translations and restrict ourselves to examples that provide the underlying intuition.\nThe description logic EL essentially allows for encoding implications of tree-shaped substructures in a model. For instance the statement “Everybody who has a caring mother and a caring father has a nice home” can be expressed by the EL axiom ∃hasMother .Caringu ∃hasFather .Caring v ∃hasHome.Nice which is equivalent to the existential rule\nhasMother(x, y) ∧ Caring(y) ∧ hasFather(x, z) ∧ Caring(z)→ hasHome(x,w) ∧Nice(w).\nHorn-ALC is more expressive than EL in that it allows to express some sort of universal quantification such as in “Whenever some caring person has children, all of them are happy” denoted by Caring v ∀hasChild which corresponds to the existential rule Caring(x) ∧ hasChild(x, y)→ Happy(y).\nIt is not hard to see that the Horn-DLs EL and Horn-ALC are captured by fr1 rules; they can even be linearly rewritten into gfr1 rules when auxiliary predicates are allowed (as it is often done when normalizing DL knowledge bases). This still holds when these DL languages are extended by inverses (indicated by adding an I to the name of the DL: ELI,\n12. See for instance (Baget & Mugnier, 2002), which provides a reduction from the word problem in a semi-Thue system, known to be undecidable, to the CQ entailment problem with existential rules (in a conceptual graph setting): this reduction yields existential rules with predicate arity bounded by 2, a body restricted to a path and a frontier of size 2.\nHorn-ALCI) and/or nominals (indicated by adding an O). In the latter case, constants must occur in the rules). For instance, the ELIO proposition “Everybody who is born in Germany likes some soccer team which has a member who is also a member of the the German national team”, written in DL notation\n∃bornin.{germany} v ∃likes.(SoccerTeam u ∃hasMember.∃hasMember−.{gnt})\n, in existential rules form\nbornin(x, germany)→ likes(x, y)∧SoccerTeam(y)∧hasMember(y, z)∧hasMember(gnt, z)\nRole hierarchies (H), allow to express generalization/specialization relationships on binary predicates (such as fatherOf implying parentOf ). Adding this feature to any of the abovementioned description logics requires to use rules with frontier size 2 and thus leads outside the frontier-one fragment. Still a linear translation into g rules remains possible.13. Going further to DLs that feature functionality or transitivity of binary predicates leads to existential rule fragments which are not longer guarded in any way considered here. The definition of existential rule fragments capturing these expressive description logics is subject of ongoing research.\nDiverse proposals have been made to overcome the structural restrictions of DLs, i.e. to allow to express non-tree-shaped relationships in the terminological knowledge. Description graphs (Motik, Grau, Horrocks, & Sattler, 2009b) constitute one of these endeavors, where the existentially quantified structure in the head of a DL axiom is allowed to be arbitrarily graph-shaped and, additionally, there are datalog rules operating locally on these graph structures. It is straight-forward that the extension of any DL up to Horn-ACLHIO by description graphs can be coded into g existential rules.\nAnother suggestion made to allow for non-tree shaped structures in both body and head of a DL axiom is to introduce DL-safe variables, that is, variables that are only allowed to be bound to “named individuals” (i.e., domain elements denoted by constants). In a setting where each statement can carry either exclusively safe variables or exclusively non-safe ones, this can be captured by the notion of DL-safe rules (Motik, Sattler, & Studer, 2005). A more liberal approach is that of the so-called nominal schemas (Krötzsch, Maier, Krisnadhi, & Hitzler, 2011; Krötzsch & Rudolph, 2014), where the two types of variables can occur jointly in the same statement. In both cases, the wg fragment captures these extensions when applied to DLs up to Horn-ALCHIO. Note that there is a direct correspondence between non-affected positions in existential rules and DL-safe variables: both can only carry domain elements corresponding to elements present in the initial data."
    }, {
      "heading" : "7.2 Pattern- or Type-Based Reasoning",
      "text" : "For many logics, reasoning algorithms as well as related complexity arguments are based on the notion of types. On an intuitive level, types represent “configurations” which may occur in a model. In the easiest case (as in some description logics), such configurations might be sets of unary predicates {p1, . . . , pn}, where {p1, . . . , pn} occurring in a model just\n13. It might, however, be noteworthy that it is possible to come up with a polynomial translation into gfr1 rules by materializing the subsumption hierarchy of the binary predicates upfront and, whenever a binary atom is created by a rule “creating” all the subsumed atoms at the same time.\nmeans that there is an individual a that is in the extension of every pi. More complex notions of types may refer to more than just one individual, leading to notions like 2-types, also known as dominoes (Rudolph, Krötzsch, & Hitzler, 2012), star-types (Pratt-Hartmann, 2005), mosaics (Blackburn, van Benthem, & Wolter, 2006), or types based on trees (Rudolph & Glimm, 2010). Often, reasoning in a logic can be carried out by only considering the (multi-)set of types that are realized in a model. Typical reasoning strategies may then compute the set of these types bottom-up (as in tableaux with anywhere-blocking ), topdown (as in type-elimination-based procedures), or describe their multiplicity by means of equational systems. The applicability of such strategies guarantees decidability whenever the overall set of possible types is finite. It is not hard to see that, in our case, abstract patterns can be seen as “graph types” where the bound on the tree-width and the finiteness of the vocabulary guarantee the finiteness of the set of types, and therefore the effectiveness of the applied blocking strategy."
    }, {
      "heading" : "7.3 Consequence-Driven Reasoning",
      "text" : "Our idea of the saturation of pattern rules in Section ... has many similarities with the approach of consequence-driven reasoning in description logics. In both cases, logical sentences that are consequences of a given theory are materialized. To see this, one should be aware that every evolution rule P1 P2 corresponds to an existential rule∧\n(G,π)∈P1\nπsafe(G)→ ∧\n(G,π)∈P2\nπsafe(G)\nand every creation rule P1 λ.P2 corresponds to an existential rule∧ (G,π)∈P1 πsafe(G)→ ∧ (G,π)∈P2 πsafe(λ(G)).\nIt can then be readily checked that the deduction calculus presented in Fig. 5 is indeed sound. As such, the presented algorithm has indeed similarities with type-based consequence driven reasoning approaches as, e.g., layed out by (Kazakov, 2009) and (Ortiz, Rudolph, & Simkus, 2010, 2011). The crucial difference here is that the mentioned works use only 1-types, whereas the patterns defined characterize larger “clusters” of elements."
    }, {
      "heading" : "7.4 Tableaux and Blocking",
      "text" : "It is well-known that the chase known from databases has many commonalities with the semantic tableau method in FOL (Beth, 1955; Smullyan, 1968), which has also been used in many other logics, most notably DLs (Baader & Sattler, 2001; Horrocks & Sattler, 2007). Note that the generic semantic tableaux for first order logic only gives rise to a semidecision procedure. In order to obtain a decision procedure for a restricted logic, termination needs to be guaranteed, typically through establishing a tree(-like) model property and the detection of repetitions in the course of the tableaux construction, leading to the idea of blocking as soon as repeating types occur (depending on the expressivity of the logic, 1-types, 2-types or even larger types have to be considered). Clearly, the blocking technique used by us in the construction of the full blocked tree can be seen as a pattern-based anywhere blocking."
    }, {
      "heading" : "7.5 Relationships to other work on guarded existential rules",
      "text" : "As already mentioned, guarded and weakly-guarded rules were introduced in (Cal̀ı et al., 2008, 2009; Cal̀ı, Gottlob, & Kifer, 2013). A fundamental notion used to bound the depth of the breadth-first saturation (with a bound depending on R and Q) is that of the type of a guard atom in the saturation (a guard atom in α∞(F,R) is the image of a rule guard by a rule application, and the type of an atom a is the set all atoms in α∞(F,R) with arguments included in terms(a)). This notion has some similarities with our bag patterns, without being exactly the restriction of bag patterns to the guarded case.\nThe notion of affected position/variable was refined into that of jointly affected position/variable in (Krötzsch & Rudolph, 2011). This yields the new classes of jointly guarded rules and jointly frontier-guarded rules, which respectively generalize wg rules and wfg rules. Since these new classes are gbts , our results apply to them. In particular, the data and combined complexities of jointly frontier-guarded rules directly follow from those of gbts and wfg : ExpTime-complete data complexity, and 2ExpTime-complete combined complexity (in both bounded and unbounded predicate arity cases). Since wg rules have the same complexities as wfg rules for data complexity and combined complexity with bounded arity, these complexities also apply to jointly guarded rules; for combined complexity with unbounded arity, the bounds are not tight (ExpTime-hardness from the result on wg and 2ExpTime-membership from the result on wfg). Note that (Krötzsch & Rudolph, 2011) also provides a further generalization, namely glut frontier-guarded, which is bts , but not gbts nor fes .\nCombinations of the gbts family with other families of rules have been proposed, by restricting possible interactions between rules of the different kinds. In (Baget et al., 2011), conditions expressed on the strongly connected components of a graph of rule dependencies allow to combine gbts , fes and fus sets of rules. In (Gottlob, Manna, & Pieris, 2013), a notion called tameness allows to combine guarded rules with sticky rules (an expressive fes concrete class of rules) by restricting the interactions between the sticky rules and the guard atoms in the guarded rules.\nFinally, let us cite some very recent work related to the guarded family of existential rules. The expressiveness of the wg and wfg fragments was studied in (Gottlob, Rudolph, & Simkus, 2014). Other work has analyzed the complexity of entailment with guarded rules extended with disjunction (Bourhis, Morak, & Pieris, 2013) or with stable negation (Gottlob, Hernich, Kupke, & Lukasiewicz, 2014b)."
    }, {
      "heading" : "7.6 Combined Approach",
      "text" : "The combined approach (Lutz et al., 2009; Kontchakov, Lutz, Toman, Wolter, & Zakharyaschev, 2010), designed for EL and the DL-Lite familly, share some similarities with our approach. The combined approach is a two-step process. First, some materialization is performed. In order to ensure finiteness of this step, an over-specialization of the canonical model is thus computed. This over-specialization requires thus a rewriting of the query, in order to recover soundness. This rewriting may require the ontology. By comparison, our approach computes a materialization that is less specific than the saturation. It is thus the completeness that has to be recovered, through a change of the querying operation, which is not a simple homomorphism anymore, but is based on the notion of APT-homomorphism."
    }, {
      "heading" : "8. Conclusion",
      "text" : "We have introduced the notion of greedy bounded-treewidth sets of existential rules that subsumes guarded rules, as well as their known generalizations, and gives rise to a generic and worse-case optimal algorithm for deciding conjunctive query entailment. Moreover, we have classified known gbts subclasses with respect to their combined and data complexities.\nThe existential rule framework is young and combines techniques from different research fields (such as databases, description logics, rule-based languages). A lot of work is still to be done to deepen its understanding, design efficient algorithms and develop its applications.\nIt remains an open question whether gbts is recognizable. We conjecture that the answer is yes. However, even if this question is interesting from a theoretical viewpoint, we recall that gbts is not more expressive than wfg , and furthermore, any gbts set of rules can be polynomially translated into a wfg set of rules, while preserving entailment (Section 3). Moreover, we built a reduction from the entailment problem, where R is fg and constantfree, to the problem of checking if some rule set R′ is gbts (this reduction is not included in this paper, since it is only one step in the study of the recognizability issue). Hence, we know that determining if some rule set is gbts is significantly harder than for wfg , where this check can be done in polynomial time.\nFuture work will aim at adding rules expressing restricted forms of equality and of useful properties such as transitivity into this framework, while preserving decidability, and the desirable PTime data complexity of fg rules.\nWe have shown in Section 4.6 that the PatSat algorithm can be adapted to run with optimal worst-case complexity for fragments of the gbts family. An important research line is the optimization, implementation and practical evaluation of this algorithm and its variants. To the best of our knowledge, currently existing prototypes processing existential rules follow a backward chaining approach, which involves rewriting the query into a union of CQs; hence, termination of the query rewriting process is ensured on fus rules (Gottlob, Orsi, & Pieris, 2014a; König, Leclère, Mugnier, & Thomazo, 2014)"
    }, {
      "heading" : "Acknowledgments",
      "text" : "Michaël Thomazo aknowledges support from the Alexander von Humboldt foundation."
    } ],
    "references" : [ {
      "title" : "The theory of joins in relational databases",
      "author" : [ "A.V. Aho", "C. Beeri", "J.D. Ullman" ],
      "venue" : "ACM Trans. Database Syst.,",
      "citeRegEx" : "Aho et al\\.,? \\Q1979\\E",
      "shortCiteRegEx" : "Aho et al\\.",
      "year" : 1979
    }, {
      "title" : "Modal Languages and Bounded Fragments of Predicate Logic",
      "author" : [ "H. Andréka", "I. Németi", "J. van Benthem" ],
      "venue" : "J. of Philosophical Logic,",
      "citeRegEx" : "Andréka et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Andréka et al\\.",
      "year" : 1998
    }, {
      "title" : "Modal languages and bounded fragments of FOL",
      "author" : [ "H. Andréka", "J. van Benthem", "I. Németi" ],
      "venue" : "Research report ML-96-03,",
      "citeRegEx" : "Andréka et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Andréka et al\\.",
      "year" : 1996
    }, {
      "title" : "Least common subsumers and most specific concepts in a description logic with existential restrictions and terminological cycles",
      "author" : [ "F. Baader" ],
      "venue" : "Gottlob, G., & Walsh,",
      "citeRegEx" : "Baader,? 2003",
      "shortCiteRegEx" : "Baader",
      "year" : 2003
    }, {
      "title" : "The Description Logic Handbook: Theory, Implementation, and Applications (Second edition)",
      "author" : [ "F. Baader", "D. Calvanese", "D. McGuinness", "D. Nardi", "P. Patel-Schneider" ],
      "venue" : null,
      "citeRegEx" : "Baader et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Baader et al\\.",
      "year" : 2007
    }, {
      "title" : "An overview of tableau algorithms for description logics",
      "author" : [ "F. Baader", "U. Sattler" ],
      "venue" : "Studia Logica,",
      "citeRegEx" : "Baader and Sattler,? \\Q2001\\E",
      "shortCiteRegEx" : "Baader and Sattler",
      "year" : 2001
    }, {
      "title" : "Walking the Decidability Line for Rules with Existential Variables",
      "author" : [ "Baget", "J.-F", "M. Leclère", "Mugnier", "M.-L" ],
      "venue" : "In Principles of Knowledge Representation and Reasoning: Proceedings of the Twelfth International Conference,",
      "citeRegEx" : "Baget et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Baget et al\\.",
      "year" : 2010
    }, {
      "title" : "Extending Decidable Cases for Rules with Existential Variables",
      "author" : [ "Baget", "J.-F", "M. Leclère", "Mugnier", "M.-L", "E. Salvat" ],
      "venue" : "IJCAI",
      "citeRegEx" : "Baget et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Baget et al\\.",
      "year" : 2009
    }, {
      "title" : "On rules with existential variables: Walking the decidability line",
      "author" : [ "Baget", "J.-F", "M. Leclère", "Mugnier", "M.-L", "E. Salvat" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "Baget et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Baget et al\\.",
      "year" : 2011
    }, {
      "title" : "The Complexity of Rules and Constraints",
      "author" : [ "Baget", "J.-F", "Mugnier", "M.-L" ],
      "venue" : "J. Artif. Intell. Res. (JAIR),",
      "citeRegEx" : "Baget et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Baget et al\\.",
      "year" : 2002
    }, {
      "title" : "Walking the Complexity Lines for Generalized Guarded Existential Rules",
      "author" : [ "Baget", "J.-F", "Mugnier", "M.-L", "S. Rudolph", "M. Thomazo" ],
      "venue" : "IJCAI",
      "citeRegEx" : "Baget et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Baget et al\\.",
      "year" : 2011
    }, {
      "title" : "The implication problem for data dependencies",
      "author" : [ "C. Beeri", "M. Vardi" ],
      "venue" : "In Proceedings of Automata, Languages and Programming, Eigth Colloquium (ICALP",
      "citeRegEx" : "Beeri and Vardi,? \\Q1981\\E",
      "shortCiteRegEx" : "Beeri and Vardi",
      "year" : 1981
    }, {
      "title" : "A Proof Procedure for Data Dependencies",
      "author" : [ "C. Beeri", "M. Vardi" ],
      "venue" : "Journal of the ACM,",
      "citeRegEx" : "Beeri and Vardi,? \\Q1984\\E",
      "shortCiteRegEx" : "Beeri and Vardi",
      "year" : 1984
    }, {
      "title" : "Semantic entailment and formal derivability",
      "author" : [ "E.W. Beth" ],
      "venue" : "Mededelingen van de Koninklijke Nederlandse Akademie van Wetenschappen, Afdeling Letterkunde, 18 (13), 309–342.",
      "citeRegEx" : "Beth,? 1955",
      "shortCiteRegEx" : "Beth",
      "year" : 1955
    }, {
      "title" : "Handbook of Modal Logic, Vol. 3 of Studies in Logic and Practical Reasoning",
      "author" : [ "P. Blackburn", "van Benthem", "J.F.A. K", "F. Wolter" ],
      "venue" : null,
      "citeRegEx" : "Blackburn et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Blackburn et al\\.",
      "year" : 2006
    }, {
      "title" : "The impact of disjunction on query answering under guarded-based existential rules",
      "author" : [ "P. Bourhis", "M. Morak", "A. Pieris" ],
      "venue" : "IJCAI",
      "citeRegEx" : "Bourhis et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bourhis et al\\.",
      "year" : 2013
    }, {
      "title" : "Taming the Infinite Chase: Query Answering under Expressive Relational Constraints",
      "author" : [ "A. Cal̀ı", "G. Gottlob", "M. Kifer" ],
      "venue" : "In Principles of Knowledge Representation and Reasoning: Proceedings of the Eleventh International Conference,",
      "citeRegEx" : "Cal̀ı et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Cal̀ı et al\\.",
      "year" : 2008
    }, {
      "title" : "Taming the infinite chase: Query answering under expressive relational constraints",
      "author" : [ "A. Cal̀ı", "G. Gottlob", "M. Kifer" ],
      "venue" : "J. Artif. Intell. Res. (JAIR),",
      "citeRegEx" : "Cal̀ı et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Cal̀ı et al\\.",
      "year" : 2013
    }, {
      "title" : "Datalog+/-: A family of logical knowledge representation and query languages for new applications",
      "author" : [ "A. Cal̀ı", "G. Gottlob", "T. Lukasiewicz", "B. Marnette", "A. Pieris" ],
      "venue" : "In Proceedings of the 25th Annual IEEE Symposium on Logic in Computer Science,",
      "citeRegEx" : "Cal̀ı et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Cal̀ı et al\\.",
      "year" : 2010
    }, {
      "title" : "Taming the infinite chase: Query answering under expressive relational constraints",
      "author" : [ "A. Cal̀ı", "G. Gottlob", "M. Kifer" ],
      "venue" : "J. Artif. Intell. Res. (JAIR),",
      "citeRegEx" : "Cal̀ı et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Cal̀ı et al\\.",
      "year" : 2013
    }, {
      "title" : "A General Datalog-Based Framework for Tractable Query Answering over Ontologies",
      "author" : [ "A. Cal̀ı", "G. Gottlob", "T. Lukasiewicz" ],
      "venue" : "In Proceedings of the Twenty-Eigth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,",
      "citeRegEx" : "Cal̀ı et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Cal̀ı et al\\.",
      "year" : 2009
    }, {
      "title" : "On the decidability and complexity of query answering over inconsistent and incomplete databases",
      "author" : [ "A. Cal̀ı", "D. Lembo", "R. Rosati" ],
      "venue" : "In Proceedings of the TwentySecond ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems, June 9-12,",
      "citeRegEx" : "Cal̀ı et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Cal̀ı et al\\.",
      "year" : 2003
    }, {
      "title" : "On the decidability of query containment under constraints",
      "author" : [ "D. Calvanese", "G. De Giacomo", "M. Lenzerini" ],
      "venue" : "In Proceedings of the 17th ACM SIGACT SIGMOD Symposium on Principles of Database Systems (PODS",
      "citeRegEx" : "Calvanese et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Calvanese et al\\.",
      "year" : 1998
    }, {
      "title" : "Tractable Reasoning and Efficient Query Answering in Description Logics: The DL-Lite Family",
      "author" : [ "D. Calvanese", "G. De Giacomo", "D. Lembo", "M. Lenzerini", "R. Rosati" ],
      "venue" : "Journal of Automated Reasoning,",
      "citeRegEx" : "Calvanese et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Calvanese et al\\.",
      "year" : 2007
    }, {
      "title" : "Embedded implicational dependencies and their inference problem",
      "author" : [ "A.K. Chandra", "H.R. Lewis", "J.A. Makowsky" ],
      "venue" : "In Proceedings of the Thirteenth Annual ACM Symposium on Theory of Computing (STOC",
      "citeRegEx" : "Chandra et al\\.,? \\Q1981\\E",
      "shortCiteRegEx" : "Chandra et al\\.",
      "year" : 1981
    }, {
      "title" : "Graph-based Knowledge Representation and Reasoning—Computational Foundations of Conceptual Graphs. Advanced Information and Knowledge",
      "author" : [ "M. Chein", "Mugnier", "M.-L" ],
      "venue" : null,
      "citeRegEx" : "Chein et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Chein et al\\.",
      "year" : 2009
    }, {
      "title" : "The Monadic Second-Order Logic of Graphs: I",
      "author" : [ "B. Courcelle" ],
      "venue" : "Recognizable Sets of Finite Graphs. Inf. Comput., 85 (1), 12–75.",
      "citeRegEx" : "Courcelle,? 1990",
      "shortCiteRegEx" : "Courcelle",
      "year" : 1990
    }, {
      "title" : "The chase revisited",
      "author" : [ "A. Deutsch", "A. Nash", "J. Remmel" ],
      "venue" : "In Proceedings of the Twenty-Seventh ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,",
      "citeRegEx" : "Deutsch et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Deutsch et al\\.",
      "year" : 2008
    }, {
      "title" : "Data Exchange: Semantics and Query Answering",
      "author" : [ "R. Fagin", "P.G. Kolaitis", "R.J. Miller", "L. Popa" ],
      "venue" : "Theor. Comput. Sci.,",
      "citeRegEx" : "Fagin et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Fagin et al\\.",
      "year" : 2005
    }, {
      "title" : "Query rewriting and optimization for ontological databases",
      "author" : [ "G. Gottlob", "G. Orsi", "A. Pieris" ],
      "venue" : "ACM Trans. Database Syst.,",
      "citeRegEx" : "Gottlob et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Gottlob et al\\.",
      "year" : 2014
    }, {
      "title" : "Stable model semantics for guarded existential rules and description logics",
      "author" : [ "G. Gottlob", "A. Hernich", "C. Kupke", "T. Lukasiewicz" ],
      "venue" : "In Principles of Knowledge Representation and Reasoning: Proceedings of the Fourteenth International Conference,",
      "citeRegEx" : "Gottlob et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Gottlob et al\\.",
      "year" : 2014
    }, {
      "title" : "Combining decidability paradigms for existential rules",
      "author" : [ "G. Gottlob", "M. Manna", "A. Pieris" ],
      "venue" : "Theory and Practice of Logic Programming,",
      "citeRegEx" : "Gottlob et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Gottlob et al\\.",
      "year" : 2013
    }, {
      "title" : "Expressiveness of guarded existential rule languages",
      "author" : [ "G. Gottlob", "S. Rudolph", "M. Simkus" ],
      "venue" : "In Proceedings of the 33rd ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, PODS’14, Snowbird, UT,",
      "citeRegEx" : "Gottlob et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Gottlob et al\\.",
      "year" : 2014
    }, {
      "title" : "Data complexity of reasoning in very expressive description logics",
      "author" : [ "U. Hustadt", "B. Motik", "U. Sattler" ],
      "venue" : "Proc. 19th Int. Joint Conf. on Artificial Intelligence",
      "citeRegEx" : "Hustadt et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Hustadt et al\\.",
      "year" : 2005
    }, {
      "title" : "Testing containment of conjunctive queries under functional and inclusion dependencies",
      "author" : [ "D. Johnson", "A. Klug" ],
      "venue" : "J. Comput. Syst. Sci.,",
      "citeRegEx" : "Johnson and Klug,? \\Q1984\\E",
      "shortCiteRegEx" : "Johnson and Klug",
      "year" : 1984
    }, {
      "title" : "Saying it with Pictures: a logical landscape of conceptual graphs",
      "author" : [ "G. Kerdiles" ],
      "venue" : "Ph.D. thesis, Univ. Montpellier II / Amsterdam.",
      "citeRegEx" : "Kerdiles,? 2001",
      "shortCiteRegEx" : "Kerdiles",
      "year" : 2001
    }, {
      "title" : "Sound, complete and minimal ucq-rewriting for existential rules",
      "author" : [ "M. König", "M. Leclère", "M. Mugnier", "M. Thomazo" ],
      "venue" : null,
      "citeRegEx" : "König et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "König et al\\.",
      "year" : 2014
    }, {
      "title" : "The combined approach to query answering in DL-lite",
      "author" : [ "R. Kontchakov", "C. Lutz", "D. Toman", "F. Wolter", "M. Zakharyaschev" ],
      "venue" : "In Principles of Knowledge Representation and Reasoning: Proceedings of the Twelfth International Conference,",
      "citeRegEx" : "Kontchakov et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Kontchakov et al\\.",
      "year" : 2010
    }, {
      "title" : "Extending Decidable Existential Rules by Joining Acyclicity and Guardedness",
      "author" : [ "M. Krötzsch", "S. Rudolph" ],
      "venue" : "IJCAI",
      "citeRegEx" : "Krötzsch and Rudolph,? \\Q2011\\E",
      "shortCiteRegEx" : "Krötzsch and Rudolph",
      "year" : 2011
    }, {
      "title" : "A better uncle for owl: nominal schemas for integrating rules and ontologies",
      "author" : [ "M. Krötzsch", "F. Maier", "A. Krisnadhi", "P. Hitzler" ],
      "venue" : "Proceedings of the 20th International Conference on World Wide Web,",
      "citeRegEx" : "Krötzsch et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Krötzsch et al\\.",
      "year" : 2011
    }, {
      "title" : "Nominal schemas in description logics: Complexities clarified",
      "author" : [ "M. Krötzsch", "S. Rudolph" ],
      "venue" : "Principles of Knowledge",
      "citeRegEx" : "Krötzsch and Rudolph,? \\Q2014\\E",
      "shortCiteRegEx" : "Krötzsch and Rudolph",
      "year" : 2014
    }, {
      "title" : "Complexity Boundaries for Horn Description Logics",
      "author" : [ "M. Krötzsch", "S. Rudolph", "P. Hitzler" ],
      "venue" : "In Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence, July 22-26,",
      "citeRegEx" : "Krötzsch et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Krötzsch et al\\.",
      "year" : 2007
    }, {
      "title" : "Complexities of Horn description logics",
      "author" : [ "M. Krötzsch", "S. Rudolph", "P. Hitzler" ],
      "venue" : "ACM Trans. Comput. Logic,",
      "citeRegEx" : "Krötzsch et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Krötzsch et al\\.",
      "year" : 2013
    }, {
      "title" : "CARIN: A representation language combining Horn rules and description logics",
      "author" : [ "A.Y. Levy", "Rousset", "M.-C" ],
      "venue" : "In Proceedings of the 12th European Conference on Artificial Intelligence (ECAI",
      "citeRegEx" : "Levy et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Levy et al\\.",
      "year" : 1996
    }, {
      "title" : "Inverse roles make conjunctive queries hard",
      "author" : [ "C. Lutz" ],
      "venue" : "Proceedings of the 2007 International Workshop on Description Logics (DL2007), CEUR-WS.",
      "citeRegEx" : "Lutz,? 2007",
      "shortCiteRegEx" : "Lutz",
      "year" : 2007
    }, {
      "title" : "Conjunctive Query Answering in the Description Logic EL Using a Relational Database System",
      "author" : [ "C. Lutz", "D. Toman", "F. Wolter" ],
      "venue" : "IJCAI",
      "citeRegEx" : "Lutz et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Lutz et al\\.",
      "year" : 2009
    }, {
      "title" : "The Theory of Relational Databases",
      "author" : [ "D. Maier" ],
      "venue" : "Computer Science Press.",
      "citeRegEx" : "Maier,? 1983",
      "shortCiteRegEx" : "Maier",
      "year" : 1983
    }, {
      "title" : "Testing implications of data dependencies",
      "author" : [ "D. Maier", "A.O. Mendelzon", "Y. Sagiv" ],
      "venue" : "ACM Trans. Database Syst.,",
      "citeRegEx" : "Maier et al\\.,? \\Q1979\\E",
      "shortCiteRegEx" : "Maier et al\\.",
      "year" : 1979
    }, {
      "title" : "OWL 2 Web Ontology Language: Profiles",
      "author" : [ "B. Motik", "B. Cuenca Grau", "I. Horrocks", "Z. Wu", "A. Fokoue", "C. Lutz" ],
      "venue" : null,
      "citeRegEx" : "Motik et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Motik et al\\.",
      "year" : 2009
    }, {
      "title" : "Representing ontologies using description logics, description graphs, and rules",
      "author" : [ "B. Motik", "B.C. Grau", "I. Horrocks", "U. Sattler" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "Motik et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Motik et al\\.",
      "year" : 2009
    }, {
      "title" : "Query answering for OWL DL with rules",
      "author" : [ "B. Motik", "U. Sattler", "R. Studer" ],
      "venue" : "Journal of Web Semantics,",
      "citeRegEx" : "Motik et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Motik et al\\.",
      "year" : 2005
    }, {
      "title" : "Worst-case optimal reasoning for the HornDL fragments of OWL 1 and 2",
      "author" : [ "M. Ortiz", "S. Rudolph", "M. Simkus" ],
      "venue" : null,
      "citeRegEx" : "Ortiz et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Ortiz et al\\.",
      "year" : 2010
    }, {
      "title" : "Query answering in the Horn fragments of the description logics SHOIQ and SROIQ",
      "author" : [ "M. Ortiz", "S. Rudolph", "M. Simkus" ],
      "venue" : "IJCAI/AAAI",
      "citeRegEx" : "Ortiz et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Ortiz et al\\.",
      "year" : 2011
    }, {
      "title" : "Linking data to ontologies",
      "author" : [ "A. Poggi", "D. Lembo", "D. Calvanese", "G. De Giacomo", "M. Lenzerini", "R. Rosati" ],
      "venue" : "J. Data Semantics,",
      "citeRegEx" : "Poggi et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Poggi et al\\.",
      "year" : 2008
    }, {
      "title" : "Complexity of the two-variable fragment with counting quantifiers",
      "author" : [ "I. Pratt-Hartmann" ],
      "venue" : "Journal of Logic, Language and Information, 14, 369–395.",
      "citeRegEx" : "Pratt.Hartmann,? 2005",
      "shortCiteRegEx" : "Pratt.Hartmann",
      "year" : 2005
    }, {
      "title" : "Foundations of description logics",
      "author" : [ "S. Rudolph" ],
      "venue" : "Polleres, A., d’Amato, C., Arenas, M., Handschuh, S., Kroner, P., Ossowski, S., & Patel-Schneider, P. F. (Eds.), Reasoning Web, Vol. 6848 of Lecture Notes in Computer Science, pp. 76–136. Springer.",
      "citeRegEx" : "Rudolph,? 2011",
      "shortCiteRegEx" : "Rudolph",
      "year" : 2011
    }, {
      "title" : "The two views on ontological query answering",
      "author" : [ "S. Rudolph" ],
      "venue" : "Gottlob, G., & Pérez, J. (Eds.), Proceedings of the 8th Alberto Mendelzon Workshop on Foundations of Data Management, Vol. 1189 of CEUR Workshop Proceedings. CEUR-WS.org.",
      "citeRegEx" : "Rudolph,? 2014",
      "shortCiteRegEx" : "Rudolph",
      "year" : 2014
    }, {
      "title" : "Nominals, inverses, counting, and conjunctive queries or: Why infinity is your friend",
      "author" : [ "S. Rudolph", "B. Glimm" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Rudolph and Glimm,? \\Q2010\\E",
      "shortCiteRegEx" : "Rudolph and Glimm",
      "year" : 2010
    }, {
      "title" : "Type-elimination-based reasoning for the description logic",
      "author" : [ "S. Rudolph", "M. Krötzsch", "P. Hitzler" ],
      "venue" : null,
      "citeRegEx" : "Rudolph et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Rudolph et al\\.",
      "year" : 2012
    }, {
      "title" : "Sound and Complete Forward and Backward Chainings of Graph Rules",
      "author" : [ "E. Salvat", "Mugnier", "M.-L" ],
      "venue" : "4th International Conference on Conceptual Structures, ICCS ’96,",
      "citeRegEx" : "Salvat et al\\.,? \\Q1996\\E",
      "shortCiteRegEx" : "Salvat et al\\.",
      "year" : 1996
    }, {
      "title" : "First-order logic",
      "author" : [ "R.M. Smullyan" ],
      "venue" : "Dover books on mathematics. Dover.",
      "citeRegEx" : "Smullyan,? 1968",
      "shortCiteRegEx" : "Smullyan",
      "year" : 1968
    }, {
      "title" : "Conjunctive Query Answering Under Existential Rules—Decidability, Complexity, and Algorithms",
      "author" : [ "M. Thomazo" ],
      "venue" : "Ph.D. thesis, Univ. Montpellier 2.",
      "citeRegEx" : "Thomazo,? 2013",
      "shortCiteRegEx" : "Thomazo",
      "year" : 2013
    }, {
      "title" : "A generic querying algorithm for greedy sets of existential rules",
      "author" : [ "M. Thomazo", "Baget", "J.-F", "Mugnier", "M.-L", "S. Rudolph" ],
      "venue" : "In Principles of Knowledge Representation and Reasoning: Proceedings of the Thirteenth International Conference,",
      "citeRegEx" : "Thomazo et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Thomazo et al\\.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 55,
      "context" : "In the Semantic Web area, one of the most prominent fields where KR technology is practically applied, ontological knowledge is often represented by means of formalisms based on description logics (DLs, (Baader, Calvanese, McGuinness, Nardi, & Patel-Schneider, 2007; Rudolph, 2011)).",
      "startOffset" : 203,
      "endOffset" : 281
    }, {
      "referenceID" : 3,
      "context" : "Consequently, conjunctive query answering has been particularly studied on less expressive DLs, such as DL-Lite (Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2007) and EL (Baader, 2003; Lutz, Toman, & Wolter, 2009).",
      "startOffset" : 177,
      "endOffset" : 220
    }, {
      "referenceID" : 20,
      "context" : ", 2007), it has been shown that this covering by a Datalog± fragment is done without increasing complexity (Cal̀ı et al., 2009).",
      "startOffset" : 107,
      "endOffset" : 127
    }, {
      "referenceID" : 6,
      "context" : "Three “abstract” classes have been introduced in (Baget et al., 2010) to describe known decidable behaviors: an obvious condition of decidability is the finiteness of the forward chaining (known as the chase in the TGD framework (Maier, Mendelzon, & Sagiv, 1979; Johnson & Klug, 1984; Beeri & Vardi, 1984)); sets of rules ensuring this condition are called finite expansion sets (fes); a more general condition introduced in (Cal̀ı et al.",
      "startOffset" : 49,
      "endOffset" : 69
    }, {
      "referenceID" : 16,
      "context" : ", 2010) to describe known decidable behaviors: an obvious condition of decidability is the finiteness of the forward chaining (known as the chase in the TGD framework (Maier, Mendelzon, & Sagiv, 1979; Johnson & Klug, 1984; Beeri & Vardi, 1984)); sets of rules ensuring this condition are called finite expansion sets (fes); a more general condition introduced in (Cal̀ı et al., 2008) accepts infinite forward chaining provided that the facts generated have a bounded treewidth (when seen as graphs); such sets of rules are called bounded-treewidth sets (bts); then decidability follows from the decidability of first-order logic (FOL) classes with the bounded-treewidth model property (Courcelle, 1990).",
      "startOffset" : 363,
      "endOffset" : 383
    }, {
      "referenceID" : 26,
      "context" : ", 2008) accepts infinite forward chaining provided that the facts generated have a bounded treewidth (when seen as graphs); such sets of rules are called bounded-treewidth sets (bts); then decidability follows from the decidability of first-order logic (FOL) classes with the bounded-treewidth model property (Courcelle, 1990).",
      "startOffset" : 309,
      "endOffset" : 326
    }, {
      "referenceID" : 6,
      "context" : ", the problem of deciding whether a given set of rules is fes , bts , or fus is undecidable (Baget et al., 2010).",
      "startOffset" : 92,
      "endOffset" : 112
    }, {
      "referenceID" : 16,
      "context" : "Guarded (g) rules (Cal̀ı et al., 2008) are inspired by the guarded fragment of FOL (Andréka, van Benthem, & Németi, 1996; Andréka, Németi, & van Benthem, 1998).",
      "startOffset" : 18,
      "endOffset" : 38
    }, {
      "referenceID" : 16,
      "context" : "They are generalized by weakly guarded rules (wg), in which the guarding condition is relaxed: only so-called “affected” variables need to be guarded; intuitively, affected variables are variables that are possibly mapped, during the forward chaining process, to newly created variables (Cal̀ı et al., 2008).",
      "startOffset" : 287,
      "endOffset" : 307
    }, {
      "referenceID" : 7,
      "context" : "In a frontier-one rule (fr1), the frontier is restricted to a single variable (Baget et al., 2009).",
      "startOffset" : 78,
      "endOffset" : 98
    }, {
      "referenceID" : 6,
      "context" : "In a frontier-guarded rule (fg), an atom in the body guards the frontier (Baget et al., 2010).",
      "startOffset" : 73,
      "endOffset" : 93
    }, {
      "referenceID" : 6,
      "context" : "When requiring only affected variables from the frontier to be guarded, we obtain the still decidable class of weakly frontier-guarded rules (wfg), which generalizes both fg and wg classes (Baget et al., 2010).",
      "startOffset" : 189,
      "endOffset" : 209
    }, {
      "referenceID" : 8,
      "context" : "This article is an extended version of two papers published at IJCAI 2011 (Baget et al., 2011) and KR 2012 (Thomazo, Baget, Mugnier, & Rudolph, 2012), respectively.",
      "startOffset" : 74,
      "endOffset" : 94
    }, {
      "referenceID" : 61,
      "context" : "It provides detailed proofs of the results presented in these conference papers and benefits from further clarifications concerning the gbts algorithm, stemming from Michaël Thomazo’s PhD thesis (Thomazo, 2013).",
      "startOffset" : 195,
      "endOffset" : 210
    }, {
      "referenceID" : 47,
      "context" : "Forward chaining (with existential rules) is known as the chase (with TGDs) (Maier et al., 1979; Aho, Beeri, & Ullman, 1979).",
      "startOffset" : 76,
      "endOffset" : 124
    }, {
      "referenceID" : 16,
      "context" : "The entailment problem is decidable when R is bts (Cal̀ı et al., 2008; Baget et al., 2011).",
      "startOffset" : 50,
      "endOffset" : 90
    }, {
      "referenceID" : 8,
      "context" : "The entailment problem is decidable when R is bts (Cal̀ı et al., 2008; Baget et al., 2011).",
      "startOffset" : 50,
      "endOffset" : 90
    }, {
      "referenceID" : 26,
      "context" : "of the satisfiability problem for classes of first-order formulas having the bounded-treewidth property, a result from Courcelle (Courcelle, 1990).",
      "startOffset" : 129,
      "endOffset" : 146
    }, {
      "referenceID" : 28,
      "context" : "The notion of affected variable is relative to the rule set: a variable is affected if it occurs only in affected predicate positions, which are positions that may contain an existential variable generated by forward chaining (Fagin et al., 2005).",
      "startOffset" : 226,
      "endOffset" : 246
    }, {
      "referenceID" : 7,
      "context" : "Because, for example, their graph of rule dependency is acyclic (Baget et al., 2009)",
      "startOffset" : 64,
      "endOffset" : 84
    }, {
      "referenceID" : 16,
      "context" : "Indeed, the problem is already known to be 2ExpTime-hard, since guarded rules - whose 2ExpTime combined complexity was already shown (Cal̀ı et al., 2008), are a particular case of gbts rules.",
      "startOffset" : 133,
      "endOffset" : 153
    }, {
      "referenceID" : 16,
      "context" : "Lower bounds for data complexity come from already known complexity results of weakly-guarded rules (Cal̀ı et al., 2008), for instance.",
      "startOffset" : 100,
      "endOffset" : 120
    }, {
      "referenceID" : 42,
      "context" : "Theorem 29 ((Krötzsch et al., 2013), Section 6.",
      "startOffset" : 12,
      "endOffset" : 35
    }, {
      "referenceID" : 44,
      "context" : "Our proof reuses the general strategy and many technical tricks from a construction used to show 2ExpTime-hardness for CQ entailment in the DLALCI from (Lutz, 2007).",
      "startOffset" : 152,
      "endOffset" : 164
    }, {
      "referenceID" : 6,
      "context" : "To simplify the next notions, we first proceed with some normalization of a set of fg rules, such that all rules have an empty frontier (so-called “disconnected rules” (Baget et al., 2010)) or a “variable-connected” body:",
      "startOffset" : 168,
      "endOffset" : 188
    }, {
      "referenceID" : 6,
      "context" : "The rules in Rdisc are integrated into F as described in (Baget et al., 2010), which can be performed with",
      "startOffset" : 57,
      "endOffset" : 77
    }, {
      "referenceID" : 35,
      "context" : "Let us point out that a set of atoms is acyclic according to the above definition if and only if the associated existentially closed conjunctive formula belongs to the guarded fragment of first-order logic (see acyclic guarded covering in (Kerdiles, 2001) and (Chein &",
      "startOffset" : 239,
      "endOffset" : 255
    }, {
      "referenceID" : 46,
      "context" : "Given a set of atoms S, checking whether it is acyclic, and if so, outputing one of its acyclic coverings can be performed in linear time (from (Maier, 1983) about the computation of a join tree in databases).",
      "startOffset" : 144,
      "endOffset" : 157
    }, {
      "referenceID" : 54,
      "context" : "More complex notions of types may refer to more than just one individual, leading to notions like 2-types, also known as dominoes (Rudolph, Krötzsch, & Hitzler, 2012), star-types (Pratt-Hartmann, 2005), mosaics (Blackburn, van Benthem, & Wolter, 2006), or types based on trees (Rudolph & Glimm, 2010).",
      "startOffset" : 179,
      "endOffset" : 201
    }, {
      "referenceID" : 13,
      "context" : "It is well-known that the chase known from databases has many commonalities with the semantic tableau method in FOL (Beth, 1955; Smullyan, 1968), which has also been used in many other logics, most notably DLs (Baader & Sattler, 2001; Horrocks & Sattler, 2007).",
      "startOffset" : 116,
      "endOffset" : 144
    }, {
      "referenceID" : 60,
      "context" : "It is well-known that the chase known from databases has many commonalities with the semantic tableau method in FOL (Beth, 1955; Smullyan, 1968), which has also been used in many other logics, most notably DLs (Baader & Sattler, 2001; Horrocks & Sattler, 2007).",
      "startOffset" : 116,
      "endOffset" : 144
    }, {
      "referenceID" : 8,
      "context" : "In (Baget et al., 2011), conditions expressed on the strongly connected components of a graph of rule dependencies allow to combine gbts , fes and fus sets of rules.",
      "startOffset" : 3,
      "endOffset" : 23
    }, {
      "referenceID" : 45,
      "context" : "The combined approach (Lutz et al., 2009; Kontchakov, Lutz, Toman, Wolter, & Zakharyaschev, 2010), designed for EL and the DL-Lite familly, share some similarities with our approach.",
      "startOffset" : 22,
      "endOffset" : 97
    } ],
    "year" : 2014,
    "abstractText" : "The need for an ontological layer on top of data, associated with advanced reasoning mechanisms able to exploit the semantics encoded in ontologies, has been acknowledged both in the database and knowledge representation communities. We focus in this paper on the ontological query answering problem, which consists of querying data while taking ontological knowledge into account. More specifically, we establish complexities of the conjunctive query entailment problem for classes of existential rules (also called tuplegenerating dependencies, Datalog± rules, or ∀∃-rules). Our contribution is twofold. First, we introduce the class of greedy bounded-treewidth sets (gbts) of rules, which covers guarded rules, and their most well-known generalizations. We provide a generic algorithm for query entailment under gbts , which is worst-case optimal for combined complexity with or without bounded predicate arity, as well as for data complexity and query complexity. Secondly, we classify several gbts classes, whose complexity was unknown, with respect to combined complexity (with both unbounded and bounded predicate arity) and data complexity to obtain a comprehensive picture of the complexity of existential rule fragments that are based on diverse guardedness notions. Upper bounds are provided by showing that the proposed algorithm is optimal for all of them. ∗. This work has been partially realized while S. Rudolph was working at AIFB, KIT, Germany and M. Thomazo was a Ph.D. student at University Montpellier 2 1 ar X iv :1 41 2. 44 85 v1 [ cs .A I] 1 5 D ec 2 01 4 Rudolph, Thomazo, Baget, & Mugnier",
    "creator" : "TeX"
  }
}