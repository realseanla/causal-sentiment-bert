{
  "name" : "1602.06052.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Strong Backdoors for Default Logic",
    "authors" : [ "Johannes K. Fichte", "Arne Meier", "Irina Schindler" ],
    "emails" : [ "jfichte@dbai.tuwien.ac.at", "meier.schindler@thi.uni-hannover.de" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 2.\n06 05\n2v 1\n[ cs\n.L O\n] 1\n9 Fe\nb 20"
    }, {
      "heading" : "1 Introduction",
      "text" : "In the area of non-monotonic logic one aims to find formalisms that model human-sense reasoning. It turned out that this kind of reasoning is quite different from classical deductive reasoning as in the classical approach the addition of information always leads to an increase of derivable knowledge. Yet, intuitively, human-sense reasoning does not work in that way: the addition of further facts might violate previous assumptions and can therefore significantly decrease the amount of derivable conclusions. Hence, in contrast to the classical process the behaviour of human-sense reasoning is non-monotonic. In the 1980s, several kinds of formalisms have been introduced, most notably, circumscription [27], default logic [34], autoepistemic logic [30], and non-monotonic logic [28]. A good introduction into this field is given by Marek and Truszczynśki [26].\nIn this paper, we focus on Reiter’s Default Logic (DL), which has been introduced in 1980 [34] and is one of the most fundamental formalism for modelling human-sense reasoning. DL extends the usual logical derivations by rules of default assumptions (default rules). Informally, default rules follow the format “in the absence of contrary information, assume . . .”. Technically, these patterns are taken up in triples of formulas α:β\nγ , which express “if prerequisite α can be deduced and justification β is never\nviolated then assume conclusion γ”. Default rules can be used to enrich calculi in different kinds of logics. Here, we consider a variant of propositional formulas, namely, formulas in conjunctive normal form (cnf). A key concept of DL is that an application of default rules must not lead to an inconsistency if conflicting rules are present, instead such rules should be avoided if possible. This concept results in the notion of stable extensions, which can be seen as a maximally consistent view of an agent with respect to his knowledge base together in combination with its set of default rules. The corresponding decision problem, i.e., the extension existence problem, then asks whether a given default theory has a consistent stable extension, and is the problem of our interest. The computationally hard part of this problem lies in the detection of the order and “applicability” of default rules, which is a quite challenging task as witnessed by its Σp2-completeness. In 1992, Gottlob showed that many important decision problems, beyond the extension existence problem, of non-monotonic logics are complete for the second level of the polynomial hierarchy [22] and thus are of high intractability.\nA prominent approach to understand the intractability of a problem is to use the framework of parameterised complexity, which was introduced by Downey and Fellows [12, 11]. The main idea of parameterised complexity is to fix a certain structural property (the parameter) of a problem instance and to consider the computational complexity of the problem in dependency of the parameter. Then ideally, the complexity drops and the problem becomes solvable in polynomial time when the parameter is fixed. Such problems are called fixed-parameter tractable and the corresponding parameterised complexity class, which contains all fixed-parameter tractable problems, is called FPT. For instance, for the propositional satisfiability problem (Sat) one (näıve) parameter is the number of variables of the given formula. Then, for a given formula ϕ of size n and k variables its satisfiability can be decided in time O(n · 2k), i.e., polynomial (even linear) runtime in n if k is considered to be fixed.\nThe invention of new parameters can be quite challenging, however, Sat has so far been considered under many different parameters [41, 36, 5, 31]. A concept that provides a parameter and has been widely used in theoretical investigations of propositional satisfiability are backdoors [42, 21, 25]. The size of a backdoor can be seen as a parameter with which one tries to exploit a small distance of a formula from being tractable. More detailed, given a class F of formulas and a formula ϕ, a subset B of its variables is a strong F-backdoor if the formula ϕ under every truth assignment over B yields a formula that belongs to the class F . Using backdoors usually consists of two phases: (i) finding a backdoor (backdoor detection) and (ii) using the backdoor to solve the problem (backdoor evaluation). If F is a class where Sat is tractable and backdoor detection is fixed-parameter tractable for this class, like the class of all Horn or Krom formulas, we can immediately conclude that Sat is fixed-parameter tractable when parameterised by the size of a smallest strong F -backdoor.\nRelated Work. Backdoors for propositional satisfiability have been introduced by Williams, Gomes, and Selman [42, 43]. The concept of backdoors has recently been lifted to some non-monotonic formalisms as abduction [33], answer set programming [18, 17], and argumentation [13]. Beyond the classification of Gottlob [22], the complexity of fragments, in the sense of Post’s lattice, has been considered by Beyersdorff et al. extensively for default logic [2], and for autoepistemic logic by Creignou et al. [9]. Also parameterised analyses of non-monotonic logics in the spirit of Courcelle’s theorem [7, 8] have recently been considered by Meier et al. [29]. Further, Gottlob et al. studied treewidth as a parameter for various non-monotonic logics [23] and also considered a more CSP focused non-monotonic context within the parameterised complexity setting [24].\nContribution. In this paper, we introduce a notion of backdoors to propositional default logic and study structural properties therein. Then we investigate the parameterised complexity of the problems of backdoor detection (parameterised by the solution size) and evaluation (parameterised by the size of the given backdoor), with respect to the most important classes of CNF formulas, e.g., cnf, krom, horn, monotone, and positive-unit. Informally, given a formula ϕ and an integer k, the detection problem asks whether there exists a backdoor of size k for ϕ. Backdoor evaluation then exploits the distance k for a target formula class to solve the problem for the starting formula class with a “simpler” complexity. Our classification shows that detection is fixed-parameter tractable for all considered target classes. However, for backdoor evaluation starting at cnf the parameterised complexity depends, as expected, on the target class: the parameterised complexity then varies between para-∆p2 (monotone), para-NP (krom,horn), and FPT (positive-unit)."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "We assume familiarity with standard notions in computational complexity, the complexity classes P and NP as well as the polynomial hierarchy. For more detailed information, we refer to other standard sources [32, 20, 12].\nParameterised Complexity. We follow the notion by Flum and Grohe [19]. A parameterised (decision) problem L is a subset of Σ∗ ×N for some finite alphabet Σ. Let C be a classical complexity class,\nthen para-C consists of all parameterised problems L ⊆ Σ∗ × N, for which there exists an alphabet Σ′, a computable function f : N → Σ′∗, and a (classical) problem L′ ⊆ Σ∗ × Σ′∗ such that (i) L′ ∈ C, and (ii) for all instances (x, k) ∈ Σ∗ × N of L we have (x, k) ∈ L if and only if (x, f(k)) ∈ L′. For the complexity class P, we write FPT instead of para-P. We call a problem in FPT fixed-parameter tractable and the runtime f(k) · |x|O(1) also fpt-time. Additionally, the parameterised counterparts of NP and ∆p2 = P NP, which are denoted by para-NP and para-∆p2 , are relevant in this paper.\nPropositional Logic. Next, we provide some notions from propositional logic. We consider a finite set of propositional variables and use the symbols ⊤ and ⊥ in the standard way. A literal is a variable x (positive literal) or its negation ¬x (negative literal). A clause is a finite set of literals, interpreted as the disjunction of these literals. A propositional formula in conjunctive normal form (CNF) is a finite set of clauses, interpreted as the conjunction of its clauses. We denote the class of all CNF formulas by cnf. A clause is Horn if it contains at most one positive literal, Krom if it contains two literals, monotone if it contains only positive literals, and positive-unit if it contains at most one positive literal. We say that a CNF formula has a certain property if all its clause have the property. We consider several classes of formulas in this paper. Table 1 gives an overview on these classes and defines clause forms for these classes.\nA formula ϕ′ is a subformula of a cnf formula ϕ (in symbols ϕ′ ⊆ ϕ) if for each clause C′ ∈ ϕ′ there is some clause C ∈ ϕ such that C′ ⊆ C. We call a class F of cnf formulas clause-induced if whenever F ∈ F , all subformulas F ′ ⊆ F belong to F . Note that all considered target classes in this paper are clause-induced.\nGiven a formula ϕ ∈ cnf, and a subsetX ⊆ Vars(ϕ), then a (truth) assignment is a mapping θ : X → {0, 1}. The truth (evaluation) of propositional formulas is defined in the standard way, in particular, θ(⊥) = 0 and θ(⊤) = 1. We extend θ to literals by setting θ(¬x) = 1 − θ(x) for x ∈ X . By A(X) we denote the set of all assignments θ : X → {0, 1}. For simplicity of presentation, we sometimes identify the set of all assignments by its corresponding literals, i.e., A(X) = { {ℓ1, . . . , ℓ|X|} | x ∈ X, ℓi ∈ {x,¬x} }. We write ϕ[θ] for the reduct of ϕ where every literal ℓ ∈ X is replaced by ⊤ if θ(ℓ) = 1, then all clauses that contain a literal ℓ with θ(ℓ) = 1 are removed and from the remaining clauses all literals ℓ′ with θ(ℓ′) = 0 are removed. We say θ satisfies ϕ if ϕ[θ] ≡ ⊤, ϕ is satisfiable if there exists an assignment that satisfies ϕ, and ϕ is tautological if all assignments θ ∈ A(X) satisfy ϕ. Let ϕ, ψ ∈ cnf and X = Vars(ϕ) ∪ Vars(ψ). We write ϕ |= ψ if and only if for all assignments θ ∈ A(X) it holds that all assignments θ that satisfy ϕ also satisfy ψ. Further, we define Th(ϕ) := {ψ ∈ cnf | ϕ |= ψ }.\nNote that any assignment θ : Vars(ϕ) → {0, 1} can be also represented by the CNF formula ∧\nθ(x)=1 x ∧ ∧ θ(x)=0 ¬x. Therefore, we often write θ |= ϕ if ϕ[θ] ≡ ⊤ holds.\nWe denote with Sat(F) the problem, given a propositional formula ϕ ∈ F asking whether ϕ is satisfiable. The problem Taut(F) is defined over a given formula ϕ ∈ F asking whether ϕ tautological."
    }, {
      "heading" : "2.1 Default Logic",
      "text" : "We follow notions by Reiter [34] and define a default rule δ as a triple α:β γ ; α is called the prerequisite, β is called the justification, and γ is called the conclusion; we set prereq(δ) := α, just(δ) := β, and concl(δ) := γ. If F is a class of formulas, then α:β\nγ is an F -default rule if α, β, γ ∈ F . An F -default\ntheory 〈W,D〉 consists of a set of propositional formulas W ∈ F and a set D of F -default rules. We sometimes call W the knowledge base of 〈W,D〉. Whenever we do not explicitly state the class F , we assume it to be cnf.\nDefinition 1 (Fixed point semantics, [34]). Let 〈W,D〉 be a default theory and E be a set of formulas. Then Γ(E) is the smallest set of formulas such that:\n1. W ⊆ Γ(E),\n2. Γ(E) = Th(Γ(E)), and\n3. for each α:β γ ∈ D with α ∈ Γ(E) and ¬β /∈ E, it holds that γ ∈ Γ(E).\nE is a stable extension of 〈W,D〉, if E = Γ(E). An extension is inconsistent if it contains ⊥, otherwise it is called consistent.\nA definition for stable extensions beyond fixed point semantics, which has been introduced by Reiter [34] as well, uses the principle of a stage construction.\nProposition 1 (Stage construction, [34]). Let 〈W,D〉 be a default theory and E be a set of formulas. Then define E0 := W and\nEi+1 := Th(Ei) ∪\n{\nγ\n∣ ∣ ∣ ∣ ∣ α : β γ ∈ D,α ∈ Ei and ¬β /∈ E } .\nE is a stable extension of 〈W,D〉 if and only if E = ⋃\ni∈N Ei. The set\nG =\n{\nα : β\nγ ∈ D\n∣ ∣ ∣ ∣ ∣ α ∈ E ∧ ¬β /∈ E }\nis called the set of generating defaults. If E is a stable extension of 〈W,D〉, then E = Th(W∪{ concl(δ) | δ ∈ G }).\nExample 1. Let W = ∅, W ′ = {x}, D1 = { x:y ¬y , ¬x:y ¬y }, and D2 = { x:z ¬y , x:y ¬z }. The default theory 〈W,D1〉 has only the stable extension Th(W ). The default theory 〈{x}, D1〉 has no stable extension. The default theory 〈{x}, D2〉 has the stable extensions Th({x,¬y}) and Th({x,¬z}).\nThe following example illustrates that a default theory might contain “contradicting” default rules that cannot be avoided in the process of determining extension existence. Informally, such default rules prohibit stable extensions. Note that there are also less obvious situations where “chains” of such default rules interact with each other.\nExample 2. Consider W ′ and D2 from Example 1 and let D ′ 2 = D2 ∪ { ⊤:β ¬β } for some formula β. The default theory 〈W ′, D′2〉 has no stable extension Th(W ) unless W ∪ {¬y} |= ¬β or W ∪ {¬z} |= ¬β.\nTechnically, the definition of stable extensions allows inconsistent stable extensions. However, Marek and Truszczyński have shown that inconsistent extensions only occur if the set W is already inconsistent where 〈W,D〉 is the theory of interest [26, Corollary 3.60]. An immediate consequence of this result explains the interplay between consistency and stability of extensions more subtle: (i) If W is consistent, then every stable extension of 〈W,D〉 is consistent, and (ii) If W is inconsistent, then 〈W,D〉 has a stable extension. In Case (2) the stable extension consists of all formulas L. Hence, it makes sense to consider\nonly consistent stable extensions as the relevant ones. Moreover, we refer by SE(〈W,D〉) to the set of all consistent stable extensions of 〈W,D〉.\nA main computational problem for DL is the extension existence problem, defined as follows where F is a class of propositional formulas:\nProblem: Ext(F) Input: An F -default theory 〈W,D〉.\nQuestion: Does 〈W,D〉 have a consistent stable extension?\nThe following proposition summarises relevant results for the extension existence problem for certain classes of formulas.\nProposition 2.\n1. Ext(cnf) is Σp2-complete [22].\n2. Ext(horn) is NP-complete [39, 40].\n3. Ext(positive-unit) ∈ P [2]."
    }, {
      "heading" : "2.2 The Implication Problem",
      "text" : "The implication problem is an important (sub-)problem when reasoning with default theories. In the following, we first formally introduce the implication problem for classes of propositional formulas, and then state its (classical) computational complexity for the classes horn and krom.\nProblem: Imp(F)\nInput: A set Φ of F -formulas and a formula ψ ∈ F . Question: Does Φ |= ψ hold?\nBeyersdorff et al. [2] have considered all Boolean fragments of Imp(F) and completely classified its computational complexity concerning the framework of Post’s lattice. However, Post’s lattice talks only about restrictions on allowed Boolean functions. Since several subclasses of cnf, like horn or krom, use the Boolean functions “∧”,”¬”, and “∨”, such classes are unrestricted from the perspective of Post’s lattice. Still, efficient algorithms are known for such classes from propositional satisfiability. The next results state a similar behaviour for the implication problem.\nLemma 1. Imp(krom) ∈ P.\nProof. Given a set Φ of krom-formulas and a formula ψ ∈ krom. Without loss of generality assume that ∧\nϕ∈Φ ϕ = ∧m i=1 Ci, and ϕ = ∧n i=1 C ′ i. Then it holds that\n〈Φ, ψ〉 ∈ Imp(krom) ⇔\n(\nm ∧\ni=1\nCi,\nn ∧\ni=1\nC′i\n)\n∈ Imp(krom) (1)\n⇔\n(\nm ∧\ni=1\nCi\n)\n→\n(\nn ∧\ni=1\nC′i\n)\n∈ Taut (2)\n⇔ n ∧\ni=1\n\n\nm ∧\nj=1\nCj → C ′ i\n\n ∈ Taut (3)\n⇔ ∀ 1 ≤ i ≤ n\n\n\nm ∧\nj=1\nCj → C ′ i\n\n ∈ Taut (4)\n⇔ ¬∃ 1 ≤ i ≤ n\n\n\nm ∧\nj=1\nCj → C ′ i\n\n 6∈ Taut (5)\n(1) definition of the implication problem. (2) expressing implication through the propositional function →. (3) α → β ∧ γ is a tautology if and only if (α → β) ∧ (α → γ) is a tautology. (4) separated to separate tautology questions. (5) α ∧ β is a tautology if neither α nor β is not a tautology.\nNow, we can check the last n problems separately by\n(\nm ∧\ni=1\nCi → (ℓ ∨ ℓ ′)\n)\n6∈ Taut ⇔\n(\nm ∧\ni=1\nCi\n)\n[θ0] ∈ Sat(krom),\nwhere θ0 is the assignment such that θ0(ℓ) := 0 and θ0(ℓ ′) := 0. Observe that, if ℓ ≡∼ℓ′ then the implication on the left part of the equivalence is always a tautology.\nSimilar to the proof of Lemma 1 one can show the same complexity for the implication problem of horn formulas. However, its complexity is already known from the work by Stillman [39].\nProposition 3 ([39, Lemma 2.3]). Imp(horn) ∈ P."
    }, {
      "heading" : "3 Strong Backdoors",
      "text" : "In this section, we lift the concept of backdoors to the world of default logic. First, we review backdoors from the propositional setting [42, 43], where a backdoor is a subset of the variables of a given formula. Formally, for a class F of formulas and a formula ϕ, a strong F-backdoor is a set B of variables such that for all assignments θ ∈ A(B), it holds that ϕ[θ] ∈ F .\nBackdoors in propositional satisfiability follow the binary character of truth assignments. Each variable of a given formula is considered to be either true or false. However, reasoning in default logic has a ternary character. When we consider consistent stable extensions of a given default theory then one of the following three cases holds for some formula ϕ with respect to an extension E: (i) ϕ is contained in E, (ii) the negation ¬ϕ is contained in E, or (iii) neither ϕ nor ¬ϕ is contained in E (e.g., for the theory 〈{x}, D2〉, from Example 1, neither b nor ¬b is contained in any of the two stable extensions, where b is a variable). Since we need to weave this trichotomous point of view into a backdoor definition for default logic, the original definition of backdoors cannot immediately be transferred (from the SAT setting) to the scene of default logic. The first step is a notion of extended literals and reducts. The latter step can be seen as a generalisation of assignment functions to our setting.\nDefinition 2 (Extended literals and reducts). An extended literal is a literal or a fresh variable xε. For convenience, we further define ∼ℓ = x if ℓ = ¬x and ∼ℓ = ¬x if ℓ = x. Given a formula ϕ and an extended literal ℓ, then the reduct ρℓ(ϕ) is obtained from ϕ such that\n1. if ℓ is a literal: then all clauses that contain ℓ are deleted and all literals ∼ℓ are deleted from all clauses,\n2. if ℓ is xε: then all occurrences of literals ¬x, x are deleted from all clauses.\nLet 〈W,D〉 be a default theory and ℓ an extended literal, then\nρℓ(W,D) :=\n(\nρℓ(W ),\n{\nρℓ(α) : ρx(β)\nρℓ(γ) ∧ yi\n∣ ∣ ∣ ∣ δi = α : β\nγ ∈ D\n})\n,\nwhere yi is a fresh proposition, and ρℓ(W ) is ⋃ ω∈W ρℓ(ω).\nLater (in the proof of Lemma 4), we will see why we need the yis. In the next step, we incorporate the notion of extended literals into sets of assignments. Therefore,\nwe introduce threefold assignment sets. Let X be a set of variables, then we define\nT(X) := {{a1, . . . , a|X|} | x ∈ X and ai ∈ {x,¬x, xε}}.\nTechnically, A(X) ( T(X) holds. However, T(X) additionally contains variables xε that will behave as “don’t care” variables encompassing the trichotomous reasoning approach explained above. For Y ∈ T(X) the reduct ρY (W,D) is the consecutive application of all ρy(·) for y ∈ Y to 〈W,D〉. Observe that the order in which we apply the reducts to 〈W,D〉 is not important.\nThe following proposition states that implication of formulas is invariant under adding conjuncts of fresh variables to the premise.\nProposition 4. Let ϕ, ψ ∈ cnf be two formulas and y /∈ Vars(ϕ) ∪ Vars(ψ). Then ϕ |= ψ if and only if ϕ ∧ y |= ψ.\nNow we show that implication for cnf formulas that do not contain tautological clauses is invariant under the application of “deletion reducts” ρxε(·).\nLemma 2. Let ψ, ϕ ∈ cnf be two formulas that do not contain tautological clauses. If ψ |= ϕ, then ρxε(ψ) |= ρxε(ϕ) for every variable x ∈ Vars(ϕ) ∪ Vars(ψ).\nProof. Assume for contradiction that ρxε(ψ) 6|= ρxε(ϕ). Then there exists an assignment θ : Vars(ρxε(ψ)) ∪ Vars(ρxε(ϕ)) → {0, 1} such that θ |= ρxε(ψ) but θ 6|= ρxε(ϕ). As θ |= ρxε(ψ) every arbitrary extension of θ satisfies ψ, in particular also any extension on {x}∪Vars(ρxε(ψ))∪Vars(ρxε(ϕ)). Denote such an extension by θx. Yet, by ψ |= ϕ we get θx |= ϕ. As this holds for any arbitrary such θx the satisfiability of ϕ is independent of setting x wherefore θx |= ρxε(ϕ) as well. (Note that here it is crucial that we require ϕ contain no tautological clauses.) As x /∈ Vars(ρxε(ϕ)) holds we get θ |= ρxε(ϕ) which is a contradiction. Thus ρxε(ψ) |= ρxε(ϕ).\nThe next lemma shows that implication for cnf formulas is invariant under the application of reducts over A.\nLemma 3. Let ψ, ϕ be two cnf formulas, and X ⊆ Vars(ψ)∪Vars(ϕ). If ψ |= ϕ, then ρY (ψ) |= ρY (ϕ) holds for every set Y ∈ A(X).\nProof. Let ψ, ϕ, and X be as in the formulation of the lemma and assume that ψ |= ϕ holds. Now fix an arbitrary Y ∈ A(X) and consider every assignment τY : Vars(ρY (ψ)) ∪ Vars(ρY (ϕ)) → {0, 1}. Note that τY is defined on (Vars(ψ) ∪ Vars(ϕ)) \\ Y . Define τ ↾ Y as the assignment τ extended by setting τ(x) := 1 if x ∈ Y , and τ(x) := 0 if ¬x ∈ Y . Thus τ ↾ Y completely agrees with τ on the variables in Y .\nThen τ ↾ Y |= ¬ψ ∨ ϕ holds by assumption as ψ |= ϕ. Then by an easy induction we get τ ↾ Y |= ϕ if and only if τ |= ρY (ϕ), and τ ↾ Y |= ψ if and only if τ |= ρY (ψ). Thus we get\nτ |= ρY (ψ) ⇐⇒ τ ↾ Y |= ψ =⇒ τ ↾ Y |= ϕ ⇐⇒ τ |= ρY (ϕ)\nand the lemma follows.\nWe denote by BD-Imp(cnf → F) the parameterised version of the problem Imp(cnf) where additionally a strong F -backdoor is given and the parameter is the size of the strong F -backdoor.\nCorollary 1. Given a class F ∈ {positive-unit,horn,krom} of CNF formulas. Then BD-Imp(cnf → F) ∈ FPT.\nProof. Let W,ϕ,X be the given input instance. Then the following FPT algorithm decides the problem BD-Imp(cnf → F). For every assignment Y ∈ A(X) check if ρY (W ) |= ρY (ϕ). For the corresponding classes F these implication problems are all decidable in polynomial time; for krom see Lemma 1, for horn see Proposition 3, and positive-unit is a special case of horn. The correctness follows from Lemma 3. Hence the corollary applies.\nA combination of Lemma 2 and Lemma 3 yields a generalisation for CNF formulas that do not contain tautological clauses. Note that the crucial difference is the use of T instead of A in the claim of the result.\nCorollary 2. Let ψ, ϕ be two cnf formulas that do not contain tautological clauses, and X ⊆ Vars(E)∪ Vars(ϕ) be a set of variables. If ψ |= ϕ then for every set Y ∈ T(X) it holds ρY (ψ) |= ρY (ϕ).\nThe following lemma is an important cornerstone for the upcoming section. It intuitively states that we do not loose any stable extensions under the application of reducts. Before we can start with the lemma we need to introduce a bit of notion. For a set D = {δ1, . . . , δn} of default rules and a set E of formulas we define y-concl(D,E) := {concl(δi) | 1 ≤ i ≤ n, δi ∈ D,E |= yi}, that is, the set of conclusions of default rules δi such that yi is implied by all formulas in E. Further, for a set X of variables, we will extend the notion for SE(·) as follows:\nSE(〈W,D〉 , X) := ⋃\nY ∈T(X)\n{Th(W ∪ y-concl(D,E)) | E ∈ SE(ρY (W,D))}.\nLemma 4. Let 〈W,D〉 be a cnf default theory with formulas that do not contain tautological clauses, and X be a set of variables from Vars(W,D). Then SE(〈W,D〉) ⊆ SE(〈W,D〉 , X).\nProof. Let 〈W,D〉 be the given default theory, X ⊆ Vars(W,D), and E ∈ SE(〈W,D〉) be a consistent stable extension of 〈W,D〉.\nNow suppose for contradiction that E /∈ SE(〈W,D〉 , X). Further, let G be the set of generating defaults of E by Proposition 1, and w.l.o.g. let G := {δ1, . . . , δk} also denote the order in which these defaults are applied. Thus it holds that E = Th(W ∪{concl(δ) | δ ∈ G}). Hence, W |= prereq(δ1) holds and further fix a Y ∈ T(X) which agrees with E on the implied literals from Vars(W,D), i.e., x ∈ Y if E |= x for x ∈ Vars(W,D), ¬x ∈ Y if |= ¬x, and xε ∈ Y otherwise. Then, by Corollary 2 we know that also ∧\nω∈W ρY (ω) |= ρY (prereq(δ1)) is true. Furthermore, we get that\n∧\nω∈W\nρY (ω) ∧ ∧\n1≤j≤i\nρY (concl(δj)) |= ρY (prereq(δi+1))\nholds for i < k. Thus, by definition of ρY (W,D), the reducts of the knowledge base W and the derived conclusions together trivially imply the yis, i.e., it holds that\n∧\nω∈W\nρY (ω) ∧ ∧\n1≤i≤k\nρY (concl(δi)) |= ∧\n1≤i≤k\nyi.\nAs neither E |= prereq(δ) holds for some δ ∈ D \\G, nor E ∪ {concl(δ) | δ ∈ G} |= δ′ is true for some δ′ ∈ D \\ G, E is a consistent set, and Y agrees with E on the implied variables from Vars(W,D), we get that no further default rule δ is triggered by ρY (W ) or ρY (W ∪ {concl(δ) | δ ∈ D \\G}).\nFurther, it holds that no justification is violated as E |= ¬β for some β ∈ ⋃\nδ∈G just(δ) would imply that ρY (E) |= ¬ρY (β) also holds by Corollary 2. Thus, eventually E′ = Th(ρY (W ) ∪ {ρY (concl(δ)) | δ ∈ G}) is a stable extension with respect to ρY (W,D). But, the set of conclusions of G coincides with y-concl(D,E′) wherefore\nE = Th(W ∪ {concl(δ) | δ ∈ G})\n= Th(W ∪ y-concl(D,E′)) ∈ SE(〈W,D〉 , X)\nholds, which contradicts our assumption. Thus, the lemma applies.\nWe have seen that it is important to disallow tautological clauses. However, the detection of this kind of clauses is possible in polynomial time. Therefore, we assume in the following that a given theory contains no tautological clauses. This is not a very weak restriction as (i) ϕ∧C ≡ ϕ for any tautological clause C, and (ii) C ≡ ⊤ for any tautological clause C.\nThe following example illustrates how reducts maintain existence of stable extensions.\nExample 3. The default theory 〈W,D〉 = {{x}, { x:y¬y∨x}} has the extension E := Th(x,¬y ∨ x) and yields the following cases for the backdoor B = {x}: ρx(W,D) = 〈{⊤}, { ⊤:z y1 }〉, yielding SE(ρx(W,D)) = {Th(y1)}, and, both, ρ¬x(W,D) and ρxε(W,D) yield an empty set of stable extensions. Thus, with y-concl(D,Th(y1)) = {¬y ∨ x} we get Th({¬y ∨ x} ∪ {x}) which is equivalent to the extension E of 〈W,D〉.\nNow, we are in the position to present a definition of strong backdoors for default logic.\nDefinition 3 (Strong Backdoors for Default Logic). Given a cnf default theory 〈W,D〉, a set B ⊆ Vars(W,D) of variables, and a class F of formulas. We say that B is a strong F -backdoor if for each Y ∈ T(B) the reduct ρY (W,D) is a F default theory."
    }, {
      "heading" : "4 Backdoor Evaluation",
      "text" : "In this section, we investigate the evaluation of strong backdoors for the extension existence problem in default logic with respect to different classes of CNF formulas. Formally, the problem of strong backdoor evaluation for extension existence is defined as follows.\nProblem: EvalExt(F → F ′) Input: An F -default theory 〈W,D〉 and a strong F ′-backdoor B ⊆ Vars(W ) ∪ Vars(D).\nParameter: The size of the backdoor B.\nQuestion: Does 〈W,D〉 have a stable extension?\nFirst, we study the complexity of the “extension checking problem”, which is a main task we need to accomplish when using backdoors as our approach following Lemma 4 yields only “stable extension candidates”. Formally, given a default theory 〈W,D〉 and a finite set Φ of formulas, EC asks whether Th(Φ) ∈ SE(〈W,D〉) holds.\nRosati [35] classified the extension checking problem as complete for the complexity class ΘP2 = ∆p2 [log], which allows only logarithmic many oracle questions to an NP oracle. For further information on the complexity class ΘP2 we refer the reader to the survey article of Eiter and Gottlob [15].We will later see that a simpler version suffices for our complexity analysis. Therefore, we state in Algorithm 1 an adaption of Rosatis algorithm [35, Figure 1] to our notation showing containment (only) in ∆p2 .\nProposition 5 ([35, Figure 1, Theorem 4]). EC ∈ ∆p2 .\nIn a way, extension checking can be compared to model checking in logic. In default logic the complexity of the extension existence problem Ext is twofold: using the approach of Proposition 1 (i) one has to non-deterministically guess the set (and ordering) of the generating defaults, and (ii) one has to verify whether the generating defaults lead to an extension. For (ii), one needs to answer quadratic many implication questions. Hence, the problem is in NPNP. Thus, a straightforward approach for EC omits the non-determinism in (i) and achieves the result in PNP.\nTheorem 1. EvalExt(cnf → horn) ∈ para-NP.\nProof. Let 〈W,D〉 be a given cnf default theory and B ⊆ Vars(W,D) be the given backdoor. In order to evaluate the backdoor we have to consider the |T(X)| = 3|B| many different reducts to horn default theories. For each of them we have to non-deterministically guess a set of generating defaults G. Then, we use Algorithm 1 to verify whether W ∧ ∧\ng∈G g is a stable extension (extensions can be represented by generating defaults; see Proposition 1). Imp(horn) ∈ P by Proposition 3. Hence, stable extension checking is in P for horn formulas. Then, after finding an extension E with respect to the reduct default theory ρY (W,D), we need to compute the corresponding extension E\n′ with respect to the original default theory. Here we just need to verify simple implication questions of the form E |= yi for 1 ≤ i ≤ |D|. Next, we need to verify whether E′ is a valid extension for 〈W,D〉 using Algorithm 1. Note that Corollary 1 shows that the implication problem of propositional formulas parameterised by the size of the backdoor is in FPT, hence we can compute the implication questions inline. As the\nAlgorithm 1: Extension checking algorithm [35, Theorem 4]\nInput: Set E of formulas and a default theory 〈W,D〉 Output: True iff E is a stable extension of 〈W,D〉\n1 D′ := ∅ 2 forall α:β γ ∈ D do // (1) Classify unviolated justifications. 3 if E 6|= ¬β then D′ := D′ ∪ {α: γ }\n// (2) Compute extension candidate of justification-free theory.\n4 E′ := W 5 while E′ did change in the last iteration do 6 forall α:\nγ ∈ D′ do\n7 if E′ |= α then E′ := E′ ∧ γ\n// (3) Does the candidate match the extension?\n8 if E |= E′ and E′ |= E then return true else return false\nAlgorithm 2: Generic algorithm for EvalExt(F → F ′)\nInput: F -default theory 〈W,D〉, backdoor B ⊆ Vars(W,D) 1 for Y ∈ T(X) do 2 construct set of generating defaults G for F ′ default theory ρY (W,D) 3 if E := ∧\nw∈ρY (W ) w ∧\n∧\nα:β γ\n∈G γ is extension for ρY (W,D) then\n4 E′ := ∧ ω∈W ω ∧ ∧ c∈y-concl(D,E′) c // always in P by construction 5 if E′ is extension for 〈W,D〉 then return true\n6 return false\nlength of the used formulas is bounded by the input size and the relevant parameter is the same as for the input this runs in fpt-time.\nTogether this yields a para-NP algorithm. Algorithm 2 depicts a generic algorithm in pseudocode.\nCorollary 3. EvalExt(cnf → krom) ∈ para-NP.\nProof. The implication problem of krom formulas is in P due to Lemma 1. Thus under a similar argumentation as in the proof of Theorem 1 we can construct a para-NP algorithm.\nCorollary 4. EvalExt(cnf → monotone) ∈ para-∆p2 .\nProof. For a monotone formula ϕ its negation is not any longer monotone unless ϕ ∈ {⊤,⊥}. This observation is important for such ϕ occurring as justifications. If ϕ /∈ {⊤,⊥} then this justification can be deleted as its negation will not be inferable whence the default rule is applicable whenever its prerequisite is met. If ϕ ∈ {⊤,⊥} then either it is only applicable in an inconsistent case or always. Hence we can distinct between these cases in polynomial time. Further observe that because of the previous argumentation there exists a unique stable extension if any. Thus the construction of the set of generating defaults and also the extension is achievable in para-∆p2 as we have to do quadratic many implication questions, and the implication problem for monotone formulas has the same upper bound as the unrestricted one, hence coNP. Step (5) of Algorithm 2 is then just uses Algorithm 2 for implication questions which are solved via the standard algorithm (which is possible as we use a para-∆p2 algorithm).\nThe following corollary shows that the consideration of backdoor evaluation for the extension existence problem starting from krom default theories is interesting.\nCorollary 5. Ext(krom) is NP-complete.\nProof. As Lemma 1 shows that Imp(krom) ∈ P we get that the extension checking problem for krom default theories is in P with the help of Proposition 5. In order to show the NP upper bound, on input 〈W,D〉 the algorithm just guesses the set of generating defaults G ⊆ D and then verifies if W ∧ ∧\nα:β γ\n∈G γ is an extension with respect to 〈W,D〉.\nFor the lower bound observe that the default theory constructed by Beyersdorff et al. [2, Lemma 5.6] consists only of krom formulas settling the lower bound by an reduction from 3Sat.\nCorollary 6. EvalExt(cnf → positive-unit) ∈ FPT.\nProof. The implication problem for positive-unit formulas is in AC0 by Beyersdorff et al. who showed this result for formulas using only conjunctions [1, Theorem 4.1(4)]. Hence, Algorithm 1 runs in polynomial time. Thus we achieve the FPT upper bound by a similar argumentation is the proof of Theorem 1."
    }, {
      "heading" : "5 Backdoor Detection",
      "text" : "In this section, we study the problem of finding backdoors, formalised in terms of the following parameterised problem:\nProblem: BdDetect(cnf → F)\nInput: A cnf default theory T and an integer k.\nParameter: The integer k.\nQuestion: Does T have a strong F -backdoor of size at most k?\nIf the target class F ′ is clause-induced, we can use a decision algorithm for BdDetect(F → F ′) to find the backdoor using self-reduction [38, 12].\nLemma 5. Let F be a clause-induced class of cnf formulas. If BdDetect(cnf → F) is fixedparameter tractable, then also computing a strong F-backdoor of size at most k of a given default theory T is fixed-parameter tractable (for parameter k).\nProof. Let T = 〈W,D〉 be a default theory. We proceed by induction on k. If k = 0 the statement is clearly true. Let k > 0. Given (T, k) we check for all v ∈ Vars(W ) ∪ Vars(D) whether ρY (W,D), ρY ′(W,D), and ρY ′′(W,D) have a strong F -backdoor of size at most k − 1 where Y = {v}, Y ′ = {¬v}, and Y ′′ = {vε}. If the answer is No for all v, then T has no strong F -backdoor of size k. If the answer is Yes for v, then by induction hypothesis we can compute a strong F -backdoor B of size at most k− 1 of ρY (W,D), ρY ′(W,D), and ρY ′′(W,D) and B ∪ {v} is a strong F -backdoor of T .\nThe following theorem provides interesting target classes, where we can determining backdoors in fpt-time.\nTheorem 2. Let C ∈ {horn, positive-unit, krom, monotone}, then BdDetect(cnf → C) ∈ FPT.\nProof. Let 〈W,D〉 be a cnf default theory and F := W ∪ { prereq(δ), just(δ), concl(δ) | δ ∈ D }. Since each class C ∈ {horn, positive-unit, krom, monotone} is clause-induced and then obviously ρZ(ϕ) ⊆ ρY (ϕ) holds for any Z ∈ T(X), we have to consider only the case Y = { xε | x ∈ X } to construct a strongC-backdoor of 〈W,D〉. Thus let Y = { xε | x ∈ X }in the following..\nC = monotone: A cnf formula ϕ is monotone if every literal appears only positively in any clause C ∈ ϕ where ϕ ∈ F. We can trivially construct a smallest strong monotone-backdoor by taking all negative literals of clauses in formulas of F in linear time. Hence, the claim holds.\nFor C ∈ {horn, positive-unit,krom} we follow known constructions from the propositional setting [36]. Therefore, we consider certain (hyper-)graph representations of the given theory and establish\nthat a set B ⊆ Vars(F) is a strong C-backdoor of 〈W,D〉 if and only if B is a d-hitting set of the respective (hyper-)graph representation of 〈W,D〉 where d depends on the class of formulas, i.e., d = 2 for horn and positive-unit and d = 3 for krom. A 2-hitting set (vertex cover) of a graph G = (V,E) is a set S ⊆ V such that for every edge uv ∈ E we have {u, v} ∩ S 6= ∅. A 3-hitting set of a hypergraph H = (V,E), with E ∈ E and |E| ≤ 3, is a set S ⊆ V such that for every hyperedge E ∈ E we have E ∩ S 6= ∅. Then, a vertex cover of size at most k, if it exists, can be found in time O(1.2738k + kn) [6] and a 3-hitting set of size at most k, if it exists, can be found in time O(2.179k + n3) [16], which gives us then a strong C-backdoor of 〈W,D〉. It remains to define the specific graph representations and to establish the connection to strong C-backdoors.\nDefinition of the various (hyper-)graphs: For C = horn we define a graph G+T on the set of variables of F, where two distinct variables x and y are joined by an edge if there is a formula ϕ ∈ F and some clause C ∈ ϕ with x, y ∈ C. For C = positive-unit we define a graph GT on the set of variables of F, where two distinct variables x and y are joined by an edge if there is a formula ϕ ∈ F and some clause C ∈ ϕ with lx, ly ∈ C where lx ∈ {x,¬x} and ly ∈ {y,¬y}. For C = krom we define a hypergraph HT on the variables Vars(F) where distinct variables x, y, z are joined by a hyperedge if there is a formula ϕ ∈ F and some clause C ∈ ϕ with {x, y, z} ⊆ Vars(C).\nNext, we establish the only-if direction of the claim: Let B ⊆ Vars(F) be a strong C-backdoor of 〈W,D〉. Consider an edge uv of G. By construction of G+T , GT , and HT there is a corresponding clause C ∈ ϕ for some formula ϕ ∈ F with u, v ∈ C. By assumption, we construct ρY (ϕ) from ϕ by deleting all occurrences of literals ¬x and x from clauses in ϕ. Since each clause in ρY (ϕ) contains at most one positive literal (horn), or only positive unit clauses (positive-unit), or at most one variable (krom), respectively, we have {u, v}∩X 6= ∅. We conclude that B is a vertex cover of G+T , vertex cover of GT , or 3-hitting set of HT , respectively, which establishes the only-if direction of the claim.\nFinally, we establish the if direction of the claim: Therefore, assume that B is a d-hitting set of the graph respective (hyper-)graph representation (d = 2 for horn and positive-unit and d = 3 for krom). Consider a clause C ∈ ρY (ϕ) for some ϕ ∈ F. For proof by contradiction assume that C is not Horn, or not positive unit, or not Krom, respectively. Then there is a set S ⊆ C (|V | = 2 for horn and positive-unit and |V | = 3 for krom) and an edge S of G such that S ∩X = ∅, contradicting the assumption that B is a vertex cover or 3-hitting set, respectively. Hence the if direction of the claim holds, which establishes the theorem.\nNow, we can use Theorem 2 to strengthen the results of Theorem 1 and Corollaries 3 and 4 by dropping the assumption that the backdoor is given.\nCorollary 7. Let C ∈ {horn, krom, monotone}, then the problem EvalExt(cnf → C) is in para-NP when parameterised by the size of a smallest strong C-backdoor of the given theory. Further, the problem EvalExt(cnf → positive-unit) is in FPT when parameterised by the size of a smallest strong positive-unit-backdoor of the given theory."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We have introduced a notion of strong backdoors for propositional default logic. In particular, we investigated on the parameterised decision problems backdoor detection and backdoor evaluation. We have established that backdoor detection for the classes cnf, horn, krom, monotone, and positive-unit are fixed-parameter tractable whereas for evaluation the classification is more complex. If cnf is the starting class and horn or krom is the target class, then backdoor evaluation is in para-NP. If monotone is the target class, then backdoor evaluation is in para-∆p2 , which is can be solved by an fptalgorithm that can query a SAT solver multiple times [10]. For positive-unit as target class backdoor evaluation is fixed-parameter tractable.\nAn interesting task for future research is to consider the remaining Schaefer classes [37], e.g., dualHorn, 1- and 0-valid, as well as the classes renamable-Horn and QHorn [3, 4], and investigate whether we can generalise Algorithm 2.We have established for backdoor evaluation the upper bounds para-NP and para-∆p2 , respectively. We think that it would also be interesting to establish corresponding lower\nbounds. Finally, a direct application of quantified Boolean formulas in the context of propositional default logic, for instance, via the work of Egly et al. [14] or exploiting backdoors similar to results by Fichte and Szeider [17], might yield new insights."
    }, {
      "heading" : "Acknowledgements",
      "text" : "The first author gratefully acknowledges support by the Austrian Science Fund (FWF), Grant Y698. He is also affiliated with the Institute of Computer Science and Computational Science at University of Potsdam, Germany. The second and third author gratefully acknowledge support by the German Research Foundation (DFG), Grant ME 4279/1-1. The authors thank Jonni Virtema for pointing out Lemma 1 and Sebastian Ordyniak for discussions on Lemma 2."
    } ],
    "references" : [ {
      "title" : "The Complexity of Propositional Implication",
      "author" : [ "Olaf Beyersdorff", "Arne Meier", "Michael Thomas", "Heribert Vollmer" ],
      "venue" : "Information Processing Letters,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2009
    }, {
      "title" : "The complexity of reasoning for fragments of default logic",
      "author" : [ "Olaf Beyersdorff", "Arne Meier", "Michael Thomas", "Heribert Vollmer" ],
      "venue" : "Journal of Logic and Computation,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2012
    }, {
      "title" : "Polynomial-time inference of all valid implications for horn and related formulae",
      "author" : [ "Endre Boros", "Yves Crama", "Peter L. Hammer" ],
      "venue" : "Ann. Math. Artif. Intell.,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1990
    }, {
      "title" : "Recognition of q-Horn formulae in linear time",
      "author" : [ "Endre Boros", "Peter L. Hammer", "Xiaorong Sun" ],
      "venue" : "Discr. Appl. Math.,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1994
    }, {
      "title" : "Tight lower bounds for certain parameterized NP-hard problems",
      "author" : [ "Jianer Chen", "Benny Chor", "Michael R. Fellows", "Xiuzhen Huang", "David W. Juedes", "Iyad A. Kanji", "Ge Xia" ],
      "venue" : "Information and Computation,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2005
    }, {
      "title" : "Improved upper bounds for vertex cover",
      "author" : [ "Jianer Chen", "Iyad A. Kanj", "Ge Xia" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2010
    }, {
      "title" : "Graph rewriting: An algebraic and logic approach",
      "author" : [ "Bruno Courcelle" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1990
    }, {
      "title" : "Graph structure and monadic second-order logic, a language theoretic approach",
      "author" : [ "Bruno Courcelle", "Joost Engelfriet" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "The complexity of reasoning for fragments of autoepistemic logic",
      "author" : [ "Nadia Creignou", "Arne Meier", "Michael Thomas", "Heribert Vollmer" ],
      "venue" : "ACM Trans. Comput. Log.,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2012
    }, {
      "title" : "Fixed-parameter tractable reductions to SAT",
      "author" : [ "Ronald DeHaan", "Stefan Szeider" ],
      "venue" : "Proceedings of the 17th International Conference on Theory and Applications of Satisfiability Testing (SAT’14),",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2014
    }, {
      "title" : "Parameterized Complexity. Monographs in Computer Science",
      "author" : [ "Rodney G. Downey", "Michael R. Fellows" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1999
    }, {
      "title" : "Fundamentals of Parameterized Complexity. Texts in Computer Science",
      "author" : [ "Rodney G. Downey", "Michael R. Fellows" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2013
    }, {
      "title" : "Augmenting tractable fragments of abstract argumentation",
      "author" : [ "Wolfgang Dvořák", "Sebastian Ordyniak", "Stefan Szeider" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2012
    }, {
      "title" : "Solving advanced reasoning tasks using quantified boolean formulas",
      "author" : [ "Uwe Egly", "Thomas Eiter", "Hans Tompits", "Stefan Woltran" ],
      "venue" : "Proceedings of the 17th Conference on Artificial Intelligence",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2000
    }, {
      "title" : "The complexity class",
      "author" : [ "Thomas Eiter", "Georg Gottlob" ],
      "venue" : "Proceedings of the 11th International Symposium on Fundamentals of Computation Theory (FCT’97),",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1997
    }, {
      "title" : "A top-down approach to search-trees: Improved algorithmics for 3-hitting",
      "author" : [ "Henning Fernau" ],
      "venue" : "set. Algorithmica,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2010
    }, {
      "title" : "Backdoors to normality for disjunctive logic programs",
      "author" : [ "Johannes K. Fichte", "Stefan Szeider" ],
      "venue" : "ACM Trans. Comput. Log.,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2015
    }, {
      "title" : "Backdoors to tractable answer-set programming",
      "author" : [ "Johannes K. Fichte", "Stefan Szeider" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2015
    }, {
      "title" : "Describing parameterized complexity classes",
      "author" : [ "Jörg Flum", "Martin Grohe" ],
      "venue" : "Information and Computation,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2003
    }, {
      "title" : "Parameterized Complexity Theory, volume XIV of Theoretical Computer Science",
      "author" : [ "Jörg Flum", "Martin Grohe" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2006
    }, {
      "title" : "Backdoors to satisfaction",
      "author" : [ "Serge Gaspers", "Stefan Szeider" ],
      "venue" : "Essays Dedicated to Michael R. Fellows on the Occasion of His 60th Birthday,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2012
    }, {
      "title" : "Complexity results for nonmonotonic logics",
      "author" : [ "Georg Gottlob" ],
      "venue" : "J. Logic Comput.,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1992
    }, {
      "title" : "Bounded treewidth as a key to tractability of knowledge representation and reasoning",
      "author" : [ "Georg Gottlob", "Reinhard Pichler", "Fang Wei" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2010
    }, {
      "title" : "Fixed-parameter complexity in AI and nonmonotonic reasoning",
      "author" : [ "Georg Gottlob", "Francesco Scarcello", "Martha Sideri" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2002
    }, {
      "title" : "Fixed-parameter algorithms for artificial intelligence, constraint satisfaction, and database problems",
      "author" : [ "Georg Gottlob", "Stefan Szeider" ],
      "venue" : "The Computer Journal,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2006
    }, {
      "title" : "Circumscription – A form of non-monotonic reasoning",
      "author" : [ "John McCarthy" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1980
    }, {
      "title" : "Non-montonic logic I",
      "author" : [ "Drew McDermott", "Jon Doyle" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1980
    }, {
      "title" : "On the parameterized complexity of non-monotonic logics",
      "author" : [ "Arne Meier", "Irina Schindler", "Johannes Schmidt", "Michael Thomas", "Heribert Vollmer" ],
      "venue" : "Archive for Mathematical Logic,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2015
    }, {
      "title" : "Semantical considerations on modal logic",
      "author" : [ "Robert C. Moore" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 1985
    }, {
      "title" : "Satisfiability of acyclic and almost acyclic CNF formulas",
      "author" : [ "Sebastian Ordyniak", "Daniel Paulusma", "Stefan Szeider" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2013
    }, {
      "title" : "Backdoors to abduction",
      "author" : [ "Andreas Pfandler", "Stefan Rümmele", "Stefan Szeider" ],
      "venue" : "Proceedings of the 23rd International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2013
    }, {
      "title" : "A logic for default reasoning",
      "author" : [ "Raymond Reiter" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 1980
    }, {
      "title" : "Model checking for nonmonotonic logics: Algorithms and complexity",
      "author" : [ "Riccardo Rosati" ],
      "venue" : "Proceedings of the 16th International Joint Conference on Artificial Intelligence (IC- JAI’99),",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 1999
    }, {
      "title" : "Fixed-parameter tractability",
      "author" : [ "Marko Samer", "Stefan Szeider" ],
      "venue" : "Handbook of Satisfiability,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2009
    }, {
      "title" : "The complexity of satisfiability problems",
      "author" : [ "Thomas J. Schaefer" ],
      "venue" : "Proceedings of the 10th Annual ACM Symposium on Theory of Computing",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 1978
    }, {
      "title" : "On self-transformable combinatorial problems",
      "author" : [ "Claus-Peter Schnorr" ],
      "venue" : "Mathematical Programming at Oberwolfach,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 1981
    }, {
      "title" : "It’s not my default: The complexity of membership problems in restricted propositional default logics",
      "author" : [ "Jonathan P. Stillman" ],
      "venue" : "Proceedings of the 8th National conference on Artificial Intelligence (AAAI’90),",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 1990
    }, {
      "title" : "The Complexity of Horn Theories with Normal Unary Defaults",
      "author" : [ "Jonathan P. Stillman" ],
      "venue" : "In Proceedings of the 8th Canadian Artificial Intelligence Conference",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 1990
    }, {
      "title" : "On fixed-parameter tractable parameterizations of SAT",
      "author" : [ "Stefan Szeider" ],
      "venue" : "Proceedings of the 6th International Conference Theory and Applications of Satisfiability (SAT’03),",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2004
    }, {
      "title" : "Backdoors to typical case complexity",
      "author" : [ "Ryan Williams", "Carla Gomes", "Bart Selman" ],
      "venue" : "Proceedings of the 18th International Joint Conference on Artificial Intelligence",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2003
    }, {
      "title" : "On the connections between backdoors, restarts, and heavy-tailedness in combinatorial search",
      "author" : [ "Ryan Williams", "Carla Gomes", "Bart Selman" ],
      "venue" : "In Informal Proceedings of the 6th International Conference on Theory and Applications of Satisfiability Testing",
      "citeRegEx" : "43",
      "shortCiteRegEx" : "43",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 25,
      "context" : "In the 1980s, several kinds of formalisms have been introduced, most notably, circumscription [27], default logic [34], autoepistemic logic [30], and non-monotonic logic [28].",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 31,
      "context" : "In the 1980s, several kinds of formalisms have been introduced, most notably, circumscription [27], default logic [34], autoepistemic logic [30], and non-monotonic logic [28].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 28,
      "context" : "In the 1980s, several kinds of formalisms have been introduced, most notably, circumscription [27], default logic [34], autoepistemic logic [30], and non-monotonic logic [28].",
      "startOffset" : 140,
      "endOffset" : 144
    }, {
      "referenceID" : 26,
      "context" : "In the 1980s, several kinds of formalisms have been introduced, most notably, circumscription [27], default logic [34], autoepistemic logic [30], and non-monotonic logic [28].",
      "startOffset" : 170,
      "endOffset" : 174
    }, {
      "referenceID" : 31,
      "context" : "In this paper, we focus on Reiter’s Default Logic (DL), which has been introduced in 1980 [34] and is one of the most fundamental formalism for modelling human-sense reasoning.",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 21,
      "context" : "In 1992, Gottlob showed that many important decision problems, beyond the extension existence problem, of non-monotonic logics are complete for the second level of the polynomial hierarchy [22] and thus are of high intractability.",
      "startOffset" : 189,
      "endOffset" : 193
    }, {
      "referenceID" : 11,
      "context" : "A prominent approach to understand the intractability of a problem is to use the framework of parameterised complexity, which was introduced by Downey and Fellows [12, 11].",
      "startOffset" : 163,
      "endOffset" : 171
    }, {
      "referenceID" : 10,
      "context" : "A prominent approach to understand the intractability of a problem is to use the framework of parameterised complexity, which was introduced by Downey and Fellows [12, 11].",
      "startOffset" : 163,
      "endOffset" : 171
    }, {
      "referenceID" : 38,
      "context" : "The invention of new parameters can be quite challenging, however, Sat has so far been considered under many different parameters [41, 36, 5, 31].",
      "startOffset" : 130,
      "endOffset" : 145
    }, {
      "referenceID" : 33,
      "context" : "The invention of new parameters can be quite challenging, however, Sat has so far been considered under many different parameters [41, 36, 5, 31].",
      "startOffset" : 130,
      "endOffset" : 145
    }, {
      "referenceID" : 4,
      "context" : "The invention of new parameters can be quite challenging, however, Sat has so far been considered under many different parameters [41, 36, 5, 31].",
      "startOffset" : 130,
      "endOffset" : 145
    }, {
      "referenceID" : 29,
      "context" : "The invention of new parameters can be quite challenging, however, Sat has so far been considered under many different parameters [41, 36, 5, 31].",
      "startOffset" : 130,
      "endOffset" : 145
    }, {
      "referenceID" : 39,
      "context" : "A concept that provides a parameter and has been widely used in theoretical investigations of propositional satisfiability are backdoors [42, 21, 25].",
      "startOffset" : 137,
      "endOffset" : 149
    }, {
      "referenceID" : 20,
      "context" : "A concept that provides a parameter and has been widely used in theoretical investigations of propositional satisfiability are backdoors [42, 21, 25].",
      "startOffset" : 137,
      "endOffset" : 149
    }, {
      "referenceID" : 24,
      "context" : "A concept that provides a parameter and has been widely used in theoretical investigations of propositional satisfiability are backdoors [42, 21, 25].",
      "startOffset" : 137,
      "endOffset" : 149
    }, {
      "referenceID" : 39,
      "context" : "Backdoors for propositional satisfiability have been introduced by Williams, Gomes, and Selman [42, 43].",
      "startOffset" : 95,
      "endOffset" : 103
    }, {
      "referenceID" : 40,
      "context" : "Backdoors for propositional satisfiability have been introduced by Williams, Gomes, and Selman [42, 43].",
      "startOffset" : 95,
      "endOffset" : 103
    }, {
      "referenceID" : 30,
      "context" : "The concept of backdoors has recently been lifted to some non-monotonic formalisms as abduction [33], answer set programming [18, 17], and argumentation [13].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 17,
      "context" : "The concept of backdoors has recently been lifted to some non-monotonic formalisms as abduction [33], answer set programming [18, 17], and argumentation [13].",
      "startOffset" : 125,
      "endOffset" : 133
    }, {
      "referenceID" : 16,
      "context" : "The concept of backdoors has recently been lifted to some non-monotonic formalisms as abduction [33], answer set programming [18, 17], and argumentation [13].",
      "startOffset" : 125,
      "endOffset" : 133
    }, {
      "referenceID" : 12,
      "context" : "The concept of backdoors has recently been lifted to some non-monotonic formalisms as abduction [33], answer set programming [18, 17], and argumentation [13].",
      "startOffset" : 153,
      "endOffset" : 157
    }, {
      "referenceID" : 21,
      "context" : "Beyond the classification of Gottlob [22], the complexity of fragments, in the sense of Post’s lattice, has been considered by Beyersdorff et al.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 1,
      "context" : "extensively for default logic [2], and for autoepistemic logic by Creignou et al.",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 8,
      "context" : "[9].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "Also parameterised analyses of non-monotonic logics in the spirit of Courcelle’s theorem [7, 8] have recently been considered by Meier et al.",
      "startOffset" : 89,
      "endOffset" : 95
    }, {
      "referenceID" : 7,
      "context" : "Also parameterised analyses of non-monotonic logics in the spirit of Courcelle’s theorem [7, 8] have recently been considered by Meier et al.",
      "startOffset" : 89,
      "endOffset" : 95
    }, {
      "referenceID" : 27,
      "context" : "[29].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 22,
      "context" : "studied treewidth as a parameter for various non-monotonic logics [23] and also considered a more CSP focused non-monotonic context within the parameterised complexity setting [24].",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 23,
      "context" : "studied treewidth as a parameter for various non-monotonic logics [23] and also considered a more CSP focused non-monotonic context within the parameterised complexity setting [24].",
      "startOffset" : 176,
      "endOffset" : 180
    }, {
      "referenceID" : 19,
      "context" : "For more detailed information, we refer to other standard sources [32, 20, 12].",
      "startOffset" : 66,
      "endOffset" : 78
    }, {
      "referenceID" : 11,
      "context" : "For more detailed information, we refer to other standard sources [32, 20, 12].",
      "startOffset" : 66,
      "endOffset" : 78
    }, {
      "referenceID" : 18,
      "context" : "We follow the notion by Flum and Grohe [19].",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 31,
      "context" : "1 Default Logic We follow notions by Reiter [34] and define a default rule δ as a triple α:β γ ; α is called the prerequisite, β is called the justification, and γ is called the conclusion; we set prereq(δ) := α, just(δ) := β, and concl(δ) := γ.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 31,
      "context" : "Definition 1 (Fixed point semantics, [34]).",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 31,
      "context" : "A definition for stable extensions beyond fixed point semantics, which has been introduced by Reiter [34] as well, uses the principle of a stage construction.",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 31,
      "context" : "Proposition 1 (Stage construction, [34]).",
      "startOffset" : 35,
      "endOffset" : 39
    }, {
      "referenceID" : 21,
      "context" : "Ext(cnf) is Σp2-complete [22].",
      "startOffset" : 25,
      "endOffset" : 29
    }, {
      "referenceID" : 36,
      "context" : "Ext(horn) is NP-complete [39, 40].",
      "startOffset" : 25,
      "endOffset" : 33
    }, {
      "referenceID" : 37,
      "context" : "Ext(horn) is NP-complete [39, 40].",
      "startOffset" : 25,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : "Ext(positive-unit) ∈ P [2].",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 1,
      "context" : "[2] have considered all Boolean fragments of Imp(F) and completely classified its computational complexity concerning the framework of Post’s lattice.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 36,
      "context" : "However, its complexity is already known from the work by Stillman [39].",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 39,
      "context" : "First, we review backdoors from the propositional setting [42, 43], where a backdoor is a subset of the variables of a given formula.",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 40,
      "context" : "First, we review backdoors from the propositional setting [42, 43], where a backdoor is a subset of the variables of a given formula.",
      "startOffset" : 58,
      "endOffset" : 66
    }, {
      "referenceID" : 32,
      "context" : "Rosati [35] classified the extension checking problem as complete for the complexity class Θ2 = ∆p2 [log], which allows only logarithmic many oracle questions to an NP oracle.",
      "startOffset" : 7,
      "endOffset" : 11
    }, {
      "referenceID" : 14,
      "context" : "For further information on the complexity class Θ2 we refer the reader to the survey article of Eiter and Gottlob [15].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 35,
      "context" : "Question: Does T have a strong F -backdoor of size at most k? If the target class F ′ is clause-induced, we can use a decision algorithm for BdDetect(F → F ) to find the backdoor using self-reduction [38, 12].",
      "startOffset" : 200,
      "endOffset" : 208
    }, {
      "referenceID" : 11,
      "context" : "Question: Does T have a strong F -backdoor of size at most k? If the target class F ′ is clause-induced, we can use a decision algorithm for BdDetect(F → F ) to find the backdoor using self-reduction [38, 12].",
      "startOffset" : 200,
      "endOffset" : 208
    }, {
      "referenceID" : 33,
      "context" : "For C ∈ {horn, positive-unit,krom} we follow known constructions from the propositional setting [36].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 5,
      "context" : "2738 + kn) [6] and a 3-hitting set of size at most k, if it exists, can be found in time O(2.",
      "startOffset" : 11,
      "endOffset" : 14
    }, {
      "referenceID" : 15,
      "context" : "179 + n) [16], which gives us then a strong C-backdoor of 〈W,D〉.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 9,
      "context" : "If monotone is the target class, then backdoor evaluation is in para-∆p2 , which is can be solved by an fptalgorithm that can query a SAT solver multiple times [10].",
      "startOffset" : 160,
      "endOffset" : 164
    }, {
      "referenceID" : 34,
      "context" : "An interesting task for future research is to consider the remaining Schaefer classes [37], e.",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 2,
      "context" : ", dualHorn, 1- and 0-valid, as well as the classes renamable-Horn and QHorn [3, 4], and investigate whether we can generalise Algorithm 2.",
      "startOffset" : 76,
      "endOffset" : 82
    }, {
      "referenceID" : 3,
      "context" : ", dualHorn, 1- and 0-valid, as well as the classes renamable-Horn and QHorn [3, 4], and investigate whether we can generalise Algorithm 2.",
      "startOffset" : 76,
      "endOffset" : 82
    }, {
      "referenceID" : 13,
      "context" : "[14] or exploiting backdoors similar to results by Fichte and Szeider [17], might yield new insights.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[14] or exploiting backdoors similar to results by Fichte and Szeider [17], might yield new insights.",
      "startOffset" : 70,
      "endOffset" : 74
    } ],
    "year" : 2016,
    "abstractText" : "In this paper, we introduce a notion of backdoors to Reiter’s propositional default logic and study structural properties of it. Also we consider the problems of backdoor detection (parameterised by the solution size) as well as backdoor evaluation (parameterised by the size of the given backdoor), for various kinds of target classes (cnf, horn, krom, monotone, positive-unit). We show that backdoor detection is fixed-parameter tractable for the considered target classes, and backdoor evaluation is either fixed-parameter tractable, in para-∆P2 , or in para-NP, depending on the target class.",
    "creator" : "dvips(k) 5.991 Copyright 2011 Radical Eye Software"
  }
}