{
  "name" : "1704.03342.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Beliefs and Probability in Bacchus’ l.p. Logic: A 3-Valued Logic Solution to Apparent Counter-intuition",
    "authors" : [ "Mieczyslaw A. Klopotek" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 4.\n03 34\n2v 1\n[ cs\n.A I]"
    }, {
      "heading" : "1 Introduction",
      "text" : "The paper of Bacchus1 aims at painless integration of two paradigms of human reasoning, that is 1) first order logics and 2) statistical inference. (see also8 ) in such a way as to avoid all the contradictions emerging in previous approaches.\nNonetheless the claim of the current paper is that also the L.p. logic of Bacchus1 fails to achieve its primary goal of becoming the tool for describing knowledge & reasoning in expert systems and other knowledge-based systems. In Section 2 we present several simple examples of basic flaws of this logic exploiting the counter intuitiveness of the L.p. logic. Section 3 demonstrates a more elaborated example pointing at weaknesses of the L.p. logic.\nAs a remedy we propose (in a sketchy way) a different deduction theory taking into account the gap between first-order way of thinking (global treatment of domains) and that of statistical (experimental) sciences (local treatment of domains)."
    }, {
      "heading" : "2 Flaws of Theories Criticized by Bacchus and",
      "text" : "His Solution\nA number of works were concerned with representational and inferential issues when probabilities of events were identified as degrees of belief. Bacchus criticized i.e. the\nfollowing approaches:\nApproach 1: (propositional logic) : (see.6,7 ) Probability of a sentence is the probability of selection of one of those possible worlds wherein this sentence holds. E.g. the 90 % belief that the famous Tweety flies is stated as Prob(F lies(Tweety)) = x with x being greater than 0.9. However, such an approach does not make it easy to state that “Most birds fly”.\nApproach 2: (first order logic) The probability of the expression: ∀x.Bird(x) → F lies(x) be expressed as Prob(∀x.Bird(x) → F lies(x)). Following the principles of probability calculus we obtain: Prob(∃ x.Bird(x)∧¬F lies(x)) = Prob(¬(∀x.Bird(x) → F lies(x))) = 1 − Prob(∀x.Bird(x) → F lies(x))). Hence if Prob(∀x.Bird(x) → F lies(x)) > 0.9, then it should hold that Prob(∃ x.Bird(x)∧¬F lies(x)) < 0.1. However one can imagine such a set of possible worlds that in most of those worlds most of birds fly and at the same time in most of the worlds non-flying birds, exist, that is both Prob(∀x.Bird(x) → F lies(x)) > 0.9 and Prob(∃ x.Bird(x) ∧ ¬F lies(x)) > 0.9 > 0.1 hold which means a contradiction.\nApproach 3: Cheeseman5 proposed that the above statements be meta-expression with conditional probability of the type:\n∀x.Prob[F lies(x) | Bird(x)] > 0.9\nHowever, this representation cannot be treated as a method of expression of statistical knowledge but rather as an update method for degrees of belief, as it leads to a contradiction when mixing general and particular knowledge (see1 for details).\nSo, both probability inside and outside the scope of quantifiers lead to contradictions. Hence Bacchus proposed an L.p. logic described in1 , where the probability is a quantifier itself (probability of the formula α(x) with the free variable x is expressed as [α(x)]x . Let us cite here from 1 :\nINFERENCE RULE: (modus ponens)\nR1: From {α , α → β} infer β.\nDEFINITION: Conditional probability [β | α]x ( β conditioned on α):\n([α]x > 0 → [β ∧ α]x = [β | α]x ∗ [α]x) ∧ ([α]x = 0 → [β | α]x = 0)"
    }, {
      "heading" : "3 The Flaws of Bacchus Himself",
      "text" : "Let us show now the major weaknesses of the L.p. logic. Let us notice the following:\n1. many Logic-based knowledge systems express general knowledge in terms of implications,\n2. all the examples of statistical knowledge representation in 1 refer to conditional probabilities instead of probabilities of implications.\n3. the concept of conditional probability in L.p. is not a primary one but a concept derived from “absolute” probability in a strange way (see below),\n4. the strangeness of conditional probability definition results from missing logical construct corresponding to conditional probability, (a construct of the form: p ⇒ q with [p ⇒ q]x == [q | p]x).\n5. the conditional probability does not suffice to substitute this missing logical construct, for how to express a statement “in most cases whenever p implies q then also v implies z”.\nLet us demonstrate the non-suitability of implication for expressing statistical knowledge.\nExample 1: What is the sum of conditional probabilities of an event and its counter-event [α | β]x + [¬α | β]x ? The answer is: either 1 or 0!! (depending on the probability of β, that is [β]x).\nExample 2: What is the conditional probability of an event conditioned on itself: [α | α]x ? The answer is: either 1 or 0!!! (depending on the probability of α, that is [α]x ).\nExample 3: Let us consider the following facts:\n“With a certainty of at most 90 % if you are man then you are fertile.”\n“With a certainty of at most 80 % if you are a fertile man then you will become a father”\n“If you are a father then you are a man.”\nWhat is the probability of being a woman ?\nThe answer is: at most 0.7. The proof is as follows:\nWe obtain the translation of the facts:\n[man(x) → fertile(x)]x ≤ 0.9,\n[man(x) ∧ fertile(x) → father(x)]x < 0.8,\n∀ x.(father(x) → man(x))\nHence: [¬(man(x) → fertile(x))]x ≥ 0.1\n[¬(man(x) ∧ fertile(x) → father(x))]x ≥ 0.2\nHence: [man(x) ∧ ¬fertile(x))]x ≥ 0.1\n[man(x) ∧ fertile(x) ∧ ¬father(x))]x > 0.2\nBut: [woman(x)]x = 1− [man(x)]x =\n= 1− [(man(x) ∧ ¬fertile(x)) ∨ (man(x) ∧ fertile(x) ∧ father(x))\n∨(man(x) ∧ fertile(x) ∧ ¬father(x))]x =\n= 1− [man(x) ∧ ¬fertile(x)]x − [man(x) ∧ fertile(x) ∧ father(x)]x\n−[man(x) ∧ fertile(x) ∧ ¬father(x)]x ≤\n≤ 1− [man(x) ∧ ¬fertile(x)]x − [man(x) ∧ fertile(x) ∧ father(x)]x ≤\n≤ 1− 0.1− 0.2 = 0.7 Q.e.d.\nExample 4. Let us consider the following facts:\n“For all x, if x is a male then x is not pregnant” and\n“For all x, it is not true that if x is a male then x is pregnant”\nThe question is: are there any females ?\nLet us use the following predicates: m(x)–male x, p(x) –pregnant x\nWe obtain the translation:\n∀x. (m(x) → ¬p(x)) and ∀x. ¬(m(x) → p(x))\nHence: [(m(x) → ¬p(x))]x = 1 and [¬(m(x) → p(x))]x = 1\nhence: [(m(x) → ¬p(x))]x = 1 and [(m(x) → p(x))] = 0\nBut: ∀x. ((m(x) → ¬p(x)) ∨ (m(x) → p(x))\nHence [(m(x) → ¬p(x)) ∨ (m(x) → p(x)]x = 1\nbut [(m(x) → ¬p(x)) ∨ (m(x) → p(x)] =\n= [m(x) → ¬p(x)]x + [m(x) → p(x)]x − [(m(x) → ¬p(x)) ∧ (m(x) → p(x)]x\nHence: 1 = 1 + 0− [(m(x) → ¬p(x)) ∧ (m(x) → p(x)]x\nHence: [(m(x) → ¬p(x)) ∧ (m(x) → p(x)]x = 0\n[¬m(x)]x = 0\nSo being a female is improbable !!!!\nBefore proceeding with another example let us remind a basic fact from intuitive reasoning: whenever we consider a piece of knowledge to be nearly sure, we reason with it as if it were absolutely true and when we obtain a result then we believe it to be nearly sure if the reasoning chain is not too long. We also take our experience\nlearned in one environment and expect it to hold in a different environment if the first environment yielded significant results. When we apply a body of general knowledge to an individual case, we usually possess only partial knowledge of the case and reason as if we have had a population of cases fitting our knowledge of the individuum and obtain statistical results covering this artificial population. This is how Bayesian networks4 are used for individual diagnosis, as done in1 Example 8 also. This is also the very nature of Miller’s Principle3 .\nLet us state some claims about L.p. logic5 :\nTheorem 1 L.p. logic is equivalent to a logic Lp’ derived from L.p. by substitution of the inference rule R with R1’ and R2’: R1’: From {[α]x = 1, [α → β]x = 1} infer [β]x = 1., with vector x being vector of all free variables in α and β. R2’: From {α → β} infer [α → β]x = 1, (x as in R1’).\nPROOF: see5 ✷\nTheorem 2 Lp’ logic is equivalent to a logic Lp” derived from Lp’ by substitution of the inference rules Ri’ with R1”, R2”, R3”: R1”: From {[α]x = 1, [β | α]x = 1} infer [β]x = 1., with vector x is vector of all free variables in α and β. R2” = R2’ R3”: From {[α → β]x = 1.[α]x > 0 infer [β | α]x = 1, (x as above).\nPROOF: see5 ✷\nTheorem 3 Given [α]x > 0, always [β | α]x ≤ [α → β]x.\nPROOF: easily seen ✷\nTheorem 4 If within the proof system Lp’ in a certain step of the proof the premise/conclusion is weakened [α]x = 1 − ε2, [α → β]x = 1 − ε1 (εi ≥ 0 and small), then in the equivalent proof in Lp” we get: [β | α]x ≥ 1− 2ε1\nPROOF:\n1 = ε1 + [α → β]x = ε1 + [¬α∨ β]x ≤ ε1 + [¬α]x + [β]x = ε1 + ε2 + [β]x ,\nhence: [β]x ≥ 1− ε1 − ε2\n[β | α]x = [β ∧ α]x/[α]x = ([β]x − [¬β ∧ α]x)/[α]x = ([β]x − [¬(β ∨¬α]x)/[α]x =\n= ([β]x − [¬(α → β)]x)/[α]x = ([β]x − (1 − [(α → β)]x))/[α]x\n≥ (1− ε1 − ε2 − 1 + 1− ε1)/(1− ε2) = (1− ε2)/(1− ε2)− 2ε1/(1− ε2) = 1− 2ε1/(1− ε2) ≥\n1 − 2ε1 Q.e.d. ✷\nExample 5: Let us consider the example 8 from1,page 227. (Fig. 1: from1 with my interpretation for X1 − X4 ): Let us first consider the rules:\nX1 (guilty)\nX3 prison\nX4 punishment\nfinancial X2punishment\n❅ ❅ ❅ ❅ ❅ ❅ ❅❘\n✠ ❅ ❅ ❅ ❅ ❅ ❅ ❅❘ ✠\nFig1: Example 8 from [page 227] [1] – intrepreted\n¬X1(x) → X3(x) and X3(x) ∨X2(x) → X4(x).\nHence if ¬X1(x) is valid, then in the logic Lp’ we obtain rules:\n[¬X1(x) → X3(x)] = 1 and [X3(x) ∨X2(x) → X4(x)]x = 1\nthen From ¬X1(x), [¬X1(x) → X3(x)]x = 1 infer[X3(x)]x = 1\nFrom [X3(x)] = 1, definition ∨ ′ infer [X3(x) ∨X2(x)]x = 1\nFrom [X3(x) ∨X2(x)] = 1, [X3(x) ∨X2(x) → X4(x)]x = 1 infer\n[X4(x)]x = 1.\nNow let us imagine we verify our rules in a real world environment. Let among 100 persons appearing before court be 5 innocent ones none of which was condemned, and 95 guilty persons of which 94 were imprisoned and one had to pay a fine. Then:\n[¬X1(x) → X(x)]x = 0.95 and [X3(x) ∨X2(x) → X4(x)]x = 1\nSo in fact our rules are highly probable. Now let us apply the rules learned previously to an individuum of which we know it is innocent. So we consider a population with [¬X1(x)]x = 1. Following the spirit of the previous deduction we obtain:\nFrom ¬X1(x), [¬X1(x) → X3(x)]x = 0.95 infer [X3(x)]x > 0.95\nFrom [X3(x)]x > 0.95, definition of ′ ∨′ infer\n[X3(x) ∨X2(x)]x > 0.95\nFrom [X3(x) ∨X2(x)]x > 0.95, [X3(x) ∨X2(x) → X4(x)]x = 1 infer\n[X4(x)]x > 0.95.\nHowever, if we considered conditional probabilities instead of probabilities of inference rules we would obtain: [X4(x)]x = 0 (innocent are not condemned). So apparently the validity of THEOREM 4 is denied, so also that of Bacchus L.p. Though the reason for the flaw is obvious – inference rules are global in nature and conditional probabilities cover local properties of a universe, hence are more suitable to be transferred to another universe – but the solution is not as easy."
    }, {
      "heading" : "4 A Solution",
      "text" : "To overcome the problems mentioned above it is necessary to find a logical construct corresponding to conditional probability. It is easily seen that enforcing the interpretation of probability of ordinary implication as conditional probability would lead to serious problems for then: [β | α]x = [α → β]x = [¬β → ¬α]x = [¬α | ¬β]x , which may easily lead to a contradiction.\nSo we see that two-valued logics are not sufficient for our purposes. Hence let us introduce the logical construct |⊢ having the following three-valued semantics: (T - =true, F=false, U=uninteresting)\np |⊢ q\n❅ p T U F\nq T T U U U U U U F F U U\nWe need also truth tables for basic logical constructs ∧, ∨, ¬ :\np ∧ q\n❅ p T U F\nq T T U F U U U F F F F F\np ∨ q\n❅ p T U F\nq T T T T U T U U F T U F\n❅ ¬q\nq T U F\nF U T\nLet us define two probability quantifiers: P1x.α and P2x.α in such a way that P1 expresses the proportion of the expression α taking value T to cases it takes value T or F. P1x.χ |⊢ β is then equivalent to conditional probability [β | χ]x . P2 expresses the proportion of cases where a takes values either T or F to cases it takes any of the values T,F,U. We have then the following properties of both:\n1) ∀x1 . . .∀xn. α → P1x.α = 1 ∧ P2x.α = 1\n2) P1x.α ≥ 0, P2x.α ≥ 0, P2x.α ≥ 1\n3) P1x.α + P1x.¬α = 1, P2x.α = P2x.¬α\n4) P1x.α + P1x.β ≥ P1x.α ∨ β\n5) P1x.α ∧ β = 0 → P1x.α + P1x.β = P1x.α ∨ β\nThe quantifier P1 captures local properties of the universe while P2 carries global ones. It is then easily seen that using f instead of implications and P1 instead of []x in previous examples would resolve all the problems encountered there. Beside this, the statement “Almost always whenever p implies q then also v implies z” may be properly expressed by P1x.(p |⊢ q) |⊢ (v |⊢ z) > 0.9. So, by proper axiomatization we will gain the following: if a proof is to be transferred from one universe to another one locally similar then all the steps engaging P1 will be kept and those involving P2 need to be verified – also with respect to Miller’s Principle. A detailed presentation of the axiomatization is given in9.\nReferences\n1. F. Bacchus: “L.p., a logic for representing and reasoning with statistical knowledge”, Computer Intelligence 6, 209-231, (1990).\n2. P. Cheeseman: “An inquiry into computer understanding”, Computational Intelligence, 4(1), 58-66, (1988).\n3. J.Y. Halpern: “An analysis of first-order logics of probability”, Artificial Intelligence 46(3), 311-350, (1990).\n4. T. Hrycej: “Gibbbs Sampling in Bayesian Networks”, Artificial Intelligence 46 (3), 351-36, (1990).\n5. M.A.Klopotek: “Bayesian Network and L.p. Logic for Statistical Inference”, A Talk at the National Workshop Cybernetics- Intelligence- Development CIR91, Siedlce-Poland, Sept. (1991) - to appear in Proceedings.\n6. C.G. Morgan: “Weak conditional comparative probability as a formal semantic theory”, Zeit. Fuer Math. Log.30, 199-212, (1984).\n7. N.J. Nilsson: “Probabilistic logic ”, Artificial Intelligence 28, 71-87, (1986).\n8. S. Watanabe: “Pattern Recognition, Human and Machine”, (1987).\n9. M.A.Klopotek: “An Axiomatic System For Statistical And Logical Reasoning” - in preparation."
    } ],
    "references" : [ {
      "title" : "L.p., a logic for representing and reasoning with statistical knowledge",
      "author" : [ "F. Bacchus" ],
      "venue" : "Computer Intelligence",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1990
    }, {
      "title" : "An inquiry into computer understanding",
      "author" : [ "P. Cheeseman" ],
      "venue" : "Computational Intelligence,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1988
    }, {
      "title" : "An analysis of first-order logics of probability",
      "author" : [ "J.Y. Halpern" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1990
    }, {
      "title" : "Gibbbs Sampling in Bayesian Networks",
      "author" : [ "T. Hrycej" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1990
    }, {
      "title" : "Weak conditional comparative probability as a formal semantic theory”, Zeit",
      "author" : [ "C.G. Morgan" ],
      "venue" : "Fuer Math. Log.30, 199-212,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 1984
    }, {
      "title" : "Probabilistic logic ",
      "author" : [ "N.J. Nilsson" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1986
    }, {
      "title" : "Pattern Recognition, Human and Machine",
      "author" : [ "S. Watanabe" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1987
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Fig1: Example 8 from [page 227] [1] – intrepreted",
      "startOffset" : 32,
      "endOffset" : 35
    } ],
    "year" : 2017,
    "abstractText" : "Fundamental discrepancy between first order logic and statistical inference (global versus local properties of universe) is shown to be the obstacle for integration of logic and probability in L.p. logic of Bacchus. To overcome the counterintuitiveness of L.p. behaviour, a 3-valued logic is proposed.",
    "creator" : "dvips(k) 5.996 Copyright 2016 Radical Eye Software"
  }
}