{
  "name" : "1401.5054.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "“ANÁLISIS E IMPLEMENTACIÓN DE ALGORITMOS EVOLUTIVOS PARA LA OPTIMIZACIÓN DE SIMULACIONES EN INGENIERÍA CIVIL.”",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "FACULTAD DE INFORMÁTICA",
      "text" : "Departamento de Ingeniería Informática"
    }, {
      "heading" : "GRADO EN INGENIERIA INFORMATICA",
      "text" : "“ANÁLISIS E IMPLEMENTACIÓN DE ALGORITMOS"
    }, {
      "heading" : "EVOLUTIVOS PARA LA OPTIMIZACIÓN DE",
      "text" : ""
    }, {
      "heading" : "SIMULACIONES EN INGENIERÍA CIVIL.”",
      "text" : ""
    }, {
      "heading" : "Alumno: José Alberto García Gutiérrez",
      "text" : ""
    }, {
      "heading" : "Tutores: Dr. D. José María Cecilia Canales, Dr. D. Alejandro Mateo Hernández",
      "text" : "Díaz."
    }, {
      "heading" : "Agradecimientos",
      "text" : "Este trabajo ha sido realizado en colaboración con el departamento de Ingeniería Civil de la Universidad Católica de Murcia, a quienes agradezco la ayuda que me han prestado y en especial a mis tutores, Alejandro y José María por su paciencia en las explicaciones, así como por haberme confiado este trabajo a pesar de que no siempre he podido dedicarle todo el tiempo que me hubiese gustado. En último lugar, me gustaría agradecer también a la unidad departamental de Física Básica de la Universidad de La Laguna de Tenerife el permitirme hacer uso de los recursos de cálculo de dicha universidad. Parte de los textos e ilustraciones referidas al análisis y el desarrollo matemático de los problemas tratados fueron aportados por sus autores para la elaboración del presente trabajo siendo por tanto suyos los derechos de cesión o reproducción de esos apartados."
    }, {
      "heading" : "Resumen",
      "text" : "En este trabajo, estudiamos la posible aplicación de algoritmos evolutivos, concretamente de la familia de las Estrategias de Evolución al problema de la estimación de un parámetro kappa para la degradación en el diseño a cortante en vigas de hormigón reforzado, un problema costoso computacionalmente y de gran relevancia en el diseño de pilares y estructuras de hormigón armado, cuya resolución algorítmica no ha sido sin embargo abordada de forma extensa en la literatura existente."
    }, {
      "heading" : "Abstract",
      "text" : "This paper studies the applicability of evolutionary algorithms, particularly, the evolution strategies family to estimation of a degradation parameter (referred as kappa parameter) for the shear design of reinforced concrete beams, a problem which have an expensive computational cost and highly relevant in the design of pillars and reinforced concrete structures, which however, has not been covered extensively in the present literature.\nÍndice General\n1. Introducción...................................................................................... 7\n1.1. Algoritmos evolutivos: Visión general.................................................................. 7\n1.2. Alcance y objetivos del proyecto......................................................................... 9\n1.3. Estructura y desarrollo del trabajo..................................................................... 10\n2. Estado del arte.................................................................................. 12\n2.1 Métodos Meta-heurísticos: tipos y evolución histórica…………………………… 13\n2.1.1 Conceptos básicos en Algoritmos Evolutivos……….………………….. 14\n2.1.2 Técnicas evolutivas. Clasificación y tipos………..…………….…..…… 18\n2.1.3 Algoritmos evolutivos en optimización continua. Estrategias de evolución (EE) …………………………………………………..……………………………..……... 20\n2.2 Algoritmos Evolutivos en aplicaciones industriales e ingeniería………………… 21\n2.3 Algoritmos Evolutivos: sobre su uso en ingeniería civil…………...................….. 25"
    }, {
      "heading" : "3. El problema de la estimación de parámetro de degradación del hormigón",
      "text" : "solicitado a cortante ……………………………………….………….. 27\n3.1 Descripción del problema. Formalización. Restricciones….……..…………………30\n3.2 Propuestas de resolución mediante técnicas evolutivas …………………………. 36\n3.2.1 Covariance Matrix Adaptation Evolution Strategy (CMA-ES) ….………. 39"
    }, {
      "heading" : "4. Experimentación y análisis de resultados ……………………………….. 44",
      "text" : ""
    }, {
      "heading" : "5. Conclusiones y trabajos futuros…………………………….…………...…. 50",
      "text" : "6. Bibliografía…………………………………………………………………….... 54\nANEXO I. Código fuente de los algoritmos implementados ………..….... 60\nANEXO II. Autorización del tutor para la defensa ……………………..…… 69\nCapítulo 1.\nIntroducción.\nEl principal aval de las técnicas algorítmicas de inspiración evolutiva es su propio éxito. Por separado o conjuntamente a otros métodos, los algoritmos evolutivos se han abierto paso y aparecen ligados a disciplinas muy dispares como la Genética, la Robótica, la Física Experimental, la Ingeniería del Software, la Ingeniería Civil, el Control de Sistemas Críticos, el Diseño Industrial o la Ingeniería de Materiales. En los siguientes capítulos, tratamos de dar una perspectiva amplia sobre qué es la computación evolutiva, el conjunto de técnicas y variantes algorítmicas que comprende y cómo estas pueden ayudar en el trabajo de campo de la Ingeniería Civil.\n1.1 Algoritmos evolutivos: Visión general\nLos algoritmos evolutivos son estrategias de optimización y búsqueda de soluciones que toman como inspiración la evolución de distintos sistemas biológicos. La idea fundamental de estos algoritmos es mantener un conjunto de individuos que representan una posible solución del problema. Estos individuos se mezclan y compiten entre sí, siguiendo el principio de selección natural en el cual sólo los más aptos sobreviven al paso del tiempo. Esto redunda en una evolución hacia soluciones cada vez más aptas.\nLos algoritmos evolutivos son una familia de métodos de optimización, y como tal, tratan de hallar una tupla de valores (xi,...,xn) tales que se minimice una determinada función F(xi,...,xn). En un algoritmo evolutivo, tras parametrizar el problema en una serie de variables, (xi,...,xn) se codifican en una población de cromosomas. Sobre esta población se aplican uno o varios operadores genéticos y se fuerza una presión selectiva (los operadores utilizados se aplicarán sobre estos cromosomas, o sobre poblaciones de ellos). Esta forma de funcionamiento les confiere su característica más destacable: un algoritmo evolutivo puede ser implementado de forma independiente del problema, o a lo sumo, con un conocimiento básico de este, lo cual los hace algoritmos robustos, por ser útil para cualquier problema, pero a la vez débiles, pues no están especializados en ningún problema concreto siendo los operadores genéticos empleados los que en gran parte confieren la especificabilidad al método empleado.\nEn los últimos años son muchos los esfuerzos dedicados por investigadores de todo el mundo al desarrollo y la aplicación de nuevos operadores y nuevas variantes algorítmicas evolutivas especializadas en los más diversos problemas. Sin embargo, no deben considerarse a las técnicas evolutivas como técnicas aisladas ni pensar que son adecuadas a todos los casos, si no entenderlas en el contexto de la que hoy se conoce como técnicas algorítmicas de Soft-Computing [69, 70, 71, 72, 79, 80], una rama de investigación muy activa en la actualidad que viene a recoger el testigo de los avances producidos en el campo de la Inteligencia Artificial después de que este resurgiera con fuerza a mediados de los años 80 del pasado siglo.\nDebido a su alta aplicabilidad los algoritmos evolutivos han tenido una adopción muy rápida tanto en la industria como en el ámbito civil o militar, actualmente los principales centros de investigación dedican ya importantes inversiones dentro de sus presupuestos a la aplicación de técnicas de inteligencia artificial en general y de computación evolutiva en particular [81, 82, 83]. Hoy día, la Inteligencia Artificial es una herramienta imprescindible para el trabajo de ingeniería y se encuentra ya embebida en multitud de dispositivos y paquetes comerciales de software permitiendo aportar una solución de caja negra a investigadores de muchas ramas, haciendo posible hallar soluciones realistas y computacionalmente tratables en áreas como:\na. Optimización numérica, real o simbólica, en situaciones donde existe una alta dimensionalidad, varios objetivos enfrentados, o no es posible conocer a priori la forma del espacio objetivo [61, 62, 73].\nb. Aprendizaje automático, clustering, clasificación y reconocimiento de patrones [74, 75].\nc. Implementación de sistemas robustos, capaces de reaccionar ante situaciones anómalas o inesperadas. [51, 52, 76]\nd. Conseguir comportamiento emergente, es decir, sistemas con respuesta adaptativa, capaces de lidiar con problemas computacionalmente difíciles y de obtener soluciones válidas ante cambios en los parámetros del problema. [49, 59, 77]\ne. En sistemas empotrados o tiempo real, capaces de dar una respuesta rápida de calidad aceptable en tiempos acotados. [5, 6, 7, 8, 78]\nf. En el tratamiento de flujos de información, compresión de bloques o procesamiento de grandes volúmenes de datos, en usos como la extracción de conocimiento, eliminación de ruido o la predicción de secuencias. [10, 33, 37, 38, 39]\nDe las ramas mencionadas, aquella que dispone de mayor número de publicaciones y en la que se basa nuestro trabajo es la que trata de explotar el potencial de la computación evolutiva como una poderosa herramienta de optimización de diseños en sistemas de naturaleza heterogénea."
    }, {
      "heading" : "1.2 Alcance y objetivos del proyecto",
      "text" : "En ámbitos como la ingeniería o el diseño industrial se presentan con frecuencia problemas de optimización de distinto grado de dificultad. De entre ellos destaca un subconjunto especial de problemas denominado conjunto NP. Un problema perteneciente a este grupo es aquel para el cual no se conoce un algoritmo exacto de resolución cuyo coste computacional guarde una relación polinomial respecto al tamaño de la entrada, esto es, que no podemos abarcar el problema simplemente aumentando nuestra capacidad de cálculo, siendo esto lo que los hace de difícil resolución. La tarea se vuelve aún más difícil cuando el problema a resolver tiene una alta dimensionalidad por la presencia de un gran número de características [1,2] o variables de entrada [3,4]. Obteniéndose un crecimiento cercano a exponencial en el tiempo de cómputo conforme se incrementa de forma lineal el número de variables consideradas. Una dificultad adicional a considerar al lidiar con un problema de optimización es el que, a veces, pequeñas variaciones en las variables de entrada del problema pueden ocasionar grandes cambios en el espacio de soluciones, (esto da lugar a los llamados sistemas caóticos), lo que hace necesario que el algoritmo ofrezca una capacidad manejable de re-parametrización [5,6]. En este ámbito las metaheurísticas aparecen como una nueva e innovadora manera de encontrar buenos ajustes y parámetros de calibración a modelos matemáticos que por su complejidad no admiten el análisis analítico, siendo además muy tolerantes a la necesitad de re-parametrizar el problema o realizar ajuste fino cuando aparece un nuevo conjunto de condiciones en el entorno [7,8].\nLos algoritmos analíticos o exactos, usados tradicionalmente como herramientas para abordar problemas de optimización, garantizan encontrar el óptimo global en muchos problemas, pero por contra, tienen el grave inconveniente de que en problemas reales pueden elevar el tiempo de ejecución necesario hasta hacer inabarcables los costes de su implementación siendo por tanto inasumibles y obligando a considerar técnicas diferentes al análisis matemático exhaustivo.\nEn contraste, los algoritmos heurísticos ad hoc son normalmente bastante rápidos [84, 85, 99, 100], pero la calidad de las soluciones encontradas puede ser a veces insuficiente y estar lejos de ser óptima, además de presentar el inconveniente adicional de determinar los discriminantes heurísticos, difíciles de definir en determinados problemas.\nLas metaheurísticas ofrecen un equilibrio adecuado entre ambos extremos: son métodos genéricos que ofrecen soluciones de buena calidad (el óptimo global en muchos casos) en un tiempo moderado [11]. Además, la naturaleza de los problemas en el ámbito científico (por ejemplo simulaciones físicas, modelado de materiales, diseño industrial, etc.) hace que en ocasiones el proceso de cómputo se realice de manera descentralizada, bien en grandes computadores especializados [9, 10], bien mediante redes dedicadas para el cálculo distribuido, y por este motivo, los algoritmos evolutivos se adaptan, por lo general, muy bien a las infraestructuras de cálculo disponibles mostrándose como herramientas de paralelización eficaces en un campo de investigación notablemente reclamado en el ámbito científico actual.\nDurante las siguientes páginas se discutirá las posibilidades de aplicación de varias clases de algoritmos evolutivos a problemas de diseño avanzado en ingeniería civil difícilmente abarcable mediante computación exhaustiva por su alta dimensionalidad y su carácter multimodal. La realización del presente trabajo se enmarca dentro de los objetivos académicos para la obtención del título de Grado en Ingeniería Informática mención en Ingeniería de Software. En él, abordaremos un problema de optimización de alta dificultad seleccionado por su trascendencia en el ámbito de estudio y llevaremos a cabo su resolución empleando técnicas evolutivas donde esperamos encontrar soluciones de calidad comparables a las conseguidas a través de las técnicas empleadas habitualmente y recogidas en la bibliografía pero con un menor costo computacional. Los objetivos que se marcan como mínimo exigible para los próximos meses incluirán:\n- Entender el problema propuesto, realizar una búsqueda bibliográfica que nos permita situar el problema y comprender su contexto así como cuál ha sido el abordaje tradicional y que trabajos conforma el estado de la cuestión. - Comprender, compilar y testar el código que constituye la implementación del problema y valorar las posibles formas de mejora y optimización. - Proponer, analizar, e implementar una o varias propuestas de resolución mediante técnicas meta-heurísticas. - Analizar los resultados obtenidos por cada uno de los métodos cuantificando las mejoras conseguidas por cada uno y realizando un análisis crítico sobre indicadores mesurables como el tiempo de cómputo, la calidad de la solución, o la complejidad algorítmica."
    }, {
      "heading" : "1.2 Estructura y desarrollo del proyecto",
      "text" : "Para el presente trabajo decidimos abordar dos partes bien diferenciadas: En una primera parte llevaremos a cabo un acercamiento a la problemática que\nqueremos abordar y analizaremos las características generales de las metaheurísticas como herramientas de parametrización de modelos numéricos y el estado del arte de la investigación en este campo. En una segunda parte, introduciremos el problema de estimación del parámetro kappa para el hormigón armado solicitado a cortante y trataremos de proponer un nuevo enfoque para su resolución basado en técnicas meta-heurísticas.\nEn el capítulo dos, daremos algunas nociones básicas sobre los diferentes enfoques algorítmicos que existen para la optimización de funciones continuas y realizaremos un recorrido bibliográfico sobre el desarrollo en este campo y las vertientes donde se centra la investigación en estas áreas en la actualidad.\nEn el capítulo tres, propondremos la resolución del problema objeto de estudio mediante Estrategias de Evolución y propondremos distintas variantes y su aplicabilidad.\nFinalmente el capítulo cuatro revisará de forma analítica los resultados obtenidos por las diferentes propuestas y mostrará los resultados de forma gráfica y comparada.\nLa última parte del trabajo consistirá en la extracción de conclusiones, exposición de limitaciones del estudio y planteamiento de posibles líneas de ampliación futura.\nCapítulo 2."
    }, {
      "heading" : "Estado de la cuestión.",
      "text" : "Hay muchas formas de abordar problemas de optimización. Probablemente la más sencilla a priori sea la mera aproximación analítica. Sin embargo, los modelos que son analíticamente tratables habitualmente son también normalmente demasiado generales para proveer la precisión que requiere un sistema físico. Además el tratamiento analítico resulta difícil y pesado computacionalmente para funciones de varias variables. Los algoritmos que intentan encontrar el mínimo a una función mediante evaluaciones de la misma pertenecen al grupo de los llamados algoritmos de hillclimbing, o de escalado de colinas; el éxito de la búsqueda en este tipo de procedimientos no depende solo de la función objetivo, sino también de la política de escalado que escojamos o dicho de otra forma de si escogemos apropiadamente la función paso (iteración) y el punto de inicio de la búsqueda (figura 1). Aun así se trata de algoritmos pensados para realizar un refinamiento de una solución que ya era en inicio razonablemente buena y por ello son sobre todos técnicas de búsqueda local, y, como tales, se concentran en encontrar el máximo más cercano al punto de inicio. Un algoritmo escalador simplemente evaluará la función en uno o más puntos e irá moviéndose por ella en pequeñas variaciones buscando el punto que maximiza la función objetivo.\nSin embargo, frecuentemente este tipo de métodos no son adecuados para paisajes de búsqueda complejos, pues suelen atascarse en mínimos locales.\nUna variante interesante que intenta evadir este problema es el método de recocido simulado, llamado así por su similitud a como se forman los metales en una forja. La técnica de recocido simulado intenta escapar de estos falsos puntos solución aceptando como valor siguiente algún vecino que no tiene necesariamente que ser mejor que las soluciones ya encontradas. Para decidir cuándo un valor, aun siendo peor, podría ser prometedor se utiliza un factor de aceptación nombrado normalmente como temperatura. De esta manera, el nuevo valor será candidato a solución siempre que la diferencia entre el punto en el que me encuentro y aquel al que voy sea menor que el valor actual de temperatura. A pesar de su aparente sencillez, esta idea permite que el algoritmo muestre una mayor tolerancia y sea más difícil el estancamiento. Sin embargo, el hecho de evitar quedar atascados e incluso alcanzar la condición de convergencia no nos asegura que estemos cerca de un valor óptimo ya que seguimos dependiendo del punto donde se inicia la búsqueda.\nParte de las problemáticas anteriores se pueden resolver usando una estrategia de multi-comienzo. Este tipo de estrategias, en realidad, no son más que la ejecución paralela de varios de estos algoritmos, y por tanto, aunque son mejores, tampoco nos garantizan que se encuentre, o incluso se aproximen al máximo global. En todo caso, tiene la ventaja de que, en cada iteración del algoritmo, se tiene una solución válida, aunque no tiene porqué ser la mejor posible. Empleemos el método que empleemos, para no degradar en un proceso de búsqueda ciega (búsqueda voraz) todos estos algoritmos necesitan una pista de hacia dónde deben avanzar para alcanzar la mejor solución. A esta función guía es a lo que en computación se le llama heurística. Una heurística consiste básicamente en usar una serie de reglas (un conocimiento previo mínimo) para avanzar hacia la resolución de un tipo de problema.\nLos Métodos Metaheurísticos fueron introducidos por vez primera por Fred Glover (también conocido por ser el creador del método Tabú) en [12] y surgieron al combinar diferentes métodos heurísticos con el objetivo de alcanzar una mayor eficiencia, robustez y eficacia en la exploración del espacio de búsqueda. Fueron diseñados para resolver problemas de optimización (optimización combinatoria y continua) complejos, donde no existía un conocimiento profundo de la forma que tiene el espacio n-dimensional de soluciones. Los algoritmos evolutivos pertenecen a este tipo de técnicas."
    }, {
      "heading" : "2.1 Metaheurísticas",
      "text" : "Actualmente existen diferentes formas de clasificar a los algoritmos metaheurísticos [7], entre las más aceptadas y utilizadas en computacional creemos acertado resaltar las siguientes:\na) Algoritmos bio-inspirados / no bio-inspirados: Si se basan o no en la evolución biológica.\nb) Estáticos / Dinámicos: Si se utiliza la misma función objetivo o no durante todo el proceso evolutivo.\nc) Basados en un conjunto de soluciones (población) / basados en una única solución: Esta radica en el número de soluciones que se utiliza en el proceso de optimización.\nd) Con memoria / sin memoria: Esta depende del uso que hacen de su historia de búsqueda, es decir, si utilizan memoria o no.\nPara este trabajo, se decide adoptar la clasificación que divide a las metaheurísticas en basadas en una solución y basadas en poblaciones porque es ampliamente utilizada en la comunidad científica. Las técnicas evolutivas (AE), que desarrollaremos en profundidad, pertenecen al grupo de las metaheurísticas basadas en poblaciones."
    }, {
      "heading" : "2.1.1 Conceptos básicos de algoritmos evolutivos",
      "text" : "Como hemos visto en las secciones anteriores, cuando modelamos problemas de la vida real uno de los más frecuentes problemas es la alta dimensionalidad de espacio de búsqueda pero no es el único. También es frecuente encontrarse con problemas en los que las condiciones para la optimalidad de la solución varían a lo largo del tiempo o no existen como tal. Este tipo de problemas se conocen como problemas multimodales.\nNo siempre las condiciones del problema permanecen estáticas durante la duración del mismo; puede ser que el espacio de búsqueda aumente o disminuya, que la valoración de una solución cambie, o simplemente que la forma más simple de resolver un problema consista en resolver previamente una serie de sub-problemas, que vayan acotando la solución cada vez más.\nEl concepto de multi-modalidad ha sido usado en diferentes contextos: estrictamente, un problema multimodal es un problema que tiene varios máximos, todos ellos de la misma jerarquía, pero también se aplica a aquellos problemas que tienen varias soluciones posibles.\nEn general, casi todo problema de búsqueda, formulado como un problema de optimización, suele tener varios máximos, uno de ellos es mejor que el resto, y este se le denomina máximo global. El resto son máximos locales; es decir, se puede definir una vecindad alrededor de ellos en la cual son máximos globales.\nLos AE son, a grosso modo, un método de optimización basado en población, especialmente útiles cuando tratamos un problema donde es costoso realizar un gran número de iteraciones o donde existen dos o más funciones objetivo ya que se adaptan excepcionalmente bien a problemas multi-objetivo. Por lo tanto, los AE están indicados para resolver todo tipo de problemas que puedan ser expresados en forma de problema de optimización de una o varias funciones sujetas a un número variable de restricciones y a una o más restricciones de contorno. Los AE son tremendamente sensibles a la manera en que codifiquemos a los individuos de la población y la codificación utilizada puede influir sensiblemente en las posibilidades de convergencia. Tanto es así que algunas variantes de AE se diferencian precisamente en elegir una u otra forma de codificación interna. Por tanto, la tarea más importante en un AE será encontrar la representación adecuada para las soluciones. La segunda tarea crítica será elegir correctamente la función que guiará la búsqueda, y que puede ser única o formarse de la combinación ponderada de varias funciones. Esta función suele recibir el nombre de función objetivo o función fitness (adecuación). Básicamente, los algoritmos genéticos funcionan como sigue: dada una población de soluciones candidatas, y en base al valor de la función objetivo para cada una de los individuos (soluciones) de esa población, se seleccionan los mejores individuos (los que minimizan la función objetivo) y se combinan para generar otros nuevos. Este proceso se repite cíclicamente.\nEn primer lugar, debemos contar con un modelo matemático que permita evaluar un punto del espacio de soluciones en que se define el problema. En otros términos, tenemos que poder plantear el problema como un problema de minimización (o maximización) de una función objetivo, que representa la presión selectiva del medio. En segundo lugar, deberá especificarse la manera de codificar las soluciones. Las codificaciones más sencillas, son aquellas que están basadas en código binario (representación en forma de cadena de bits). La interpretación que sedé a esa cadena dependerá de la naturaleza de la solución (puede ser la codificación de un valor entero, de un real, un vector de valores boléanos... y cualquier otra estructura de datos).\nLa figura muestra el esquema algorítmico general que puede encontrarse en cualquier algoritmo evolutivo con pequeñas modificaciones en lo esencial. En primer lugar (1) se procede a la inicialización de la población. Para cada individuo de la población se selecciona un valor que puede ser completamente aleatorio. También puede considerarse tomar como valores iniciales una aproximación a la solución. Después se aplica a cada individuo la función objetivo, es decir, la función objetivo nos dice cuan bueno es un individuo como solución, lo que da una medida de lo adaptado que está cada uno de ellos. En función del valor obtenido se ordena la población (2.2), quedando así en primer lugar los individuos más adaptados. Se seleccionan entonces los individuos que se van a cruzar (2.3).\nHay distintas maneras de realizar esa selección, las más usuales son:\nSelección basada en rango: Según este criterio se seleccionan los m individuos mejor adaptados.\nSelección por ruleta: Este criterio consiste en dar a cada individuo una probabilidad de ser seleccionado proporcional a su fitness. En este tipo de selección un individuo puede seleccionarse dos veces y cruzarse consigo mismo.\nSelección por torneo: Este criterio toma n individuos de la población y selecciona al de mayor fitness de los selecciona dos. Una hemos seleccionado a nuestros progenitores se procede a cruzarlos (3): se escoge un punto de corte, y la tira de bits que representa a cada progenitor se divide en dos por ese punto.\nSelección ad hoc: Muchas veces la naturaleza del problema o de los datos de entrada fuerzan a que la selección se realice siguiendo criterios específicos al problema. Un ejemplo de esto lo encontramos en los métodos de selección utilizados en optimización multi-objetivo.\nEl cruce normalmente (salvo en las estrategias de evolución) representa el mecanismo más importante y es la base de todos los AE ya que en este paso es donde se produce el intercambio de información genética. Este intercambio genético se puede llevar a cabo de muchas formas. Los tipos principales de cruce son:\nCrossover n-puntos: los dos cromosomas se cortan por n puntos, y el material genético situado entre ellos se intercambia. Lo más habitual es un crossover deun punto o de dos puntos.\nCrossover uniforme: se genera un patrón aleatorio de 1s y 0s, y se intercambian los bits de los dos cromosomas que coincidan donde hay un 1 en el patrón. O bien se genera un número aleatorio para cada bit, y si supera una determinada probabilidad se intercambia ese bit entre los dos cromosomas.\nCrossover especializados: en algunos problemas, aplicar aleatoriamente el crossover da lugar a cromosomas que codifican soluciones inválidas; en\neste caso hay que aplicar el crossover de forma que generen siempre soluciones válidas. Un ejemplo de estos son los operadores de crossover usados en el problema del viajante. También aparecen operadores de cruce especializados en codificaciones muy especializadas o en problemas donde se ha llevado un estudio exhaustivo y tenemos un amplio conocimiento del problema y queremos traspasarlo al algoritmo. En el paso 4 se genera en la descendencia una mutación en un alelo (en el caso más simple la mutación consiste en negar un bit) aleatorio. Esto sucede con una probabilidad baja (esto es, en la mayoría de los casos, el paso 4 no tiene efecto).\nUna vez se ha generado la descendencia, deberá insertarse en la población (5). Para llevar a cabo la inserción existen diversas políticas:\nEliminar a los individuos peor adaptados e insertar los recién generados.\nEliminar al individuo peor y reemplazarlo.\nReemplazar toda la población\nDebemos elegir cuidadosamente cada uno de estos parámetros ya que de ellos dependerá el éxito de nuestro algoritmo.\nPor último, en el paso 6 se comprueba si alguno de los individuos disponibles satisface los criterios establecidos y se puede considerar como solución al problema. En este paso también se puede comprobar si se ha excedido un número de iteraciones o un límite de tiempo. Si no es así y ningún individuo cumple los criterios de parada, se vuelve al paso 2.3.\nEste sencillo algoritmo junto los mecanismos de cruce y selección se encuentran en la base de todos los algoritmos genéticos que con el tiempo han ido incorporando a un amplio abanico de operadores genéticos mejores y más complejos."
    }, {
      "heading" : "2.1.2 Técnicas evolutivas. Clasificación y tipos",
      "text" : "Existen varias aproximaciones a la idea de algoritmos evolutivos (En adelante abreviados como AE) pero a pesar del amplio abanico de algoritmos disponibles, todos ellos son similares en su planteamiento básico y en el uso que dan a las ideas evolutivas, y difieren principalmente en la forma de representación de la información y en la importancia que dan a los diferentes operadores genéticos.\nA pesar del gran número de variantes y paradigmas recogidos como computación evolutiva [20], la mayoría de los autores están de acuerdo en clasificarlas en:\n-Evolutionary programming\n-Evolutionary strategies\n-Genetic algorithms\n-Genetic programming\nLos algoritmos de Estrategia Evolutiva (ES) fueron introducidos por Rechenberg et al. [22] a principio de los 70 en diferentes aplicaciones industriales e hidráulicas. Destacan sobre las otras porque están pensados para trabajar sobre espacios continuos (números reales) y porque los parámetros de funcionamiento del algoritmo (tasa de mutación, probabilidad de cruce.) no son fijos sino que forman parte del proceso de optimización. Por ejemplo, en el algoritmo CMA-ES, el cálculo de dichos parámetros se calcula a partir de la obtención de las matrices de covarianza en el espacio de n dimensiones.\nLos Algoritmos Genéticos (GA) como caso particular, son un tipo de algoritmo evolutivo que ha demostrado ser muy efectivo en la optimización de procesos no lineales [28,29], con saturación de ruido, y en general poco conocidos. Además los AGs son algoritmos que pueden abarcar y aplicarse con éxito a un amplio espectro de problemas y para su diseño es suficiente con tener un conocimiento mínimo a priori acerca del sistema. Esto convierte a los algoritmos genéticos en un paradigma de aplicación deseable en un gran número de escenarios donde la complejidad del problema hace desaconsejable otro tipo de metodologías. En escenarios menos adversos, y especialmente cuando el usuario desea hacer una implementación rápida (aunque esta no sea la más eficiente) se emplea una simplificación de este esquema llamada Simple Genetic Algorithm (SGA).\nUna aproximación evolutiva distinta es la Programación Genética (GP). Este paradigma permite abordar problemas de optimización no lineal basada en un lenguaje simbólico. El paradigma usado en programación genética también utiliza principios de selección darwiniana como la selección basada en fitness, pero los operadores genéticos ahora actúan sobre árboles simbólicos [30]. Por ejemplo, cada uno de estos árboles podría estar formado por sentencias de un lenguaje de programación determinado. Sale de lo convencional y se diferencia de los GA principalmente en lo que respecta a su sistema de representación. Las estructuras sometidas a adaptación son comúnmente programas completos que son ejecutables o conjuntos jerárquicos de reglas evaluables de forma dinámica y con tamaños y formas distintos. Frecuentemente este tipo de sistemas son sistemas híbridos, a modo de ejemplo, podemos citar el caso de la GP-Fuzzy (Reglas difusas construidas a través de programación genética) [31], que comprende una población de reglas difusas / bases (estructuras simbólicas) que son los candidatos a ser soluciones al problema, y evolucionan en respuesta a una presión selectiva inducida por su relativo éxito en la implementación de la conducta deseada. Este no es un ejemplo aislado, en muchos casos las técnicas evolutivas son usadas dentro de soluciones híbridas. Los métodos híbridos han demostrado ser eficaces en el diseño de sistemas inteligentes [32]. En los últimos años han proliferado todo tipo de soluciones híbridas que transgreden las líneas de separación entre diferentes algoritmos para tomas las características buenas de uno y otro. La lógica borrosa, las redes neuronales y los paradigmas evolutivos pueden ser y son metodologías complementarias en los trabajos de diseño e implementación de sistemas inteligentes. Cada uno de esos enfoques tiene sus ventajas e inconvenientes. Para aprovechar las ventajas y eliminar sus desventajas, en aplicaciones operativas reales muchos trabajos proponen la integración de varias de estas metodologías. Estas técnicas incluyen la integración de redes neuronales y técnicas de lógica difusa, así como la combinación de estas dos tecnologías con técnicas de computación evolutiva."
    }, {
      "heading" : "2.1.3 Algoritmos evolutivos para optimización continua. Estrategias de evolución (EE).",
      "text" : "Las Estrategias de Evolución (Evolutionary Strategies en lengua inglesa) son una familia de algoritmos estocásticos de optimización numérica de funciones no-lineales o problemas de optimización continua no convexa donde no es posible conocer a priori la forma del espacio de soluciones ni es factible realizar el cálculo de las derivadas sucesivas. Los algoritmos de Evolución diferencial [86, 87, 88, 89] y CMA-ES (Estrategia de evolución de adaptación mediante covarianzas) [90, 91, 92] son dos ejemplos de miembros de esta familia.\nLas estrategias de evolución fueron desarrolladas por Rechenberg [22] en su intento de resolver problemas difíciles en el campo de la hidrodinámica. La primera versión del algoritmo, llamada (1+1)-EE o estrategia e evolución de dos miembros utilizaba únicamente un padre y un descendiente. El descendiente se mantenía en la población solo si resultaba mejor que su padre. En la siguiente generación el siguiente hijo era calculado a partir de valores normales (ecuación 1), donde t se refiere a la generación actual y N es un vector de números Gaussianos con media 0 y desviación estándar σ.\n),0(1 σNXX tt +=+ (1) En sucesivos trabajos, Rechenberg extendió el concepto de población y propuso otras variantes como la variante (µ+1) – EE [23], en la cual hay µ pares que generan solo un descendiente el cual puede reemplazar al peor padre de la población.\nAlgorithm 2.1: Evolutionary Strategies (De Jong, 2006)\n. Con posterioridad, serian Schwefel et al. quienes mejorarían el concepto añadiendo el uso de múltiples hijos y una variante multi-generacional, respectivamente (µ+λ) – EE, y (µ,λ) - EE [24]. En el primer caso, el el proceso\nde selección la descendencia y los padres son tenidos en cuenta de forma equitativa; En el segundo caso, solo se tiene en cuenta la descendencia. El esquema general de un algoritmo de estrategia de evolución aparece recogido en el algoritmo 2.1. De especial relevancia es el método de selección, que en las estrategias de evolución se realice de forma determinista, razón por la cual solo los mejores individuos pasan a la siguiente generación. El operador principal es la mutación, realizando el operador de recombinación un papel únicamente secundario que incluso se omite en algunos casos.\nSegún el consenso generalizado [102,103] son buenas guías de cuando debería considerarse el uso de EE el que se den varias de las situaciones siguientes:\nFunciones no-lineales Funciones de variables no-separables Espacios de búsqueda no convexos Situaciones de multi-modalidad Funciones caóticas o con gran cantidad de ruido Media o alta dimensionalidad (desde 5 hasta 100 dimensiones)\nCuando una o más e estas características concurren en la naturaleza de la función a optimizar (ver figura 4), el uso de estrategias de evolución puede reportar importantes beneficios."
    }, {
      "heading" : "2.2 Algoritmos evolutivos en aplicaciones industriales e ingeniería",
      "text" : "Los Algoritmos Evolutivos son una potente herramienta en optimización de formas. Debido a su relativa sencillez en comparación con otros métodos algorítmicos, su facilidad de uso, y su capacidad para adaptarse a los problemas de optimización multi-objetivo, los AE han sido aplicados a problemas de optimización de diseños en muchas áreas [21, 35, 40], entre estas aplicaciones se encuentran la resolución de problemas reales de diseño\nde materiales o todo tipo de conjuntos aerodinámicos, desde conducciones de aire, turbinas o compresores, hasta diseños de motores, diseños mecánicos completos o conjuntos de alerones.\nLos AE han sido aplicados con éxito en proyectos de toda envergadura produciendo importantes reducciones de costes y mejoras sustanciales en los resultados conseguidos [93, 94, 95, 96, 97]. Revisando la bibliografía encontramos referencias muy tempranas, dando testimonio de la enorme solidez teórica de la que disponen estas técnicas a día de hoy. Entre ellos, encontramos los trabajos de referencia de Fogel [21] que estudió la aplicabilidad de lo que hoy conocemos como técnicas de programación evolutiva al diseño de autómatas; Rechenberg [22,23], que resolvió con éxito por primera vez problemas industriales de hidráulica utilizando algoritmos poblacionales que simulaban evolución, muy parecidos a las actuales estrategias evolutivas; y Schwefel [24], que estudió su aplicación a problemas de optimización numérica, todos ellos de principios de los 70.\nMás tarde sería Holland [25], quien, basándose en el trabajo que venía desarrollando en el estudio de sistemas adaptativos sentaría la base teórica formal de todos los algoritmos evolutivos actuales dando forma a la teoría de los esquemas [25, 26].\nMucho más recientemente, queda patente, al consultar la bibliografía, un resurgir del interés por los algoritmos evolutivos en la primera mitad de los años 90. Son muchos los trabajos que se publican en esos años, aunque podemos destacar algunos.\nPor ejemplo en el campo de la física encontramos el trabajo de Charbonneau en entre los años 1994 y 1996, centrados en la elaboración de una extensa toolbox para la utilización de algoritmos genéticos en aplicaciones científicas como el modelado del viento solar, la simulación de interacciones entre cuerpos masivamente pesados o la estimación de distancias basadas en el efecto Doppler [33]. En el campo de la acústica, y casi al mismo tiempo, cabe destacar el trabajo de Tang et at. [34], en que se analizan las posibles ventajas del uso de algoritmos genéticos en el análisis de ondas y el procesamiento de\nseñales. Orientados a la industria aeroespacial, encontramos las publicaciones de Keane y Brown [35], que utilizaron un algoritmo genético para producir nuevos diseños para brazos o jirafas destinados a transportar carga pesada que pudiesen montarse en órbita y utilizarse con satélites, estaciones espaciales y otros proyectos de construcción aeroespacial.\nEn un enfoque diferente, Altshuler y Linden [36] a finales de 1997, utilizaron un algoritmo genético para conseguir formas evolutivas de antenas de alambre con propiedades especificadas a priori por la parametrización dada. Y ya en el año 2000, Hughes y Leylanden [37] centraron su investigación en los problemas de optimización multi-objetivo, y aplicaron con éxito algoritmos genéticos modificados a problemas multi-objetivo como el de la clasificación de objetivos basándose en sus reflexiones radar.\nAlgo después, en 2002, Gurfil et al. utilizarían un algoritmo similar aplicándolo a la caracterización de orbitas geocéntricas [38], poniendo especial énfasis en su estudio en encontrar soluciones sub-óptimas, por la importancia que tienen este tipo de órbitas para el posicionamiento de satélites pues permiten una alta tasa de transferencia en comunicaciones mientras se mantienen dentro de un entorno operacional seguro y fuera de perturbaciones térmicas y de radiaciones e interferencias producidas por el campo magnético de la tierra.\nA finales de ese año, en el ámbito de la física, encontramos los trabajos de Metcalfe et al. [39], donde se lleva a cabo la implementación de un algoritmo genético distribuido para la determinación de parámetros globalmente óptimos para el ajuste de modelos matemáticos experimentales en la inferencia de información física y estructural de cuerpos celestes a través del análisis de sus frecuencias de oscilación (estudio de sus periodos de pulsación) abriendo la puerta a la automatización masiva de este tipo de observaciones.\nEn el campo de la optimización de diseños, distinguimos los experimentos de Galvão et al. [40] donde los autores utilizaron algoritmos genéticos para diseñar polímeros conductores de electricidad basados en el carbono, conocidos como polianilinas. Y centrándonos en diseño industrial, cabe mencionar el notorio trabajo de Oyama et al., donde se aplican algoritmos evolutivos al rediseño de rotores transónicos de cohetes [44] así como los trabajos de Liou et al. [45] y Lian et al. [46,47] aplicados al rediseño de los pistones de motores de combustible líquido.\nEn el mismo campo, Kroo et al. [41] describían el uso de métodos de diseño evolutivo en aplicaciones en aeronáutica a través de ejemplos aplicados al diseño de aviones supersónicos (figura 5 izq.) lo que supuso un gran avance en el campo pues, en la aeronáutica, los procesos de optimización cobran vital importancia pues, un pequeño cambio en la geometría del diseño, puede producir grandes deferencias en el flujo del aire a altas velocidades, y una\npequeña variación en el peso estructural de un diseño, puede repercutir enormemente en su rendimiento operativo.\nLas complejas simulaciones necesarias para llevar a cabo las mediciones que permiten validar los nuevos diseños basados en todo un conjunto de hipótesis de comportamiento a menudo representan un tiempo de cómputo elevado, requiriendo en ocasiones la solución de grande sistemas de ecuaciones diferenciales no lineales a veces trabajando con millones de vértices o soluciones estructurales con cientos de miles de grados de libertad. En esta materia, los algoritmos evolutivos son una solución válida que permiten encontrar muchas buenas aproximaciones y hacerlo además de forma paralelizable, rebajando con ello los tiempos de cálculo.\nLa adaptabilidad y la simplicidad de las técnicas evolutivas permiten su aplicación en estos casos obteniendo en muchos casos soluciones más eficientes que la optimización numérica directa y ahorrando un considerable esfuerzo computacional. En este caso concreto el algoritmo propuesto por los autores fue un algoritmo PCGA, un algoritmo que está estrechamente relacionado con las estrategias de evolución [42,43]. El algoritmo PCGA utiliza una población generalmente pequeña con codificación real para las variables. En PCGA un descendiente se crea como combinación lineal de sus padres, concretamente mediante interpolación entre dos diseños anteriores o extrapolación en una dirección dada a partir de estos. El mejor hijo sustituye al peor padre preservando el mejor diseño en la población y requiriendo solo comparaciones locales que pueden ser fácilmente paralelas.\nDe nuevo en el estudio del tratamiento de señales y el filtrado de ruido es interesante el trabajo de Andreas M. Chwatal de 2008 [48], que en este caso propone la utilización de algoritmos evolutivos para el análisis de los datos obtenidos de la sonda espacial europea CAROT, en concreto como alternativa a la descomposión de ondas de interferencia mediante el método de Fourier.\nUnos meses más tarde, encontramos nuevas aplicaciones en ingeniería industrial en los papers de Peniak y Cangelosi [49] quienes utilizaron un algoritmo genético para entrenar una red neuronal de capa oculta utilizada para enviar correcciones de rumbo en tiempo real a vehículos autónomos a partir de la información de las mediciones de los sensores a bordo, y que nos sirve como ejemplo ilustrativo de configuración en un esquema híbrido. Se han publicado numerosas propuestas para intentar mejorar el rendimiento de los EA. Una forma de conseguirlo es mediante la hibridación, como hemos explicado en las secciones anteriores las soluciones hibridas suelen darse con frecuencia, y entre estas soluciones, una fórmula de hibridación frecuente es la unión de un algoritmo evolutivo y un método determinista, por ejemplo el método de descenso del gradiente [50]. Los métodos de descenso de gradiente tienen una tasa de rapidez de convergencia muy elevada y la idea es ceder parte de esta propiedad al EA. La estrategia a seguir es normalmente la de utilizar el EA para descomponer el espacio de soluciones original en varias subregiones para luego dejar al algoritmo determinista la tarea de buscar cerca de esos sub-intervalos. Esta es la estrategia propuesta por Oyama et al. que utiliza un método híbrido basado en un EA y un método basado en gradiente, en este caso un resolutor por programación secuencial cuadrática (SQP).\nEn el último lustro, podemos citar como trabajos innovadores a Dellnitz et al. [51] que implementa un algoritmo de programación genética con la finalidad de generar secuencias óptimas de comandos de control para satélites que se encuentran aparcados en órbitas periódicas; Kang et al. [52], los cuales hacen uso de un algoritmo de programación genética que les permite el estudio de las mejores rutas sobre mapas representados por grafos adaptativos obtenidos mediante el despliegue aleatorio de sensores; y Gosselin et al. [53] que publica un completo review sobre el uso de técnicas evolutivas en simulaciones de incendios y problemas de trasferencia de calor con frontera."
    }, {
      "heading" : "2.3 Algoritmos evolutivos en Ingeniería Civil.",
      "text" : "En lo referente al campo concreto de la ingeniería civil, los primeros trabajos que encontramos donde hay un uso expreso de AE fueron desarrollados por Coello et al. [54, 54b] en 1997, y tenían como objetivo la optimización de del diseño de vigas de hormigón armado. Para tal fin, implementaron un AG simplificado (SGA) en diferentes sistemas de codificación, provisto de una tasa de mutación que se elegía de manera aleatoria en cada iteración (dentro del rango 0.0 - 0.9), un método de selección por torneo y un operador de cruce de 2 puntos. Los autores utilizan métodos empíricos para experimentar con diferentes sistemas de codificación y diferente número de variables de entrada entre las que consideraron el canto y ancho de la viga, el tipo de refuerzo, y el área de su armadura inferior. El resultado final fue la optimización del diseño de\nvigas de hormigón armado sometidas a un conjunto específico de restricciones, teniendo en cuenta factores como el coste de los materiales (hormigón, acero, encofrado, etc...), o el coste del proceso de producción. Los resultados obtenidos fueron comparados con los presentados algunos años antes por Chakrabarty, utilizando programación geométrica e involucrando un menor número de restricciones en el modelo. En esta ocasión, el algoritmo fue una variante de SGA (descrito con anterioridad) que representaba una clara alternativa al proceso tradicional de obtención de estos valores mediante métodos analíticos obteniendo resultados más realistas para los parámetros del modelo habida cuenta del mayor número de restricciones aplicadas y una convergencia más rápida. De manera concurrente Rafiq y Southcombe [55] aplican SGA al problema de optimizar el armado de pilares de hormigón sometidos a esfuerzo axil y flexión esviada. En este último caso, la geometría del pilar no es una variable del problema sino un parámetro de entrada.\nEn 1998, Kuomousis et al. [57] utilizan un algoritmo genético para decidir el número y la ubicación óptimos de barras de armado en secciones de hormigón en edificios de varias plantas. Y un año más tarde, Botello et al. [56] presentan un algoritmo hibrido que utiliza un AG con codificación real que integra fases de búsqueda local mediante el método de recocido simulado; en esta ocasión, el objetivo era, una vez más, la optimización del diseño de estructuras bajo diferentes condiciones de funcionamiento; por un lado, se estudió el diseño óptimo de pórticos de naves industriales sometidos a cargas laterales, y por otro, se analizó la respuesta de elementos estructurales de puentes sometidos a efectos de compresión.\nCuatro años más tarde, Chau y Albermani [58] crean una nueva aplicación informática para el diseño optimizado de depósitos rectangulares de hormigón armado mediante el uso del programa comercial Abaqus ®. Los resultados fueron muy buenos, a pesar de llevar a cabo un análisis relativamente simple del problema basado en la consideración únicamente de tres variables geométricas: canto de las losa de hormigón, cuantía de la armadura y separación entre barras, repitiendo los mismos valores de dichas variables para todos los elementos del depósito. También en 2003, Leps y Sejnoha [59] aplican un algoritmo de 21 variables que combina SA (recocido simulado) y un AG para la optimización de una viga continua simétrica de hormigón de dos vanos con armadura de cortante y de flexión. La técnica en cuestión, conocida como Augmented Simulted Annealing, es similar a un SA en el que: a) se trabaja con una población de soluciones en lugar de con una única solución y b) las nuevas soluciones se obtienen a partir de las existentes mediante la aplicación de los operadores genéticos y no mediante el concepto de movimiento (como se realiza en el SA).\nMas recientemente, Lee y Ahn, proponen el optimizado de pórticos planos de hormigón armado [60] empleando también un algoritmo SGA al que incorporan\nuna estrategia elitista, y, Fairnairn et al. [61], diseñan un procedimiento para optimizar la construcción de estructuras de hormigón en masa utilizando un SGA con codificación binaria y política elitista, y, tomando como variables de entrada, el tipo y coste de materiales, su resistencia térmica o la distribución interna de cada capa de componente; ello permitió estimar diferentes características de funcionamiento de la estructura como su permeabilidad, su distribución térmica, o su estado tensional. El algoritmo propuesto se enfrenta a los resultados obtenidos mediante la aplicación de un modelo termo-quimiomecánico de Coussy al caso concreto de la construcción de una presa para una central hidroeléctrica. De forma muy similar, Lim et al. [62] estudian el balance óptimo de proporciones en la fabricación de hormigón de alta resistencia.\nEn 2005, Sobolev et al. [63], utilizan un algoritmo genético para optimizar las proporciones de materiales compuestos de cemento y hormigón habida cuenta de su repercusión en las propiedades físicas del material (densidad, viscosidad, etc..) así como en el rendimiento (fortaleza, durabilidad, elasticidad, etc..) de la mezcla finalmente obtenida. El algoritmo utilizado es el algoritmo SAGA (SeftAdaptative Genetic Algorithm) propuesto por Amirjanov un año antes [64]. Este algoritmo se basa en un algoritmo genético de evolución diferencial con aprendizaje adaptativo, donde los mejores individuos de la población actúan como focos atractores indicando al algoritmo las zonas prometedoras donde debe concentrarse la búsqueda.\nEn otro ámbito de aplicabilidad, Prendes et al. estúdian el uso de algoritmos genéticos en la evaluación del diseño de edificios de estructura metálica [65] centrando los objetivos de diseño en la resistencia a cargas estáticas, la seguridad y el coste de los materiales. El algoritmo utilizado es un AG de baja especificabilidad utilizando codificación real, un tamaño de población de entre 60 y 100 individuos y tasa de mutación aleatoria con valores entre 0.01 y 0.03, obteniendo mejoras moderadas de en torno al 10% en la estabilidad de la estructura.\nTambién cabe destacar, por el ámbito de aplicación que iniciaron, el trabajo desarrollado por Dhyanjyoti et al. en 2006 [66], donde los autores se valieron de un algoritmo genético para llevar a cabo predicciones sobre el comportamiento elasto-plástico que experimentan los materiales de estructura cristalina cuando se les somete a cargas cíclicas. El artículo estudia además la resistencia de los distintos materiales frente a ratios de deformación constantes, buscando un aumentando la seguridad del diseño y evitando posibles procesos de fatiga. En este caso, la fuente consultada no proporciona mayor detalle acerca del tipo de AG empleado.\nEn los últimos 5 años encontramos las publicaciones de Nehdi et al. [67] en el que se presenta un modelo para medir la resistencia a esfuerzo a cortante en\nvigas de hormigón con refuerzo laminado externo de materiales FRP. Para parametrizar su modelo utilizan un AG simple que parte de un conjunto de 212 datos obtenidos de forma experimental obteniendo un ajuste mejor que el presentado hasta entonces por los modelos y normativas existentes (ACI 440, EuroCode2, Matthys model y Colotty model). Los mismos autores [68] ya habían estudiado la aplicación de AG en la estimación de la resistencia a cortante en vigas de hormigón igualmente reforzadas internamente con FRP. En ambos casos, el algoritmo implementado utilizaba codificación real y un método de selección estocástica con una tasa de mutación baja de 0,005. La capacidad de obtener varias soluciones sub-optimas concurrentemente permitió a los autores experimentar con diferentes materiales y disposiciones.\nCapítulo 3."
    }, {
      "heading" : "El problema de la estimación de",
      "text" : "parámetro de degradación del hormigón solicitado a cortante.\nLa teoría de campo de compresiones (CFT) comprende un conjunto de hipótesis de comportamiento para el hormigón armado que permiten la realización de predicciones sobre la deformación y evolución de ruptura del material sometido a carga y esfuerzo cortante. Hernández-Díaz en su tesis doctoral [101], lleva a cabo una revisión teórica de dicha teoría proponiendo una formulación actualizada del modelo más cercana a como ocurre el deterioro del hormigón armado (en función a la deformación y del comportamiento de tenso-rigidez del acero) que integra muchos de los últimos avances en el campo (Vecchio 1986; Collins 1991; Bentz 2000) y que es más coherente con el comportamiento de la armadura y con el fenómeno real de adherencia entre el hormigón y el acero antes, y una vez se produce el agrietamiento de la estructura. En este contexto, Hernández-Díaz define un parámetro kappa que relaciona la deformación con la consistencia y degradación de la viga, lo que permite, una notable simplificación en las ecuaciones, siendo este, un parámetro que requiere un ajuste experimental ya que resulta de la resolubilidad del sistema no lineal de ecuaciones que conforman las ecuaciones directoras al modelo de campo de compresiones, más las ecuaciones de equilibrio, y del modelo constitutivo del acero. Apoyándonos en sus resultados, tratamos de obtener una mejor estimación para el parámetro kappa utilizando algoritmos de optimización evolutiva que mejoren los resultados obtenidos de forma algebraica por los autores en los trabajos referidos."
    }, {
      "heading" : "3.1 Descripción del problema. Formalización. Restricciones",
      "text" : "Durante los últimos años han aparecido varias teorías que tienen como objetivo estudiar la respuesta del hormigón frente a esfuerzo cortante. Unas de las que constituyen el principal marco teórico son las teorías de campo de compresiones.\nSon varias las hipótesis que se han ido incorporando con aplicaciones importantes en la predicción de deformaciones. Hernandez-Diaz en [101]\nrealiza una revisión actualizada de las teorías de campo de compresiones integrando la denominada hipótesis de Wagner [ref original 12], según la cual, la dirección del campo de tensiones coincide con la del campo principal de deformaciones. Y el parámetro kappa denominado “de degradación del hormigón” introducido por Gil Martín et al [ref original 19] que permite que el área efectiva de hormigón sometida a tracción (Ac) varíe conforme lo hace el agrietamiento. El parámetro kappa (k), resulta además clave en la solubilidad de las ecuaciones constitutivas del acero lo que lo hace merecedor de un estudio en profundidad.\nEl estudio del agrietado del hormigón estructural es un proceso especialmente complejo, al tratarse de un sistema vivo, en el que, conforme avanza la degradación, la fisura inicial se propaga y se ramifica en nuevas grietas donde una parte de las ecuaciones dependen de los ángulos de inclinación de las fisuras. Los modelos de campo de compresiones determinan el ángulo de inclinación de estas gritas considerando las deformaciones de la armadura, tanto trasversal como longitudinal, y del hormigón, sujeto a unas condiciones de equilibrio y a las relaciones de tensión-deformación entre la armadura y el hormigón agrietado, que determinan, como la rigidez tensional del hormigón (la contribución a tracción del hormigón) afecta a la respuesta tenso-deformacional del acero y por tanto al material compuesto.\nEl modelo descrito por Hernández-Díaz está formado por un sistema de once ecuaciones no lineales [101], el presente trabajo no tiene por finalidad la justificación de dichas ecuaciones por lo que pasaremos simplemente a enumerarlas brevemente agrupadas según su naturaleza:\n3 condiciones de equilibrio\n1 2 (tan cot ) w\nV\nz b σ σ θ θ+ = +\n⋅ (1)\n2 2 ; ; 2 1( sin cos )s t s t wA b sσ σ θ σ θ= − ⋅ (2)\n; 1 ; 1 ; 2 ; 2 1 tans x s x s x s x w V A A b zσ σ σ θ + + = (3)\ndonde θ es el ángulo de inclinación de las tensiones de compresión diagonal, V es el esfuerzo cortante, σ1 es la tensión de tracción principal para el hormigón, , σ2 es el esfuerzo de compresión principal en el hormigón, bw es el ancho del entramado, s es la separación de estribo, As;x1, As;x2 y As;t son las áreas de sección transversal de las barras inferiores longitudinales, barras superiores longitudinales y de estribo, respectivamente.\n2 condiciones de compatibilidad\n2 12\n2 1\ntan x t\nt x\nε ε ε ε θ ε ε ε ε − −\n= = − − (4)\n1 2x tε ε ε ε= + − (5)\ndonde εt es la deformación transversal promedio, ε1 es la deformación principal por tracción, εx es la deformación longitudinal media y ε2 es la tensión principal de compresión.\n2 ecuaciones para el comportamiento del hormigón a compresión:\n{ }12, 1min 1 , (0.8 170 )max cf f ε −= ⋅ + (6) 2\n2 2 2 2, 2max\nc c\nf ε εσ ε ε     = −      (7)\nDonde fc es la fuerza a compresión del hormigón, εc es la fuerza compresiva correspondiente a fc, y f2,max es una cota máxima para el estrés a compresión.\n1 ecuación de comportamiento del hormigón a tracción\n1 1\n1 1 1\n1\nfor\n( ) for\n1 500\nc ct\nct ct\nE\nf ε ε ε ασ ε ε ε\nε ≤  ⋅=  >  + ⋅ (8)\nDonde Ec es el módulo de la elasticidad del hormigón y εct es la deformación correspondiente a la resistencia a la tracción del hormigón (fct).\n3 ecuaciones del modelo constitutivo para el acero de las barras de refuerzo (una para la armadura longitudinal inferior, otra para la armadura longitudinal superior, y una para la transversal)\n; 1\n; 1; 1 ; 1 ; 1\n; 1\nmax; 1; 1 max; 1 ; 1\n; 1\n,\n, 1 500\nwhere:\n1 500\ns x x max x\nc xs x ct y x x max x\ns x x\nct\nxy x x c x\ns s s x\nE A f f\nA\nf\nf A\nE E A\nε ε ε κσ ε ε\nε\nε ε κ\n≤ =  − > +\n+ = −\n(9)\n; 2\n; 2; 2 ; 2 ; 2\n; 2\nmax; 2; 2 max; 2 ; 2\n; 2\n,\n, 1 500\nwhere:\n1 500\ns x x max x\nc xs x ct y x x max x\ns x x\nct\nxy x x c x\ns s s x\nE\nA f f\nA\nf\nf A\nE E A\nε ε ε κσ ε ε\nε\nε ε κ\n≤ =  − > +\n+ = −\n(10)\n;\n;; ; ;\n;\nmax;; max; ;\n;\n,\n, 1 500\nwhere:\n1 500\ns x t max t\nc ts t ct y t t max t\ns t x\nct\nty t t c t\ns s s t\nE\nA f f\nA\nf\nf A E E A\nε ε ε κσ ε ε\nε\nε ε κ\n≤ =  − > +\n+ = −\n(11)\nEn las ecuaciones (9), (10) y (11), los subíndices x1, x2 y t denotan el refuerzo longitudinal inferior, superior y transverso respectivamente. En el caso más general, cada tipo de armadura presenta diferente límite elástico (fy), diferente cuantía (As), diferente coeficiente de adherencia hormigón-acero (αi) y diferente área efectiva de hormigón a tracción (Ac), razón por la cual la deformación aparente de cedencia (εmax) definida por la TUCC varía de un tipo de armadura a otro.\nEn total tenemos once ecuaciones y once incógnitas θ, εx, εt, ε1, ε2, σ1, σ2,σs;x1, σs;x2, σs;t, f2,max que pueden ser resueltas para un determinado valor de V (cortante de agotamiento) y κ.\nMediante sustitución y operación algebraica es posible reducir el sistema a un sistema de dos ecuaciones (que denotaremos f y g) y dos incógnitas (ε1, θ); que tomarán distinta forma dependiente del régimen de comportamiento que tomamos como supuesto (elástico o plástico) para cada tipo de armadura. La\nfunción que define la primera ecuación se denota f y representa el equilibrio los refuerzos longitudinales superior e inferior; la función que define la segunda ecuación se denota g y corresponde al equilibrio de refuerzo transversal.\nComo hemos dicho anteriormente, las expresiones de estas funciones dependen de la hipótesis de comportamiento asumida, que posteriormente deberemos verificar en base a la solución general del sistema. En ambas ecuaciones, se denota como \"E\" la hipótesis correspondiente al régimen elástico, y por \"P\" la hipótesis correspondiente al régimen plástico, de forma que para un espécimen concreto indicaremos una terna de tres letras \"E\" o \"P\" que se corresponden a la hipótesis asumida para sus refuerzos longitudinal superior e inferior y trasversal.\n( ); 1 ; 2 1 1 co [ , t 1 5 ] 00 w ct u s x s xE sE\nb f z Vf A A Eθ\nε θ ε − + + + = Ω\n(12)\n; 1 ; 2 ; 1\n1\n1 2 ; 2cot\n1 500 1 50 [ , ] 0\n( ) ctw ct u s x s s x y c x P xE fb f z V A E A f A f κ ε θ ε θ\nε − + Ω + + = + −\nΩ (13)\n( ); 1 ; 2 ; 1 ; 1 ; 2 ; 2\n1\n1 1 cot (\n1 50\n) [ , ]\n0 1 500\nct c x c xw ct u s x y x s xP yP x\nf A Ab f z V A f Af f κ ε θ ε θ ε + − + + − + +\n= Ω (14)\n;\n1\n1 tan 1 50 [ , ] 0 E w ct u\ns t s\nb f s V s E\nz g Aθ ε θ ε ⋅− + + = Ψ\n(15)\n1 ; 1 ; ;\n1\nta ( )\n[ n 1 500 1 50 0\n, ] ctc tP w ct u s t y t\nfb f s V s A f\nz\nA g ε ε θ ε θ κ⋅− + − + + =\nΨ (16)\nDonde los factores Ω y Ψ se definen como:\n2\n2\n1\n2 1\n2 (behavior coefficient for the longitudinal reinforcement)\n1 tan\n(behavior coefficient for the transverse reinforcement) 1 tan\ntan\ntan\nc\nc\nθ\nθ\nε θ λε\nε λε θ\nΩ = +\n+\n+Ψ = +\nSujeto a:\n1\n1\n(cot tan )\n1 500 1 1\nmin , 0.8 170\nct\nw\nc c\nfV\nb z\nf f\nθ θ ε\nε\nλ\n+ − +\n− −    + = \nUna importante propiedad de este sistema reducido es que permite su representación gráfica permitiéndonos obtener la llamada curva de solubilidad\ndel sistema [105]. Esta curva se compone de un conjunto de puntos (κ, ε1) para los que el sistema reducido tiene una solución real.\nEn el estudio referido se llevó a cabo una selección de un total de 81 vigas de hormigón armado ensayadas hasta su agotamiento a cortante, correspondientes a diferentes campañas experimentales y contenidas en la base de datos de cortante editada por Reineck et al. [106]. Para cada una de las vigas se midieron directamente, entre otros parámetros, los valores de cortante (Vexp) y tensión en cercos (σst,exp) en la sección de agotamiento. En la Tabla 1 se resumen los valores experimentales de cortante y tensión en cercos de los 81 especímenes.\nAuthor Beam V u σ st,exp Ahmad et al. (1995) [2] NHW-3b 122779 324.14\nA50 115426 492.41 A75 142203 420 C50 134107 507.59 C75 137977 444 S1-4 277900 450 S2-3 253300 265.96 S4-6 202900 300 S7-4 273600 375\nLeonhardt et al. (1962) [14] ET3 126248 313.92\nMoayer et al. (1974)[18] P20 120096 310.28 Soerensen (1974) [19] T22 128987 399.27\nBernhardt et al. (1986) [4] S8 A 125720 427\nH 50/4 246340 540 H 75/4 255230 530 H 100/4 266530 540\nRC 30 A1 676000 480 RC 30 A2 688000 480 RC 60 A1 990000 480 RC 60 A2 938000 480 RC 60 B1 1181000 480 RC 60 B2 1239000 480 RC 70 B1 1330000 480\nRosenbusch et al. (1999) [18] MHB 2.5-25 98801 267.30\nT3 105000 270 T4 110000 270 T6 205000 270 T7 109000 280 T8 124000 280 T9 154000 280 T13 90000 270 T15 104000 270 T17 134000 280 T19 106000 270 T20 138000 280 T26 179000 280 T32 216000 270 T34 112000 270 T35 115000 270 T37 209000 270 T38 238000 270\nPalaskas et al. (1981) [16]\nKong et al. (1997) [13]\nCladera et al. (2002) [6]\nLevi et al. (1988) [15]\nRegan (1971) [17]\nTabla 1. Listado de los 81 especímenes recopilados por Reineck et al. (2000).\nUna vez sustituidos los parámetros calculados en las ecuaciones reducidas del sistema, se obtiene, para cada una de las hipótesis de comportamiento ya definidas, un conjunto de dos funciones {f,g} parametrizado en V y κ.\nA medida que aumenta el valor de κ, se produce una evolución en la posición relativa de las curvas de ceros de las funciones f y g. Se dice que una hipótesis de comportamiento es soluble cuando ambas funciones tengan al menos un punto de intersección para algún valor de κ. Así mismo, diremos que una sección de hormigón armado es soluble a efectos del ajuste del parámetro κ cuando lo sea al menos una de las hipótesis de comportamiento para el valor experimental de V.\nLa figura 7 representa la curva de puntos (κ, ε1) del espécimen H 75/4 para la hipótesis EEP. De ellos solo una pequeña parte verifica la hipótesis de comportamiento asumida (porción en verde). A efectos del ajuste del parámetro κ, necesitamos especímenes que, además de solubles, sean consistentes. La\nfunción de parámetro buscado será aquel que logre intersectar el mayor número de segmentos consistentes para los 81 especímenes tomados en el experimento y para aquellas de sus hipótesis que sean solubles. Por simplicidad, se buscará el que esta función tome forma polinómica { }3 21 1 1 1( ) ; , , ,a b c d a b c dκ ε ε ε ε= + + + ∈R"
    }, {
      "heading" : "3.2 Propuestas de resolución mediante técnicas evolutivas",
      "text" : "Hernández et al. proponen en [107] resolver el problema de la estimación del parámetro de degradación del hormigón armado mediante algoritmo de computación evolutiva derivado del Little Genetic Algorithm (LGA) propuesto por Coley et al. en el año 2000 para usos académicos e industriales [108]. En pocas palabras el método es una simplificación del esquema general de los algoritmos genéticos donde una población inicial de individuos evolucionan a través de dos mecanismos. Un mecanismo de selección basado en ruleta (proporcional al fitness) y un operador de cruce uniforme de 1 punto con una probabilidad de mutación aleatoria entre 0 y 1. La política de reemplazo realiza el reemplazo completo de la población en cada generación llevando a cabo una estrategia elitista (conservación del más apto individuo). Cada individuo en la población lleva asociado un array R de 4*l bits (genoma) que codifica los cuatro coeficientes de una función cúbica κR(ε1). El array R puede dividirse por tanto en cuatro secuencias de l bits R1, R2, R3 y R4, que resultan de dividir los números enteros cuyos codificaciones en codificación gray son R1, R2, R3 y\nR4, respectivamente, por 2l, y, finalmente, transformar los números obtenidos en valores binarios.\nPara calcular la función de aptitud (fitness) se hace uso de la siguiente función auxiliar Fit(R)∈[0,1].\n( ) { }\n2\n, ,exp , , consistent( ) # ; is consistent st X st X R XF R X X\nσ σ− = ∑\n(17)\nDonde σst,X,exp es la tensión experimental en cercos en el punto de ruptura (σst,exp) cuyo valor conocemos (tabla 1) y σst,X,R es la tensión teórica obtenida por el modelo tomando la ecuación κ=κR(ε1) una vez deshechos los cambios de variable. Como podemos ver, la diferencia cuadrada (σst,X,exp- σst,X,R)\n2 actuará de error cuadrático para la obtención del fitness. En caso de que este valor no pueda calcularse se devolverá un valor de fitness penalizado lo suficientemente alto como para que se descarte la solución.\nPara llevar a término la ejecución del algoritmo se monta un cluster formado por 64 procesadores AMD Opteron de doble núcleo interconectados mediante red GigaNet. Aun así, el tiempo de ejecución del algoritmo fue de 285 horas terminando su ejecución al alcanzar un límite de ejecuciones impuesto a priori partiendo de una población inicial donde ya ha sido incluido una solución aceptable (obtenida por los autores mediante regresión numérica).\nComo consecuencia de haber añadido soluciones artesanales en la población inicial y la alta dispersión de los puntos (ε1, κopt) de las muestras de la base de datos, la aptitud máxima no aumenta mucho más allá del valor inicial máximo de 16,63 % en las primeras generaciones. La figura 8 muestra la representación gráfica del candidato más apto encontrado después de 200 generaciones. Los coeficientes correspondientes a esta solución para la función cúbica 3 2\n1 1 1 1( )R a b c dκ ε ε ε ε= + + + son a=-0.1713, b=0.0346, c=1.2902 y d=-0.4725, y el fitness conseguido 28.40%.\nLa siguiente figura (figura 9) muestra la evolución del fitness conseguido a lo largo de la ejecución del algoritmo. En ella podemos observar como existe una situación de estancamiento donde no existe una evolución real de la aptitud de los individuos de la población y donde la búsqueda ha degenerado en un proceso meramente aleatorio. La causa de este fenómeno posiblemente no puede ser explicada por un único factor sino por una conjunción de varios factores. El más visible de todos ellos es que la búsqueda se realiza en un vasto espacio de soluciones contínuas (el espacio R de 4 dimensiones) y sin embargo el algoritmo empleado es enormemente genérico y no especializado en espacios continuos difíciles. También el hecho de introducir desde el principio soluciones aceptables, en combinación con la política elitista va a desembocar en un empobrecimiento muy rápido de la información genética contenida en la población. Tampoco ayuda la penalización introducida, que en la ejecución considerada era de 5 magnitudes (105). Esta práctica se vuelve aún menos recomendable si consideramos que debido a la naturaleza del problema, puede darse el caso de que dos valores muy cercanos en el espacio de soluciones no comportan solubilidad, es decir, uno puede ser resoluble y\notro no, y, al estar la función fitness indefinida en el caso de la no solubilidad, esta circunstancia lleva al extremo de que un avance en la dirección correcta pueda ser penalizado y por tanto descartado de la búsqueda. Podríamos considerar estos puntos no definidos como ruido en el espacio de soluciones. En este escenario, escapar de los mínimos locales (que serán abundantes) es crucial para poder alcanzar un mínimo global. Si esto es así, entonces la política elitista tendría que ser llevada a cabo con sumo cuidado ya que puede dificultar el que el algoritmo pueda escapar de estos puntos trampa.\nAdemás de estas consideraciones, existen otras de menor gravedad que también deberían ser tenidas en cuenta. Por ejemplo, la forma de cruce (cruce binario uniforme en un punto) no necesariamente es coherente ni con la naturaleza de la solución, ni con la del dato mismo. Es decir, al partir una cadena binaria por la mitad podemos de hecho estar rompiendo un número real el dos mitades (una con la parte entera y otra con la parte decimal) o incluso, estar partiendo por la mitad una de las dos partes. Además cruzar los coeficientes R1 y R2 de una solución con los coeficientes R3 y R4 de otra solución podría no tener sentido. Así mismo, al realizarse la mutación al nivel binario, podemos encontrar que la matación de un bit produzca un salto enorme o diminuto en el valor de un coeficiente según el bit afectado."
    }, {
      "heading" : "3.2.1 Covariance Matrix Adaptation Evolution Strategy (CMA-ES)",
      "text" : "Para tratar de solventar las deficiencias encontradas en el algoritmo básico, se propone la implementación de un algoritmo CMA-ES, que, aunque en sus inicios fue concebido como método de búsqueda local [109] ofrece también un buen rendimiento y calidad en la solución cuando es aplicado en la búsqueda sobre espacios reales cuando el paisaje de búsqueda es complejo o contiene gran cantidad de ruido [110, 111]. El algoritmo CMA-ES siglas de estrategia de evolución des-aleatorizada (ES) con adaptación de matriz de covarianza [90, 91, 92] es un método de búsqueda que basa su heurística en la sucesiva adaptación de la matriz de covarianza completa de una distribución normal (distribución gaussiana) de mutación (figura 11).\nEl esquema general del algoritmo está recogido en la figura 10. En él puede verse como CMA-ES emplea una función gaussiana para generar mu soluciones para luego utilizar lambda mejores candidatos para refinar la propia función de distribución en un proceso iterativo. El bucle principal del algoritmo (ecuación 1) parte de una distribución gaussiana se generan los pesos, afectados por la raíz cuadrada de covarianzas (√C) que actúa como matriz de transformación sobre los datos (1.1).\nA continuación, se utilizan esos pesos para perturbar a la nueve de puntos (1.2) y se evalúan según su aptitud (1.3).\n(Ec1):∀i=1,…,λ: wi ←σ √C Ni (0,1), 1.1\nyi ←y+wi, (L2) 1.2\npi ←F(yi), 1.3\nUna vez terminado el proceso de reajuste se procede a realizar la selección (2.1) y el cruce (2.2) hasta alcanzar el tamaño apropiado indicado por lambda.\n(Ec2): ∀i=1,…,mu\nSel ← Sel U Seleccionar (pi) 2.1\ny * ← Recombinar (sel) 2.2\nCódigo Mathematica equivalente: OffspringPop = Table[ (* Próxima generación *) ( offspring[[4]] = Table[ Random[norm], {n}]; offspring[[3]] = sigma*(SqrtCov.offspring[[4]]); (* Ec 1 .1 *) offspring[[2]] = yParent + offspring[[3]]; (* Ec 1 .2 *) offspring[[1]] = f[offspring[[2]]]; (* Ec 1 .3 *) offspring ), {lambda} ]; (* esta es la nueva pop de tamaño lambda *)\nPuede observarse como el vector obtenido en 1.1 conecta el Yparent de dos generaciones. Posteriormente se procede a auto-adaptar los valores de la propia búsqueda. La ecuación 3, ajusta el vector de dirección de la búsqueda. Aquí el termino (1-(1/tau)) es un término de memoria (cumulacion). Y decrece conforme a la convergencia.\n(Ec3): S- VECTOR DE DIRECCION\nPosteriormente, el vector de dirección calculado es usado para actualizar la matriz C (ecuación 4). Como se ha dicho anteriormente tauC es una ponderación de tiempo en función de la generación actual, como este va decreciendo el elipsoide va colapsando en cada generación.\nCódigo Mathematica equivalente: ParentPop = Take[Sort[OffspringPop], mu]; (* tomar los padres *) Desc = Sum[ParentPop[[m]], {m, 1, mu}]/mu; (* el cruce *) (* Ec 2 *) yParent = Desc[[2]]; (* el nuevo centro masas *)\nCódigo Mathematica equivalente: s = (1-1/tau)*s + Sqrt[mu/tau*(2-1/tau)]*Desc[[3]]/sigma;(* Ec 3 *)\nCódigo Mathematica equivalente: sSigma = (1-1/tauSigma)*sSigma + Sqrt[mu/tauSigma*(2-1/tauSigma)] * Desc[[4]];(* Ec 5 *) sigma = sigma*Exp[(sSigma.sSigma - n)/(2*n*Sqrt[n])]; (* Ec 6 *)\nCapítulo 4."
    }, {
      "heading" : "Experimentación y análisis de los",
      "text" : "resultados obtenidos.\nEn las secciones anteriores, hemos ahondado en la complejidad del problema de estimación del parámetro de degradación del hormigón armado sujeto a esfuerzo cortante y repasado su expresión analítica y las técnicas que se han utilizado tradicionalmente para su abordaje. Así mismo, hemos realizado una introducción a las técnicas de computación evolutiva y descrito en detalle el funcionamiento del subgrupo de estas técnicas conocido como estrategias de evolución. En el presente capítulo, utilizaremos una de esas técnicas (descrita en el apartado anterior) para tratar de conseguir el mejor ajuste para el parámetro de una función polinómica de grado 3 que cumpla los requisitos impuestos por el problema. El problema a resolver puede entonces enunciarse como un problema de optimización donde deberemos encontrar los cuatro coeficientes para el polinomio interpolador del parámetro que consiguen un mejor ajuste. Un vector R candidato a solución vendrá por tanto formado por cuatro números reales {R1, R2, R3, R4} que representan los cuatro coeficientes del polinomio buscado.\nGráfico 1. Evolución del fitness para la implementación básica de cma-es. Pueden observarse como aparecen reiteradas generaciones perdidas.\nEl algoritmo evolutivo utilizado será una versión adaptada y mejorada de la utilizada por los autores en los papers de Beyer et al. de 2001 [29b] y HansGeorg Beyer de 2007.\n0\n0,05\n0,1\n0,15\n0,2\n0,25\n0,3\n0,35\n0,4\n1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 1\n1 0\n1\n1 1\n1\n1 2\n1\n1 3\n1\n1 4\n1\n1 5\n1\n1 6\n1\n1 7\n1\n1 8\n1\n1 9\n1\n2 0\n1\n2 1\n1\n2 2\n1\n2 3\n1\n2 4\n1\nBest\nAl tratarse de un problema especialmente duro computacionalmente y ser muy costoso el cálculo de la función de aptitud, el algoritmo cma aparece como una buena opción por ser un algoritmo que no necesita de un gran número de evaluaciones y que funciona relativamente bien con poblaciones pequeñas.\nEn la gráfica 1, sobre estas líneas se observan los valores de fitness obtenidos para la mejor de tres ejecuciones. En ella observamos como el valor de aptitud crece rápidamente en las primeras generaciones pero se estanca después de 100 generaciones oscilando alrededor del 22%. En la figura 7 están graficadas las mejores soluciones encontradas por el algoritmo durante la misma ejecución para 100, 150 y 200 generaciones.\nSi restringimos la gráfica eliminando valores imposibles (segmentos del primer cuadrante con pendiente ascendente) obtenemos el detalle de la figura 8.\nSin embargo los resultados no dejan de ser pobres y en el gráfico 1, se aprecian varias caídas bruscas que se corresponden con soluciones inválidas que aparecen incluso en estadios avanzados de la búsqueda. Asociamos dichos saltos a valores donde la función fitness no está definida. Y es que para la función de aptitud con la que trabajamos dos polinomios que están muy próximos\npueden tener puntuaciones de aptitud Figure 13. Detalle de las funciones anteriores.\nradicalmente distintos ya un pequeño cambio en los coeficientes puede hacer que el sistema de ecuaciones no tenga solución.\nPara esquivar estos problemas, se decide añadir un valor de penalización, este valor (debe ser un número muy grande en comparación con el rango donde se mueve la función de aptitud), hará que se descarten las soluciones invalidas y que se minimice la posibilidad de que estas sean seleccionadas. También se decide fijar el número de padres considerados a dos ya que de esta forma, un descendiente será combinación lineal de los coeficientes de únicamente dos padres lo que debería minimizar el riesgo de dar saltos bruscos.\nHechos estos cambios volvemos a ejecutar el algoritmo obtenido en este caso una gráfica de fitness donde se observa un valor más estable y una tendencia más clara al alza (grafico 2), aunque los resultados siguen sin ser los esperados.\nGráfico 2. Evolución del fitness en la ejecución de CMA-es con las modificaciones indicadas (versión 2).\nA la vista de la nueva grafica observamos que aparecen esporádicamente, incluso en generaciones muy tempranas, soluciones medianamente buenas con valores de aptitud por encima del 25% (recordemos que el polinomio obtenido por LGA tenía un ajuste del 16,6%) que sin embargo parecen no heredarse a sus descendientes.\n0\n0,05\n0,1\n0,15\n0,2\n0,25\n0,3\n0,35\n0,4\n1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 1\n1 0\n1\n1 1\n1\n1 2\n1\n1 3\n1\n1 4\n1\n1 5\n1\n1 6\n1\n1 7\n1\n1 8\n1\n1 9\n1\n2 0\n1\n2 1\n1\n2 2\n1\n2 3\n1\n2 4\n1 Best\nEsto nos mueve a replantear de nuevo el algoritmo y se decide probar una nueva modificación del algoritmo base buscando producir un comportamiento elitista mediante la incorporación de una memoria global de soluciones, que hará las veces de archivo genético regenerando con periodicidad semialeatoria la variabilidad genética de la población evitando la convergencia prematura y orientando la búsqueda hacia zonas que resultaron ser prometedoras. Así mismo, y para minimizar el número de evaluaciones, se decide hacer variar lambda de manera que el tamaño de la descendencia se ajuste según sea la diferencia entre el máximo fitness y el fitness promedio. El mecanismo descrito, puede observarse en el fragmento de la salida de mensajes que se aprecia en la captura (figura 9). En ella vemos como la población se retroalimenta en ciertas iteraciones de individuos que habían quedado apartados durante un tiempo del flujo evolutivo. Para confirmar el correcto funcionamiento de la modificación, se realizan una nueva serie de ejecuciones y graficamos de nuevo tomando la evolución de la mejor aptitud para cada generación. En la nueva grafica (grafico 3), observamos un crecimiento más suave y progresivo así como una recuperación más rápida cuando el algoritmo avanza en una dirección errónea.\nGráfico 3. Evolución del fitness en la ejecución e algoritmo CMA-es con modificaciones referidas (versión 3)\nCon todo, los resultados son mejores en las nuevas pruebas pero no satisfacen las expectativas del experimento por lo que decidimos sustituir la función buscada (hasta ahora veníamos trabajando con funciones polinómicas de\ngrado 3) por una función de la forma κ(ε1)=a/(1+b*(ε1)^c), ya que creemos que la forma de esta función podría ajustarse mejor a nuestros datos experimentales. Al realizar nuevamente la batería de pruebas nos sorprende gratamente observar como mejoran sensiblemente la correspondencia obteniendo valores de aptitud en el entorno de 50-53%.\nLos datos obtenidos son bastante mejores que en la anterior ocasión con una convergencia clara que por encima de la generación 150 (esta tendencia puede observarse en el grafico 4) e incluye ya hasta el tercer decimal. Parece que la nueva función favorece la búsqueda disminuyendo la inter-dependencia al estar los parámetros del problema menos acoplados. Por otra parte, el mejor ajuste podría favorecer el que el algoritmo pase más tiempo en el espacio de soluciones aceptables.\n0\n0,05\n0,1\n0,15\n0,2\n0,25\n0,3\n0,35\n0,4\n0,45\n0,5\n1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 1\n1 0\n1\n1 1\n1\n1 2\n1\n1 3\n1\n1 4\n1\n1 5\n1\n1 6\n1\n1 7\n1\n1 8\n1\n1 9\n1\n2 0\n1\n2 1\n1\n2 2\n1\n2 3\n1\n2 4\n1\nBest\nGráfico 4. Evolución del fitness en la ejecución de algoritmo CMA-es con modificaciones indicadas (versión 4)\nTomemos por ejemplo el caso de la función polinómica; En él, el parámetro R1 se correspondía con el coeficiente del término de orden 3, así, que una variación en este coeficiente alteraba considerablemente el resultado, mientras, que un cambio similar en el coeficiente de orden 1 alteraría en pequeña medida el resultado.\n3) Mejores para generación 25 (verde), 50 (gris), 75 (rojo), amarillo (100), rosa (150). A partir de ahí las gráficas se solapaban y es difícil graficar. DER. Los cinco mejores resultados obtenidos. El mejor, representado en color azul verdoso (y=1,04901/1+52,3107*x^0,660418) obtuvo un 51% de ajuste.\nLa figura 12 muestra la evolución del mejor candidato con un lapso de 25 generaciones. En ella puede observarse gráficamente cómo evolucionan los parámetros de entrada para ajustar la función (izquierda) y como se lleva a cabo el ajuste fino local (derecha). La convergencia ahora puede apreciarse claramente en la fase de ajuste local cuando el tamaño del paso tiende a hacerse muy pequeño.\n0\n0,1\n0,2\n0,3\n0,4\n0,5 0,6 1\n1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 1\n1 0\n1\n1 1\n1\n1 2\n1\n1 3\n1\n1 4\n1\n1 5\n1\n1 6\n1\n1 7\n1\n1 8\n1\n1 9\n1\n2 0\n1\n2 1\n1\n2 2\n1\n2 3\n1\n2 4\n1\nnkappa\nBest\nCapítulo 5."
    }, {
      "heading" : "Conclusiones y posibles trabajos",
      "text" : "futuros.\nLos resultados obtenidos demuestran que las estrategias de evolución pueden mejorar notablemente los resultados obtenidos mediante métodos de regresión y tienen una aplicación clara en problemas donde el paisaje de búsqueda no se conoce o es imposible de calcular.\nEn el problema en cuestión que nos ocupa son varios los inconvenientes con los que nos hemos encontrado y que hemos tenido que lidiar. El primero de ellos es la costosa evaluación de candidatos y la imposibilidad de aproximar su aptitud mediante alguna directriz heurística.\nLa representación de los parámetros del problema, que en nuestro caso se correspondían con los coeficientes del polinomio interpolador promovían el solapamiento de las variables. De forma que, por ejemplo, un pequeño cambio en el coeficiente de orden 3 podía alterar enormemente el resultado mientras que un cambio similar en el término independiente solo ocasionaba un cambio pequeño. Para mayor dificultad, encontramos que la función de aptitud no estaba definida en todos los valores de forma que era enormemente difícil para el algoritmo aprender acerca del espacio de soluciones y un camino evolutivo prometedor podía acabar degenerando en soluciones inválidas.\nComo línea de investigación futura debería proponerse una reformulación de la representación de los candidatos que permitiese una mayor libertad al método genético, a la vez que aprovechase mejor sus capacidades y limitase la degeneración de la población. Por ejemplo, podría considerarse permitir al algoritmo elegir el tipo de función interpoladora o incluso construir la suya propia a partir de bloques constructivos básicos.\nTambién, y debido a las capacidades implícitas de paralelización de los AE en futuras ampliaciones podrían considerarse estrategias de evolución en implementación paralela para explotar al máximo las posibilidades de ejecución concurrente en multi-cpu, complutación GPU, o ejecución en Grid dedicado de alto rendimiento.\nBibliografía\n[1] MOSER, Martin; JOKANOVIC, Dusan P.; SHIRATORI, Norio. An algorithm for the\nmultidimensional multiple-choice knapsack problem. IEICE transactions on\nfundamentals of electronics, communications and computer sciences, 1997, vol. 80, no\n3, p. 582-589..\n[2] TAMIR, Arie. New pseudopolynomial complexity bounds for the bounded and other\ninteger Knapsack related problems. Operations Research Letters, 2009, vol. 37, no 5,\np. 303-306.\n[3 TAVAKKOLI-MOGHADDAM, Reza; RAHIMI-VAHED, Alireza; MIRZAEI, Ali Hossein.\nA hybrid multi-objective immune algorithm for a flow shop scheduling problem with bi-\nobjectives: weighted mean completion time and weighted mean tardiness. Information\nSciences, 2007, vol. 177, no 22, p. 5072-5090.\n[4] VEGA GARCIA, C., et al. Applying neural network technology to human-caused\nwildfire occurrence prediction. AI applications, 1996, vol. 10..\n[5] SUD, Avneesh, et al. Real-time path planning for virtual agents in dynamic\nenvironments. En ACM SIGGRAPH 2008 classes. ACM, 2008. p. 55.\n[6] SUD, Avneesh, et al. Real-time navigation of independent agents using adaptive\nroadmaps. En Proceedings of the 2007 ACM symposium on Virtual reality software and\ntechnology. ACM, 2007. p. 99-106..\n[7] STENTZ, Anthony. Optimal and efficient path planning for partially-known\nenvironments. En Robotics and Automation, 1994. Proceedings., 1994 IEEE\nInternational Conference on. IEEE, 1994. p. 3310-3317.\n[8] LI, Yi; GUPTA, Kamal. Motion planning of multiple agents in virtual environments\non parallel architectures. En Robotics and Automation, 2007 IEEE International\nConference on. IEEE, 2007. p. 1009-1014.\n[9] SANCHES, Carlos Alberto Alonso; SOMA, Nei Yoshihiro; YANASSE, Horacio\nHideki. An optimal and scalable parallelization of the< i> two-list</i> algorithm for the\nsubset-sum problem. European Journal of Operational Research, 2007, vol. 176, no 2,\np. 870-879.\n[10] PLAZA, Antonio; VALENCIA, David; PLAZA, Javier. An experimental comparison\nof parallel algorithms for hyperspectral analysis using heterogeneous and\nhomogeneous networks of workstations. Parallel Computing, 2008, vol. 34, no 2, p. 92-\n114..\n[11] FINK, Andreas; VOΒ, Stefan. Generic metaheuristics application to industrial\nengineering problems. Computers & Industrial Engineering, 1999, vol. 37, no 1, p. 281-\n284.\n[12]GLOVER, Fred W.; KOCHENBERGER, Gary A. Handbook of metaheuristics\n(International series in operations research & management science). 2003.\n[21] FOGEL, David B. Artificial Intelligence Through Simulated Evolution. Wiley-IEEE\nPress, 1967. New York: Wiley Publishing\n[22] RECHENBERG, Ingo. Cybernetic solution path of an experimental problem. 1965.\n[23] RECHENBERG, Ingo, I.: Evolutionsstrategie : Optimierung technischer Systeme\nnach Prinzipien der biologischen Evolution. 15. Stuttgart-Bad Cannstatt : Frommann-\nHolzboog, 1973.\n[24] SCHWEFEL, H.P. Numerische Optimierunguon Computer-Modellenmittels der\nEzdutionsstrategie, 1977, Volume 26 of Interdisciplinary systems research. Basel\nBirkhauser.\n[25] HOLLAND, John H. Outline for a logical theory of adaptive systems. Journal of the\nACM (JACM), 1962, vol. 9, no 3, p. 297-314..\n[26] HOLLAND, John H. Adaptation in natural and artificial systems: An introductory\nanalysis with applications to biology, control, and artificial intelligence. U Michigan\nPress, 1975.\n[26b] JOHN, Holland. Holland, Adaptation in Natural and Artificial Systems: An\nIntroductory Analysis with Applications to Biology, Control and Artificial Intelligence.\n1992.\n[27] TURCK-CHIÈZE, Sylvaine, et al. The solar interior. Physics reports, 1993, vol.\n230, no 2, p. 57-235..\n[28] EIBEN, Agosten E.; SMITH, James E. Introduction to evolutionary computing.\nBerlin: Springer, 2010.\n[29] MICHALEWICZ, Zbigniew. Genetic algorithms+ data structures= evolution\nprograms. springer, 1996..\n[29b] BEYER, Hans-Georg. The theory of evolution strategies. Springer, 2001.\n[30] ZAFRA, Amelia; GIBAJA, Eva L.; VENTURA, Sebastián. Multiple instance learning\nwith multiple objective genetic programming for web mining.Applied Soft Computing,\n2011, vol. 11, no 1, p. 93-102\n[31] AKBARZADEH-T, M. R., et al. Soft computing paradigms for hybrid fuzzy\ncontrollers: experiments and applications. En Fuzzy Systems Proceedings, 1998. IEEE\nWorld Congress on Computational Intelligence., The 1998 IEEE International\nConference on. IEEE, 1998. p. 1200-1205..\n[32] QIN, Hao; YANG, Simon X. Adaptive neuro-fuzzy inference systems based\napproach to nonlinear noise cancellation for images. fuzzy sets and systems, 2007, vol.\n158, no 10, p. 1036-1063..\n[33] CHARBONNEAU, Paul. Genetic algorithms in astronomy and astrophysics.The Astrophysical Journal Supplement Series, 1995, vol. 101, p. 309.\n[34] TANG, Kit-Sang, et al. Genetic algorithms and their applications. Signal Processing Magazine, IEEE, 1996, vol. 13, no 6, p. 22-37.\n[35] KEANE, A. J. The design of a satellite beam with enhanced vibration performance using genetic algorithm techniques. The Journal of the Acoustical Society of America, 1996, vol. 99, no 4, p. 2599-2603..\n[36] ALTSHULER, Edward E.; LINDEN, Derek S. Wire-antenna designs using genetic algorithms. Antennas and Propagation Magazine, IEEE, 1997, vol. 39, no 2, p. 33-43..\n[37] HUGHES, Evan J.; LEYLAND, Maurice. Using multiple genetic algorithms to generate radar point-scatterer models. Evolutionary Computation, IEEE Transactions on, 2000, vol. 4, no 2, p. 147-163.\n[38] VASILE, Massimiliano. Hybrid behavioral-based multiobjective space trajectory optimization. En Multi-Objective Memetic Algorithms. Springer Berlin Heidelberg, 2009. p. 231-253.\n[39] METCALFE, Travis S.; CHARBONNEAU, Paul. Stellar structure modeling using a parallel genetic algorithm for objective global optimization. Journal of Computational Physics, 2003, vol. 185, no 1, p. 176-193.\n[40] GIRO, R., M. Cyrillo y D.S. Galvão. Designing conducting polymers using genetic algorithms.Chemical Physics Letters, vol.366, no.1-2, p.170-175, 2002.\n[41] KROO, I. Aeronautical Applications of Evolutionary Design. VKI lecture series on Optimization Methods & Tools for Multicriteria/Multidisciplinary Design, 2004.\n[42] HANSEN, Nikolaus; OSTERMEIER, Andreas. Adapting arbitrary normal mutation distributions in evolution strategies: The covariance matrix adaptation. En Evolutionary Computation, 1996., Proceedings of IEEE International Conference on. IEEE, 1996. p. 312-317..\n[43] HANSEN, Nikolaus; MÜLLER, Sibylle D.; KOUMOUTSAKOS, Petros. Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES). Evolutionary Computation, 2003, vol. 11, no 1, p. 1-18.\n[44] OYAMA, Akira; LIOU, Meng-Sing; OBAYASHI, Shigeru. Transonic axial-flow blade shape optimization using evolutionary algorithm and three-dimensional Navier-Stokes solver. En 9th AIAA/ISSMO Symposium and Exhibit on Multidisciplinary Analysis and Optimization, Atlanta, GA. 2002. [45] LIAN, Yongsheng; OYAMA, Akira; LIOU, Meng-Sing. Progress in design optimization using evolutionary algorithms for aerodynamic problems.Progress in Aerospace Sciences, 2010, vol. 46, no 5, p. 199-223. [46] LIAN, Yongsheng; LIOU, Meng-Sing. Multiobjective Optimization Using Coupled Response Surface Model and Evolutionary Algorithm. AIAA journal, 2005, vol. 43, no 6, p. 1316-1325. [47] LIAN, Yongsheng; LIOU, Meng-Sing; OYAMA, Akira. An enhanced evolutionary algorithm with a surrogate model. En Proceedings of genetic and evolutionary computation conference, Seattle, WA. 2004. [48] HWATAL, Andreas M.; RAIDL, Günther R. Determining orbital elements of extrasolar planets by evolution strategies. En Computer Aided Systems Theory– EUROCAST 2007. Springer Berlin Heidelberg, 2007. p. 870-877.\n[49] PENIAK, Martin; MAROCCO, Davide; CANGELOSI, Angelo. Autonomous robot exploration of unknown terrain: A preliminary model of mars rover robot. En Proceedings of 10th ESA Workshop on Advanced Space Technologies for Robotics and Automation. 2008.\n[50] OYAMA, Akira; LIOU, Meng-Sing. Multiobjective optimization of rocket engine pumps using evolutionary algorithm. Journal of Propulsion and Power, 2002, vol. 18, no 3, p. 528-535.\n[51] SCHÜTZE, Oliver, et al. Designing optimal low-thrust gravity-assist trajectories using space pruning and a multi-objective approach.Engineering Optimization, 2009, vol. 41, no 2, p. 155-181.\n[52] KANG, Shin-Jin; KIM, YongO; KIM, Chang-Hun. Live path: adaptive agent navigation in the interactive virtual world. The Visual Computer, 2010, vol. 26, no 6-8, p. 467-476.\n[53] GOSSELIN, Louis; TYE-GINGRAS, Maxime; MATHIEU-POTVIN, François. Review of utilization of genetic algorithms in heat transfer problems.International Journal of Heat and Mass Transfer, 2009, vol. 52, no 9, p. 2169-2188.\n[54] COELLO, CA Coello; CHRISTIANSEN, Alan D.; HERNÁNDEZ, F. Santos. A simple genetic algorithm for the design of reinforced concrete beams.Engineering with Computers, 1997, vol. 13, no 4, p. 185-196.\n[54b] COELLO, Carlos Coello; HERNÁNDEZ, Filiberto Santos; FARRERA, Francisco Alonso. Optimal design of reinforced concrete beams using genetic algorithms. Expert systems with Applications, 1997, vol. 12, no 1, p. 101-108.\n[55] RAFIQ, Mohammad Y.; SOUTHCOMBE, Colin. Genetic algorithms in optimal design and detailing of reinforced concrete biaxial columns supported by a declarative approach for capacity checking. Computers&structures, 1998, vol. 69, no 4, p. 443- 457.\n[56] MARROQUÍN, José Luis; BOTELLO RIONDA, Salvador; OÑATE, Eugenio. Un modelo de optimización estocástica aplicado a la optimización de estructuras de barras prismáticas. Revista internacional de métodos numéricos para cálculo y diseño en ingeniería, 1999, vol. 15, no 4, p. 425-434.\n[57] KOUMOUSIS, Vlasis K.; ARSENIS, S. J. Genetic algorithms in optimal detailed design of reinforced concrete members. Computer Aided Civil and Infrastructure Engineering, 1998, vol. 13, no 1, p. 43-52.\n[57b] GOVINDARAJ, V.; RAMASAMY, J. V. Optimum detailed design of reinforced concrete continuous beams using genetic algorithms. Computers & structures, 2005, vol. 84, no 1, p. 34-48.\n[58] CHAU, K. W.; ALBERMANI, F. Knowledge-based system on optimum design of liquid retaining structures with genetic algorithms. Journal of structural engineering, 2003, vol. 129, no 10, p. 1312-1321.\n[59] LEPŠ, Matěj; ŠEJNOHA, Michal. New approach to optimization of reinforced concrete beams. Computers & structures, 2003, vol. 81, no 18, p. 1957-1966.\n[60] LEE, C.; AHN, J. Flexural design of reinforced concrete frames by genetic algorithm. Journal of structural engineering, 2003, vol. 129, no 6, p. 762-774.\n[61] FAIRBAIRN, Eduardo MR, et al. Optimization of mass concrete construction using genetic algorithms. Computers & structures, 2004, vol. 82, no 2, p. 281-299.\n[62] LIM, Chul-Hyun; YOON, Young-Soo; KIM, Joong-Hoon. Genetic algorithm in mix proportioning of high-performance concrete. Cement and Concrete Research, 2004, vol. 34, no 3, p. 409-420.\n[63] AMIRJANOV, Adil; SOBOLEV, Konstantin. Optimal proportioning of concrete aggregates using a self-adaptive genetic algorithm. Computers and Concrete, 2005, vol. 2, no 5, p. 411-421.\n[64] QIN, A. Kai; SUGANTHAN, Ponnuthurai N. Self-adaptive differential evolution algorithm for numerical optimization. En Evolutionary Computation, 2005. The 2005 IEEE Congress on. IEEE, 2005. p. 1785-1791.\n[65] GERO, Mª Belén Prendes, et al. APLICACIÓN DE UN ALGORITMO GENÉTICO ELITISTA EN LA OPTIMIZACIÓN DE EDIFICIOS METÁLICOS..\n[66] DEKA, Dhyanjyoti. Crystal plasticity modeling of deformation and creep in polycrystalline, Metallurgical and Materials Transactions A, 2006, vol. 37, no 5, p. 1371-1388.\n[67] NEHDI M, El Chabib H, Said A. Genetic algorithm model for shear capacity of RC beams reinforced with externally bonded FRP. Materials and Structures 44:1249– 1258, 2011\n[68] NEHDI M, El Chabib H, Said A. Proposed shear design equations for FRPreinforced concrete beams based on genetic algorithms approach. ASCE J Mater CivEng 19:1033–1042, 2007.\n[69] BONISSONE, Piero P. Soft computing: the convergence of emerging reasoning technologies. Soft computing, 1997, vol. 1, no 1, p. 6-18.\n[70] KECMAN, Vojislav. Learning and soft computing: support vector machines, neural networks, and fuzzy logic models. MIT press, 2001.\n[71] MITRA, Sushmita; PAL, Sankar K.; MITRA, Pabitra. Data mining in soft computing framework: A survey. IEEE transactions on neural networks, 2002, vol. 13, no 1, p. 3- 14.\n[72] SANCHEZ, Elie; SHIBATA, Takanori; ZADEH, Lotfi Asker (ed.). Genetic algorithms and fuzzy logic systems: Soft computing perspectives. World Scientific, 1997.\n[73] GONZÁLEZ, Javier Serrano, et al. Optimization of wind farm turbines layout using an evolutive algorithm. Renewable Energy, 2010, vol. 35, no 8, p. 1671-1681.\n[74] MAULIK, Ujjwal; BANDYOPADHYAY, Sanghamitra. Genetic algorithm-based clustering technique. Pattern recognition, 2000, vol. 33, no 9, p. 1455-1465.\n[75] DEMIRIZ, Ayhan; BENNETT, Kristin P.; EMBRECHTS, Mark J. Semi-supervised clustering using genetic algorithms. Artificial neural networks in engineering (ANNIE99), 1999, p. 809-814.\n[76] ONG, Yew-Soon; NAIR, Prasanth B.; LUM, Kai Yew. Max-min surrogate-assisted evolutionary algorithm for robust design. Evolutionary Computation, IEEE Transactions on, 2006, vol. 10, no 4, p. 392-404.\n[77] GUTIÉRREZ, José A. García; COTTA, Carlos; LEIVA, Antonio J. Fernández. Design of emergent and adaptive virtual players in a war RTS game. Foundations on Natural and Artificial Computation. Springer Berlin Heidelberg, 2011. p. 372-382.\n[78] FLOREANO, Dario; MONDADA, Francesco. Evolution of homing navigation in a real mobile robot. Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on, 1996, vol. 26, no 3, p. 396-407.\n[79] JANG, Jyh-Shing Roger; SUN, Chuen-Tsai; MIZUTANI, Eiji. Neuro-fuzzy and soft computing-a computational approach to learning and machine intelligence [Book Review]. Automatic Control, IEEE Transactions on, 1997, vol. 42, no 10, p. 1482-1484.\n[80] JANG, Jyh-Shing Roger; SUN, Chuen-Tsai; MIZUTANI, Eiji. Neuro-fuzzy and soft computing-a computational approach to learning and machine intelligence [Book Review]. Automatic Control, IEEE Transactions on, 1997, vol. 42, no 10, p. 1482-1484.\n[81] AKBARZADEH-T, M.-R., et al. Soft computing for autonomous robotic systems. Computers & Electrical Engineering, 2000, vol. 26, no 1, p. 5-32\n[82] ZADEH, Lotfi A. Some reflections on soft computing, granular computing and their roles in the conception, design and utilization of information/intelligent systems. Soft Computing-A fusion of foundations, methodologies and applications, 1998, vol. 2, no 1, p. 23-25.\n[83] DASGUPTA, Dipankar; JI, Zhou; GONZALEZ, Fabio. Artificial immune system (AIS) research in the last five years. En Evolutionary Computation, 2003. CEC'03. The 2003 Congress on. IEEE, 2003. p. 123-130.\n[84] ZHANG, Zheng, et al. A greedy algorithm for aligning DNA sequences.Journal of Computational biology, 2000, vol. 7, no 1-2, p. 203-214.\n[85] WOLSEY, Laurence A. An analysis of the greedy algorithm for the submodular set covering problem. Combinatorica, 1982, vol. 2, no 4, p. 385-393.\n[86] QUINTERO, Luis Vicente Santana. Un Algoritmo Basado en Evolución Diferencial para Resolver Problemas Multiobjetivo. 2004. Tesis Doctoral. Tesis de Maestría CINVESTAV-IPN.\n[87] RICE, Kenneth V.; STORN, Rainer M.; LAMPINEN, Jouni A. Differential evolution a practical approach to global optimization. 2005.\n[88] SUN, Jianyong; ZHANG, Qingfu; TSANG, Edward PK. DE/EDA: A new evolutionary algorithm for global optimization. Information Sciences, 2005, vol. 169, no 3, p. 249-262.\n[89] QIN, A. Kai; SUGANTHAN, Ponnuthurai N. Self-adaptive differential evolution algorithm for numerical optimization. En Evolutionary Computation, 2005. The 2005 IEEE Congress on. IEEE, 2005. p. 1785-1791.\n[90] HANSEN, Nikolaus; KERN, Stefan. Evaluating the CMA evolution strategy on multimodal test functions. En Parallel Problem Solving from Nature-PPSN VIII. Springer Berlin Heidelberg, 2004. p. 282-291.\n[91] ROS, Raymond; HANSEN, Nikolaus. A simple modification in CMA-ES achieving linear time and space complexity. En Parallel Problem Solving from Nature–PPSN X. Springer Berlin Heidelberg, 2008. p. 296-305.\n[92] AUGER, Anne; HANSEN, Nikolaus. A restart CMA evolution strategy with increasing population size. En Evolutionary Computation, 2005. The 2005 IEEE Congress on. IEEE, 2005. p. 1769-1776.\n[93] SAVIC, Dragan A.; WALTERS, Godfrey A. Genetic algorithms for least-cost design of water distribution networks. Journal of Water Resources Planning and Management, 1997, vol. 123, no 2, p. 67-77.\n[94] BAKIRTZIS, Anastasios G., et al. Optimal power flow by enhanced genetic algorithm. Power Systems, IEEE Transactions on, 2002, vol. 17, no 2, p. 229-236.\n[95] DA SILVA, Edson Luiz; GIL, Hugo Alejandro; AREIZA, Jorge Mauricio. Transmission network expansion planning under an improved genetic algorithm. En Power Industry Computer Applications, 1999. PICA'99. Proceedings of the 21st 1999 IEEE International Conference. IEEE, 1999. p. 315-321.\n[96] DASGUPTA, Dipankar. Computational Intelligence in Cyber Security. EnComputational Intelligence for Homeland Security and Personal Safety, Proceedings of the 2006 IEEE International Conference on. IEEE, 2006. p. 2-3.\n[97] VLAHOPOULOS, N.; HART, C. G. A Multidisciplinary design optimization approach to relating affordability and performance in a conceptual submarine design. Journal of Ship Production and Design, 2010, vol. 26, no 4, p. 273-289.\n[98] DE JONG, Kenneth A. Evolutionary computation: a unified approach. Cambridge: MIT press, 2006\n[99] SIVAKUMAR, Raghupathy; SINHA, Prasun; BHARGHAVAN, Vaduvur. CEDAR: a core-extraction distributed ad hoc routing algorithm. Selected Areas in Communications, IEEE Journal on, 1999, vol. 17, no 8, p. 1454-1465.\n[100] SHEN, Chien-Chung; JAIKAEO, Chaiporn. Ad hoc multicast routing algorithm with swarm intelligence. Mobile Networks and Applications, 2005, vol. 10, no 1-2, p. 47- 59.\n[101] HERNÁNDEZ-DÍAZ, A. M. Revisión de las teorías de campo de compresiones en hormigón estructural. 2013.\n[102] DE JONG, Kenneth A. Evolutionary computation: a unified approach. Cambridge: MIT press, 2006.\n[103] EBELING, Werner. Applications of evolutionary strategies. Systems Analysis Modelling Simulation, 1990, vol. 7, no 1, p. 3-16.\n[104] COLLINS, Michael P.; MITCHELL, Denis. Prestressed concrete structures. Englewood Cliffs: Prentice Hall, 1991.\n[105] HERNÁNDEZ-DÍAZ A M; GARCÍA-ROMÁN, M.D; Gil-Martín L.M.; HernándezMontes. Why is not always solvable the shear model for reinforced concrete beams proposed by the Compression Field Theories, 2012.\n[106] REINECK, K.; Kuchma, D.; Fitik, B., Formelsammlumg für die Datenerhebungs dateil Stahlbetonbalken mit Bügel, 2011.\n[107] HERNÁNDEZ-DÍAZ, A.M; GARCÍA-ROMÁN, M.D. Introducing a Degradation Parameter in the Shear Design of Reinforced Concrete Beams, 2013.\n[108] COLEY, David A. An introduction to genetic algorithms for scientists and engineers. World Scientific, 1999.\n[109] HANSEN, Nikolaus; OSTERMEIER, Andreas. Adapting arbitrary normal mutation distributions in evolution strategies: The covariance matrix adaptation. En Evolutionary Computation, 1996., Proceedings of IEEE International Conference on. IEEE, 1996. p. 312-317.\n[110] MÜLLER, Sibylle D.; HANSEN, Nikolaus; KOUMOUTSAKOS, Petros. Increasing the serial and the parallel performance of the CMA-evolution strategy with large populations. En Parallel Problem Solving from Nature—PPSN VII. Springer Berlin Heidelberg, 2002. p. 422-431.\n[111] JASTREBSKI, Grahame A.; ARNOLD, Dirk V. Improving evolution strategies through active covariance matrix adaptation. En Evolutionary Computation, 2006. CEC 2006. IEEE Congress on. IEEE, 2006. p. 2814-2821.\nAnexo I."
    }, {
      "heading" : "Código fuente de los algoritmos",
      "text" : "implementados.\n(* ::Package:: *)\n(* basado en los ejemplos de codigo del paper de Beyer et al. at 2001 y Hans-Georg Beyer de 2007 *)\n(* ************************************************************************* *)\n(* ENTRADA & SALIDA *)\n(* ************************************************************************* *)\nmessages=OpenWrite[path<>\"messages.txt\"];\ninputdata=path<>\"DataBase_Kuchma_et_al_nonprestressed_mathematica.xls\";\nvalidhyp=path<>\"Critical_Outlet_kappa_refined.xls\";\ninitpop=path<>\"initial_population.csv\";\nthetaseeds=path<>\"Strut-angle_seeds.xls\";\noutputxls=path<>\"Salida.csv\"; outputpng=path<>\"Salida.png\";\n(* ************************************************************************* *)\n(* PARAMETROS PROBLEMA *)\n(* ************************************************************************* *)\nepsilon1seeds=3; (* Number of equispaced seeds for epsilon1 to try *)\nspecimens={\"NHW-3b\",\"A50\",\"A75\",\"C50\",\"C75\",\"S1-4\",\"S2-3\",\"S4-6\",\"ET3\",\"P20\",\"T-22\",\"S8 A\",\"H 50/4\",\"H 75/4\",\"H 100/4\",\"RC 30 A1\",\"RC 30 A2\",\"RC 60 B1\",\"MHB 2.5- 25\",\"T3\",\"T4\",\"T6\",\"T7\",\"T8\",\"T9\",\"T13\",\"T15\",\"T17\",\"T19\",\"T20\",\"T26\",\"T32\",\"T34\",\"T35\",\"T37\",\"T38\"};\npenal=10^5;\n(* ************************************************************************* *)\n(* Parametros de estrategia *)\n(* ************************************************************************* *)\nmu = 4; (* número de padres considerados *)\nmaxlambda = 32; (* tama\\[NTilde]o de la descendencia *)\nminlambda = 12; (* tama\\[NTilde]o de la descendencia *)\nyInit = Table[2, {3}]; (* vector inicial *)\nsigmaInit = 0.2; (* initial global mutation strength sigma *)\nsigmaMin = 10^-8; (* Criterio de parada sigma < sigmaMin *)\n(* ************************************************************************* *)\n(* Inicialización de la distribución de arranque *)\n(* ************************************************************************* *)\nnorm = NormalDistribution[0, 1]; (* inicializamos distribucion normal *)\nn = Dimensions[yInit][[1]]; (* dimensiones del espacio de busqueda *)\ntau = Sqrt[n]; tauC = n^2; tauSigma = Sqrt[n];\nCov = IdentityMatrix[n]; (* matriz covarianzas inicialmente igual a identidad *)\nsigma = sigmaInit;\ns = Table[0, {n}];\nsSigma = Table[0, {n}];\n(* Inicializacion Memoria *)\nIndividual = {f[yInit], yInit, yInit, yInit};\nParentPop = Table[Individual, {mu}];\nyParent = yInit; (* centroide inicial *)\noffspring = {{}, {}, {}, {}}; (* reservamos mem para la pob *)\nelite = {{}, {}, {}, {}}; (* reservamos mem para la pob *)\n(* Definicion de Funciones *)\nftest[x_] := Module[ {n}, n = Dimensions[x][[1]];\nSum[ i*x[[i]]^3, {i, 1, n}] ]\nf[R_]:=Module[{i,j,T,fit,Es,EqSystem,suma,\\[Alpha],\\[Alpha]1,\\[Alpha]2,\\[Alpha]t,z,bw,Asx1,Asx2,Ast,s,fy x1,fyx2,fyt,fc,\\[Epsilon]c,fctm,\\[Epsilon]ctm,Acx1,Acx2,Act,Ec,V,\\[Sigma]stexp,sol,\\[Kappa]limx1,\\[Kappa ]limx2,\\[Kappa]limt,\\[Kappa]lim2x1,\\[Kappa]lim2x2,\\[Kappa]lim2t,\\[Kappa]lim1,\\[Kappa]lim2,epsilonx,e psilont,\\[Epsilon]yx1,\\[Epsilon]yx2,\\[Epsilon]yt,check,hypx1,hypx2,hypt,emaxx1,emaxx2,emaxt,solx1,sol x2,solt,iter,y0,x0,x1,x2,a,b,c,d,H,spec,line,hyp,h,diff,specdiff,seedvector,S,lineseed,Sol},\nIf [R[[1]]==Null, return penal];If [R[[2]]==Null, return penal]; (* casos imposibles *)\nIf [R[[3]]==Null, return penal]; (* casos imposibles *)\na=Coef[R[[1]]];\nb=Coef[R[[2]]];\nc=Coef[R[[3]]];\nd=Coef[R[[4]]];\nPrint[\"Polinomio candidato \",a,\"/(1+\",b,\"*\\[Epsilon]1^\",c,\")\"];\nT=Import[inputdata];\nEs=200000;\n(* PARA CADA ESPECIMEN *)\nFor[spec=1,spec<=Length[specimens],spec++,\nline=0;\nFor[i=1,i<=Length[T[[1]]] && line==0, i++,\nIf[T[[1,i,1]]==specimens[[spec]],line=i];\n];\nIf[line==0 ,\nWrite[messages,\"Specimen \"<>ToString[specimens[[spec]]]<>\" is not in DataBase. Check if\n'path' for DataBase file is right.\"];\nExit[];\n];\n\\[Alpha]=T[[1,line,7]];\n\\[Alpha]1=T[[1,line,4]];\n\\[Alpha]2=T[[1,line,5]];\n\\[Alpha]t=T[[1,line,6]];\nz=T[[1,line,8]];\nbw=T[[1,line,9]];\nAsx1=T[[1,line,10]];\nAsx2=T[[1,line,11]];\nAst=T[[1,line,12]];\ns=T[[1,line,13]];\nfyx1=T[[1,line,14]];\nfyx2=T[[1,line,15]];\nfyt=T[[1,line,16]];\nfc=T[[1,line,17]];\nEc=8500Power[fc+8, (3)^-1];\n\\[Epsilon]c=T[[1,line,18]];\nfctm=T[[1,line,19]];\n\\[Epsilon]ctm=fctm/Ec;\nAcx1=T[[1,line,20]];\nAcx2=T[[1,line,21]];\nAct=T[[1,line,22]];\nEs=200000;\nV=T[[1,line,23]];\n\\[Epsilon]yx1= fyx1/Es;\n\\[Epsilon]yx2=fyx2/Es;\n\\[Epsilon]yt=fyt/Es;\n(* ESTE ES EL VALOR EXPERIMENTAL *)\n\\[Sigma]stexp=T[[1,line,2]];\n(* Limits to 'Degradation Parameter' for each type of reinforcement *)\n(* valores de frontera *)\n\\[Kappa]limx1=Asx1*fyx1/(\\[Alpha]1*Acx1*fctm);\nIf[\\[Alpha]2!=0,\\[Kappa]limx2=Asx2*fyx2/(\\[Alpha]2*Acx2*fctm)];\n\\[Kappa]limt=Ast*fyt/(\\[Alpha]t*Act*fctm);\n\\[Kappa]lim1=Min[\\[Kappa]limt,If[\\[Alpha]2!=0,Min[\\[Kappa]limx1,\\[Kappa]limx2],\\[Kappa]limx\n1]];\n\\[Kappa]lim2x1=\\[Kappa]limx1*(4500*\\[Epsilon]yx1+(1+1500*\\[Epsilon]yx1)^(3/2)-\n1)/(6750*\\[Epsilon]yx1);\nIf[\\[Alpha]2!=0,\\[Kappa]lim2x2=\\[Kappa]limx2*(4500*\\[Epsilon]yx2+(1+1500*\\[Epsilon]yx2)^(3\n/2)-1)/(6750*\\[Epsilon]yx2)];\n\\[Kappa]lim2t=\\[Kappa]limt*(4500*\\[Epsilon]yt+(1+1500*\\[Epsilon]yt)^(3/2)-\n1)/(6750*\\[Epsilon]yt);\n\\[Kappa]lim2=Min[\\[Kappa]lim2t,If[\\[Alpha]2!=0,Min[\\[Kappa]lim2x1,\\[Kappa]lim2x2],\\[Kappa]l\nim2x1]];\n(* Valores iniciales para el parámetro theta para el newton-rap *)\nS=Import[thetaseeds];\nFor[i=1,i<=Length[S[[1]]] && lineseed==0, i++,\nIf[S[[1,i,1]]==specimens[[spec]],\nlineseed=i;\nseedvector={};\n];\n];\nIf[lineseed==0 ,\nWrite[messages,\"Specimen \"<>ToString[specimens[[spec]]]<>\" has no theta seeds. Check if\n'path' for theta seeds file is right.\"];\nseedvector={30 Degree,30 Degree,30 Degree,30 Degree,30 Degree}; (* caso default *)\n];\n(* Hipótesis válidas para cada espécimen. Al menos una de ellas es cierta *)\nH=Import[validhyp];\nline=0;\nFor[i=1,i<=Length[H[[1]]] && line==0, i++,\nIf[H[[1,i,1]]==specimens[[spec]],line=i];\n];\nIf[line==0 ,\nWrite[messages,\"Specimen \"<>specimens[[spec]]<>\" has no valid behaviour\nhypotheses. Check if 'path' for hypotheses file is right.\"];\nExit[];\n];\nhyp={};\nFor[h=0,h<=4,h++,\nIf[H[[1,line,2+9*h]]!=\"\" && H[[1,line,2+9*h]]!=\"Null\",\nhyp=Append[hyp,Table[StringTake[H[[1,line,2+9*h]],{k}],{k,1,3}]];\nIf[lineseed!=0,seedvector=Append[seedvector,S[[1,lineseed,2+h]]]];\n];\n];\ndiff={};\nFor[i=1,i<=Length[hyp],i++,\nj=1;\nspecdiff={};\nWhile[j<=epsilon1seeds, (*** Search for solutions with several seeds for epsilon1 ***)\nClear[\\[Sigma]1,\\[Sigma]2,\\[Sigma]sx1,\\[Sigma]sx2,\\[Sigma]st,\\[Epsilon]1,\\[Epsilon]2,\\[Epsilon]x\n,\\[Epsilon]t,\\[Theta],f2max,\\[Kappa]];\n(* sustituciones de variables *)\n\\[Sigma]1=\\[Alpha]*fctm/(1+Sqrt[500*\\[Epsilon]1]);\n\\[Sigma]2=(Tan[\\[Theta]]+1/Tan[\\[Theta]])*V/(z*bw)-\\[Sigma]1;\nf2max=Min[fc,fc/(0.8+170*\\[Epsilon]1)];\n\\[Epsilon]2=\\[Epsilon]c*(1-Sqrt[1-\\[Sigma]2/f2max]);\n\\[Epsilon]t=(\\[Epsilon]2*Tan[\\[Theta]]^2+\\[Epsilon]1)/(Tan[\\[Theta]]^2+1);\n\\[Epsilon]x=\\[Epsilon]1+\\[Epsilon]2-\\[Epsilon]t;\n\\[Kappa]=a/(1+b*(\\[Epsilon]1)^c);\n\\[Sigma]sx1=If[hyp[[i,1]]==\"E\",Es*\\[Epsilon]x,fyx1-\n\\[Kappa]*(Acx1/Asx1)*\\[Alpha]1*fctm/(1+Sqrt[500*\\[Epsilon]x])];\n\\[Sigma]sx2=If[\\[Alpha]2==0,0,If[hyp[[i,2]]==\"E\",Es*\\[Epsilon]x,fyx2-\n\\[Kappa]*(Acx2/Asx2)*\\[Alpha]2*fctm/(1+Sqrt[500*\\[Epsilon]x])]];\n\\[Sigma]st=If[hyp[[i,3]]==\"E\",Es*\\[Epsilon]t,fyt-\n\\[Kappa]*(Act/Ast)*\\[Alpha]t*fctm/(1+Sqrt[500*\\[Epsilon]t])];\n(* soluciona el sistema mediante N-R *)\nEq1[\\[Epsilon]1_,\\[Theta]_]:=Evaluate[Asx1*\\[Sigma]sx1+Asx2*\\[Sigma]sx2-\nV/Tan[\\[Theta]]+\\[Sigma]1*bw*z];\nEq2[\\[Epsilon]1_,\\[Theta]_]:=Evaluate[\\[Sigma]st*Ast-\n(\\[Sigma]2*Sin[\\[Theta]]^2-\\[Sigma]1*Cos[\\[Theta]]^2)*bw*s];\nQuiet[Sol=Check[FindRoot[{Eq1[\\[Epsilon]1,\\[Theta]],Eq2[\\[Epsilon]1,\\[Theta]]},{\\[Epsil\non]1,\\[Epsilon]ctm+(Min[\\[Epsilon]yx1,\\[Epsilon]yx2]+\\[Epsilon]yt-\\[Epsilon]ctm)*(j1)/(epsilon1seeds-1)},{\\[Theta],seedvector[[i]]}, MaxIterations->10000],0]];\n(* hay solución pero está fuera de rango *)\nIf[Length[Sol]!=0,\n\\[Epsilon]1=\\[Epsilon]1/.Sol[[1]];\n(* POLINOMIO INTERPOLADOR para el valor k *)\n\\[Kappa]=a/(1+b*(\\[Epsilon]1)^c);\nIf[\\[Epsilon]1<\\[Epsilon]ctm || \\[Kappa]>\\[Kappa]lim2,\n(* Print[specimens[[spec]],\" - \",hyp[[i]],\" ->\nSoluci\\[OAcute]n fuera de rango \\[Epsilon]1=\" ,\\[Epsilon]1,\" < \\[Epsilon]ctm=\", \\[Epsilon]ctm,\" \\[Theta]=\",\\[Theta]/.Sol[[2]],\" \\[Kappa]=\", a*(\\[Epsilon]1*1000)^3+b*(\\[Epsilon]1*1000)^2+c*\\[Epsilon]1*1000+d ]; *)\nSol=0; (* Descarto solucion *)\n];\n];\n(* hay solucion. eq1 y eq2 se interceptan *)\nIf[Length[Sol]!=0,\n(*Print [Sol];*)\n(* deshacer el cambio de variables *)\n\\[Theta]=\\[Theta]/.Sol[[2]];\n\\[Sigma]1=\\[Alpha]*fctm/(1+Sqrt[500*\\[Epsilon]1]);\n\\[Sigma]2=(Tan[\\[Theta]]+1/Tan[\\[Theta]])*V/(z*bw)-\\[Sigma]1;\nf2max=Min[fc,fc/(0.8+170*\\[Epsilon]1)];\n\\[Epsilon]2=\\[Epsilon]c*(1-Sqrt[1-\\[Sigma]2/f2max]);\n\\[Epsilon]t=(\\[Epsilon]2*Tan[\\[Theta]]^2+\\[Epsilon]1)/(Tan[\\[Theta]]^2+1); (* la\nsolucion contradice la hipotesis inicial?. *)\n\\[Epsilon]x=\\[Epsilon]1+\\[Epsilon]2-\\[Epsilon]t;(* la solucion\ncontradice la hipotesis inicial?. *)\n(* ESTE ES EL VALOR TEORICO *)\n\\[Sigma]st=If[hyp[[i,3]]==\"E\",Es*\\[Epsilon]t,fyt-\n\\[Kappa]*(Act/Ast)*\\[Alpha]t*fctm/(1+Sqrt[500*\\[Epsilon]t])];\nsolx1=FindRoot[Es*(\\[Epsilon]yx1-x)==\n\\[Kappa]*(Acx1/Asx1)*\\[Alpha]1*fctm/(1+Sqrt[500*x]),{x,\\[Epsilon]yx1}];\nemaxx1=x/.solx1[[1]];\nIf[\\[Alpha]2!=0,\nsolx2=FindRoot[Es*(\\[Epsilon]yx2-x)==\n\\[Kappa]*(Acx2/Asx2)*\\[Alpha]2*fctm/(1+Sqrt[500*x]),{x,\\[Epsilon]yx2}];\nemaxx2=x/.solx2[[1]];\n];\nsolt=FindRoot[Es*(\\[Epsilon]yt-x)==\n\\[Kappa]*(Act/Ast)*\\[Alpha]t*fctm/(1+Sqrt[500*x]),{x,\\[Epsilon]yt}];\nemaxt=x/.solt[[1]];\n(* Calculo las diferencias cuadradas *)\nspecdiff=If[((\\[Epsilon]x<=emaxx1 &&\nhyp[[i,1]]==\"E\")||(\\[Epsilon]x>=emaxx1 && hyp[[i,1]]==\"P\")) &&(\\[Alpha]2==0 ||( \\[Epsilon]x<=emaxx2 && hyp[[i,2]]==\"E\")||(\\[Epsilon]x>=emaxx2 && hyp[[i,2]]==\"P\")) && ((\\[Epsilon]t<=emaxt && hyp[[i,3]]==\"E\")||(\\[Epsilon]t>=emaxt && hyp[[i,3]]==\"P\")), Append[specdiff,(\\[Sigma]st\\[Sigma]stexp)^2],Append[specdiff,penal]];\n];\n(* NO hay solucion. eq1 y eq2 no se interceptan *)\nIf[Length[Sol]==0,\nspecdiff=Append[specdiff,penal];\n];\nj++;\n]; (* fin for por cada especimen. *)\ndiff=Append[diff,Min[specdiff]];\n]; (* fin for por cada hipotesis. siguiente hipotesis posible *)\nsuma=suma+Min[diff];\n]; (* fin for por cada especimen *)\nIf[suma==Null,\nReturn[penal]; (* caso imposible *) ];\nsuma=Evaluate[suma/(Length[specimens]*10^2)];\nfit=Max[0,1-(suma/1000)]//N;\nIf [suma<1000,Print [\"Suma \",suma, \", Fitness Norm. \", fit]; ,Print [\"No se alcanza solucion.\"];Return[penal];];\nReturn[suma]; ];\nCoef[x_]:=Tan[\\[Pi]*x-\\[Pi]/2];\nCoord[y_]:=ArcTan[y]/\\[Pi]+1/2;\n(* **************************************************************************** *)\n(* ITERACION PRINCIPAL *)\n(* **************************************************************************** *)\nWhile[ True,\nSqrtCov = Transpose[CholeskyDecomposition[Cov]]; (* matriz transformacion *)\ngeneracion=generacion+1;\nlambda=Max[minlambda,(maxlambda-generacion)] //N;\nPrint[\"Generacion \",generacion,\" lambda=\", lambda];\nfmed=0;\nOffspringPop = Table[ (* Proxima generacion *)\n( offspring[[4]] = Table[ Random[norm], {n}]; (* E1 .1 *)\noffspring[[3]] = sigma*(SqrtCov.offspring[[4]]); (* E1 .2 *)\noffspring[[2]] = yParent + offspring[[3]]; (* E1 .3 *)\noffspring[[1]] = f[offspring[[2]]]; fmed = (fmed + offspring[[1]])/2; (* E1 .4 *)\noffspring\n), {lambda} ]; (* esta es la nueva pop de tam lambda *)\nIf [Element[generacion,Primes],OffspringPop = Union[OffspringPop,Take[Sort[elite],\nMin[5,Length[elite]-1]]];]; (* elitismo *)\nParentPop = Take[Sort[OffspringPop], mu]; (* tomar los padres *)\nPrint[\"f_Mean = \", fmed, \", f_Best = \", ParentPop[[1, 1]]]; (* el mejor *)\nPrint[\"Candidato a elite: \", f[ParentPop[[1, 2]]]];\nWrite[messages,\"Generacion;\"<> ToString[generacion] <> \";Mejor Fitness;\"<>ToString[ParentPop[[1,\n1]]]<> \";Med Fitness;\"<>ToString[fmed]];\nIf [Mod[generacion,10]==0, Print[\"Best = \", ParentPop[[1]]]; ];\nIf [generacion==1, elite=Take[Sort[OffspringPop], 1];,elite=Union[elite,Take[Sort[OffspringPop], 1]];]; (*\nelitismo *)\nPrint[\"nueva elite = \", elite];\nRecombinant = Sum[ParentPop[[m]], {m, 1, mu}]/mu; (* el cruce *) (* E2 *)\nyParent = Recombinant[[2]]; (* el nuevo centro *)\ns = (1-1/tau)*s + Sqrt[mu/tau*(2-1/tau)]*Recombinant[[3]]/sigma;(* E3 *)\nCov = (1-1/tauC)*Cov + Outer[Times, (s/tauC), s]; (* E4 *)\nCov = (Cov + Transpose[Cov])/2; (* forzamos la simetria *)\nsSigma = (1-1/tauSigma)*sSigma +\nSqrt[mu/tauSigma*(2-1/tauSigma)]*Recombinant[[4]]; (* E5 *)\nsigma = sigma*Exp[(sSigma.sSigma - n)/(2*n*Sqrt[n])]; (* E6 *)\nIf[ sigma < sigmaMin, Break[] ]\nIf[ generacion > maxgens, Break[] ]\n] (* termina si se cumple *)\nMejores=Take[Sort[elite], 5];\nExport[outputxls,ParentPop[[1, 1]],\"CSV\"];\nExport[outputxls,Mejores,\"CSV\"];\nClose[messages];\nAnexo II."
    }, {
      "heading" : "Autorización para la defensa.",
      "text" : "Dr. D. José María Cecilia Canales profesor de la UCAM.\nCERTIFICA: que el Trabajo Fin de Grado titulado “ANÁLISIS E IMPLEMENTACIÓN DE"
    }, {
      "heading" : "ALGORITMOS EVOLUTIVOS PARA LA OPTIMIZACIÓN DE SIMULACIONES EN INGENIERÍA CIVIL.”",
      "text" : "que presenta D. José Alberto García Gutiérrez, para optar al título oficial de Grado en\nIngeniería informática mención en Ingeniería del Software, ha sido realizado bajo su dirección.\nA su juicio reúne las condiciones necesarias para ser presentado en la Universidad Católica San\nAntonio de Murcia y ser juzgado por el tribunal correspondiente.\nMurcia, a 1 de Junio de 2014"
    } ],
    "references" : [ {
      "title" : "An algorithm for the multidimensional multiple-choice knapsack problem",
      "author" : [ "Martin MOSER", "Dusan P. JOKANOVIC", "Norio. SHIRATORI" ],
      "venue" : "IEICE transactions on fundamentals of electronics, communications and computer sciences,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1997
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "La tarea se vuelve aún más difícil cuando el problema a resolver tiene una alta dimensionalidad por la presencia de un gran número de características [1,2] o variables de entrada [3,4].",
      "startOffset" : 150,
      "endOffset" : 155
    }, {
      "referenceID" : 0,
      "context" : "Para calcular la función de aptitud (fitness) se hace uso de la siguiente función auxiliar Fit(R)∈[0,1].",
      "startOffset" : 98,
      "endOffset" : 103
    }, {
      "referenceID" : 0,
      "context" : "2 *) offspring[[1]] = f[offspring[[2]]]; (* Ec 1 .",
      "startOffset" : 15,
      "endOffset" : 18
    }, {
      "referenceID" : 0,
      "context" : "[1] MOSER, Martin; JOKANOVIC, Dusan P.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 0,
      "context" : "norm = NormalDistribution[0, 1]; (* inicializamos distribucion normal *)",
      "startOffset" : 25,
      "endOffset" : 31
    }, {
      "referenceID" : 0,
      "context" : "n = Dimensions[yInit][[1]]; (* dimensiones del espacio de busqueda *)",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 0,
      "context" : "ftest[x_] := Module[ {n}, n = Dimensions[x][[1]];",
      "startOffset" : 44,
      "endOffset" : 47
    }, {
      "referenceID" : 0,
      "context" : "If [R[[1]]==Null, return penal];If [R[[2]]==Null, return penal]; (* casos imposibles *)",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 0,
      "context" : "a=Coef[R[[1]]];",
      "startOffset" : 9,
      "endOffset" : 12
    }, {
      "referenceID" : 0,
      "context" : "For[i=1,i<=Length[T[[1]]] && line==0, i++,",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 0,
      "context" : "For[i=1,i<=Length[S[[1]]] && lineseed==0, i++,",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 0,
      "context" : "For[i=1,i<=Length[H[[1]]] && line==0, i++,",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 0,
      "context" : "Sol[[1]];",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "solx1[[1]];",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 0,
      "context" : "solx2[[1]];",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 0,
      "context" : "solt[[1]];",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 0,
      "context" : "offspring[[1]] = f[offspring[[2]]]; fmed = (fmed + offspring[[1]])/2; (* E1 .",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 0,
      "context" : "offspring[[1]] = f[offspring[[2]]]; fmed = (fmed + offspring[[1]])/2; (* E1 .",
      "startOffset" : 61,
      "endOffset" : 64
    }, {
      "referenceID" : 0,
      "context" : "Print[\"f_Mean = \", fmed, \", f_Best = \", ParentPop[[1, 1]]]; (* el mejor *)",
      "startOffset" : 50,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "Print[\"f_Mean = \", fmed, \", f_Best = \", ParentPop[[1, 1]]]; (* el mejor *)",
      "startOffset" : 50,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "Print[\"Candidato a elite: \", f[ParentPop[[1, 2]]]];",
      "startOffset" : 41,
      "endOffset" : 47
    }, {
      "referenceID" : 0,
      "context" : "Write[messages,\"Generacion;\"<> ToString[generacion] <> \";Mejor Fitness;\"<>ToString[ParentPop[[1, 1]]]<> \";Med Fitness;\"<>ToString[fmed]];",
      "startOffset" : 93,
      "endOffset" : 99
    }, {
      "referenceID" : 0,
      "context" : "Write[messages,\"Generacion;\"<> ToString[generacion] <> \";Mejor Fitness;\"<>ToString[ParentPop[[1, 1]]]<> \";Med Fitness;\"<>ToString[fmed]];",
      "startOffset" : 93,
      "endOffset" : 99
    }, {
      "referenceID" : 0,
      "context" : "If [Mod[generacion,10]==0, Print[\"Best = \", ParentPop[[1]]]; ];",
      "startOffset" : 54,
      "endOffset" : 57
    }, {
      "referenceID" : 0,
      "context" : "Export[outputxls,ParentPop[[1, 1]],\"CSV\"];",
      "startOffset" : 27,
      "endOffset" : 33
    }, {
      "referenceID" : 0,
      "context" : "Export[outputxls,ParentPop[[1, 1]],\"CSV\"];",
      "startOffset" : 27,
      "endOffset" : 33
    } ],
    "year" : 2014,
    "abstractText" : "This paper studies the applicability of evolutionary algorithms, particularly, the evolution strategies family to estimation of a degradation parameter (referred as kappa parameter) for the shear design of reinforced concrete beams, a problem which have an expensive computational cost and highly relevant in the design of pillars and reinforced concrete structures, which however, has not been covered extensively in the present literature.",
    "creator" : "PDFCreator Version 1.2.3"
  }
}