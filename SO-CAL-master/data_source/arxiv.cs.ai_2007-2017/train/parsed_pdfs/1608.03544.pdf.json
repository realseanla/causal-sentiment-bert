{
  "name" : "1608.03544.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "On Context-Dependent Clustering of Bandits",
    "authors" : [ "Claudio Gentile", "Shuai Li", "Purushottam Kar", "Alexandros Karatzoglou", "Giovanni Zappella" ],
    "emails" : [ "<claudio.gentile@uninsubria.it>." ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "In many prominent applications of bandit algorithms, such as computational advertising, web-page content optimization and recommendation systems, one of the main sources of information is embedded in the preference relationships between users and the items served. Preference patterns, emerging from clicks, views or purchase of items, are typically exploited through collaborative filtering techniques.\nIn fact, it is common knowledge in recommendation systems practice that collaborative effects carry more information about user preferences than, say, demographic metadata (e.g., (Pilaszy & Tikk, 2009)). Yet, as content recommendation functionalities are incorporated in very diverse online services, the requirements often differ vastly. For instance, in a movie recommendation system, where the catalog is relatively static and ratings for items will accumulate, one can easily deploy collaborative filtering methods\n1DiSTA, University of Insubria, Italy 2University of Cambridge, United Kingdom 3IIT Kanpur, India 4Telefonica Research, Spain 5Amazon Berlin, Germany. Correspondence to: Claudio Gentile <claudio.gentile@uninsubria.it>.\nUnder review.\nsuch as matrix factorization or restricted Boltzmann machines. The same methods become practically impossible to use in more dynamic environments such as in news or YouTube video recommendation, where we have to deal with a continuous stream of new items to be recommended, along with new users to be served. These dynamic environments pose a dual challenge to recommendation methods: 1) How to present the new items to the users (or, vice versa, which items to present to new users), in order to optimally gather preference information on the new content (exploration), and 2) How to use all the available user-item preference information gathered so far (exploitation). Ideally, one would like to exploit both the content information but also, and more importantly, the collaborative effects that can be observed across users and items.\nWhen the users to serve are many and the content universe (or content popularity) changes rapidly over time, recommendation services have to show both strong adaptation in matching user preferences and high algorithmic scalability/responsiveness so as to allow an effective on-line deployment. In typical scenarios like social networks, where users are engaged in technology-mediated interactions influencing each other’s behavior, it is often possible to single out a few groups or communities made up of users sharing similar interests and/or behavior. Such communities are not static over time and, more often than not, are clustered around specific content types, so that a given set of users can in fact host a multiplex of interdependent communities depending on specific content items, which can be changing dramatically on the fly. We call this multiplex of interdependent clusterings over users induced by the content universe a context-dependent clustering. In addition to the above, the set of users itself can change over time, for new users get targeted by the service, others may sign out or unregister. Thus, a recommendation method has to readily adapt to a changing set of both users and items.\nIn this paper, we introduce and analyze the CAB (ContextAware clustering of Bandit) algorithm, a simple and flexible algorithm rooted in the linear contextual bandit framework that does the above by incorporating collaborative effects which traditional approaches to contextual bandits ignore (e.g., (Auer, 2002; Li et al., 2010; Chu et al., 2011; Abbasi-Yadkori et al., 2011)). CAB adapts to match user preferences in the face of a constantly evolving content\nar X\niv :1\n60 8.\n03 54\n4v 2\n[ cs\n.L G\n] 2\n7 Fe\nb 20\n17\nuniverse and set of targeted users. CAB implements the context-dependent clustering intuition by computing clusterings of bandits which allows each content item to cluster users into groups (which are few relative to the total number of users), where within each group, users tend to react similarly when that item gets recommended. CAB distinguishes itself in allowing distinct items to induce distinct clusterings, which is frequently observed in practice (e.g., (Sutskever et al., 2009)). These clusterings are in turn suggestive of a natural context-dependent feedback sharing mechanism across users. CAB is thus able to exploit collaborative effects in contextual bandit settings in a manner similar to the way neighborhood techniques are used by batch collaborative filtering.\nWe analyze our algorithm from both the theoretical and the experimental standpoint. On the theoretical side, we provide a regret analysis where the number of users engaged essentially enters in the regret bound only through the expected number of context-dependent clusters over the users, a natural measure of the predictive hardness of learning these users. We also extend this result to provide a sharper bound under sparsity assumptions on the user model vectors. On the experimental side, we present comparative evidence on production and real-world datasets that our algorithm significantly outperforms, in terms of prediction performance, state-of-the-art contextual bandit algorithms that either do not leverage any clustering at all or do so in a context-independent fashion."
    }, {
      "heading" : "1.1. Related Work",
      "text" : "The literature on contextual bandit algorithms is too large to be surveyed here. In the sequel, we briefly mention what we believe are the works most closely related to ours. The technique of sequentially clustering users in the bandit setting was introduced in (Maillard & Mannor, 2014; Gentile et al., 2014), but has also been inspired by earlier references, e.g., (Azar et al., 2013) on transfer learning for stochastic bandits, and (Djolonga et al., 2013) on low-rank (Gaussian Process) bandits. This led to further developments such as (Nguyen & Lauw, 2014), which relies on k-means clustering, and (Korda et al., 2016) which proposes distributed clustering of confidence ball algorithms for solving linear bandit problems in peer to peer networks. Related papers that implement feedback sharing mechanisms by leveraging (additional) social information among users include (Cesa-Bianchi et al., 2013; Wu et al., 2016). In all these cases, the way users are grouped is not context-dependent. Even more related to our work is the recent paper (Li et al., 2016) which proposes to simultaneously cluster users as well as items, with item clusters dictating user clusters. However, a severe limitation of this approach is that the content universe has to be finite and known in advance, and in addition to that the result-\ning algorithm is somewhat involved. Compared to all these previous works, our approach distinguishes itself for being simple and flexible (e.g., we can seamlessly accomodate the inclusion/exclusion of users), as well as for performing feedback propagation among users in a context-dependent manner. As will be demostrated in Section 5, this offers significant performance boosts in real-world recommendation settings."
    }, {
      "heading" : "2. Notation and Preliminaries",
      "text" : "We will consider the bandit clustering model standard in the literature, but with the crucial difference that we will allow user behavior similarity to be represented by a family of clusterings that depend on the specific feature (or context) vector x under consideration. In particular, we let U = {1, . . . , n} represent the set of n users. An item, represented by its feature vector x ∈ Rd can be seen as inducing a (potentially different) partition of the user set U into a small number m(x) of clusters {U1(x), U2(x), . . . , Um(x)(x)}, where m(x) n. Users belonging to the same cluster Uj(x) share similar behavior w.r.t. x (e.g., they both like or both dislike the item represented by x), while users lying in different clusters have significantly different behavior.\nThis is a much more flexible model that allows users to agree on their opinion of certain items and disagree on others, something that often holds in practice. It is important to note that the mapping x → {U1(x), U2(x), . . . , Um(x)(x)} specifying the actual partitioning of U into the clusters determined by x (including the number of clustersm(x)), and the common user behavior within each cluster are unknown to the learner, and have to be inferred based on user feedback.\nTo make things simple, we assume that the contextdependent clustering is determined by the linear functions x → u>i x, each one parameterized by an unknown vector ui ∈ Rd hosted at user i ∈ U , with ||ui|| = 1 for all i, in such a way that if users i, i′ ∈ U are in the same cluster w.r.t. x then u>i x = u > i′x, and if i, i\n′ ∈ U are in different clusters w.r.t. x then |u>i x − u>i′x| ≥ γ, for some gap parameter γ > 0.1 We will henceforth call this assumption the γ-gap assumption. We note that such gap assumptions are standard in this literature (Gentile et al., 2014; Li et al., 2016). For user vectors u1, . . . ,un ∈ Rd corresponding to the n users (note that these are unknown to the algorithm), context x ∈ Rd, and user index i ∈ U , we denote by Ni(x) the true neighborhood of i w.r.t. x, i.e., Ni(x) = {j ∈ U : u>j x = u>i x}. Hence, Ni(x) is simply the cluster (over U) that i belongs to w.r.t. x. No-\n1 As usual, this hypothesis may be relaxed by assuming the existence of two thresholds, one for the within-cluster distance of u>i x and u > i′x, the other for the between-cluster distance.\ntice that i ∈ Ni(x) for any i and any x. We will henceforth assume that all instance vectors x satisfy ||x|| ≤ 1.\nAs is standard in linear bandit settings (e.g., (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011; Krause & Ong, 2011; Crammer & Gentile, 2011; Yue et al., 2012; Djolonga et al., 2013; Cesa-Bianchi et al., 2013; Agrawal & Goyal, 2013; Gentile et al., 2014; Li et al., 2016; Korda et al., 2016), and references therein), the unknown user vectorui determines the (average) behavior of user i. More precisely, upon receiving context vector x, user i “reacts” by delivering a payoff value yi(x) = u>i x+ i(x) , where i(x) is a conditionally zero-mean sub-Gaussian error variable with (conditional) variance parameter σ2(x) ≤ σ2 for all x.2 Hence, conditioned on the past, the quantity u>i x is indeed the expected payoff observed at user i for context vector x. In fact, for the sake of concreteness, we will assume throughout that for all i ∈ U and x ∈ Rd we have yi(x) ∈ [−1,+1].\nAs is standard in online learning settings, learning is broken up into a discrete sequence of time steps (or rounds): At each time t = 1, 2, . . . , the learner receives a user index it ∈ U , representing the user to serve content to. Notice that the user to serve may change from round to round, but the same user may recur several times. Together with it, the learner receives a set of context vectors Ct = {xt,1,xt,2, . . . ,xt,ct} ⊆ Rd, such that ||xt,k|| ≤ 1 for all t and k = 1, . . . , ct, encoding the content which is currently available for recommendation to user it. The learner is compelled to pick some x̄t = xt,kt ∈ Ct to recommend to it, and then observes it’s feedback in the form of payoff yt ∈ [−1,+1] whose (conditional) expectation is u>it x̄t. The sequence of pairings {it, Ct} T t=1 = {(i1, C1), (i2, C2), . . . , (iT , CT )} will be generated by an exogenous process and, in a sense, represents the ”data at hand”. As we shall see in Section 4, the performance of our algorithm will depend on the properties of these data.\nThe practical goal of the learner is to maximize its total payoff ∑T t=1 yt over T time steps. From a theoretical standpoint, we are instead interested in bounding the cumulative regret achieved by our algorithms. More precisely, let the regret rt of the learner at time t be the extent to which the average payoff of the best choice in hindsight at user it exceeds the average payoff of the algorithm’s choice, i.e.,\nrt = (\nmax x∈Ct\nu>itx ) −u>it x̄t .\nWe are aimed at bounding with high probability (over the noise variables it(x̄t), and any other possible source of randomness) the cumulative regret ∑T t=1 rt . As a special\n2 Recall that a zero-mean random variable X is sub-Gaussian with variance parameter σ2 if E[exp(sX)] ≤ exp(s2 σ2/2) for all s ∈ R. Any variable X with E[X] = 0 and |X| ≤ b is sub-Gaussian with variance parameter upper bounded by b2.\ncase of the above model, when the set of items do not possess informative features, we can always resort to the noncontextual bandit setting (e.g., (Auer et al., 2002; Audibert et al., 2009)). To implement this approach, we simply take the set of all items (which must be finite for this technique to work), and apply a one-hot encoding by assigning to the i-th item, the i-th canonical basis vector ei, with one at the i-th position and zero everywhere else as the context vector. It is easy to see that the expected payoff given by user i on item j will simply be the j-th component of vector ui.\nOur aim would be to obtain a regret bound that gracefully improves as the context-dependent clustering structure over the users becomes stronger. More specifically, values taken by the number of clusters m(x) would be of particular interest since we expect to reap the strongest collaborative effects whenm(x) is small whereas not much can be done by way of collaborative analysis if m(x) ≈ n. Consequently, a desirable regret bound would be one that diminishes with m(x). Yet, recall that m(x) is a function of the context vector x, which means that we expect our regret bound to also depend on the properties of the actual data {it, Ct}Tt=1. We will see in Section 4 that, under suitable stochastic assumptions on the way {it, Ct}Tt=1 is generated, our regret analysis essentially replaces the dependence on the total number of users n by the (possibly much) smaller quantity E[m(x)], the expected number of clusters over users, the expectation being over the draw of context vectors x."
    }, {
      "heading" : "3. The Context-Aware Bandit Algorithm",
      "text" : "We present Context-Aware (clustering of) Bandits (dubbed as CAB, see Algorithm 1), an upper-confidence boundbased algorithm for performing recommendations in the context-sensitive bandit clustering model. Similar to previous works (Cesa-Bianchi et al., 2013; Gentile et al., 2014; Nguyen & Lauw, 2014; Li et al., 2016; Wu et al., 2016), CAB maintains a vector estimate wi,t to serve as a proxy to the unknown user vector ui at time t. CAB also maintains standard correlation matrices Mi,t. The standard confidence bound function for user i for item x at time t is derived as CBi,t(x) = α(t) √ x>M−1i,t x, for a suitable function α(t) = O( √ d log t).\nHowever, CAB makes sharp departures from previous works both in the way items are recommended, as well as in they way the estimates wi,t are updated.\nItem Recommendation: At time t, we are required to serve user it ∈ U by presenting an item out of a set of items Ct = {xt,1, . . . ,xt,ct} available at time t. To do so, CAB first computes for each item xt,k in Ct, the set of users that are likely to give the item a similar payoff as it. This set N̂it,t(xt,k) is the estimated neighborhood of user it with respect to item xt,k. A user j is included in N̂it,t(xt,k) if\nAlgorithm 1 Context-Aware clustering of Bandits (CAB) 1: Input: Separation parameter γ, exploration parameter α(t) 2: Init: bi,0 = 0 ∈ Rd and Mi,0 = I ∈ Rd×d, i = 1, . . . n 3: for t = 1, 2, . . . , T do 4: Set wi,t−1 = M−1i,t−1bi,t−1, for all i = 1, . . . , n\n5: Use CBi,t(x) = α(t) √\nx>M−1i,t−1x, for all x, i = 1, . . . , n\n6: Receive user it ∈ U , and context vectors Ct = {xt,1, . . . ,xt,ct} for items to be recommended // Compute neighborhoods and aggregates 7: for k = 1, . . . , ct do 8: Compute neighborhood N̂k := N̂it,t(xt,k) for this item\nN̂k = { j ∈ U : |w>it,t−1xt,k −w > j,t−1xt,k|\n≤ CBit,t−1(xt,k) + CBj,t−1(xt,k) } .\n9: Set wN̂k,t−1 = 1\n|N̂k|\n∑ j∈N̂k wj,t−1\n10: Set CBN̂k,t−1(xt,k) = 1\n|N̂k|\n∑ j∈N̂k CBj,t−1(xt,k)\n11: end for 12: Recommend item x̄t = xt,kt ∈ Ct such that\nkt = argmax k=1,...,ct\n( wN̂k,t−1 >xt,k + CBN̂k,t−1(xt,k) ) .\n13: Observe payoff yt ∈ [−1, 1] . // Update user weight vectors 14: if CBit,t−1(x̄t) ≥ γ/4 then 15: Set Mit,t = Mit,t−1 + x̄tx̄ > t , 16: Set bit,t = bit,t−1 + ytx̄t, 17: Set Mj,t = Mj,t−1, bj,t = bj,t−1 for all j 6= it . 18: else 19: for all j ∈ N̂kt such that CBj,t−1(x̄t) < γ/4 do 20: Mj,t = Mj,t−1 + x̄tx̄>t , 21: bj,t = bj,t−1 + ytx̄t . 22: end for 23: Set Mj,t = Mj,t−1, bj,t = bj,t−1 for all j /∈ N̂kt and for j ∈ N̂kt such that CBj,t−1(x̄t) ≥ γ/4 . 24: end if 25: end for\nthe estimated payoff it gives to the item xt,k is sufficiently close to that given to the item by user it (see step 8).\nCAB incorporates collaborative effects by lifting the notions of the user proxy and confidence bounds to a set of users N ⊆ U . CAB uses a simple, flat averaging lift: CBN,t(x) = 1|N | ∑ j∈N CBj,t(x) and wN,t =\n1 |N | ∑ j∈N wj,t. Next, CAB uses (see step 12) aggregated confidence bounds CBN̂it,t(xt,k)(xt,k) and aggregated proxy vectorswN̂it,t(xt,k),t−1 to select an item x̄t = xt,kt ∈ Ct based on an upper confidence estimation step.\nProxy Updates: Classical approaches update the user proxieswi,t by solving a regularized least squares problem involving (feature representations of) items served previously to user i and payoffs received. However, CAB remains fully committed to the collaborative approach (see\nsteps 14-24) by allowing a user i to inherit updates due to an itemx served to another user j if the two users do indeed agree on their opinion on item xwith a sufficiently high degree of confidence. After the feedback yt is received from user it, the algorithm updates the proxies wj,t.\nIf CAB is not too confident regarding the opinion it has along the direction x̄t, formally CBit,t−1(x̄t) ≥ γ/4, then only the proxy at user it is updated (see step 15-17). However, if CAB is confident i.e. if CBit,t−1(x̄t) < γ/4 then the proxy updates are performed (see steps 19-23) for all users j in it’s estimated neighborhood with respect to x̄t about whose opinions CAB is confident too. Notice that all such users j undergo the same update, which is motivated by the algorithm’s belief that N̂it,t(x̄t) = Nit(x̄t), i.e., that the conditional expectation u>it x̄t of yt given x̄t is actually also equal to u>j x̄t for all users j ∈ N̂it,t(x̄t) such that CBj,t−1(x̄t) < γ/4,\nIt is worth noting that CAB is extremely flexible in handling a fluid set of users U . Due to its context-sensitive user aggregation step, which is repeated at every round, CAB allows users to be added or dropped on the fly, in a seamless manner. This is in strike contrast to past approaches to bandit aggregation, such as GobLin (Cesa-Bianchi et al., 2013), CLUB (Gentile et al., 2014), and COFIBA (Li et al., 2016), where more involved feedback sharing mechanisms across the users are implemented which are based either on static network Laplacians or on time-evolving connected components of graphs over a given set of users."
    }, {
      "heading" : "4. Regret Analysis",
      "text" : "Our regret analysis depends on a specific measure of hardness of the data at hand: for an observed sequence of users {it}Tt=1 = {i1, . . . , iT } and corresponding sequence of item sets {Ct}Tt=1 = {C1, . . . , CT }, where Ct = {xt,1, . . . ,xt,ct}, the hardness HD({it, Ct}Tt=1, η) of the pairing {it, Ct}Tt=1 at level η > 0 is defined as\nHD({it, Ct}Tt=1, η) = max { t = 1, . . . , T : ∃j ∈ U , ∃k1, k2, . . . , kt, :\nI + t∑ s≤t : is=j xs,ksx > s,ks has smallest eigenvalue ≤ η } .\nIn words, HD({it, Ct}Tt=1, η) roughly measures the number of rounds we need to wait in the worst case over all possible users j and all possible ways of building matrices Mj,t through rank-one adjustments based on the data found in {it, Ct}Tt=1 until all correlation matrices Mj,t have eigenvalues lower bounded by η. Based on the above hardness definition, the following result summarizes our main efforts in this section. The full proof is given in the appendix, along with few ancillary results.\nTheorem 1 Let CAB (Algorithm 1) be run on {it, Ct}Tt=1, with ct ≤ c for all t. Also, let the condition |u>j x − w>j,tx| ≤ CBj,t(x) hold for all j ∈ U and x ∈ Rd, along with the γ-gap assumption. Then the cumulative regret∑T t=1 rt of the algorithm can be deterministically upper bounded as follows:\nT∑ t=1 rt ≤ 9α(T )\n( c n HD ( {it, Ct}Tt=1, 16α2(T )\nγ2\n)\n+ √√√√d log T T∑ t=1\nn\n|Nit(x̄t)|\n)\nwhere we set α(T ) = O( √\nlog T ). Some comments are in order. Theorem 1 delivers a deterministic regret bound on the cumulative regret, and is composed of two terms. The first term is a measure of hardness of the data sequence {it, Ct}Tt=1 at hand whereas the second term is the usual√ T -style term in linear bandit regret analyses (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011). However, note that the dependence of the second term on the total number n of users to be served gets replaced by a much smaller quantity n|Nit (x̄t)| that depends on the actual size of context-dependent clusters of the served users.\nWe will shortly see that if the pairings {it, Ct}Tt=1 are generated in a favorable manner, such as sampling vectors xt,k i.i.d. according to an unknown distribution over the instance space (see Lemma 1 below), the hardness measure can be upper bounded with high probability by a term of the form log Tγ2 . Similarly, for the second term, in the simple case when Nit(x̄t) = B for all t, the second term has the form √ n B T , up to log factors. Notice that √ T is roughly\nthe regret effort for learning a single bandit, and √\nn B T is\nthe effort for learning nB -many (unrelated) clusters of bandits when the clustering is known. Thus, in this example, it is the ratio nB that quantifies the hardness of the problem, insofar clustering is concerned. Again, under favorable circumstances (see Lemma 2 below), we can relate the quantity ∑T t=1\nn |Nit (x̄t)| to the expected number of contextdependent clusters of users, the expectation being w.r.t. the random draw of context vectors.\nOn the other hand, making no assumptions whatsoever on the way {it, Ct}Tt=1 is generated makes it hard to exploit the cluster structure. For instance, if {it, Ct}Tt=1 is generated by an adaptive adversary, this might cause HD ( {it, Ct}Tt=1, η ) to become linear in T for any constant η > 1, thereby making the bound in Theorem 1 vacuous. However, a naive algorithm that disregards the cluster structure, making no attempts to incorporate collaborative effects, and running n-many independent LINUCB-like algorithms (Auer, 2002; Abbasi-Yadkori et al., 2011; Chu\net al., 2011), easily yields a √ nT regret bound3.\nA sufficient condition for controlling the hardness term in Theorem 1 is provided by the following lemma.\nLemma 1 For each round t, let the context vectors Ct = {xt,1, . . . ,xt,ct} be generated i.i.d. (conditioned on it, ct, past data {is, Cs}t−1s=1 and rewards y1, . . . , yt−1) from a sub-Gaussian random vector X ∈ Rd with (conditional) variance parameter ν2, such that ||X|| ≤ 1, and E[XX>] is full rank with smallest eigenvalue λ > 0. Let also ct ≤ c for all t, and ν2 ≤ λ 2\n8 ln(4c) . Finally, let the sequence {it}Tt=1 be generated uniformly at random,4 independent of all other variables. Then with probability at least 1− δ,\nHD ( {it, Ct}Tt=1, η ) = O ( n η\nλ2 log\n( Tnd\nδ\n)) .\nThe following lemma handles the second term in the bound of Theorem 1.\nLemma 2 For each round t, let the context vectors Ct = {xt,1, . . . ,xt,ct} be generated i.i.d. (conditioned on it, ct, past data {is, Cs}t−1s=1 and rewards y1, . . . , yt−1) from a random vector X ∈ Rd with ||X|| ≤ 1. Let also ct ≤ c for all t. Then, with probability at least 1− δ,\nT∑ t=1\n1 |Nit(x̄t)| ≤ 2TcE[m(X)] n + 12 log\n( log T\nδ\n) .\nRemark 1 The linear dependence on c on the right-hand side can be turned to logarithmic, e.g., at the cost of an extra sub-Gaussian assumption on variables 1|Ni(x)| , i ∈ U .\nFinally, we recall the following upper confidence bound, from (Abbasi-Yadkori et al., 2011).\nLemma 3 Let CBj,t(x) = α(t) √ x>M−1j,t x, with α(t) =\nO (√\nd log Tnδ\n) .5 Then, under the payoff noise model de-\nfined in Section 2, |u>j x − w>j,tx| ≤ CBj,t(x) holds uniformly for all j ∈ U , x ∈ Rd, and t = 1, 2, . . ..\nA straightforward combination of Theorem 1 with Lemmata 1, 2, and 3 yields the following result.\n3 To see this, simply observe that each of the n LINUCB-like algorithms has a regret bound of the form √ Ti, where Ti is the\nnumber of rounds where it = i. Then ∑T t=1 rt ≤ ∑n i=1 √ Ti ≤√\nnT , with equality if Ti = T/n for all i. 4 Any distribution over U that assigns a strictly positive probability pj to all j ∈ U would suffice by replacing nwith the inverse of the smallest user probability pj .\n5 The big-oh notation here hides the dependence on the variance σ2 of the payoff values.\nCorollary 1 Let CBj,t(x) be defined with α(t) as in Lemma 3, and let the γ-gap assumption hold. Assume context vectors are generated as in Lemma 1 in such a way that the sub-Gaussian assumption therein holds with ct ≤ c. Finally, let the sequence {it}Tt=1 be generated as described in Lemma 1. Then, with probability at least 1 − δ, the regret of CAB (Algorithm 1) satisfies\nT∑ t=1 rt = R+ Õ ( d √ Tc (E[m(X)]) ) ,\nwhere the Õ-notation hides logarithmic factors in TNdδ , and R is of the form6\nR = c n2 d\n√ d\nλ2 γ2 log2.5\n( Tnd\nδ\n) .\nSparse user models. We conclude with a pointer to an additional result we have for sparse linear models contained in the supplemental (Section B therein), which is in line with past analyses on sparse linear bandits for a single user (Abbasi-Yadkori et al., 2012; Carpentier & Munos, 2012; Carpentier, 2015): If u1, . . . ,un are s-sparse, in the sense that for all i ∈ U it holds that ‖ui‖0 ≤ s, for s d, then replacing the least-squares solution in Step 4 of Figure 1 with the solution computed by a two-stage fully corrective method (Needell & Tropp, 2008; Dai & Milenkovic, 2009) allows us to obtain an improved regret bound. Specifically, we can replace factor d √ d in R above by s2 √ s, and factor d multiplying the √ T -term by a factor of the form √ s d."
    }, {
      "heading" : "5. Experiments",
      "text" : "We tested CAB on production and real-world datasets, and compared them to standard baselines as well as to state-ofthe-art bandit and clustering of bandit algorithms. When no features have been used on the items, a one-hot encoding was adopted. We tried to follow as much as possible previous experimental settings, like those described in (CesaBianchi et al., 2013; Gentile et al., 2014; Korda et al., 2016; Li et al., 2016)."
    }, {
      "heading" : "5.1. Dataset Description",
      "text" : "Tuenti. Tuenti (owned by Telefonica) is a Spanish social network website that serves ads on its site, the data contains ad impressions viewed by users along with a variable that registers a click on an ad. The dataset contains d = 105 ads, n = 14, 612 users, and 15M records/timesteps. We adopted a one hot encoding scheme for the items, hence items are described by the unit-norm vectors e1, . . . , ed. Since the available payoffs are those associated with the\n6 In fact, no special efforts have been devoted here to finding sharper upper bounds on R.\nitems served by the system, we performed offline policy evaluation through a standard importance sampling technique: we discarded on the fly all records where the system’s recommendation (the logged policy) did not coincide with the algorithms’ recommendations. The resulting number of retained records was around T = 1M , loosely depending on the different algorithms and runs. Yet, because this technique delivers reliable estimates when the logged policy makes random choices (e.g., (Li et al., 2010)), we actually simulated a random logged policy as follows. At each round t, we retained the ad served to the current user it with payoff value at (1 = “clicked”, 0 = “not clicked”), but also included 14 extra items (hence ct = 15 for all t) drawn uniformly at random in such a way that, for any item ej , if ej occurs in some set Ct, this item will be the one served by system only 1/15 of the times. Notice that this random selection was independent of the available payoff at.\nKDD Cup. This dataset was released for the KDD Cup 2012 Online Advertising Competition7 where the instances were derived from the session logs of the search engine soso.com. A search session included user, query and ad information, and was divided into multiple instances, each being described using the ad impressed at that time at a certain depth and position. Instances were aggregated with the same user ID, ad ID, and query. We took the chronological order among all the instances, and seeded the algorithm with the first ct = 20 instances (the length of recommendation lists). Payoffs at are again binary. The resulting dataset had n = 10, 333 distinct users, and d = 6, 780 distinct ads. Similar to the Tuenti dataset, we generated random recommendation lists, and a random logged policy. We employed one-hot encoding as well in this dataset. The number of retained records was around T = 0, 1M .\nAvazu. This dataset was released for the Avazu ClickThrough Rate Prediction Challenge on Kaggle8. Here click-through data were ordered chronologically, and nonclicks and clicks were subsampled according to different strategies. As before, we simulated a random logged policy over recommendation lists of size ct = 20 ∀t. Payoffs are once again binary. The final dataset had n = 48, 723 users, ct = 20 for all t, d = 5, 099 items, while the number of retained records was around T = 1, 1M . Again, we took the one-hot encoding for the items.\nLastFM and Delicious. These two datasets9 are extracted from the music streaming service Last.fm and the social bookmarking web service Delicious. The LastFM dataset includes n = 1,892 users, and 17,632 items (the artists). De-\n7http://www.kddcup2012.org/c/ kddcup2012-track2\n8https://www.kaggle.com/c/ avazu-ctr-prediction\n9www.grouplens.org/node/462\nlicious refers to n = 1,861 users, and 69,226 items (URLs). Preprocessing of data followed previous experimental settings where these datasets have been used, e.g., (CesaBianchi et al., 2013; Gentile et al., 2014). Specifically, after a tf-idf representation of the available items, the context vectors xt,i have been generated by retaining only the first d = 25 principal components. Binary payoffs were created as follows. LastFM: If a user listened to an artist at least once the payoff is 1, otherwise it is 0. Delicious: the payoff is 1 if the user bookmarked the URL, and 0 otherwise. We processed the datasets to make them suitable for use with multi-armed bandit algorithms. Recommendation lists Ct of size ct = 25 ∀t were generated at random by first selecting index it at random over the n users, and then padding with 24 vectors chosen at random from the available items up to that time step, in such a way that at least one of these 25 items had payoff 1 for the current user it. This was repeated for T = 50, 000 times for the two datasets.\nTable 1 summarizes the main statistics of our datasets."
    }, {
      "heading" : "5.2. Algorithms",
      "text" : "We used the first 20% of each dataset to tune the algorithms’ parameters through a grid search, and report results on the remaining 80%. All results are averaged over 5 runs. We compared to a number of state-of-the art bandit and clustering-of-bandit methods:\n• CLUB (Gentile et al., 2014) sequentially refines user clusters based on their confidence ellipsoid balls; We seeded the graph over users by an initial random Erdos-Renyi graphs with sparsity parameter p = (3 log n)/n. Because this is a randomized algorithm, each run was repeated five times, and then averaged the results (the observed variance turned out to be small anyway).\n• DynUCB (Nguyen & Lauw, 2014) uses a traditional k-Means algorithm to cluster bandits.\n• LinUCB-SINGLE uses a single instance of LinUCB (Chu et al., 2011) to serve all users, i.e., all users belong to the same cluster, independent of the items.\n• LinUCB-MULTIPLE uses an independent instance of LinUCB per user with no interactions among them, i.e., each user forms a cluster on his/her own, again independent of the items.\n• The following variant of CAB (see Algorithm 1): each user j is considered for addition to the estimated neighborhoods N̂k of the currently served user it only if wj,t−1 has been updated at least once in the past.\n• Random recommendations, denoted here by RAN, that pick items within Ct fully at random.\nAll tested algorithms (excluding RAN) are based on upper-confidence bounds of the form CBi,t(x) = α √ x>Ni,tx log(1 + t). In all cases, we viewed α as a tunable parameter across the values 0, 0.01, 0.02, . . . , 0.2. The α2 parameter in CLUB was chosen within {0.1, 0, 2, . . . , 0.5}. The number of clusters in DynUCB was increased according to an exponential progression, starting from 1, and ending to n. Finally, the γ parameter in CAB was simply set to 0.2. In fact, the value of γ did not happen to have a significant influence on the performance of the version of CAB we tested."
    }, {
      "heading" : "5.3. Results",
      "text" : "The results of our experiments are summarized in Figures 1, 2, and 3. All of these results come from the remaining 80% of the datasets after using 20% of the data for tuning. For the online advertising datasets Tuenti, KDD Cup, and Avazu (Figure 1), we measured performance using the Click-Through Rate (CTR), hence the higher the curves the better. For the LastFM and Delicious datasets (Figure 2), we instead report the ratio of the cumulative regret of the tested algorithm to the cumulative regret of RAN, hence the lower the better.\nThe experimental setting is in line with past work in the area (e.g., (Li et al., 2010; Cesa-Bianchi et al., 2013; Gentile et al., 2014; Li et al., 2016)), and so are some of the results that we reproduce here. Moreover, by the way data have been prepared, our findings give reliable estimates of the actual CTR performance (Figure 1) or actual regret performance (Figure 2) of the tested algorithms.\nIn four out of five datasets, CAB was found to offer superior performance, as compared to all baselines. CAB performed particularly well on the Tuenti dataset where it\ndelivers almost double the CTR compared to some of the baselines. CAB’s performance advantage was more moderate on the KDD Cup and Avazu datasets. This is expected since exploiting collaborative effects is more important on a dataset like Tuenti, where users are exposed to a few (≈ 100) ads, as compared to the KDD Cup dataset (where ads are also modulated by a user query) and the Avazu dataset, both of which have a much broader ad base (≈ 7000). This provides a strong indication that CAB effectively exploits collaborative effects. In general, on the first three datasets (Tuenti, KDD Cup, and Avazu – see Figure 1), CAB was found to offer benefits in the cold-start region (i.e., the initial relatively small fraction of time horizon), but it also continues to maintain a lead throughout.\nOn the LastFM and Delicious datasets (Figure 2), the results we report are consistent with (Gentile et al., 2014). On LastFM all methods are again outperformed by CAB. The overall performance of all bandit methods seems though to be relatively poor; this can be attributed to the way the LastFM dataset was generated. Here users typically have little interaction with the music serving system and a lot of the songs played were generated by a recommender. Hence while there are collaborative effects, they are relatively weak compared to datasets such as Tuenti.\nOn the other hand, on the Delicious dataset the best performing strategy seems to be LinUCB-MULTIPLE, which deliberately avoids any feedback sharing mechanism among the users. This dataset reflects user web-browsing patterns, as evinced by their bookmarks. In line with past experimental evidence (e.g., (Gentile et al., 2014)), this dataset does not seem to contain any collaborative information, hence we can hardly expect to take advantage of clustering efforts. To shed further light, in Figure 3 we plotted the average distance between a linear model for user it and the corresponding linear models for all other users j 6= it, as a function of t. For each of the two datasets and each user i ∈ U , these linear models have been computed by taking the whole test set and treating each pairing (xt,k, yt,k) with it = i, and yt,k = 1 as a training sample for a (regularized) least-squares estimator for user i. The conclusion we can draw after visually comparing the left and the right plots in Figure 3 is that on Delicious these estimated user models tend to be significantly more separated than on LastFM, which easily explains the effectiveness of LinUCB-MULTIPLE. Moreover, on Delicious studies have shown that tags which are used as item features are generally chosen by users to reflect their interests and for personal use, hence we can expect these features to diverge even for similar websites. On the other hand, in LastFM tags are typically reflecting the genre of the song."
    }, {
      "heading" : "6. Conclusions and Ongoing Research",
      "text" : "In this paper we proposed a novel contextual bandit algorithm for personalized recommendation systems. Our algorithm is able to effectively incorporate collaborative effects by implementing a simple context-dependent feedback sharing mechanism. Our approach greatly relaxes the restrictions and requirements imposed by earlier works (e.g., (Cesa-Bianchi et al., 2013; Gentile et al., 2014; Nguyen & Lauw, 2014; Li et al., 2016; Wu et al., 2016)), and offers a much higher flexibility in handling practical situations, like the on-the-fly inclusion or exclusion of users. Under additional assumptions on the way data are generated, we provided a crisp regret analysis depending on the expected number of clusters over the users, a natural context-dependent notion of the (statistical) difficulty of the learning task. These theoretical findings are further strengthened in the sparse model scenario for users, where improved bounds are shown. We carried out an extensive experimental comparison on a number of production and real-world datasets, with very encouraging results, as compared to available approaches.\nWe have started to test (contextual) Thompson Sampling versions of both CAB and its competitors (results are not reported here since they are too preliminary), but so far we have not observed any significant statistical difference compared to what is in Section 5. From the theoretical standpoint, it would be nice to complement our upper bound in Corollary 1 with a lower bound helping to characterize the regret complexity of our problem. From the experimental standpoint, we are planning to have the sparse bandit version of our algorithm undergo a similar experimental validation as the one presented here."
    }, {
      "heading" : "A. Proofs",
      "text" : "The following lemma is the starting point of our regret analysis. In what follows, {·} denotes the indicator function of the predicate at argument.\nLemma 4 Suppose that for all i ∈ U , and all x ∈ Rd it holds that\n|w>i,tx− u>i x| ≤ CBi,t(x) .\nThen the instantaneous regret rt the CAB algorithm (Algorithm 1) incurs at time t can be deterministically upper bounded as rt ≤ (3α(T ) + 2) ( {N̂it,t(x∗t ) 6= Nit(x∗t )}+ {N̂it,t(x̄t) 6= Nit(x̄t)} ) +2 CBNit (x̄t),t−1(x̄t) .\nProof. Let x∗t = argmaxk=1,...,ct u > it xt,k, so that\nrt = u > itx ∗ t − u>it x̄t .\nThen, setting for brevity\nN∗ = Nit(x ∗ t ), N̂∗ = N̂it,t(x ∗ t ),\nN− = Nit(x̄t), N̂− = N̂it,t(x̄t),\nwe can write\nrt = u > itx ∗ t − u>it x̄t\n= 1 |N∗| ∑ j∈N∗ u>j x ∗ t − u>it x̄t (since u > j x ∗ t = u > it x∗t for all j ∈ N∗)\n= 1 |N∗| ∑ j∈N∗ ( u>j x ∗ t −w>N∗,t−1x∗t +w>N∗,t−1x∗t −w>N̂∗,t−1x ∗ t +w > N̂∗,t−1x ∗ t + CBN̂∗,t−1(x ∗ t )− CBN̂∗,t−1(x ∗ t )\n−u>it x̄t ) .\nUsing |w>j,t−1x∗t − u>j x∗t | ≤ CBj,t−1(x∗t ) for all j ∈ N∗, Cauchy-Shwartz inequality, and the definition of x̄t, the above can be upper bounded as\n≤ CBN∗,t−1(x∗t ) + ||wN∗,t−1 −wN̂∗,t−1|| · {N̂ ∗ 6= N∗}+w> N̂−,t−1x̄t + CBN̂−,t−1(x̄t)− CBN̂∗,t−1(x ∗ t )− u>it x̄t = (\nCBN∗,t−1(x ∗ t )− CBN̂∗,t−1(x ∗ t ) ) ·{N̂∗ 6= N∗}+ ||wN∗,t−1 −wN̂∗,t−1|| · {N̂ ∗ 6= N∗}\n+ ( w> N̂−,t−1x̄t −w > N−,t−1x̄t ) ·{N̂− 6= N−}+w>N−,t−1x̄t + CBN̂−,t−1(x̄t)− u > it x̄t.\nUsing again Cauchy-Shwartz inequality, and u>j x̄t = u > it x̄t for all j ∈ N−, the above can in turn be upper bounded by\n≤ (\nCBN∗,t−1(x ∗ t )− CBN̂∗,t−1(x ∗ t ) + ||wN∗,t−1 −wN̂∗,t−1|| ) ·{N̂∗ 6= N∗}+ ||wN̂−,t−1 −wN−,t−1|| · {N̂ − 6= N−}\n+w>N−,t−1x̄t − 1 |N−| ∑ j∈N− u>j x̄t + CBN̂−,t−1(x̄t)\n≤ (\nCBN∗,t−1(x ∗ t ) + ||wN∗,t−1 −wN̂∗,t−1|| ) ·{N̂∗ 6= N∗}+ ||wN̂−,t−1 −wN−,t−1|| · {N̂ − 6= N−}\n+ CBN−,t−1(x̄t) + CBN̂−,t−1(x̄t)\n(using |w>j,t−1x̄t − u>j x̄t| ≤ CBj,t−1(x̄t) for all j ∈ N−)\n= (\nCBN∗,t−1(x ∗ t ) + ||wN∗,t−1 −wN̂∗,t−1|| ) ·{N̂∗ 6= N∗}+ ||wN̂−,t−1 −wN−,t−1|| · {N̂ − 6= N−}+ 2CBN−,t−1(x̄t)\n+ ( CBN̂−,t−1(x̄t)− CBN−,t−1(x̄t) ) ·{N̂− 6= N−}\n≤ (\nCBN∗,t−1(x ∗ t ) + ||wN∗,t−1 −wN̂∗,t−1||\n) ·{N̂∗ 6= N∗}+ ( CBN̂−,t−1(x̄t) + ||wN̂−,t−1 −wN−,t−1|| ) ·{N̂− 6= N−}\n+ 2CBN−,t−1(x̄t) .\nWe now handle the terms within the round braces. Since maxx : ||x||≤1 x>M −1 i,t x ≤ 1 for all i and t (by construction, Mi,t I as Mi,0 = I), we have that CBN∗,t−1(x∗t ) and CBN̂−,t−1(x̄t) are both upper bounded by α(T ). Moreover, using the shorthand uN = 1|N | ∑ j∈N uj , for N ⊆ U , we have\n||wN∗,t−1 −wN̂∗,t−1|| ≤ ||wN∗,t−1 − uN∗ ||+ ||uN∗ − uN̂∗ ||+ ||uN̂∗ −wN̂∗,t−1||\n≤ max x : ||x||≤1 CBN∗,t−1(x) + ||uN∗ ||+ ||uN̂∗ ||+ max x : ||x||≤1 CBN̂∗,t−1(x)\n≤ 2(α(T ) + 1) .\nHence, we conclude that rt ≤ (3α(T ) + 2) ( {N̂∗ 6= N∗}+ {N̂− 6= N−} ) + 2CBN−,t−1(x̄t) ,\nas claimed.\nUnder the γ-gap assumption, we also have the following lemma.\nLemma 5 Let it be the user served at time t (see Figure 1). Let\n|u>j x−w>j,tx| ≤ CBj,t(x)\nhold for all j ∈ U , and x ∈ Rd. Also, for fixed xot , let CBj,t−1(xot ) < γ/4 holds for all j ∈ U . Then\nN̂it,t(x o t ) = Nit(x o t ) .\nProof. We first claim that, under the assumptions of this lemma, the following two implications hold:\n1. Given i, j ∈ U , if u>i x 6= u>j x and CBi,t(x) + CBj,t(x) < γ/2 then |w>i,tx−w>j,tx| > CBi,t(x) + CBj,t(x) .\n2. Given i, j ∈ U , if |w>i,tx−w>j,tx| > CBi,t(x) + CBj,t(x) then u>i x 6= u>j x .\nIn order to prove Item 1, notice that the γ-gap assumption entails that u>i x 6= u>j x is equivalent to |u>i x − u>j x| ≥ γ. Hence we can write\nγ ≤ |u>i x− u>j x| ≤ |u>i x−w>i,tx|+ |w>i,tx−w>j,tx|+ |w>j,tx− u>j x| ≤ CBi,t(x) + |w>i,tx−w>j,tx|+ CBj,t(x) < γ/2 + |w>i,tx−w>j,tx| ,\nimplying that |w>i,tx−w>j,tx| > γ/2 > CBi,t(x) + CBj,t(x) .\nAs for Item 2, we can write\nCBi,t(x) + CBj,t(x) < |w>i,tx−w>j,tx| ≤ |w>i,tx− u>i x|+ |u>i x− u>j x|+ |u>j x−w>j,tx| ≤ CBi,t(x) + |u>i x− u>j x|+ CBj,t(x) ,\nimplying that |u>i x− u>j x| > 0. Using the above two claims, we want to show that both\n1a. Nit(x o t ) ⊆ N̂it,t(xot ) and\n2a. N̂it,t(x o t ) ⊆ Nit(xot )\nhold. We choose i = it in the above. Then, in order to prove Item 1a, we observe that if j ∈ U is such that u>itx o t = u > j x o t then Item 2 above implies |w>it,t−1x o t −w>j,t−1xot | ≤ CBit,t−1(xot ) + CBj,t−1(xot ), i.e., j ∈ N̂it,t(xot ). On the other hand, if j is such that |w>it,t−1x o t − w>j,t−1xot | ≤ CBit,t−1(xot ) + CBj,t−1(xot ) then Item 1 above allows us to conclude that either u>itx o t = u > j x o t or CBit,t−1(x o t ) + CBj,t−1(x o t ) ≥ γ/2. Yet, because CBj,t−1(xot ) < γ/4 for all j ∈ U , the second conclusion is ruled out, thereby implying j ∈ Nit(xot ).\nRemark 2 It is important to observe that, under the hypotheses of Lemma 5 (when setting there xot = x̄t), also the set of j ∈ U whose profile wj,t−1 gets updated at the end of round t in Figure 1 coincides with Nit(x̄t).\nBy setting xot to either x ∗ t or x̄t, we now combine Lemma 5 with Lemma 4 to bound the number of rounds t such that N̂it,t(x ∗ t ) 6= Nit(x∗t ) and the number of rounds t such that N̂it,t(x̄t) 6= Nit(x̄t). In turn, these will be immediately related to the hardness HD({it, Ct}Tt=1, η) of the data {it, Ct}Tt=1 at our disposal. Moreover, we will use Remark 2 to exploit the fact that when the confidence bounds CBj,t−1(x̄t) are all small enough along the selected direction x̄t, then the number of weight updates performed in round t is exactly equal to the size of the true neighborhood Nit(x̄t).\nProof of Theorem 1. Consider the bound in Lemma 4. We can write\n{N̂it,t(x∗t ) 6= Nit(x∗t )} ≤ {∃k = 1, . . . , ct : N̂it,t(xt,k) 6= Nit(xt,k)}\n≤ ct∑ k=1 {N̂it,t(xt,k) 6= Nit(xt,k)}\n≤ ct∑ k=1 {∃j ∈ U : CBj,t−1(xt,k) ≥ γ/4} (using Lemma 5)\n≤ ct∑ k=1 ∑ j∈U {CBj,t−1(xt,k) ≥ γ/4} .\nClearly, the very same upper bound applies to {N̂it,t(x̄t) 6= Nit(x̄t)}. Moreover, T∑ t=1 CBNit (x̄t),t−1(x̄t) = T∑ t=1 {∃j∃k : CBj,t−1(xt,k) ≥ γ/4} × CBNit (x̄t),t−1(x̄t) + ∑\nt : CBj,t−1(xt,k)<γ/4 ∀j∀k\nCBNit (x̄t),t−1(x̄t)\n≤ T∑ t=1 ct∑ k=1 ∑ j∈U {CBj,t−1(xt,k) ≥ γ/4} × max x : ||x||≤1 CBNit (x̄t),t−1(x)\n+ ∑\nt : CBj,t−1(xt,k)<γ/4 ∀j∀k\nCBNit (x̄t),t−1(x̄t)\n≤ α(T ) T∑ t=1 ct∑ k=1 ∑ j∈U {CBj,t−1(xt,k) ≥ γ/4}+ ∑ t : CBj,t−1(xt,k)<γ/4 ∀j∀k CBNit (x̄t),t−1(x̄t) .\nPutting together as in Lemma 4 gives\nT∑ t=1 rt ≤ (8α(T ) + 4) T∑ t=1 ct∑ k=1 ∑ j∈U {CBj,t−1(xt,k) ≥ γ/4}+ 2 ∑ t : CBj,t−1(xt,k)<γ/4 ∀j ∀k CBNit (x̄t),t−1(x̄t) . (1)\nWe first focus on the triple sum in (1), which is easily rewritten in terms of HD({it, Ct}Tt=1, η), for a suitable level η. In fact, if we denote by λmax(·) and λmin(·) the maximal and the minimal eigenvalue of the matrix at argument, we have\nCBj,t−1(xt,k) = α(t) √ x>t,kM −1 j,t−1xt,k\n≤ α(T ) √ λmax(M −1 j,t−1) = α(T )√\nλmin(Mj,t−1) ,\nwhich is smaller than γ/4 if λmin(Mj,t−1) > 16α2(T ) γ2 . Hence, recalling that n = |U| and ct ≤ c for all t,\nT∑ t=1 ct∑ k=1 ∑ j∈U {CBj,t−1(xt,k) ≥ γ/4} ≤ c n HD ( {it, Ct}Tt=1, 16α2(T ) γ2 ) .\nNext, we focus on the last sum in (1). Let UP(j) ⊆ {1, . . . , T} be the set of rounds t such that wj,t undergoes an update. Also, let G = {t = 1, . . . , T : CBj,t−1(x̄t) < γ/4∀j ∈ U}. Notice that, for all j ∈ U and t = 1, . . . , T ,\nMj,t = I + ∑\ns≤t : s∈UP(j)\nx̄sx̄ > s . (2)\nWe can write∑ t : CBj,t−1(xt,k)<γ/4 ∀j ∀k CBNit (x̄t),t−1(x̄t) ≤ ∑ t∈G CBNit (x̄t),t−1(x̄t)\n= ∑ t∈G\n1 |Nit(x̄t)| ∑\nj∈Nit (x̄t)\nCBj,t−1(x̄t)\n= ∑ j∈U ∑ t∈G:j∈Nit (x̄t) CBj,t−1(x̄t) |Nit(x̄t)| ≤ ∑ j∈U  ∑ t∈G:j∈Nit (x̄t) 1 |Nit(x̄t)|2 1/2 ×  ∑ t∈G:j∈Nit (x̄t) CB2j,t−1(x̄t) 1/2 (3)\n(from Cauchy-Shwartz inequality) .\nNow, observe that from Remark 2, {t ∈ G : j ∈ Nit(x̄t)} ⊆ UP(j). Hence, for each j ∈ U , we have∑ t∈G:j∈Nit (x̄t) CB2j,t−1(x̄t) ≤ ∑ t∈UP(j) CB2j,t−1(x̄t)\n≤ α2(T ) ∑\nt∈UP(j)\nx̄>t M −1 j,t−1x̄t\n≤ 2α2(T ) log |Mj,T | |Mj,0|\n(from, e.g., Lemma 24 in (Dekel et al., 2012))\n≤ 2 dα2(T ) log(1 + |UP(j)|) ≤ 2 dα2(T ) log(1 + T ) ,\nwhere |M | denotes the determinant of matrix M . Furthermore, again from Cauchy-Shwartz inequality, we can write\n∑ j∈U ( ∑ t∈G:j∈Nit (x̄t)\n1\n|Nit(x̄t)|2\n)1/2 ≤ n∑ j∈U ∑ t∈G:j∈Nit (x̄t)\n1\n|Nit(x̄t)|2\n1/2\n= n∑ t∈G ∑ j∈Nit (x̄t)\n1\n|Nit(x̄t)|2 1/2 ≤ (n T∑ t=1\n1\n|Nit(x̄t)|\n)1/2 .\nPiecing together as in (3), and plugging back into (1) gives the claimed result.\nProof sketch of Lemma 1. The proof is similar to that of Lemma 2 in (Gentile et al., 2014), where it is shown (Claim 1 therein) that under the assumptions of this lemma\nEt [\nmin k∈{1 ...,ct}\n(z>xt,k) 2 | (it, ct) ] ≥ λ/4 .\nThe proof then continues as in Lemma 2 of (Gentile et al., 2014) by setting up a Freedman-style matrix tail bound to get, as a consequence of the above, the following high-confidence estimate, holding with probability at least 1 − δ, uniformly over j ∈ U , and t = 1, 2, . . . ,:\nmin k1∈{1,...,c1},...,kt∈{1,...,ct} λmin I + ∑ s≤t : is=j xs,ksx > s,ks  ≥ 1 +Bλ,ν,c(Tj,t, δ 2nd ) , (4)\nwhere\nBλ,ν,c(T, δ) = λ/4T − 8 ( log(T/δ) + √ T log(T/δ) ) .\nWe continue by lower bounding (4) with high probability. Observe that, for any fixed j and t, variable Tj,t is binomial with parameters t and 1/n. Let us define the auxiliary function\nD(x) = 2n ( x+ 5\n3 log\n( Tn\nδ\n)) = O ( nx+ n log ( Tn\nδ\n)) .\nA standard application of Bernstein inequality to (Bernoulli) i.i.d. sequences allows us to conclude that, for any fixed value x,\nP(∃j ∈ U , ∃t > D(x) : Tj,t ≤ x) ≤ δ . (5)\nNow, in order for (4) to be lower bounded by η for all j ∈ U with probability at least 1− δ, it suffices to have\nTj,t = Ω\n( η\nλ2 log\n( nd\nδ\n)) := x∗ .\nWe set x = x∗ into (5) to conclude that when\nt ≥ D(x∗) = Ω ( n η\nλ2 log\n( Tnd\nδ )) then\nHD ( {it, Ct}Tt=1, η ) = O ( n η\nλ2 log\n( Tnd\nδ\n)) ,\nas claimed Proof of Lemma 2. Fix round t, let Et[·] denote the conditional expectation E [ · | {is, Cs}t−1s=1, y1, . . . , yt−1 ] . We have\nEt [ 1 |Nit(x̄t)| | (it, ct) ] ≤ Et [ ct∑ k=1\n1\n|Nit(xt,k)| | (it, ct)\n] ,\nso that\nEt [\n1 |Nit(x̄t)| | ct ] ≤ 1 n n∑ i=1 Et [ ct∑ k=1\n1\n|Ni(xt,k)| | ct\n]\n= 1\nn ct∑ k=1 Et [ n∑ i=1\n1\n|Ni(xt,k)| | ct ] = ct n E [m(X)]\n≤ c n E [m(X)] , (6)\nthe last equality deriving from the fact that for any givenx, the set of n users is partitioned intom(x) clusters corresponding to the neighborhoods Ni(x) (so that ∑n i=1 1 |Ni(x)| = m(x)). Let us now define the variables\nDt = 1\n|Nit(x̄t)| − Et\n[ 1 |Nit(x̄t)| | ct ] ,\nfor t = 1, . . . , T . We have that D1, . . . , DT is a martingale difference sequence to which we can apply standard concentration inequalities. In particular, in the light of (6), and the fact that the conditional variance of 1|Nit (x̄t)| is not larger than its conditional mean, we can use, e.g., (Kakade & Tewari, 2008) to conclude that, with probability at least 1− δ,\nT∑ t=1\n1 |Nit(x̄t)| ≤ 2Tc n E [m(X)] + 12 log\n( log T\nδ\n) ,\nas claimed."
    }, {
      "heading" : "B. Extending CAB to Sparse User Models",
      "text" : "In this section, we give details on how CAB can be modified to work when user models (i.e. the vectors ui, i = 1, . . . , n) are s-sparse i.e. ‖ui‖0 ≤ s for s d. We will denote Si = supp(ui) to be the support of the vector for user i. We will assume for the sake of simplicity that |Si| ≤ s∗ for all i. We will also make the standard assumption that non-zero coordinates of the vectors do not take vanishing values. More formally, we will assume that for some π > 0, for all i, for all j, either ui[j] = 0 or else |ui[j]| > π. Note that different users can have different supports, but all of them must be s∗-sparse.\nSparse user models arise when the user and item vectors are extremely high dimensional and not all features are useful in encoding the preference patterns of every user. Rather, every user chooses a (possibly different) set of features that best encode its preferences. Sparse models are also extremely popular in resource constrained settings where dense models are too expensive to store or too slow to predict with.\nIn such cases, performing least squares regression to obtain the proxy vectors is not only expected to give poor results, but also requires the much larger number of trials O(d) per user i to effectively estimate ui, which can be prohibitive since users typically interact very sparsely with recommendation systems.\nTo make our exposition easier, we introduce some handy notation. Let Ti(t) = ∑t−1 τ=1{it = i} denote the number of times user i has been served till time t. Also let Xi,t ∈ RTi(t)×d denote the matrix of all item context vectors that have been served to user i till time t and i,t ∈ RTi(t) denote the vector of sub-Gaussian error values that were introduced into the payoffs user i offered in the past. Also, for any set S ⊂ [d], we let XSi,t denote the submatrix of Xi,t that contains only those columns that are present in the set S and the rest zeroed out. For any vector u, the notation uS will denote the vector with coordinates in S retained and the rest zeroed out. However, we will abuse this notation while using it in context of the correlation matrix. We will denote using MSi,t−1 = (X S i,t) >XSi,t the correlation matrix formed using item context vectors restricted to the coordinates in S.\nTo ameliorate the challenges in high dimensional settings with sparse user models, we present the spCAB algorithm which adapts to extremely high dimensional features. The spCAB algorithm is identical to the CAB algorithm (Algorithm 1 except in two critical respects\n1. In step 4, instead of solving the least squares problem to identify the next proxy for the users, a sparse recovery technique is used, given in (7) below.\n2. We use a different notion of confidence bounds sCBi,t(x) = αsp(t) √ x>(M Ŝi,t−1 i,t−1 )\n−1x, where Ŝi,t−1 = supp(wi,t−1) is the support of the current estimate of the model for user i, and we set αsp(t) ≤ √ s log T .\nwi,t−1 = min ‖w‖0≤s′ fi,t(w) =: ∑ t:it=i (w>x̄t − yt)2 + ‖w‖22 (7)\nAlgorithm 2 Two-stage Hard-thresholding 1: Input: function f with gradient oracle, sparsity level s, sparsity expansion level ` 2: w1 = 0, t = 1 3: while not converged do 4: gt = ∇wf(wt), St = supp(wt) 5: Zt = St ∪ (largest ` elements of |gt\nSt |)\n6: bt = arg minβ,supp(β)⊆Zt f(β) // fully corrective step 7: w̃t = Ps(bt) 8: wt+1 = arg minw,supp(w)⊆supp(w̃t) f(w) // fully corrective step 9: t = t+ 1\n10: end while 11: Output: wt\nSparse recovery has a rich history in signal processing and learning domains with a tremendous amount of progress in recent years. There exist a plethora of methods, including relaxation techniques, iterative hard thresholding techniques, pursuit techniques and fully corrective techniques, to solve the problem.\nFor our purposes, fully corrective methods such as CoSaMP (Needell & Tropp, 2008) and Subspace Pursuit (Dai & Milenkovic, 2009) would be very convenient. These offer a linear rate of convergence whenever requisite properties, mentioned below, are satisfied. Algorithm 2 gives a general outline of these methods for general sparse recovery with an objective function f . We will only be required to consider the case when f is the ridge-regression function induced in the linear bandit problem as mentioned in (7).\nTwo properties that would be crucial to analyzing these sparse recovery methods are those of restricted strong convexity and restricted strong smoothness, outlined below.\nDefinition 1 (RSC Property) A differentiable function f : Rp → R is said to satisfy restricted strong convexity (RSC) at sparsity level s = s1 + s2 with strong convexity constraint αs if the following holds for all w1,w2 s.t. ‖w1‖0 ≤ s1 and ‖w2‖0 ≤ s2:\nf(w1)− f(w2) ≥ 〈w1 −w2,∇wf(w2)〉+ αs 2 ‖w1 −w2‖22.\nDefinition 2 (RSS Property) A differentiable function f : Rp → R is said to satisfy restricted strong smoothness (RSS) at sparsity level s = s1 + s2 with strong convexity constraint Ls if the following holds for allw1,w2 s.t. ‖w1‖0 ≤ s1 and ‖w2‖0 ≤ s2:\nf(w1)− f(w2) ≤ 〈w1 −w2,∇wf(w2)〉+ Ls 2 ‖w1 −w2‖22.\nB.1. Regret Analysis for spCAB\nWe will sketch a regret bound proof for spCAB by proving counterparts to Lemmata 1 and 3 in the sparse user model case. Lemma 2 will not require any modifications. First of all we invoke sparse recovery guarantees (Jain et al., 2014, Theorems 3 and 4) and standard martingale arguments to show the following result for two-stage fully corrective methods when applied to the user proxy estimation problem.\nTheorem 2 Suppose the objective function fi,t satisfies RSC and RSS parameters given by α2s+s∗(fi,t) = α and L2s+`(fi,t) = L respectively. Suppose Algorithm 2 is invoked with fi,t, ` ≥ s∗ and s ≥ 4L 2 α2 ` + s ∗ − ` ≥ 4L 2 α2 s ∗. Then, the τ -th iterate of Algorithm 2, for τ = O(Lα · log( 1 )) satisfies, with probability at least 1 − δ: ‖w τ − ui‖2 ≤\nO (√\ns∗ log dδ Ti(t)\n+ √ ) .\nIt is easy to see that if we run Algorithm 2 for longer than Ω( 1π2 ) iterations, as well as if Ti(t) ≥ Ω ( s∗ log dT π2 ) , then, we will have, with very high probability, ‖wτ − ui‖2 ≤ π/2,\nwhich can be easily seen to guarantee that Ŝi,t := supp(wi,t−1) = supp(wτ ) = supp(ui) = Si, since we set wi,t−1 =\nwτ . Now, notice that fully corrective methods always solve the least squares problem over their current support. This means that if we denote X = Xi,t, then we have\nwτ = ((XSi)>XSi + I)−1(XSi)>(Xui + i,t) = ((X Si)>XSi + I)−1(XSi)>(XSiuSii + i,t)\nUsing a proof technique identical to the one used for proving (Abbasi-Yadkori et al., 2011, Theorem 2) and applying restricted strong convexity, we can show that, for any x\n|w>i,t−1x− u>i x| ≤ αsp(t) · √ x>(M Ŝi,t i,t−1) −1x,\nwhere αsp(t) ≤ O( √ s log T/δ). Notice the stark improvement in the behavior of the exploration parameter in the sparse model case. For the dense model, we had to set α(t) ∼ √ d log t and in high dimensional settings, we have αsp(t) α(t). Note also that this establishes the counterpart to Lemma 3 in the sparse model case.\nTo complete the regret bound proof for the sparse case, we need to now complete three tasks:\n1. Establish Lemma 1;\n2. Satisfy the RSC, RSS conditions; 3. Ensure that Ti(t) ≥ Ω ( s∗ log dT\nπ2\n) .\nThe third task is the simplest – it is easy to see that using standard results on Bernoulli variables, after T0 = 2n ( s∗ log dT\nπ2 +\n2 log nTδ ) , with probability at least 1− δ, Ti(t) ≥ Ω ( s∗ log dT π2 ) for all i ∈ U and all t > T0.\nIt turns out that the first and the second tasks are actually identical. Recall from the proof of Lemma 1 that all we need is an upper bound on the quantity sCBi,t(x). While bounding CB, this was equivalent to establishing an upper bound on√ x>M−1i,t x which was itself equivalent to a lower bound on the eigenvalues of Mi,t. In this case, we need to show an upper bound on √ x>(M\nŜi,t i,t ) −1x =\n√ (xŜi,t)>(M\nŜi,t i,t ) −1xŜi,t ,\nsince MSi,t = (X S i,t) >XSi,t. This is equivalent to showing a lower bound on the restricted eigenvalues of Mi,t. More specifically, we will want to establish a lower bound on the following quantity:\nmin S⊂[d],|S|=s∗\nλmin(M S i,t)\nIt is easy to see that this is equivalent to demonstrating RSC/RSS properties of the objective function fi,t. Corresponding to the restricted eigenvalue requirement, we propose a counterpart of the hardness coefficient spHD ( {it, Ct}Tt=1, η ) , wherein we wish an upper bound on the time before all possible correlation matrices of all users have their s∗-restricted eigenvalues bounded below by η. For our results, we would require a bound on spHD ( {it, Ct}Tt=1, 16(αsp(T ))2\nγ2\n) . Fortunately, the\ntechnique of Gentile et al. (2014) of using Freedman-style inequalities (Tropp, 2011) which was used to prove the bound for Lemma 1 can still be harnessed to give\nsHD ( {it, Ct}Tt=1, η ) ≤ O (ns∗η λ2 log Tnd δs∗ ) Using the above, we can show the following regret bound for spCAB in the sparse user model setting.\nTheorem 3 If spCAB is executed on a bandit clustering setting with s∗-sparse user models satisfying the requisite properties mentioned above, then with probability at least 1− δ, the regret of spCAB satisfies\nT∑ t=1 rt ≤ Rsp + Õ (√ s∗ d Tc (E[m(X)]) ) ,\nwhere the Õ-notation hides logarithmic factors in TNdδ , and R is of the form\nRsp = c n2 (s∗)2\n√ s ∗\nλ2 γ2 log2.5\n( Tnd\nδs∗\n) .\nNotice the drastic reduction in the dependence of d in the regret bound. spCAB enjoys a regret bound that depends weakly on the ambient dimension of the problem setting as it has only √ d and log d dependence on d. We also notice that the bound can be further improved if the item contexts are low dimensional as well.\nSuppose that the item contexts xt,k are sampled from a distribution that has support only over a low r-dimensional space. Then, it can be easily shown that spCAB, without any modifications, offers the following regret bound.\nT∑ t=1 rt ≤ c n2 (s∗)2 √ s ∗ λ2 γ2 log2.5 ( Tnd δs∗ ) + Õ (√ s∗ r Tc (E[m(X)]) ) .\nNote that in this regret bound, the dependence on d is only in logarithmic terms."
    } ],
    "references" : [ {
      "title" : "Improved algorithms for linear stochastic bandits",
      "author" : [ "Abbasi-Yadkori", "Yasin", "Pal", "David", "Szepesvari", "Csaba" ],
      "venue" : "In Proc. NIPS,",
      "citeRegEx" : "Abbasi.Yadkori et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Abbasi.Yadkori et al\\.",
      "year" : 2011
    }, {
      "title" : "Online-to-Confidence-Set Conversions and Application to Sparse Stochastic Bandits",
      "author" : [ "Abbasi-Yadkori", "Yasin", "Pál", "Dávid", "Szepesvári", "Csaba" ],
      "venue" : "In Proc 15th AISTATS,",
      "citeRegEx" : "Abbasi.Yadkori et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Abbasi.Yadkori et al\\.",
      "year" : 2012
    }, {
      "title" : "Thompson sampling for contextual bandits with linear payoffs",
      "author" : [ "S. Agrawal", "N. Goyal" ],
      "venue" : "In 30th ICML,",
      "citeRegEx" : "Agrawal and Goyal,? \\Q2013\\E",
      "shortCiteRegEx" : "Agrawal and Goyal",
      "year" : 2013
    }, {
      "title" : "Exploration-exploitation tradeoff using variance estimates in multi-armed bandits",
      "author" : [ "Audibert", "Jean Yves", "Munos", "Remi", "Szepesvari", "Csaba" ],
      "venue" : "In Theoretical Computer Science,",
      "citeRegEx" : "Audibert et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Audibert et al\\.",
      "year" : 2009
    }, {
      "title" : "Using confidence bounds for explorationexploitation trade-offs",
      "author" : [ "Auer", "Peter" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Auer and Peter.,? \\Q2002\\E",
      "shortCiteRegEx" : "Auer and Peter.",
      "year" : 2002
    }, {
      "title" : "Finite-time analysis of the multiarmed bandit problem",
      "author" : [ "Auer", "Peter", "Cesa-Bianchi", "Nicolo", "Fischer", "Paul" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Auer et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Auer et al\\.",
      "year" : 2002
    }, {
      "title" : "Sequential transfer in multi-armed bandit with finite set of models",
      "author" : [ "M.G. Azar", "A. Lazaric", "E. Brunskill" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Azar et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Azar et al\\.",
      "year" : 2013
    }, {
      "title" : "Implementable confidence sets in high dimensional regression",
      "author" : [ "Carpentier", "Alexandra" ],
      "venue" : "In Proc 18th AISTATS,",
      "citeRegEx" : "Carpentier and Alexandra.,? \\Q2015\\E",
      "shortCiteRegEx" : "Carpentier and Alexandra.",
      "year" : 2015
    }, {
      "title" : "Bandit Theory meets Compressed Sensing for high-dimensional Stochastic Linear Bandit",
      "author" : [ "Carpentier", "Alexandra", "Munos", "Remi" ],
      "venue" : "In Proc. 15th AISTATS,",
      "citeRegEx" : "Carpentier et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Carpentier et al\\.",
      "year" : 2012
    }, {
      "title" : "A gang of bandits",
      "author" : [ "Cesa-Bianchi", "Nicolo", "Gentile", "Claudio", "Zappella", "Giovanni" ],
      "venue" : "In Proc. NIPS,",
      "citeRegEx" : "Cesa.Bianchi et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Cesa.Bianchi et al\\.",
      "year" : 2013
    }, {
      "title" : "Contextual bandits with linear payoff functions",
      "author" : [ "Chu", "Wei", "Li", "Lihong", "Reyzin", "Lev", "Schapire", "Robert" ],
      "venue" : "In Proc. AISTATS,",
      "citeRegEx" : "Chu et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Chu et al\\.",
      "year" : 2011
    }, {
      "title" : "Multiclass classification with bandit feedback using adaptive regularization",
      "author" : [ "Crammer", "Koby", "Gentile", "Claudio" ],
      "venue" : "In Proc. ICML,",
      "citeRegEx" : "Crammer et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Crammer et al\\.",
      "year" : 2011
    }, {
      "title" : "Subspace pursuit for compressive sensing signal reconstruction",
      "author" : [ "Dai", "Wei", "Milenkovic", "Olgica" ],
      "venue" : "IEEE Trans. Inf. Theory,",
      "citeRegEx" : "Dai et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Dai et al\\.",
      "year" : 2009
    }, {
      "title" : "Selective sampling and active learning from single and multiple teachers",
      "author" : [ "Dekel", "Ofer", "Gentile", "Claudio", "Sridharan", "Karthik" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Dekel et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Dekel et al\\.",
      "year" : 2012
    }, {
      "title" : "High-dimensional gaussian process bandit",
      "author" : [ "J. Djolonga", "A. Krause", "V. Cevher" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Djolonga et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Djolonga et al\\.",
      "year" : 2013
    }, {
      "title" : "Online clustering of bandits",
      "author" : [ "Gentile", "Claudio", "Li", "Shuai", "Zappella", "Giovanni" ],
      "venue" : "In Proc. 31st ICML,",
      "citeRegEx" : "Gentile et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Gentile et al\\.",
      "year" : 2014
    }, {
      "title" : "On Iterative Hard Thresholding Methods for Highdimensional M-Estimation",
      "author" : [ "Jain", "Prateek", "Tewari", "Ambuj", "Kar", "Purushottam" ],
      "venue" : "[cs.LG],",
      "citeRegEx" : "Jain et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Jain et al\\.",
      "year" : 2014
    }, {
      "title" : "On the generalization ability of online strongly convex programming algorithm",
      "author" : [ "S. Kakade", "A. Tewari" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Kakade and Tewari,? \\Q2008\\E",
      "shortCiteRegEx" : "Kakade and Tewari",
      "year" : 2008
    }, {
      "title" : "Distributed clustering of linear bandits in peer to peer networks",
      "author" : [ "Korda", "Nathan", "Szorenyi", "Balazs", "Li", "Shuai" ],
      "venue" : "In Proc. 33rd ICML,",
      "citeRegEx" : "Korda et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Korda et al\\.",
      "year" : 2016
    }, {
      "title" : "Contextual gaussian process bandit optimization",
      "author" : [ "Krause", "Andreas", "Ong", "Cheng Soon" ],
      "venue" : "In Proc. NIPS,",
      "citeRegEx" : "Krause et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Krause et al\\.",
      "year" : 2011
    }, {
      "title" : "A contextual-bandit approach to personalized news article recommendation",
      "author" : [ "Li", "Lihong", "Chu", "Wei", "Langford", "John", "Schapire", "Robert" ],
      "venue" : "In Proc. WWW,",
      "citeRegEx" : "Li et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2010
    }, {
      "title" : "Collaborative filtering bandits",
      "author" : [ "Li", "Shuai", "Karatzoglou", "Alexandros", "Gentile", "Claudio" ],
      "venue" : "In Proc. 39th SIGIR,",
      "citeRegEx" : "Li et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Concentration inequalities and model selection",
      "author" : [ "Massart", "Pascal" ],
      "venue" : "In Lecture Notes in Mathematics. Springer,",
      "citeRegEx" : "Massart and Pascal.,? \\Q2007\\E",
      "shortCiteRegEx" : "Massart and Pascal.",
      "year" : 2007
    }, {
      "title" : "CoSaMP: Iterative Signal Recovery from Incomplete and Inaccurate Samples",
      "author" : [ "Needell", "Deanna", "Tropp", "Joel A" ],
      "venue" : "Appl. Comput. Harmon. Anal.,",
      "citeRegEx" : "Needell et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Needell et al\\.",
      "year" : 2008
    }, {
      "title" : "Dynamic clustering of contextual multi-armed bandits",
      "author" : [ "Nguyen", "Trong", "Lauw", "Hady" ],
      "venue" : "In Proc. CIKM,",
      "citeRegEx" : "Nguyen et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2014
    }, {
      "title" : "Recommending new movies: Even a few ratings are more valuable than metadata",
      "author" : [ "Pilaszy", "Istvan", "Tikk", "Domonkos" ],
      "venue" : "In Proc. RecSys,",
      "citeRegEx" : "Pilaszy et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Pilaszy et al\\.",
      "year" : 2009
    }, {
      "title" : "Modelling relational data using bayesian clustered tensor factorization",
      "author" : [ "I. Sutskever", "R. Salakhutdinov", "J. Tenenbaum" ],
      "venue" : "In NIPS,",
      "citeRegEx" : "Sutskever et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Sutskever et al\\.",
      "year" : 2009
    }, {
      "title" : "Freedmans inequality for matrix martingales",
      "author" : [ "Tropp", "Joel A" ],
      "venue" : "[math.PR],",
      "citeRegEx" : "Tropp and A.,? \\Q2011\\E",
      "shortCiteRegEx" : "Tropp and A.",
      "year" : 2011
    }, {
      "title" : "Contextual bandits in a collaborative environment",
      "author" : [ "Wu", "Qingyun", "Wang", "Huazheng", "Gu", "Quanquan", "Hongning" ],
      "venue" : "In Proc. 39th SIGIR,",
      "citeRegEx" : "Wu et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2016
    }, {
      "title" : "Hierarchical exploration for accelerating contextual bandits",
      "author" : [ "Yue", "Yisong", "Hong", "Sue Ann", "Guestrin", "Carlos" ],
      "venue" : "In Proc. ICML,",
      "citeRegEx" : "Yue et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Yue et al\\.",
      "year" : 2012
    }, {
      "title" : "Regret Analysis for spCAB We will sketch a regret bound proof for spCAB by proving counterparts to Lemmata 1 and 3 in the sparse user model case. Lemma 2 will not require any modifications. First of all we invoke sparse recovery guarantees (Jain et al., 2014, Theorems 3 and 4) and standard martingale arguments to show the following result for two-stage fully corrective methods",
      "author" : [ "−w2‖2. B" ],
      "venue" : null,
      "citeRegEx" : "B.1.,? \\Q2014\\E",
      "shortCiteRegEx" : "B.1.",
      "year" : 2014
    }, {
      "title" : "Using a proof technique identical to the one used for proving (Abbasi-Yadkori et al., 2011, Theorem 2) and applying restricted strong convexity",
      "author" : [ "i + i" ],
      "venue" : null,
      "citeRegEx" : "i and t,? \\Q2011\\E",
      "shortCiteRegEx" : "i and t",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 20,
      "context" : ", (Auer, 2002; Li et al., 2010; Chu et al., 2011; Abbasi-Yadkori et al., 2011)).",
      "startOffset" : 2,
      "endOffset" : 78
    }, {
      "referenceID" : 10,
      "context" : ", (Auer, 2002; Li et al., 2010; Chu et al., 2011; Abbasi-Yadkori et al., 2011)).",
      "startOffset" : 2,
      "endOffset" : 78
    }, {
      "referenceID" : 0,
      "context" : ", (Auer, 2002; Li et al., 2010; Chu et al., 2011; Abbasi-Yadkori et al., 2011)).",
      "startOffset" : 2,
      "endOffset" : 78
    }, {
      "referenceID" : 26,
      "context" : ", (Sutskever et al., 2009)).",
      "startOffset" : 2,
      "endOffset" : 26
    }, {
      "referenceID" : 15,
      "context" : "The technique of sequentially clustering users in the bandit setting was introduced in (Maillard & Mannor, 2014; Gentile et al., 2014), but has also been inspired by earlier references, e.",
      "startOffset" : 87,
      "endOffset" : 134
    }, {
      "referenceID" : 6,
      "context" : ", (Azar et al., 2013) on transfer learning for stochastic bandits, and (Djolonga et al.",
      "startOffset" : 2,
      "endOffset" : 21
    }, {
      "referenceID" : 14,
      "context" : ", 2013) on transfer learning for stochastic bandits, and (Djolonga et al., 2013) on low-rank (Gaussian Process) bandits.",
      "startOffset" : 57,
      "endOffset" : 80
    }, {
      "referenceID" : 18,
      "context" : "This led to further developments such as (Nguyen & Lauw, 2014), which relies on k-means clustering, and (Korda et al., 2016) which proposes distributed clustering of confidence ball algorithms for solving linear bandit problems in peer to peer networks.",
      "startOffset" : 104,
      "endOffset" : 124
    }, {
      "referenceID" : 9,
      "context" : "Related papers that implement feedback sharing mechanisms by leveraging (additional) social information among users include (Cesa-Bianchi et al., 2013; Wu et al., 2016).",
      "startOffset" : 124,
      "endOffset" : 168
    }, {
      "referenceID" : 28,
      "context" : "Related papers that implement feedback sharing mechanisms by leveraging (additional) social information among users include (Cesa-Bianchi et al., 2013; Wu et al., 2016).",
      "startOffset" : 124,
      "endOffset" : 168
    }, {
      "referenceID" : 21,
      "context" : "Even more related to our work is the recent paper (Li et al., 2016) which proposes to simultaneously cluster users as well as items, with item clusters dictating user clusters.",
      "startOffset" : 50,
      "endOffset" : 67
    }, {
      "referenceID" : 15,
      "context" : "We note that such gap assumptions are standard in this literature (Gentile et al., 2014; Li et al., 2016).",
      "startOffset" : 66,
      "endOffset" : 105
    }, {
      "referenceID" : 21,
      "context" : "We note that such gap assumptions are standard in this literature (Gentile et al., 2014; Li et al., 2016).",
      "startOffset" : 66,
      "endOffset" : 105
    }, {
      "referenceID" : 10,
      "context" : ", (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011; Krause & Ong, 2011; Crammer & Gentile, 2011; Yue et al., 2012; Djolonga et al., 2013; Cesa-Bianchi et al., 2013; Agrawal & Goyal, 2013; Gentile et al., 2014; Li et al., 2016; Korda et al., 2016), and references therein), the unknown user vectorui determines the (average) behavior of user i.",
      "startOffset" : 2,
      "endOffset" : 256
    }, {
      "referenceID" : 0,
      "context" : ", (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011; Krause & Ong, 2011; Crammer & Gentile, 2011; Yue et al., 2012; Djolonga et al., 2013; Cesa-Bianchi et al., 2013; Agrawal & Goyal, 2013; Gentile et al., 2014; Li et al., 2016; Korda et al., 2016), and references therein), the unknown user vectorui determines the (average) behavior of user i.",
      "startOffset" : 2,
      "endOffset" : 256
    }, {
      "referenceID" : 29,
      "context" : ", (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011; Krause & Ong, 2011; Crammer & Gentile, 2011; Yue et al., 2012; Djolonga et al., 2013; Cesa-Bianchi et al., 2013; Agrawal & Goyal, 2013; Gentile et al., 2014; Li et al., 2016; Korda et al., 2016), and references therein), the unknown user vectorui determines the (average) behavior of user i.",
      "startOffset" : 2,
      "endOffset" : 256
    }, {
      "referenceID" : 14,
      "context" : ", (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011; Krause & Ong, 2011; Crammer & Gentile, 2011; Yue et al., 2012; Djolonga et al., 2013; Cesa-Bianchi et al., 2013; Agrawal & Goyal, 2013; Gentile et al., 2014; Li et al., 2016; Korda et al., 2016), and references therein), the unknown user vectorui determines the (average) behavior of user i.",
      "startOffset" : 2,
      "endOffset" : 256
    }, {
      "referenceID" : 9,
      "context" : ", (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011; Krause & Ong, 2011; Crammer & Gentile, 2011; Yue et al., 2012; Djolonga et al., 2013; Cesa-Bianchi et al., 2013; Agrawal & Goyal, 2013; Gentile et al., 2014; Li et al., 2016; Korda et al., 2016), and references therein), the unknown user vectorui determines the (average) behavior of user i.",
      "startOffset" : 2,
      "endOffset" : 256
    }, {
      "referenceID" : 15,
      "context" : ", (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011; Krause & Ong, 2011; Crammer & Gentile, 2011; Yue et al., 2012; Djolonga et al., 2013; Cesa-Bianchi et al., 2013; Agrawal & Goyal, 2013; Gentile et al., 2014; Li et al., 2016; Korda et al., 2016), and references therein), the unknown user vectorui determines the (average) behavior of user i.",
      "startOffset" : 2,
      "endOffset" : 256
    }, {
      "referenceID" : 21,
      "context" : ", (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011; Krause & Ong, 2011; Crammer & Gentile, 2011; Yue et al., 2012; Djolonga et al., 2013; Cesa-Bianchi et al., 2013; Agrawal & Goyal, 2013; Gentile et al., 2014; Li et al., 2016; Korda et al., 2016), and references therein), the unknown user vectorui determines the (average) behavior of user i.",
      "startOffset" : 2,
      "endOffset" : 256
    }, {
      "referenceID" : 18,
      "context" : ", (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011; Krause & Ong, 2011; Crammer & Gentile, 2011; Yue et al., 2012; Djolonga et al., 2013; Cesa-Bianchi et al., 2013; Agrawal & Goyal, 2013; Gentile et al., 2014; Li et al., 2016; Korda et al., 2016), and references therein), the unknown user vectorui determines the (average) behavior of user i.",
      "startOffset" : 2,
      "endOffset" : 256
    }, {
      "referenceID" : 5,
      "context" : ", (Auer et al., 2002; Audibert et al., 2009)).",
      "startOffset" : 2,
      "endOffset" : 44
    }, {
      "referenceID" : 3,
      "context" : ", (Auer et al., 2002; Audibert et al., 2009)).",
      "startOffset" : 2,
      "endOffset" : 44
    }, {
      "referenceID" : 9,
      "context" : "Similar to previous works (Cesa-Bianchi et al., 2013; Gentile et al., 2014; Nguyen & Lauw, 2014; Li et al., 2016; Wu et al., 2016), CAB maintains a vector estimate wi,t to serve as a proxy to the unknown user vector ui at time t.",
      "startOffset" : 26,
      "endOffset" : 130
    }, {
      "referenceID" : 15,
      "context" : "Similar to previous works (Cesa-Bianchi et al., 2013; Gentile et al., 2014; Nguyen & Lauw, 2014; Li et al., 2016; Wu et al., 2016), CAB maintains a vector estimate wi,t to serve as a proxy to the unknown user vector ui at time t.",
      "startOffset" : 26,
      "endOffset" : 130
    }, {
      "referenceID" : 21,
      "context" : "Similar to previous works (Cesa-Bianchi et al., 2013; Gentile et al., 2014; Nguyen & Lauw, 2014; Li et al., 2016; Wu et al., 2016), CAB maintains a vector estimate wi,t to serve as a proxy to the unknown user vector ui at time t.",
      "startOffset" : 26,
      "endOffset" : 130
    }, {
      "referenceID" : 28,
      "context" : "Similar to previous works (Cesa-Bianchi et al., 2013; Gentile et al., 2014; Nguyen & Lauw, 2014; Li et al., 2016; Wu et al., 2016), CAB maintains a vector estimate wi,t to serve as a proxy to the unknown user vector ui at time t.",
      "startOffset" : 26,
      "endOffset" : 130
    }, {
      "referenceID" : 9,
      "context" : "This is in strike contrast to past approaches to bandit aggregation, such as GobLin (Cesa-Bianchi et al., 2013), CLUB (Gentile et al.",
      "startOffset" : 84,
      "endOffset" : 111
    }, {
      "referenceID" : 15,
      "context" : ", 2013), CLUB (Gentile et al., 2014), and COFIBA (Li et al.",
      "startOffset" : 14,
      "endOffset" : 36
    }, {
      "referenceID" : 21,
      "context" : ", 2014), and COFIBA (Li et al., 2016), where more involved feedback sharing mechanisms across the users are implemented which are based either on static network Laplacians or on time-evolving connected components of graphs over a given set of users.",
      "startOffset" : 20,
      "endOffset" : 37
    }, {
      "referenceID" : 10,
      "context" : "The first term is a measure of hardness of the data sequence {it, Ct}t=1 at hand whereas the second term is the usual √ T -style term in linear bandit regret analyses (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011).",
      "startOffset" : 167,
      "endOffset" : 226
    }, {
      "referenceID" : 0,
      "context" : "The first term is a measure of hardness of the data sequence {it, Ct}t=1 at hand whereas the second term is the usual √ T -style term in linear bandit regret analyses (Auer, 2002; Chu et al., 2011; Abbasi-Yadkori et al., 2011).",
      "startOffset" : 167,
      "endOffset" : 226
    }, {
      "referenceID" : 0,
      "context" : "However, a naive algorithm that disregards the cluster structure, making no attempts to incorporate collaborative effects, and running n-many independent LINUCB-like algorithms (Auer, 2002; Abbasi-Yadkori et al., 2011; Chu et al., 2011), easily yields a √ nT regret bound3.",
      "startOffset" : 177,
      "endOffset" : 236
    }, {
      "referenceID" : 10,
      "context" : "However, a naive algorithm that disregards the cluster structure, making no attempts to incorporate collaborative effects, and running n-many independent LINUCB-like algorithms (Auer, 2002; Abbasi-Yadkori et al., 2011; Chu et al., 2011), easily yields a √ nT regret bound3.",
      "startOffset" : 177,
      "endOffset" : 236
    }, {
      "referenceID" : 0,
      "context" : "Finally, we recall the following upper confidence bound, from (Abbasi-Yadkori et al., 2011).",
      "startOffset" : 62,
      "endOffset" : 91
    }, {
      "referenceID" : 1,
      "context" : "We conclude with a pointer to an additional result we have for sparse linear models contained in the supplemental (Section B therein), which is in line with past analyses on sparse linear bandits for a single user (Abbasi-Yadkori et al., 2012; Carpentier & Munos, 2012; Carpentier, 2015): If u1, .",
      "startOffset" : 214,
      "endOffset" : 287
    }, {
      "referenceID" : 15,
      "context" : "We tried to follow as much as possible previous experimental settings, like those described in (CesaBianchi et al., 2013; Gentile et al., 2014; Korda et al., 2016; Li et al., 2016).",
      "startOffset" : 95,
      "endOffset" : 180
    }, {
      "referenceID" : 18,
      "context" : "We tried to follow as much as possible previous experimental settings, like those described in (CesaBianchi et al., 2013; Gentile et al., 2014; Korda et al., 2016; Li et al., 2016).",
      "startOffset" : 95,
      "endOffset" : 180
    }, {
      "referenceID" : 21,
      "context" : "We tried to follow as much as possible previous experimental settings, like those described in (CesaBianchi et al., 2013; Gentile et al., 2014; Korda et al., 2016; Li et al., 2016).",
      "startOffset" : 95,
      "endOffset" : 180
    }, {
      "referenceID" : 20,
      "context" : ", (Li et al., 2010)), we actually simulated a random logged policy as follows.",
      "startOffset" : 2,
      "endOffset" : 19
    }, {
      "referenceID" : 15,
      "context" : ", (CesaBianchi et al., 2013; Gentile et al., 2014).",
      "startOffset" : 2,
      "endOffset" : 50
    }, {
      "referenceID" : 15,
      "context" : "• CLUB (Gentile et al., 2014) sequentially refines user clusters based on their confidence ellipsoid balls; We seeded the graph over users by an initial random Erdos-Renyi graphs with sparsity parameter p = (3 log n)/n.",
      "startOffset" : 7,
      "endOffset" : 29
    }, {
      "referenceID" : 10,
      "context" : "• LinUCB-SINGLE uses a single instance of LinUCB (Chu et al., 2011) to serve all users, i.",
      "startOffset" : 49,
      "endOffset" : 67
    }, {
      "referenceID" : 20,
      "context" : ", (Li et al., 2010; Cesa-Bianchi et al., 2013; Gentile et al., 2014; Li et al., 2016)), and so are some of the results that we reproduce here.",
      "startOffset" : 2,
      "endOffset" : 85
    }, {
      "referenceID" : 9,
      "context" : ", (Li et al., 2010; Cesa-Bianchi et al., 2013; Gentile et al., 2014; Li et al., 2016)), and so are some of the results that we reproduce here.",
      "startOffset" : 2,
      "endOffset" : 85
    }, {
      "referenceID" : 15,
      "context" : ", (Li et al., 2010; Cesa-Bianchi et al., 2013; Gentile et al., 2014; Li et al., 2016)), and so are some of the results that we reproduce here.",
      "startOffset" : 2,
      "endOffset" : 85
    }, {
      "referenceID" : 21,
      "context" : ", (Li et al., 2010; Cesa-Bianchi et al., 2013; Gentile et al., 2014; Li et al., 2016)), and so are some of the results that we reproduce here.",
      "startOffset" : 2,
      "endOffset" : 85
    }, {
      "referenceID" : 15,
      "context" : "On the LastFM and Delicious datasets (Figure 2), the results we report are consistent with (Gentile et al., 2014).",
      "startOffset" : 91,
      "endOffset" : 113
    }, {
      "referenceID" : 15,
      "context" : ", (Gentile et al., 2014)), this dataset does not seem to contain any collaborative information, hence we can hardly expect to take advantage of clustering efforts.",
      "startOffset" : 2,
      "endOffset" : 24
    }, {
      "referenceID" : 9,
      "context" : ", (Cesa-Bianchi et al., 2013; Gentile et al., 2014; Nguyen & Lauw, 2014; Li et al., 2016; Wu et al., 2016)), and offers a much higher flexibility in handling practical situations, like the on-the-fly inclusion or exclusion of users.",
      "startOffset" : 2,
      "endOffset" : 106
    }, {
      "referenceID" : 15,
      "context" : ", (Cesa-Bianchi et al., 2013; Gentile et al., 2014; Nguyen & Lauw, 2014; Li et al., 2016; Wu et al., 2016)), and offers a much higher flexibility in handling practical situations, like the on-the-fly inclusion or exclusion of users.",
      "startOffset" : 2,
      "endOffset" : 106
    }, {
      "referenceID" : 21,
      "context" : ", (Cesa-Bianchi et al., 2013; Gentile et al., 2014; Nguyen & Lauw, 2014; Li et al., 2016; Wu et al., 2016)), and offers a much higher flexibility in handling practical situations, like the on-the-fly inclusion or exclusion of users.",
      "startOffset" : 2,
      "endOffset" : 106
    }, {
      "referenceID" : 28,
      "context" : ", (Cesa-Bianchi et al., 2013; Gentile et al., 2014; Nguyen & Lauw, 2014; Li et al., 2016; Wu et al., 2016)), and offers a much higher flexibility in handling practical situations, like the on-the-fly inclusion or exclusion of users.",
      "startOffset" : 2,
      "endOffset" : 106
    }, {
      "referenceID" : 13,
      "context" : ", Lemma 24 in (Dekel et al., 2012)) ≤ 2 dα(T ) log(1 + |UP(j)|) ≤ 2 dα(T ) log(1 + T ) ,",
      "startOffset" : 14,
      "endOffset" : 34
    }, {
      "referenceID" : 15,
      "context" : "The proof is similar to that of Lemma 2 in (Gentile et al., 2014), where it is shown (Claim 1 therein) that under the assumptions of this lemma",
      "startOffset" : 43,
      "endOffset" : 65
    }, {
      "referenceID" : 15,
      "context" : "The proof then continues as in Lemma 2 of (Gentile et al., 2014) by setting up a Freedman-style matrix tail bound to get, as a consequence of the above, the following high-confidence estimate, holding with probability at least 1 − δ, uniformly over j ∈ U , and t = 1, 2, .",
      "startOffset" : 42,
      "endOffset" : 64
    }, {
      "referenceID" : 15,
      "context" : "Fortunately, the technique of Gentile et al. (2014) of using Freedman-style inequalities (Tropp, 2011) which was used to prove the bound for Lemma 1 can still be harnessed to give",
      "startOffset" : 30,
      "endOffset" : 52
    } ],
    "year" : 2017,
    "abstractText" : "We investigate a novel cluster-of-bandit algorithm CAB for collaborative recommendation tasks that implements the underlying feedback sharing mechanism by estimating the neighborhood of users in a context-dependent manner. CAB makes sharp departures from the state of the art by incorporating collaborative effects into inference as well as learning processes in a manner that seamlessly interleaving explore-exploit tradeoffs and collaborative steps. We prove regret bounds under various assumptions on the data, which exhibit a crisp dependence on the expected number of clusters over the users, a natural measure of the statistical difficulty of the learning task. Experiments on production and real-world datasets show that CAB offers significantly increased prediction performance against a representative pool of state-of-the-art methods.",
    "creator" : "LaTeX with hyperref package"
  }
}