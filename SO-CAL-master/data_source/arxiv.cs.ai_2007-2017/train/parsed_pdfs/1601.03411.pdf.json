{
  "name" : "1601.03411.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Analysis of Algorithms and Partial Algorithms",
    "authors" : [ "Andrew MacFie" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 1.\n03 41\n1v 5\n[ cs\n.A I]\n7 A\nug 2\n01 7"
    }, {
      "heading" : "1 Introduction: Shortcomings of Traditional Analysis of Algorithms",
      "text" : "Currently, the (running time) analysis of algorithms takes the following form. Given two algorithms A, B that solve the same problem, we find which is more efficient by asymptotically comparing the running time sequences (an), (bn) [4,15]. This could be using worst-case or average-case running times or even smoothed analysis [16]. We refer to this general method as traditional analysis of algorithms.\nAs with any model, traditional analysis of algorithms is not perfect. Authors have noted [1,9] that comparing sequence tails avoids the arbitrariness of any particular range of input lengths but leads us to say an = n\n100 is superior to bn = ( 1 + exp(−1010) )n\nwhich is false for practical purposes. A further issue with traditional analysis is illustrated by this situation: Say we have a function F : {0, 1}∗ → {0, 1} and an algorithm A that computes F such that for n ≥ 0, A takes (n!)! steps on the input 0n and n steps on any other input of length n. The algorithm A then has worst-case running time (n!)! and average-case running time slightly greater than 2−n(n!)!, which are both terrible. However, if the inputs are generated according to a uniform distribution, the probability of taking more than n steps is 2−n which is quickly negligible. We see that A should be considered an excellent algorithm but traditional analysis does not tell us that, unless we add “with high probability”.\nThe same issue arises if A simply does not halt on 0n, in which case the worst-case and average-case running times are infinite. Indeed, this is not an esoteric phenomenon. For any problem with Turing degree 0′ we cannot have an algorithm that halts on every input, but we develop partial solutions that work on a subset of inputs. Such problems include string compression (Kolmogorov complexity), the halting problem in program analysis [2], algebraic simplification [17], program optimization, automated theorem proving, and Solomonoff induction (central to artificial general intelligence [13]). E.g. in the case of automated\ntheorem proving, Buss, describing the main open problems in proof theory [3], states, “Computerized proof search ... is widely used, but almost no mathematical theory is known about the effectiveness or optimality of present-day algorithms.”\nDefinition 1. An algorithm A is a partial algorithm (a.k.a. computational method [12, p5]) for a given problem if on all inputs, A either outputs the correct value, or does not terminate.\nDefinition 2. We refer to partial algorithms for problems with Turing degree 0′ as 0′ algorithms.\nTo analyze 0′ algorithms, and perhaps to better analyze normal terminating algorithms, we need a new approach that is not based on worst-case or average-case running time sequences. In Sect. 2 we present a new method for analyzing algorithms, called expected-reward analysis that avoids some of the issues mentioned above. Then in Sect. 3 we mention how this method can be used in self-improving AI systems. We give directions for further work in Sect. 4.\nNotation 1. Given a (possibly partial) algorithm A and an input ω, we denote the number of steps taken by A on ω by cA(ω), which takes the value ∞ if A does not halt on ω."
    }, {
      "heading" : "2 Expected-Reward Analysis of Algorithms",
      "text" : ""
    }, {
      "heading" : "2.1 Definition",
      "text" : "Let A be a (possibly partial) algorithm with inputs in Ω. We say the score of A is\nS(A) = ∑\nω∈Ω\nP ({ω})r(ω)D(cA(ω)) = E(r · (D ◦ cA)) ,\nwhere P is a probability measure on Ω, D is a discount function [7], and r(ω) is a reward (a.k.a. utility) value associated with obtaining the solution to ω. The expression S(A) may be interpreted as the expected discounted reward that A receives if run on a random input, and the practice of comparing scores among algorithms we call expected-reward analysis. A higher score indicates a more efficient algorithm.\nThe functions D and r are arbitrary and are free to be set in the context of a particular application. E.g. in graphical user interface software we often desire near-instant responses, with utility rapidly dropping off with time. Assuming 0 ≤ r ≤ 1, we immediately see that for all A, partial or not, we have\n0 ≤ S(A) ≤ 1 .\nFor simplicity in this paper we assume r(ω) = 1 and D is an exponential discount function, i.e.\nD(cA(ω)) = exp(−λ cA(ω)) ,\nwhere λ > 0 is a discount rate.\nThe choice of P is also arbitrary; we remark on two special cases. If all inputs of a given length are weighted equally, P is determined by a probability mass function on Z0+. In this case any common discrete probability distribution may be used as appropriate. The measure P is also determined by a probability mass function on Z0+ if we weight equal-length inputs according to Solomonoff’s universal distribution m [13], which is a particularly good general model, although computationally difficult.\nExpected-reward analysis is non-asymptotic, in the sense that all inputs potentially matter. Thus, while expected-reward analysis can be used on terminating algorithms, we expect it to give different results from traditional analysis, in general. Since particular inputs can make a difference to S(A), it may be advantageous to “hardcode” initial cases into an algorithm. This practice certainly exists, e.g. humans may store the 12×12 multiplication table as well as knowing a general integer multiplication algorithm.\nComputational complexity theory often works with classes of problems whose definitions are equivalent for all “reasonable” models of computation [5]. However, even a varying constant factor could arbitrarily change a score. This is simply the price of concreteness, and outside of complexity theory, traditional analysis of algorithms generally selects a particular model of computation and gives precise results that do not necessarily apply to other models [6].\nUnlike traditional analysis, experimental data is relevant to score values in a statistical sense. If we are able to generate inputs according to P , either artificially or by sampling inputs found in practice, S(A) is a quantity amenable to statistical estimation. This suggests a form of experimental analysis of algorithms which focuses on a single real number rather than plotting the estimated running time for every input length, which, in the necessary absence of asymptotics in experimental analysis, may not conclusively rank two competing algorithms anyway.\nThe expected-reward paradigm already appears in the analysis of artificial agents, rather than algorithms [8]. As we see in Sect. 3, however, even in applications to AI, working in the more classical domain of algorithms brings benefits."
    }, {
      "heading" : "2.2 Theory and Practice",
      "text" : "Traditional analysis of algorithms has an established literature going back decades which provides a set of techniques for performing traditional analysis on algorithms developed for various problems. We do not significantly develop a mathematical theory of expected-reward analysis here, but we make some very brief initial remarks.\nBy way of introductory example, we consider expected-reward analysis applied to some well-known sorting algorithms. Let Sn be the set of permutations of [1..n] and let Πn be a uniform random element of Sn. We denote the algorithms mergesort and quicksort by M and Q, as defined in [15], and set\nmn = E [exp(−λ cM (Πn))] , qn = E [exp(−λ cQ(Πn))] ,\nwhere cA(ω) is the number of comparison operations used by an algorithm A to sort an input ω.\nProposition 1. For n ≥ 1 we have\nmn = exp ( −λ(n⌈lg(n)⌉+ n− 2⌈lg(n)⌉) ) , m0 = 1, (1)\nqn = e−λ(n+1)\nn\nn ∑\nk=1\nqk−1qn−k, q0 = 1 .\nProof. From [15], M makes the same number of comparisons for all inputs of length n ≥ 1:\ncM (Πn) = n⌈lg(n)⌉+ n− 2 ⌈lg(n)⌉ ,\nso (1) is immediate. Now, when Q is called on Πn, let ρ(Πn) be the pivot element, and let Πn, Πn be the subarrays constructed for recursive calls to Q, where the elements in Πn are less than ρ(Πn), and the elements in Πn are greater.\nWe have\nE[ exp(−λcQ(Πn))]\n= 1\nn\nn ∑\nk=1\nE[exp(−λ(n+ 1 + cQ(Πn) + cQ(Πn)) ) | ρ(Πn) = k]\n= e−λ(n+1)\nn\nn ∑\nk=1\nE[exp(−λ(cQ(Πn) + cQ(Πn)) ) | ρ(Πn) = k] .\nIt can be seen that given ρ(Πn) = k, Πn and Πn are independent, thus\nE[ exp(−λcQ(Πn))]\n= e−λ(n+1)\nn\nn ∑\nk=1\nE[exp(−λcQ(Πn)) | ρ(Πn) = k] ·\nE[exp(−λcQ(Πn)) | ρ(Πn) = k]\n= e−λ(n+1)\nn\nn ∑\nk=1\nE[exp(−λcQ(Πk−1))]E[exp(−λcQ(Πn−k))] . ⊓⊔\nFrom examining the best-case performance of Q, it turns out that cM (Πn) ≤ cQ(Πn) for all n, so the expected-reward comparison of M and Q is easy: S(M) ≥ S(Q) for any parameters. However, we may further analyze the absolute scores of M and Q to facilitate comparisons to arbitrary sorting algorithms. When performing expected-reward analysis on an individual algorithm, our main desideratum is a way to quickly compute the score value to within a given precision for each possible parameter value P, λ. Proposition 1 gives a way of computing scores of M and Q for measures P that give equal length inputs\nequal weight, although it does not immediately suggest an efficient way in all cases. Bounds on scores are also potentially useful and may be faster to compute; in the next proposition, we give bounds on mn and qn which are simpler than the exact expressions above.\nProposition 2. For n ≥ 1,\ne−2λ(n−1)\n(n− 1)!λ/ log(2) ≤ mn ≤\ne−λ(n−1)\n(n− 1)!λ/ log(2) . (2)\nFor all 0 < λ ≤ log(2) and n ≥ 0,\ne−2γλ(n+1)−λ\n(n+ 1)!2λ (2π(n+ 1))λ < qn ≤\ne−2λn\n(n!)λ/ log(2) ,\nwhere γ is Euler’s constant.\nProof. Sedgewick and Flajolet [15] give an alternative expression for the running time of mergesort:\ncM (Πn) =\nn−1 ∑\nk=1\n(⌊lg k⌋+ 2) .\nStatement (2) follows from this because\nlog(k)/ log(2) + 1 < ⌊lg k⌋+ 2 ≤ log(k)/ log(2) + 2 .\nWith 0 < λ ≤ log(2), we prove the upper bound\nqn ≤ e−2λn\n(n!)λ/ log(2) (3)\nfor all n ≥ 0 by induction. Relation (3) clearly holds for n = 0. We show that (3) can be proved for n = N (N > 0) on the assumption that (3) holds for 0 ≤ n ≤ N − 1. Proposition 1 gives\nqN = e−λ(N+1)\nN\nN ∑\nk=1\nqk−1qN−k\n≤ e−λ(N+1)\nN\nN ∑\nk=1\ne−2λ(k−1) ((k − 1)!)λ/ log(2) e−2λ(N−k) ((N − k)!)λ/ log(2)\n(by the assumption)\n= e−3λN+λ\n(\n1\nN\nN ∑\nk=1\n(\n1\n(k − 1)!\n1\n(N − k)!\n)λ/ log(2) )\n≤ e−3λN+λ\n\n\n1\nNλ/ log(2)\n(\nN ∑\nk=1\n1\n(k − 1)!\n1\n(N − k)!\n)λ/ log(2) \n\n(by Jensen’s inequality, since 0 < λ/ log(2) ≤ 1)\n= e−3λN+λ ( (2N−1)λ/ log(2)\n(N !)λ/ log(2)\n)\n= e−2λN\n(N !)λ/ log(2) .\nThus (3) has been proved for all n ≥ 0.\nFor the lower bound on qn, we use the probabilistic form of Jensen’s inequality,\nqn = E [exp(−λcQ(Πn))] ≥ exp(−λE [cQ(Πn)]) ,\nnoting that average-case analysis of quicksort [15] yields\nE [cQ(Πn)] = 2(n+ 1)(Hn+1 − 1), n ≥ 0 ,\nwhere (Hn) is the harmonic sequence. For n ≥ 0, the bound\nHn+1 < log(n+ 1) + γ + 1\n2(n+ 1)\nholds [11] (sharper bounds exist), so we have\nqn > exp\n(\n−2λ(n+ 1)\n(\nlog(n+ 1) + γ + 1\n2(n+ 1) − 1\n))\n= e−2(γ−1)λ(n+1)−λ(n+ 1)−2λ(n+1) .\nWe finish by applying Stirling’s inequality\n(n+ 1)−(n+1) ≥ √ 2π(n+ 1) e−(n+1)/(n+ 1)!, n ≥ 0 . ⊓⊔\nFrom these results we may get a sense of the tasks involved in expectedreward analysis for typical algorithms.We note that with an exponential discount function, the independence of subproblems in quicksort is required for obtaining a recursive formula, whereas in traditional average-case analysis, linearity of expectation suffices.\nWe end this section by mentioning an open question relevant to a theory of expected-reward analysis.\nQuestion 1. If we fix a computational problem and parameters P, λ, what is supA S(A), and is it attained?\nIf supA S(A) is not attained then the situation is similar to that in Blum’s speedup theorem. Comparing supA S(A) among problems would be the expectedreward analog of computational complexity theory but because of the sensitivity of S to parameters and the model of computation, this is not useful."
    }, {
      "heading" : "3 Self-Improving AI",
      "text" : "The generality of 0′ problems allows us to view design and analysis of 0′ algorithms as a task which itself may be given to a 0′ algorithm, bringing about recursive self-improvement. Here we present one possible concrete example of this notion and discuss connections with AI.\nComputational problems with Turing degree 0′ are Turing-equivalent so without loss of generality in this section we assume 0′ algorithms are automated theorem provers. Specifically, we fix a formal logic system, say ZFC (assuming it is consistent), and take the set of inputs to be ZFC sentences, and the possible outputs to be provable and not provable.\nLet a predicate β be such that β(Z) holds iff Z is a 0′ algorithm which is correct on provable inputs and does not terminate otherwise. In pseudocode we write the instruction to run some Z on input ω as Z(ω), and if ω contains β or S (the score function), their definitions are implicitly included.\nWe give an auxiliary procedure Search which takes as input a 0′ algorithm Z and a rational number x and uses Z to obtain a 0′ algorithm which satisfies β and has score greater than x (if possible). Symbols in bold within a string literal get replaced by the value of the corresponding variable. We assume 0′ algorithms are encoded as strings in a binary prefix code.\n1: procedure Search(x, Z) 2: u ← the empty string 3: loop 4: do in parallel until one returns provable: 5: A: Z(“∃v : (Z∗ = u0v =⇒ β(Z∗) ∧ S(Z∗) > x)”) 6: B: Z(“∃v : (Z∗ = u1v =⇒ β(Z∗) ∧ S(Z∗) > x)”) 7: C: Z(“Z∗ = u =⇒ β(Z∗) ∧ S(Z∗) > x”)\n8: if A returned provable then 9: u ← u0 10: if B returned provable then 11: u ← u1 12: if C returned provable then 13: return u\nWe remark that the mechanism of Search is purely syntactic and does not rely on consistency or completeness of ZFC, or the provability thereof. This would not be the case if we strengthened β to require that β(Z) is true only if at most one of Z(ω) and Z(¬ω) returns provable. Such a β would never provably hold in ZFC.\nThe following procedure Improve takes an initial 0′ algorithm Z0 and uses dovetailed calls to Search to output a sequence of 0′ algorithms that tend toward optimality.\n1: procedure Improve(Z0) 2: best ← Z0, pool ← {}, score ← 0 3: for n ← 1 to ∞ do 4: an ← nth term in Stern-Brocot enumeration of Q ∩ (0, 1] 5: if an > score then 6: initialState← initial state of Search(an, best) 7: add (an, best, initialState) to pool\n8: improvementFound ← false 9: for (a, Z, state) in pool do\n10: run Search(a, Z) one step starting in state state 11: newState ← new current state of Search(a, Z) 12: if state is not a terminating state then 13: in pool, mutate (a, Z, state) into (a, Z, newState) 14: continue 15: improvementFound ← true 16: best ← output of Search(a, Z) 17: score ← a 18: for (â, Ẑ, ˆstate) in pool where â ≤ score do 19: remove (â, Ẑ, ˆstate) from pool\n20: print best\n21: if improvementFound then 22: for (a, Z, state) in pool do 23: initialState← initial state of Search(a, best) 24: add (a, best, initialState) to pool\nThe procedure Improve has the following basic property.\nProposition 3. Let (Zn) be the sequence of 0 ′ algorithms printed by Improve. If β(Z0) holds, and if there is any 0 ′ algorithm Y and s ∈ Q where β(Y ) and S(Y ) > s > 0 are provable, we have\nlim n→∞ S(Zn) ≥ s .\nIf (Zn) is finite, the above limit can be replaced with the last term in (Zn).\nProof. The value s appears as some value an. For an = s, if an > score in line 5, then Search(s, best) will be run one step for each greater or equal value of n and either terminates (since Y exists) and score is set to s, or is interrupted if we eventually have score ≥ s before Search(s, best) terminates. It suffices to note that when score attains any value x > 0, all further outputs Z satisfy S(Z) > x and there is at least one such output. ⊓⊔\nThe procedure Improve also makes an attempt to use recently printed 0′ algorithms in calls to Search. However, it is not true in general that S(Zn+1) ≥ S(Zn). Checking if a particular output Zn is actually an improvement over Z0 or Zn−1 requires extra work.\nIn artificial general intelligence (AGI) it is desirable to have intelligent systems with the ability to make autonomous improvements to themselves [14]. If an AGI system such as an AIXI approximation [10] already uses a 0′ algorithm Z to compute the universal distribution m, we can give the system the ability to improve Z over time by devoting some of its computational resources to running Improve. This yields a general agent whose environment prediction ability tends toward optimality."
    }, {
      "heading" : "4 Future Work",
      "text" : "We would like to be able to practically use expected-reward analysis with various parameter values, probability measures, and discount functions, on both terminating and non-terminating algorithms. Particularly, we would like to know whether 0′ algorithms may be practically analyzed. It may be possible to develop general mathematical tools and techniques to enhance the practicality of these methods, such as exist for traditional analysis; this is a broad and open-ended research goal.\nAcknowledgements. The author wishes to thank Zhicheng Gao, Nima Hoda, Patrick LaVictoire, Saran Neti, and anonymous referees for helpful comments."
    } ],
    "references" : [ {
      "title" : "Why philosophers should care about computational complexity",
      "author" : [ "S. Aaronson" ],
      "venue" : "Computability: Gödel, Turing, Church, and Beyond",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Looper: Lightweight detection of infinite loops at runtime",
      "author" : [ "J. Burnim", "N. Jalbert", "C. Stergiou", "K. Sen" ],
      "venue" : "In International Conference on Automated Software Engineering",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Re: Proof theory on the eve of year",
      "author" : [ "S. Buss" ],
      "venue" : "http://www.ihes.fr/~carbone/papers/proofsurveyFeferman2000.html",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2000
    }, {
      "title" : "Introduction to Algorithms",
      "author" : [ "T.H. Cormen", "C.E. Leiserson", "R.L. Rivest", "C. Stein" ],
      "venue" : "MIT Press, Cambridge, MA, third edn.",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Handbook of Theoretical Computer Science, Vol",
      "author" : [ "P. van Emde Boas" ],
      "venue" : "A. pp. 1–66. MIT Press, Cambridge, MA, USA",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "Analytic combinatorics",
      "author" : [ "P. Flajolet", "R. Sedgewick" ],
      "venue" : "Cambridge University Press, Cambridge",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Time discounting and time preference: A critical review",
      "author" : [ "S. Frederick", "G. Loewenstein", "T. O’Donoghue" ],
      "venue" : "Journal of Economic Literature pp. 351–401",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Toward a formal characterization of real-world general intelligence",
      "author" : [ "B. Goertzel" ],
      "venue" : "Proceedings of the 3rd Conference on Artificial General Intelligence, AGI. pp. 19–24",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Feasible functions",
      "author" : [ "Y. Gurevich" ],
      "venue" : "London Mathematical Society Newsletter 206, 6–7",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Universal Artificial Intelligence: Sequential Decisions based on Algorithmic Probability",
      "author" : [ "M. Hutter" ],
      "venue" : "Springer, Berlin",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Gamma: Exploring Euler’s Constant",
      "author" : [ "H. Julian" ],
      "venue" : "Princeton University Press",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "The Art of Computer Programming, Vol",
      "author" : [ "D.E. Knuth" ],
      "venue" : "1. Addison-Wesley, Reading, MA",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "An Introduction to Kolmogorov Complexity and its Applications",
      "author" : [ "M. Li", "P. Vitányi" ],
      "venue" : "Springer Science & Business Media",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Gödel machines: Fully self-referential optimal universal selfimprovers",
      "author" : [ "J. Schmidhuber" ],
      "venue" : "Artificial General Intelligence, pp. 199–226. Springer",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "An Introduction to the Analysis of Algorithms",
      "author" : [ "R. Sedgewick", "P. Flajolet" ],
      "venue" : "AddisonWesley",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "Smoothed analysis: an attempt to explain the behavior of algorithms in practice",
      "author" : [ "D.A. Spielman", "S.H. Teng" ],
      "venue" : "Communications of the ACM 52(10), 76–84",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "The Mathematica Guidebook for Symbolics",
      "author" : [ "M. Trott" ],
      "venue" : "Springer Science & Business Media",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "Given two algorithms A, B that solve the same problem, we find which is more efficient by asymptotically comparing the running time sequences (an), (bn) [4,15].",
      "startOffset" : 153,
      "endOffset" : 159
    }, {
      "referenceID" : 14,
      "context" : "Given two algorithms A, B that solve the same problem, we find which is more efficient by asymptotically comparing the running time sequences (an), (bn) [4,15].",
      "startOffset" : 153,
      "endOffset" : 159
    }, {
      "referenceID" : 15,
      "context" : "This could be using worst-case or average-case running times or even smoothed analysis [16].",
      "startOffset" : 87,
      "endOffset" : 91
    }, {
      "referenceID" : 0,
      "context" : "Authors have noted [1,9] that comparing sequence tails avoids the arbitrariness of any particular range of input lengths but leads us to say an = n 100 is superior to bn = ( 1 + exp(−10) n which is false for practical purposes.",
      "startOffset" : 19,
      "endOffset" : 24
    }, {
      "referenceID" : 8,
      "context" : "Authors have noted [1,9] that comparing sequence tails avoids the arbitrariness of any particular range of input lengths but leads us to say an = n 100 is superior to bn = ( 1 + exp(−10) n which is false for practical purposes.",
      "startOffset" : 19,
      "endOffset" : 24
    }, {
      "referenceID" : 1,
      "context" : "Such problems include string compression (Kolmogorov complexity), the halting problem in program analysis [2], algebraic simplification [17], program optimization, automated theorem proving, and Solomonoff induction (central to artificial general intelligence [13]).",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 16,
      "context" : "Such problems include string compression (Kolmogorov complexity), the halting problem in program analysis [2], algebraic simplification [17], program optimization, automated theorem proving, and Solomonoff induction (central to artificial general intelligence [13]).",
      "startOffset" : 136,
      "endOffset" : 140
    }, {
      "referenceID" : 12,
      "context" : "Such problems include string compression (Kolmogorov complexity), the halting problem in program analysis [2], algebraic simplification [17], program optimization, automated theorem proving, and Solomonoff induction (central to artificial general intelligence [13]).",
      "startOffset" : 260,
      "endOffset" : 264
    }, {
      "referenceID" : 2,
      "context" : "theorem proving, Buss, describing the main open problems in proof theory [3], states, “Computerized proof search .",
      "startOffset" : 73,
      "endOffset" : 76
    }, {
      "referenceID" : 6,
      "context" : "where P is a probability measure on Ω, D is a discount function [7], and r(ω) is a reward (a.",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 12,
      "context" : "The measure P is also determined by a probability mass function on Z0+ if we weight equal-length inputs according to Solomonoff’s universal distribution m [13], which is a particularly good general model, although computationally difficult.",
      "startOffset" : 155,
      "endOffset" : 159
    }, {
      "referenceID" : 4,
      "context" : "Computational complexity theory often works with classes of problems whose definitions are equivalent for all “reasonable” models of computation [5].",
      "startOffset" : 145,
      "endOffset" : 148
    }, {
      "referenceID" : 5,
      "context" : "This is simply the price of concreteness, and outside of complexity theory, traditional analysis of algorithms generally selects a particular model of computation and gives precise results that do not necessarily apply to other models [6].",
      "startOffset" : 235,
      "endOffset" : 238
    }, {
      "referenceID" : 7,
      "context" : "The expected-reward paradigm already appears in the analysis of artificial agents, rather than algorithms [8].",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 14,
      "context" : "We denote the algorithms mergesort and quicksort by M and Q, as defined in [15], and set",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 14,
      "context" : "From [15], M makes the same number of comparisons for all inputs of length n ≥ 1: cM (Πn) = n⌈lg(n)⌉+ n− 2 ⌈lg(n)⌉ , so (1) is immediate.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 14,
      "context" : "Sedgewick and Flajolet [15] give an alternative expression for the running time of mergesort:",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 14,
      "context" : "For the lower bound on qn, we use the probabilistic form of Jensen’s inequality, qn = E [exp(−λcQ(Πn))] ≥ exp(−λE [cQ(Πn)]) , noting that average-case analysis of quicksort [15] yields",
      "startOffset" : 173,
      "endOffset" : 177
    }, {
      "referenceID" : 10,
      "context" : "holds [11] (sharper bounds exist), so we have",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 13,
      "context" : "In artificial general intelligence (AGI) it is desirable to have intelligent systems with the ability to make autonomous improvements to themselves [14].",
      "startOffset" : 148,
      "endOffset" : 152
    }, {
      "referenceID" : 9,
      "context" : "If an AGI system such as an AIXI approximation [10] already uses a 0 algorithm Z to compute the universal distribution m, we can give the system the ability to improve Z over time by devoting some of its computational resources to running Improve.",
      "startOffset" : 47,
      "endOffset" : 51
    } ],
    "year" : 2017,
    "abstractText" : "We present an alternative methodology for the analysis of algorithms, based on the concept of expected discounted reward. This methodology naturally handles algorithms that do not always terminate, so it can (theoretically) be used with partial algorithms for undecidable problems, such as those found in artificial general intelligence (AGI) and automated theorem proving. We mention an approach to self-improving AGI enabled by this methodology.",
    "creator" : "LaTeX with hyperref package"
  }
}