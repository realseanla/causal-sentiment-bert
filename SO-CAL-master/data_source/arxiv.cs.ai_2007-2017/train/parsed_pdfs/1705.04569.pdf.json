{
  "name" : "1705.04569.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Mutsunori Banbara", "Torsten Schaub", "Benjamin Kaufmann", "Max Ostrowski" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 5.\n04 56\n9v 1\n[ cs\n.A I]\n1 2\ngramming (ASP) with finite domain constraint processing (CP). While its predecessors rely on a black-box approach to hybrid solving by integrating the CP solver gecode, the new clingcon system pursues a lazy approach using dedicated constraint propagators to extend propagation in the underlying ASP solver clasp. No extension is needed for parsing and grounding clingcon’s hybrid modeling language since both can be accommodated by the new generic theory handling capabilities of the ASP grounder gringo. As a whole, clingcon 3 is thus an extension of the ASP system clingo 5, which itself relies on the grounder gringo and the solver clasp. The new approach of clingcon offers a seamless integration of CP propagation into ASP solving that benefits from the whole spectrum of clasp’s reasoning modes, including for instance multi-shot solving and advanced optimization techniques. This is accomplished by a lazy approach that unfolds the representation of constraints and adds it to that of the logic program only when needed. Although the unfolding is usually dictated by the constraint propagators during solving, it can already be partially (or even totally) done during preprocessing. Moreover, clingcon’s constraint preprocessing and propagation incorporate several well established CP techniques that greatly improve its performance. We demonstrate this via an extensive empirical evaluation contrasting, first, the various techniques in the context of CSP solving and, second, the new clingcon system with other hybrid ASP systems."
    }, {
      "heading" : "1 Introduction",
      "text" : "The shortcoming of Answer Set Programming (ASP; (Lifschitz 2008)) to succinctly represent variables over large numeric domains has led to the development of several systems enhancing ASP with capabilities for finite domain Constraint Processing (CP; (Rossi et al. 2006)). Starting from the seminal work in (Baselice et al. 2005) and the consecutive development of traditional DPLL1-style hybrid ASP solvers like adsolver (Mellarkod et al. 2008), modern hybrid ASP solvers take advantage of CDCL2-based solving technology (Marques-Silva and Sakallah 1999; Zhang et al. 2001; Gebser et al. 2007) in different ways. Let us illustrate this by describing the approach of three representative Constraint Answer Set Programming (CASP; (Balduccini and Lierler 2013)) systems.\n∗ Affiliated with the Simon Fraser University, Canada, and Griffith University, Australia. 1 Tracing back to the Davis-Putman-Logemann-Loveland procedure (Davis and Putnam 1960; Davis et al. 1962) 2 Standing for: Conflict-Driven Constraint Learning\nA black-box approach is pursued in the two previous clingcon series where the ASP solver clasp is combined with the CP solver gecode (Gecode Team 2006) by following the lazy approach to SMT3solving (Barrett et al. 2009). In the clingcon setting, this means that clasp only generates truth assignments for abstracted constraint expressions, while gecode checks whether the actual constraints can be made true or false accordingly. On the one hand, this black-box approach benefits from the vast spectrum of constraints available in gecode and seamlessly keeps up with advanced CP technology, among others regarding preprocessing and propagation.Moreover, this approach avoids an explicit representation of integer variables in ASP and thus can deal with very large domains. On the other hand, the usage of an external CP solver restricts information exchange which impedes the CDCL approach of clasp. First, neither conflict nor propagation information is provided by gecode and thus must be approximated within the interface to sustain conflict analysis in CDCL. Second, the granularity induced by constraint abstraction leads to weaker propagation than what is obtainable when encoding integer variables.\nA translation-based approach is pursued by the aspartame system (Banbara et al. 2015) where a CSP4 is fully translated into ASP and then solved by an ASP solver. This approach follows the one of the CP solver sugar (Tamura et al. 2009) translating CSPs to SAT5 (Biere et al. 2009). This is done by representing each integer variable along with its domain according to the order encoding scheme (Crawford and Baker 1994). Such an approach is called eager in SMT solving. On the one hand, this approach benefits from the full power of CDCL-based search. Also, the granularity induced by an explicit representation of integer variables provides more accurate conflict and propagation information, and approximations for reasons and conflicts as used in the former clingcon system (Ostrowski and Schaub 2012) are made obsolete. On the other hand, such an explicit representation limits scalability: aspartame (just as sugar) can only deal with medium sized domains up to a few thousand integers. Also, when dealing with larger domains, CDCL search may suffer from congestion due to too much conflict information. Finally, aspartame cannot make use of readily available CP techniques for preprocessing and propagation; all this must be captured in the underlying ASP encoding.\nA lazy approach is pursued by the inca system (Drescher and Walsh 2012) where the ASP solver clasp is augmented with dedicated propagators for linear and selected global constraints by following the approach of lazy clause generation (Ohrimenko et al. 2009). The idea is to make parts of the encoding explicit whenever they reflect a conflict or propagation signaled by a propagator. In this way, the explicit representation of constraints is only unfolded when needed and its extent is controlled by the deletion scheme of the ASP solver. This approach also benefits from the full power of CDCL-based search but outsources constraint oriented inferences. In this way, the overall size of the hybrid problem is under control of the ASP solver. As a consequence, inca can deal with large domains. But it has its limits because the vocabulary and basic inference schemes of the order encoding must be provided at the outset by introducing auxiliary variables and nogoods. The propagators rely on this for making parts of the constraint encoding explicit. Moreover, this lazy approach cannot harness implemented CP techniques for preprocessing and propagation; inca provides advancedmeans for propagation but uses no sophisticated preprocessing techniques.\nThe third generation of clingcon also follows a lazy approach to hybridASP solving but largely\n3 Standing for: Satisfiability Modulo Theories 4 Standing for: Constraint Satisfaction Problem 5 Standing for: Satisfiability Testing\nextends the lazy one of inca while drawing on experience with aspartame and the previous clingcon series. The current version of clingcon 3 features propagators for linear constraints and can translate distinct constraints. The ultimate design goal was to conceive a hybrid solver architecture that integrates seamlessly with the infrastructure of the ASP system clingo in order to take advantage of its full spectrum of grounding and solving capabilities. For the latter, it is essential to give the solver access to the representation of constraint variables and their domains, otherwise hybrid forms of multi-objective optimization or operations on models like intersection or union cannot reuse existing capacities. The lazy approach lets us accomplish this while controlling space demands. However, we take the approach of inca one step further by permitting lazy variable generation (Thibaut and Stuckey 2009) to unfold the vocabulary and the basic inference schemes of the order encoding only when needed. This enables clingcon 3 to represent very large (and possibly non-contiguous) domains of integer variables. Furthermore, clingcon 3 features a variety of established CP preprocessing techniques to enhance its lazy approach. This also includes an initial eager translation that allows for unfolding up front parts or even the entire CSP.\nWhat is more, clingcon is not restricted to single-shot solving but fully blends in with clingo’s multi-shot solving capabilities (Gebser et al. 2015). This does not only allow for incremental hybrid solving but moreover equips clingcon with powerful APIs. For instance, the latter allow for conceiving reactive procedures to loop on solving while acquiring changes in the problem specification. In fact, due to our design, most of clingo’s elaborate features carry over to clingcon. Among others, this includes multi-threaded solving as well as unsatisfiable core and modeldriven multi-criteria optimization. Exceptions to this are signature-based forms of reasoning, like projective enumeration or heuristic modifications that must be dealt with indirectly by associating constraint atoms with auxiliary regular atoms with which such operations can be performed.\nOur paper is structured as follows. The next section provides the formal foundations of Constraint Answer Set Programming (CASP) and presents the basics of CDCL-based ASP solving along with their extension to CASP solving. Section 3 details relevant features of clingcon 3. We start with an architectural overview in Section 3.1 and introduce the input language of clingcon 3 in Section 3.2. We then explain clingcon’s extended solving algorithms in Section 3.3 and detail distinguished features in Section 3.4. The final subsection of Section 3 is dedicated to multi-shot CASP solving. Section 4 provides a detailed empirical analysis of clingcon’s features and performance in contrast to competing CP and CASP systems. We summarize the salient features of the new clingcon series in Section 5 and discuss related work."
    }, {
      "heading" : "2 Formal Preliminaries",
      "text" : "We begin in Section 2.1 with a gentle introduction to CASP along with some auxiliary concepts. We then provide the basics of CDCL-based ASP solving and show how they extend to CASP solving in Section 2.2."
    }, {
      "heading" : "2.1 Constraint Answer Set Programming",
      "text" : "Constraint logic programs consist of a logic program P over disjoint sets A, C of propositional variables, and an associated constraint satisfaction problem (CSP) (V , D,C). Elements ofA and C are referred to as regular and constraint atoms, respectively. We consider linear CSPs, where V\nis a set of integer variables,D is a set of corresponding variable domains, and C is a set of linear constraints.\nLogic programs. A logic program P consists of rules of the form6\na0 ← a1, . . . , am,∼am+1, . . . ,∼an (1)\nwhere 0 ≤ m ≤ n and a0 ∈ A and each ai ∈ A ∪ C is an atom for 1 ≤ i ≤ n.\nAs an example, consider the logic program P1:\na← ∼b (2)\nb← ∼a (3)\nc← a, x < 7 (4)\nThis program contains regular atoms a, b, and c from A along with the constraint atom x < 7 from C. Accordingly, x is an integer variable in V .\nWe need the following auxiliary definitions. We define head(r) = a0 as the head of rule r in (1), body(r) = {a1, . . . , am,∼am+1, . . . ,∼an} as its body, and atom(r) = {a0, a1, . . . , am, am+1, . . . , an}. Moreover, we let head(P ) = {head(r) | r ∈ P}, body(P ) = {body(r) | r ∈ P}, bodyP (a) = {body(r) | r ∈ P, head (r) = a}, and atom(P ) = {atom(r) | r ∈ P}. If body(r) = ∅, r is called a fact. If head(r) is missing, r is called an integrity constraint and r stands for x← body(r),∼x where x is a new atom.7\nIn ASP, the semantics of a logic program is given by its (constraint) stable models (Gelfond and Lifschitz 1988; Gebser et al. 2009). However, in view of our focus on computational aspects, we rather deal with Boolean assignments and constraints and give a corresponding characterization of a program’s stable models below.\nConstraint Satisfaction Problems. A linear CSP (V , D,C) deals with linear constraints in C of the form\na1v1 + · · ·+ anvn ≤ b (5)\nwhere ai and b are integers and vi ∈ V for 1 ≤ i ≤ n. The domain of a variable v ∈ V is given by D(v). The complement of a constraint c ∈ C is denoted as c. We require that C is closed under complements. Constraint atoms in C are identified with constraints in C via a function γ : C → C.\nIn our example, we have x ∈ V and let D(x) = {1, . . . , 10}. Moreover, we associate the constraint atom x < 7 with the linear constraint x ≤ 6, or formally, γ(x < 7) = x ≤ 6. Since we require C to be closed under complements, it contains both x ≤ 6 and its complement −x ≤ −7.\nAn assignmentC : v ∈ V 7→ d ∈ D(v) satisfies a linear constraint, if (5) holds after replacing each vi by C(vi). We let satC(C) denote the set of all constraints in C satisfied by C. Following (Drescher 2015), we call (C, satC(C)) a configuration of (V , D,C). For instance, the assignmentC = {x 7→ 5} satisfies the linear constraint x ≤ 6. Accordingly, ({x 7→ 5}, {x ≤ 6}) is a configuration of ({x}, {D(x)}, {x ≤ 6,−x ≤ −7}}).\n6 We present our approach in the context of normal logic programs, though it readily applies to disjunctive logic programs — as does clingcon 3. 7 As syntactic sugar, a rule c ← a1, . . . , am,∼am+1, . . . ,∼an with a constraint atom c ∈ C in the head stands for ← a1, . . . , am,∼am+1, . . . ,∼an,∼c.\nMoreover, we rely on the CP concept of a view. Following (Schulte and Tack 2005), a view on a variable x is an expression ax + b for integers a, b; its image is defined as img(ax + b) = {ax+ b | x ∈ D(x)}.8 Since a view ax+ b can always be replaced with a fresh variable y along with a constraint y = ax + b, we may use them nearly everywhere where we would otherwise use variables. For a view v, we define lb(v) and ub(v) as the smallest/largest value in img(v).9 Then, prev(d, v) (next(d, v)) is a function mapping a value d to the largest (smallest) element d′ in img(v) which is smaller (larger) than d if d > lb(v) (d < ub(v)), otherwise it is −∞ (∞). In our example, we have lb(x) = 1 and ub(x) = 10, and for instance prev (17, 2x + 3) = 15, prev(5, x) = 4, and prev(0, x) = −∞, respectively."
    }, {
      "heading" : "2.2 Basics of ASP and CASP Solving",
      "text" : "The basic idea of CDCL-based ASP solving is to map inferences from rules as in (1) to unit propagation on Boolean constraints. Our description of this approach follows the one given in (Gebser et al. 2012).\nAccordingly, we represent Boolean assignments, B, over a set of atoms A ∪ C by sets of signed literals Ta or Fa standing for a 7→ T and a 7→ F, respectively, where a ∈ A ∪ C. The complement of a signed literal σ is denoted by σ. We define BT = {a ∈ A ∪ C | Ta ∈ B} and BF = {a ∈ A ∪ C | Fa ∈ B}. Then, an assignment B is complete, if BT ∩ BF = ∅ and B T ∪ BF = A ∪ C. For instance, the assignment {Ta,Fb,Fc,F(x < 7)} is complete wrt the atoms in our example.\nBoolean constraints are represented as nogoods. A nogood is a set of signed literals representing an invalid partial assignment. A nogood δ is violated by a Boolean assignment B whenever δ ⊆ B. A complete Boolean assignment is a solution of a set of nogoods, if it violates none of them. Given a Boolean assignment B and a nogood δ such that δ \\ B = {σ} and σ /∈ B, we say that δ is unit wrt B and asserts the unit-resulting literal σ. For a set ∆ of nogoods and an assignmentB, unit propagation is the iterated process of extendingB with unit-resulting literals until no further literal is unit-resulting for any nogood in∆.\nWith these concepts in hand, the Boolean constraints induced by a logic program P can be\ncaptured as follows:\n∆P = ⋃\nB∈body(P ), B={a1,...,am,∼am+1,...,∼an}\n \n\n{FB,Ta1, . . . ,Tam,Fam+1, . . . ,Fan}, {TB,Fa1}, . . . , {TB,Fam}, {TB,Tam+1}, . . . , {TB,Tan}\n \n\n∪ ⋃\na∈atom(P ), body\nP (a)={B1,...,Bk}\n{\n{Ta,FB1, . . . ,FBk}, {Fa,TB1}, . . . , {Fa,TBk}\n}\n(6)\nΛP = ⋃\nU⊆atom(P ), EBP (U)={B1,...,Bk}\n{{Ta,FB1, . . . ,FBk} | a ∈ U} (7)\nwhere EBP (U) = {body(r) ∈ P | head(r) ∈ U, body(r) ∩ U = ∅}.\nThen, according to (Gebser et al. 2012), a set of atoms X is a stable model of a regular logic program P iffX = BT ∩ atom(P ) for a (unique) solutionB of∆P ∪ ΛP .\nFor example, the nogoods obtained in (6) for the atom a in our example are {Ta,F{∼b}} and {Fa,T{∼b}}. Similarly, the body {∼b} of Rule (2) gives rise to nogoods {F{∼b},Fb} and\n8 Any linear expression with only one variable can be converted to an expression of the form ax+ b. 9 Note that for a view of the form 1x+ 0 we have D(x) = img(x).\n{T{∼b},Tb}. Hence, once an assignment containsTa, we may derive Fb via unit propagation (using both the first and last nogood).\nTo extend this characterization to programswith constraint atoms, it is important to realize that the truth value of such atoms is determined external to the program. In CASP, this is reflected by the requirement that constraint atoms must not occur in the head of rules.10 Hence, treating constraint atoms as regular ones leaves them unfounded. For instance, in our example, we would get from both (6) and (7) the nogood {T(x < 7)}, which would set (x < 7) permanently to false. To address this issue, (Drescher and Walsh 2012) exempt constraint atoms from the respective sets of nogoods and define the variants∆CP and Λ C P by replacing atom(P ) in the qualification of (6) and (7) with atom(P ) \\ C.\nThen, in (Ostrowski 2017) it is shown that (X,C) is a constraint stable model of a program P wrt (V , D,C) as defined in (Gebser et al. 2009) iff and X = BT ∩ atom(P ) for a (unique) solutionB of∆CP ∪ Λ C P ∪ {{Fc} | γ(c) ∈ satC(C)} ∪ {{Tc} | γ(c) ∈ satC(C)}.\nAccordingly, our example yields the following constraint stable models\nX C {a} x ∈ {7, . . . , 10} {b} x ∈ {7, . . . , 10} {b, x < 7} x ∈ {1, . . . , 6} {a, c, x < 7} x ∈ {1, . . . , 6}\n(8)\nwhere x ∈ {m, . . . , n} means that either x 7→ m, or x 7→ m+ 1, . . . or x 7→ n. For instance, the very first constraint stable model corresponds to the Boolean assignment {Ta,Fb,Fc,F(x < 7)} paired with the constraint variable assignment {x 7→ 7}.\nSimilar to logic programs, linear constraints can be represented as sets of nogoods by means of an order encoding (Tamura et al. 2009). This amounts to representing the above unit nogoods {{Fc} | γ(c) ∈ satC(C)} ∪ {{Tc} | γ(c) ∈ satC(C)} by more elaborate nogoods capturing the semantics provided by satC(C).\nTo this end, we let OV stand for the set of order atoms associated with variables in V and require it to be disjoint fromA∪ C. Whenever the set V is clear from the context, we drop it and simply write O. More precisely, we introduce an order atom (v ≤ d) ∈ O for each constraint variable v ∈ V and value d ∈ D(v), d 6= ub(v). We refer to signed literals over O as signed order literals.\nNow, we are ready to map a linear CSP (V , D,C) into a set of nogoods. First, we need to make sure that each variable in V has exactly one value from its domain in\nD. To this end, we define the following set of nogoods.\nΦ(V , D) = {{T(v ≤ d),F(v ≤ next(d, v))} | v ∈ V , d ∈ D(v),\nnext(d, v) < ub(v)} (9)\nIntuitively, each such nogood stands for an implication “(v ≤ d) ⇒ (v ≤ d+ 1)”. In our example, we get the following nogoods.\nΦ({x}, {D(x)}) = {{T(x ≤ 1),F(x ≤ 2)}, . . . , {T(x ≤ 8),F(x ≤ 9)}}. (10)\nSecond, we need to establish the relation between constraint atoms C and their associated linear constraints in C. Following (Feydy et al. 2011), a reified constraint is an equivalence “Tc ⇔\n10 In alternative semantic settings, theory atoms may also occur as rule heads (cf. (Gebser et al. 2016a)).\nγ(c)” where c ∈ C; it is decomposable into two half-reified constraints “Tc⇒ γ(c)” and “Fc⇒ γ(c)”. To proceed analogously, we extend γ to signed literals over C as follows:\nγ(σ) =\n{\nγ(a) if σ = Fa, a ∈ C γ(a) if σ = Ta, a ∈ C\nFor instance, we have γ(F(x < 7)) = (−x ≤ −7).\nTo translate constraints into nogoods, we need to translate expressions of the form av+ b ≤ 0 for v ∈ V and integers a, b into signed ordered literals.11 Following (Tamura et al. 2009), we then define (av + b ≤ 0)‡ as\n(av + b ≤ 0)‡ =\n \n\n(v ≤ ⌊−b a ⌋)† if a > 0\n(v ≤ ⌈−b a ⌉ − 1)† if a < 0\nwhere (v ≤ d)† is defined for lb(v) ≤ d < ub(v) as\n(v ≤ d)† =\n{\nT(v ≤ d) if d ∈ D(v) T(v ≤ prev (d, v)) if d /∈ D(v)\nIf d ≥ ub(v) then (v ≤ d)† = T∅; if d < lb(v) then (v ≤ d)† = F∅, where ∅ stands for the empty body.12 Expressing our example constraint x ≤ 6 in terms of signed order literals results in (1 · x+ (−6) ≤ 0)‡ = T(x ≤ 6). The signed literal T(x ≤ 6) indicates that 6 is the largest integer satisfying the constraint. Also, we get the signed literals (x ≤ 0)† = F∅ and (x ≤ 10)† = T∅.\nWe sometimes use <,>, or ≥ as operators in these expressions and implicitly convert them to the normal form av + b ≤ 0 to be used in this translation. Accordingly, the complementary constraint yields (x > 6)‡ = ((−1) · x+ 7 ≤ 0)‡ = (x ≤ ⌈−7−1⌉ − 1) † = F(x ≤ 6).\nThe actual relation between the constraint atoms in C and their associated linear constraints in\nC is established via the following nogoods.\nΨ(C) = ⋃\nc∈C ψ(Tc, γ(c)) ∪ ψ(Fc, γ(c)) . (11)\nFor all constraint atoms c ∈ C associated with the linear constraint γ(c) = ∑n\ni=1 aivi ≤ b in C,\nwe define for both of its half-reified constraints the set of nogoods\nψ(Tc, ∑n i=1 aivi ≤ b) = {{Tc} ∪ δ \\ {T∅} | δ ∈ φ( ∑n i=1 aivi ≤ b),F∅ /∈ δ} (12) ψ(Fc, ∑n\ni=1 aivi ≤ b) = {{Fc} ∪ δ \\ {T∅} | δ ∈ φ( ∑n i=1 aivi ≤ b),F∅ /∈ δ} (13)\nwhere\nφ( ∑n\ni=1 aivi ≤ b) =\n \n\n{(a1v1 > b)‡} if n = 1 {(a1v1 ≥ d)‡} ∪ δ if n > 1\nδ ∈ φ( ∑n\ni=2 aivi ≤ b− d), d ∈ img(a1v1)\n \n\nNote that nogoods with T∅ and F∅ are simplified in (12) and (13). Also, observe that the definition of φ is recursive although this does not show with our simple examples.\n11 Any linear inequality using <,>,≤,≥ and one variable can be converted into this form. 12 We use T∅ and F∅ as representatives for tautological and unsatisfiable signed literals; they are removed in (12) and\n(13) below.\nIn our example, we obtain\nψ(T(x < 7), x ≤ 6) = {{T(x < 7),F(x ≤ 6)}} (14)\nψ(F(x < 7),−x ≤ −7) = {{F(x < 7),T(x ≤ 6)}} (15)\nTaken together, both nogoods realize the aforementioned equivalence between the constraint atom (x < 7) and its associated constraint. Note that (x < 7) is a constraint atom in C, while (x ≤ 6) is an order atom in O and thus belongs to the encoding of the constraint associated with (x < 7). For further illustration, reconsider the Boolean assignment {Ta,Fb,Fc,F(x < 7)} inducing the first constraint stable models in (8). Applying unit propagation, we get F(x ≤ 6) via (15) and in turnF(x ≤ 5) toF(x ≤ 1) via the nogoods in Φ({x}, {D(x)}) in (10). Similarly, makingT(x ≤ 7) true yieldsT(x ≤ 8) and T(x ≤ 9) also via the nogoods in (10).\nAll in all, a CSP (V , D,C) is characterized by the nogoods in Φ(V , D) and Ψ(C). While in (8) the corresponding constraint variable assignment C is determined externally, it can be directly extracted from a solution B for Φ(V , D) by means of the following functions: The upper bound for a view v relative to a Boolean assignment B is given by ubB(v) = min({ub(v)} ∪ {d | d ∈ img(v), (v ≤ d)‡ ∈ B}) and its lower bound by lbB(v) = max({lb(v)} ∪ {d | d ∈ img(v), (v ≥ d)‡ ∈ B}). Then, C(v) = lbB(v) = ubB(v) for all v ∈ V . Accordingly, the above Boolean assignment corresponds toC = {x 7→ 7}.\nCombining the nogoods stemming from the logic program and its associated CSP, we obtain\nthe following characterization of constraint logic programs.\nTheorem 2.1 Let P be a constraint logic program over A ∪ C associated with the CSP (V , D,C) and let X ⊆ A∪ C andC a total assignment over V .\nThen, (X,C) is a constraint stable model of P wrt (V , D,C) as defined in (Gebser et al. 2009) iff (C, satC(C)) is a configuration for (V , D,C), X = BT ∩ atom(P ) for a (unique) solution B of∆CP ∪ Λ C P ∪Ψ(C) ∪ Φ(V , D), andC = {v 7→ lbB(v) | v ∈ V}.\nThe proof of this theorem is obtained by combining existing characterizations of logic programs in terms of nogoods and similar ones for CSPs in terms of clauses in CNF (Ostrowski 2017).\nNogood propagators. The basic idea of lazy constraint propagation is to make the nogoods in Ψ(C) and Φ(V , D) only explicit when needed. This is done by propagators corresponding to the respective set of nogoods. A popular example of this is the unfounded-set algorithm in ASP solvers that only makes the nogoods in ΛP in (7) explicit when needed.\nFollowing (Drescher and Walsh 2012), a propagator for a set Θ of nogoods is a function ΠΘ mapping a Boolean assignment B to a subset of Θ such that for each total assignment B: if δ ⊆ B for some δ ∈ Θ, then δ′ ⊆ B for some δ′ ∈ ΠΘ(B). That is, whenever there is a nogood in Θ violated by an assignmentB, then ΠΘ(B) yields a violated nogood, too. A propagatorΠΘ is conflict optimal, if for all partial assignments B, the violation of a nogood in Θ by B implies that some nogood in ΠΘ(B) is violated by B. ΠΘ is inference optimal, if it is conflict optimal and ΠΘ(B) contains all unit nogoods of Θ wrt B.\nWe obtain the following extension of Theorem 2.1.\nTheorem 2.2 Let P be a constraint logic program over A ∪ C associated with the CSP (V , D,C) and let ΠΘ be a propagator for Θ = ΛCP , Ψ(C), and Φ(V , D), respectively.\nThen,B is a solution of∆CP ∪ Λ C P ∪Ψ(C) ∪Φ(V , D) iffB is a solution of\n∆CP ∪ ΠΛC P (B) ∪ΠΨ(C)(B) ∪ΠΦ(V,D)(B) .\nThis theorem tells us that the nogoods in Ψ(C), Φ(V , D), and ΛCP must not be explicitly represented but can be computed by corresponding propagatorsΠΘ that add them lazily when needed.\nTo relax the restrictions imposed by this theorem, the idea is to compile out a subset of constraints and variables of the CSP while leaving the others subject to lazy constraint propagation. This is captured by the following corollary to Theorem 2.2.\nCorollary 2.1 Let P be a constraint logic program over A ∪ C associated with the CSP (V , D,C) and let ΠΘ be a propagator for Θ = ΛCP , Ψ(C \\ C ′), and Φ(V \\ V ′, D \\D′), respectively, for subsets C′ ⊆ C,"
    }, {
      "heading" : "V ′ ⊆ V , and D′ ⊆ D.",
      "text" : "Then,B is a solution of∆CP ∪ Λ C P ∪Ψ(C) ∪Φ(V , D) iffB is a solution of\n∆CP ∪Ψ(C ′) ∪ Φ(V ′, D′) ∪ ΠΛC\nP\n(B) ∪ ΠΨ(C\\C′)(B) ∪ΠΦ(V\\V′,D\\D′)(B) .\nThis correspondence nicely reflects upon the basic idea of our approach. While the entire set of loop nogoods ΛCP is handled by the unfounded set propagator ΠΛC P (B) as usual, the ones capturing the CSP is divided among the explicated nogoods inΨ(C′)∪Φ(V ′, D′) and the implicit ones handled by the propagators ΠΨ(C\\C′)(B) and ΠΦ(V\\V′,D\\D′)(B). Note that variables and domain elements are often only dealt with implicitly through their induced order atoms in O.\n3 The clingcon system\nWe now detail various aspects of the new clingcon 3 system. We begin with an overview of its architecture along with its salient components. The next sections detail its input language andmajor algorithms. The subsequent section is dedicated to distinguished clingcon features, which are experimentally evaluated in Section 4. Finally, we illustrate in the last section clingcon’s multi-shot solving capabilities by discussing several incremental solutions to the n-queens puzzle."
    }, {
      "heading" : "3.1 Architecture",
      "text" : "clingcon 3 is an extension of the ASP system clingo 5, which itself relies on the grounder gringo and the solver clasp. The architecture of clingcon 3 is given in Figure 1. More precisely, cling-\ncon uses gringo’s capabilities to specify and process customized theory languages. For this, it is sufficient to supply a grammar fixing the syntax of constraint-related expressions. As detailed in Section 3.2, this allows us to express linear constraints similar to standard ASP aggregates by using first-order variables. Unlike this, clingcon extends clasp in several ways to accommodate its lazy approach to constraint solving. First, clasp’s preprocessing capabilities are extended to integrate linear constraints. Second, dedicated propagators are added to account for lazy constraint propagation. Both extensions are detailed in Section 3.3 and 3.4. And finally, a special output module was created to integrate CSP solutions. Notably, clingcon pursues a lazy yet twofold approach to constraint solving that allows for making a part of the nogoods in Ψ(C) explicit during preprocessing, while leaving the remaining constraints implicit and the creation of corresponding nogoods subject to the constraint propagator. In this way, a part of the CSP can be put right up front under the influence of CDCL-based search. All other constraints are only turned into nogoods when needed. Accordingly, only a limited subset of order atoms from O must be introduced at the beginning; further ones are only created if they are needed upon the addition of new nogoods. This is also called lazy variable generation.\nIt is worth mentioning that both the grounding and the solving component of clingcon can also be used separately via clingo’s option ‘--mode’. That is, the same result as with clingcon is obtained by passing the output of ‘clingcon --mode=gringo’ to ‘clingcon --mode=clasp’. The intermediate result of grounding a CASP program is expressed in the\naspif format (Gebser et al. 2016b) that accommodates both the regular ASP part of the program as well as its constraint-based extension. This modular design allows others to take advantage of clingcon’s infrastructure for their own CASP solvers. Also, other front ends can be used for generating ground CASP programs; eg. the flatzinc translator used in Section 4.\nFinally, extra effort was taken to transfer clasp specific features to clingcon’s solving component. This includes multi-threading (Gebser et al. 2012), unsatisfiable core techniques (Andres et al. 2012), multi-criteria optimization (Gebser et al. 2011), domain-specific heuristics (Gebser et al. 2013), multi-shot solving (Gebser et al. 2015), and clasp’s reasoning modes like enumeration, intersection and union of models. Vocabulary-sensitive reasoning modes like projective enumeration and domain-specific heuristics can be used via auxiliary atoms."
    }, {
      "heading" : "3.2 Language",
      "text" : "As mentioned, the treatment of the extended input language of CASP programs can be mapped onto gringo’s theory language capabilities (Gebser et al. 2016a). For this, it is sufficient to supply a corresponding grammar fixing the syntax of the language extension. The one used for clingcon is given in Listing 1. The grammar is named csp and consists of two parts, one defining theory terms in lines 2-27 and another defining theory atoms in lines 29-33. All regular terms are implicitly included in the respective theory terms. Theory terms are then used to represent constraint-related expressions that are turned by grounding into linear constraint atoms using predicate &sum, domain restrictions using predicate &dom, directives &show and &minimize, and the predefined global constraint &distinct.\nBefore delving into further details, let us illustrate the resulting syntax by the CASP program for two dimensional strip packing given in Listing 2, originally due to (Soh et al. 2010). Given a set of rectangles, each represented by a fact r(I,W,H)where I identifies a rectangle with width W and height H, the task is to fit all into a container of width w and height ub while minimizing\n1 #theory csp { 2 dom_term { 3 + : 5, unary; 4 - : 5, unary; 5 .. : 1, binary, left; 6 * : 4, binary, left; 7 + : 3, binary, left; 8 - : 3, binary, left 9 };\n10 linear_term { 11 + : 5, unary; 12 - : 5, unary; 13 * : 4, binary, left; 14 + : 3, binary, left; 15 - : 3, binary, left 16 }; 17 show_term { 18 / : 1, binary, left 19 }; 20 minimize_term { 21 + : 5, unary; 22 - : 5, unary; 23 * : 4, binary, left; 24 + : 3, binary, left; 25 - : 3, binary, left; 26 @ : 0, binary, left 27 };\n29 &dom/0 : dom_term, {=}, linear_term, any; 30 &sum/0 : linear_term, {<=,=,>=,<,>,!=}, linear_term, any; 31 &distinct/0 : linear_term, any; 32 &show/0 : show_term, directive; 33 &minimize/0 : minimize_term, directive 34 }.\nListing 1: Language Syntax\nthe needed height of the container. The first two lines of Listing 2 restrict the domain of the left lower corner of each rectangle I. The respective instantiations of x(I) and y(I) yield constraint variables denoting the x and y coordinate of I, respectively. Note that in both lines the consecutive dots ‘..’ construct a theory term ‘0..w-W’ and ‘0..ub-H’ once w and ub are replaced, respectively. The choice rule in Line 4-7 lets us choose among all combinations of two rectangles, that is, which one is left, right, below or above. At least one of these relations must hold so that no two rectangles overlap. Atoms of form le(VI,C,VJ) indicate that coordinate VI+C must be less than or equal to VJ. This property is enforced by the linear constraint in Line 9. Finally, to minimize the overall height of (stacked) rectangles, we introduce the variable height. This variable’s value has to be greater than or equal to the y coordinate of any rectangle I plus the rectangle’s height H. This ensures that height is greater or equal to the height of the highest rectangle. Finally, height is minimized in Line 13.\nNow, if we take the three rectangles r(a,5,2), r(b,2,3), r(c,2,2) along with ub=10\n1 &dom{0..w-W} = x(I) :- r(I,W,H). 2 &dom{0..ub-H} = y(I) :- r(I,W,H).\n4 1 { le(x(I),WI,x(J)); 5 le(x(J),WJ,x(I)); 6 le(y(I),HI,y(J)); 7 le(y(J),HJ,y(I)) } :- r(I,WI,HI), r(J,WJ,HJ), I < J.\n9 &sum{VI; C} <= VJ :- le(VI,C,VJ).\n11 &dom{0..ub} = height. 12 &sum{y(I); H} <= height :- r(I,W,H). 13 &minimize {height}. 14 &show {height}.\nListing 2: Two Dimensional Strip Packing\nand w=6, we obtain the ground program in Listing 3. The domains of the constraint variables giving the x- and y-coordinates are delineated in Line 3 and 4. Note that in contrast to regular ASP the grounder leaves termswith the theory symbol.. intact. The orientation of each pair of rectangles is chosen in Lines 6-11. If for examplele(x(c),2,x(b)) becomes true, that is, rectangle c is left of b, then the constraint x(c) + 2 ≤ x(b) is enforced in Line 22. After setting the domain for the height variable in Line 26, we restrict it to be greater or equal to the top y-coordinate of all rectangles in Lines 28-30. Line 32 enforces the minimization of this variable. A solution with minimal height consists of the regular atoms le(y(b),3,y(a)), le(y(c),2,y(a)), and le(x(c),2,x(b)) and the constraint variable assignment {height 7→ 5,y(c) 7→ 1,x(c) 7→ 2,x(a) 7→ 1,x(b) 7→ 4,y(a) 7→ 3,y(b) 7→ 0}. Of course other minimal configurations exist.\nWe have seen above how seamlessly theory atoms capturing constraint-related expressions can be used in logic programs. We detail below the five distinct atoms featured by clingcon and refer the interested reader for a general introduction to theory terms and atoms to (Gebser et al. 2016a).\nActual constraints are represented by the theory atoms &dom, &sum, and &distinct. All three can occur in the head and body of rules, as indicated by any in Line 29-31 in Listing 1. We discuss below their admissible format after grounding. In the following, a linear expression is a sum of integers, products of integers, or products of an integer and a constraint variable.\nDomain constraints are of form &dom{d1; . . . ; dn} = t where\n• each di is a domain term of form\n— u or\n— v..w\nwhere u, v, w are constraint variable free linear expressions and\n• t is a linear expression containing exactly one constraint variable.\nThen, the previous expression represents the constraint t ∈ ⋃n\ni=1JdiK, where JdK = {u} if\nd = u, JdK = {v, . . . , w} if d = v..w, and undefined otherwise. This constraint can be used to set the domain of variables where even non-contiguous domains can be used by having n > 1. For example &dom{1..3; 5} = x represents the constraint x ∈ {1, . . . , 3} ∪ {5}.\n1 r(a,5,2). r(b,2,3). r(c,2,2).\n3 &dom{0..(6-5)} = x(a). &dom{0..(6-2)} = x(b). &dom{0..(6-2)} = x(c). 4 &dom{0..(10-2)} = y(a). &dom{0..(10-3)} = y(b). &dom{0..(10-2)} = y(c).\n6 1 <= { le(x(a),5,x(b)); le(x(b),2,x(a)); 7 le(y(a),2,y(b)); le(y(b),3,y(a)) }. 8 1 <= { le(x(a),5,x(c)); le(x(c),2,x(a)); 9 le(y(a),2,y(c)); le(y(c),2,y(a)) }.\n10 1 <= { le(x(b),2,x(c)); le(x(c),2,x(b)); 11 le(y(b),3,y(c)); le(y(c),2,y(b)) }.\n13 &sum{ x(a); 5 } <= x(b) :- le(x(a),5,x(b)). 14 &sum{ x(b); 2 } <= x(a) :- le(x(b),2,x(a)). 15 &sum{ y(a); 2 } <= y(b) :- le(y(a),2,y(b)). 16 &sum{ y(b); 3 } <= y(a) :- le(y(b),3,y(a)). 17 &sum{ x(a); 5 } <= x(c) :- le(x(a),5,x(c)). 18 &sum{ x(c); 2 } <= x(a) :- le(x(c),2,x(a)). 19 &sum{ y(a); 2 } <= y(c) :- le(y(a),2,y(c)). 20 &sum{ y(c); 2 } <= y(a) :- le(y(c),2,y(a)). 21 &sum{ x(b); 2 } <= x(c) :- le(x(b),2,x(c)). 22 &sum{ x(c); 2 } <= x(b) :- le(x(c),2,x(b)). 23 &sum{ y(b); 3 } <= y(c) :- le(y(b),3,y(c)). 24 &sum{ y(c); 2 } <= y(b) :- le(y(c),2,y(b)).\n26 &dom{ 0..10 } = height.\n28 &sum{ y(a); 2 } <= height. 29 &sum{ y(b); 3 } <= height. 30 &sum{ y(c); 2 } <= height.\n32 &minimize{ height }. 33 &show{ height }.\nListing 3: Two Dimensional Strip Packing Example\nLinear constraints are of form &sum{t1; . . . ; tn} ◦ tn+1 where\n• each ti is a linear expression containing at most one constraint variable, and • ◦ is one of the operators <=,=,>=,<,>,!=\nThis expression represents the linear constraint (t1 + · · ·+ tn) ◦ tn+1, which can be translated into one or two linear constraints as in (5). Distinct constraints are of form &distinct{t1; . . . ; tn} where each ti is a linear expression\ncontaining at most one constraint variable. Such an expression stands for the constraints ti 6= tj for 0 ≤ i < j ≤ n. The distinct constraint is one of the most common global constraints in CP. We use it to show how global constraints can be incorporated into the language.\nThe two remaining theory atoms provide directives, similar to their regular counterparts.\nOutput directives are of form &show{s1; . . . ; sn} where each si is a show term of form\n• f/m where f is a function symbol andm a positive integer\n• t, where t is a constraint variable.\nWhile the latter adds variable t to the list of output variables, the first one adds all variables of the form f(t1, . . . , tm) (where ti is a term) as output variables. For all constraint stable models, the value of the output variables is shown in a solution. Minimize directives are of form &minimize{m1; . . . ;mn}where eachmi is a minimize term\nof form ti@li and ti being a linear expression with at most one constraint variable. Since we support multi-objective optimization, li is an integer stating the priority level. Whenever @li is omitted, it is assumed to be zero. Priorities allow for representing lexicographically ordered minimization objectives. As in regular ASP, higher levels are more significant than lower ones. Let us make precise how minimize statements induce optimal constraint stable models. Let P be a constraint logic program associated with (V , D,C). For a variable assignment C and an integer l, define ∑ C\nl as the sum of all values a · C(v) + c for all occurrences of minimize\nterms av + c@l in all minimize statements in P . A constraint stable model (X,C) of P wrt (V , D,C) is dominated if there is a constraint stable model (X ′,C′) such that ∑ C ′\nl < ∑ C l\nand ∑\nC ′ l′ = ∑ C l′ for all l ′ > l, and optimal otherwise. Maximization can be achieved by\nmultiplying each minimize term by −1.\nNote that the set of constraints supported by clingcon is only a subset of the constraints expressible with the syntax fixed in Listing 1. While for example expressions with more than one constraint variable are well-formed according to the syntax, they are not supported by clingcon."
    }, {
      "heading" : "3.3 Algorithms",
      "text" : "As mentioned, clingcon pursues a lazy approach to constraint solving that distinguishes two phases. During preprocessing, any part of the nogoods representing a CSP can be made explicit and thus put right away under the influence of CDCL-based solving. Unlike this, the remaining constraints are at first kept implicit and their corresponding nogoods are only added via constraint propagators to CDCL solving when needed. This partitioning of constraints constitutes a trade-off. On the one hand, constraint propagators are usually slower than unit propagation, in particular, when dealing with sets of nogoods of moderate size because of modern SAT techniques such as the two-watched-literals scheme (Zhang et al. 2001). On the other hand, translating all constraints is often impracticable, in particular, when dealing with very large domains. Hence, a good trade-off is to restrict the translation to “small constraints” in order to benefit from the high performance of CDCL solving and to unfold “larger constraints” only by need.\nIn what follows, we make clingcon’s two-fold approach precise by presenting algorithms for translation and propagation of constraints before discussing implementation details in Section 3.4.\nPartial Translation. Following Corollary 2.1, a subset C′ ⊆ C of the constraint atoms is used to create the set of nogoodsΨ(C′). Therefore, Algorithm 1 creates a set of nogoods that is equivalent to ψ(σ, a1v1+ · · ·+anvn ≤ b), as defined in (12) and (13); in turn, they are used to createΨ(C′) as shown in (11). To this end, it is initially engaged by TRANSLATE({σ}, a1v1+ · · ·+anvn ≤ b). We start the algorithm by having σ in our set of literals δ, and setting d to the smallest value greater than b − ∑n\nj=2 ub(ajvj) in the image of a1v1. This is the smallest value needed to\nviolate the constraint. If d and the least sum ∑n\nj=2 lb(ajvj) added by all other views is still\nless than b in Line 4, we have to recursively translate the rest of the constraint, while subtracting\nAlgorithm 1: TRANSLATE\nInput :A set of signed literals δ and a linear constraint a1v1 + · · ·+ anvn ≤ b Output :A set of nogoods\n1 Σ ← ∅ 2 d← next(b− ∑n\nj=2 ub(ajvj), a1v1)\n3 while d ≤ ub(a1v1) 4 if d+ ∑n\nj=2 lb(ajvj) ≤ b then\n5 Σ ← Σ ∪ TRANSLATE(δ ∪ {(a1v1 ≥ d)‡}, a2v2 + · · ·+ anvn ≤ b− d) 6 else 7 return Σ ∪ {δ ∪ {(a1v1 ≥ d)‡}} 8 d← next(d, a1v1) 9 return Σ\nd from the right-hand side in Line 5. Otherwise the constraint is already violated and we return all nogoods created so far in Line 7. We iteratively increase d in Line 8 and repeat this process (Line 3) for all values in img(a1v1). Note that this also involves adding all order atomsOΨ(C′) = ⋃\nδ∈Ψ(C′) δ T ∪ δF included in the created nogoodsΨ(C′) to the solver. Which constraints to translate is subject to heuristics and command line options, as explained\nin Section 3.4.\nExtended Conflict Driven Constraint Learning. After translating a part of the problem into a set of nogoods Ψ(C′), using the order atoms OΨ(C′) ⊆ O, we explain how to solve the remaining constraint logic program P over A, C associated with (V , D,C). Our algorithmic approach follows the one in (Drescher and Walsh 2012), where a modified CDCL algorithm supporting external propagators is presented. We extend this algorithm with lazy nogood and variable generation in Algorithm 2. The algorithm relies upon a growing set of Boolean variables B, which is initiated with all atoms (regular, constraint, and a subset of the order atoms in OΨ(C′)), and subsequently expanded by further order atoms. Accordingly, the Boolean assignmentB is restricted to atoms in B, and recorded nogoods are accumulated in ∇. Starting with an empty assignment, the PROPAGATION method (Line 5), extends the assignment B with propagated literals, adds new nogoods to∇ and extends the set of atoms B. This method is detailed below in Algorithm 3. When encountering a conflicting assignment (Line 6), we either backtrack (Line 8) or, if we cannot recover from the conflict, return unsatisfiable. Whenever all atoms in B are assigned (Line 9), we check whether a complete assignment for the variables in V is obtained fromB in Line 10. If this is the case, we return the constraint stable model (BT ∩ atom(P ), {v 7→ lbB(v) | v ∈ V}). Otherwise, SPLITV,D(B,B) creates a new order atom for the constraint variable with the currently largest domain that splits the domain in half. If we face an incomplete assignment, we extend it using the SELECT function.\nAlgorithm 3 reflects the proceeding of our propagators. At first, UNITPROPAGATION is run on the completion nogoods ∆CP , the nogoods from the partial translation Ψ(C ′), and finally the already learned nogoods∇. Then, propagatorΠΛC P is engaged via UFSPROPAGATION. If it does not add any new nogoods to ∇, CSPPROPAGATION is called. This method acts as a propagator, returning a set of nogoods∇′. Since some of these nogoods may use new order atoms not intro-\nAlgorithm 2: EXTENDED CDCL\nInput :A constraint logic program P overA, C associated with (V , D,C), a set of\nconstraints atoms C′ ⊆ C, and a set of order atomsOΨ(C′) ⊆ O\nOutput :A constraint stable model or unsatisfiable\n1 B ← A ∪ C ∪ OΨ(C′) // set of atoms 2 B ← ∅ // assignment over A ∪ C ∪O 3 ∇ ← ∅ // set of (dynamic) nogoods 4 loop 5 (B,B,∇) ← PROPAGATION(B,B, C′,∇) 6 if CONFLICT(B) then 7 if ROOTCONFLICT(B) then return unsatisfiable 8 (B,∇) ← BACKTRACKP (B,∇) 9 else if COMPLETE(B) then\n10 if lbB(v) = ubB(v) for all v ∈ V then 11 return (BT ∩ atom(P ), {v 7→ lbB(v) | v ∈ V}) 12 else B ← B ∪ {SPLITV,D(B,B)} 13 else B ← B ∪ {SELECT(B)}\nAlgorithm 3: PROPAGATION\nGlobal :A constraint logic program P overA, C associated with (V , D,C) Input :A set of atoms B, a Boolean assignmentB, a set of constraint atoms C′, and a set\nof learned nogoods∇\nOutput :A set of atoms, a Boolean assignment, and a set of learned nogoods\n1 loop 2 B ← UNITPROPAGATIONP (B,Ψ(C′) ∪∇) 3 if CONFLICT(B) then return (B,B,∇) 4 ∇′ ← UFSPROPAGATIONP (B) 5 if ∇′ 6= ∅ then 6 ∇ ← ∇∪∇′ 7 else 8 ∇′ ← CSPPROPAGATION(B, C′,B) 9 if ∇′ 6= ∅ then\n10 for δ ∈ ∇′ do B ← B ∪ δT ∪ δF 11 ∇ ← ∇∪∇′ 12 else return (B,B,∇)\n13 end\nduced so far, we dynamically extend the set of atoms B by the atoms in δT ∪ δF stemming from the added nogoods δ ∈ ∇′.\nNew nogoods produced by any propagator are added to the set ∇ of recorded nogoods and propagation resumes afterwards (lines 6 and 11). Notably, CSPPROPAGATION is not run until a fixpoint is obtained. However, its set of returned nogoods remains non empty until a fixpoint is reached. In this way, unit propagation interleaves with constraint propagation while delaying\nmore complex propagation. In all, since unit propagation is much faster, it always precedes unfounded set propagation, which again precedes constraint propagation. This order reflects the complexity of the respective propagators, so that the faster the propagation, the sooner it is engaged.\nLazy Variable Generation. Realizing CSPPROPAGATION as a propagator for ΠΨ(C) and ΠΦ(V,D) allows for lazy nogood generation and for capturing inferences of the order encoding. However, to be effective, lazy variable generation requires a different set of constraints to be propagated. For illustration, suppose CSPPROPAGATION is a propagator for Ψ(C) ∪ Φ(V , D). Considering our example program P1 along with T(x < 7) ∈ B results in CSPPROPAGATION(∅, ∅, {T(x < 7)}) = {{T(x < 7),F(x ≤ 6)}}, which is a subset of Ψ(C) according to (14). This nogood comprises the order atom (x ≤ 6) which is added to B in Line 10 of Algorithm 3. Having this nogood, unit propagation adds in turn T(x ≤ 6) to the assignment in Line 2. Then, CSPPROPAGATION({(x ≤ 6)}, ∅, {T(x ≤ 6)}) yields the nogoods {{T(x ≤ 6),F(x ≤ 7)}, . . . , {T(x ≤ 8),F(x ≤ 9)}} belonging to Φ(V , D) and produces the corresponding order atoms (x ≤ 7), . . . , (x ≤ 9). We see that once a certain upper bound T(v ≤ x) ∈ B is found, all order atoms in {(v ≤ x′) | x′ > x, x′ ∈ D(v), x′ < ub(v)} are added to B. Similarly, if a lower bound F(v ≤ x) ∈ B is fixed, all order atoms {(v ≤ x′) | x′ ≤ x, x′ ∈ D(v)} are added to B. To avoid adding superfluous order atoms, we let CSPPROPAGATION be a propagator forΨ(C) ∪Φ′(V , D) where\nΦ′(V , D) = {{T(v ≤ d),F(v ≤ e)} | v ∈ V , d ∈ D(v), e ∈ D(v), d < e < ub(v)}.\nAlthough Φ′(V , D) is a superset of Φ(V , D), CSPPROPAGATION only adds nogoods from Φ′(V , D) whose order atoms have already been introduced, that is, {(v ≤ d), (v ≤ e)} ⊆ B. While Φ(V , D) contains for each variable v a linear number of nogoods of form {T(v ≤ d),F(v ≤ next(d, v))}, Φ′(V , D) contains a quadratic number of nogoods for each variable. The nogoods in Φ(V , D) allow for propagating the truth value of one order literal to its adjacent one. Unlike this, Φ′(V , D) contains redundant nogoods that allow for propagating the truth value of one order literal to all greater ones by means of nogoods of form {T(v ≤ d),F(v ≤ e)} for all values e ∈ D(v) such that d < e < ub(v). Instead of “chaining” all values together, the latter nogoods allow us to directly jump to any value. As we restrict our propagator for Φ′(V , D) to only return nogoods where all order atoms are included in B, no new order atoms are created. In our example, this optimized CSPPROPAGATION function does not return any nogoods, viz. CSPPROPAGATION({(x ≤ 6)}, ∅, {T(x ≤ 6)}) = ∅, as none of the order atoms (x ≤ 7), . . . , (x ≤ 9) are included in B and no propagation needs to be done.\nCSPPROPAGATION is depicted in Algorithm 4 and consists of two parts (lines 1-10 and 11-21).\nThe first part starts with selecting the unit nogoods from Φ′(V , D). For every variable v ∈ V , we check if it already has an upper bound ub (lines 3-4) given byT(v ≤ ub) ∈ B. If this is the case, we add the nogoods\n{{T(v ≤ ub),F(v ≤ x)} | x > ub, (v ≤ x) ∈ B,T(v ≤ x) /∈ B}\ntoΣ to ensure consistency of all order atoms (v ≤ x) ∈ B where x > ub that are not already true. Lines 6-8 do the same for current lower bound of the variable. If any nogoods are found, they are immediately returned in Line 10. The PROPAGATION function continues with unit propagation on the new nogoods. The second part of the constraint propagation (lines 11-21), generating the\nAlgorithm 4: CSPPROPAGATION\nGlobal :A constraint logic program P overA, C associated with (V , D,C) Input :A set of atoms B, a set of constraint atoms C′, and a Boolean assignmentB Output :A set of nogoods\n1 Σ ← ∅ // an empty set of nogoods 2 for v ∈ V do 3 if T(v ≤ d) ∈ B for some d ∈ D(v) then 4 ub← min {d | d ∈ D(v),T(v ≤ d) ∈ B} 5 Σ ← Σ ∪ {{T(v ≤ ub),F(v ≤ x)} | x > ub, (v ≤ x) ∈ B,T(v ≤ x) /∈ B} 6 if F(v ≤ d) ∈ B for some d ∈ D(v) then 7 lb← max {d | d ∈ D(v),F(v ≤ d) ∈ B} 8 Σ ← Σ ∪ {{T(v ≤ x),F(v ≤ lb)} | x < lb, (v ≤ x) ∈ B,F(v ≤ x) /∈ B}\n9 end\n10 if Σ 6= ∅ then return Σ 11 for c ∈ C \\ C′ do 12 if Tc ∈ B then 13 Σ ← Σ ∪ PROPAGATEBOUNDS(B,Tc⇒ γ(c)) 14 else if Fc ∈ B then 15 Σ ← Σ ∪ PROPAGATEBOUNDS(B,Fc⇒ γ(c)) 16 else 17 Σ ← Σ ∪ PROPAGATEREIFICATION(B,Tc⇒ γ(c))\n18 Σ ← Σ ∪ PROPAGATEREIFICATION(B,Fc⇒ γ(c)) 19 if Σ 6= ∅ then return Σ\n20 end 21 return ∅\nnogoods in Ψ(C \\ C′) lazily, is only done if all order atoms are properly propagated, i.e. no new nogoods have been generated in the first part (lines 1-10). This is detailed in the next paragraph.\nConstraint Propagation. To generate the nogoods inΨ(C \\C′) lazily, Algorithm 4 uses functions PROPAGATEBOUNDS and PROPAGATEREIFICATION for half-reified constraint Tc ⇒ γ(c) and Fc ⇒ γ(c), respectively, for each c ∈ C \\ C′. In the respective algorithms 5 and 6, we consider four different strengths of propagation, denoted by ps . A strength of 1 means that our propagator only produces conflicting nogoods. A strength of 2 means that it additionally checks if yet undecided constraints became true. Strength 3 furthermore adds unit nogoods that also propagate the bounds of the variables in a constraint if it is already decided to be true, whereas strength 4 also computes optimized nogoods for yet undecided constraints. The propagators are conflict optimal and for strength 4 even inference optimal. We divided our propagator into two algorithms, handling reified constraints of form σ ⇒ a1v1 + · · · + anvn ≤ b. Algorithm 5 is only called if σ ∈ B. Whenever σ is true, we check whether the constraint a1v1 + · · · + anvn ≤ b can be falsified. If it can never be falsified, e.g. the sum of the current upper bounds already satisfies the constraint in Line 1, we are done. If we only have propagation strength 1 or 2, we check in Line 3 whether the sum of the current lower bounds is already above the bound b. In this case, we simply return the current lower bounds of the views as a nogood, since the constraint is already\nAlgorithm 5: PROPAGATEBOUNDS\nGlobal :An integer ps Input :A Boolean assignmentB and a half-reified constraint σ ⇒ a1v1 + · · ·+ anvn ≤ b Output :A set of nogoods\n1 Σ ← ∅ // An empty set of nogoods 2 if ∑n\nj=1 ubB(ajvj) ≤ b then return ∅\n3 if ps ≤ 2 then 4 if ∑n\nj=1 lbB(ajvj) > b then\n5 Σ ← {{σ} ∪ {(ajvj ≥ lbB(ajvj))‡ | 1 ≤ j ≤ n}} 6 return Σ 7 for i = 1..n do 8 cur ← b− ∑n\nj=1,j 6=i lbB(ajvj)\n9 if cur < ubB(aivi) then\n10 Σ ← Σ ∪ {{σ, (aivi > cur)‡} ∪ {(ajvj ≥ lbB(ajvj))‡ | 1 ≤ j ≤ n, j 6= i}} 11 if cur < lbB(aivi) then return Σ 12 end 13 return Σ\nviolated. For example, take the constraint σ ⇒ x+y ≤ 9 withD(x) = D(y) = {1, . . . , 15} and the current lower and upper bounds lbB(x) = 7, ubB(x) = 10, lbB(y) = 5, and ubB(y) = 12. The sum of the lower bounds 7 + 5 is greater than 9, and so the constraint is violated. Therefore, we add the nogood {σ, (x ≥ 7)‡, (y ≥ 5)‡}. If the propagation strength is greater than 2 (Lines 6-10), we try to find new upper bounds for the views of the constraint. For this purpose, cur represents the maximal value that aivi can take without violating the constraint. All other views ajvj (j 6= i) contribute at least their current lower bound to the sum. In our example, this means that cur = 9 − 5 = 4. If this value is less than the current upper bound of aivi (Line 8), we create a nogood that allows us to propagate the new upper bound. In the example, this is {σ, (x > 4)‡, (y ≥ 5)‡}. Compared to the nogood that was created in Line 4, this nogood is stronger as the required minimum for x is lower. If cur is even below the current lower bound of aivi, we have a conflict and stop eagerly (Line 11). Since cur = 4 and lbB(x) = 7, this is the case in our example. This algorithm has linear complexity O(n), but since we consider domains/images with holes, finding the literal (aivi > cur) ‡ is actually O(log(|D(vi)|)) which raises the overall complexity for propagation strength greater than 2.\nAlgorithm 6 is only called if neither σ ∈ B nor σ ∈ B, e.g. whenever σ is unknown, and propagation strength is at least 2 (Line 1). If the sum of all current lower bounds of the left hand side is greater than b (Lines 2 and 3), the constraint can never become satisfied. Given a propagation strength below 4, we simply create a nogood based on the current lower bounds. In our example, this is the same nogood {σ, (x ≥ 7)‡, (y ≥ 5)‡} generated in Algorithm 5. If the propagation strength is 4 (Lines 8-13), we try to find a sum of the views that is minimally greater than b. In our example, we start with a lower bound low = 12. By subtracting lbB(x), we get low′ = 5. This leaves us with cur = next(9 − 5, x) = 5 adding (x ≥ 5)‡ to our nogood. In the second iteration, we now have to find a sufficient lower bound for y that violates the constraint. We see that this value is 5, adding (y ≥ 5)‡ to δ in Line 11 resulting in the nogood {σ, (x ≥ 5)‡, (y ≥ 5)‡}. Again, the complexity of the refined search is higher but\nAlgorithm 6: PROPAGATEREIFICATION\nGlobal :An integer ps Input :A Boolean assignmentB and a half-reified constraint σ ⇒ a1v1 + · · ·+ anvn ≤ b Output :A set of nogoods\n1 if ps = 1 then return ∅ 2 low ← ∑n\nj=1 lbB(ajvj)\n3 if low > b then 4 δ ← {σ} 5 if ps < 4 then 6 δ ← δ ∪ {(ajvj ≥ lbB(ajvj))‡ | 1 ≤ j ≤ n}) 7 else 8 for j ∈ 1..n do 9 low′ ← low − lbB(ajvj)\n10 cur ← next(b− low′, ajvj) 11 δ ← δ ∪ {(ajvj ≥ cur)‡} 12 low ← low′ + cur\n13 end 14 return {δ}\nalso the produced nogoods are stronger. Note that as an optimization, PROPAGATEBOUND and PROPAGATEREIFICATION are only called if the bounds of the variables of the constraints have changed. The propagation strength is set using the option --prop-strength."
    }, {
      "heading" : "3.4 Distinguished Features",
      "text" : "After presenting the algorithmic framework of clingcon 3, we now describe some of its specific features. Many of them aim at reducing the size of domains and the number of variables, while others address special functionalities, like global constraints or multi-objective optimization over integer variables, respectively.\nWhen we refer in the following to the truth value of atoms, we consider a partial assignment\nobtained by propagation and/or preprocessing.\nViews. A view av + b can be represented with the same set of order atoms as its variable v (Thibaut and Stuckey 2009). Consider the view −5v + 7 together with the domain D(v) = {1, 2, 3, 4, 5}. We show how the order atoms of v are used to encode constraints over the view in clingcon. The view −5v + 7 has the following values in its image: img(−5v + 7) = {−18,−13,−8,−3, 2}. The order literals for {(v ≤ x)‡ | x ∈ D(v)} and {(−5v + 7 ≤ x)‡ | x ∈ img(−5v + 7)} are given in Table 1. We see that the set of order atoms used for\nthese literals is the same. By allowing views instead of variables, we avoid introducing new\nvariables (for views). In fact, neither the XCSP (Roussel and Lecoutre 2009) nor the flatzinc13 format allow for using views in global constraints. For instance, a distinct constraint over the set the views {1000v1, 1000v2, 1000v3, 1000v4, 1000v5} translates into the same nogoods as a distinct constraint over {v1, v2, v3, v4, v5}. Due to the restriction to use variables, according solvers like sugar (Tamura et al. 2009) introduce auxiliary variables v′i = 1000vi for 1 ≤ i ≤ 5. If D(vi) = {1, . . . , 10}, bound propagation yields the domainsD(v ′ i) = {1000·1, . . . , 1000·10} = {1000, . . . , 10000}.14 Furthermore, around 220000 nogoods for the equality constraints are created. By handling views directly, we avoid introducing these auxiliary variables and constraints in clingcon.\nThe same holds for minimize statements. Views on variables such as 3 ∗ v2 or −v3 allow for weighting variables during minimization as well as maximization, without the need of introducing auxiliary variables and additional constraints.\nNon-Contiguous Integer Domains. We represent domains of variables (and images of views) as sorted lists of ranges like [1..3, 7..12, 39..42] instead of single ranges like [1..42]. This has the advantage that we can represent domains with holes directly, without any additional constraints. Introducing order atoms for such a non-contiguous domain produces fewer atoms (12 in this example) than for a domain only represented with two bounds (41). A drawback of this representation is that the lookup for a certain value d in the domain becomes logarithmic, as we rely upon binary search in the list of ranges. This is frequently done in Algorithms 1, 5 and 6 whenever a calculated value d leads to searching for a literal (v ≤ d)‡.\nEquality Processing. To minimize the number of atoms and nogoods that have to be created during a translation or solving process, we need to reduce the number of integer variables. To accomplish this, we consider the equalities in a CSP that include only two integer variables, and replace all occurrences of the first variable with a view on the second variable in all other constraints. Consider a constraint logic program P over A, C associated with (V , D,C). For each element γ(σ) ∈ C of the form ax + c1 = by + c2 (or ax + c1 6= by + c2) where σ is true (false), a, b, c1, c2 are integers, and x, y ∈ V , we successively replace constraints in C. For this, we normalize the constraint γ(σ) to ax = by + c where x is lexicographically smaller than y and multiply all constraints in C containing variable y with b and replace by + c by ax in them. The domain of x is made domain consistent such that ad ∈ img(by + c) holds for all d ∈ D(x). Afterwards, we remove γ(σ) from C and y from V . Note that by replacing variables, new equalities may arise, which we process until a fixpoint is reached.\nFor illustration, consider the following set C of constraints.\na = 2b (16)\nb = 2c (17)\nc = 2d (18)\nd = 2e (19)\ne = 2f (20)\na+ 14d− 3f + b ≤ −g (21)\n13 http://www.minizinc.org/downloads/doc-1.3/flatzinc-spec.pdf 14 As done in the sugar system.\nAnd assume that the constraint literals associated with the first 5 constraints are true. Furthermore, let D = {D(x) = {−212, . . . , 212 | x ∈ {a, b, c, d, e, f, g}}. Without any simplification, we have 7 variables, all with a domain size of roughly 8000. By simply translating these constraints, we would create around 120000 order atoms and 118 million nogoods. Let us show how equality processing allows us to significantly reduce these numbers in our example. To begin with, we multiply the constraint in (21), viz. a+ 14d− 3f + b ≤ −g, with 2 and replace −6f with −3e using the constraint in (20). This yields 2a + 28d − 3e + 2b ≤ −2g. Also, (20) allows us to restrict the domain of e to D(e) = {−211, . . . , 211}. We then remove e = 2f from the set of constraints and f from the set of variables. We repeat this procedure for all other equalities. To replace e, we again multiply the obtained constraint by 2, yielding 4a+ 56d− 6e+ 4b ≤ −4g, and replace 6e with 3d using (19). This results in 4a + 53d + 4b ≤ −4g. Again, we remove d = 2e and variable e, and obtain D(d) = {−210, . . . , 210}. Using (18), we multiply by 2 and replace 106d with 53c which leads to the constraint 8a + 53c + 8b ≤ −8g. To remove c, the constraint in (17) is used to replace 106c with 53b resulting in 16a + 69b ≤ −16g. In the last step, we apply (16) to get 32a + 69a ≤ −32g which simplifies to 101a ≤ −32g. As a result, the overall set of constraints is thus reduced to a single constraint 101a ≤ −32g. This constraint uses only two variables with domainsD(a) = {−27, . . . , 27} and D(g) = {−212, . . . , 212}. All other constraints and variables have been removed. To translate this constraint, we need 9265 order atoms and 268 nogoods.\nOur approach to equivalence processing is inspired by Boolean Equipropagation (Metodi et al. 2013), which directly replaces the order atoms of one variable with the other. Directly using integer variables, without considering the order literal representation, allows us to use this technique also in the context of lazy variable generation. Here, it reduces the number of variables, which leads to shorter constraints, which ultimately reduces the number of nogoods in the translation process.\nEquality preprocessing is done once in clingcon, before the actual solving starts and can be\ncontrolled using the command line option --equality-processing.\nDistinct Translation. clingcon features two alternatives for translating global distinct constraints. Assume that constraint atom c represents a distinct constraint over a set {v1, . . . , vn}. Since we represent distinct constraints in terms of rules and other linear constraints, this constraint atom becomes a regular atom and is used in the head of rules.\nThe first method to handle this constraint uses a quadratic number of new, regular atoms\nneq(vi, vj) for all 1 ≤ i < j ≤ n together with the rules\nneq(vi, vj) ← (vi − vj ≤ 1)\nneq(vi, vj) ← (vj − vi ≤ 1)\nto represent that two variables are unequal. By adding the following rule to the program\nc ← neq(v1, v2), neq(v1, v3), . . . , neq(v1, vn),\nneq(v2, v3), . . . , neq(v2, vn),\n. . . ...\nneq(vn−1, vn)\nclingcon ensures that c is only true if all variables are distinct from each other.\nThe second alternative uses a so-called direct encoding (Walsh 2000). For each value\nd ∈ ⋃n\ni=1 img(vi), we ensure that at most one variable from {v1, . . . , vn} takes this value. There-\nfore, we introduce regular atoms of form eq(vi, d) for all these variables together with the rule\neq(vi, d) ← (vi ≤ d), (−vi ≤ −d) (22)\nrepresenting that vi = d. Furthermore, we add a cardinality constraint (Simons et al. 2002) for each value d to the effect that no two or more variables may have the same value, viz.\nc′ ← 2 {eq(v1, d), . . . , eq(vn, d)}\nThe new regular atom c′ is true if two or more variables have the same value d. If this is not the case, the distinct constraint atom holds via the rule:\nc ← ∼c′\nWe reuse the direct encoding atoms eq(vi, d) for other distinct constraints. Note that introducing all direct encoding atoms also involves the creation of corresponding order atoms before the solving process. So no variable from a distinct constraint can be created lazily. This is also the reason why this option is not enabled in clingcon by default and distinct constraints are translated using inequalities. The use of the direct encoding along with cardinality constraints is enabled with the option --distinct-to-card.\nPigeon Hole Constraints. To enhance the propagation strength when translating distinct constraints in clingcon, we add rules for the lower and upper bounds. Consider the constraint atom c for a distinct constraint over {v1, . . . , vn} and let U = ⋃n i=0 img(vi), l be the nth smallest element in U , and u be the nth greatest element in U . We add the rules:\n← c, (v1 > u), . . . , (vn > u)\n← c, (v1 < l), . . . , (vn < l)\nwhere as before, c is treated as regular atom.\nSo given a distinct constraint over {v1, v2, v3} with D(vi) = {1, . . . , 10} for 1 ≤ i ≤ 3 we\nadd the rules\n← c, (v1 > 8), (v2 > 8), (v3 > 8)\n← c, (v1 < 3), (v2 < 3), (v3 < 3)\nThis forbids all variables to have a value greater than eight or to have a value less than three. This feature only causes a constant overhead in the number of rules. It can be controlled using the option --distinct-pigeon.\nPermutation Constraints. A distinct constraint over {v1, . . . , vn} where U = ⋃n i=1 img(vi) and |U | = n induces a permutation on the variables. Let c be the constraint atom representing this global constraint. In this special case, we can add the rules\n← c,∼eq(v1, d), . . . ,∼eq(vn, d) for all d ∈ U.\nThese rules enforce that each value is taken at least once.\nFor example, given a distinct constraint over {v1, v2, v3} with D(vi) = {1, . . . , 3} for 1 ≤\ni ≤ 3 we add the rules\n← c,∼eq(v1, 1),∼eq(v2, 1),∼eq(v3, 1)\n← c,∼eq(v1, 2),∼eq(v2, 2),∼eq(v3, 2)\n← c,∼eq(v1, 3),∼eq(v2, 3),∼eq(v3, 3)\nThis feature introduces direct encoding atoms along with the respective rules and order atoms in (22). Since these atoms cannot be treated lazily, this feature is disabled by default but can be controlled using the option --distinct-permutation.\nSorting. Sorting constraints by descending coefficients is known to avoid redundant nogoods in the translation process (Tamura et al. 2013). Also, systems like sugar sort constraints by smallest domain first, and when tied, with largest coefficient. clingcon can either sort by coefficient or domain size first, in decreasing or increasing order. The option --sort-coefficient controls the sorting of the constraints.\nSplitting Constraints. Considering that directly translating a linear constraint a1v1 + · · · + anvn ≤ b with the order encoding leads to an exponential number of nogoods, we split long constraints into shorter ones by introducing new variables. Thereby we adapt the heuristics of sugar. We only split a constraint if the number of variables is greater than α and if its translation produces more than β nogoods. If both conditions hold, we recursively split a constraint into α parts. The new constraints have the form akvk + · · ·+ alvl = vkl where 1 ≤ k ≤ l ≤ n. α and β are freely configurable. By default, splitting is disabled in clingcon, but α and β can be changed with options --split-size and --max-nogoods-size.\nSymmetry Breaking. When splitting a constraint like a1v1 + a2v2 + a3v3 ≤ b, we get the constraints a1v1 + a1v2 = v 1 2 and v 1 2 + a3v3 ≤ b. Equations like a1v1 + a1v2 = v 1 2 are represented as conjunctions of a1v1 + a1v2 ≤ v12 and a1v1 + a1v2 ≥ v 1 2 . By dropping the latter inequality, we obtain an equi-satisfiable set of constraints being smaller than before but admitting more (symmetric) solutions, as v12 freely varies. Symmetry breaking should therefore be enabled if one wants to enumerate all solutions without duplicates. This form of symmetry breaking is usually skipped in SAT-based CSP solvers like sugar. This option is set via --break-symmetries.\nDomain Propagation. To create the domain of variables like v1n in the aforementioned constraints of form a1v1 + · · · + anvn = v1n, we may use bound propagation. For example, the constraint 42x + 1337z = y where D(x) = D(z) = {0, 1} results in the domain D(y) = {42 · lb(x) + 1137 · lb(z), . . . , 42 · ub(x) + 1137 · ub(z)} = {0, . . . , 1379}. Using domain propagation instead leads to the much smaller domain D(y) = {42dx + 1137dz | dx ∈ D(x), dz ∈ D(z)} = {0, 42, 1337, 1379}. However, we restrict domain propagation to preprocessing by default, as it has an exponential runtime. clingcon allows for controlling domain propagation by setting a threshold on the domain size; this is set by option --domain-size.\nTranslate Constraints. Following a two-fold approach, clingcon is able to translate some constraints while leaving others to constraint propagators as shown in Section 3.3. clingcon provides the option --translate-constraints=m to decide which constraints to translate or not.\nThe translation depends on the estimated number of nogoods ∏n−1\ni=1 |D(vi)| that Algorithm 1 pro-\nduces for a constraint a1v1 + · · ·+ anvn ≤ b. If this number is below the threshold m, clingcon translates the constraint. Also all order atoms used in these nogoods are created.\nRedundant Nogood Check. A nogood δ is said to be stronger than a nogood δ′, iff for all literals (v > d)‡ ∈ δ, there exists a literal (v > d′)‡ ∈ δ′ such that d ≤ d′ and v is a view. Whenever a nogood is created in Line 7 in Algorithm 1, we compare it to the previously created one. If one of them is stronger, we only keep the stronger one, otherwise, we keep both. This feature allows clingcon to remove some redundant nogoods during the translation process. It is especially useful if the constraints are not sorted by descending coefficients. The check just adds constant overhead to the translation process but avoids creating a significant amount of nogoods. For instance, translating the famous send more money problem results in 628 nogoods among which 327 are redundant, when using --split-size=3. This feature can be triggered using option --redundant-nogood-check.\nDon’t Care Propagation. Suppose we want to express that (x > 7) should hold whenever a holds; otherwise we do not care whether (x > 7) holds or not. A corresponding constraint logic program is given in the first row of Table 2 together with its constraint stable models. In the standard case for CASP, the constraint atom is reified with its constraint via T(x > 7) ⇔ x > 7. In the case that a is true, the constraint atom (x > 7) has to be true. The reification ensures that x is greater than 7, leading to three different assignments {{x 7→ d} | d ∈ {8, . . . , 10}} for variable x. In the case that a is false, the constraint atom (x > 7) can either be true or false. The first case results in the same three assignments, while the latter corresponds to seven others, viz. {{x 7→ d} | d ∈ {1, . . . , 7}}, as the reification imposes that the constraint x > 7 does not hold, basically enforcing x ≤ 7. We note that in case a is false, the constraint imposed on x is either x > 7 or x ≤ 7. This means that there is actually no restriction on the assignment of x. We exploit this observation by replacing (x > 7) with a new constraint atom (x > 7)′ and adding the rule ← ∼a, (x > 7)′. The idea is that atom (x > 7)′ imposes (x > 7) as a half-reified constraint, meaning that x is enforced to be greater than 7 only if the constraint atom (x > 7)′ is true, i.e. T(x > 7)′ ⇒ x > 7. We obtain exactly the same stable models in terms of the regular atoms and integer variable assignments, as depicted in the second row of Table 2. The difference between these two programs lies in the assignment of the constraint atoms. The additional rule ← ∼a, (x > 7)′ ensures that the constraint atom (x > 7)′ is false, whenever a is false. Since we connect the constraint atom with its constraint using a half-reified constraint, this constraint has no effect on the assignment of x, resulting in {{x 7→ d} | d ∈ {1, . . . , 10}}. Although the\nnumber of constraint stable models stays the same, the number of different Boolean assignments is reduced.\nThis technique is called Don’t Care Propagation (Thiffault et al. 2004). All constraint atoms that only occur in integrity constraints and only positively (negatively) in the whole program are don’t care atoms. clingcon fixes the truth value of don’t care atoms to false (true), if all integrity constraints containing the atom have at least one literal being false under the current assignment. Don’t care propagation can be useful in SAT, but it has even more potential to be helpful in CASP/SMT, since we not only reduce the search space but also the theory propagator has to handle only one half-reified constraint per don’t care atom. This means only half of the inferences have to be checked. This technique is not specifically designed for CSP but it can also be used for other theories. Don’t care propagation is controlled using the option\n--dont-care-propagation.\nOrder Atom Generation. When translating a constraint, all order atoms for all its integer variables must be available. By not translating all constraints, we also do not need to create all order atoms. Some of them can be created on the fly during propagation. With this in mind, it might still be useful to create a certain number of order atoms per variable in a preprocessing step. clingcon can create n atoms evenly spread among the domain values of a variable v. So if we have a domain D(v) = {1, . . . , 10, 90, . . . , 100} and create four order atoms we use (v ≤ 3), (v ≤ 8), (v ≤ 92) and (v ≤ 97). These order atoms allow the solver to split the domain during the search. Option --min-lits-per-var=n adds at least min(n, |D(v)| − 1) order atoms for each variable v.\nExplicit Binary Order Nogoods. Some order atoms are created before solving. Therefore, it can also be beneficial to create a subset of the order nogoods Φ′(V , D) in advance, as shown in Corollary 2.1. Given that we created the set of order atoms {(v ≤ x1), . . . , (v ≤ xn)} for a variable v ∈ V where xi < xi+1 for 1 ≤ i ≤ n, the explicit order nogoods\n{{Tv ≤ x1,Fv ≤ x2}, . . . , {Tv ≤ xn−1,Fv ≤ xn}}\ncan also be created. To introduce these binary order nogoods for all order atoms that have been created before the solving process, the option --explicit-binary-order can be used.\nObjective Functions. We support multi-objective optimization on sets of views. For all views av + c subject to minimization, we use the signed order literals (av + c ≥ d)‡ with weight {\nd− prev(d, av + c) if d > lb(av + c)\nd if d = lb(av + c)\nfor all values d ∈ img(av+c) in an ASP minimize statement. This minimizes the total sum of the set of views. By using nativeASP minimize statements, clingcon reuses clasp’s branch and bound and unsatisfiable core based techniques (Andres et al. 2012). For instance, for minimizing 3x where D(x) = {1, 3, 7}, we have the following weighted literals in the (internal) ASP minimize statement (3x ≥ 3)‡ = 3, (3x ≥ 9)‡ = 6, and (3x ≥ 21)‡ = 12. In terms of ASP-pseudo-code this amounts to a minimize statement of form#minimize{6 : ∼x ≤ 1; 12 : ∼x ≤ 3} although order literals are not part of the input language. (3x ≥ 3)‡ evaluates to true, while (3x ≥ 9)‡ and (3x ≥ 21)‡ can be expressed via order literals as ∼(x ≤ 1) and ∼(x ≤ 3), respectively.\nFlattening Objective Functions. Minimizing the value of an integer variable y that is included in a constraint γ(σ) = a1v1 + · · · + anvn = y where σ is true, is equivalent to minimizing the value of a1v1 + · · · + anvn. Directly using the views aivi strengthens the nogoods used to represent the minimize statement. The constraint a1v1 + · · ·+ anvn = y can be removed if y is not used anywhere else.15 In fact, this pattern occurs quite often in our minizinc benchmark set. Replacing variable y with its constituents a1v1 + · · · + anvn can be controlled with the option\n--flatten-optimization.\nReduced Nogood Learning. Whenever CSPPROPAGATION in Algorithm 3 and 4 derives a nogood, it is possible to not add it to the store of learned nogoods∇ but rather keep it implicit and only add it if it is really needed for conflict analysis. The internal interface of clasp supports such a behavior. While the learned nogoods ∇ improve the strength of unit propagation, too many nogoods decrease its performance. Therefore, lazily adding these nogoods when they are actually needed can improve unit propagation. To disable the storage of nogoods and handle them implicitly, clingcon provides option --learn-nogoods."
    }, {
      "heading" : "3.5 Multi-Shot CASP Solving",
      "text" : "As mentioned, a major design objective of clingcon 3 is to transfer clingo’s functionalities to CASP solving. A central role in this is played by multi-shot solving (Gebser et al. 2014; Gebser et al. 2015) because it allows for casting manifold reasoning modes. More precisely, multi-shot solving is about solving continuously changing logic programs in an operative way. This can be controlled via reactive procedures that loop on solving while reacting, for instance, to outside changes or previous solving results. These reactions may entail the addition or retraction of rules that the operative approach can accommodate by leaving the unaffected program parts intact within the solver. This avoids re-grounding and benefits from heuristic scores and nogoods learned over time.\nTo extend multi-shot solving to CASP, our propagators allow for adding and deleting constraints in order to capture evolving CSPs. Evolving constraint logic programs can be extremely useful in dynamic applications, for example, to:\n• add new resources in a planning domain, • set the value of an observed variable measured using sensors, • add restrictions to reduce the capacity of containers, or • increase their capacity depending on other systems like weather forecast etc.\nThe presented propagators provide means for all these issues. New resources can be added using additional constraint variables and domains. Values can be limited by adding constraints and rules to the constraint logic program. Due to our monotone treatment of CSPs in CASP, it is always possible to add new constraint atoms. Since they are not allowed to occur in rule heads they to not interfere with the completion of the logic program. Hence, we can combine (and therefore extend) two constraint logic programs under exactly the same restrictions that apply to normal logic programs (cf. (Gebser et al. 2014)).\nWhile confining variables is easy, accomplished by adding constraints on those variables, increasing their capacity is addressed via lazy variable generation. That is, we start with a virtually\n15 We keep the constraint to be able to correctly print y in a solution.\nmaximumdomain that is restrained by retractable constraints. The domain is then increased by relaxing these constraints. Importantly, the order atoms representing the active domain are only generatedwhen needed. This avoids introducing a large amount of atoms, especially in the non-active area of the domain. As an example, consider the variable x and its domainD(x) = {1, . . . , 109} having one billion elements. By adding the constraint x ≤ 10, only the first 10 values are valid assignments. After retracting x ≤ 10 and adding x ≤ 20, only the first 20 values constitute the search space. Since order atoms are only introduced in the actual search space, no atoms are introduced for the huge amount (109− 20) of other values. Using this technique, CASP can deal with increasing domains within reasonable space.\nFor illustration, let us consider the well-known n-queens puzzle for demonstrating how to incrementally add new constraints and constraint variables to a constraint logic program and how to remove constraints from it. To illustrate how seamlessly clingcon integrates CASP and multi-shot solving, we apply clingo’s exemplary Python script for incremental solving to model different incremental versions of the n-queens puzzle in CASP. Multi-shot solving in clingo relies on two directives (Gebser et al. 2014), the #program directive for regrouping rules and the #external directive for declaring atoms as being external to the program at hand. The truth value of such external atoms is set via clingo’s API. Clingo’s incremental solving procedure is provided in Python and loops over increasing integers until a stop criterion is met. It presupposes three groups of rules declared via #program directives. At step 0 the programs named base and check(n) are ground and solved for n = 0. Then, in turn programs check(n) and step(n) are added for n > 0 and the obtained program is grounded and solved. Other names and components are definable by appropriate changes to the Python program. Stop criteria can be the satisfiability or unsatisfiability of the respective program at each iteration. In addition, at each step n an external atom query(n) is introduced; it is set to true for the current iteration n and false for all previous instances with smaller integers than n. Although we reproduce the exemplary Python program from clingo’s example pool in Listing 4, we must refer the reader to (Gebser et al. 2014) for further details.\nThe CASP encoding of the incrementaln-queens puzzle in Listing 5 demonstrates the addition and removal of constraints and also shows how variable domains are dynamically increased. As usual, the goal is to put n queens on an n × n board such that no two queens threaten each other. Here, however, this is done for an increasing sequence of integers n such that the queens puzzle for n is obtained by extending the one for n− 1. While the first line of Listing 5 includes the Python program in Listing 4, the next one includes the grammar from Listing 1. Line 3 suppresses the output of regular atoms. The remaining encoding makes use of two features of clingo’s exemplary incremental solving procedure, viz. subsequently grounding and solving rules regrouped under program step(n) and the external atom query(n).16 In Listing 5, all rules in lines 7-17 are regrouped under subprogramstep(n). The Python program in Listing 4makes clingcon in turn solve the empty program, then program step(1), then program step(1) and step(2) together, then both former programs and step(3), etc. This is done by keeping the previous programs in the solver and by replacing parameter n in lines 7-17 with the respective integer when grounding the added subprogram. Thus, at each step n a fact ‘pos(n).’ is added\n16 Strictly speaking, Line 1-3 belong to the program base that is treated once at the beginning (cf. Listing 4 and (Gebser et al. 2014) for details).\n1 #script (python)\n3 import clingo\n5 def get(val, default): 6 return val if val != None else default\n8 def main(prg): 9 imin = get(prg.get_const(\"imin\"), clingo.Number(0))\n10 imax = prg.get_const(\"imax\") 11 istop = get(prg.get_const(\"istop\"), clingo.String(\"SAT\"))\n13 step, ret = 0, None 14 while ((imax is None or step < imax.number) and 15 (step == 0 or step < imin.number or ( 16 (istop.string == \"SAT\" and not ret.satisfiable) or 17 (istop.string == \"UNSAT\" and not ret.unsatisfiable) or 18 (istop.string == \"UNKNOWN\" and not ret.unknown)))): 19 parts = [] 20 parts.append((\"check\", [step])) 21 if step > 0: 22 prg.release_external(clingo.Function(\"query\", [step-1])) 23 parts.append((\"step\", [step])) 24 prg.cleanup() 25 else: 26 parts.append((\"base\", [])) 27 prg.ground(parts) 28 prg.assign_external(clingo.Function(\"query\", [step]), True) 29 ret, step = prg.solve(), step+1 30 #end.\n32 #program check(t). 33 #external query(t).\nListing 4: Incremental mode of Clingo\nto the solver (cf. Line 7). The heads of Line 9 and 10 represent the linear constraints\nq(n) > 0 and q(x) ≤ n for x ∈ {1, . . . , n} .\nAt each step n, the integer variable q(n) is introduced and required to be a positive integer. Moreover, all integer variables q(1) to q(n) are required to take values less or equal than n. However, while the former constraint is unconditional, the latter are subject to the external atom query(n). The functioning of Listing 4 ensures that only query(n) is true while query(s) is false for all s < n. In this way, the domain of all constraint variables q(1) to q(n) is increased by one at each step. Lines 12-15 in Listing 4 add distinct constraints to the effect that no two queens can be placed on the same row or diagonal of the board. Line 17 simply instructs clingcon to add q(n) to the output constraint variables.\nIn the following, we detail the grounding process for this example. The base program simply consists of the first 3 lines of the original encoding. Afterwards, program step(1) is grounded, adding the first constraints of the problem. The result is shown in Listing 6. The first variable q(1) is introduced and its lower bound is fixed to 1 in Line 3. Its upper bound is also restricted to 1 but here only if query(1) holds. This is only the case of n=1 when solving program step(1) (Line 4). In all subsequent cases, query(1) is false, and hence q(1) ≤ 1 is not imposed anymore. Accordingly, the atom &sum{q(1)} <= 1 can vary freely (since it is an external constraint atom). Don’t care propagation, described in Section 3.4, addresses such atoms and removes them from the system.\nAs solving the 1-queen problem is uninteresting, the second solving step adds program\n1 #include \"incmode.lp\". 2 #include \"csp.lp\". 3 #show.\n5 #program step(n).\n7 pos(n).\n9 &sum{ q(n) } > 0.\n10 &sum{ q(X) } <= n :- pos(X), query(n).\n12 &distinct{ q(X) : pos(X) }.\n14 &distinct{ q(X)+X-1 : pos(X) }. 15 &distinct{ q(X)-X+1 : pos(X) }.\n17 &show{ q(n) }.\nListing 5: Incremental n-queens encodingQ1 (incqueens.lp)\n1 pos(1).\n3 &sum{ q(1) } > 0. 4 &sum{ q(1) } <= 1 :- query(1).\n6 &distinct{ q(1) }.\n8 &distinct{ q(1) }. 9 &distinct{ q(1) }.\n11 &show{ q(1) }.\nListing 6: Grounded incremental n-queens program step(1).\nstep(2) shown in Listing 7. We are now solving the second step and query(1) is no longer true, which amounts to removing the rule from Line 4 in Listing 6. The new step adds two rules for this instead (lines 4-5) and restricts all variables to be less than or equal 2. Also, additional distinct constraints are added involving q(2). The next step again removes the rules in lines 4-5 by making query(2) false and adds a new restriction (lines 4-6 in Listing 8). In this way, we not only add new variables at each step, but also increase the upper bounds of existing ones. For solving the third step, the grounded rules of all three steps are taken together, only query(3) is set to true, and all previously added instances of query/1 are false.\nListing 9 shows a run of Listing 5 up to 10 steps. Setting the stop criterion to UNKNOWNmakes\nsure that the process neither terminates upon satisfiable nor unsatisfiable result.\nA closer look at the distinct constraints in lines 12 to 15 of Listing 5 reveals quite some redundancy. This is because the constraints added at each step supersede the ones added previously, and they all coexist in the system. For example, at Step 3 the system contains 3 instances of Line 12, namely &distinct{q(1)}, &distinct{q(1),q(2)},\n1 pos(2).\n3 &sum{ q(2) } > 0. 4 &sum{ q(1) } <= 2 :- query(2). 5 &sum{ q(2) } <= 2 :- query(2).\n7 &distinct{ q(1), q(2) }.\n9 &distinct{ q(1), q(2)+1 }. 10 &distinct{ q(1), q(2)-1 }.\n12 &show{ q(2) }.\nListing 7: Grounded incremental n-queens program step(2).\n1 pos(3).\n3 &sum{ q(3) } > 0. 4 &sum{ q(1) } <= 3 :- query(3). 5 &sum{ q(2) } <= 3 :- query(3). 6 &sum{ q(3) } <= 3 :- query(3).\n8 &distinct{ q(1),q(2),q(3) }.\n10 &distinct{ q(1), q(2)+1, q(3)+2 }. 11 &distinct{ q(1), q(2)-1, q(3)-2 }.\n13 &show{ q(3) }.\nListing 8: Grounded incremental n-queens program step(3).\nand &distinct{q(1),q(2),q(3)}. Clearly, the first two constraints are redundant in view of the third but remain in the system. To avoid this redundancy, we can make use of the external atom query(n) to remove the redundant distinct constraints at each step in the same way we tighten the upper bound of variable domains. This amounts to replacing lines 12-15 in Listing 5 with the ones given in Listing 10 below.\n12 &distinct{ q(X) : pos(X)} :- query(n).\n14 &distinct{ q(X)+X-1 : pos(X)} :- query(n). 15 &distinct{ q(X)-X+1 : pos(X)} :- query(n).\nListing 10: Retracting Constraints, encodingQ2\nAlthough the last modification guarantees that the system bears no redundant distinct constraints,17 it leads to adding and removing the same restrictions over and over again. For example, the constraint that q(1) and q(2) must have different values is included in every distinct constraint after step 1. And this information is retracted and re-added at each\n17 Given that don’t care propagation is enabled by default.\nstep. This is avoided by the constraints in Listing 11. This formulation only adds constraints for the new variable q(n) at each step n and stays clear from retracting any constraints.\n12 &sum{ q(X) } != q(n) :- X=1..n-1.\n14 &sum{ q(X)+X-1 } != q(n)+n-1 :- X=1..n-1. 15 &sum{ q(X)-X+1 } != q(n)-n+1 :- X=1..n-1.\nListing 11: Partial Constraints, encodingQ3\nTable 3 gives a comparison of the three different encodings for the incremental n-queens problem for 30 steps. The first row gives the respective total running time. The second one reports the total number of introduced atoms. The third one gives the sum of static nogoods generated at each step, and the last one the sum of dynamic nogoods generated by lazy constraint propagation. We observe that the initial encoding Q1 performs worst in all aspects. The inherent redundancy ofQ1 is reflected by the high number of dynamic nogoods generated by the constraint propagator.\nThis is the source of its inferior overall performance. Unlike this, the two alternative approaches bear less redundancy, as reflected by their much lower number of dynamic nogoods. In Q2, this is achieved by eliminating duplicate inferences from redundant constraints. Although Q3 even further reduces the number of atoms as well as static and dynamic nogoods, its runtime is slightly inferior. This is arguably due to the usage of elementary linear constraints rather then global distinct constraints (and the pigeon hole constraints which are enabled by default)."
    }, {
      "heading" : "4 Experiments",
      "text" : "In this section, we evaluate the afore-presented features and compare clingconwith other systems. We performed all our benchmarks on an Intel Xeon E5520 2.27GHz processor with Debian GNU/Linux 7.9 (wheezy). We used a timeout of 1800 seconds and restricted main memory to 6GB. In all tests, we count a memory out as a timeout. The experiments are split into three sections. First, we evaluate the presented features and discuss corresponding configurations of clingcon. Second, we compare clingcon with state of the art CP solvers using the benchmark classes of the minizinc competition 2015. And finally, we contrast clingcon with other CASP systems using different CASP problems.\nTo evaluate the presented techniques, we give a comprehensive comparison in Table 5. To concentrate on the CP techniques of clingcon 3.2.0, we use the CP benchmarks of the minizinc competition 2015.18 We removed the benchmark classes large scheduling and project planning as they cannot be translated into the flatzinc format without the use of special global constraints. For all other classes, we used the mzn2fzn19 toolchain to convert all instances to flatzinc while removing all non-linear and global constraints except for distinct. This functionality is provided\n18 http://www.minizinc.org/challenge2015/challenge.html 19 http://www.minizinc.org/software.html\nby mzn2fzn, which translates non-supported constraints away. We use the standard translation provided bymzn2fzn to be able to handle all benchmark classes. In this way, even problems using constraints on sets, non-linear equations, or complex global constraints can be handled by solvers restricted to basic linear constraints. For making this benchmark suite available to the CASP community, we build a converter from flatzinc to the aspif format (Gebser et al. 2016b) used by clingcon; it is called fz2aspif.20 To evaluate the different features, we modified the scoring system of the minizinc competition, which is based on the Borda count evaluation technique. On a per instance basis, a configuration gets one point for every other configuration being worse. A configuration is considered worse, if either the found optimization value is at least 1% lower, or if it has the same optimization value but is slower. A configuration is considered slower if it is at least 5 seconds slower. Classes marked with * are decision problems (all others are optimization problems); classes containing the global distinct constraint are marked with †. We have exactly five instances per class.\nThe following discussion refers to the results shown in Table 5. The columns used for comparison are named in the paragraph heading. ColumnD presents the default configuration of clingcon given in Table 4. All other listed configurations differ only in one or two options from this default in order to test specific techniques. For instance, for evaluating equality processing, we compare default configuration D , using equality processing, with configuration NE , disabling equality processing. Thus, except for --equality-processing, all other options remain unaltered.\nEquality Processing (D , NE ) To evaluate the influence of equality processing, we compare\ndefault configuration D (with equality processing) with configuration NE (without equality processing). This feature improves performance on nearly all benchmark classes significantly. By simply removing constraints and variables the underlying CSP gets easier to solve (no matter if it is solved by translation or propagators).\nDistinct Translation (D , DT ) Translating global distinct constraints into cardinality rules pre-\nvents order atoms from being created lazily. The default configurationD translates them into a set of inequalities. The translation using cardinality constraints in columnDT performs better on cvrp, open-stacks, and p1f, while it performs worse on the benchmark class costas. As long as the domain size is small, this feature can be useful for problems using distinct constraints. The configurationDT performs best of all tested configurations.\nPigeon Hole Constraints (D , NP ) Since pigeon hole constraints add only constant overhead\nin the number of nogoods, they are enabled in configuration D . Disabling their addition, slightly increases performance on benchmark classes containing distinct constraints (marked with †), as witnessed in columnNP . Although these constraints have no positive effect on the benchmarks at hand, we keep this feature enabled by default since it increases propagation strength.\nPermutation Constraints (D , PO) Unlike pigeon hole constraints, permutation constraints in-\ntroduce direct encoding atoms which prevents lazy variable generation for some constraint variables. This is the reason why this feature is disabled by default in configuration D . We enabled it in column PO . Again, this feature only influences benchmark classes containing distinct constraints. It improves performance for the cvrp class but decreases it on the other classes. The impact of this feature depends upon the respective problem.\n20 https://potassco.org/labs/2016/12/02/fz2aspif.html\nSorting (D , SC ) As we cannot account for all combinations of sorting mechanisms, we eval-\nuate this feature only on the cases discussed in (Tamura et al. 2013). Default configuration D implements the one in sugar; it sorts by smallest domain first and prefers on ties larger coefficient. The alternative sorting recommended in (Tamura et al. 2013) first sorts on larger coefficients and afterwards uses the smaller domain. This behavior is enforced by setting\n--sort-coefficient=true and reflected in column SC . We see that both sorting meth-\nods yield a similar performance when applied to our lazy nogood generating approach.\nSplitting Constraints (D , SP , T4 , ST ) Splitting constraints into smaller ones is manda-\ntory for any translation-based approach using the order encoding to avoid an exponential number of nogoods. We restricted our evaluation to a splitting size of 3, as done in sugar. The default configuration D of clingcon does not split any constraints. The effect of splitting constraints into ternary ones (--split-size=3) is reflected by column SP ; it performs poorly in our lazy nogood generating setting because it introduces many new constraints and variables. On the other hand, when translating all constraints (--translate-constraints=-1) as shown in column T4 , the split into constraints of up to three variables (--translate-constraints=-1 and --split-size=3) increases performance significantly, as witnessed by column ST . We conclude that splitting constraints is not necessary for lazy nogood generating solvers but essential for translational approaches that use the order encoding. Symmetry Breaking (SP , NS ) Splitting constraints introduces auxiliary variables that may\nlead to redundant solutions. Symmetry breaking eliminates such redundancies and has only an effect when splitting constraints. This is why it is interesting to compare column SP (--split-size=3) where symmetry breaking is enabled with column NS (--split-size=3 and --break-symmetries=false) where it is disabled. In both cases, all constraints are split into ternary ones. The additional constraints remove symmetric solutions from the search space and therefore seem to be beneficial, especially on classes tdtsp, radiation, and mapping. Domain Propagation (D1 , D2 , SP , D3 ) To investigate the impact of domain propagation dur-\ning preprocessing, we tested four different configurations that all split constraints into ternary ones (--split-size=3). They only differ in using the options --domain-size=0 (no domain propagation) in column D1 , --domain-size=1000 in column D2 ,\n--domain-size=10000 in column SP , and --domain-size=-1 (unlimited domain\npropagation) in column D3 . We observe that unlimited domain propagation reduces performance in benchmark class triangular but has no significant influence otherwise. The other tested configurations have no influence on the runtime of the benchmarks. We assume that domain propagation prunes the domains not enough to make a considerable difference. For the default configuration of clingcon, we decided to restrict it to a reasonable number (10000) which leaves it enabled for mid-sized domains. Translate Constraints (T1 , T2 , D , T3 , T4 ) We have already seen that translating all con-\nstraints as shown in column T4 is not very beneficial. Now, we evaluate whether the translation of “small” constraints improves performance through a mixture of “translating small constraints” and “handling larger ones lazily”. Therefore, we compare the results obtained with option --translate-constraints=0 (no constraints are translated) in columnT1 , with T2 where --translate-constraints=1000 (translate constraints that produce up to 1000 nogoods) is used, with D using --translate-constraints=10000 (up to 10000 nogoods), with T3 using --translate-constraints=50000 (up to 50000\nnogoods), andT4 using --translate-constraints=-1 (all constraints are translated). There is a trade-off on the size of constraints to translate. While translating small constraints (constraints that produce up to 1000 nogoods) improves performance, the translation of larger constraints decreases it again. On some benchmarks, like triangular and p1f, translating no constraints is beneficial. Also, translating all constraints in T4 performs worst of all tested configurations.\nRedundant Nogood Check (ST , NR) To evaluate this feature, we decided to translate all con-\nstraints (--translate-constraints=-1). Since this configuration is not producing good results for a comparison (most of the time the translation is simply too large to be finished), we additionally split the constraints into ternary ones with option --split-size=3. With this, we compare the configurationwith redundancy check in column ST withNR where redundancy checking is disabled (--redundant-nogood-check=false). The redundant nogood check is fast and simply removes redundant nogoods from the order encoding. Benchmark classes like costas and cvrp perform better with the reduced set of nogoods, while redundant nogoods are beneficial for gfd-schedule and radiation.\nDon’t Care Propagation (D , ND) is enabled by default and removes unnecessary implica-\ntions from the problem. Disabling this feature (--dont-care-propagation=false) in column ND decreases performance.\nOrder Atom Generation (M1 , D , M2 , M3 ) Adding order atoms lazily is mandatory to\nhandle large domains. We now evaluate the effect of adding a small amount of order atoms eagerly for every constraint variable, evenly spread among its domain values. Therefore, we compare column M1 using --min-lits-per-var=0 (adding no atoms), with D using --min-lits-per-var=1000 (adding 1000 order atoms per variable), with M2 using --min-lits-per-var=10000 (adding 10000), and M3 using\n--min-lits-per-var=-1 (adding all order atoms). Adding no order atoms in advance\ndrastically reduces performance of the system while adding 1000 to 10000 order atoms achieves best performance. When adding too many or even all order atoms before solving, performance is again decreased, especially on classes with large domains like zephyrus. Also, note that the tested benchmark classes are very sensitive to this option as adding atoms beforehand may influence the heuristic of the search.\nFlattening Objective Functions (D , NF ) is a feature well received by this benchmark set. All\nflatzinc encodings contain only one variable subject to minimization. On most benchmark classes this variable simply represents the sum of a set of variables. Adding this set directly to the objective function avoids adding an unnecessary and probably large constraint and also improves propagation strength of the learned nogoods. Unlike D , configuration NF disables this feature via --flatten-optimization=false. We observe that flattening the optimization statement increases the performance on many benchmark classes.\nLazy Nogood Generation (P1 , P2 , P3 , D) We now evaluate the four afore-described prop-\nagation strengths where --prop-strength=1 is reflected by the results in column P1 ,\n--prop-strength=2 by the ones in column P2 , --prop-strength=3 in column P3 ,\nand --prop-strength=4 in the default configuration D . We see that a high propagation strength is important. Especially propagating changed bounds with --prop-strength=3 is necessary for many benchmark classes. Interestingly, less propagation performs best for the classes knapsack and triangular where constraint propagation is not dominating the search but still takes time. On these classes, configurations with propagation strength 1 or 2 spend less\ntime on CSPPROPAGATION() and more on pure CDCL search, as attested by a much higher number of choices. Explicit Binary Order Nogoods (D , EO) Default configurationD does not introduce explicit\nbinary order nogoods Φ(V , D) but uses a propagator for capturing the corresponding inferences lazily. The option --explicit-binary-order=true (reflected by column EO ) creates these nogoods explicitly for all order atoms created during preprocessing, leaving the others subject to lazy nogood propagation. Although, overall performance of the implicit binary order nogoods is better, for some benchmark classes like cvrp and spot5 using binary order nogoods explicitly is the best choice. This is one of the options for which it is hard to find a clear cut default setting and that needs consideration for each benchmark class. Reduced Nogood Learning (D , RL) clingcon’s default configuration D adds all nogoods re-\nturned by CSPPROPAGATION to the set of learned nogoods (viz. ∇ in Algorithm 3). Lazily adding these nogoods when they are actually needed for conflict analysis is achieved with\n--learn-nogoods; the results are shown in column RL. The average performance of\nadding nogoods lazily is inferior to the one obtained by learning all nogoods. Nevertheless, the latter setting performs best on costas and nmseq, the two decision problems in our benchmark set. Future work has to investigate which of the nogoods have to be learned and which of them can be added lazily.\nConfigurationDT is the configuration with the highest overall score. Nevertheless, clingcon’s default configuration is more conservative since it allows for using lazy variable generation in all cases. For instance, with configuration DT it is impossible to run the multi-shot n-queens example presented in Section 3.5, because 230 order atoms had to be created per queen in order to use cardinality constraints for the distinct constraint.\nNext, we compare clingcon to state of the art CP solvers on the same set of benchmarks with the same scoring system. The second column of Table 6 shows configuration DT of clingcon 3. This is the best configuration of the internal comparison in Table 5, which is obtained using the command line option --distinct-to-cardinality=true. We compare it to g12fd (Mercury FD Solver), which is the G12 FlatZinc interpreter’s default solver, taken from the minizinc 2.0.11 package.21 Furthermore, we have taken gecode 4.4.0,22 a well-known classical CP solver. Also, the lazy clause generating solvers minisatid 3.11.0 (De Cat et al. 2013)23 as well as chuffed,24 the best solver of the minizinc competition 2015.25 Finally, we compare to picatsat 2.0,26 a CP solver that won the second place at the minizinc competition 2016 by translating constraints into SAT using a logarithmic encoding. We ran g12fd and gecode with\n--ignore-user-search to disable any special heuristic given in the problem encodings for\nall solvers. In the competition, this is called “free search”. To measure the core performance of the systems, it is most instructive to consider chuffed′ and picatsat′ which use the two solvers on exactly the same set of constraints as clingcon. Hence, all non-linear and global constraints (except distinct) are translated using mzn2fzn in the same way for all systems. 27\n21 http://www.minizinc.org/software.html 22 http://www.gecode.org 23 With some bugfixes. Special thanks to Bart Bogaerts for his great support on this work. 24 https://github.com/geoffchu/chuffed— SHA 5b379ed9942ee59e8684149eae3fec1af426f6ee 25 It did not participate in the ranking as it is was entered by the organizers. It ran outside of competition and was faster\nthan the winning system. 26 http://picat-lang.org 27 Unfortunately, we were unable to compare to the lazy clause generating system g12lazy, as it produced wrong results\nThe results in Table 6 show that clingcon28 outperforms established systems such as g12fd, gecode, minisatid, and even picatsat. There are also different benchmark classes where solvers dominate each other and vice versa. We point out that gecode has special propagators for many non-linear and global constraints that have been used in the benchmarks. Also chuffed, as a lazy clause generating solver, has propagators for many other constraints and can therefore handle some of the benchmark classes much better. As we are building a CASP system, we refrain from supporting a broad variety of global constraints, as some of them can be modeled in ASP. So for a better comparison on the features of clingcon, we translated all non-linear and global constraints except for distinct in the columns chuffed′ and picatsat′ into linear ones. Here, we see that these systems profit from the dedicated treatment of global constraints but that the base performance of clingcon is comparable. In general, clingcon does not match the performance of the best solver of the minizinc competition 2015 but on benchmark classes like freepizza, grid-colour, opd, knapsack, and spot5, it even outperformed chuffed. We conclude that clingcon, despite being a CASP system, is at eye level with state of the art CP solvers but cannot top the best lazy clause generating systems.\nFinally, we compare clingcon against six other CASP systems.\n• inca (Drescher and Walsh 2010) with the option --linear-bc,29 a lazy nogood gener-\nating system not supporting lazy variable generation.\n• clingcon 2 (Ostrowski and Schaub 2012), using gecode 3.7.3 as a black-box CP solver.\non some of the benchmarks and is no longer maintained. We were also unable to convert the competition benchmarks to a format readable by sugar, as existing converters are outdated and not compatible anymore. 28 Note that the Borda Count scores are relative to the compared systems, and therefore are different for the same configuration of clingcon in Table 5 and 6. 29 This option was recommended by the authors of the system for these kind of benchmarks.\n• ezcsp 1.6.24 (Balduccini and Lierler 2013), also pursuing a black-box approach but using\nCP solver B-Prolog 7.4 with ASP solver clasp.\n• aspartame (Banbara et al. 2015), a system using an eager translation of the constraint part\nby means of an ASP encoding.\n• ezsmt 1.0.0 (Lierler and Susman 2016), translating CASP programs to SMT, solved by\nSMT solver z3 4.2.2.\n• clingo 5.1.0, a pure ASP solver to measure the influence of the CP part on solving.\nThe first benchmark class is the two dimensional strip packing problem (Soh et al. 2010); its encoding is shown in Listing 2. In Table 7, column clingo 5 reflects the results obtained with a highly optimized ASP encoding, using a handcrafted order encoding. Time is given in seconds, letting - denote a timeout of 1800 seconds. The best objective value computed so far is given in the columns headed with opt. For aspartame, we have taken an encoding provided in (Banbara et al. 2015). For the other systems such as clingcon 2, clingcon 3, and inca, we adjusted the syntax for the linear constraints. We refrained from comparing with ezcsp or ezsmt as both systems are not supporting optimization of integer variables. The bottom row counts the number of times a system performed best. We clearly see that clingcon 2 is outperformed even by the manual ASP encoding. The new clingcon 3 system performs best. The translational approach of aspartame is close to the inca system, and both perform better than the manual ASP approach. According to (Soh et al. 2010), these results are in accord with dedicated, state of the art systems.\nThe next benchmark classes are incremental scheduling, weighted sequence, and reverse folding, all stemming from the ASP competition.30 Encodings for clingo, ezcsp,31 ezsmt and clingcon 2 have been taken from (Lierler and Susman 2016) in combination with instances from the ASP competition.32 We changed the pure ASP encoding for clingo slightly for a better grounding performance. For these classes, we could not provide an encoding for aspartame, as its prototypical CASP support does not allow for modeling parametrized n-ary constraints.\nFor incremental scheduling, inca produces wrong results due to its usage of an intermediate version of gringo, viz. 3.0.92. The runtime in seconds for incremental scheduling is shown in Table 8. We see that clingcon 2 improves on the dedicated ASP encoding. In fact, incremental scheduling is a true CASP problem where the pure ASP encoding can be improved by using CP. While the black-box approach of ezcsp performs worst, ezsmt and clingcon 3 clearly dominate this comparison.33 The enhanced preprocessing techniques and the lazy variable generation of clingcon even outperforms the industrial SMT solver z3 (as used in ezsmt).\nFor the weighted sequence problem, we see in Table 9 that inca, clingo, ezsmt, and clingcon 3 perform well on this benchmark set, while clingcon 2 could not compete with the timings of the other systems and ezcsp did not solve any of them. Again, time is shown in seconds and - denotes a timeout of 1800 seconds. We also see that the performance of the pure ASP encoding is in the same range as that of the winning CASP systems. Hence, the ASP solving part clearly dominates the CSP part. This also explains the slightly worse performance of clingcon 3 due to its heavy preprocessing of the CSP part.\nFor the reverse folding problem, we compare the same systems as before. Table 10 gives\n30 http://aspcomp2015.dibris.unige.it/LPNMR-comp-report.pdf 31 To be comparable, we used the encoding without cumulative constraint. 32 We refrained from using the other three benchmark classes from this source as the available instances were too easy\nto solve to produce informative results. 33 The time to run the completion and translation processes for ezcsp and ezsmt is not included in the tables.\nthe running time in seconds. While all CASP systems improve upon the pure ASP encoding, clingcon 2 and clingcon 3 perform best on this benchmark class. The preprocessing overhead of clingcon 3 does not pay off in terms of runtime on this benchmark class, making it perform slightly worse than clingcon 2. Of the two lazy nogood generating solvers inca and clingcon 3, the latter performs better due to lazy variable generation, as not all order atoms have to be generated before solving. While the black-box approach of ezcsp can solve the problem, the translation to SMT by ezsmt performs even better. We conclude that this is also due to the fact that no auxiliary atoms for an encoding of the constraints are used in ezsmt. A closer inspection revealed that the\nnumber of choices for inca and clingcon 2 is below 100 on average. For this problem, the ASP part is dominated by the CSP part. This is also the reason why the pure ASP encoding produces a memory out on all instances (it was not able to ground all constraints).\nWe conclude that clingcon 3 improves significantly upon its predecessor clingcon 2, is comparable to state of the art CP systems, and the currently fastest CASP system available. All benchmarks, encodings, instances and results are available online.34"
    }, {
      "heading" : "5 Discussion",
      "text" : "CASP combines ASP with CP, and thus brings together various techniques from both areas. Groundbreaking work has been done with the systems ac- and adsolver (Mellarkod et al. 2008; Mellarkod and Gelfond 2008) by using an off-the-shelf CP solver. This is called a black-box approach. It features a very high abstraction level and allows for great flexibility, for instance, for changing solvers or theories. Unfortunately, this high abstraction hinders tight integration techniques that are necessary to achieve a performance suitable for real world problems. Still using a black-box CP solver but having a tighter integration into modern CDCL algorithms is common to systems like ezcsp and its extensions (Balduccini 2009; Balduccini and Lierler 2013), dlvhex (Eiter et al. 2012), and clingcon 2 (Gebser et al. 2009). These systems use a CP solver for propagation and consistency checking. No auxiliary variables are used to represent nonBoolean variables. This prevents these systems from producing strong reasons and conflicts, needed for effective CDCL-based search. The system clingcon 2 tries to circumvent this problem. It strengthens propagation and integration (Ostrowski and Schaub 2012) by using filtering\n34 https://potassco.org/clingcon\ntechniques and special knowledge about the theory. A different way to tackle the problem is the eager approach. The theory part of the problem is translated to ASP, SAT, or SMT in a preprocessing step. dingo (Janhunen et al. 2011) translates ASP enriched with difference constraints to SMT, ezsmt translates CASP to SMT, and aspartame (Banbara et al. 2015) provides an ASP encoding to translate CP (and CASP) into ASP. The eager approach has the strongest integration because only one solver without dedicated propagators is used to solve the problem. The features of modern CDCL algorithms such as conflict driven heuristics and learn-\ning are supported natively without any change to the ASP solver. Nevertheless, translational methods into ASP or SAT have the drawback of being very memory intensive since the whole theory has to be represented using propositional variables. Encodings that use for instance binary representations of integer variables lack propagation strength. To overcome these problems, inca (Drescher and Walsh 2012) translates constraints on the fly, that is, it relies upon lazy nogood generation, which is strongly inspired by lazy clause generation (Ohrimenko et al. 2009). It features a tight integration, profits from the learning capabilities of CDCL, and avoids the grounding bottleneck of eager techniques since only the currently interesting part of the theory is generated. inca concentrates on the support of various encodings and implements a propagator for linear and distinct constraints. Unfortunately, the basic vocabulary of these encodings has to be provided beforehand, not removing the grounding bottleneck for variables with large domains. Lazy variable generation (Thibaut and Stuckey 2009) overcomes this problem and is a state of the art technique in CP. Close work in the neighboring area of model expansion was done in the idp system (De Cat et al. 2014) using minisatid (De Cat et al. 2013) for combining lazy clause generation and lazy variable generation for handling linear constraints. Also, the constraint solver chuffed, the leading CP solver in the minizinc competition 2015, supports lazy clause and variable generation and has propagators for a set of global constraints.\nWe take this up to extend ASP with CP for tackling CASP problems with modern CP techniques. By extending the input language of gringo in a modular way, we enhance the modeling capabilities of ASP with linear constraints over integers and handle them with advanced hybrid search and propagation techniques. Our design goal is to have a tight integration, overcoming grounding and memory bottlenecks of translation-based approaches, while using the learning capabilities of CDCL algorithms. We integrated these techniques in clasp and clingo while preserving features like multi-threading, unsatisfiable core optimization, multi-objective optimization etc. We developed a propagator for linear constraints and are able to translate parts of the constraints beforehand. Furthermore, variables with huge domains are managed by introducing order atoms on the fly. Several dedicated preprocessing techniques improve our lazy nogood generation approach. Our empirical evaluation leads to the result that some techniques that are known to be crucial for translational approaches using the order encoding cannot be adopted easily. This concerns especially sorting and splitting of constraints, which has either no or even a negative effect on the performance of lazy nogood propagation. Other, more general techniques like equality processing, don’t care propagation, and flattening of the objective function improve the performance in general. Another interesting result is that translating a subset of small constraints is beneficial over translating none or all. These techniques have allowed us to develop the modern CASP solver clingcon. It combines the first-order modeling language of ASP with the performance of state of the art CP solvers for handling constraints over integers. Also, making clingcon incremental, such that multi-shot solving can be used with clingo’s API, enables us to use CASP in reactive environments and thus opens up new application areas. Our software is open source and freely available as part of the potassco project.35\nFuture work. CASP is a useful paradigm to solve problems with resources, capacities, and finegrained timing information. Its semantics has been extended in various ways, as for instance in bound foundedASP (Aziz et al. 2013) or default reasoning with constraints (Cabalar et al. 2016).\n35 https://potassco.org\nThe latter approach already presents a translator relying upon clingcon 3. This indicates that related approaches can take advantage of the development of CASP and its systems.\nWe plan to develop a translation option for converting a CASP problem into an (C)ASP problem by (partially) translating the constraints. The output can then be handled by other solvers than clasp. We also preserved special functionalities of the ASP solver clasp in order to use unsatisfiable core techniques (Andres et al. 2012) and multi-criteria optimization (Gebser et al. 2011) for integer variables. Also, domain-specific heuristics (Gebser et al. 2013) can be used in the encodings of CASP problems. However, all these features still need to be evaluated in the context of CASP. Furthermore, we want to use the ability to handle constraints over large domains to tackle complex planning problems (Balduccini et al. 2016). These often involve a fine grained handling of resources and timings and are a perfect area of application for CASP.\nAcknowledgments. This work was partially funded by JSPS (KAKENHI 15K00099) and DFG (SCHA 550/9). We are grateful to Bart Bogaerts for his help with minisatid. A special thanks goes to Philipp Wanko for his comments, and of course, to Roland Kaminski for all his support!"
    } ],
    "references" : [ {
      "title" : "Unsatisfiability-based optimization in clasp",
      "author" : [ "B. ANDRES", "B. KAUFMANN", "O. MATHEIS", "T. SCHAUB" ],
      "venue" : "See Dovier and Santos Costa (2012), 212–221.",
      "citeRegEx" : "ANDRES et al\\.,? 2012",
      "shortCiteRegEx" : "ANDRES et al\\.",
      "year" : 2012
    }, {
      "title" : "Stable model semantics for founded bounds",
      "author" : [ "R. AZIZ", "G. CHU", "P. STUCKEY" ],
      "venue" : "Theory and Practice of Logic Programming 13, 4-5, 517–532.",
      "citeRegEx" : "AZIZ et al\\.,? 2013",
      "shortCiteRegEx" : "AZIZ et al\\.",
      "year" : 2013
    }, {
      "title" : "Representing constraint satisfaction problems in answer set programming",
      "author" : [ "M. BALDUCCINI" ],
      "venue" : "Proceedings of the Second Workshop on Answer Set Programming and Other Computing Paradigms (ASPOCP’09), W. Faber and J. Lee, Eds. 16–30.",
      "citeRegEx" : "BALDUCCINI,? 2009",
      "shortCiteRegEx" : "BALDUCCINI",
      "year" : 2009
    }, {
      "title" : "Integration schemas for constraint answer set programming: a case study",
      "author" : [ "M. BALDUCCINI", "Y. LIERLER" ],
      "venue" : "Theory and Practice of Logic Programming 13.",
      "citeRegEx" : "BALDUCCINI and LIERLER,? 2013",
      "shortCiteRegEx" : "BALDUCCINI and LIERLER",
      "year" : 2013
    }, {
      "title" : "PDDL+ planning via constraint answer set programming",
      "author" : [ "M. BALDUCCINI", "D. MAGAZZENI", "M. MARATEA" ],
      "venue" : "CoRR abs/1609.00030.",
      "citeRegEx" : "BALDUCCINI et al\\.,? 2016",
      "shortCiteRegEx" : "BALDUCCINI et al\\.",
      "year" : 2016
    }, {
      "title" : "aspartame: Solving constraint satisfaction problems with answer set programming",
      "author" : [ "M. BANBARA", "M. GEBSER", "K. INOUE", "M. OSTROWSKI", "A. PEANO", "T. SCHAUB", "T. SOH", "N. TAMURA", "M. WEISE" ],
      "venue" : "Proceedings of the Thirteenth International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR’15), F. Calimeri, G. Ianni, and M. Truszczyński, Eds. Lecture Notes in Artificial Intelligence, vol. 9345. Springer-Verlag, 112–126.",
      "citeRegEx" : "BANBARA et al\\.,? 2015",
      "shortCiteRegEx" : "BANBARA et al\\.",
      "year" : 2015
    }, {
      "title" : "Satisfiability modulo theories",
      "author" : [ "C. BARRETT", "R. SEBASTIANI", "S. SESHIA", "C. TINELLI" ],
      "venue" : "See Biere et al. (2009), Chapter 26, 825–885.",
      "citeRegEx" : "BARRETT et al\\.,? 2009",
      "shortCiteRegEx" : "BARRETT et al\\.",
      "year" : 2009
    }, {
      "title" : "Towards an integration of answer set and constraint solving",
      "author" : [ "S. BASELICE", "P. BONATTI", "M. GELFOND" ],
      "venue" : "Proceedings of the Twenty-first International Conference on Logic Programming (ICLP’05), M. Gabbrielli and G. Gupta, Eds. Lecture Notes in Computer Science, vol. 3668. Springer-Verlag, 52–66.",
      "citeRegEx" : "BASELICE et al\\.,? 2005",
      "shortCiteRegEx" : "BASELICE et al\\.",
      "year" : 2005
    }, {
      "title" : "Handbook of Satisfiability",
      "author" : [ "A. BIERE", "M. HEULE", "H. VAN MAAREN", "T. WALSH", "Eds." ],
      "venue" : "Frontiers in Artificial Intelligence and Applications, vol. 185. IOS Press.",
      "citeRegEx" : "BIERE et al\\.,? 2009",
      "shortCiteRegEx" : "BIERE et al\\.",
      "year" : 2009
    }, {
      "title" : "Proceedings of the Twenty-fifth IEEE International Conference on Tools with Artificial Intelligence (ICTAI’13)",
      "author" : [ "A. BRODSKY", "Ed." ],
      "venue" : "IEEE Computer Society.",
      "citeRegEx" : "BRODSKY and Ed.,? 2013",
      "shortCiteRegEx" : "BRODSKY and Ed.",
      "year" : 2013
    }, {
      "title" : "An ASP semantics for default reasoning with constraints",
      "author" : [ "P. CABALAR", "R. KAMINSKI", "M. OSTROWSKI", "T. SCHAUB" ],
      "venue" : "Proceedings of the Twenty-fifth International Joint Conference on Artificial Intelligence (IJCAI’16), R. Kambhampati, Ed. IJCAI/AAAI Press, 1015–1021.",
      "citeRegEx" : "CABALAR et al\\.,? 2016",
      "shortCiteRegEx" : "CABALAR et al\\.",
      "year" : 2016
    }, {
      "title" : "Technical Communications of the Thirty-second International Conference on Logic Programming (ICLP’16)",
      "author" : [ "M. CARRO", "A. KING", "Eds." ],
      "venue" : "Vol. 52. Open Access Series in Informatics (OASIcs).",
      "citeRegEx" : "CARRO et al\\.,? 2016",
      "shortCiteRegEx" : "CARRO et al\\.",
      "year" : 2016
    }, {
      "title" : "Experimental results on the application of satisfiability algorithms",
      "author" : [ "J. CRAWFORD", "A. BAKER" ],
      "venue" : null,
      "citeRegEx" : "CRAWFORD and BAKER,? \\Q1994\\E",
      "shortCiteRegEx" : "CRAWFORD and BAKER",
      "year" : 1994
    }, {
      "title" : "A machine program for theorem-proving",
      "author" : [ "M. DAVIS", "G. LOGEMANN", "D. LOVELAND" ],
      "venue" : "Communications of the ACM 5, 394–397.",
      "citeRegEx" : "DAVIS et al\\.,? 1962",
      "shortCiteRegEx" : "DAVIS et al\\.",
      "year" : 1962
    }, {
      "title" : "A computing procedure for quantification theory",
      "author" : [ "M. DAVIS", "H. PUTNAM" ],
      "venue" : "Journal of the ACM 7, 201–215.",
      "citeRegEx" : "DAVIS and PUTNAM,? 1960",
      "shortCiteRegEx" : "DAVIS and PUTNAM",
      "year" : 1960
    }, {
      "title" : "Predicate logic as a modelling language: The IDP system",
      "author" : [ "B. DE CAT", "B. BOGAERTS", "M. BRUYNOOGHE", "M. DENECKER" ],
      "venue" : "CoRR abs/1401.6312.",
      "citeRegEx" : "CAT et al\\.,? 2014",
      "shortCiteRegEx" : "CAT et al\\.",
      "year" : 2014
    }, {
      "title" : "Model expansion in the presence of function symbols using constraint programming",
      "author" : [ "B. DE CAT", "B. BOGAERTS", "J. DEVRIENDT", "M. DENECKER" ],
      "venue" : "See Brodsky (2013), 1068–1075.",
      "citeRegEx" : "CAT et al\\.,? 2013",
      "shortCiteRegEx" : "CAT et al\\.",
      "year" : 2013
    }, {
      "title" : "Technical Communications of the Twenty-eighth International Conference on Logic Programming (ICLP’12)",
      "author" : [ "A. DOVIER", "V. SANTOS COSTA", "Eds." ],
      "venue" : "Vol. 17. Leibniz International Proceedings in Informatics (LIPIcs).",
      "citeRegEx" : "DOVIER et al\\.,? 2012",
      "shortCiteRegEx" : "DOVIER et al\\.",
      "year" : 2012
    }, {
      "title" : "Conflict-driven constraint answer set solving",
      "author" : [ "C. DRESCHER" ],
      "venue" : "Ph.D. thesis, Computer Science and Engineering, Faculty of Engineering, UNSW.",
      "citeRegEx" : "DRESCHER,? 2015",
      "shortCiteRegEx" : "DRESCHER",
      "year" : 2015
    }, {
      "title" : "A translational approach to constraint answer set solving",
      "author" : [ "C. DRESCHER", "T. WALSH" ],
      "venue" : "Theory and Practice of Logic Programming 10, 4-6, 465–480.",
      "citeRegEx" : "DRESCHER and WALSH,? 2010",
      "shortCiteRegEx" : "DRESCHER and WALSH",
      "year" : 2010
    }, {
      "title" : "Answer set solving with lazy nogood generation",
      "author" : [ "C. DRESCHER", "T. WALSH" ],
      "venue" : "See Dovier and Santos Costa (2012), 188–200.",
      "citeRegEx" : "DRESCHER and WALSH,? 2012",
      "shortCiteRegEx" : "DRESCHER and WALSH",
      "year" : 2012
    }, {
      "title" : "Conflict-driven ASP solving with external sources",
      "author" : [ "T. EITER", "M. FINK", "T. KRENNWALLNER", "C. REDL" ],
      "venue" : "Theory and Practice of Logic Programming 12, 4-5, 659–679.",
      "citeRegEx" : "EITER et al\\.,? 2012",
      "shortCiteRegEx" : "EITER et al\\.",
      "year" : 2012
    }, {
      "title" : "Half reification and flattening",
      "author" : [ "T. FEYDY", "Z. SOMOGYI", "P. STUCKEY" ],
      "venue" : "Proceedings of the Seventeenth International Conference on Principles and Practice of Constraint Programming (CP’11), J. Lee, Ed. Lecture Notes in Computer Science, vol. 6876. Springer-Verlag, 286–301.",
      "citeRegEx" : "FEYDY et al\\.,? 2011",
      "shortCiteRegEx" : "FEYDY et al\\.",
      "year" : 2011
    }, {
      "title" : "Theory solving made easy with clingo 5",
      "author" : [ "M. GEBSER", "R. KAMINSKI", "B. KAUFMANN", "M. OSTROWSKI", "T. SCHAUB", "P. WANKO" ],
      "venue" : "See Carro and King (2016), 2:1–2:15.",
      "citeRegEx" : "GEBSER et al\\.,? 2016a",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2016
    }, {
      "title" : "Theory solving made easy with clingo 5 (extended version)",
      "author" : [ "M. GEBSER", "R. KAMINSKI", "B. KAUFMANN", "M. OSTROWSKI", "T. SCHAUB", "P. WANKO" ],
      "venue" : "Available at http://www.cs.uni-potsdam.de/wv/publications/. Extended version of (Gebser et al. 2016a).",
      "citeRegEx" : "GEBSER et al\\.,? 2016b",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2016
    }, {
      "title" : "Multi-criteria optimization in answer set programming",
      "author" : [ "M. GEBSER", "R. KAMINSKI", "B. KAUFMANN", "T. SCHAUB" ],
      "venue" : "Technical Communications of the Twenty-seventh International Conference on Logic Programming (ICLP’11), J. Gallagher and M. Gelfond, Eds. Vol. 11. Leibniz International Proceedings in Informatics (LIPIcs), 1–10.",
      "citeRegEx" : "GEBSER et al\\.,? 2011",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2011
    }, {
      "title" : "Answer Set Solving in Practice",
      "author" : [ "M. GEBSER", "R. KAMINSKI", "B. KAUFMANN", "T. SCHAUB" ],
      "venue" : "Synthesis Lectures on Artificial Intelligence and Machine Learning. Morgan and Claypool Publishers.",
      "citeRegEx" : "GEBSER et al\\.,? 2012",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2012
    }, {
      "title" : "Clingo = ASP + control: Preliminary report",
      "author" : [ "M. GEBSER", "R. KAMINSKI", "B. KAUFMANN", "T. SCHAUB" ],
      "venue" : "Technical Communications of the Thirtieth International Conference on Logic Programming (ICLP’14), M. Leuschel and T. Schrijvers, Eds. Theory and Practice of Logic Programming, Online Supplement, vol. arXiv:1405.3694v1. Available at http://arxiv.org/abs/1405.3694v1.",
      "citeRegEx" : "GEBSER et al\\.,? 2014",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2014
    }, {
      "title" : "Ricochet robots reloaded: A casestudy in multi-shot ASP solving",
      "author" : [ "M. GEBSER", "R. KAMINSKI", "P. OBERMEIER", "T. SCHAUB" ],
      "venue" : "Advances in Knowledge Representation, Logic Programming, and Abstract Argumentation: Essays Dedicated to Gerhard Brewka on the Occasion of His 60th Birthday, T. Eiter, H. Strass, M. Truszczyński, and S. Woltran, Eds. Lecture Notes in Artificial Intelligence, vol. 9060. Springer-Verlag, 17–32.",
      "citeRegEx" : "GEBSER et al\\.,? 2015",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2015
    }, {
      "title" : "Conflict-driven answer set solving",
      "author" : [ "M. GEBSER", "B. KAUFMANN", "A. NEUMANN", "T. SCHAUB" ],
      "venue" : "Proceedings of the Twentieth International Joint Conference on Artificial Intelligence (IJCAI’07), M. Veloso, Ed. AAAI/MIT Press, 386–392.",
      "citeRegEx" : "GEBSER et al\\.,? 2007",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2007
    }, {
      "title" : "Multi-threaded ASP solving with clasp",
      "author" : [ "M. GEBSER", "B. KAUFMANN", "T. SCHAUB" ],
      "venue" : "Theory and Practice of Logic Programming 12, 4-5, 525–545.",
      "citeRegEx" : "GEBSER et al\\.,? 2012",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2012
    }, {
      "title" : "Constraint answer set solving",
      "author" : [ "M. GEBSER", "M. OSTROWSKI", "T. SCHAUB" ],
      "venue" : "Proceedings of the Twenty-fifth International Conference on Logic Programming (ICLP’09), P. Hill and D. Warren, Eds. Lecture Notes in Computer Science, vol. 5649. Springer-Verlag, 235–249.",
      "citeRegEx" : "GEBSER et al\\.,? 2009",
      "shortCiteRegEx" : "GEBSER et al\\.",
      "year" : 2009
    }, {
      "title" : "Gecode: Generic constraint development environment",
      "author" : [ "GECODE TEAM." ],
      "venue" : "Available from http://www.gecode.org.",
      "citeRegEx" : "TEAM.,? 2006",
      "shortCiteRegEx" : "TEAM.",
      "year" : 2006
    }, {
      "title" : "The stable model semantics for logic programming",
      "author" : [ "M. GELFOND", "V. LIFSCHITZ" ],
      "venue" : "Proceedings of the Fifth International Conference and Symposium of Logic Programming (ICLP’88), R. Kowalski and K. Bowen, Eds. MIT Press, 1070–1080.",
      "citeRegEx" : "GELFOND and LIFSCHITZ,? 1988",
      "shortCiteRegEx" : "GELFOND and LIFSCHITZ",
      "year" : 1988
    }, {
      "title" : "Tight integration of non-ground answer set programming and satisfiability modulo theories",
      "author" : [ "T. JANHUNEN", "G. LIU", "I. NIEMELÄ" ],
      "venue" : "Proceedings of the First Workshop on Grounding and Transformation for Theories with Variables (GTTV’11), P. Cabalar, D. Mitchell, D. Pearce, and E. Ternovska, Eds. 1–13.",
      "citeRegEx" : "JANHUNEN et al\\.,? 2011",
      "shortCiteRegEx" : "JANHUNEN et al\\.",
      "year" : 2011
    }, {
      "title" : "SMT-based constraint answer set solver EZSMT (system description)",
      "author" : [ "Y. LIERLER", "B. SUSMAN" ],
      "venue" : "See Carro and King (2016), 1:1–1:15.",
      "citeRegEx" : "LIERLER and SUSMAN,? 2016",
      "shortCiteRegEx" : "LIERLER and SUSMAN",
      "year" : 2016
    }, {
      "title" : "What is answer set programming? In Proceedings of the Twenty-third National Conference on Artificial Intelligence (AAAI’08), D",
      "author" : [ "V. LIFSCHITZ" ],
      "venue" : "Fox and C. Gomes, Eds. AAAI Press, 1594–1597.",
      "citeRegEx" : "LIFSCHITZ,? 2008",
      "shortCiteRegEx" : "LIFSCHITZ",
      "year" : 2008
    }, {
      "title" : "GRASP: A search algorithm for propositional satisfiability",
      "author" : [ "J. MARQUES-SILVA", "K. SAKALLAH" ],
      "venue" : "IEEE Transactions on Computers 48, 5, 506–521.",
      "citeRegEx" : "MARQUES.SILVA and SAKALLAH,? 1999",
      "shortCiteRegEx" : "MARQUES.SILVA and SAKALLAH",
      "year" : 1999
    }, {
      "title" : "Integrating answer set reasoning with constraint solving techniques",
      "author" : [ "V. MELLARKOD", "M. GELFOND" ],
      "venue" : "Proceedings of the Ninth International Symposium on Functional and Logic Programming (FLOPS’08), J. Garrigue and M. Hermenegildo, Eds. Lecture Notes in Computer Science, vol. 4989. Springer-Verlag, 15–31.",
      "citeRegEx" : "MELLARKOD and GELFOND,? 2008",
      "shortCiteRegEx" : "MELLARKOD and GELFOND",
      "year" : 2008
    }, {
      "title" : "Integrating answer set programming and constraint logic programming",
      "author" : [ "V. MELLARKOD", "M. GELFOND", "Y. ZHANG" ],
      "venue" : "Annals of Mathematics and Artificial Intelligence 53, 1-4, 251–287.",
      "citeRegEx" : "MELLARKOD et al\\.,? 2008",
      "shortCiteRegEx" : "MELLARKOD et al\\.",
      "year" : 2008
    }, {
      "title" : "Boolean equi-propagation for concise and efficient SAT encodings of combinatorial problems",
      "author" : [ "A. METODI", "M. CODISH", "P. STUCKEY" ],
      "venue" : "Journal of Artificial Intelligence Research 46, 303–341.",
      "citeRegEx" : "METODI et al\\.,? 2013",
      "shortCiteRegEx" : "METODI et al\\.",
      "year" : 2013
    }, {
      "title" : "Propagation via lazy clause generation",
      "author" : [ "O. OHRIMENKO", "P. STUCKEY", "M. CODISH" ],
      "venue" : "Constraints 14, 3, 357–391.",
      "citeRegEx" : "OHRIMENKO et al\\.,? 2009",
      "shortCiteRegEx" : "OHRIMENKO et al\\.",
      "year" : 2009
    }, {
      "title" : "Modern constraint answer set solving",
      "author" : [ "M. OSTROWSKI" ],
      "venue" : "Ph.D. thesis, University of Potsdam.",
      "citeRegEx" : "OSTROWSKI,? 2017",
      "shortCiteRegEx" : "OSTROWSKI",
      "year" : 2017
    }, {
      "title" : "ASP modulo CSP: The clingcon system",
      "author" : [ "M. OSTROWSKI", "T. SCHAUB" ],
      "venue" : "Theory and Practice of Logic Programming 12, 4-5, 485–503.",
      "citeRegEx" : "OSTROWSKI and SCHAUB,? 2012",
      "shortCiteRegEx" : "OSTROWSKI and SCHAUB",
      "year" : 2012
    }, {
      "title" : "Handbook of Constraint Programming",
      "author" : [ "F. ROSSI", "P. VAN BEEK", "T. WALSH", "Eds." ],
      "venue" : "Elsevier Science.",
      "citeRegEx" : "ROSSI et al\\.,? 2006",
      "shortCiteRegEx" : "ROSSI et al\\.",
      "year" : 2006
    }, {
      "title" : "XML representation of constraint networks: Format XCSP 2.1",
      "author" : [ "O. ROUSSEL", "C. LECOUTRE" ],
      "venue" : "CoRR abs/0902.2362",
      "citeRegEx" : "ROUSSEL and LECOUTRE,? \\Q2009\\E",
      "shortCiteRegEx" : "ROUSSEL and LECOUTRE",
      "year" : 2009
    }, {
      "title" : "Views and iterators for generic constraint implementations",
      "author" : [ "C. SCHULTE", "G. TACK" ],
      "venue" : "Proceedings of the Eleventh International Conference on Principles and Practice of Constraint Programming (CP’05), P. van Beek, Ed. Lecture Notes in Computer Science, vol. 3709. Springer-Verlag, 118–132.",
      "citeRegEx" : "SCHULTE and TACK,? 2005",
      "shortCiteRegEx" : "SCHULTE and TACK",
      "year" : 2005
    }, {
      "title" : "Extending and implementing the stable model semantics",
      "author" : [ "P. SIMONS", "I. NIEMELÄ", "T. SOININEN" ],
      "venue" : "Artificial Intelligence 138, 1-2, 181–234.",
      "citeRegEx" : "SIMONS et al\\.,? 2002",
      "shortCiteRegEx" : "SIMONS et al\\.",
      "year" : 2002
    }, {
      "title" : "A SAT-based method for solving the two-dimensional strip packing problem",
      "author" : [ "T. SOH", "K. INOUE", "N. TAMURA", "M. BANBARA", "H. NABESHIMA" ],
      "venue" : "Fundamenta Informaticae 102, 3-4, 467–487.",
      "citeRegEx" : "SOH et al\\.,? 2010",
      "shortCiteRegEx" : "SOH et al\\.",
      "year" : 2010
    }, {
      "title" : "Compiling pseudo-boolean constraints to SAT with order encoding",
      "author" : [ "N. TAMURA", "M. BANBARA", "SOH", "T." ],
      "venue" : "See Brodsky (2013), 1020–1027.",
      "citeRegEx" : "TAMURA et al\\.,? 2013",
      "shortCiteRegEx" : "TAMURA et al\\.",
      "year" : 2013
    }, {
      "title" : "Compiling finite linear CSP into SAT",
      "author" : [ "N. TAMURA", "A. TAGA", "S. KITAGAWA", "M. BANBARA" ],
      "venue" : "Constraints 14, 2, 254–272.",
      "citeRegEx" : "TAMURA et al\\.,? 2009",
      "shortCiteRegEx" : "TAMURA et al\\.",
      "year" : 2009
    }, {
      "title" : "Lazy clause generation reengineered",
      "author" : [ "F. THIBAUT", "P. STUCKEY" ],
      "venue" : "Proceedings of the Fifteenth International Conference on Principles and Practice of Constraint Programming (CP’09), I. Gent, Ed. Lecture Notes in Computer Science, vol. 5732. Springer-Verlag, 352–366.",
      "citeRegEx" : "THIBAUT and STUCKEY,? 2009",
      "shortCiteRegEx" : "THIBAUT and STUCKEY",
      "year" : 2009
    }, {
      "title" : "Solving non-clausal formulas with DPLL search",
      "author" : [ "C. THIFFAULT", "F. BACCHUS", "T. WALSH" ],
      "venue" : "Proceedings of the Tenth International Conference on Principles and Practice of Constraint Programming (CP’04), M. Wallace, Ed. Lecture Notes in Computer Science, vol. 3258. Springer-Verlag, 663–678.",
      "citeRegEx" : "THIFFAULT et al\\.,? 2004",
      "shortCiteRegEx" : "THIFFAULT et al\\.",
      "year" : 2004
    }, {
      "title" : "SAT versus CSP",
      "author" : [ "T. WALSH" ],
      "venue" : "Proceedings of the Sixth International Conference on Principles and Practice of Constraint Programming (CP’00), R. Dechter, Ed. Lecture Notes in Computer Science, vol. 1894. Springer-Verlag, 441–456.",
      "citeRegEx" : "WALSH,? 2000",
      "shortCiteRegEx" : "WALSH",
      "year" : 2000
    }, {
      "title" : "Efficient conflict driven learning in a Boolean satisfiability solver",
      "author" : [ "L. ZHANG", "C. MADIGAN", "M. MOSKEWICZ", "S. MALIK" ],
      "venue" : "Proceedings of the International Conference on Computer-Aided Design (ICCAD’01). ACM Press, 279–285.",
      "citeRegEx" : "ZHANG et al\\.,? 2001",
      "shortCiteRegEx" : "ZHANG et al\\.",
      "year" : 2001
    } ],
    "referenceMentions" : [ {
      "referenceID" : 36,
      "context" : "The shortcoming of Answer Set Programming (ASP; (Lifschitz 2008)) to succinctly represent variables over large numeric domains has led to the development of several systems enhancing ASP with capabilities for finite domain Constraint Processing (CP; (Rossi et al.",
      "startOffset" : 48,
      "endOffset" : 64
    }, {
      "referenceID" : 44,
      "context" : "The shortcoming of Answer Set Programming (ASP; (Lifschitz 2008)) to succinctly represent variables over large numeric domains has led to the development of several systems enhancing ASP with capabilities for finite domain Constraint Processing (CP; (Rossi et al. 2006)).",
      "startOffset" : 250,
      "endOffset" : 269
    }, {
      "referenceID" : 7,
      "context" : "Starting from the seminal work in (Baselice et al. 2005) and the consecutive development of traditional DPLL-style hybrid ASP solvers like adsolver (Mellarkod et al.",
      "startOffset" : 34,
      "endOffset" : 56
    }, {
      "referenceID" : 39,
      "context" : "2005) and the consecutive development of traditional DPLL-style hybrid ASP solvers like adsolver (Mellarkod et al. 2008), modern hybrid ASP solvers take advantage of CDCL-based solving technology (Marques-Silva and Sakallah 1999; Zhang et al.",
      "startOffset" : 97,
      "endOffset" : 120
    }, {
      "referenceID" : 37,
      "context" : "2008), modern hybrid ASP solvers take advantage of CDCL-based solving technology (Marques-Silva and Sakallah 1999; Zhang et al. 2001; Gebser et al. 2007) in different ways.",
      "startOffset" : 81,
      "endOffset" : 153
    }, {
      "referenceID" : 54,
      "context" : "2008), modern hybrid ASP solvers take advantage of CDCL-based solving technology (Marques-Silva and Sakallah 1999; Zhang et al. 2001; Gebser et al. 2007) in different ways.",
      "startOffset" : 81,
      "endOffset" : 153
    }, {
      "referenceID" : 29,
      "context" : "2008), modern hybrid ASP solvers take advantage of CDCL-based solving technology (Marques-Silva and Sakallah 1999; Zhang et al. 2001; Gebser et al. 2007) in different ways.",
      "startOffset" : 81,
      "endOffset" : 153
    }, {
      "referenceID" : 3,
      "context" : "Let us illustrate this by describing the approach of three representative Constraint Answer Set Programming (CASP; (Balduccini and Lierler 2013)) systems.",
      "startOffset" : 115,
      "endOffset" : 144
    }, {
      "referenceID" : 14,
      "context" : "1 Tracing back to the Davis-Putman-Logemann-Loveland procedure (Davis and Putnam 1960; Davis et al. 1962) 2 Standing for: Conflict-Driven Constraint Learning",
      "startOffset" : 63,
      "endOffset" : 105
    }, {
      "referenceID" : 13,
      "context" : "1 Tracing back to the Davis-Putman-Logemann-Loveland procedure (Davis and Putnam 1960; Davis et al. 1962) 2 Standing for: Conflict-Driven Constraint Learning",
      "startOffset" : 63,
      "endOffset" : 105
    }, {
      "referenceID" : 6,
      "context" : "A black-box approach is pursued in the two previous clingcon series where the ASP solver clasp is combined with the CP solver gecode (Gecode Team 2006) by following the lazy approach to SMTsolving (Barrett et al. 2009).",
      "startOffset" : 197,
      "endOffset" : 218
    }, {
      "referenceID" : 5,
      "context" : "A translation-based approach is pursued by the aspartame system (Banbara et al. 2015) where a CSP is fully translated into ASP and then solved by an ASP solver.",
      "startOffset" : 64,
      "endOffset" : 85
    }, {
      "referenceID" : 50,
      "context" : "This approach follows the one of the CP solver sugar (Tamura et al. 2009) translating CSPs to SAT (Biere et al.",
      "startOffset" : 53,
      "endOffset" : 73
    }, {
      "referenceID" : 8,
      "context" : "2009) translating CSPs to SAT (Biere et al. 2009).",
      "startOffset" : 30,
      "endOffset" : 49
    }, {
      "referenceID" : 43,
      "context" : "Also, the granularity induced by an explicit representation of integer variables provides more accurate conflict and propagation information, and approximations for reasons and conflicts as used in the former clingcon system (Ostrowski and Schaub 2012) are made obsolete.",
      "startOffset" : 225,
      "endOffset" : 252
    }, {
      "referenceID" : 20,
      "context" : "A lazy approach is pursued by the inca system (Drescher and Walsh 2012) where the ASP solver clasp is augmented with dedicated propagators for linear and selected global constraints by following the approach of lazy clause generation (Ohrimenko et al.",
      "startOffset" : 46,
      "endOffset" : 71
    }, {
      "referenceID" : 41,
      "context" : "A lazy approach is pursued by the inca system (Drescher and Walsh 2012) where the ASP solver clasp is augmented with dedicated propagators for linear and selected global constraints by following the approach of lazy clause generation (Ohrimenko et al. 2009).",
      "startOffset" : 234,
      "endOffset" : 257
    }, {
      "referenceID" : 51,
      "context" : "However, we take the approach of inca one step further by permitting lazy variable generation (Thibaut and Stuckey 2009) to unfold the vocabulary and the basic inference schemes of the order encoding only when needed.",
      "startOffset" : 94,
      "endOffset" : 120
    }, {
      "referenceID" : 28,
      "context" : "What is more, clingcon is not restricted to single-shot solving but fully blends in with clingo’s multi-shot solving capabilities (Gebser et al. 2015).",
      "startOffset" : 130,
      "endOffset" : 150
    }, {
      "referenceID" : 33,
      "context" : "In ASP, the semantics of a logic program is given by its (constraint) stable models (Gelfond and Lifschitz 1988; Gebser et al. 2009).",
      "startOffset" : 84,
      "endOffset" : 132
    }, {
      "referenceID" : 31,
      "context" : "In ASP, the semantics of a logic program is given by its (constraint) stable models (Gelfond and Lifschitz 1988; Gebser et al. 2009).",
      "startOffset" : 84,
      "endOffset" : 132
    }, {
      "referenceID" : 18,
      "context" : "Following (Drescher 2015), we call (C, satC(C)) a configuration of (V , D,C).",
      "startOffset" : 10,
      "endOffset" : 25
    }, {
      "referenceID" : 46,
      "context" : "Following (Schulte and Tack 2005), a view on a variable x is an expression ax + b for integers a, b; its image is defined as img(ax + b) = {ax+ b | x ∈ D(x)}.",
      "startOffset" : 10,
      "endOffset" : 33
    }, {
      "referenceID" : 26,
      "context" : "Our description of this approach follows the one given in (Gebser et al. 2012).",
      "startOffset" : 58,
      "endOffset" : 78
    }, {
      "referenceID" : 26,
      "context" : "Then, according to (Gebser et al. 2012), a set of atoms X is a stable model of a regular logic program P iffX = B ∩ atom(P ) for a (unique) solutionB of∆P ∪ ΛP .",
      "startOffset" : 19,
      "endOffset" : 39
    }, {
      "referenceID" : 20,
      "context" : "To address this issue, (Drescher and Walsh 2012) exempt constraint atoms from the respective sets of nogoods and define the variants∆P and Λ C P by replacing atom(P ) in the qualification of (6) and (7) with atom(P ) \\ C.",
      "startOffset" : 23,
      "endOffset" : 48
    }, {
      "referenceID" : 42,
      "context" : "Then, in (Ostrowski 2017) it is shown that (X,C) is a constraint stable model of a program P wrt (V , D,C) as defined in (Gebser et al.",
      "startOffset" : 9,
      "endOffset" : 25
    }, {
      "referenceID" : 31,
      "context" : "Then, in (Ostrowski 2017) it is shown that (X,C) is a constraint stable model of a program P wrt (V , D,C) as defined in (Gebser et al. 2009) iff and X = B ∩ atom(P ) for a (unique) solutionB of∆P ∪ Λ C P ∪ {{Fc} | γ(c) ∈ satC(C)} ∪ {{Tc} | γ(c) ∈ satC(C)}.",
      "startOffset" : 121,
      "endOffset" : 141
    }, {
      "referenceID" : 50,
      "context" : "Similar to logic programs, linear constraints can be represented as sets of nogoods by means of an order encoding (Tamura et al. 2009).",
      "startOffset" : 114,
      "endOffset" : 134
    }, {
      "referenceID" : 22,
      "context" : "Following (Feydy et al. 2011), a reified constraint is an equivalence “Tc ⇔",
      "startOffset" : 10,
      "endOffset" : 29
    }, {
      "referenceID" : 23,
      "context" : "(Gebser et al. 2016a)).",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 50,
      "context" : "Following (Tamura et al. 2009), we then define (av + b ≤ 0) as",
      "startOffset" : 10,
      "endOffset" : 30
    }, {
      "referenceID" : 31,
      "context" : "Then, (X,C) is a constraint stable model of P wrt (V , D,C) as defined in (Gebser et al. 2009) iff (C, satC(C)) is a configuration for (V , D,C), X = B ∩ atom(P ) for a (unique) solution",
      "startOffset" : 74,
      "endOffset" : 94
    }, {
      "referenceID" : 42,
      "context" : "The proof of this theorem is obtained by combining existing characterizations of logic programs in terms of nogoods and similar ones for CSPs in terms of clauses in CNF (Ostrowski 2017).",
      "startOffset" : 169,
      "endOffset" : 185
    }, {
      "referenceID" : 20,
      "context" : "Following (Drescher and Walsh 2012), a propagator for a set Θ of nogoods is a function ΠΘ mapping a Boolean assignment B to a subset of Θ such that for each total assignment B: if δ ⊆ B for some δ ∈ Θ, then δ ⊆ B for some δ ∈ ΠΘ(B).",
      "startOffset" : 10,
      "endOffset" : 35
    }, {
      "referenceID" : 24,
      "context" : "The intermediate result of grounding a CASP program is expressed in the aspif format (Gebser et al. 2016b) that accommodates both the regular ASP part of the program as well as its constraint-based extension.",
      "startOffset" : 85,
      "endOffset" : 106
    }, {
      "referenceID" : 26,
      "context" : "This includes multi-threading (Gebser et al. 2012), unsatisfiable core techniques (Andres et al.",
      "startOffset" : 30,
      "endOffset" : 50
    }, {
      "referenceID" : 0,
      "context" : "2012), unsatisfiable core techniques (Andres et al. 2012), multi-criteria optimization (Gebser et al.",
      "startOffset" : 37,
      "endOffset" : 57
    }, {
      "referenceID" : 25,
      "context" : "2012), multi-criteria optimization (Gebser et al. 2011), domain-specific heuristics (Gebser et al.",
      "startOffset" : 35,
      "endOffset" : 55
    }, {
      "referenceID" : 28,
      "context" : "2013), multi-shot solving (Gebser et al. 2015), and clasp’s reasoning modes like enumeration, intersection and union of models.",
      "startOffset" : 26,
      "endOffset" : 46
    }, {
      "referenceID" : 23,
      "context" : "As mentioned, the treatment of the extended input language of CASP programs can be mapped onto gringo’s theory language capabilities (Gebser et al. 2016a).",
      "startOffset" : 133,
      "endOffset" : 154
    }, {
      "referenceID" : 48,
      "context" : "Before delving into further details, let us illustrate the resulting syntax by the CASP program for two dimensional strip packing given in Listing 2, originally due to (Soh et al. 2010).",
      "startOffset" : 168,
      "endOffset" : 185
    }, {
      "referenceID" : 23,
      "context" : "the interested reader for a general introduction to theory terms and atoms to (Gebser et al. 2016a).",
      "startOffset" : 78,
      "endOffset" : 99
    }, {
      "referenceID" : 54,
      "context" : "On the one hand, constraint propagators are usually slower than unit propagation, in particular, when dealing with sets of nogoods of moderate size because of modern SAT techniques such as the two-watched-literals scheme (Zhang et al. 2001).",
      "startOffset" : 221,
      "endOffset" : 240
    }, {
      "referenceID" : 20,
      "context" : "Our algorithmic approach follows the one in (Drescher and Walsh 2012), where a modified CDCL algorithm supporting external propagators is presented.",
      "startOffset" : 44,
      "endOffset" : 69
    }, {
      "referenceID" : 51,
      "context" : "A view av + b can be represented with the same set of order atoms as its variable v (Thibaut and Stuckey 2009).",
      "startOffset" : 84,
      "endOffset" : 110
    }, {
      "referenceID" : 50,
      "context" : "Due to the restriction to use variables, according solvers like sugar (Tamura et al. 2009) introduce auxiliary variables v i = 1000vi for 1 ≤ i ≤ 5.",
      "startOffset" : 70,
      "endOffset" : 90
    }, {
      "referenceID" : 40,
      "context" : "Our approach to equivalence processing is inspired by Boolean Equipropagation (Metodi et al. 2013), which directly replaces the order atoms of one variable with the other.",
      "startOffset" : 78,
      "endOffset" : 98
    }, {
      "referenceID" : 53,
      "context" : "The second alternative uses a so-called direct encoding (Walsh 2000).",
      "startOffset" : 56,
      "endOffset" : 68
    }, {
      "referenceID" : 47,
      "context" : "Furthermore, we add a cardinality constraint (Simons et al. 2002) for each value d to the effect that no two or more variables may have the same value, viz.",
      "startOffset" : 45,
      "endOffset" : 65
    }, {
      "referenceID" : 49,
      "context" : "Sorting constraints by descending coefficients is known to avoid redundant nogoods in the translation process (Tamura et al. 2013).",
      "startOffset" : 110,
      "endOffset" : 130
    }, {
      "referenceID" : 52,
      "context" : "This technique is called Don’t Care Propagation (Thiffault et al. 2004).",
      "startOffset" : 48,
      "endOffset" : 71
    }, {
      "referenceID" : 0,
      "context" : "By using nativeASP minimize statements, clingcon reuses clasp’s branch and bound and unsatisfiable core based techniques (Andres et al. 2012).",
      "startOffset" : 121,
      "endOffset" : 141
    }, {
      "referenceID" : 27,
      "context" : "A central role in this is played by multi-shot solving (Gebser et al. 2014; Gebser et al. 2015) because it allows for casting manifold reasoning modes.",
      "startOffset" : 55,
      "endOffset" : 95
    }, {
      "referenceID" : 28,
      "context" : "A central role in this is played by multi-shot solving (Gebser et al. 2014; Gebser et al. 2015) because it allows for casting manifold reasoning modes.",
      "startOffset" : 55,
      "endOffset" : 95
    }, {
      "referenceID" : 27,
      "context" : "(Gebser et al. 2014)).",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 27,
      "context" : "Multi-shot solving in clingo relies on two directives (Gebser et al. 2014), the #program directive for regrouping rules and the #external directive for declaring atoms as being external to the program at hand.",
      "startOffset" : 54,
      "endOffset" : 74
    }, {
      "referenceID" : 27,
      "context" : "Although we reproduce the exemplary Python program from clingo’s example pool in Listing 4, we must refer the reader to (Gebser et al. 2014) for further details.",
      "startOffset" : 120,
      "endOffset" : 140
    }, {
      "referenceID" : 27,
      "context" : "Listing 4 and (Gebser et al. 2014) for details).",
      "startOffset" : 14,
      "endOffset" : 34
    }, {
      "referenceID" : 24,
      "context" : "For making this benchmark suite available to the CASP community, we build a converter from flatzinc to the aspif format (Gebser et al. 2016b) used by clingcon; it is called fz2aspif.",
      "startOffset" : 120,
      "endOffset" : 141
    }, {
      "referenceID" : 49,
      "context" : "Sorting (D , SC ) As we cannot account for all combinations of sorting mechanisms, we evaluate this feature only on the cases discussed in (Tamura et al. 2013).",
      "startOffset" : 139,
      "endOffset" : 159
    }, {
      "referenceID" : 49,
      "context" : "The alternative sorting recommended in (Tamura et al. 2013) first sorts on larger coefficients and afterwards uses the smaller domain.",
      "startOffset" : 39,
      "endOffset" : 59
    }, {
      "referenceID" : 19,
      "context" : "• inca (Drescher and Walsh 2010) with the option --linear-bc, a lazy nogood generating system not supporting lazy variable generation.",
      "startOffset" : 7,
      "endOffset" : 32
    }, {
      "referenceID" : 43,
      "context" : "• clingcon 2 (Ostrowski and Schaub 2012), using gecode 3.",
      "startOffset" : 13,
      "endOffset" : 40
    }, {
      "referenceID" : 3,
      "context" : "24 (Balduccini and Lierler 2013), also pursuing a black-box approach but using CP solver B-Prolog 7.",
      "startOffset" : 3,
      "endOffset" : 32
    }, {
      "referenceID" : 5,
      "context" : "• aspartame (Banbara et al. 2015), a system using an eager translation of the constraint part by means of an ASP encoding.",
      "startOffset" : 12,
      "endOffset" : 33
    }, {
      "referenceID" : 35,
      "context" : "0 (Lierler and Susman 2016), translating CASP programs to SMT, solved by SMT solver z3 4.",
      "startOffset" : 2,
      "endOffset" : 27
    }, {
      "referenceID" : 48,
      "context" : "The first benchmark class is the two dimensional strip packing problem (Soh et al. 2010); its encoding is shown in Listing 2.",
      "startOffset" : 71,
      "endOffset" : 88
    }, {
      "referenceID" : 5,
      "context" : "For aspartame, we have taken an encoding provided in (Banbara et al. 2015).",
      "startOffset" : 53,
      "endOffset" : 74
    }, {
      "referenceID" : 48,
      "context" : "According to (Soh et al. 2010), these results are in accord with dedicated, state of the art systems.",
      "startOffset" : 13,
      "endOffset" : 30
    }, {
      "referenceID" : 35,
      "context" : "Encodings for clingo, ezcsp, ezsmt and clingcon 2 have been taken from (Lierler and Susman 2016) in combination with instances from the ASP competition.",
      "startOffset" : 71,
      "endOffset" : 96
    }, {
      "referenceID" : 39,
      "context" : "Groundbreaking work has been done with the systems ac- and adsolver (Mellarkod et al. 2008; Mellarkod and Gelfond 2008) by using an off-the-shelf CP solver.",
      "startOffset" : 68,
      "endOffset" : 119
    }, {
      "referenceID" : 38,
      "context" : "Groundbreaking work has been done with the systems ac- and adsolver (Mellarkod et al. 2008; Mellarkod and Gelfond 2008) by using an off-the-shelf CP solver.",
      "startOffset" : 68,
      "endOffset" : 119
    }, {
      "referenceID" : 2,
      "context" : "Still using a black-box CP solver but having a tighter integration into modern CDCL algorithms is common to systems like ezcsp and its extensions (Balduccini 2009; Balduccini and Lierler 2013), dlvhex (Eiter et al.",
      "startOffset" : 146,
      "endOffset" : 192
    }, {
      "referenceID" : 3,
      "context" : "Still using a black-box CP solver but having a tighter integration into modern CDCL algorithms is common to systems like ezcsp and its extensions (Balduccini 2009; Balduccini and Lierler 2013), dlvhex (Eiter et al.",
      "startOffset" : 146,
      "endOffset" : 192
    }, {
      "referenceID" : 21,
      "context" : "Still using a black-box CP solver but having a tighter integration into modern CDCL algorithms is common to systems like ezcsp and its extensions (Balduccini 2009; Balduccini and Lierler 2013), dlvhex (Eiter et al. 2012), and clingcon 2 (Gebser et al.",
      "startOffset" : 201,
      "endOffset" : 220
    }, {
      "referenceID" : 31,
      "context" : "2012), and clingcon 2 (Gebser et al. 2009).",
      "startOffset" : 22,
      "endOffset" : 42
    }, {
      "referenceID" : 43,
      "context" : "It strengthens propagation and integration (Ostrowski and Schaub 2012) by using filtering",
      "startOffset" : 43,
      "endOffset" : 70
    }, {
      "referenceID" : 34,
      "context" : "dingo (Janhunen et al. 2011) translates ASP enriched with difference constraints to SMT, ezsmt translates CASP to SMT, and aspartame (Banbara et al.",
      "startOffset" : 6,
      "endOffset" : 28
    }, {
      "referenceID" : 5,
      "context" : "2011) translates ASP enriched with difference constraints to SMT, ezsmt translates CASP to SMT, and aspartame (Banbara et al. 2015) provides an ASP encoding to translate CP (and CASP) into ASP.",
      "startOffset" : 110,
      "endOffset" : 131
    }, {
      "referenceID" : 20,
      "context" : "To overcome these problems, inca (Drescher and Walsh 2012) translates constraints on the fly, that is, it relies upon lazy nogood generation, which is strongly inspired by lazy clause generation (Ohrimenko et al.",
      "startOffset" : 33,
      "endOffset" : 58
    }, {
      "referenceID" : 41,
      "context" : "To overcome these problems, inca (Drescher and Walsh 2012) translates constraints on the fly, that is, it relies upon lazy nogood generation, which is strongly inspired by lazy clause generation (Ohrimenko et al. 2009).",
      "startOffset" : 195,
      "endOffset" : 218
    }, {
      "referenceID" : 51,
      "context" : "Lazy variable generation (Thibaut and Stuckey 2009) overcomes this problem and is a state of the art technique in CP.",
      "startOffset" : 25,
      "endOffset" : 51
    }, {
      "referenceID" : 1,
      "context" : "Its semantics has been extended in various ways, as for instance in bound foundedASP (Aziz et al. 2013) or default reasoning with constraints (Cabalar et al.",
      "startOffset" : 85,
      "endOffset" : 103
    }, {
      "referenceID" : 10,
      "context" : "2013) or default reasoning with constraints (Cabalar et al. 2016).",
      "startOffset" : 44,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "We also preserved special functionalities of the ASP solver clasp in order to use unsatisfiable core techniques (Andres et al. 2012) and multi-criteria optimization (Gebser et al.",
      "startOffset" : 112,
      "endOffset" : 132
    }, {
      "referenceID" : 25,
      "context" : "2012) and multi-criteria optimization (Gebser et al. 2011) for integer variables.",
      "startOffset" : 38,
      "endOffset" : 58
    }, {
      "referenceID" : 4,
      "context" : "Furthermore, we want to use the ability to handle constraints over large domains to tackle complex planning problems (Balduccini et al. 2016).",
      "startOffset" : 117,
      "endOffset" : 141
    } ],
    "year" : 2017,
    "abstractText" : "We present the third generation of the constraint answer set system clingcon, combining Answer Set Programming (ASP) with finite domain constraint processing (CP). While its predecessors rely on a black-box approach to hybrid solving by integrating the CP solver gecode, the new clingcon system pursues a lazy approach using dedicated constraint propagators to extend propagation in the underlying ASP solver clasp. No extension is needed for parsing and grounding clingcon’s hybrid modeling language since both can be accommodated by the new generic theory handling capabilities of the ASP grounder gringo. As a whole, clingcon 3 is thus an extension of the ASP system clingo 5, which itself relies on the grounder gringo and the solver clasp. The new approach of clingcon offers a seamless integration of CP propagation into ASP solving that benefits from the whole spectrum of clasp’s reasoning modes, including for instance multi-shot solving and advanced optimization techniques. This is accomplished by a lazy approach that unfolds the representation of constraints and adds it to that of the logic program only when needed. Although the unfolding is usually dictated by the constraint propagators during solving, it can already be partially (or even totally) done during preprocessing. Moreover, clingcon’s constraint preprocessing and propagation incorporate several well established CP techniques that greatly improve its performance. We demonstrate this via an extensive empirical evaluation contrasting, first, the various techniques in the context of CSP solving and, second, the new clingcon system with other hybrid ASP systems.",
    "creator" : "LaTeX with hyperref package"
  }
}