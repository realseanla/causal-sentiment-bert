{
  "name" : "1408.6706.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Equilibrium States in Numerical Argumentation Networks",
    "authors" : [ "D. Gabbay" ],
    "emails" : [ "dov.gabbay@kcl.ac.uk", "odinaldo.rodrigues@kcl.ac.uk" ],
    "sections" : [ {
      "heading" : "1 Orientation and Background",
      "text" : ""
    }, {
      "heading" : "1.1 Orientation",
      "text" : "A finite system 〈S,R〉, with R a binary relation on S, can be viewed in many different ways; among them are\n1. As an abstract argumentation framework [10], and\n2. As a generator of equations [13, 14]\nar X\niv :1\n40 8.\n67 06\nv2 [\nWhen viewed as an abstract argumentation framework, the basic concepts studied are those of extensions (being certain subsets of S) and different semantics (being sets of extensions). When studied as generators of equations, one can generate equations in such a way that the solutions f to the equations correspond to (complete) extensions and sets of such solutions correspond to semantics.\nThis paper offers an iteration schema for finding specific solutions to the equations responding to initial requirements and shows what these solutions correspond to in the abstract argumentation sense.\nWe now explain the role iteration formulas play in general in the equational context.\nWhen we have a system of equations designed to model an application area1 we face two problems: 1) find any solution to the system of equations, which will have a meaning in the application area giving rise to the equations; 2) given boundary conditions and/or other requirements not necessarily mathematical which are meaningful in the application area,2 we would like to find a solution to the system of equations that is compatible/respects the initial conditions/requirements.\nThese two problems are distinct. The first one of finding any solution is a numerical analysis problem. There are various iteration methods in numerical analysis to find solutions, of which one of the most known is Newton’s method.3 The second problem is totally different. It calls for an understanding of the requirements coming from the application area and possibly the design of a specialised iteration formula which respects the type of requirements involved.\nThis paper provides the Gabbay-Rodrigues Iteration Schema, for the case of the equational approach to argumentation, seeking solutions (which we shall see will correspond to complete extensions) respecting as much as possible initial demands and restrictions of what arguments are in or out of the extension. We compare what our iteration schema does with Caminada and Pigozzi’s downadmissible and up-complete constructions [7]. Because we are dealing with iteration formulas (involving limits) and we are comparing with set theoretical operations (as in Caminada and Pigozzi’s paper) we have to be detailed and precise and despite it being conceptually clear and simple, the proofs turn out to be mathematically involved, and require some patience from our readers. However, once we establish the properties of our iteration schema, its use and application are straightforward and computationally simple, especially in the context of such tools as MATHEMATICA and others like it. The reader may wish to just glance at the technical proofs and concentrate on the examples and\n1For example, equations of fluid flow in hydrodynamics or equations of particle motion in mechanics, or equations modelling argumentation networks according to the equational approach (to be explained later), or equations modelling a biological system of predator-prey ecology, or some polynomial equation arising in macroeconomics.\n2For example, initial conditions in the case of particle mechanics, or initial size of population in the ecology, or arguments that we would like to be accepted.\n3This method starts with an initial guess of a possible solution and uses various iteration formulae hoping that it will converge to a solution (for an introduction on numerical analysis see [21]).\ndiscussions. Note the iteration schema idea is very general and applies to other systems of equations possibly using other iteration formulas.\nThe actual technical development of the paper will start in Section 2. In Appendix A we emphasise the distinction between the above two problems with two detailed examples, the first modelling the dynamics of predator-prey interactions and the second about merging/voting in argumentation networks. We shall see that Newton’s method does not work in these scenarios and that there is the need for a new type of iteration schema. Thus this paper is not just incremental to the equational approach but constitutes a serious and necessary conceptual extension."
    }, {
      "heading" : "1.2 Background",
      "text" : "An abstract argumentation framework is a formalism proposed by Dung [10] and defined in terms of a tuple 〈S,R〉, where S is a non-empty set of arguments and R ⊆ S×S is a binary attack relation. We will refer to an abstract argumentation framework 〈S,R〉 simply as an argumentation network. If (X,Y ) ∈ R, we say that the argument X attacks the argument Y . 〈S,R〉 can be seen as a directed graph (see Figure 1). As informally introduced in Section 1, Att(X) will be used to denote the set {Y ∈ S | (Y,X) ∈ R}, i.e., the set of arguments attacking the argument X. Following graph theory convention, if X has no attackers (i.e., Att(X) = ∅), we say that X is a source node in 〈S,R〉. Given a set E ⊆ S, we write E → X as a shorthand for ∃Y ∈ E, such that (Y,X) ∈ R. Furthermore, following [4], we use E+ to denote the set {Y ∈ S | E → Y }.\nGiven an argumentation network, one usually wants to reason about the status of its arguments, i.e., whether an argument persists or is defeated by other arguments. It should be clear that arguments that have no attacks on them always persist. However, an attack from X to Y may not in itself be sufficient to defeat Y , because X may be defeated by some argument that attacks it, and thus one needs an evaluation process to determine the status of all arguments systematically. In Dung’s original formulation, this was done through an acceptability semantics defining conditions for the acceptability of an argument. The semantics can be defined in terms of extensions — subsets of S with special properties. These subsets are based on two fundamental notions which are explained next.\nA set E ⊆ S is said to be conflict-free if for all elements X,Y ∈ E, we have that (X,Y ) 6∈ R. Intuitively, arguments of a conflict-free set do not attack each other. However, this does not necessarily mean that all arguments in the set are properly supported. Well supported sets satisfy special admissibility criteria. We say that an argument X ∈ S is acceptable with respect to E ⊆ S, if for all Y ∈ S, such that (Y,X) ∈ R, there is an element Z ∈ E, such that (Z, Y ) ∈ R. A set E ⊆ S is admissible if it is conflict-free and all of its elements are acceptable with respect to itself. An admissible set E is a complete extension if and only if E contains all arguments which are acceptable with respect to itself. E is called a preferred extension of S, if and only if E is maximal with respect to set inclusion amongst all complete extensions of S. Similarly, E is called a stable extension of S if and only if E is conflict-free and for every X ∈ S\\E, there is an element Y ∈ E, such that (Y,X) ∈ R.\nNow consider the argumentation networks (L) and (R) depicted in Figure 2. According to the semantics given above, the network (L) has three extensions E0 = ∅, E1 = {X} and E2 = {Y }. Both E1 and E2 are preferred and stable extensions. The network (R) only has only one extension, which is empty, and hence this is also its only preferred extension. This extension is however not stable.\nBesides Dung’s acceptability semantics, it is also possible to give meaning to these networks through Caminada’s labelling semantics [6, 5] and through Gabbay’s equational approach [13, 14]. These are explained next.\nThe labelling semantics. The labelling semantics uses labelling functions λ : S −→ {in,out,und} satisfying certain conditions tailored so as to obtain a complete correspondence with Dung’s semantics.\nThe labelling of an argument in disagreement with Dung’s semantics is said to be “illegal”. This is explained further as follows.\nDefinition 1.1 (Illegal labelling of an argument [7]) Let 〈S,R〉 be an argumentation network and λ a labelling function for S.\n1. An argument X ∈ S is illegally labelled in by λ if λ(X) = in and there exists Y ∈ Att(X) such that λ(Y ) 6= out.\n2. An argument X ∈ S is illegally labelled out by λ if λ(X) = out and there is no Y ∈ Att(X) such that λ(Y ) = in.\n3. An argument X ∈ S is illegally labelled und by λ if λ(X) = und and either for all Y ∈ Att(X), λ(Y ) = out or there exists Y ∈ Att(X), such that λ(Y ) = in.\nA legal (complete) labelling is a labelling in which no argument is illegally labelled.\nIt is possible to have more than one legal labelling function for the same argumentation network. Each labelling function will correspond to an extension in Dung’s semantics. For example, for network (L), we have the three functions λ1, λ2 and λ0 below.\nλ1 ⇔ E1 = {X} λ2 ⇔ E2 = {Y } λ0 ⇔ E0 = ∅ λ1(X) = in λ2(X) = out λ0(X) = und λ1(Y ) = out λ2(Y ) = in λ0(Y ) = und\nFor the network (R), we have only the function λ such that λ(X) = λ(Y ) = λ(Z) = und. This gives the empty extension.\nThe equational approach. The equational approach views an argumentation network 〈S,R〉 as a mathematical graph generating equations for functions in the unit interval U = [0, 1]. Any solution f to these equations conceptually corresponds to an extension. Of course, the end result depends on how the equations are generated and we can get different solutions for different equations. Once the equations are fixed, the totality of the solutions to the system of equations is viewed as the totality of extensions via an appropriate mapping. One equation schema we can possibly use for generating equations is the Eqmax below, where V (X) is the value of a node X ∈ S:\n(Eqmax) V (X) = 1−maxYi∈Att(X){V (Yi)}\nAnother possibility is Eqinv: (Eqinv) V (X) = ∏ Yi∈Att(X)(1− V (Yi))\nIt is easy to see that according to Eqmax the value of any source argument will be 1 (since they have no attackers) and the value of any argument with an attacker with value 1 will be 0. The situation is more complex with nodes participating in cycles. Consider the network (L) again, with equations\nV (X) = 1− V (Y ) V (Y ) = 1− V (X)\nIf values are taken from the unit interval, this system of equations will accept any solution V such that V (X) + V (Y ) = 1. We can divide these solutions between three classes: V 1(X) = 1, V 1(Y ) = 0; V 2(X) = 0, V 2(Y ) = 1 and 0 < V 0(X) < 1, 0 < V 0(Y ) < 1 with V 0(X) + V 0(Y ) = 1. These again correspond to the three extensions E1, E2 and E0 given before.\nIn fact, Gabbay has shown that in the case of Eqmax the totality of solutions to the system of equations corresponds to the totality of extensions in Dung’s sense [14]. The correspondence is best explained in terms of the labelling semantics, using the following correspondence:\nV (X) = 1 :: λ(X) = in V (X) = 0 :: λ(X) = out 0 < V (X) < 1 :: λ(X) = und\nThe advantage of the equational approach is that it allows us to think of an argumentation network as a numeric system in which nodes are given certain values depending on specific rules governing their interaction with their neighbours. A rule may for instance require the value of a node to be 0 if the value of any attacking node is 1. Another rule may force the value of a node to be 1 if it has no attacking nodes. The schema Eqmax and Eqinv embed these rules, and they agree with Dung’s semantics. A solution to the system of equations is any combination of values of nodes satisfying the equations. Of course, since the node values are no longer discrete we have more freedom to design rules which are appropriate for a given application. Part of the objective of this paper is to explore the nature of these rules.\nWe start by generalising some concepts a bit further. Consider the network in Figure 3 in which Att(X) = {Y1, Y2, . . . , Yk}. To agree with Dung’s semantics, if the value of any attacker of X is 1, we want the value of X to be 0. If all of the attackers of X have value 0, we want the value of X to be 1. For any other combination of values of the attackers we want the value of X to be anything other than 0 or 1. So within the traditional semantics but taking the extended set of values of the unit interval, we can think of a single attack by a node with value v as the order-reversing operation which returns the value 1− v. This is a kind of negation.4 Since a node can have multiple attacks, we also need an operation to combine the values of the attackers. We can think of this as a type of conjunction, which numerically can be obtained through several operations. For instance, in fuzzy logic, the standard semantics of (weak) conjunction is given by the operation min.\n4If we make und equals 1\n2 , then an attack by a single undecided node will have value 1 2 .\nTherefore, the value of a node X can be defined as\nV (X) = min Y ∈Att(X)\n{1− V (Y )}\nwhich is equivalent to\nV (X) = 1− max Y ∈Att(X) {V (Y )}\nobtained by our now familiar schema Eqmax. Note that the conjunction operation in the schema Eqinv is product. The operations min and product are two examples of t-norms. They are two instances of functions that are particularly suitable for argumentation semantics. The following definition elaborates on this further.\nDefinition 1.2 A function g with domain being the family of all finite sequences of elements from U and range U is argumentation-friendly if g satisfies the following conditions.\n(T1) g(∅) = 1\n(T2) g(1; ∆) = g(∆)5\n(T3) g(〈x1, . . . , x, . . . , y, . . . , xn〉) = g(〈x1, . . . , y, . . . , x, . . . , xn〉)\n(T4) g(∆) = 0 if and only if 0 ∈ ∆\n(T5) g(∆) = 1 if and only if x = 1 for every x ∈ ∆\n(T6) g is continuous as a multi-variable function6\nExample 1.1 Below are some examples of argumentation-friendly functions: 1. g(∆) = {\n1, if ∆ = ∅ min{xi}, if ∆ = 〈x1, . . . , xn〉\n2. g(∆) = {\n1, if ∆ = ∅ Πn1 (1− xi), if ∆ = 〈x1, . . . , xn〉\n3. gλ(∆) = (1−λ) min{ 12 , g(∆)}+λmax{ 1 2 , g(∆)}, for any g satisfying (T1)–\n(T6).\nLater on, we will see that argumentation-friendly functions will be used both to calculate aggregation of attacks as well as for combining the value of attacks with initial values. However, as we mentioned attack is a type of negation and hence when operating on the attack of a node with value v, we will consider the complement of v to 1, i.e., (1− v).\nNotice that t-norms satisfy conditions (T1)–(T4) above. 5The values of g for any sequence containing the value 1 is the same as the value of g for the subsequence without the 1. 6In fact, this condition is only needed to guarantee the existence of solutions to the equations.\nDefinition 1.3 For any assignment of values v : S 7−→ U define the sets in(v) = {X ∈ dom v | v(X) = 1} and out(v) = {X ∈ dom v | v(X) = 0}.\nTheorem 1.1 Let N = 〈S,R〉 be a network, g an argumentation-friendly function, and T a system of equations written for N , where for each node X, V (X) = gY ∈Att(X)({1 − V (Y )}). Take any solution V to T , it follows that in(V ) is a complete extension. Proof. Suppose that in(V ) is not conflict-free. Then there are X,Y ∈ in(V ), such that (X,Y ) ∈ R. Since Y ∈ in(V ), then V (Y ) = 1 = gW∈Att(Y )({1 − V (W )}). But X ∈ Att(Y ) and X ∈ in(V ), and hence V (X) = 1. It then follows by (T4) that g(〈. . . , 0, . . .〉) = 0 and hence 1 6= 0, a contradiction.\nNow suppose that X ∈ in(V ). We show that for all Y ∈ Att(X) there exists Z ∈ in(V ), such that (Z, Y ) ∈ R. If V (X) = 1, then gY ∈Att(X)({1−V (Y )}) = 1 and then by (T5) it follows that 1 − V (Y ) = 1, for all Y ∈ Att(X) and hence V (Y ) = 0 for all Y ∈ Att(X). Take any such Y . Since V (Y ) = 0, we have by (T4) that for some W ∈ Att(Y ), V (W ) = 1. It then follows that W ∈ in(V ).\nTheorem 1.2 Let N = 〈S,R〉 be a network, g an argumentation-friendly function, and T a system of equations written for N , where for each node X, V (X) = gY ∈Att(X){1 − V (Y )}. Then for every preferred extension EN of N , there exists a solution V to T such that\n(C1) If X ∈ EN , then V (X) = 1\n(C2) If EN → X, then V (X) = 0\n(C3) If X 6∈ EN and EN 6→ X, then 0 < V (X) < 1\nProof. Let us start by partitioning the set S using EN into three sets ∆1 = EN , ∆0 = {X ∈ S | EN → X}, and ∆u = S\\(∆0 ∪∆1). Note that the elements of ∆u are the undecided elements in S with respect to EN . Each element of ∆u is not attacked by any element of ∆1 and its attackers cannot all come from ∆0, i.e., at least one attacker comes from ∆u itself. Consider the argumentation network 〈∆u, R ∆u〉. Write a system of equations Tu using g for 〈∆u, R ∆u〉. For each X ∈ ∆u, the equation is\nVu(X) = gY ∈∆u s.t. (Y,X)∈R ∆u{1− Vu(Y )}\nBy Brouwer’s theorem, the above equations have a solution Vu.7 To be clear Vu is defined on ∆u, giving values Vu(X), such that for every X ∈ ∆u, Vu(X) = gY ∈∆u s.t. (Y,X)∈R ∆u{1− Vu(Y )}\nWe are seeking however a solution V defined for all of S = ∆0 ∪∆1 ∪∆u, which satisfies the system of equations T for 〈S,R〉:\nV (X) = gY ∈Att(X){1− V (Y )} 7The Euclidean version of the theorem states that if g is a real-valued function, defined and continuous on a bounded closed interval I of the real line where g(x) ∈ I, for all x ∈ I, then g has a fixed-point. In our case, there are n = |S| variables in the network 〈S,R〉, which we can associate with the vector −→ X . We can then see each equation as −→ X = −→g ( −→ X ), where −→g is a continuous function on the n-dimensional space [0, 1]n (see Theorem 1.2 in [21]).\nFurthermore, we want V to be such that V (X) = 1 for X ∈ ∆1, V (X) = 0, for X ∈ ∆0 and V (X) ∈ (0, 1) for X ∈ ∆u. We now define such a solution V . Let\nV (X) = 1, for all X ∈ ∆1 V (X) = 0, for all X ∈ ∆0 V (X) = Vu(X), for all X ∈ ∆u\nWe have to show now that V indeed solves the system of equations T for 〈S,R〉. Take X ∈ S: Case 1: X ∈ ∆1. We defined V (X) = 1. We need to show that 1 = gY ∈Att(X) {1−V (Y )}. Since X ∈ EN , then all of its attackers are in ∆0, and then V (Y ) = 0 (by definition), for all Y ∈ Att(X). Therefore, gY ∈Att(X){1− V (Y )} = 1, by (T5).\nCase 2: X ∈ ∆0. We defined V (X) = 0. We need to show that 0 = gY ∈Att(X) {1− V (Y )}. Since EN → X, then there exists Y ∈ Att(X), such that Y ∈ ∆1. By definition, V (Y ) = 1, and then gY ∈Att(X){1− V (Y )} = 0, by (T4). case 3: X ∈ ∆u. We defined V (X) = Vu(X) = gY ∈∆u s.t. (Y,X)∈R ∆u{1 − Vu(Y )}. We need to show that gY ∈Att(X){1 − V (Y )} = gY ∈∆u s.t. (Y,X)∈R ∆u {1 − Vu(Y )}. We noted above, that X ∈ ∆u implies that none of its attackers belong to ∆1 and therefore any remaining attackers Z not in ∆u must be in ∆0. By definition, V (Z) = 0, therefore 1 − 0 = 1 and by (T2), such values can be safely deleted in the calculation of gY ∈Att(X){1 − V (Y )}. Therefore, deleting all such values will show that gY ∈∆u s.t. (Y,X)∈R ∆u{1−Vu(Y )} = gY ∈∆u∪∆0 s.t. (Y,X)∈R{1− Vu(Y )}.\nHaving shown that V above solves the system of equations T , we can use Theorem 1.1 to show that in(V ) is a complete extension. We now ask whether any of the values Vu(X), for X ∈ ∆u can be 0 or 1. The answer is no, for if Vu(X) = 1 for any X ∈ ∆u, then V (X) = 1 and then X ∈ in(V )\\EN , which is impossible, since EN is a preferred extension. Analogously, we can only get V (X) = 0 for some X ∈ Deltau, if for some of its attackers Z ∈ ∆u, V (Z) = 1, which as we mentioned is impossible. This completed the proof.\nThe condition of preferred extension of the Theorem 1.2 is necessary, as shown in the example below.\nExample 1.2 Consider the complete extension E = {X} of the network below. E is not preferred, since E is a proper subset of {X,W}.\nX Y W Z\nThe network generates the following equations.\nV (X) = 1− V (Y ) (1) V (Y ) = 1− V (X) (2) V (W ) = 1− V (Z) (3) V (Z) = g({1− V (W ), 1− V (Z)}) (4)\nSince V (X) = 1, we get that V (Y ) = 0 and these values satisfy equations (1) and (2) above. However, replacing (3) in (4) gives us\nV (Z) = g(V (Z), 1− V (Z))\nIf g is product, this gives us V (Z) = V (Z)·(1−V (Z))), and hence 1 = 1−V (Z) ∴ V (Z) = 0, and hence V (W ) = 1, and therefore no solution corresponding to E using g exists. Note that the two preferred extensions {X,W} and {Y,W} include W . No extension can include Z.\nHowever, with g as min, we have that (4) becomes\nV (Z) = min({1− V (W ), 1− V (Z)})\nand for this set of equations, the values V (X) = 1, V (Y ) = 0, V (W ) = V (Z) = 1 2 form a solution corresponding to E.\nThe loop in the example above is quite elucidating. Let us analyse it in some more detail.\nExample 1.3 Consider the network with a single self-referencing loop below.\nX\nThe network generates the equation:\nV (X) = g({1− V (X)})\nNotice that g({1 − V (X)}) = 1 − V (X) and hence we have that V (X) = 1 − V (X) ∴ V (X) = 12 , whatever the function g is, as long as it satisfies (T1)–(T5).\nNote that min satisfies (T1)–(T4). As a result, we have that:\nCorollary 1.1 Let N = 〈S,R〉 be a network and T a system of equations written for N , where for each node X, V (X) = minY ∈Att(X)({1 − V (Y )}). Take any solution V to T . It follows that in(V ) is a complete extension.\nThis follows from Theorem 1.1. What it means is that any solution to the system of equations defined in terms of Eqmax can be translated into a complete extension simply by defining that extension as the set containing the nodes whose solution values are 1. Obviously, different solutions will give rise to different extensions.\nProposition 1.1 Let N = 〈S,R〉 be a network and T a system of equations written for N , where for each node X, V (X) = minY ∈Att(X)({1 − Y }). Then for every complete extension E of N , there exists a solution V to T satisfying:\n(C1) If X ∈ E, then V (X) = 1.\n(C2) If E → X, then V (X) = 0.\n(C3) If X 6∈ E and E 6→ X, then 0 < V (X) < 1.\nProof. Let E be a complete extension. Consider the following assignment of values to the nodes in S:\n• if X ∈ E, then V (X) = 1\n• if E → X, then V (X) = 0\n• V (X) = 12 , otherwise\nWe now show that the values above form a solution to the system of equations T . As in Theorem 1.2, replacing the above values in the original system of equations will reduce them to the following types.\n(1) 1 = min(∆1)\n(2) 0 = min(∆2)\n(3) 12 = min(∆3)\nWe have seen that ∆1 = {1} and since 1 = min({1}), (1) is satisfied. Similarly, 0 ∈ ∆2 and since min({0, . . .}) = 0, so is (2). Notice that the image of V is {0, 1/2, 1}. All values in ∆3 are greater than 0, but at least one of them is 12 , therefore min(∆3) = 12 , and hence the above assignment solves the equations.\nSo far, we have shown the basics of the equational numerical approach to abstract argumentation frameworks. In the next section we consider two additional developments that follow naturally. Firstly, we know that solutions do exist to the system of equations, but can we find them using some numerical method? For example, by applying iterations given some initial guess?8 Secondly, we would like to apply our methodology to questions of merging, voting, or any other application where a set of initial values emerges and needs to be transformed to the “closest” extension. How can we do that? The following section provides a method to answer these questions."
    }, {
      "heading" : "2 The Gabbay-Rodrigues Iteration Schema",
      "text" : "Suppose we are given initial values which do not correspond to any extension in the way that we presented them in the previous section. These values may come attached to the nodes for different reasons. For instance, the arguments themselves may be expressed as some proof in a fuzzy logic and the initial values can represent the values of the conclusions of the proofs, or they can be obtained as the result of the merging of some networks, or they may come from some voting mechanism, etc. Whatever the reason, the initial values may or may not\n8As can be done to find the square root of numbers using Newton’s method.\ncorrespond to a complete extension in Dung’s sense and we seek a mechanism that would allow us to find the “best” possible extension corresponding to them.\nConsider the equation Eqmax:\n(Eqmax) V (X) = 1−maxYi∈Att(X){V (Yi)}\nEqmax is satisfied when the value of the node X is legal (in Caminada and Pigozzi’s terminology [7]). That is, if the value of X is 1 and the value of all of X’s attackers are 0; or if the value of X is 0 and at least of one X’s attackers has value 1; or if the value of X ∈ (0, 1) and at least one of X’s attackers has value in (0, 1) and no attacker of X has value 1. If we aim to correct the values of the nodes in a network iteratively, we need a mechanism that leaves legal in, out and und node values intact, changing illegal in or out values into und.9 To make a distinction between these classes of values, we will call the values in {0, 1} crisp and the values in (0, 1) undecided.\nNow consider the following averaging function:\n(1−X) ·min {\n1 2 , 1−maxY ∈Att(X) Y\n} +X ·max { 1 2 , 1−maxY ∈Att(X) Y } For legal assignments of values, we have three cases to consider:\n(L1) X is legally in. In this case X = 1 and all of its attackers have value 0. We want the value of X to remain 1. We have that:\n(1−X) ·min { 1\n2 , 1− max Y ∈Att(X) Y\n} +X ·max { 1\n2 , 1− max Y ∈Att(X) Y\n} =\n1 ·max { 1\n2 , 1\n} =\n= 1\n(L2) X is legally out. In this case X = 0 and at least one of its attackers has value 1. We want the value of X to remain 0. We have that:\n1 ·min { 1\n2 , 1− max Y ∈Att(X) Y\n} +X ·max { 1\n2 , 1− max Y ∈Att(X) Y\n} =\n1 ·min { 1\n2 , 0\n} + 0 ·max { 1\n2 , 0\n} =\n= 0\n(L3) X is legally und. In this case 0 < X < 1, none of its attackers has value 1 and at least one of its attackers has value greater than 0. This means that 0 < maxY ∈Att(X) Y < 1 and therefore 0 < (1−maxY ∈Att(X) Y ) < 1. Let α1 = min { 1 2 , 1−maxY ∈Att(X) Y } and α2 = max { 1 2 , 1−maxY ∈Att(X) Y } .\nIt follows that 0 < α1 < 1 and 0 < α2 < 1. We want the value of X to 9We will come to the correction of illegal und nodes later.\nremain undecided, although we are prepared to accept changes to its initial value as long as its final value remains in the interval (0, 1). We have that:\n(1−X) ·min { 1\n2 , 1− max Y ∈Att(X) Y\n} +X ·max { 1\n2 , 1− max Y ∈Att(X) Y\n} =\n(1−X) · α1 +X · α2 = α1 −X · α1 +X · α2 = α1 −X · (α1 − α2) = κ\nNotice that α1 ≤ 12 and α2 ≥ 1 2 , therefore α2 6< α1. If α1 = α2, then κ = α1 and hence 0 < κ ≤ 12 . If α1 < α2, then 0 < α1 < 1 2 and α2 = 1 2 . Therefore, − 12 < (α1 − α2) < 0. It then follows that 0 < α1 ≤ κ < 1 2 and therefore the value of X remains in (0, 1).\nWhat (L1)–(L3) above give us is that legal labellings are preserved.10 Later on, we shall see that our iteration schema also eventually corrects all illegal values. It does so in two stages. In the first stage, all illegal crisp values are turned into undecided (this is done in t ≤ |S| iterations). In the second stage, all remaining illegal undecided values converge to whatever legal crisp values they should be, so that in the limit, all of the values in the sequence are legal. Therefore, the Gabbay-Rodrigues Iteration Schema introduced below provides a numerical iterative method to turn any initial illegal assignment of values to arguments into its closest legal assignment.11\nDefinition 2.1 Let N = 〈S,R〉 be an argumentation network and V0 be an assignment of values to the nodes in S. The Gabbay-Rodrigues Iteration Schema is defined by the following system of equations T , where for each node X ∈ S, the value Vi+1(X) is defined in terms of the values of the nodes in Vi as follows:\nVi+1(X) = (1− Vi(X)) ·min { 1 2 , 1−maxY ∈Att(X) Vi(Y ) } +\nVi(X) ·max { 1 2 , 1−maxY ∈Att(X) Vi(Y ) } (T) We call the system of equations for N using the above iteration schema its GR system of equations. We ask whether we can regard the iteration schema above as an equation schema as in the previous section, i.e.,\nX = (1−X) ·min { 1\n2 , 1− max Y ∈Att(X) Y\n} +X ·max { 1\n2 , 1− max Y ∈Att(X) Y\n} (GR)\n10Legal undecided values may change, although they remain in the undecided range (by (L3)).\n11The precise definition of “closest” will be made clear in Theorem 2.9.\nTo further clarify this point, let us take an equation written with an argumentation-friendly function g for a node X in terms of its attackers. The equation would be\nX = g(∪Y ∈Att(X){1− Y })\nIt is clear that if one of the attackers of X is 1, the value of X solves to 0, and if all the attackers of X are 0, the value of X will solve to 1. This follows from the properties (T1)–(T5) of an argumentation-friendly function. Now let us compare and see what happens when we use the formula above. If the value of one of the attackers of X is 1, the first component of the sum will be 0, whereas the second component will be 12 , because the equation is implicit, we have the equation\nX = X\n2\nwhich solves to X = 0, which is correct. If the values of all attackers of X are 0, then we get the equation\nX = (1−X)\n2 +X\nwhich solves to X = 1, which again gives a correct result. Otherwise, assume that the values of all attackers are either 0 or 12 , with at least one of them being 1 2 . We get the equation\nX = (1−X) 2 + X 2\nwhich again solves to the correct value of X = 12 . By correct we mean that the results are exactly compatible with the Caminada labelling mentioned in Section 1, where X = 1 means X is in, X = 0 means X is out and X = 12 means X is und.\nTherefore, the Gabbay-Rodrigues schema remains faithful to the spirit of Dung’s semantics captured through the legal Caminada labellings just as Eqmax does. Its advantage over Eqmax is that it can be used iteratively as we will show in the rest of this section. 12\nWe start by showing some properties of the schema. The first one ensures that the values of all nodes remain in the unit interval in all iterations.\nProposition 2.1 Let N = 〈S,R〉 be an argumentation network and V0 : S 7−→ U an assignment of initial values to the nodes in S. Let each assignment Vi, i > 0, be calculated by the Gabbay-Rodrigues Iteration Schema for N . It follows that Vi(X) ∈ U , for all i ≥ 0 and all X ∈ S. Proof. The base of the induction is the initial value assignment that holds trivially. The induction step is proven by looking at the maximum and minimum values that the nodes can take and showing that the sum in the iterated schema\n12As an equation, we can regard the expression (GR) just as another type of g, a special eqGR.\nis always a number in U . Now, suppose that indeed for all nodes X ∈ S, 0 ≤ Vk(X) ≤ 1, for a given iteration k. Pick any node X. It follows that\nVk+1(X) = (1− Vk(X)) ·min {\n1/2, 1− max Y ∈Att(X) Vk(Y )\n} +\nVk(X) ·max {\n1/2, 1− max Y ∈Att(X) Vk(Y ) } So we have that Vk+1(X) = (1−α) ·x+α ·y, where 0 ≤ α ≤ 1, 0 ≤ (1−α) ≤ 1, 0 ≤ x ≤ 1/2, and 1/2 ≤ y ≤ 1.\nThe lowest value for Vk+1(X) is obtained with the lowest values for x and y, when we get that Vk+1(X) = α2 . If α = 0, then Vk+1(X) = 0 ≥ 0. If α = 1, then we get Vk+1(X) = 1/2 ≤ 1. The highest value for Vk+1(X) is obtained with the highest values for x and y, when we get that Vk+1(X) = (1−α) 2 +α. If α = 0, then Vk+1(X) = 1/2 ≤ 1. If α = 1, then we get Vk+1(X) = 1 ≤ 1. In all cases, 0 ≤ Vk+1(X) ≤ 1.\nWe now show that a given “legal” set of initial values for the nodes in S satisfies the equations and hence the values remain unchanged.\nProposition 2.2 Let N = 〈S,R〉 be a network and T its GR system of equations. Then for every complete extension E of N and all X ∈ S, if V0 is defined using E by the clauses (C1)–(C3) below, we have that V1(X) = V0(X).\n(C1) If X ∈ E, then V0(X) = 1\n(C2) If E → X, then V0(X) = 0\n(C3) If X 6∈ E and E 6→ X, then V0(X) = 12 Proof. Let E be a complete extension and suppose V0(X) = 1. Then X ∈ E and hence, i) either Att(X) = ∅, or ii) for all Y ∈ Att(X), E → Y (since E is admissible). As a result, 1−maxY ∈Att(X){V (Y )} = 1, and hence we have that\nV1(X) = max\n{ 1\n2 , 1\n} = 1 = V0(X).\nIf on the other hand, V0(X) = 0, then E → X. Therefore, there exists some Y ∈ Att(X), such that Y ∈ E and hence V0(Y ) = 1. It follows that\nV1(X) = min\n{ 1\n2 , 1− 1\n} = 0 = V0(X).\nFinally, if V0(X) = 12 , then X 6∈ E and E 6→ X. We must have that for all Y ∈ Att(X), V0(Y ) < 1 (otherwise, we would have that E → X). We must also have that for some Y ∈ Att(X), V0(Y ) > 0, otherwise E would defend X and since it is complete X ∈ E, but then V0(X) = 1. Therefore, 1−maxY ∈Att(X){V (Y )} = 12 , and hence we have that\nV1(X) = 1\n2 ·min\n{ 1\n2 ,\n1\n2\n} + 1\n2 ·max\n{ 1\n2 ,\n1\n2\n} = 1\n4 +\n1 4 = 1 2 = V0(X).\nObviously, if for all nodes X, V1(X) = V0(X) as above, then for all nodes X, Vi+1(X) = Vi(X), for all i ≥ 0.\nFurthermore, crisp values do not “swap” between each other and undecided values do not become crisp:\nTheorem 2.1 Let N = 〈S,R〉 be an argumentation network, T a system of equations for N using the Gabbay-Rodrigues Iteration Schema, and V0 : S 7−→ U an assignment of initial values to the nodes in S. Let V0, V1, V2, . . . be a sequence of value assignments where each Vi, i > 0, is generated by T . Then the following properties hold for all X ∈ S and for all k ≥ 0\n1. If Vk(X) = 0, then Vk+1(X) 6= 1.\n2. If Vk(X) = 1, then Vk+1(X) 6= 0.\n3. If 0 < Vk(X) < 1, then 0 < Vk+1(X) < 1.\nProof.\n1. Suppose Vk(X) = 0, then Vk+1(X) = min { 1/2, 1−maxY ∈Att(X) Vi(Y ) } ≤\n1/2. 2. Suppose Vk(X) = 1, then Vk+1(X) = max { 1/2, 1−maxY ∈Att(X) Vi(Y ) } ≥\n1/2.\n3. Suppose 0 < Vk(X) < 1. We first show that Vk+1(X) > 0. Note that 0 < (1− Vk(X)) < 1. Therefore, we have that\nVk+1(X) = (1− Vk(X)) ·min {\n1/2, 1− max Y ∈Att(X) Vi(Y )\n} +\nVk(X) ·max {\n1/2, 1− max Y ∈Att(X) Vi(Y ) } It is easy to see that the first component of the above sum is greater than or equal to 0, whereas the second is strictly greater than 0, and hence Vk+1(X) > 0.\nSince we start with values in U , Proposition 2.1, gives us that Vk+1(X) ≤ 1, for all X ∈ S. We therefore only need to show that Vk+1(X) 6= 1. Again we have that Vk+1(X) = (1− α) · x+ α · y, where\n0 < α < 1\n0 < (1− α) < 1 0 ≤ x ≤ 1/2 1/2 ≤ y ≤ 1\nSuppose Vk+1(X) = 1. It follows that\n(1− α) · x+ α · y = 1 x− α · x+ α · y = 1\nα(y − x) = (1− x)\nα = 1− x y − x\nSince α < 1, we have that 1−x < y−x, and hence y > 1, a contradiction.\nThe above theorem shows that any changes between iterations can only generate new values for nodes in the interval (0, 1), i.e., successive iterations can only turn crisp values into undecided. Therefore, the sets of nodes with crisp values can only decrease throughout the iterations:\nCorollary 2.1 Let N = 〈S,R〉 be an argumentation network, V0 : S 7−→ U an initial assignment of values to the nodes in S and T its GR system of equations. It follows that for all 0 ≤ i ≤ j, in(Vj) ⊆ in(Vi) and out(Vj) ⊆ out(Vi).\nThe situation in the limit of the sequence of values is more complex and we will deal with it later. If between two successive iterations there are no changes in the crisp values, then these values “stabilise”:\nTheorem 2.2 Let N = 〈S,R〉 be a network, T its GR system of equations, and V0 an initial assignment of values to the nodes in S. Let V0, V1, V2, . . . be a sequence of value assignments where each Vi, i > 0, is generated by T . Assume that for some iteration i and all nodes X ∈ S such that Vi(X) ∈ {0, 1}, we have that Vi+1(X) = Vi(X), then for all j ≥ 1, Vi+j(X) = Vi(X). Proof. Assume that Vi(X) ∈ {0, 1} for some node X. There are two cases to consider.\nCase 1: Vi(X) = 0. By assumption, we have that Vi+1(X) = 0. We show that Vi+2(X) = 0. If Vi+1(X) = 0, we have that\nVi+1(X) = (1− Vi(X)) ·min { 1\n2 , 1− max Y ∈Att(X) {Vi(Y )}\n} +\nVi(X) ·max { 1\n2 , 1− max Y ∈Att(X) {Vi(Y )} } 0 = min { 1\n2 , 1− max Y ∈Att(X) {Vi(Y )} } So, maxY ∈Att(X){Vi(Y )} = 1 and hence for some Y ∈ Att(X), Vi(Y ) = 1. By assumption Vi+1(Y ) = 1 and hence maxY ∈Att(X){Vi+1(Y )} = 1. Therefore,\nVi+2(X) = min\n{ 1\n2 , 1− max Y ∈Att(X) {Vi+1(Y )}\n} = 0\nCase 2: Vi(X) = 1. By assumption, we have that Vi+1(X) = 1. We show that Vi+2(X) = 1. If Vi+1(X) = 1, we have that\nVi+1(X) = (1− Vi(X)) ·min { 1\n2 , 1− max Y ∈Att(X) {Vi(Y )}\n} +\nVi(X) ·max { 1\n2 , 1− max Y ∈Att(X) {Vi(Y )} } 1 = max { 1\n2 , 1− max Y ∈Att(X) {Vi(Y )}\n}\nSo, maxY ∈Att(X){Vi(Y )} = 0, and hence for all Y ∈ Att(X), Vi(Y ) = 0. By assumption, maxY ∈Att(X){Vi+1(Y )} = 0, and hence\nVi+2(X) = max\n{ 1\n2 , 1− max Y ∈Att(X) {Vi+1(Y )}\n} = 1\nDefinition 2.2 Let N = 〈S,R〉 be an argumentation network and V0 : S 7−→ U an assignment of initial values to the nodes in S. A sequence of assignments Vi : S 7−→ U where each i > 0 is generated by the Gabbay-Rodrigues Iteration Schema for N becomes stable at iteration k, if for all nodes X ∈ S we have that\n1. If Vk(X) ∈ {0, 1}, then Vk+1(X) = Vk(X); and\n2. k is the smallest value for which the condition above holds.\nNote that if Vk(X) ∈ (0, 1), then Vk+1(X) ∈ (0, 1), for all k ≥ 0, by Theorem 2.1.\nCorollary 2.2 Consider a sequence of value assignments V0, V1, V2, . . . as described in Theorem 2.2. If the sequence becomes stable at iteration k, then the sequence remains stable for all iterations k + j, j ≥ 0. Proof. The first stability condition in Definition 2.2 follows from Theorem 2.1 and the second condition follows from Theorem 2.2.\nCorollary 2.3 Let N = 〈S,R〉 be an argumentation network, V0 : S 7−→ U an assignment of initial values to the nodes in S and T its GR system of equations. The following hold:\n1. If the sequence of value assignments is not stable at iteration k, then there exists X ∈ S, such that Vk(X) ∈ {0, 1} and Vk+1(X) ∈ (0, 1).\n2. Let |S| = n. Then, the sequence is stable for some k ≤ n.\nProof. (1) follows from Theorem 2.1. For (2), notice that each iteration i which is not stable causes at least one node to change value from {0, 1} into (0, 1). Theorem 2.1 states that all values in (0, 1) remain in (0, 1). Since S is finite, there are only finitely many nodes that can change from {0, 1} into (0, 1) and the number of iterations in which this can happen is bounded by |S|.\nCorollary 2.3 shows that for some value 0 ≤ k ≤ |S|, the sequence of value assignments V0(X), V1(X), V2(X), . . . eventually becomes stable. That is, there exists k ≥ 0, such that for all j ≥ 0 and all nodes X\n• if Vk(X) = 0, then Vk+j = 0;\n• if Vk(X) = 1, then Vk+j = 1; and\n• if Vk(X) ∈ (0, 1), then Vk+j ∈ (0, 1).\nRemark 2.1 Given an argumentation-friendly function g, we can define the Gabbay-Rodrigues Iteration Schema for g, denoted by GR(g), as follows.\nVi+1(X) = (1− Vi(X)) ·min { 1\n2 , g(∪Y ∈Att(X){1− Vi(Y )})\n} +\nVi(X) ·max { 1\n2 , g(∪Y ∈Att(X){1− Vi(Y )}) } If we further assume that g satisfies the optional condition\n(T6) If for all x ∈ ∆, we have that x < 1 and for some x ∈ ∆, x > 0, then g(∆) ∈ (0, 1).\nThen the above sequence of definitions and theorems in this section still holds if we replace GR by GR(g).\nThe above discussion laid out the properties of the Gabbay-Rodrigues Iteration Schema. In what follows we shall apply it to the following question. Suppose we have an argumentation network 〈S,R〉 with associated equations and an initial assignment f : S 7−→ U . f may come from a single agent who insists on giving certain values to the arguments of S; or f may be the result of merging several argumentation frameworks with the nodes in S (through some well-defined process, e.g., voting); or f may arise from any other process. Our problem is to find the function f ′, closest to f , which also corresponds to an extension of 〈S,R〉 (for example, solves the equations generated from 〈S,R〉). Now, what do we mean by “closest”? Following Caminada and Pigozzi [7], we take the view that “closest” means agreeing on the maximal number of nodes with f -values in {0, 1}. In what follows, we show how to find such an assignment f ′, through the Gabbay-Rodrigues Iteration Schema.\nTheorem 2.3 Let 〈S,R〉 be a network and f : S 7−→ U an assignment of values to the nodes in S. Then there is an assignment h : S 7−→ U such that the sets in(h) ⊆ in(f) and out(h) ⊆ out(f) are maximal and for every node X ∈ S:\nIf h(X) = 1, then maxY ∈Att(X){h(Y )} = 0; and (5) If h(X) = 0, then maxY ∈Att(X){h(Y )} = 1. (6)\nProof. The proof is analogous to the proof of Theorem 5 in [7]. Take any two assignments g1 and g2 such that for all X ∈ S:\n• g1(X) = 0 implies f(X) = 0 and g2(X) = 0 implies f(X) = 0; and\n• g1(X) = 1 implies f(X) = 1 and g2(X) = 1 implies f(X) = 1\nand\nIf g1(X) = 1, then maxY ∈Att(X){g1(Y )} = 0; and (7) If g2(X) = 1, then maxY ∈Att(X){g2(Y )} = 0; and (8) If g1(X) = 0, then maxY ∈Att(X){g1(Y )} = 1; and (9)\nIf g2(X) = 0, then maxY ∈Att(X){g2(Y )} = 1 (10)\nIt follows that in(g1) ⊆ in(f) and out(g1) ⊆ out(f); and in(g2) ⊆ in(f) and out(g2) ⊆ out(f).\nLet us construct an assignment h : S 7−→ U , such that for all X ∈ S:\nh(X) = 1 iff max(g1(X), g2(X)) = 1 (11) h(X) = 0 iff min(g1(X), g2(X)) = 0 (12)\nh(X) = 1/2 iff 0 < g1(X) < 1 and 0 < g2(X) < 1 (13)\nWe now show that the assignment h is a well-defined function and that in(h) ⊆ in(f) and that out(h) ⊆ out(f). It is easy to see that every node X gets at least one value h(X). We need to show that for every node X, this value is unique and that the above inclusions are satisfied. From (13), it is easy to see that h(X) is equal to 1/2 if and only if both g1(X) ∈ (0, 1) and g2(X) ∈ (0, 1). To show inclusion, suppose X ∈ in(h). Then h(X) = 1 and hence max(g1(X), g2(X)) = 1. Either g1(X) = 1 or g2(X) = 1 (or both), and hence f(X) = 1. Therefore X ∈ in(f). To show that h(X) is unique in this case, it is sufficient to show that min(g1(X), g2(X)) > 0. Suppose min(g1(X), g2(X)) = 0, then either g1(X) = 0 or g2(X) = 0, in which case f(X) = 0, a contradiction, since f is a function. Analogously, if X ∈ out(h), then h(X) = 0 and hence min(g1(X), g2(X)) = 0. Then either g1(X) = 0 or g2(X) = 0 (or both), and hence f(X) = 0. Therefore, X ∈ out(f). To show that h(X) is also unique in this case, it suffices to show that max(g1(X), g2(X)) < 1. Suppose that max(g1(X), g2(X)) = 1, then either g1(X) = 1 or g2(X) = 1, in which case f(X) = 1, a contradiction, since f is a function.\nWe now show that h satisfies (5) and (6). Suppose h(X) = 1. By construction, max(g1(X), g2(X)) = 1. It follows that i) either X ∈ in(g1), and then by (7), maxY ∈Att(X){g1(Y } = 0. This means that for every Y ∈ Att(X), g1(Y ) = 0. By (12), for every Y ∈ Att(X), h(Y ) = 0, and hence maxY ∈Att(X){h(Y )} = 0; or ii) X ∈ in(g2), and then by (8), maxY ∈Att(X){g2(Y } = 0. By (12), for in(g2) is also admissible, Y ∈ out(g2), and hence for every Y ∈ Att(X), h(Y ) = 0, and hence again maxY ∈Att(X){h(Y )} = 0. This shows that h satisfies (5).\nAs for (6), suppose h(X) = 0, then by the construction of h either g1(X) = 0 or g2(X) = 0 (or both). The two cases are identical. We consider only the case\ng1(X) = 0. By (9), maxY ∈Att(X){g1(Y )} = 1, and hence for some Y ∈ Att(X), g1(Y ) = 1. By (11), we have that h(Y ) = 1 and then maxY ∈Att(X){h(Y )} = 1.\nNote that in(g1) ⊆ in(h), out(g1) ⊆ out(h), in(g2) ⊆ in(h) and out(g2) ⊆ out(h). Therefore, since every g1 and g2 satisfying (7)–(10) give rise to a function h as described, and the number of all such functions is finite, then there exists one such h that the sets in(h) and out(h) are maximal.\nCorollary 2.4 Let 〈S,R〉 be a network and f : S 7−→ U an assignment of values to the nodes in S and h : S 7−→ U the assignment such that the sets in(h) ⊆ in(f) and out(h) ⊆ out(f) are maximal and for every node X ∈ S:\nIf h(X) = 1, then maxY ∈Att(X){h(Y )} = 0; and (14) If h(X) = 0, then maxY ∈Att(X){h(Y )} = 1. (15)\nas given by Theorem 2.3. Then the set in(h) is the largest admissible subset of in(f) such that also out(h) ⊆ out(f). Proof. in(h) is conflict-free: if you take X ∈ in(h), then h(X) = 1 and then maxY ∈Att(X){h(Y )} = 0. Therefore, either Att(X) = ∅; or for all Y ∈ Att(X), h(Y ) = 0, and hence Y 6∈ in(h).\nTo show that in(h) is admissible, we just need to show that if X ∈ in(h) and Y ∈ Att(X), then there exists Z ∈ Att(Y ), such that Z ∈ in(h). Assume that X ∈ in(h) and Y ∈ Att(X). By definition, h(X) = 1, and then by (14), maxWx∈Att(X){h(Wx)} = 0, and hence h(Y ) = 0. By (15), maxWy∈Att(Y ) {h(Wy)} = 1. Therefore, there exists Z ∈ Att(Y ), such that Z ∈ in(h).\nThe fact that in(h) is the largest subset of in(f) subject to out(h) ⊆ out(f) comes directly from Theorem 2.3.\nRemark 2.2 Consider the following network.\nX Y\nThere is no largest admissible subset of E = {X,Y }! There are two maximal admissible subsets E1 = {X} and E2 = {Y }, so the requirement that “no new out nodes are generated” is very important in Theorem 2.3. In terms of assignments (or labellings for that matter) this was expressed as: out(h) ⊆ out(f).13\nIf we are given an assignment f(A) = 1 and f(B) = 1, there is a class of assignments h such that the sets in(h) ⊆ in(f) and out(h) ⊆ out(f) are the largest. For instance, h(A) = h(B) = 12 . In the example above, it is sufficient to set 0 < h(A) < 1 and 0 < h(B) < 1 (we chose the value 12 in Theorem 2.3 simply because we wanted to show that one existed and because as we shall see the legal undecided values will end up converging to 12).\nNote, in particular that the assignment f does not satisfy the conditions of Theorem 2.3 (which guarantee by Corollary 2.4 that in(f) is an admissible\n13If we are given just E, we may want to think of an assignment f such that in(f) = E and out(f) = {X | E → X}, leaving the nodes in S\\(in(E) ∪ out(E)) with a value in (0, 1).\nset). We could turn f into an admissible assignment by just flipping one of the values of A or B to 0. However, if we did this, for instance, by generating the assignment f ′(A) = 1 and f ′(B) = 0, then although in(f ′) is admissible and in(f ′) ⊆ in(f), we would not have that out(f ′) = {B} ⊆ out(f) = ∅!\nThis is as it should be, because an initial assignment f encodes not only which nodes we would like to be in, but also those that we would like to be out, and we cannot decide without further information to optimise on the in’s in detriment of the out’s.\nTheorem 2.4 Let N = 〈S,R〉 be a network and T its GR system of equations. If the sequence of values V0, V1, . . . becomes stable at iteration k, then in(Vk) is the largest admissible set such that in(Vk) ⊆ in(V0) and out(Vk) ⊆ out(V0). Proof. We first show that in(Vk) is an admissible set.\n1. Suppose in(Vk) is not conflict-free. Therefore, there must exist X,Y ∈ in(Vk), such that (Y,X) ∈ R. Since X,Y ∈ in(Vk), Vk(X) = Vk(Y ) = 1. Vk+1(X) = max { 1/2, 1−maxY ∈Att(X) Vk(Y ) } = 1/2, and then the se-\nquence is not stable at k, a contradiction. Therefore, in(Vk) is conflictfree.\n2. Suppose in(Vk) is not admissible. It follows that there exists X ∈ in(Vk) and some Y ∈ S with (Y,X) ∈ R, such that in(Vk) 6→ Y . Since X ∈ in(Vk), then Vk(X) = 1 and since the sequence is stable at k, Vk+1(X) = 1 = max { 1/2, 1−maxW∈Att(X) Vk(W ) } . Therefore, maxW∈Att(X) Vk(W )\n= 0. In particular, Vk(Y ) = 0, and hence Vk+1(Y ) = min {1/2, 1− maxZ∈Att(Y ) Vk(Z) } = 0, and therefore there exists Z ∈ Att(Y ), such that Vk(Z) = 1, and hence Z ∈ in(Vk), and hence in(Vk) → Y , a contradiction. Therefore, in(Vk) is admissible.\nNow we need to show that in(Vk) is indeed the maximal admissible set such that in(Vk) ⊆ in(V0) and out(Vk) ⊆ out(V0). By Theorem 2.3, there are unique maximal sets in(Vmax) ⊆ in(V0) and out(Vmax) ⊆ out(V0) such that in(Vmax) is admissible. Furthermore, in(Vmax) ⊇ in(Vk) and out(Vmax) ⊇ out(Vk). Suppose either in(Vk) or out(Vk) are not maximal and let 0 < j < k be the first index such that there is some X ∈ in(Vmax), such that X 6∈ in(Vj) or that there is some Y ∈ out(Vmax) such that Y 6∈ out(Vj) (or both). We start with the first case. Since X ∈ in(Vmax), then X ∈ in(Vj−1) and hence Vj−1(X) = 1. Since X 6∈ in(Vj), then Vj(X) < 1. It follows that Vj(X) = max { 1/2, 1−maxY ∈Att(X) Vj−1(Y ) } < 1. Therefore, there exists Y ∈ Att(X), such that Vj−1(Y ) > 0 and hence Y 6∈ out(Vj−1). Since in(Vmax) is admissible, Y ∈ out(Vmax) and this is a contradiction with the fact that j was the first index such that there was some Y ∈ out(Vmax) such that Y 6∈ out(Vj) .\nThe second case is analogous. Take Y ∈ out(Vmax) such that Y 6∈ out(Vj). Since Y ∈ out(Vmax), then Y ∈ out(Vj−1) and hence Vj−1(Y ) = 0. Since Y 6∈ out(Vj), then Vj(Y ) > 0. It follows that Vj(Y ) = min{1/2, 1−maxZ∈Att(Y ) Vj−1(Z)} > 0. Therefore, for all Z ∈ Att(Y ) we have that Vj−1(Z) < 1 and hence there is no Z ∈ Att(Y ), such that Z ∈ in(Vj−1). Since Y ∈ out(Vmax),\nthere must be some Z ′ ∈ Att(Y ), such that Z ′ ∈ in(Vmax), but this is a contradiction since Z ′ 6∈ in(Vj−1) and j was the first index such that there was some X ∈ in(Vmax), such that X 6∈ in(Vj).\nRemark 2.3 Given an argumentation network N = 〈S,R〉, an argumentationfriendly function g, a system of equations T written for N using g, and an assignment v : S 7−→ U , which represents initial desired values, then if v corresponds to a complete extension then the above theorems tell us that the sequence of equations V0 = v, V1, V2,. . . will become stable at some iteration k and Vk = v. Otherwise, Vk is the function giving the maximal possible crisp part in(Vk) and out(Vk) agreeing with v such that the set in(Vk) is admissible. We now have the option of extending in(Vk) into a complete extension Ecomp that is the closest extension agreeing with in(v). If this extension is also preferred, then it would correspond to an assignment f ′, which solves the original system of equations T (by Theorem 1.2). If the extension is not preferred, then whether such an f ′ exists depends on the nature of the function g. Some such functions, such as min can always find an f ′ for every complete extension. Others, such as product, can not always find them.14\nWe will see that with the Gabbay-Rodrigues Iteration Schema, if we continue iterating, in the limit of the sequence, we will get an extension.\nThe following definition helps to translate between values in U and values in {in,out,und}.\nDefinition 2.3 (Caminada-Pigozzi/Gabbay-Rodrigues Translation) A labelling function λ and a valuation function V can be inter-defined according to the table below.\nλ(X) → Vλ(X) V (X) → λV (X) in → 1 1 → in out → 0 0 → out und → 1/2 (0, 1) → und\nThe choice of the value 1/2 in the translation from und is arbitrary. Any value in (0, 1) would do, but we will see that legal undecided values will converge to 1/2 in the limit, and so 1/2 is the natural choice.\nDefinition 2.4 A legal assignment V is an assignment of values V : S 7−→ U such that the corresponding labelling function λV defined according to Definition 2.3 is also legal.\nProposition 2.3 Let λ be a labelling function and Vλ its corresponding CaminadaPigozzi translation. If the Gabbay-Rodrigues Iteration Schema is employed using Vλ as V0, then for some value k ≥ 0, the sequence of values V0, V1, . . . will\n14Product is given in Item 2. of Example 1.1. For the network S = {A,B}, R = {(A,B), (B,A), (B,B)} and the complete extension “all undecided”, there is no solution using product.\nbecome stable and the sets in(Vk) and out(Vk) will correspond to the downadmissible labelling of λ. Proof. This follows directly from Theorem 2.4 and Corollary 2.3.\nWe may also arbitrarily start with V0(X) = 1 for all nodes X ∈ S and see if this assignment satisfies the equations. At each iteration, the equations may force the crisp values of some nodes to turn to und. Eventually, some iteration k ≤ |S| will produce the last set of new undecided values, at which point we say that the sequence has stabilised. We have that in(Vk) and out(Vk) correspond to the largest admissible labelling such that in(Vk) ⊆ in(V0) and out(Vk) ⊆ out(V0). in(Vk) can now form the basis of a complete extension. The smallest of such (complete) extensions comes from what Caminada and Pigozzi called the up-complete labelling of λVk :\nDefinition 2.5 ([7]) Let λ be an admissible labelling. The up-complete labelling of λ is a complete labelling λ′ s.t. in(λ′) ⊇ in(λ) and out(λ′) ⊇ out(λ) and in(λ′) and out(λ′) are the smallest sets satisfying these conditions.\nIf we continue with our calculations we can see what happens with the values V0, V1,. . . ,Vi, . . . in the limit of the sequence. We cal these the equilibrium values. Formally,\nDefinition 2.6 Let N = 〈S,R〉 be an argumentation network, T its GR system of equations, and V0 an assignment of initial values to the nodes in S. The equilibrium value of the node X is defined as Ve(X) = limi→∞ Vi(X).\nThe understanding of the meaning of the equilibrium values requires an analysis of the behaviour of the sequence. The value of a node X is essentially determined by the values of the nodes in Att(X). At the stable point k we know that the crisp values remain crisp. The values of the attackers of a node at the stable point k can be of one of three types:\n1. maxY ∈Att(X){Vk(Y )} = 0\n2. maxY ∈Att(X){Vk(Y )} = 1\n3. 0 < maxY ∈Att(X){Vk(Y )} < 1\nIf the value of a node Y at the stable point k is in {0, 1}, then Theorem 2.2 ensures that it will remain the same in the limit limi→∞ Vi(Y ). As it turns out, if maxY ∈Att(X){Vk(Y )} = 0, then limi→∞ Vi(X) = 1. And if maxY ∈Att(X){Vk(Y )} = 1, then limi→∞ Vi(X) = 0, as shown by the next theorem.\nTheorem 2.5 Let N = 〈S,R〉 be an argumentation network and V0 : S 7−→ U assign initial values to the nodes in S. Let the sequence of value assignments V0, V1, V2, . . . where each Vi, i > 0, is generated by the Gabbay-Rodrigues Iteration Schema be stable at iteration k. For every X ∈ S:\n1. If maxY ∈Att(X){Vk(Y )} = 0, then Ve(X) = 1; and\n2. If maxY ∈Att(X){Vk(Y )} = 1, then Ve(X) = 0.\n3. If Vk(X) ∈ {0, 1}, then Ve(X) = Vk(X);\nProof.\n1. If maxY ∈Att(X) Vk(Y ) = 0, and the sequence is stable at k, then by Corollary 2.2, maxY ∈Att(X) Vk+j(Y ) = 0, for all j ≥ 0. We have that\nVk+1(X) = (1− Vk(X)) ·min { 1\n2 , 1\n} + Vk(X) ·max { 1\n2 , 1 } = 1\n2 − Vk(X) 2 + Vk(X) = 1 2 + Vk(X) 2\nVk+2(X) = 1\n2 +\n1 4 + Vk(X) 4\nVk+j(X) = j∑ k=1 1 2k + Vk(X) 2j\nVe(X) = lim j→∞ Vk+j(X)\n= ∞∑ k=1 1 2k + lim j→∞ Vk(X) 2j = 1 + 0 = 1\nSo if the maximum value mk of all attackers of X at iteration k is 0, then the value of X converges to 1; and finally\n2. If maxY ∈Att(X) Vk(Y ) = 1, and the sequence is stable at k, then by Corollary 2.2, maxY ∈Att(X) Vk+j(Y ) = 1, for all j ≥ 0. We have that\nVk+1(X) = (1− Vk(X)) ·min { 1\n2 , 0\n} + Vk(X) ·max { 1\n2 , 0 } = Vk(X)\n2\nVk+2(X) = Vk(X)\n4 ∴ Vk+j(X) =\nVk(X)\n2j\nVe(X) = lim j→∞ Vk+j(X) = lim j→∞\nVk(X)\n2j = 0\nSo if the maximum value mk of all attackers of X at iteration k is 1, then the value of X converges to 0.\n3. This follows from the fact that the sequence is stable at k;\nThe theorem above asserts self-correction for the values of nodes whose attackers are either all out or that have an attacker that is in. Case 3 above, in\nwhich 0 < maxY ∈Att(X){Vk(Y )} < 1, is harder and will be dealt with in stages. We start with the case of a cycle whose values of the nodes are all in (0, 1) (see Figure 4). Such cycles may involve an even or odd number of nodes, so we have chains of attacks of one of the following types:\n• either X = Z1 ← Z2 ← . . .← Z2n = X (even cycle)\n• or X = Z1 ← Z2 ← . . .← Z2n+1 = X (odd cycle)\nThe next lemma shows that in either case, the value of X in the limit is 12 .\nTheorem 2.6 Let the sequence of values V0, V1, . . . , be stable at iteration k. Let X be a point such that Vk+i(X), Vk+i+1(X), . . . ∈ (0, 1), for all i ≥ 0. Our final aim is to show that limi→∞ Vk+i(X) = 12 . As a first step towards our goal, we show that any converging subsequence V ck+j(X) converges to 1 2 (by a subsequence V ck+j(X) we mean some of the elements of the sequence Vk+i(X), that is for every j there is an ij such that V ck+j(X) = Vk+ij (X)). From now on we talk about the subsequence V ck+j(X), which we further assume that it converges to V ce (X), for every such X, and we will show that V ce (X) = 1 2 , for every X. To be absolutely clear we assume for the time being that there is a sequence of values s1, s2, s3, . . . , such that for every X, the sequence V csi(X) converges to V ce (X) and we show that under these conditions V ce (X) = 1 2 .\nConsider all possible cycles X = Z1 ← Z2 ← . . . ← Z2n = X (even) and X = Z1 ← Z2 ← . . . ← Z2n+1 = X (odd) and assume that amongst them we have a cycle such that there exists a sequence of values r1, r2, . . . such that for each Zi, Zi+1 is the node in Att(Zi) with maximum value and 0 < V ck+r1+r2+...+rm(Zi) < 1, for every m ≥ 0. Then V c e (Zi) = 1 2 , for all Zi.\nProof. Since the Gabbay-Rodrigues Iteration Schema uses continuous functions, if the schema holds for the elements of the sequence V ck+j(X), for every X ∈ S, it also holds for the limit V ce (X).\nWe get the following systems of equations\n1. For the cycle X = Z1 ← Z2 ← . . .← Z2n = X: V ce (X) = (1−V ce (X)) ·min { 1 2 , 1− V c e (Y ) } +V ce (X) ·max { 1 2 , 1− V c e (Y ) } ,\nwhere Y is the node in Att(X) with maximum value. We have two cases to consider.\n• V ce (Y ) ≥ 12 , then we get that\nV ce (X) = 1− V ce (Y )\n1.5− V ce (Y )\n• V ce (Y ) ≤ 12 , the we get that\nV ce (X) = 1\n1 + 2 · V ce (Y )\nit is easy to see from the equations that if V ce (Y ) ≥ 12 , then V c e (X) ≤ 12 and if V ce (Y ) ≤ 12 , then V c e (X) ≥ 12 . Therefore, if we have the cycle X = Z1 ← Z2 ← . . . ← Z2n = X, then we get that 12 ≤ Z1 ≤ 1 2 , so all Zi = 1 2 .\n2. For the cycle X = Z1 ← Z2 ← . . .← Z2n+1 = X, we have that\n• either V ce (Y ) ≥ 12 . Let us write V c e (Y ) = 1 2 + (Y ), for some 0 ≤\n(Y ) < 12 . We then get that\nV ce (X) = 1− V ce (Y )\n1.5− V ce (Y )\n= 1− 12 − (Y )\n1.5− ( 12 + (Y ))\n= 1 2 − (Y ) 1− (Y )\nWrite V ce (X) = 1 2 − η, for some 0 < η < 1 2 .\n1 2 − η = 1 2 − (Y ) 1− (Y )\nη = 12 − 1 2− (Y ) 1− (Y )\n= (1 (Y ))−2( 12− (Y ))\n2(1− (Y )\n= 1− (Y )− 1 + 2 (Y )\n2(1− (Y ))\n= (Y )\n2(1− (Y ))\n• or V ce (Y ) ≤ 12 . Let us write V c e (Y ) = 1 2 − (Y ), for some 0 ≤ (Y ) <\n1 2 . We then get that\nV ce (X) = 1\n1 + 2( 12 − (Y )\n= 1\n1 + 1− 2 (Y )\n= 1\n2(1− (Y ))\n= 1\n2 + η\nη = 1 2(1− (Y )) − 1 2\n= 1− 1 + (Y ) 2(1− (Y ))\n= (Y )\n2(1− (Y ))\nWhere are we now? We saw that if we start from V ce (Y ) = 1 2 ± (Y ) and Y → X (Y attacks X as in a cycle), then V ce (X) = 12 ± η, where η is in the other direction and\nη = (Y )\n2(1− (Y )) .\nLet us now assume a cycle\nX = Z1 ← Z2 ← . . .← Zn = X\nAssume Z1 = 12 ± . What would the value of Zk be? We claim that\nZk = 1\n2 ± ηk\nwhere ηk =\n2(2k − (2k − 1) )\nThe proof is by induction. Let X = Zk, then Y = Zk+1, and then\nηk+1 = ηk\n2(1− ηk)\n=\n2(2k−(2k−1) )\n2(1− 2(2k−(2k−1) ) )\n=\n2(2k−(2k−1) ) 2 ( 2(2k−(2k−1) − ) 2(2k−(2k+1) ) )\n= 2 ( 2k+1 − 2k+1 + 2 − ) =\n2(2k+1 − (2k+1 − 1) )\nSo the recursion works. Now if we have a loop, we get\nZn = Z1\nSo ηn = η1 and thus\nη = η\n2(2k+1 − (2k+1 − 1) )\nIf we divide by η ( 6= 0), we get\n1 = 1\n2(2k+1 − (2k+1 − 1) )\nIt is easy to see that only = 12 solves the equation. This means that V ce (Zi) = 1 2 , for all Zi.\nRemark 2.4 Ordinarily we cannot guarantee that Zi+1 is the node in Att(Zi) with maximum value for all k′ > k, we need to find a subsequence. This is done as follows: we start with a node X and since there are a finite number of nodes attacking it (the network is finite), there exists a subsequence such that there is a single attacker whose V ck′ value is the maximum for all k\n′ in the subsequence. We can assume it is Z2. This Z2 is not unique, there may be other choices. Let Zα22 be one arbitrary such choice. Repeating this consideration now for Z α2 2 and for the subsequence thus obtained, we get a Zα33 and a further subsequence of the subsequence and so on. Eventually, we get a final subsequence (which depends on the choices of Zαii ) V c k+r1 ,V ck+r1+r2 , . . ., such that Z αi+1 i+1 is the node in Att(Zαii ) with maximum value and 0 < V c k+r1+r2+...+rm\n(Zαii+1) < 1, for each m.\nRemark 2.5 We use a similar argument to the one in Remark 2.4 to show that if a subsequence V ck+j(X) converges to V c e (X), then it can be further refined to a subsequence V csi such that V c si(Y ) converges for all Y . The reason is that the\nnumber of such Y is finite (since S is finite). We can then successively refine the sequence V ck+j(X) into subsequences for which V c k+j(Y ) also converges. Therefore, Theorem 2.6, can be used to show that the convergent sequence V ck+j converges to 12 . We can therefore further conclude that every convergent subsequence of Vk+m(X) converges to 12 . The next lemma shows that the sequence Vk+m(X) itself converges to 12 .\nLemma 2.1 Let α = α1, α2, α3, . . ., be an infinite sequence of values in [0, 1]. If every convergent subsequence of α converges to 12 , then limi→∞ αi = 1 2 . Proof. For every 0 < ε < 12 , [ 1 2 − ε, 1 2 + ε] only a finite number of αi’s are in [0, 12 − ε] ∪ [ 1 2 + ε, 1]. Otherwise, say [0, 1 2 − ε] has an infinite number of αi’s. Then since [0, 12 − ε] is a closed interval with an infinite number of values in it, there would exist an infinite convergent subsequence of α in it that does not converge to 12 .\nTherefore, we have shown that for every 0 < ε < 12 , ε small, there exists a number m such that for every n > m, ( 12 − αn) ∈ [ 1 2 − ε, 1 2 + ε], that is limi→∞ αi = 1 2 .\nTheorem 2.5 asserts what the limit values of the nodes whose values of the attackers are known at the stable iteration k. Theorem 2.7 asserts the same in terms of the limit values of the attackers.\nTheorem 2.7\n1. If maxY ∈Att(X){Ve(Y )} = 0, then Ve(X) = 1.\n2. If maxY ∈Att(X){Ve(Y )} = 1, then Ve(X) = 0.\nProof. Note that limj→∞{Vj+1(X)} = limj→∞{Vj(X)}.\n1. If maxY ∈Att(X){Ve(Y )} = 0, then we have that Ve(X) = (1− Ve(X)) ·min { 1\n2 , 1\n} + Ve(X) ·max { 1\n2 , 1 } Ve(X) = (1− Ve(X)) · 1\n2 + Ve(X)\n2 · Ve(X) = 1− Ve(X) + 2 · Ve(X) Ve(X) = 1\nSo if the equilibrium values of all attackers of X is 0, then the equilibrium value of X is 1.\n2. If maxY ∈Att(X){Ve(Y )} = 1, then we have that Ve(X) = (1− Ve(X)) ·min { 1\n2 , 0\n} + Ve(X) ·max { 1\n2 , 0 } Ve(X) = Ve(X) 2 Ve(X) = 0\nSo if the equilibrium value of any of the attackers of X is 1, then the equilibrium value of X is 0.\nTheorem 2.8 Let 〈S,R〉 be an argumentation network and T its GR system of equations. If the assignment V0 : S 7−→ U is legal then the sequence V0, V1, V2, . . . , where each Vi, i > 0, is generated by T , is stable at iteration 0. Proof. Suppose V0 is legal. Then if V0(X) = 0, then there exists Y ∈ Att(X) such that V0(Y ) = 1. Therefore V1(X) = min {1/2, 0} = 0. If V0(X) = 1, then for all Y ∈ Att(X), V0(Y ) = 0, and hence maxY ∈Att(X)V0(Y ) = 0. Therefore, V1(X) = max {1/2, 1} = 1.\nThe stability of the crisp values then follows from Theorem 2.2 and since 0 < V0(X) < 1, then by Theorem 2.1 (case 3), so does the stability of the remaining non-crisp values.\nProposition 2.4 Let 〈S,R〉 be an argumentation network; T its GR system of equations and Ve a function with the equilibrium values of the nodes in S calculated according to the Gabbay-Rodrigues Iteration Schema. Let λ be a legal labelling function.\nTake any X ∈ S. If λ and Ve agree on the values of all nodes in Att(X), then λ and Ve agree on the value of X. Proof. There are three cases to consider. Proofs of cases 1. and 2. are similar to the proofs of cases 1. and 2. of Theorem 2.5.\n1. maxY ∈Att(X){Ve(Y )} = 0, then for all Y ∈ Att(X), Ve(Y ) = 0. It follows that Ve(X) = ∑∞ k=1 1 2k + limj→∞ Vk(X)\n2j = 1 + 0 = 1. Since Ve and λ agree with each other on the values of all nodes in Att(X), we have that for all Y ∈ Att(X), λ(Y ) = out and since λ is legal, λ(X) = in, and hence λ and Ve agree with each other with respect to the value of X as well.\n2. maxY ∈Att(X){Ve(Y )} = 1, then there exists Y ∈ Att(X), such that Ve(Y ) = 1. It follows that Ve(X) = limj→∞ Ve(X) 2j = 0. Since Ve and λ agree with\neach other on the values of all nodes in Att(X), we have that λ(Y ) = in and since λ is legal, λ(X) = out. Hence λ and Ve agree with each other with respect to the value of X as well.\n3. maxY ∈Att(X){Ve(Y )} = 12 , then there exists Y ∈ Att(X), such that Ve(Y ) = 1 2 (and hence λ(Y ) = und) and for no Y ∈ Att(X), Ve(Y ) = 1 (and hence for no Y ∈ Att(X), λ(Y ) = in). It follows that\nVe(X) = 1− Ve(X) 2 + Ve(X)\n2 2 · Ve(X) =1\nVe(X) = 1\n2\nSince λ is legal, λ(X) = und, and hence λ and Ve agree with each other with respect to the value of X.\nAnd now to the main theorem of this section, which explains the equilibrium values of all nodes and shows their relationship to Caminada and Pigozzi’s downadmissible/up-complete constructions. A down-admissible labelling is obtained after a series of contraction operations as defined below.\nDefinition 2.7 ([7]) Let λ be a labelling of an argumentation network 〈S,R〉. A contraction sequence from λ is a sequence of labellings [λ1 = λ, . . . λk] such that\n1. For each i ∈ {1, . . . , k− 1}, λi+1 = λi−{(X, in), (X,out)}∪ {(X,und)}, where X is an argument that is illegally labelled in, or illegally labelled out in λj; and\n2. λk is a labelling without any arguments illegally labelled in or illegally labelled out.\nTheorem 6 of [7] shows us that if we successively contract an initial labelling λ, then at the end of the contraction sequence [λ1 = λ, λ2, . . . λk], λk corresponds to the down-admissible labelling of λ, which is the largest admissible labelling that is smaller or equal to λ.\nNot every admissible labelling corresponds to a complete extension. However, an admissible labelling can be turned into a labelling that corresponds to a complete extension by changing the labels of nodes that illegally labelled und, to in or out as appropriate. Each such operation is called an expansion, and an expansion sequence corresponds to a list of all such operations:\nDefinition 2.8 ([7]) Let λ be an admissible labelling of the argumentation network 〈S,R〉. An expansion sequence from λ is a sequence of labellings [λ1 = λ, . . . λk] such that\n1. For each i ∈ {1, . . . , k − 1},\nλi+1 =  λi − {(X,und)} ∪ {(X, in)}, if X is an argument that is illegally labelled und in λi and all its attackers are labelled out\nλi − {(X,und)} ∪ {(X,out)}, if X is an argument that is illegally labelled und in λi and it has an attacker labelled in\n2. λk is a labelling without any arguments illegally labelled und.\nCaminada and Pigozzi have shown us that if [λ1 = λ, . . . λk] is an expansion sequence,15 then λk is a complete labelling and it is the smallest such labelling containing λ. We now introduce a few concepts to help us in the proof of our main theorem.\nDefinition 2.9 Let 〈S,R〉 be an argumentation network; V be an assignment of values to the nodes in S; and λ a labelling of these nodes. We say that V and λ agree with each other with respect to the value of a node X if and only if the following conditions hold:\n15Note λ1 must be admissible.\n1. V (X) = 1 if and only if λ(X) = in\n2. V (X) = 0 if and only if λ(X) = out\n3. V (X) = 1/2 if and only if λ(X) = und\nWe say that V and λ agree with each other if they agree with the values of all nodes in S.\nDefinition 2.10 (Attack tree of a node) Let 〈S,R〉 be a network. The attack tree tree(X) of a node X ∈ S is the tree with root X and for every node N in Tree(X), the children of N are the nodes in Att(N).\nDefinition 2.11 (Path from a node) Let 〈S,R〉 be a network. Take X ∈ S. A path from X is a sequence of nodes X = Z0, Z1, Z2, . . . such that each Zi+1, i ≥ 0, is a child of Zi in the attack tree of X. The set of all paths from a node X is denoted Π(X). We allow for a single node to be a path.\nUsing paths, we can define a strongly connected component (SCC) to be a maximal subset C ⊆ S, such that for every X,Y ∈ C, there exists a path from X containing Y .\nNote that in a SCC C for every path π = Z0, Zi, . . . from every node Z0 ∈ C, there exists a smallest i(π) such that for some r(π), Zi(π) = Zi(π)+r(π). i(π) < |C|. i(π) is the index of the first node in the path π that is involved in a loop, or you can think of it as the minimum distance from the starting node of the path π to a looping node in the path. If i(π) = 0, then Z0 attacks itself. Let us call the loop head of the path π = Z0, Z1, . . ., the node Zi(π).\nDefinition 2.12 (Vmax-paths) Let Z be a node in a SCC C and let the sequence of values V0, V1, . . . be stable at iteration k. The set of Vmax-paths of Z is defined as Vmax-paths(Z) = {π = [Z = Z0, Z1, . . . ] ∈ Π(Z) | for each Zi, Vk+r(Zi+1) = maxZ′i+1{Vk+r(Z ′ i+1)} for an infinite number of r’s}.\nFor every Z ∈ C, the set of Vmax-paths from Z is non-empty (see Remark 2.4).\nDefinition 2.13 (Bar of a node) Let C be a SCC and take X ∈ C. The bar of X is the set\nbar(X) = {Z ∈ C | Z is the loop head of a path in Vmax-paths(X)}.\nDefinition 2.14 Let Γ(X) be the set of Vmax-paths of X and take U ⊆ C a set of points. The bar of X modified by U is defined as\nbar(X,U) = ⋃\nπ∈Γ(X)\n{ y y is the first node in π such that either y is\nthe loop head of π or y ∈ U\n}\nTheorem 2.9 Let 〈S,R〉 be an argumentation network; V0 be an initial assignment of values to the nodes in S; λ0 an initial labelling of these nodes; and V0 and λ0 faithful to each other according to Definition 2.3. Let λda be the labelling at the end of a contraction sequence from λ0 and λCP the labelling at the end of an expansion sequence after λda. Let k be the point at which the sequence V0, V1,. . . becomes stable and Ve(X) the equilibrium value of a node calculated through the Gabbay-Rodrigues Iteration Schema. Then λCP and Ve agree with each other according to Definition 2.9. Proof. The proof is done on induction on the depth of a node X. Suppose the depth of X is 0. There are three main cases to consider.\nCase 1: X is a source node. By definition, X has no attackers, and hence maxY ∈Att(X) V0(Y ) = maxY ∈Att(X) Vk(Y ) = 0 and then by Theorem 2.5, Ve(X) = 1.\nIf λ0(X) = in, then X is legally labelled in, X does not take part in the contraction or expansion sequences and therefore λCP (X) = in. If λ0(X) = out, then X is illegally labelled out, and therefore the label of X is changed to und in the contraction sequence and since it is illegally labelled und, then it is subsequently changed to in in the expansion sequence. If λ0(X) = und, then X cannot be contracted, and since it is illegally labelled und, its label must be changed to in during the expansion sequence. In all cases, λCP (X) = in, and hence λCP and Ve agree with each other with respect to the value of X.\nCase 2: X is part of a source SCC C and both V0 C and λ0 C are legal assignments within C. Let us partition C into two components: Cc containing all nodes with crisp values and Cu containing all nodes with undecided values.\nSince λ0 C is a legal assignment, and the nodes in Cc only have values in {in,out}, then no nodes in Cc are illegally labelled and hence their labels are unaffected by the contraction sequence. Likewise, since no node is labelled undecided in Cc, nothing can be subsequently expanded and λCP Cc = λ0 Cc. By construction, the values of all nodes in Cu are und, and hence these nodes are not affected by the contraction sequence. Furthermore, they are all legally labelled undecided and hence the values remain unchanged, and hence λCP C = λ0 C.\nSince V0 C is a legal assignment, then by Theorem 2.8, it is stable at iteration 0. As a result, for all nodes X ∈ Cc, V1(X) = V0(X). Hence by Theorem 2.2, Ve(X) = V0(X) for all nodes X ∈ Cc, and then since λ0 and V0 are faithful to each other (Definition 2.3), conditions 1. and 2. of Definition 2.9 are satisfied. We now show that condition 3. also follows. For all nodes X ∈ Cu, we have that 0 < V0(X) < 1. Since V0 C is a legal assignment, then for every X ∈ Cu, 0 < maxY ∈Att(X){V0(Y )} < 1.16\n16This effectively means that the only possible incoming attacks from Cc are from nodes labelled out. Otherwise, the attacked nodes in Cu should have been labelled out and hence would have been illegally labelled und.\nNotice that by construction Cu = C\\Cc. Stage two of case 3 below shows that for all nodes X ∈ Cu, Ve(X) = 1/2. Therefore, condition 3. of Definition 2.9 is also satisfied and as a result, λCP and Ve agree with each other with respect to all nodes in C.\ncase 3: X is part of a source SCC C and λ0 C and V0 C are not legal assignments. Stage one: We know that the sequence of assignments V0, V1,. . . , eventually becomes stable at some iteration k and by Theorem 2.4, in(Vk) ⊆ in(V0), out(Vk) ⊆ out(V0) and in(Vk) is the largest admissible subset of in(V0). By Theorem 6 of [7], in(λCP ) is the largest (and unique) admissible subset of in(λ0) and since λ0 and V0 are faithful to each other, we can conclude that in(Vk) = in(λda) and out(Vk) = out(λda). Note that since the sequence is stable at k, in(Vk) ⊆ in(Ve) and out(Vk) ⊆ out(Ve). Consider the sequence of expansion operations e1, e2, . . . , em and the sequence of labellings λ0 = λda, λ1, λ2,. . . ,λm = λCP , where for each i > 0, λi is obtained from λi−1 via the expansion ei. We show by induction on m that in(λCP ) ⊆ in(Ve) and out(λCP ) ⊆ out(Ve). In a second step, we show that if λCP (X) = und, then Ve(X) = 1/2. Suppose that e1 turns the node X illegally labelled und by λda into in. Then out(λ1) = out(λda) and in(λ1) = in(λda) ∪ {X}. Then for all Y ∈ Att(X), λda(X) = out. Therefore, Vk(Y ) = 0 for all Y ∈ Att(X), and hence maxY ∈Att(X){Vk(Y )} = 0. By Theorem 2.5, Ve(X) = 1 and therefore X ∈ in(Ve). We set V 1,outk = out(Vk) and V 1,in k = in(Vk)∪{X}.\nSuppose that e1 turns the node X illegally labelled und by λda into out. Then in(λ1) = in(λda) and out(λ1) = out(λda) ∪ {X}. Then there exists Y ∈ Att(X) such that λda(X) = in. Therefore, Vk(Y ) = 1 for some Y ∈ Att(X), and hence maxY ∈Att(X){Vk(Y )} = 1. By Theorem 2.5, Ve(X) = 0 and therefore X ∈ out(Ve(X)). We set V 1,outk = out(Vk)∪{X} and V 1,ink = in(Vk). Assume that for some i, in(λi) = V i,in k and out(λi) = V i,out k . Now consider the i+ 1-th expansion operation ei+1. Suppose that e1+1 turns the node X illegally labelled und in λi into in. Then for all Y ∈ Att(X), λi(X) = out. Therefore, Ve(Y ) = 0 for all Y ∈ Att(X), and hence maxY ∈Att(X){Ve(Y )} = 0. By Theorem 2.7, Ve(X) = 1 and therefore X ∈ in(Ve). As before, we set V i+1,outk = V i,out k and V i+1,ink = in(Vk) ∪ {X}. Suppose that ei+1 turns the node X illegally labelled und by λi into out. Then there exists Y ∈ Att(X) such that λi(X) = in. Therefore, Ve(Y ) = 1 for some Y ∈ Att(X), and hence maxY ∈Att(X){Ve(Y )} = 1. By Theorem 2.7, Ve(X) = 0 and therefore X ∈ out(Ve(X)). Again, we set V i+1,outk = V i k ∪ {X} and V i+1,in k = V i,in k .\nBy now we know that if X ∈ V m,ink , then Ve(X) = 1 and λCP (X) = in and that X ∈ V m,outk , then Ve(X) = 0 and λCP (X) = out. We ask if there is some Z 6∈ V m,ink such that Ve(Z) = 1 or Z 6∈ V m,out k such that Ve(Z) = 0. The answer is no as it is explained in stage two below.\nStage two:\nLet us use Cc to denote (V m,ink ∪V m,out k ) and C u to denote C\\Cc. Suppose X ∈ Cu. We know that V m,ink = in(λCP ) is a complete extension and that no further expansion operation is possible from λCP , therefore if X 6∈ in(λCP ), then either λCP (X) = out and hence X ∈ V m,outk , which is not possible, or λCP (X) = und and legally so. Therefore there exists Y ∈ Att(X), such that λCP (Y ) = und and hence 0 < maxY ∈Att(X){Ve(Y )} < 1. Similarly, if X 6∈ out(λCP ), then either λCP (X) = in and hence X ∈ V m,ink , which is not possible, or λCP (X) = und and legally so. Therefore there exists Y ∈ Att(X), such that λCP (Y ) = und and hence 0 < maxY ∈Att(X){Ve(Y )} < 1 and therefore 0 < Ve(X) < 1. So we know that for all X ∈ Cu, λCP (X) = und and 0 < Ve(X) < 1. In what follows, we will show that indeed for all nodes in C − Cc, Ve(X) = 1/2. Note that since we are in a SCC C, for all X ∈ Cu, there is an infinite attack tree with root X, in which every branch is of the form X = Z0, Z1, Z2, . . . , Zk = X, where for every i > 0, (Zi+1, Zi) ∈ R. Some of the Zi are in V m,out k , but none can be in V m,in k , for that would make Zi−1 out.\nThe proof is done by induction on the maximum distance from a node X in Cu to a loop Z1, Z2, . . . , Zk = Z1, where every Zi ∈ C\\V mk . There are infinitely many paths from X in the attack tree of X, but we only need to consider the set Γ(X) with all Vmax-paths of X. Each such path is of the form π(X) = (Z0 = X), Z1, . . .. Now define the distance of X, dimX, as the maximum index i such that for each path π(X), Zi ∈ bar(Z, V m,outk ). This means that Zi is the first point in the path π(X) which is either a repetition of a previous point or a point in V m,outk .\nIf dimX = 0, then X must be attacked by a cycle involving only X (otherwise X ∈ V m,outk , and then Ve(X) = 0, a contradiction). Therefore, we have a cycle that attacks X and which involves X alone. All attackers in this cycle (i.e., X) have maximum value and 0 < Vk+r(X) < 1 for every r ≥ 0. By Theorem 2.6, the value of every node in the cycle is Ve(X) = 1/2. Now the equilibrium value of the node X attacked by the\ncycle is calculated by Ve(X) = (1− Ve(X)) ·min { 1\n2 ,\n1\n2\n} + Ve(X) ·max { 1\n2 ,\n1\n2 } =\n1− Ve(X) 2 + Ve(X) 2\n= 1− Ve(X) + Ve(X)\n2\n= 1\n2\nNow assume that the equilibrium value of all nodes with distance up to k is 1/2 and consider the node X with distance k + 1. For all Y ∈ Att(X), we have that dimY ≤ k. Therefore, either Y ∈ V m,outk in which case Ve(Y ) = 0, or by the inductive hypothesis Ve(Y ) = 1/2.17 Therefore we have that maxY ∈ Att(X){Ve(Y )} = 1/2 and as before\nVe(X) = (1− Ve(X)) ·min { 1\n2 ,\n1\n2\n} + Ve(X) ·max { 1\n2 ,\n1\n2 } = 1\n2\nTo conclude, for all X ∈ V m,ink , Ve(X) = 0; for all X ∈ V m,out k , Ve(X) = 0; and for all X ∈ Cu, Ve(X) = 1/2. in(Ve C) (resp., in(λCP C)) in this case is the minimal complete extension containing in(Vk C) (resp., in(λda C)).\nAssume the theorem holds for all nodes of depth up to k. We now show that it holds for nodes of depth k + 1.\nDefine Known0k+1 = {X ∈ S | depth(X) ≤ k} and Known m+1 k+1 = {X ∈ S | depth(X) = k + 1 and for all Y ∈ Att(X), Y ∈ Knownmk+1}. We show that for all i ≥ 0, we have that λCP (X) = Ve(X), for all X ∈ Knownik+1. First notice that by induction hypothesis, λCP (X) = Ve(X) for all X ∈ Known0k+1. Now suppose that λCP (X) = Ve(X) for all X ∈ Knownik+1, then by Proposition 2.4, λCP (X) = Ve(X) for all X ∈ Knowni+1k+1. Since the network is finite, Knownek+1 = Known e+1 k+1, for some e ≥ 0. Define Cuk+1 = {X ∈ S | depth(X) = k + 1} \\ Knownek+1. By definition, if there exists X ∈ Cuk+1 and Y ∈ Att(X) such that Y ∈ Knownek+1, then λCP (Y ) = out and Ve(Y ) = 0 (otherwise the value of X would be known). Therefore, we can exclude the nodes in Knownek+1 and consider Cuk+1 in isolation. C u k+1 can therefore be treated as a network of depth 0, and the proof will follow exactly from Cases 2 and 3 of the base of the main induction, and hence for all X ∈ Cuk+1, Ve(X) = λCP (X).\nCorollary 2.5 Let 〈S,R〉 be an argumentation network and V0 be an initial assignment of values to the nodes in S. Let Ve(X) be the equilibrium value of\n17Note that Att(X) 6⊆ Vm,outk , otherwise X would be illegally labelled und.\na node X calculated through the Gabbay-Rodrigues Iteration Schema. For all nodes X ∈ S, Ve(X) ∈ {0, 1/2, 1}. Proof. Follows from the possible equilibrium values of all nodes in Theorem 2.9."
    }, {
      "heading" : "3 Discussion and Worked Examples",
      "text" : "Suppose we are given a network such as the one in Figure 5 with some initial values to its nodes. The values may or may not correspond to a complete extension. We can write equations for the network, apply the Gabbay-Rodrigues Iteration Schema and obtain extensions for the network.\nFor the sake of illustration, we consider three sets of representative initial values 1., 2. and 3.. The table in Figure 5 shows what happens when these values are applied to the equations, giving both the values at the stable point (Vk) and at the limit (Ve). The corresponding down-admissible labellings and their resulting up-completion according to Caminada-Pigozzi’s procedure can be obtained simply by replacing 0 with out, 1 with in and values in (0, 1) with und.\nCase 1. represents the situation in which the initial values in the cycleW ↔ Z are compatible with an extension and hence the crisp values are preserved by the calculations. We end up with the complete extension E1 = {X,Z}. Contrast this with case 2., in which the initial values of W and Z are 1 and 0, resp. The extension E = {X,W} is also complete but is obtained neither by our procedure nor by Caminada-Pigozzi’s down-admissible/up-complete construction. This can be explained as follows. The initial illegal value of Y invalidates the initial acceptance of W , turning it into undecided in the calculation of the downadmissible subset. From that point on, the original legal assignments for W and Z can no longer be restored and they both end up as undecided. As a result, we obtain the complete (but not preferred) extension E2 = {X}. This interference does not happen in case 1., because there the interference of the undecided value of Y over W is dominated by Z’s 1 value that keeps W ’s 0 value in check (because of the behaviour of max). As a result, both W ’s and\nZ’s initial values are retained. If however we start with a preferred extension, which is also complete by definition, we get as a result unchanged initial values (cf. Theorem 2.9). CaminadaPigozzi also give the same result because the down-admissible labelling of a labelling yielding a preferred extension is the labelling itself and since that labelling is also complete, then the up-completion does not change anything (case 3. in the table of Figure 5.\nWe can suggest an enhanced procedure to improve on the results obtained in case 2., which is outlined below. The procedure starts with an empty set of crisp values (Crisp) and a set of initial values to the nodes.\n1. Calculate the equilibrium values for all nodes using the iteration schema.\n2. If {X ∈ S | Ve(X) ∈ {0, 1}} ⊆ Crisp, stop. The extension is defined in the set {X | Ve(X) = 1}. Otherwise, set Crisp = Crisp ∪ {X ∈ S | Ve(X) ∈ {0, 1}} and proceed to step 3.\n3. For every X ∈ {X | Ve(X) ∈ {0, 1}}, set V0 = Ve(X) and leave V0(X) as before for the remaining nodes.\n4. Repeat from 1.\nThe above procedure is sound, since at each run the equilibrium values computed yield a complete extension. Note that re-using some of the original values does not affect soundness. If they cannot be used to generate a larger extension, they will just converge to 1/2. The procedure also terminates as long as the original network S is finite, since a new iteration is invoked only when new crisp values are generated and this is bound by |S|.\nIf we apply the procedure to Case 2. above, in the first run we will get Ve(X) = 1, Ve(Y ) = 0, Ve(W ) = Ve(Z) = 1/2. Hence, Crisp = {X,Y }. We then run it once more, this time with initial values V0(X) = 1, V0(Y ) = 0, V0(W ) = 1 and V0(Z) = 0. This will stabilise immediately at these values and then Crisp = {X,Y,W,Z}. In the third run, no new crisp values are generated, so we stop with extension {X,W}, which is a preferred extension (see case 3. above). This is closer to the original values, because the preference of W over Z is preserved.\nObviously, the procedure can also be applied using Caminada-Pigozzi’s construction instead of the Gabbay-Rodrigues Iteration Schema of step 1. above."
    }, {
      "heading" : "3.1 Worked Examples with Cycles",
      "text" : "The table in Figure 6 displays initial, stable and equilibrium values (V0, Vk, Ve) for all nodes in the networks (L) and (R). The last row of the table indicates the iteration in which the stable values were reached and the equilibrium values approximated (S,E). Obviously the equilibrium values are an approximation. We set our tolerance as 10−19, the upper bound of the relative error due to rounding in the calculations in our 64-bit machine.18 Independent nodes, such\n18Effectively this means that if the maximum variation in node values between two successive iterations is smaller than 10−19, we cannot be sure it is not simply the result of a rounding\n(L) (R)\nas Z in the networks above always converge to 1 independently of their initial values. This also happens to all nodes whose values of the attackers all converge to 0. Cases (L) and (R) explore different scenarios involving cycles. The odd cycle in (L) attacks the even cycle X ↔ Y and the even cycle in (R) attacks the odd cycle A → B → C → A. We start with (L), which contains an odd cycle attacking an even cycle. The values in the odd cycle in this case will converge to 1/2 independently of their initial values. This may or may not have an effect on nodes that are attacked by any of the nodes in the cycle. We start with an initial valid configuration for X and Y in both (L1) and (L2). The end results will differ though as explained next. If X starts with 0 and Y with 1 (L1), then the interference of the undecidedness of B over X is dominated by the Y ’s value of 1 and the initial values of both X and Y persist. However, if X starts with 1 and Y with 0, the undecidedness of B will then “contaminate” the X–Y loop. It will force X to become undecided, which in turn makes Y also become undecided. As a result, all of the values will converge to 1/2 apart from Z’s, which as we said is independent and will converge to 1 (L2).\nNow let us look at (R) in which the even cycle attacks the odd one. (R1) and (R2) contain different initial valid configurations for the even cycle. This time the nodes in the even cycle are independent of external values and their original values remain. If X starts with 1, it remains with 1 and this in turn breaks the odd cycle. The attacked node B is forced to converge to 0, forcing C to converge to 1 and A to converge to 0 (independently of their initial values). An\nerror due to the precision of the computer. At that point we assume we have reached the limit of what can be accurately calculated.\ninitial value of 0 for X cannot break the odd cycle and its values will converge to 1/2 independently of their initial values (R2)."
    }, {
      "heading" : "4 Comparisons with other work",
      "text" : "This section compares our framework with other techniques that deal with initial values. Our discussions so far and the use of the Gabbay-Rodrigues Iteration Schema were in the context of the equational approach to an argumentation network when we are given some initial values. Our problem was to find a solution to the system of equations that was “close” to these initial values.\nTwo important concepts which are directly related to the work presented in this paper were proposed in [7], which addressed the problem of finding an extension of an argumentation network given an initial labelling of its arguments. Their procedure works in two steps. Firstly, they calculate the downwardadmissible labelling of the original labelling, which essentially consists of an admissible labelling whose crisp part is maximally included in the original labelling. This is done by a procedure which at each step, turns an illegally labelled argument from in or out into und until no illegal crisp values remain. They called this step a contraction sequence and it is similar to what our schema does to the sequence of value assignments until it becomes stable, except that at each iteration our schema may contract more than one node simultaneously, whereas theirs contracts only one node per iteration. More importantly, their procedure is non-deterministic: it selects an illegally labelled node for contraction, but this requires searching for such nodes. Hence there is an implicit cost involved in it. Even though the search can be optimised, it renders the overall cost of the procedure in terms of steps higher than ours, which is truly bounded by |S|. Now, given an admissible labelling, a complete extension is constructed by turning nodes that are illegally labelled und into in or out as appropriate. They call this step an expansion and its counterpart in our procedure is the calculation of the limit values of the sequence. Obviously, in a computer program, we can only approximate these limit values. In our implementation, we stop the iterations when we can no longer guarantee the accuracy of the calculations without introducing rounding errors due to the limitations of the processor. This happens in linear time too (see Figure 6). In practice, the limit values can be guessed much earlier as the iteration values can be seen to be converging towards one of the three values 0, 1/2 and 1.\nWe stress that neither are we limited to the discreet values out, in and und, nor to the Eqmax equation used in the iteration schema and this allows the application of the schema in the calculation of extensions given different semantics (see Section 5).\nOne can take a different approach to the one above, especially if one is not using any equations. One can take the view that given a network with initial values, we should give an iteration formula that will stabilise on some limit final values. This approach is a bit risky. One needs to explain where the initial values come from and what is the meaning of the iteration formula. One also needs\nto check whether or not the iteration formula is sound relative to the network’s extensions in Dung’s sense. In other words, if the initial values correspond to an acceptable Dung extension, does the iteration formula yield a result which does not correspond to a Dung extension? We begin with the work of Pereira et al. [9], which does not take any equational approach but simply iterates on the values of the nodes. We examine in detail what they do.\nIn what follows, 〈S,R〉 is an acyclic argumentation network and f : S 7−→ U is a function assigning initial values to the nodes in S.\nDefinition 4.1 Consider the sequence α0(X), α1(X), . . . , αi(X), . . ., where\nα0(X) = f(X)\nαi(X) = αi−1(X) + min\n{ f(X), 1− max\nY ∈Att(X) αi−1(Y )\n}\nand let α(X) = lim\ni→∞\n1 2 αi + 1 2 min\n( f(X), 1− max\nY ∈Att(X) αi(Y ) ) Definition 4.2 The attack depth of a node X of an acyclic argumentation network, in symbols a-depth(X), is defined recursively as\na-depth(X) =\n{ 0, if Att(X) = ∅(\nmax Y ∈Att(X)\na-depth(Y ) ) + 1, otherwise\nThe function a-depth is well-defined, because there are no cycles in 〈S,R〉.\nDefinition 4.3 Given initial values for the nodes of an acyclic network, the function β : S 7−→ U provides a means of calculating fixed-point values for all nodes as follows.\nβ(X) =  f(X), if a-depth(X) = 0 min { f(X), 1− max\nY ∈Att(X) β(Y )\n} , otherwise\nTheorem 4.1 α(X) = β(X) for all X ∈ S. Proof. The proof is done by induction on the depth of a node. Base cases: (Depth 0) Let X be an argument node of depth 0. By definition, X\nhas no attacks. It follows that\nα0(X) = f(X)\nα1(X) = 1\n2 α0(X) +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) α0(Y ) } = 1\n2 f(X) +\n1 2 f(X)\n= f(X)\nα2(X) = 1\n2 α1(X) +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) α1(Y ) } = 1\n2 f(X) +\n1 2 f(X) = f(X)\nα(X) = lim i→∞\n{ 1\n2 αi +\n1 2 f(X) } α(X) = f(X) = β(X)\n(Depth 1) Let X be an argument node of depth 1. By definition, all nodes Y attacking X have depth 0. For all such nodes f(Y ) = α0(Y ) = α1(Y ) = αi(Y ) = . . . = α(Y ) = β(Y ).\nα0(X) = f(X)\nα1(X) = 1\n2 α0(X) +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) α0(Y ) } = 1\n2 f(X) +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) β(Y ) } α2(X) = 1\n2\n( 1\n2 f(X) +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) β(Y )\n}) +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) β(Y ) } = 1\n22 f(X) +\n1\n22 min\n{ f(X), 1− max\nY ∈Att(X) β(Y )\n} +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) β(Y ) } αi(X) = 1\n2i f(X) + t∑ i=1 1 2i ·min { f(X), 1− max Y ∈Att(X) β(Y ) } = 1\n2i f(X) +\n( 1− 1\n2i\n) ·min { f(X), 1− max\nY ∈Att(X) β(Y ) } α(X) = lim\ni→∞ αi(X)\n= lim i→∞\n1 2i f(X) +\n( 1− 1\n2i\n) ·min { f(X), 1− max\nY ∈Att(X) β(Y )\n}\n= min { f(X), 1− max\nY ∈Att(X) β(Y ) } = β(X)\nAssume that the theorem holds for nodes with attack depth up to k and let X be an argument node whose attack depth is k + 1. We have that\nα0(X) = f(X)\nα1(X) = 1\n2 α0(X) +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) α0(Y ) } = 1\n2 f(X) +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) α0(Y ) } α2(X) = 1\n2\n( 1\n2 f(X) +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) α0(Y )\n}) +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) α1(Y ) } = 1\n22 f(X) +\n1\n22 min\n{ f(X), 1− max\nY ∈Att(X) α0(Y )\n} +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) α1(Y ) } α3(X) = 1\n2\n( 1\n22 f(X) +\n1\n22 min\n{ f(X), 1− max\nY ∈Att(X) α0(Y )\n} +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) α1(Y )\n}) +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) α2(Y ) } = 1\n23 f(X) +\n1\n23 min\n{ f(X), 1− max\nY ∈Att(X) α0(Y )\n} +\n1\n22 min\n{ f(X), 1− max\nY ∈Att(X) α1(Y )\n} +\n1 2 min\n{ f(X), 1− max\nY ∈Att(X) α2(Y ) } αi(X) = 1\n2i f(X) +\n1\n2i−0 min\n{ f(X), 1− max\nY ∈Att(X) α0(Y )\n} +\n1\n2i−1 min\n{ f(X), 1− max\nY ∈Att(X) α1(Y )\n} + . . .+\n1\n21 min\n{ f(X), 1− max\nY ∈Att(X) αi−1(Y )\n}\nαi+1(X) = 1\n2i f(X) + i∑ i=1 1 2i ·min { f(X), 1− max Y ∈Att(X) αi(Y ) } = 1\n2i f(X) +\n( 1− 1\n2i\n) ·min { f(X), 1− max\nY ∈Att(X) αi(Y ) } α(X) = lim\ni→∞\n1 2i f(X) +\n( 1− 1\n2i\n) ·min { f(X), 1− max\nY ∈Att(X) αi(Y ) } = lim\ni→∞\n( 1− 1\n2i\n) min { f(X), 1− max\nY ∈Att(X) αi(Y ) } = lim\ni→∞ min\n{ f(X), 1− max\nY ∈Att(X) αi(Y ) } = min { f(X), 1− max\nY ∈Att(X) lim i→∞ αi(Y ) } α(X) = min { f(X), 1− max\nY ∈Att(X) α(Y )\n}\nBut the attack depth of the nodes Y ∈ Att(X) is no higher than k. By the induction hypothesis we have that α(Y ) = β(Y ) for all Y ∈ Att(X) and hence\nα(X) = min { f(X), 1− max\nY ∈Att(X) β(Y )\n} = β(X)\nThe theorem above shows that when there are no cycles, for any node X, the sequence αi(X) converges to the value β(X), which can be calculated by considering the tree with root X and propagating values from the leaves to the root according to Definition 4.3.\nOne can argue that the procedure is not sound with respect to admissibility. In particular, the algorithm does not turn arbitrary initial values into admissible ones. If we give initial value 0 to a node which should not be labelled out, the algorithm does not correct the node’s value and it remains illegally out. Likewise, if we start with a two-node cycle A↔ B and provide initial values to A and B that correspond to a complete extension, say A = 1, B = 0, in the limit we get values A = 12 and B = 0. Ideally, the initial values should remain the same as in the Gabbay-Rodrigues Iteration Schema (and indeed Caminada and Pigozzi’s down-admissible/up-complete construction)."
    }, {
      "heading" : "5 Conclusions and Future Research",
      "text" : "This paper investigated aspects concerned with argumentation networks where the arguments are provided with initial values. We are aware that assigning values to nodes and propagating values through the network has been independently investigated before as in, e.g., [8, 2]. However, our approach is different because we see a network as a generator for equations whose solutions generalise the concept of extensions of the network.\nThere are advantages to using equations to calculate extensions in this way as numerical values arise naturally in many applications where argumentation systems are used and the behaviour of the node interactions can be described naturally using equations. In addition, there are many mathematical tools to help find solutions to the equations.\nThe equational approach is general enough to be adapted to particular applications. For instance, the arguments themselves may be expressed as some proof in a fuzzy logic and then the initial values can represent the values of the conclusions of the proofs, in the spirit of Prakken’s work [20]; or they can be obtained as the result of the merging of several networks, as proposed in [17, 16].\nIn this paper, we showed that the equations can be solved through an iterative process, as in Newton’s method and as such one can regard initial values as initial guesses or a desired configuration of the extension. The GabbayRodrigues Iteration Schema takes the following generalised form:\nVi+1(X) = (1− Vi(X)) ·min {1/2, g(N (X))}+ Vi(X) ·max {1/2, g(N (X))}\nIn this paper, we considered the special case where g is min and N (X) is the set of complemented values of the nodes in the “neighbourhood” of X (i.e., the attackers of X).19 Other operations can be used for argumentation systems, whose relationship with the schema is being further investigated. One such operation is product, which unlike min combines the strength of the attacks on a node. Another interesting possibility is to use the schema for abstract dialectical frameworks (ADFs) [3]. ADFs require the specification of a possibly unique type of equation for each node. Consider the ADF with nodes a, b, c and d with R = {(a, b), (b, c), (c, c)}. The ADF equations are: Ca = >, Cb = a, Cc = c∧b and Cd = ¬d. The complete models for this ADF are m1 = (t, t, u, u), m2 = (t, t, t, u) and m3 = (t, t, f, u). The Gabbay-Rodrigues schema converges to m1 given initial values (1, 1, 1/2, 1/2); to m2 given initial values (1, 1, 1, 1); and to m3 given initial values (0, 0, 0, 0).\nFor the case of min, we showed that the values generated at each iteration in the schema eventually “stabilise” by changing illegal crisp values into undecided. This process will calculate the down-admissible labelling of the initial values, as in [7], in time t linear to the set of arguments (t ≤ |S|). If we carry on the calculation, the values of the sequence in the limit will correspond to a complete extension of the original network. Obviously, the values corresponding to a legitimate extension are all legal. If they are given as input, the sequence will immediately stabilise. In practice, a few iterations are sufficient to indicate what the values will converge to in the limit. We have also outlined a procedure which can improve on the calculation above by propagating crisp values and replacing the remaining undecided values with their initial counterparts after each run of the iterations. This procedure terminates when no new crisp values are generated. Original crisp values which are compatible with a calculated extension can thus be preserved and hence we can end up with a larger complete\n19Note that 1−maxY ∈Att(X){V (Y )} = minY ∈Att(X){1− V (Y )}.\nextension than the one obtained through a single run. This extension is as compatible as possible with the initial values."
    }, {
      "heading" : "Acknowledgements",
      "text" : "The authors would like to thank Massimiliano Giacomin, Gabriella Pigozzi, Martin Caminada and Sanjay Modgil for comments and discussions on the topic of this paper."
    }, {
      "heading" : "A Predator-Prey and Argumentation Motivating Case Studies",
      "text" : "Let us motivate our ideas through two main examples. Our purpose is to make some conceptual distinction about iteration processes.\nExample A.1 Let us look at an example from biology. This is a model by M. P. Hassell [18] of the dynamics of a system with two parasitoids (P and Q) and one host (N). The interactions in the ecology are depicted in Figure 7. The equations modelling the dynamics are the following (see [1, p. 295]).\nN t+1 = λN tf1(P t)f2(Qt) P t+1 = N t[1− f1(P t)] Qt+1 = N tf1(P t)[1− f2(Qt)]\nIn the above equations the subscripts t and t+ 1 indicate two successive generations of P , Q and N ; λ is the finite host rate of increase; and the functions f1 and f2 are the probabilities of a host not being found by P t or Qt parasitoids, respectively. This model applies to two quite distinct types of interaction that are frequently found in real systems. It applies to cases where P acts first, to be followed by Q acting only on the survivors. Such is the case where a host population with discrete generations is parasitized at different developmental stages. In addition, it applies to cases where both P and Q act together on the same host stage, but the larvae of P always out-compete those of Q, should multiparasitism occur.\nThe functions f1 and f2 are:\nf1(P t) =\n[ 1 +\na1P t k1 ]−k1 f2(Qt) = [ 1 +\na2Qt k2 ]−k2 where a1, a2, k1 and k2 are constants.\nTo simplify and later compare the biological model with the argumentation model, we put k1 = k2 = −1.\nThis gives\nf1(P t) = 1− a1P t f2(Qt) = 1− a2Qt\nand therefore, the equations are\n(1, t): N t+1 = λNt(1− a1P t)(1− a2Qt) (2, t): P t+1 = a1NtP t (3, t): Qt+1 = a2QtN t(1− a1P t) At a state of equilibrium, we get the following fixpoint equations:\nN = λN(1− a1P )(1− a2Q) (16) P = a1NP (17) Q = a2QN(1− a1P ) (18)\nIt can be easily seen from the above equations that one of the solutions is P = Q = N = 0 (the “all zero” solution). If we ignore it, we get from (17) that\nN = 1\na1 (19)\nand from (18) we get\n1 = a2 · 1\na1 (1− a1P ) (20)\nand hence\na1 = a2 − a2a1P P = a2 − a1 a1a2\nFrom (16), we get\n1 = λ ( 1− a1(a2 − a1)\na1a2\n) (1− a2Q)\n1 = λa1 a2 (1− a2Q)\nso a2 λa1 = 1− a2Q\na2Q = λa1 − a2 λa1\nQ = λa1 − a2 λa1a2\nTo have a specific example for discussion let a1 = 2, a2 = 3, λ = 2. We get N = 0.5, P = 16 and Q = 1 12 . Indeed, substituting these values in the equations we have (1) 1 = 2 ( 1− 2 · 16 ) ( 1− 312\n) = 2 · 23 · 9 12 = 2 · 1836 = 1\n(2) 1 = 2 · 12 = 1\n(3) 1 = 3 · 12 ( 1− 26 ) = 32 · 4 6\n= 1 Let us substitute a1, a2 and λ in the equations and pretend we do not know\nthe solution. We get the equations:\n(1*) N = 2N(1− 2P )(1− 3Q) (2*) P = 2PN (3*) Q = 32Q(1− 2P )\nSo we have a system of equations modelling a certain ecology. The equations above give rise to the iteration equations\n(1∗, i): N i+1 = 2N i(1− 2P i)(1− 3Qi) (2∗, i): P i+1 = 2N iP i (3∗, i): Qi+1 = 32Qi(1− 2P i)\nLet us discuss our options. We have a system of equations involving N , P and Q and we want to solve it. We do not know whether there are solutions.\nOption 1 – a mathematical view. Let us just find a solution. We can guess a candidate solution, use Newton’s method and iterate. Let us do this with the guess N0 = P 0 = Q0 = 1 2 and iterate. These are equations (1∗, i), (2∗, i) and (3∗, i) for i = 1. Because the equations come from ecological considerations, the iterations are not just a numerical device but also have an evolutionary meaning. However, our view is purely mathematical. The corresponding to the meaning is accidental.\nWe get N1 = 2 · 12 ·Ni(1− 1) ( 1− 32 ) = 0 P 1 = 2 · 12 · 1 2 = 0 Q1 = 3 2 ·Qi(1− 2P i) = 0\nN2 = 0 P 2 = 0 Q2 = 0\nWe converge to the “all zero” solution.\nOption 2 – a semantical view. We seek a solution motivated not by mathematics but by the meaning of the equations: by ecological considerations. So let us adopt\nthe friends of parasites view and say that we are equal and we all have a right to live and so let us seek a steady state of compromise and living together in tolerance and understanding, namely N0 = P 0 = Q0 = 1 2 .\nUnfortunately using Newton’s method leads us, as shown above, to the solution P = Q = N = 0. In biological terms this is not good, it means everything is dead. So we may need a better iteration schema, a schema suitable for the biological interpretation.\nWe can choose to be selfish and cruel and start with N0 = 1 and P 0 = Q0 = 0. This means we aim at full population and no parasites. Iterating the equations will give us\nN1 = 2 P 1 = 0 Q1 = 0\nNk = 2 k P k = 0 Qk = 0\nThis does not lead to a solution. It diverges! The reader can check that even if the initial values are very close to a solu-\ntion, the method in general will not converge to the solution.\nRemark A.1 The conclusion we draw from Example A.1 is that we must be aware that some iteration processes can be mathematical only, just possibly leading to a mathematical solution but otherwise semantically meaningless, and some may be semantically meaningful and useful in the context of the application area from which the equations arise.\nThis observation shall become sharper and clearer in the case of our next example from abstract argumentation.\nExample A.2 Consider Figure 7 again but this time as an argumentation network where N , P , Q are arguments. This network has three extensions E1, E2 and E3, namely\nE1 = P is in = N and Q are out\nE2 = N is in = P and Q are out\nE3 = P , N and Q are all und In [13, 14, 15], we showed how to provide semantics for abstract argumentation in terms of equations. These equations are generated according to equation schema, of which two of the most significant ones are Eqmax and Eqinv, described next.\nLet Att(X) = {Y1, . . . , Yk} be all the attackers of X. Consider X, Y1,. . . ,Yk as variables ranging over [0, 1]. Define\nGmax(Att(X)) = 1−max{Y1, . . . , Yk} Ginv(Att(X)) = Π k i=1(1− Yi)\nThe equation we write for a node X is\nX = G(Att(X)) (*)\nwhere G can be Gmax or Ginv or some other function. We consider X = 1 to mean X is in; X = 0 to mean X is out; and 0 < X < 1 to mean that X is und. The background material on the equational approach is given in the next section. It is sufficient to say here that Gmax follows more closely the traditional semantics of argumentation networks being only concerned about the highest strength of attack to a node. The solutions to the equations using Gmax correspond to the traditional concept of extensions (in Dung’s sense) taking the nodes with value 1 in a solution to be the nodes in the extension.\nGinv on the other hand is also sensitive to the number of attackers to a node. For example, assume there are 10 undecided attackers Yi of X each having value 1 2 (und), then the value of X becomes 1 210 under Ginv, while under Gmax, the value of X is simply 12 . Note that X is nearer to 0 (i.e., out) in the Ginv case! The Gmax equations for the network in Figure 7 are:\nN = 1−max{P ,Q} (21) P = 1−N (22) Q = 1−max{P ,N} (23)\nand its Ginv equations are:\nN = (1− P )(1−Q) (24) P = (1−N) (25) Q = (1− P )(1−N) (26)\nThe Gmax equations have the solutions: N = Q = 0 and P = 1 (E1); N = 1, P = Q = 0 (E2); and N = P = Q = 12 (E3). The Ginv only accepts the first two solutions with the extension E3 not being possible.20\nNow suppose we actually do not know whether there are solutions or what they would be and let us consider our options. We have a system of equations involving N , P and Q and we want to try and solve it.\nOption 1 – A mathematical view. Let us just find a solution. This is a numerical analysis problem. We can guess a candidate solution; use, for instance, Newton’s method; and iterate in the hope of converging to a solution. Option\n20The specific behaviour of Ginv is outside of the scope of this paper. However it is explored in detail in [12].\n2 – A semantical view. We seek a solution motivated not by mathematics but by the meaning of the equations; by argumentation considerations. Newton’s method may not be adequate here. We want a method which, if we start very near a solution, then we get convergence to that desired solution. Here we cannot accept any solution. We want solutions which reflect the input. So we need to devise algorithms involving iterations which have a semanical meaning, in addition to the usual mathematical properties that the iteration sequences calculated by these algorithms converge. This point is important. Suppose we give the following interpretation to the network. 100 voters need to form a committee from amongst three experts P , Q and N to give an opinion on a crucial issue. All of them vote for N to be included (in), none of them want P to be included (i.e, they want P to be out), and they are equally divided on their support for Q (und). There is however an additional information about these candidates which is of a personal nature of which the voters are not aware. These are represented by the attack relation in the network, in which X → Y means X refuses to work with Y . We thus say that we have a numerical assignment N = 1, P = 0 and Q = 12 and we now ask what extension (i.e., what committee membership) is nearest to this majority vote? At first glance, the reader may think that it is extension E2 (N is in, and P and Q are out), because it agrees with the wishes of all of the voters that N is in and P is out. We would like our iteration algorithm to give us this result if possible.\nLet us look at what Newton’s method would do to these initial values. We start with initial values N0 = 1, P 0 = 0 and Q0 = 1 2 and iterate for the case of Gmax (equations (21)–(23)). We shall see that iterating in this way is not satisfactory. We get\nN1 = 1 2 , P 1 = 0, Q1 = 0 N2 = 1, P 2 = 12 , Q2 = 1 2 N2 = 1 2 , P 2 = 0, Q2 = 0\nThere is no convergence here, so this is not satisfactory as we do not get an answer for membership (i.e., no extension in the argumentation sense).\nLet us now compare with the Gabbay-Rodrigues Iteration Schema for Gmax, which is the main subject matter of this paper and is introduced in Section 2. The schema always yields a solution which corresponds to an extension in the argumentation sense.\nLet 〈S,R〉 be an argumentation network and X,Yi ∈ S be considered variables. Let Att(X) = {Yj} (j ≥ 0) be the attackers of X and let the equations be X = Gmax(Att(X)).21 Let Vi(X) be the value of X at iteration step i. Then the value of X at step i+ 1 is calculated as\nVi+1(X) = (1− Vi(X)) ·min { 1\n2 , G ({Vi(Yj)})\n} +\nVi(X) ·max { 1\n2 , G({Vi(Yj)}) } 21Ginv can also be used, with different results.\nSo for the network in Figure 7 and Gmax we get Vi+1(N) = (1− Vi(N)) ·min { 1\n2 , 1−max{Vi(P ), Vi(Q)}\n} +\nVi(N) ·max { 1\n2 , 1−max{Vi(P ), Vi(Q)} } Vi+1(P ) = (1− Vi(P )) ·min { 1\n2 , 1− Vi(N)\n} +\nVi(P ) ·max { 1\n2 , 1− Vi(N) } Vi+1(Q) = (1− Vi(Q)) ·min { 1\n2 , 1−max{Vi(P ), Vi(N)}\n} +\nVi(Q) ·max { 1\n2 , 1−max{Vi(P ), Vi(N)} } Let us now take the initial conditions V0(N) = 1, V0(P ) = 0 and V0(Q) = 0 and calculate the iterations. All values will converge to 12 . The perceptive reader might ask what is the philosophy behind the schema that led us to the extension E3, rather than to the larger extension E2. The schema is very sensitive to the undecided values. It acts cautiously in considering the votes for N ’s being included, because a proportion of the voters wanted Q to be included but N and Q cannot work together."
    }, {
      "heading" : "B Numerical Argumentation Networks",
      "text" : "In [1], the idea of support and attack networks was initially proposed. These networks allow for the assignment of initial values to the nodes of the graph; the specification of a transmission factor associated with the strength with which an attack between arguments is carried out; and the higher-level notion of an attack to an attack. In [17], we showed how some of these features can be used in the merging of argumentation networks. The numerical argumentation networks we now propose share some of the features of the support and attack networks, but introduce a functional approach to the computation of interaction between nodes.\nDefinition B.1 (Numerical Argumentation Network) A numerical argumentation network is a tuple 〈S,R, V0, Ve, g, h,Π〉, where\n• S is a set of nodes, representing arguments;\n• R ⊆ S2 is an attack relation, where (X,Y ) ∈ R means “X attacks Y ”;\n• V0 : S −→ U is a function assigning initial values to the nodes in S;\n• g is a function to combine attacks to a node;\n• h is a function to combine the initial value of a node with the value of its attack;\n• Π is an algorithm to compute equilibrium values Ve(X), for each node X ∈ S.\nWe assume that g and h are possibly distinct argumentation-friendly functions according to Definition 1.2. The equilibrium value of a node X, Ve(X), is defined as h(V0(X), gY ∈Att(X)({1− Ve(Y )})) and computed by the algorithm Π. Since the computation of the equilibrium values of the nodes takes the values of the attacking nodes into account, in Cayrol and Lagasquie-Schiex’s terminology, the algorithm Π offers a procedure to perform an interaction-based valuation of the graph 〈S,R〉. However, our approach is more general because the computation is done in terms of equations satisfying abstract principles.\nWe start our discussion with a simple graph without cycles, such as the one in Figure 8 to illustrate how numerical argumentation networks are used in the context of the argumentation-friendly functions seen in this paper.\nGiven initial values V0(X), V0(Y ), and V0(Z) for the nodes X, Y and Z, respectively, we want the values of Ve(X), Ve(Y ) and Ve(Z) to depend on them. Since the node X is not attacked by any node, its equilibrium value Ve(X) is defined as h(V0(X), g(∅)) = h(V0(X), 1) = V0(X). However, the value of Ve(Y ) and Ve(Z) depend not only on their initial values, but also on the equilibrium values of their attackers. This suggests some notion of directionality in the computation.\nNow consider a more complex network, in which the node X has a number of attackers as well as an initial value V0(X) as depicted in Figure 9.\nWe can compute g({1 − Ve(Y1), . . . , 1 − Ve(Yk)}) = y, which gives us the value of the attack on X. The equilibrium value of X is the result of combining its initial value V0(X) with the value of the combined attacks on it, so we can pretend we have the interaction depicted in Figure 10. and compute h(Ve(Z1), Ve(Z2)), i.e., h(V0(X), g({1 − Ve(Y1), . . . , 1 − Ve(Yk)}). We get equations of the kind\nVe(X) = h(V0(X), g({1− Ve(Y1), . . . , 1− Ve(Yk)}) (27)\nto solve. As we mentioned, g and hmay be different functions, so for example we could have g({1− Ve(Y1), . . . , 1− Ve(Yk)}) = min({1− Ve(Y1), . . . , 1− Ve(Yk)}) and h(x, y) = x · y.\nWhen f and g are the same, e.g., f = g = min, we can pretend we have Figure 11. And then we get Ve(X) = min({1− (1− V0(X)), 1− Ve(Y1), . . . , 1− Ve(Yk)}) = min({V0(X), 1 − Ve(Y1), . . . , 1 − Ve(Yk)}). Note that in this situation, the traditional equation (without h and initial values) is a special case of V0(X) = 1, because h(1, z) = z and then Ve(X) = h(1, g({1 − Ve(Y1), . . . , 1 − Ve(Yk)})) = g({1− Ve(Y1), . . . , 1− Ve(Yk)}).\nWe now address another issue. Once we solve equation (27), we get a function Ve such that\nVe(X) = h(V0(X), g({1− Y1, . . . , 1− Yk}))\nCan we use Ve(X) itself as an initial value? In other words, do we have that equation (28) below holds?\nVe(X) = h(Ve(X), g({1− Y1, . . . , 1− Yk})) (28)\nThe answer is “no”, because g and h are not necessarily the same function. In case it is the same function, we have\nVe(X) = h(Ve(X), g({1− Y1, . . . , 1− Yk})) = g({Ve(X), g({1− Y1, . . . , 1− Yk})}) = g({Ve(X), 1− Y1, . . . , 1− Yk}) = g({Z, 1− Y1, . . . , 1− Yk})\nwhere Z is the equilibrium value of a new point attacking X, whose value is fixed at V0(X). We can simulate this by adding new points Z1X and Z 2 X for each X and form the graph depicited in Figure 12. All solutions to the cycle\nZ1X ↔ Z2X are of the form (Ve(Z1X),1− Ve(Z1X)), which means that Z1X can get any value in U and hence so can its attack on X. This can be seen as having the same effect as giving X a particular initial value in U .\nThese conditions are satisfied by the t-norm min. An attack takes the complement of the value of the attacking node to 1 (co-norm).\nWe have that\nmin Y ∈Att(X) {1− Ve(Y )} = 1− max Y ∈Att(X) {Ve(Y )}\ngiving us our now familiar Eqmax. The t-norm min only cares about the strength of the strongest argument. In some applications, one could argue that attacks by multiple arguments should bear more weight than the value of any of the arguments alone. One way of modelling this is by combining attacks via product.∏\nY ∈Att(X)\n(1− Ve(Y )) (29)\nAgain, if any attacker of an argument has equilibrium value 1, then the value of the product will be 0. Otherwise, if all attackers of X are fully defeated, i.e., if they all have equilibrium value 0, then the value of the product will be 1. Combining the value of attacks in this way was initially proposed in [1].\nThe expression (29) is equivalent to\n1−gY ∈Att(X)Ve(Y ) (30)\nwhere xgy = x+y−x.y and for V = {x1, . . . , xk}, gV = (((x1gx2)g. . .)gxk). (30) is the complement of the probabilistic sum t-conorm. It is well known that in probability theory, the probabilistic sum expresses the probability of the occurrence of independent events. Since we want to weaken the value of the attacked node, we take the complement of this sum to 1.\nA network generates a system of equations. If there are cycles in the graph, then some of the variables associated with equilibrium values will be expressed in terms of each other. We now explore this in a bit more detail.\nConsider the following example.\nAssume that all initial values are 1, that g and h are product. The graph in Figure 13 will generate the system of equations\nVe(X) = 1− Ve(Y ) Ve(Y ) = 1− Ve(X)\nwhich has an infinite number of solutions given by the formula Ve(X)+Ve(Y ) = 1. A way to arrive at a unique solution to the equations is to introduce a\nconstant κ < 1 and analyse the solution to the system of equations in the limit κ→ 1. This would give us\nVe(X) = κ(1− Ve(Y )) Ve(Y ) = κ(1− Ve(X))\nVe(X) = κ− κVe(Y ) = κ− κ(κ− κVe(X)) = κ− κ2 + κ2Ve(X)\nVe(X)− κ2Ve(X) = κ− κ2\nVe(X)(1− κ2) = κ− κ2\nVe(X) = κ(1− κ)\n(1− κ)(1 + κ)\nVe(X) = κ\n1 + κ\nHence, when κ→ 1, Ve(X) = Ve(Y ) = 1/2. This result explains the implicit introduction of the parameter ε to the vote aggregation function proposed by Leite and Martins in [19].22\nSince the initial values of the two nodes in the network of Figure 13 are the same, another way of looking at the network is by unravelling the cycle starting arbitrarily at one of its nodes, say X. In our example, this would result in the (infinite) network of Figure 14.\nIf we assume the initial values for X and Y are both x, the equilibrium value for X could be calculated as\nVe(X) = x · (1− (x · (1− (x · (1− . . .)))) Now suppose x = 11+ε , for some ε > 0, we have that\nVe(X) = 1\n1 + ε\n( 1− ( 1\n1 + ε\n( 1− ( 1\n1 + ε (1− . . .) )))) Thus, in fact, we would be multiplying the initial value x = 11+ε by the number\nδ = 1− ( 1\n1 + ε\n( 1− ( 1\n1 + ε (1− . . .) ))) 22We disagree with the reasons for the introduction of the parameter itself, although technically it is the reason why the solution converges. A full discussion about this is given on Section 4.\nLet us calculate what the value δ is. To simplify the calculation we set α = (1 + ε), we then get\nδ = 1− ( 1\nα\n( 1− ( 1\nα (1− . . .) ))) If we expand the first multiplication, we get\nδ = 1− ( 1\nα − 1 α2\n( 1− 1\nα (. . .) )) = 1− [ 1\nα − 1 α2 + 1 α3\n( 1− 1\nα (. . .) )] = 1− [ 1\nα − 1 α2 + 1 α3 − 1 α4\n( 1− 1\nα (. . .) )] = 1− [( α− 1 α2 ) + ( α− 1 α4 ) + ( α− 1 α6 ) + . . .\n] The component (\nα− 1 α2\n) + ( α− 1 α4 ) + ( α− 1 α6 ) + . . .\ncan be re-written as ∞∑ k=1 (α− 1) ( 1 α2 )k which is the same as\n∞∑ k=0 (α− 1) ( 1 α2 )k − (α− 1)\nThe first component in the main subtraction above is the sum of a geometric series with common ratio 1α2 and scale factor α − 1. Now note that the ratio 1 α2 < 1, since α = 1 + ε > 1, and hence\n∞∑ k=0 (α− 1) ( 1 α2 )k = (α− 1) 1− 1α2 = α2(α− 1) α2 − 1\nThe subtraction can therefore be re-written as\nα2(α− 1) α2 − 1 − (α− 1)\n= α2(α− 1)− (α2 − 1)(α− 1)\nα2 − 1\n= (α− 1)(α2 − α2 + 1) α2 − 1 = α\nα2 − 1\nRemember that α = 1 + ε, hence α\nα2 − 1 = 1 + ε− 1 (1 + ε)(1 + ε)− 1\n= ε\nε2 + 2ε+ 1− 1 = ε\nε(ε+ 2)\n= 1\nε+ 2\nTherefore,\nδ = ( 1− 1\nε+ 2 ) and hence in the limit ε→ 0, we get\nVe(X) = lim ε→0\n1\n1 + ε\n( 1− 1\nε+ 2\n) = 1\n2\nas expected. If we just have an acyclic sequence of attacks such as the one in Figure 15, we can analyse what happens with the equilibrium values of each node, given a fixed initial value v for all nodes (again we consider f as product).\nFrom the network in Figure 15, we get that Ve(X1) = v, Ve(X2) = v · (1−v), Ve(X3) = v · (1 − (v · (1 − v))), and so forth. If v = 1, then Ve(X1) = 1, Ve(X2) = 0, Ve(X3) = 1,. . . . The values alternate between 0 and 1, agreeing with Dung’s original semantics as expected. If v = 0, then Ve(Xi) = 0 for all 0 ≤ i ≤ k. This is a consequence of the fact, that by using g, the equilibrium value depends on the node’s initial value and if this is 0, so is the equilibrium value of the node when g is product. Similarly, if the initial values of all nodes is 12 , we get Ve(X1) = 1 2 , Ve(X2) = 1 4 , Ve(X3) = 3 8 , . . . .\nContrast the calculation of the equilibrium values above with that of Besnard and Hunter [2], in which the values are calculated by a so-called categoriser function. In their paper, the given example of such a function was the hcategoriser h, defined as\nh(X) =\n{ 1, if Att(X) = ∅\n1 1+ ∑ Y ∈Att(X) h(Y ) , otherwise\nAssuming initial value v = 1 in the example above, we would have that h(X1) = 1, h(X2) = 12 , h(X3) = 2 3 , and so forth. This obviously does not agree with Dung’s interpretation.\nThe effect on the equilibrium value of a node calculated using g and h as product, when the node is attacked by a single node of same initial value is now discussed. This is the scenario depicted in Figure 16.\nIf we assume that X and Y get initial value x, we have that since X has no attacking arguments, Ve(X) = x · (1− 0) = x. We then have\nVe(X) = x Ve(Y ) = x(1− Ve(X)) = x− x2\nIf X gets initial value 1, then it gets equilibrium value 1 and since it attacks Y , its equilibrium value is 0, as expected.23 On the other hand, if X and Y get initial value 0, then Y ’s equilibrium value will also be 0. If X and Y get initial value 12 , then the attack by X on Y is not sufficiently strong to annihilate Y ’s initial value completely. In fact, it only brings it down by 50%, i.e., giving it equilibrium value 14 . This is the maximum weakening that an attack by an equally strong argument can inflict on Y using product. The full range of values under these circumstances is illustrated by Figure 17.\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1\nE qu\nili br\niu m\nv al\nue o\nf Y\nInitial value of X\nx-x2\nB.1 Comparisons with Social Abstract Argumentation Networks\nIn [19], Leite and Martins proposed social abstract argumentation frameworks which can be seen as an extension of Dung’s abstract argumentation frameworks to allow the representation of information about votes to arguments. This work was subsequently extended in [11] to handle votes on attacks too.\nThe motivation for these networks is to provide a means to calculate the result of the interaction between arguments using approval and disapproval ratings from users of news forums. The idea is that when a user sees an argument, she may approve it, disapprove it, or simply abstain from expressing an opinion. Since the arguments relate to each other through an attack relation (not necessarily known to the users), the votes themselves are not sufficient to provide an overall picture of the discussion. An interesting feature of these environments is therefore their intrinsic informal nature in the sense that in practice it is possible that voters vote for multiple arguments in the debate and also that users may be unware of conflicts between the arguments.\nOne immediate concern is the provision of an appropriate semantics which can give an interpretation to the votes capturing the intuition of the voting process. The semantics must take into account both the interactions between the arguments as well as the votes originally cast for them.\nWe now introduce Eǧilmez et al.’s work [11], which is an extension to [19] so we can compare it with our methodology.24\nDefinition B.2 [11] A social abstract argumentation framework is a tuple 〈S,R, VS , VR〉, where S is a set of arguments; R : S × S is a binary attack relation between arguments; and VS : S −→ N × N and VR : R −→ N × N are functions mapping arguments and attacks to tuples 〈v+, v−〉 representing the total of approval and disapproval votes received by each.\nIn order to provide a semantical interpretation, Eǧilmez et al. introduce the concept of a semantic framework presented below.\nDefinition B.3 [11] A social abstract argumentation semantic framework is a tuple 〈L, τ,f,g,¬〉, where\n• L is a totally ordered set with top and bottom elements > and ⊥, respectively\n• τ : N × N −→ L is a vote aggregation function that computes the social support of arguments and attacks\n• fS ,fR : L × L −→ L; g : L × L −→ L; and ¬ : L −→ L are algebraic operations on L\n24Note that [19] were not aware (and did not quote) [1], which was six years earlier. Thus, the only new contribution in [1] was how they determine the initial values and the connection with voting.\nThe operations τ , f, g and ¬ are used to calculate the overall strength of the arguments and attacks based on their initial votes. For the voting scenario considered in [11], the so-called product semantics was given. In this semantics, L is U (i.e., the interval [0, 1]); fS and fR are both the product t-norm f, where xfy = x.y; g is its associated t-conorm, i.e., xgy = 1−(1−x).(1−y) = x + y − x.y; ¬x = 1 − x; and τ is one of a family of operations τε defined as follows:\nDefinition B.4 [Initial support for attacks and arguments] Let X be an argument and VS(X) = 〈p,m〉.\nτε(X) = p\np+m+ ε\nwhere ε > 0. The initial support value for an attack (X,Y ) is calculated identically, except that we use VR ( (X,Y ) ) instead of VS(X).\nOne can regard τε and the operation that calculates the initial social support value for arguments and attacks. However, one adverse effect of calculating the initial support in this way is that it fails to put the votes in context, so an argument for which a single supporting vote is cast can get social support close to 1 (depending on what the value of is).25\nThe semantics of a social abstract framework is then defined by a social model presented below.\nDefinition B.5 [11] Let F be a social abstract argumentation framework and T = 〈L, τ,fS ,fR,g,¬〉 a semantic framework. A social model of F under semantics T is a total mapping M : S −→ L such that for every X ∈ S\nM(X) = τ(X)f ¬gYi∈Att(X) {τ ( (Yi, X) ) fM(Yi)}\nNote that if f is product t-norm and g is its t-conorm, as in [11], then\nM(X) = τ(X)f ¬gYi∈Att(X) {τ ((Yi, X))fM(Yi)}\n= τ(X) · 1− 1− ∏\nYi∈Att(X)\n(1− τ((Yi, X)) ·M(Yi))  = τ(X) ·\n∏ Yi∈Att(X) (1− τ((Yi, X)) ·M(Yi))\nContrast M(X) with the equilibrium value of X, Ve(X) as we proposed it in [17, Definition 5]:\nVe(X) = V0(X) · ∏\nYi∈Att(X)\n(1− ξ ((Yi, X))Ve(Yi))\n25ε cannot be 0, because this would render τε ill defined for components with no votes.\nThe calculation is exactly the same, except that we compute initial support differently as discussed next. We emphasise that the notion of the strength of attack already existed since [1].\nAs Leite et al. initially pointed out in [19], there are difficulties with the vote aggregation function τ . At first, the constant ε was introduced to avoid the existence of infinite models. For example, consider the network\nY\n1\n1\nX\nAnd assume that VS(X) = VS(Y ) = 〈x, 0〉. Then we have that τ0(X) = τ0(Y ) = 1 and hence any model M satisfying the equation M(X) = 1−M(Y ) is a social model of the network.\nHowever, if the social support uses a very small value for ε that is nevertheless greater than 0, we get the following situation.\nM(X) = 1\n1 + ε (1−M(Y ))\nM(Y ) = 1\n1 + ε (1−M(X))\nIf we substitute one value for the other, we get that\nM(X) = 1\n1 + ε\n( 1− 1\n1 + ε (1−M(X)) ) = 1\n1 + ε\n( 1 + ε− 1 +M(X)\n1 + ε ) = 1\n1 + ε\n( ε+M(X)\n1 + ε ) = ε+M(X)\n(1 + ε)2\nM(X)(1 + ε)2 = ε+M(X)\nM(X)(1 + ε)2 −M(X) = ε\nM(X) = ε\n(1 + ε)2 − 1\n= ε\n2ε+ ε2\n= 1\n2 + ε\nand hence limε→0M(X) = 12 = M(Y ), which provides a unique solution. In our opinion, there is a methodological problem and a technical one. The value ε > 0 solves the technical problem, which is the convergence to a single model. However, methodologically speaking, the objective of τ is to calculate initial support for components and in that respect, the constant ε has no part to play. This situation does not arise in [17, 16], because the social support function there is normalised with respect to the total number of argumentation networks being merged. We hope we have shed some light into the technicalities of finding solutions to the equations throughout this paper.\nA more difficult problem is the exaggerated role played by terminal arguments with little support, as shown below. Consider the following example:\nX Y\nτ ( (X,Y ) )\nand assume that VS(X) = 〈1, 0〉 and VS(Y ) = 〈99, 0〉. According to Definition B.4, τ0(X) = 1. Since X is a terminal argument, M(X) = 1(1−0) = 1 and hence M(Y ) = τ0(Y )(1 − τ ((X,Y )) ·M(X)) = τ0(Y ) (1− τ ((X,Y ))). Hence, the fate of Y depends on how strongly the attack from X is supported.26 Although this technically solves the problem, it mixes the two issues, because a voter must vote for an argument as well as for its attacks, if they are to have any effect and an argument can get very high initial support even if it is voted only by a very small number of voters.27\n26The main motivation for the introduction of the weights on attacks in [11]. 27High values of τ should correspond to high level of initial support."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2015,
    "abstractText" : "<lb>Given an argumentation network with initial values to the arguments,<lb>we look for algorithms which can yield extensions compatible with such<lb>initial values. We find that the best way of tackling this problem is to offer<lb>an iteration formula that takes the initial values and the attack relation<lb>and iterates a sequence of intermediate values that eventually converges<lb>leading to an extension. The properties surrounding the application of<lb>the iteration formula and its connection with other numerical and non-<lb>numerical techniques proposed by others are thoroughly investigated in<lb>this paper. 1 Orientation and Background 1.1 Orientation<lb>A finite system 〈S,R〉, with R a binary relation on S, can be viewed in many<lb>different ways; among them are 1. As an abstract argumentation framework [10], and 2. As a generator of equations [13, 14] 1<lb>ar<lb>X<lb>iv<lb>:1<lb>40<lb>8.<lb>67<lb>06<lb>v2<lb>[<lb>cs<lb>.A<lb>I]<lb>1<lb>8<lb>M<lb>ar<lb>2<lb>01<lb>5 When viewed as an abstract argumentation framework, the basic concepts<lb>studied are those of extensions (being certain subsets of S) and different se-<lb>mantics (being sets of extensions). When studied as generators of equations,<lb>one can generate equations in such a way that the solutions f to the equations<lb>correspond to (complete) extensions and sets of such solutions correspond to<lb>semantics.<lb>This paper offers an iteration schema for finding specific solutions to the<lb>equations responding to initial requirements and shows what these solutions<lb>correspond to in the abstract argumentation sense.<lb>We now explain the role iteration formulas play in general in the equational<lb>context.<lb>When we have a system of equations designed to model an application area1<lb>we face two problems: 1) find any solution to the system of equations, which<lb>will have a meaning in the application area giving rise to the equations; 2)<lb>given boundary conditions and/or other requirements not necessarily mathe-<lb>matical which are meaningful in the application area,2 we would like to find<lb>a solution to the system of equations that is compatible/respects the initial<lb>conditions/requirements.<lb>These two problems are distinct. The first one of finding any solution is a<lb>numerical analysis problem. There are various iteration methods in numerical<lb>analysis to find solutions, of which one of the most known is Newton’s method.3<lb>The second problem is totally different. It calls for an understanding of the<lb>requirements coming from the application area and possibly the design of a<lb>specialised iteration formula which respects the type of requirements involved.<lb>This paper provides the Gabbay-Rodrigues Iteration Schema, for the case of<lb>the equational approach to argumentation, seeking solutions (which we shall see<lb>will correspond to complete extensions) respecting as much as possible initial<lb>demands and restrictions of what arguments are in or out of the extension. We<lb>compare what our iteration schema does with Caminada and Pigozzi’s down-<lb>admissible and up-complete constructions [7]. Because we are dealing with<lb>iteration formulas (involving limits) and we are comparing with set theoretical<lb>operations (as in Caminada and Pigozzi’s paper) we have to be detailed and<lb>precise and despite it being conceptually clear and simple, the proofs turn out<lb>to be mathematically involved, and require some patience from our readers.<lb>However, once we establish the properties of our iteration schema, its use and<lb>application are straightforward and computationally simple, especially in the<lb>context of such tools as MATHEMATICA and others like it. The reader may<lb>wish to just glance at the technical proofs and concentrate on the examples and<lb>1For example, equations of fluid flow in hydrodynamics or equations of particle motion<lb>in mechanics, or equations modelling argumentation networks according to the equational<lb>approach (to be explained later), or equations modelling a biological system of predator-prey<lb>ecology, or some polynomial equation arising in macroeconomics.<lb>2For example, initial conditions in the case of particle mechanics, or initial size of population<lb>in the ecology, or arguments that we would like to be accepted.<lb>3This method starts with an initial guess of a possible solution and uses various iteration<lb>formulae hoping that it will converge to a solution (for an introduction on numerical analysis<lb>see [21]).",
    "creator" : "LaTeX with hyperref package"
  }
}