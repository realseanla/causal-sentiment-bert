{
  "name" : "1609.05224.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Prioritised Default Logic as Argumentation with Partial Order Default Priorities",
    "authors" : [ "Anthony P. Young", "Sanjay Modgil", "Odinaldo Rodrigues" ],
    "emails" : [ "peter.young@kcl.ac.uk", "sanjay.modgil@kcl.ac.uk", "odinaldo.rodrigues@kcl.ac.uk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 9.\n05 22\n4v 1\n[ cs\n.A I]\nContents"
    }, {
      "heading" : "1 Introduction 2",
      "text" : ""
    }, {
      "heading" : "2 Background 4",
      "text" : "2.1 Notation Used in this Paper . . . . . . . . . . . . . . . . . . . . . 4 2.2 The ASPIC+ Framework . . . . . . . . . . . . . . . . . . . . . . . 4 2.3 Brewka’s Prioritised Default Logic . . . . . . . . . . . . . . . . . 8\n3 From ASPIC+ to PDL 9\n3.1 Representing PDL in ASPIC+ . . . . . . . . . . . . . . . . . . . . 9 3.2 A Suitable Argument Preference Relation . . . . . . . . . . . . . 10 3.3 The Representation Theorem . . . . . . . . . . . . . . . . . . . . 18\n3.3.1 Non-Blocked Defaults . . . . . . . . . . . . . . . . . . . . 18 3.3.2 Existence and Uniqueness of Stable Extensions . . . . . . 21 3.3.3 The Representation Theorem: Statement and Proof . . . 24\n3.4 Satisfaction of Rationality Postulates . . . . . . . . . . . . . . . . 27 3.4.1 The Stable Extension is Grounded . . . . . . . . . . . . . 27\n1The results of Section 3 first appeared in the preprint [23] and have been published in the conference proceedings of AAMAS2016 [24]. This paper gives the full proofs of these results.\n3.4.2 The Trivialisation and Rationality Theorems . . . . . . . 31 3.4.3 Inconsistent Arguments . . . . . . . . . . . . . . . . . . . 32\n3.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32"
    }, {
      "heading" : "4 On Lifting the Assumption of a Total Order Default Priority 33",
      "text" : "4.1 The Argument Preference Relation based on Partial Order Default Priorities . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 4.1.1 A Representation of Rules and their Ordering using Strings 33 4.1.2 Algorithm and Example Calculation . . . . . . . . . . . . 34 4.1.3 Properties of the Generalised SP Order . . . . . . . . . . 37 4.1.4 The Generalised Argument Preference Relation for <D Partial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 4.2 The Representation Theorem for Partial Order Default Priorities 41\n4.2.1 Linearisation of the Argument Preference Relation and Spanning Subgraphs . . . . . . . . . . . . . . . . . . . . . 41 4.2.2 Existence of Stable Extensions in the Partial Order Case 42 4.2.3 Proof of the Representation Theorem . . . . . . . . . . . 43\n4.3 Satisfaction of Rationality Postulates . . . . . . . . . . . . . . . . 46 4.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47"
    }, {
      "heading" : "5 Conclusions 47",
      "text" : "5.1 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 5.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48"
    }, {
      "heading" : "1 Introduction",
      "text" : "Dung’s abstract argumentation theory [11] has become established as a means for unifying various nonmonotonic logics (NMLs) [4,20,22], where the inferences of a given NML can be interpreted as conclusions of justified arguments. Abstract argumentation defines “justified arguments” by making use of principles familiar in everyday reasoning and debate. This renders the process of inference in the NML transparent and amenable to human inspection and participation, and serves as a basis for distributed reasoning and dialogue.\nMore precisely, relating NMLs and argumentation is to endow the NML with argumentation semantics. This has already been done for default logic [11], logic programming [11], defeasible logic [12] and preferred subtheories [16]. This allows the application of argument game proof theories [15] to the process of inference in these NMLs, and the generalisation of these dialectical proof theories to distributed reasoning amongst computational agents, where agents can engage in argumentation-based dialogues [1, 14, 17].\nAbstract argumentation has been upgraded to structured argumentation theory [3], one example of which is the ASPIC+ framework for structured argumentation [16]. In ASPIC+, arguments are constructed from premises and deductive or defeasible rules of inference. The conclusions of arguments can contradict each other and hence arguments can attack each other. A preference relation\nover the arguments can be used to determine which attacks succeed as defeats. The arguments and defeats instantiate an abstract argumentation framework, where the justified arguments are determined using Dung’s method. The conclusions of the justified arguments are then identified with the nonmonotonic inferences from the underlying premises and rules of inference. The advantages of ASPIC+ are that the framework provides a systematic and general method of endowing non-monotonic logics with argumentation semantics, and identifies sufficient conditions on the underlying logic and preference relations that guarantee the satisfaction of various normatively rational desiderata [10].\nThis paper endows Brewka’s prioritised default logic (PDL) [7] with argumentation semantics. PDL is an important NML because it upgrades default logic (DL) [19] with an explicit priority relation over defaults, so that, for example, one can account for recent information taking priority over information in the distant past. PDL has also been used to represent the (possibly conflicting) beliefs, obligations, intentions and desires (BOID) of agents, and model how these different categories of mental attitudes override each other in order to generate goals and actions that attain those goals [9].\nWe prove a correspondence between inferences in PDL and the conclusions of the justified arguments defined by the argumentation semantics. We realise these contributions by appropriately representing PDL in ASPIC+. The main challenges involve understanding how priorities over defaults in PDL can be represented as an ASPIC+ argument preference relation, and then applying the properties of this preference relation to prove that the extensions of PDL correspond to the conclusions of justified arguments.\nThis paper has five sections. In Section 2, we review ASPIC+, abstract argumentation, and PDL. In Section 3 we present an instantiation of ASPIC+ to PDL when the default priority is total. The key results are the design of an appropriate argument preference relation (Section 3.2), and showing that this argument preference relation guarantees that the conclusions of the justified arguments correspond exactly to the PDL extensions by the representation theorem (Section 3.3). We then investigate some properties and directly prove that the normative rationality postulates of [10] are satisfied (Section 3.4).2\nIn Section 4 we lift the assumption that the priority order on the defaults is total. Following the pattern of the previous section we generalise the argument preference (Section 4.1) to accommodate for partial order default priorities. We then prove a generalised representation theorem (Sections 4.2) and prove a partial result concerning the satisfaction of the rationality postulates of [10] (Section 4.3). We conclude in Section 5 with suggestions for future work.\n2But in this case we are not leveraging the properties of ASPIC+ to achieve this. We will discuss this point in Section 5."
    }, {
      "heading" : "2 Background",
      "text" : ""
    }, {
      "heading" : "2.1 Notation Used in this Paper",
      "text" : "In this paper: “:=” is read “is defined as”. WLOG stands for “without loss of generality”. N denotes the set of natural numbers. We denote set difference with −. For two sets A, B, A⊖B := (A−B)∪(B −A) denotes their symmetric difference. If f : X → Y is a function and A ⊆ X , f(A) ⊆ Y is the image set of A in Y under f . For a set X its power set is P (X) and its finite power set (set of all finite subsets) is Pfin(X). X ⊆fin Y iff X is a finite subset of Y , therefore X ∈ Pfin(Y ) ⇔ X ⊆fin Y . Undefined quantities are denoted by ∗, for example 1/0 = ∗ in the real numbers. Order isomorphism is denoted by ∼=.\nIf 〈P, .〉 is a preordered set then the strict version of the preorder is a < b ⇔ [a . b, b 6. a], which is also a strict partial order. If < is a strict partial order on P and U ⊆ P , then we define the set max< U := {x ∈ U (∀y ∈ U)x 6< y} ⊆ U , i.e. the set of all <-maximal elements of U . We define the set min< U analogously. For a set X we define the set of possible strict partial orders on X to be PO(X) := { <⊆ X2 < is a strict partial order } . Similarly, the set of all possible strict total orders onX is TO(X) := { <⊆ X2 < is a strict total order }\n⊂ PO(X). We will use the terms “total (order)” and “linear (order)” interchangeably. We will also call totally ordered sets either “tosets” or “chains”.\n2.2 The ASPIC+ Framework\nAbstract argumentation abstracts from the internal logical structure of arguments, the nature of defeats and how they are determined by preferences, and consideration of the conclusions of the arguments [11]. However, these features are referenced when studying whether any given logical instantiation of a framework yields complete extensions that satisfy the rationality postulates of [10]. ASPIC+ [16] provides a structured account of abstract argumentation, allowing one to reference the above features, while at the same time accommodating a wide range of instantiating logics and preference relations in a principled manner. ASPIC+ then identifies conditions under which complete extensions defined by the arguments, attacks and preferences, satisfy the rationality postulates of [10].\nIn ASPIC+, the tuple 〈L, −, Rs, Rd, n〉 is an argumentation system, where L is a logical language and − : L → P(L) is the contrary function θ 7→ θ where θ is the set of wffs that are inconsistent with θ. Let θ1, . . . , θm, φ ∈ L be wffs for m ∈ N, Rs is the set of strict inference rules of the form (θ1, . . . , θm → φ), denoting that if θ1, . . . , θm are true then φ is also true, and Rd is the set of defeasible inference rules of the form (θ1, . . . , θm ⇒ φ), denoting that if θ1, . . . , θm are true then φ is tentatively true. Note Rs∩Rd = ∅. For a strict or defeasible rule r = (θ1, . . . θm → / ⇒ φ), we define Ante(r) := {θ1, . . . , θm} ⊆fin L,3 and Cons(r) := φ ∈ L. Finally, n : Rd → L is a partial function that assigns a name to some of the defeasible rules. For any S ⊆ L we define the set ClRs(S) ⊆ L to be the smallest superset of S that also contains Cons(r) for\n3Note it is possible to have m = 0 and hence Ante(r) = ∅.\nall r ∈ Rs such that Ante(r) ⊆ ClRs(S). We call ClRs the closure under strict rules operator.\nIn ASPIC+, a knowledge base is a set K := Kn ∪ Kp ⊆ L where Kn is the set of axioms and Kp is the set of ordinary premises. Note that Kn ∩ Kp = ∅. Given an argumentation system and K, arguments are defined inductively:\n1. (Base) [θ] is a singleton argument with θ ∈ K, conclusion Conc([θ]) := θ, premise set Prem ([θ]) := {θ} ⊆ K, top rule TopRule([θ]) := ∗ and set of subarguments Sub ([θ]) := {[θ]}.\n2. (Inductive) Let A1, . . . , An be arguments with respective conclusions Conc(A1), . . . , Conc(An) and premise sets Prem(A1), . . . , P rem(An). If there is a rule r := (Conc (A1) , . . . , Conc (An) → / ⇒ φ) ∈ R, then B := [A1, . . . , An → / ⇒ φ] is also an argument with Conc(B) = φ, premises Prem(B) :=\n⋃n i=1 Prem(Ai), TopRule(B) = r ∈ R and set of\nsubarguments Sub(B) := {B} ∪ ⋃n\ni=1 Sub(Ai).\nLet A be the (unique) set of all arguments freely constructed following the above rules. It is clear that arguments are finite objects in that each argument has finitely many premises, and take finitely many rules to reach its conclusion. We define the conclusion map Conc : A → L : A 7→ Conc(A). We can generalise this to arbitrary sets of arguments (abuse of notation):\nConc : P (A) → P (L) : S 7→ Conc(S) := ⋃\nA∈S\nConc(A). (2.1)\nTwo strict or defeasible rules are equal iff they have the same antecedent sets, consequents and name syntactically in the underlying L. Two arguments are equal iff they are constructed identically as described above. More precisely, we can define equality of arguments inductively. The base case would be two singleton arguments [θ], [φ] are equal iff θ and φ are syntactically the same formulae. Given n arguments A1, . . . , An and two equal rules r1 and r2 (either both strict or both defeasible) with antecedent {Conc (Ai)} n i=1, such that B1 is the rule r1 appended to the Ai’s, and B2 is the rule r2 appended to the Ai’s, then B1 and B2 are equal arguments.\nWe say A is a subargument of B iff A ∈ Sub(B) and we write A ⊆arg B. We say A is a proper subargument of B iff A ∈ Sub(B) − {B} and we write A ⊂arg B. It can be shown that ⊆arg is a preorder on Sub(B). A set of arguments is subargument closed iff it is ⊆arg-down closed. Clearly, for every defeasible rule r in an argument A, there is a subargument of A with r as its top rule, by the inductive construction of arguments.\nAn argument A ∈ A is firm iff Prem(A) ⊆ Kn. Further, SR(A) ⊆ Rs is the set of strict rules applied in constructing A, and DR(A) ⊆ Rd is the set of defeasible rules applied in constructing A. We also define Premn(A) := Prem(A) ∩ Kn and Premp(A) := Prem(A) ∩ Kp. An argument A is strict iff DR(A) = ∅, else A is defeasible. We can generalise DR ( · ) to sets as well just like Equation 2.1 for Conc ( · ).\nGiven R ⊆ Rd, we introduce the set of all arguments freely constructed with defeasible rules restricted to those in R as the set Args(R) ⊆ A, which are all arguments with premises in K, strict rules in Rs and defeasible rules in R. Formally, Args(R) is defined inductively just as how arguments are constructed, but with the choice of defeasible rules restricted to those in R. It is easy to show that this definition is equivalent to\nA ∈ Args(R) ⇔ DR(A) ⊆ R. (2.2)\nClearly, Args(Rd) = A. Given R, Args(R) exists and is unique. Let S ⊆fin A. The set of all strict extensions of S is the set StExt (S) where\nA ∈ StExt (S) ⇔DR(A) = DR(S), SR(A) ⊇ SR(S),\nP remp(A) = Premp(S), P remn(A) ⊇ Premn(S).\nA set S ⊆ A is closed under strict extensions iff for all T ⊆fin S, StExt (T ) ⊆ S.\nLemma 2.1. The set Args(R), for any R ⊆ Rd, is closed under strict extensions and subarguments.\nProof. If A ∈ Args(R) and B ⊆ A, then DR(B) ⊆ DR(A) ⊆ R so DR(B) ⊆ R and hence B ∈ Args(R), therefore Args(R) is subargument closed. Now let T ⊆fin Args(R), so for all B ∈ T , DR(B) ⊆ R, therefore DR(T ) := ⋃\nB∈T DR(B) ⊆ R. Let A ∈ StExt (T ), then DR(A) = DR(T ) ⊆ R and hence A ∈ Args (R). Therefore, StExt (T ) ⊆ Args (R), therefore Args(R) is closed under strict extensions.\nAn argument A attacks another argument B, denoted as A ⇀ B, iff at least one of the following hold, where:\n1. A is said to undermine attack B on the (singleton) subargument B′ = [φ] iff there is some φ ∈ Premp(B) such that Conc(A) ∈ φ.\n2. A is said to rebut attack B on the subargument B′ iff there is some B′ ⊆arg B such that r := TopRule (B′) ∈ Rd, φ := Cons(r) and Conc(A) ∈ φ.\n3. A is said to undercut attack B on the subargument B′ iff there is some B′ ⊆arg B such that r := TopRule(B ′) ∈ Rd and Conc(A) ∈ n(r).\nSee [16, Section 2] for a further discussion of why attacks are distinguished in this way. We abuse notation to define the attack relation as ⇀⊆ A2 such that (A, B) ∈⇀⇔ A ⇀ B. Notice that by the transitivity of ⊆arg, if A ⇀ B and B ⊆arg C, then A ⇀ C.\nA preference relation over arguments is then used to determine which attacks succeed as defeats. We denote the preference -⊆ A2 (not necessarily a preorder for now) such that A - B ⇔ B is at least as preferred as A. Strict preference and equivalence are, respectively, A ≺ B ⇔ [A - B, B 6- A] and A ≈ B ⇔ [A - B, B - A]. We define a defeat as\nA →֒ B ⇔ (∃B′ ⊆arg B) [A ⇀ B ′, A 6≺ B′] . (2.3)\nThat is to say, A defeats B (on B′) iff A attacks B on the subargument B′, and B′ is not strictly preferred to A. Notice the comparison is made at the subargument B′ instead of the whole argument B. We abuse notation to define the defeat relation as →֒ ⊆ A2 such that (A, B) ∈ →֒ ⇔ A →֒ B. A set of arguments S ⊆ A is conflict-free (cf) iff →֒ ∩ S2 = ∅.4 Notice that by the transitivity of ⊆arg and that the preference comparison is made at the defeated subargument, if A →֒ B and B ⊆arg C, then A →֒ C. As relations, →֒ ⊆⇀.\nPreferences between arguments are calculated from the argument structure by comparing arguments at their fallible components, i.e. the ordinary premises and defeasible rules. This is achieved by endowing Kp and Rd with preorders .K and .D respectively, where (e.g.) r1 .D r2 iff r2 is just as preferred or more preferred than r1 (and analogously for .K). These preorders are then aggregated to a set-comparison relation E between the sets of premises and / or defeasible rules of the arguments, and then finally to - ⊆ A2, following the method in [16, Section 5].5 We will use a modified version of this lifting, which will be explained in Section 3.2.\nGiven the preference relation - between arguments, we call the structure 〈A, ⇀, -〉 an ASPIC+ SAF (structured argumentation framework), or attack graph. Its corresponding defeat graph is 〈A, →֒〉, where →֒ is defined in terms of ⇀ and - as in Equation 2.3.\nGiven 〈A, →֒〉 one can then evaluate the extensions under Dung’s abstract argumentation semantics, and thus identify the inferences defined by argumentation as the conclusions of the justified arguments. We now recap the key definitions of [11]. An argumentation framework is a directed graph 〈A, →֒〉, where A is the set of arguments and →֒ ⊆ A2 is the defeat relation, such that A →֒ B means A is a (successful) counterargument against B. The argumentation frameworks we consider are defeat graphs, but this is a general definition.\nLet S ⊆ A and A, B ∈ A. S defeats B iff (∃A ∈ S)A →֒ B. S is conflictfree (cf) iff →֒ ∩S2 = ∅. S defends A iff (∀B ∈ A) [B →֒ A ⇒ S defeats B]. The characteristic function is χ : P (A) → P (A), such that χ(S) := {A ∈ A S defends A} ⊆ A. S is an admissible extension iff S is cf and S ⊆ χ(S). An admissible extension S is: a complete extension iff S = χ(S); a preferred extension iff S is a ⊆-maximal complete extension; the grounded extension iff S is the ⊆-least complete extension; a stable extension iff S is complete and defeats all arguments B ∈ A− S.\nLet S := {complete, preferred, grounded, stable} be the set of Dung semantics. An argument A ∈ A is sceptically (credulously) justified under the semantics s ∈ S iff A belongs to all (at least one) of the s-extensions of 〈A, →֒〉.\nInstantiations of ASPIC+ should satisfy some properties to ensure they are rational [10]. Given an instantiation let 〈A, ⇀, -〉 be its ASPIC+ attack graph\n4Note that [16] studies two different notions of cf sets: one where no two arguments attack each other, and the other where no two arguments defeat each other. We choose the latter notion of cf as this is more commonplace in argumentation formalisms that distinguish between attacks and defeats, e.g. in [18].\n5Note there are many other ways to lift a preference < on a set of objects X to compare subsets of X in various ways that are “compatible” with < [2].\nwith corresponding defeat graph 〈A, →֒〉. Let E be any complete extension. The Caminada-Amgoud rationality postulates state:\n1. (Subargument closure) E is subargument closed.\n2. (Closure under strict rules) E satisfies Conc(E) = ClRs [Conc(E)], where Conc (E) is defined in Equation 2.1.\n3. (Consistency) Conc(E) is consistent.6\nAn ASPIC+ instantiation is normatively rational iff it satisfies these rationality postulates. These postulates may be proved directly given an instantiation. ASPIC+ also identifies sufficient conditions for an instantiation to satisfy these postulates [16, Section 4], which we will discuss in Section 5."
    }, {
      "heading" : "2.3 Brewka’s Prioritised Default Logic",
      "text" : "In this section we recap Brewka’s prioritised default logic (PDL) [7]. We work in first order logic (FOL) of arbitrary signature where the set of first-order formulae is FL and the set of closed first order formulae7 a.k.a. sentences is SL ⊆ FL, with the usual quantifiers and connectives. Entailment is denoted by |=. Logical equivalence of formulae is denoted by ≡. Given S ⊆ FL, the deductive closure of S is Th(S), and given θ ∈ FL, the addition operator + : P(FL)×FL → P (FL) is defined as S + θ := Th(S ∪ {θ}).\nA normal default is an expression θ:φ φ\nwhere θ, φ ∈ FL and read “if θ is the case and φ is consistent with what we know, then jump to the conclusion φ even if it does not deductively follow”. In this case we call θ the antecedent and φ the consequent. A normal default θ:φ\nφ is closed iff θ, φ ∈ SL. We will assume\nall defaults are closed and normal unless stated otherwise. Given S ⊆ SL, a default is active (in S) iff [θ ∈ S, φ /∈ S, ¬φ /∈ S].\nA finite prioritised default theory (PDT) is a structure T := 〈D, W, <〉, where the set of facts W ⊆ SL is not necessarily finite and 〈D, <〉 is a finite strict partially ordered set of defaults that nonmonotonically extend W . The priority relation is such that d′ < d ⇔ d is more8 prioritised than d′. All PDTs in this paper are finite.\nThe inferences of a PDT T = 〈D,W,<〉 are defined by its extensions. Let <+⊇< be a linearisation of <. A prioritised default extension (with respect to <+) (PDE) is a set E := ⋃\ni∈N Ei ⊆ SL built inductively as:\n6Notice by properties 2 and 3 above ClRs (Conc (E)) is consistent. ASPIC + distinguishes this into direct and indirect consistency given that Rs is in general arbitrary and do not have to be the rules of inference of classical logic. We will not make this distinction because our underlying logic will be first order logic (FOL) (Section 3.1). Further, consistency in the abstract logic of ASPIC+ is expressed in terms of the contrary function, but since our contrary function will just be classical negation, we can take the usual meaning of consistency in FOL.\n7i.e. first order formulae without free variables 8 We have defined the order dually to [7] so as to comply with orderings over the ASPIC+ defeasible inference rules. This goes against the tradition in NML where the smaller item in < is the more preferred one.\nE0 := Th(W ) and (2.4)\nEi+1 :=\n{\nEi + φ, if property 1 Ei, else (2.5)\nwhere “property 1” abbreviates “φ is the consequent of the <+-greatest9 default d active in Ei”. Intuitively, one first generates all classical consequences from the facts W , and then iteratively adds the nonmonotonic consequences from the highest priority default to the lowest. Notice if W is inconsistent then E0 = E = FL. For this paper we will assume W is always consistent.\nFor finite D it can be shown that the ascending chain Ei ⊆ Ei+1 stabilises at some finite i ∈ N and that E is consistent provided that W is consistent. E does not have to be unique because there are many distinct linearisations of <. We say T sceptically infers θ ∈ SL iff θ ∈ E for all extensions E of T .\nA PDT T for which < is a strict total order is a linearised PDT (LPDT). If < is total then there is only one way to apply the defaults in D by Equation 2.5, hence the extension is unique. We will use the notation <+ to emphasise that the priority is total, and the notation T+ to denote an arbitrary LPDT.\nFor the rest of this paper, if we declare T to be a PDT, we mean T = 〈D,W,<〉 where each component is defined above, and we make no further assumptions on each component. If we declare T+ to be an LPDT, we mean T+ = 〈D,W,<+〉 where <+ is a strict total order on D.\n3 From ASPIC+ to PDL\n3.1 Representing PDL in ASPIC+\nWe now instantiate ASPIC+ to PDL. Let T+ := 〈D, W, <+〉 be an LPDT.10\n1. Our arguments are expressed in FOL, so our set of wffs L is FL.\n2. The contrary function − : FL → P (FL) syntactically defines conflict in terms of classical negation. For all θ ∈ FL, θ = {¬θ} unless θ has the syntactic form ¬φ for some φ ∈ FL, then θ = {φ}. As θ is singleton, we will abuse notation and write θ to refer to its element.\n3. The set of strict rules Rs characterises inference in FOL. Notice Rs is closed under transposition, i.e. for all 1 ≤ i ≤ n ∈ N+,\n(θ1, θ2, . . . , θi−1, θi, θn+1, . . . , θn → φ) ∈ Rs\n⇒ (θ1, θ2, . . . , θi−1,−φ, θn+1, . . . , θn → −θi) ∈ Rs.\nWe leave the proof theory implicit. ClRs instantiates to deductive closure.\n9See Footnote 8. 10We will lift this assumption of a total order priority in Section 4.\n4. The set of defeasible rules Rd is defined as:\nRd :=\n{\n(θ ⇒ φ) θ : φ\nφ ∈ D\n}\n,\nwith the naming function n ≡ ∗. Clearly, there is a bijection f where\nf : D → Rd : θ : φ\nφ 7→ f\n(\nθ : φ\nφ\n)\n:= (θ ⇒ φ) (3.1)\nand we will define the strict version of the preorder ≤D over Rd as 11\n(θ ⇒ φ) <D (θ ′ ⇒ φ′) ⇔\nθ : φ\nφ <+\nθ′ : φ′\nφ′ . (3.2)\nWe can see that the strict toset 〈Rd, <D〉 is order isomorphic to 〈D, < +〉.\n5. The set of axiom premises is Kn = W , because we take W to be the set of facts. Furthermore, Kp = ∅.\nThe set A of ASPIC+ arguments are defined as in Section 2.2.12 All arguments are firm because Kp = ∅, and so there are no undermining attacks. As n is undefined, no attack can be an undercut. Therefore, we only have rebut attacks,\nA ⇀ B ⇔ (∃B′, B′′ ⊆arg B) B ′ =\n[ B′′ ⇒ Conc(A) ] . (3.3)\nDefeats are defined as in Equation 2.3. In the next section, we will define the argument preference -, based on the strict total order <D over Rd."
    }, {
      "heading" : "3.2 A Suitable Argument Preference Relation",
      "text" : "We wish to define a suitable argument preference relation such that the conclusion set of the stable extension defined by →֒ corresponds to the extension of the underlying PDT.13 The first place to look for such a relation is in the existing relations of ASPIC+ [16, Definition 19]. However, simple counterexamples can be devised to show the inferences of the PDT and its argumentation counterpart do not correspond.\nThe difference between PDL and ASPIC+ is in how blocked defaults are treated. In PDL, blocked defaults are simply excluded from the extension. In ASPIC+, it is possible to construct arguments with defeasible rules that correspond to blocked defaults. If <+ ∼= <D such that <\n+ is arbitrary, there is no guarantee that the blocked defaults will be positioned in the chain <+ such that arguments with blocked defaults are always defeated by arguments with\n11From Footnote 8, we do not need to define <D as the order-theoretic dual to < +, avoiding potential confusion as to which item is more preferred. 12As Rs is a countably infinite set, A is also a countably infinite set. 13In Section 3.4, we will show that for the resulting defeat graphs there is only one extension in that is stable, grounded and preferred.\nonly non-blocked defaults.14 To ensure that arguments with blocked defaults are defeated and hence the conclusions of the justified arguments form the extension of the PDT, we need to rearrange the rules in Rd to take into account the structure of arguments. ASPIC+ does allow for explicit reference to argument structure, i.e. we can tell which defeasible rules preceed which within an argument.\nRearranging <D to take argument structure into account captures the PDL meaning of “active” default, because defaults are added to Ei when its prerequisite is inferred. This rearrangement will mean that every defeasible rule r corresponding to a blocked default will be less preferred than the rules which make up arguments that rebut the argument with r as its top rule. We now devise a new ASPIC+ argument preference relation which incorporates the argument structure into the preorder <D.\nMore formally, given any strict total order <D on Rd, we first define a transformation <D 7→ <SP , where the subscript SP stands for structure-preference. This sorts the defeasible rules in a way compatible with both the priority <D and their logical structure.\nThe set Rd is finite because we have assumed that D is finite (Sections 2.3 and 3.1). Let 1 ≤ i ≤ |Rd| =: N ∈ N. We define ai ∈ Rd to be the <D-greatest element of the following set:\n{\nr ∈ Rd Ante(r) ⊆ Conc\n[\nArgs\n(\ni−1 ⋃\nk=1\n{ak}\n)]}\n−\ni−1 ⋃\nj=1\n{aj} . (3.4)\nThe intuition is: a1 is the most preferred rule whose antecedent is inferred by the conclusions of all strict arguments, a2 is the next most preferred rule, whose antecedent is amongst the conclusions of all arguments having at most a1 as a defeasible rule. Similarly, a3 is the next most preferred rule, whose antecedent is amongst the conclusions of all arguments having at most a1 and a2 as defeasible rules, and so on until all of the rules ofRd are exhausted. Notice that the second union after the set difference in Equation 3.4 ensures that once a rule is applied it cannot be applied again. We then define <SP as (notice the dual order)\nai <SP aj ⇔ j < i. (3.5)\nWe define the non-strict order to be ai ≤SP ai ⇔ [ai = aj or ai <SP aj]. This makes sense because i 7→ ai is bijective betweenRd and {1, 2, 3, . . . , N}. Clearly <SP is a strict total order on Rd. We call this the structure preference order on Rd, which exists and is unique given <D. This means the transformation <D 7→<SP is functional, where <D is total on Rd.\nNow let <D be any strict partial order on Rd. We define the strict set comparison relation on Pfin (Rd) corresponding to <D. For Γ, Γ\n′ ⊆fin Rd, the relation ⊳DEli, called the disjoint elitist order, is defined as follows:\nΓ ⊳DEli Γ ′ ⇔ (∃x ∈ Γ− Γ′) (∀y ∈ Γ′ − Γ)x <D y. (3.6)\n14We will see this explicitly in Example 1 later.\nThe lifting <D 7→ ⊳DEli is functional. We will focus on the following special case of ⊳DEli, where instead of <D we have <SP :\nΓ ⊳SP Γ ′ ⇔ (∃x ∈ Γ− Γ′) (∀y ∈ Γ′ − Γ)x <SP y. (3.7)\nThe corresponding strict argument preference is, for A,B ∈ A,\nA ≺SP B ⇔ DR(A) ⊳SP DR(B). (3.8)\nWe define the corresponding non-strict preference as\nA -SP B ⇔ [DR(A) ⊳SP DR(B) or DR(A) = DR(B)] (3.9)\nWe now show that -SP satisfies the following properties.\nLemma 3.1. For all A,B ∈ A, DR(A) ⊆ DR(B) ⇒ B -SP A.\nProof. If DR(B) = DR(A) then B ≈ A, so B -SP A. If DR(A) ⊂ DR(B), then DR(A) − DR(B) = ∅, which means B ≺SP A is vacuously true from Equation 3.7 so B -SP A.\nThe following result shows that larger arguments, which potentially can contain more fallible information (i.e. defeasible rules), cannot be more preferred than its (smaller) subarguments.\nCorollary 3.2. For all A,B ∈ A, if A ⊆arg B then B -SP A.\nProof. It can be shown from how ASPIC+ arguments are constructed (Section 2.2) that A ⊆arg B ⇒ DR(A) ⊆ DR(B), and then invoke Lemma 3.1.\nCorollary 3.3. Strict arguments are -SP -maximal.\nProof. Let A ∈ A be strict and B ∈ A be arbitrary. Assume for contradiction that A ≺SP B. As DR(A) = ∅, Equations 3.7 and 3.8 instantiate to: A ≺SP B ⇔ (∃x ∈ ∅) (∀y ∈ DR(B))x <SP y, which is impossible by the first bounded quantifier. Therefore, if A is strict, then for all (∀B ∈ A)A 6≺SP B.\nLemma 3.4. Let 〈P,<〉 be a strict toset, then 〈Pfin (P ) , ⊳DEli〉 is also a strict toset, where ⊳DEli is defined in Equation 3.6, here with < instead of <D.\nProof. We prove ⊳DEli is irreflexive, transitive and total on Pfin (P ), assuming that < is a strict total order on P .15 To show irreflexivity, assume for contradiction that there is some Γ ∈ Pfin (P ) such that Γ ⊳DEli Γ, which by Equation 3.6 is equivalent to a formula whose first bounded quantifier is “(∃x ∈ ∅)”, which\n15 More generally, it can be shown that for any strict partial order <, the relation ⊳DEli from Equation 3.6 is acyclic, and hence irreflexive and asymmetric, but not necessarily transitive. If < is a modular order [13, Lemma 3.7], then ⊳DEli is transitive. Further, if < total (recalling that total orders are modular), then ⊳DEli is trichotomous, and hence a strict total order.\nis false, so ⊳DEli is irreflexive. To show transitivity, let n1, · · · , n7 ∈ N, such that\n{a1, · · · , an1} ∪ {b1, · · · , bn2} ∪ {c1, · · · , cn3} ∪ {d1, · · · , dn4}\n∪ {e1, · · · , en5} ∪ {f1, · · · , fn6} ∪ {g1, · · · , gn7} ⊆ P. (3.10)\nAll of these elements a1, . . . , gn7 are distinct. If ni = 0 then the corresponding set is empty. Let Γ, Γ′, Γ′′ ⊆fin P , where\nΓ = {a1, · · · , an1} ∪ {d1, · · · , dn4} ∪ {f1, · · · , fn6} ∪ {g1, · · · , gn7} ,\nΓ′ = {b1, · · · , bn2} ∪ {d1, · · · , dn4} ∪ {e1, · · · , en5} ∪ {g1, · · · , gn7} and\nΓ′′ = {c1, · · · , cn3} ∪ {e1, · · · , en5} ∪ {f1, · · · , fn6} ∪ {g1, · · · , gn7} .\nWe can picture these sets with the Venn diagram in Figure 3.1. The solid outer rectangle represents the set P . The three finite sets Γ, Γ′, Γ′′ are the three rectangles within. Each overlapping region has exactly the elements indicated and nothing more. This configuration exhausts all possibilities for Γ, Γ′ and Γ′′.\nNow suppose < permits Γ⊳DEliΓ ′⊳DEliΓ ′′, we write this out in terms of elements (Equations 3.11 and 3.12). Γ ⊳DEli Γ ′ is equivalent to\n(∃x ∈ Γ− Γ′) (∀y ∈ Γ′ − Γ) x < y\n⇔ (∃x ∈ {a1, · · · , an1} ∪ {f1, · · · , fn6}) (∀y ∈ {b1, · · · , bn2} ∪ {e1, · · · , en5}) x < y\n⇔ (∃x ∈ {a1, · · · , an1} ∪ {f1, · · · , fn6})\n\n\n(\nn2 ∧\ni=1\nx < bi\n)\n∧\n\n\nn5 ∧\nj=1\nx < ej\n\n\n\n\n⇔\nn1 ∨\nk=1\n\n\n(\nn2 ∧\ni=1\nak < bi\n)\n∧\n\n\nn5 ∧\nj=1\nak < ej\n\n\n\n ∨\nn6 ∨\nl=1\n\n\n(\nn2 ∧\ni=1\nfl < bi\n)\n∧\n\n\nn5 ∧\nj=1\nfl < ej\n\n\n\n .\n(3.11)\nNote that there are (n1 + n6) disjuncts in Equation 3.11. Applying the same reasoning as in Equation 3.11, we can see that Γ′ ⊳DEli Γ ′′ is equivalent to\nn2 ∨\nk=1\n\n\n(\nn3 ∧\ni=1\nbk < ci\n)\n∧\n\n\nn6 ∧\nj=1\nbk < fj\n\n\n\n ∨\nn4 ∨\nl=1\n\n\n(\nn3 ∧\ni=1\ndl < ci\n)\n∧\n\n\nn6 ∧\nj=1\ndl < fj\n\n\n\n .\n(3.12)\nThere are (n2+n4) disjuncts in Equation 3.11. We need to show that Γ⊳DEliΓ ′′. By the same reasoning as Equations 3.11 and 3.12, this is equivalent to\nn1 ∨\nk=1\n\n\n(\nn3 ∧\ni=1\nak < ci\n)\n∧\n\n\nn5 ∧\nj=1\nak < ej\n\n\n\n ∨\nn4 ∨\nl=1\n\n\n(\nn3 ∧\ni=1\ndl < ci\n)\n∧\n\n\nn5 ∧\nj=1\ndl < ej\n\n\n\n .\n(3.13)\nSo, to prove Equation 3.13, we need to show one of the disjuncts of Equation 3.13 i.e. for at least one of 1 ≤ k ≤ n1 or 1 ≤ l ≤ n4, we show either\n\n\n(\nn3 ∧\ni=1\nak < ci\n)\n∧\n\n\nn5 ∧\nj=1\nak < ej\n\n\n\n or\n\n\n(\nn3 ∧\ni=1\ndl < ci\n)\n∧\n\n\nn5 ∧\nj=1\ndl < ej\n\n\n\n\n(3.14)\nby establishing all of the conjuncts. Given Γ ⊳DEli Γ ′ ⊳DEli Γ ′′, we take the conjunction of Equations 3.11 and 3.12, making (n1 + n6)(n2 + n4) disjuncts, which is equivalent to the following expression: \n\n\nn1 ∨\nk=1\n\n\n(\nn2 ∧\ni=1\nak < bi\n)\n∧\n\n\nn5 ∧\nj=1\nak < ej\n\n\n\n ∨\nn6 ∨\nl=1\n\n\n(\nn2 ∧\ni=1\nfl < bi\n)\n∧\n\n\nn5 ∧\nj=1\nfl < ej\n\n\n\n\n\n\n\n∧\n\n\n\nn2 ∨\nk=1\n\n\n(\nn3 ∧\ni=1\nbk < ci\n)\n∧\n\n\nn6 ∧\nj=1\nbk < fj\n\n\n\n ∨\nn4 ∨\nl=1\n\n\n(\nn3 ∧\ni=1\ndl < ci\n)\n∧\n\n\nn6 ∧\nj=1\ndl < fj\n\n\n\n\n\n\n\n.\nAs ∧ and ∨ bi-distribute, we have four cases:\n1. For some 1 ≤ k ≤ n1 and 1 ≤ k ′ ≤ n2, we have\n(\nn2 ∧\ni=1\nak < bi\n)\n∧\n\n\nn5 ∧\nj=1\nak < ej\n\n ∧\n(\nn3 ∧\ni′=1\nbk′ < ci′\n)\n∧\n\n\nn6 ∧\nj′=1\nbk′ < fj′\n\n .\n(3.15)\nThis means for some 1 ≤ k ≤ n1, we have \n\nn5 ∧\nj=1\nak < ej\n\n , and from (3.16)\n(\nn2 ∧\ni=1\nak < bi\n)\n∧\n(\nn3 ∧\ni′=1\nbk′ < ci′\n)\n,\nthat 1 ≤ k′ ≤ n2, and transitivity of <, we infer (\nn3 ∧\ni=1\nak < ci\n)\n. (3.17)\nEquations 3.16 and 3.17 imply Γ ⊳DEli Γ ′′.\n2. For some 1 ≤ k ≤ n1 and 1 ≤ l ≤ n4, we have\n(\nn2 ∧\ni=1\nak < bi\n)\n∧\n\n\nn5 ∧\nj=1\nak < ej\n\n ∧\n(\nn3 ∧\ni′=1\ndl < ci′\n)\n∧\n\n\nn6 ∧\nj′=1\ndl < fj′\n\n\n(3.18)\nThis case uses the assumption that < is total.16 The second and the third bracketed conjuncts in Equation 3.18 are necessary but not sufficient to lead to Γ ⊳DEli Γ\n′′. Let k0 be the witness to 1 ≤ k ≤ n1 and l0 be the witness to 1 ≤ l0 ≤ n4. As < is total, either ak0 < dl0 or dl0 < ak0 (remember all elements are distinct).\n• If ak0 < dl0 then ak0 < ci for all 1 ≤ i ≤ n3. Therefore, ( ∧n3 i=1 ak0 < ci). • If dl0 < ak0 then dl0 < ej for all 1 ≤ j ≤ n5. Therefore, ( ∧n5 j=1 dl0 < ej ) .\nIn either case, Γ ⊳DEli Γ ′′.\n3. For some 1 ≤ l ≤ n6 and 1 ≤ k ≤ n2, we have\n(\nn2 ∧\ni=1\nfl < bi\n)\n∧\n\n\nn5 ∧\nj=1\nfl < ej\n\n ∧\n(\nn3 ∧\ni′=1\nbk < ci′\n)\n∧\n\n\nn6 ∧\nj′=1\nbk < fj′\n\n\n(3.19)\n16It can be shown that if < is not total, ⊳DEli is not transitive, see [23, Lemma A.2].\nThe irreflexivity of < and the first and last bracketed conjuncts gives a contradiction when you run over all indices, so this case gives a contradiction.\n4. For some 1 ≤ l ≤ n6 and 1 ≤ l ′ ≤ n4, we have\n(\nn2 ∧\ni=1\nfl < bi\n)\n∧\n\n\nn5 ∧\nj=1\nfl < ej\n\n ∧\n(\nn3 ∧\ni′=1\ndl′ < ci′\n)\n∧\n\n\nn6 ∧\nj′=1\ndl′ < fj′\n\n\n(3.20)\nThis case is similar to the first case – we use transitivity to combine the second and last bracketed conjuncts. This infers the second conjunct of Equation 3.14, which means Γ ⊳DEli Γ ′′.\nTherefore, in all cases, Γ ⊳DEli Γ ′′. This shows ⊳DEli is transitive on Pfin (P ).\nTo show trichotomy, let Γ, Γ′ ∈ Pfin(P ) be arbitrary. We start by assuming Γ 6= Γ′ and show exactly one of Γ ⊳DEli Γ\n′ or Γ′ ⊳DEli Γ is true. From Equation 3.6, we consider the symmetric difference Γ⊖Γ′. The set 〈Γ⊖ Γ′, <〉 ⊆ 〈P, <〉 is also a finite strict toset. This means there must exist a <-least element x0 ∈ Γ⊖ Γ ′, say. There are two mutually exclusive possibilities. If x0 ∈ Γ− Γ ′, then Γ ⊳DEli Γ ′. If x0 ∈ Γ ′ − Γ, then Γ′ ⊳DEli Γ ′. This establishes trichotomy. Therefore, 〈Pfin (P ) , ⊳DEli〉 is a strict chain.\nTherefore, given the strict toset 〈Rd, <D〉, 〈Pfin (Rd) , ⊳SP 〉 is also a strict toset.\nLemma 3.5. The argument preference -SP is a total preorder on A.\nProof. We instantiate 〈P,<〉 in Lemma 3.4 to 〈Rd, <SP 〉. This is valid because by Equation 3.5 and the discussion aftewards, <SP is a strict total order on Rd. Further, Equation 3.7 is Equation 3.6 with <SP instead of <D. Therefore, 〈Pfin (Rd) , ⊳SP 〉 is a strict toset by Lemma 3.4. By Equation 3.8, ≺SP is a strict total order on A, and -SP (Equation 3.9) is a total preorder on A.\nBy Lemma 3.5, if two arguments A and B satisfy A 6≺SP B, then B -SP A. We demonstrate the features of <SP and ≺SP with Examples 1 and 2.\nExample 1. Suppose that instead of respecting the logical structure of the defeasible rules with <SP , we use an argument preference relation ≺ based on ⊳DEli (Equation 3.6) instead of ⊳SP , i.e. replace ⊳SP in Equation 3.9 with ⊳DEli. Now consider the following LPDT. Let T+ haveW = ∅ and D = {dk} 5 k=1 where\nd1 := : c1 c1 , d4 := c3 : c4 c4 , d3 := : c3 c3 , d2 := c1 : c2 c2 , d5 := c1 : ¬(c2 ∧ c4) ¬(c2 ∧ c4) ,\nsuch that d1 < + d4 < + d3 < + d2 < + d5. Our PDE is constructed in the usual manner starting from E0 = Th(∅) by Equation 2.4. Equation 2.5 gives the order of application of the defaults:\nE1 = E0 + c3, E2 = E1 + c4, E3 = E2 + c1, E4 = E3 + ¬(c2 ∧ c4), (3.21)\nwith Ek = E4 for all k ≥ 5. As ¬(c2 ∧ c4) ≡ (¬c2 ∨ ¬c4), along with c4 (from d4), we have ¬c2, which blocks d2. The unique PDE from this LPDT is E := Th({c1,¬c2, c3, c4}). Now consider the corresponding arguments following our instantiation. We have the defeasible rules17 r1 <D r4 <D r3 <D r2 <D r5. The relevant arguments and sets of defeasible rules are\nA := [[⇒ c1] ⇒ c2], DR(A) = {r1, r2}\nB := [[⇒ c3] ⇒ c4], DR(B) = {r3, r4}\nC := [[⇒ c1] ⇒ ¬(c2 ∧ c4)], DR(C) = {r1, r5} ,\nD := [B,C → ¬c2], DR(D) = {r1, r3, r4, r5} .\nWe illustrate these arguments in Figure 3.2. Our convention for diagrams is that broken arrows represent defeasible rules, and solid arrows represent strict rules. Solid vertical lines spanning the length of arguments label those arguments. In the diagrams of this paper, defeasible rules with empty antecedent have the symbol ⊤ as a placeholder for their antecedent.\nFor the stable extension to correspond to the PDL extension, the desired stable extension contains the argumentsD, B, C, [⇒ c3], [⇒ c1], the conclusions of which are, respectively, ¬c2, c4, ¬ (c2 ∧ c4) , c3, c1, which under deductive closure, corresponds to E. However, this would require D →֒ A, which means, by Equation 2.3, D ⇀ A and D 6≺ A. Clearly, D ⇀ A on A. However, it is not the case that r2 is the <D-least defeasible rule, so D ≺ A. Therefore, this argument preference relation does not generate the corresponding stable extension to E.\nSuppose now that we do respect the logical structure of the rules and use ≺SP as our argument preference (Equation 3.8). By applying Equations 3.4 and 3.5, we can show that a1 = r3, a2 = r4, a3 = r1, a4 = r5 and a5 = r2. The structure preference order is r2 <SP r5 <SP r1 <SP r4 <SP r3. Notice that\n17We define, for 1 ≤ i ≤ 5, ri := f (di), by Equation 3.1.\nthis is precisely the order in which the corresponding normal defaults are added in PDL, as Equation 3.21 shows. It is easy to show that the corresponding stable extension under the argument preference ≺SP corresponds to the PDL inference, because r2 is now <SP -least, so D 6≺SP A. Therefore A ≺SP D, so A →֒ D.\nExample 2. However, <SP does not necessarily follow the PDL order of the application of defaults. Consider 〈{d1, d2} , {a} , < +〉 with d1 := a:¬a ¬a\nand d2 := :b b such that d2 < + d1. We have E = Th ({a, b}), where d1 is blocked by W , so d2 is the only default added. In argumentation, we have Kn = {a}, r1 := (a ⇒ ¬a) and r2 := (⇒ b), such that r2 <D r1. The arguments are A0 := [a], A1 := [A0 ⇒ ¬a] and B := [⇒ b]. Applying Equation 3.4, we have r2 <SP r1, which clearly is not the order of how the corresponding defaults are added in PDL. Yet the correspondence still holds, since A0 →֒ A1 because A0 is strict and strict arguments always defeat any non-strict argument they attack, so the stable extension is the strict extension of {A0, B}, the conclusion set of which (after deductive closure) is the extension of the underlying LPDT.\nWe have now defined the structure-preference argument preference relation -SP . Given an LPDT T\n+, we denote its attack graph to be AG (T+) := 〈A,⇀,-SP 〉, and its defeat graph to be DG (T\n+) := 〈A, →֒〉, where →֒ is defined by Equation 2.3 with - equal to -SP ."
    }, {
      "heading" : "3.3 The Representation Theorem",
      "text" : "In this section we state and prove the representation theorem (Theorem 3.14), which guarantees that the inferences with argumentation semantics under the preference -SP correspond exactly to the inferences in PDL."
    }, {
      "heading" : "3.3.1 Non-Blocked Defaults",
      "text" : "We introduce some concepts to help prove the representation theorem. Let T be a PDT and E = ⋃\ni∈N Ei one of its extensions generated from the linearisation <+⊇<. The set of generating defaults (w.r.t. <+), GD(<+), is defined as\nGDi(< +) :=\n{ d ∈ D d is <+-greatest active in Ei } ,\nGD(<+) := ⋃\ni∈N\nGDi(< +) ⊆ D. (3.22)\nIntuitively, this is the set of defaults applied to calculate E following the priority <+. However, the same E can be generated by distinct total orders.\nExample 3. Consider the PDT 〈{ a:c c , b:c c } , {a, b} , ∅ 〉 . We have two possible linearisations a:c c <+1 b:c c and b:c c <+2 a:c c . By Footnote 8 (page 8) we have GD(<+1 ) = { b:c c } and GD(<+2 ) = { a:c c }\n, which are not equal, even though both linearisations give the same extension E = Th ({a, b, c}). In both cases, the default in D−GD (\n<+i )\n(for i = 1, 2) is not active not because it is blocked by ¬c, but rather because it adds no new information.\nWe wish to distinguish between inactive defaults that conflict with something known and inactive defaults that do not add any new information. We call a default θ:φ\nφ semi-active (in S ⊆ SL) iff [θ ∈ S, ¬φ /∈ S, φ ∈ S]. Let <+ ⊇ < be\ntotal and which generates the extension E (Equation 2.5). The set SAD (<+) of semi-active defaults with respect to the linearisation <+ is defined as\n{ d ∈ D d is semi-active w.r.t. E, which is generated by <+ } . (3.23)\nSemi-active defaults add no new information. The set of non-blocked defaults is\nNBD(<+) := GD(<+) ∪ SAD(<+) ⊆ D. (3.24)\nLemma 3.6. If <+ generates the PDE E, then\nNBD(<+) :=\n{\nθ : φ\nφ ∈ D θ ∈ E, ¬φ /∈ E\n}\n. (3.25)\nProof. It is sufficient to show Equation 3.24 (with Equations 3.22 and 3.23) is the same as the right hand side of Equation 3.25. Let <+ generate the extension E and, for notational convenience, we suppress the argument “<+” in the sets for this proof.18 (⇒) Case 1: Assume d ∈ SAD, then Ante(d) ⊆ E, ¬Conc(d) /∈ E and Conc(d) ∈ E.\nd ∈{d′ ∈ D Ante(d′) ⊆ E, ¬Conc(d′) /∈ E} and hence (3.26)\nSAD ⊆{d ∈ D Ante(d) ⊆ E, ¬Conc(d) /∈ E} . (3.27)\nCase 2: Now assume d ∈ GD, which is equivalent to (∃i ∈ N) d ∈ GDi. This is equivalent to (∃i ∈ N) [Ante(d) ⊆ Ei, Conc(d) /∈ Ei, ¬Conc(d) /∈ Ei], which is equivalent to\nAnte(d) ⊆ Ej0 , Conc(d) /∈ Ej0 , ¬Conc(d) /∈ Ej0 j0 witness to i. (3.28)\nThis implies Ante(d) ⊆ Ej0 , ¬Conc(d) /∈ Ej0 , and it follows that Ante(d) ⊆ E, ¬Conc(d) /∈ Ej0 . Clearly, this means Ante(d) ⊆ E. Now assume for contradiction that ¬Conc(d) ∈ E, which means there is some i0 ∈ N such that ¬Conc(d) ∈ Ei0 . What is the relationship between i0 and j0? There are three possibilities:\n• i0 = j0 would mean ¬Conc(d) /∈ Ei0 and ¬Conc(d) ∈ Ei0 – contradiction.\n• i0 < j0: We have ¬Conc(d) /∈ Ej0 and ¬Conc(d) ∈ Ei0 , which is also impossible because the Ei’s form an ascending chain, so Ei0 ⊆ Ej0 . Therefore, we get ¬Conc(d) ∈ Ej0 and ¬Conc(d) /∈ Ej0 .\n• i0 > j0: We have ¬Conc(d) /∈ Ej0 and ¬Conc(d) ∈ Ei0 . From Equation 3.28, we have that d is active in Ej0 , hence Conc(d) ∈ Ej0+1 ⊆ Ei0 , which makes ¬Conc(d) ∈ Ei0 impossible because the Ei’s are consistent.\n18For example, instead of writing “GD ( <+ ) ” we write “GD”.\nTherefore, ¬Conc(d) /∈ E. So we have Ante(d) ⊆ E and ¬Conc(d) /∈ E. Therefore, Equation 3.26 is true for this case and we have\nGD ⊆ {d ∈ D Ante(d) ⊆ E, ¬Conc(d) /∈ E} . (3.29)\nWe can take the union of Equations 3.27 and 3.29 to get\nGD ∪ SAD ⊆ {d ∈ D Ante(d) ⊆ E, ¬Conc(d) /∈ E} . (3.30)\n(⇐) Now assume d ∈ {d′ ∈ D Ante(d′) ⊆ E, ¬Conc(d′) /∈ E}, which means Ante(d) ⊆ E and ¬Conc(d) /∈ E. We have, for some i0 ∈ N,\n⇔Ante(d) ⊆ Ei0 , (∀j ∈ N)¬Conc(d) /∈ Ej\n⇔Ante(d) ⊆ Ei0 , ¬Conc(d) /∈ Ei0 , (∀j ∈ N− {i0})¬Conc(d) /∈ Ej\n⇔ (∀j ∈ N− {i0})¬Conc(d) /∈ Ej and\n[(Ante(d) ⊆ Ei0 , ¬Conc(d) /∈ Ei0 , Conc(d) ∈ Ei0) or\n(Ante(d) ⊆ Ei0 , ¬Conc(d) /∈ Ei0 , Conc(d) /∈ Ei0)]\n⇔ (∀j ∈ N− {i0})¬Conc(d) /∈ Ej and\n[(Ante(d) ⊆ Ei0 , ¬Conc(d) /∈ Ei0 , Conc(d) ∈ Ei0) or d ∈ GDi0\n⇒ (∀j ∈ N− {i0})¬Conc(d) /∈ Ej and\n[(Ante(d) ⊆ Ei0 , ¬Conc(d) /∈ Ei0 , Conc(d) ∈ Ei0) or d ∈ GD\n⇒d ∈ GD or [Ante(d) ⊆ Ei0 , ¬Conc(d) /∈ Ei0 , Conc(d) ∈ Ei0 and\n(∀j ∈ N− {i0})¬Conc(d) /∈ Ej ]\n⇒d ∈ GD or [Ante(d) ⊆ E and (∀j ∈ N)¬Conc(d) /∈ Ej ]\n⇒d ∈ GD or [Ante(d) ⊆ E and ¬Conc(d) /∈ E] ⇔ d ∈ GD ∪ SAD.\nTherefore, we have\n{d ∈ D Ante(d) ⊆ E, ¬Conc(d) /∈ E} ⊆ GD ∪ SAD. (3.31)\nThe result follows from Equations 3.30 and 3.31.\nGiven E, NBD(<+) is uniquely determined by Equation 3.25, so we will write NBD(E) instead. Equation 3.25 adapts Reiter’s idea of a generating default [19, page 92, Definition 2] to PDL.\nWe use these concepts to show that the rearrangement of rules <D 7→<SP , as defined in Equation 3.5, does not change the extension of the LPDT. This is because the manner through which <SP incorporates the argument structure captures the idea of Equation 2.5, which is the method of how PDL incorporates both structure and preference when choosing the “<+-most active” default.\nLemma 3.7. Let T := 〈D,W,<+〉 and T ′ := 〈 D,W,<+ ′ 〉 be two LPDTs such\nthat <+ ∼=<D 7→<SP∼=< +′ ,19 then both T and T ′ have the same extension E.\nProof. Let E be the unique extension of T , and E′ be the unique extension of T ′. To show E = E′, we need to show that they have the same generating defaults, i.e. GD (<+) = GD ( <+ ′ ) . As <+ ′ ∼=<SP , and < +∼=<D 7→<SP , the\nrearrangement <D 7→<SP will always choose the <D-greatest active defeasible rule for a1 in Equation 3.4, the second <D-greatest active defeasible rule for a2... etc. until all defeasible rules are rearranged, but the defeasible rules corresponding to the generating defaults of <+ ′ will always be chosen first in the rearrangement, therefore GD (<+) = GD ( <+ ′ ) and hence the result follows."
    }, {
      "heading" : "3.3.2 Existence and Uniqueness of Stable Extensions",
      "text" : "Let T+ be an LPDT. In this section we show that its defeat graph DG (T+) has a unique stable extension. We propose an algorithm that imitates how PDL extensions are constructed over an LPDT (Equation 2.5). Given S ⊆ A, r ∈ Rd, the definition of Args ( · ) (Equation 2.2) and <SP we define ⊕ as S ⊕ r := Args(DR(S) ∪ {r}), i.e. we close S under all arguments over all strict rules, all defeasible rules in S, and the addition of a new defeasible rule r.\nConsider Algorithm 1, which takes as input the attack graph AG (T+) of an LPDT T+, and the strict chain of defeasible rules under the SP order 〈Rd, <SP 〉. The output is a set of arguments S ⊆ A. The formal definition is:20\nAlgorithm 1 Generating a Stable Extension\n1: function GenerateStableExtension(〈A, ⇀, -SP 〉, 〈Rd, <SP 〉) 2: S ← {all strict arguments in A} 3: for r ∈ Rd from <SP -greatest to <SP -smallest do 4: if S ⊕ r has no attacks, (S ⊕ r) 2 ∩ ⇀= ∅, then 5: S ← S ⊕ r return S\nAlgorithm 1 first creates the largest possible set of undefeated arguments that do not attack each other. This includes all strict arguments as they are never defeated nor do they attack each other, and possibly some undefeated defeasible arguments. Then, the algorithm includes the defeasible rules from most to least preferred under <SP and tests whether the resulting arguments that are constructed by the inclusion of such a defeasible rule attack each other in the sense of Equation 3.3 (Lines 4–5). Note that the resulting attack must originate\n19This means that the chain 〈 D,<+ 〉\nis order isomorphic to 〈Rd, <D〉 as described by Equations 3.1 and 3.2. Then we calculate <SP from <D as described in Section 3.2 and form a new chain 〈 D,<+ ′ 〉\n, which is order isomorphic to 〈Rd, <SP 〉. 20This is a brute-force definition used to prove that stable extensions exist and are unique\nin such defeat graphs.\nfrom the arguments having at most the defeasible rules added so far. As <SP is total, all defeasible rules are considered, and the result includes as many defeasible rules as possible such that the result has no attacks. Adding the rules in the order of <SP while ensuring no attacks mimics the condition of Equation 2.5. It is clear from the algorithm that S exists and is unique given the input, as it is of the form Args(R) for some R ⊆ Rd (Equation 2.2). We show S is a stable extension.\nLemma 3.8. The output S of Algorithm 1 is cf (conflict free).\nProof. cf is guaranteed by the consistency of Kn and that defeasible rules r ∈ Rd are only added if the resulting arguments do not attack each other (Lines 4 - 5). Therefore, by Equation 2.3, S contains no defeats and must be cf.\nNote that the setup of the algorithm prevents not just defeats but attacks from appearing in S (Line 4). Normally, this is not sufficient to guarantee that Conc (S) is consistent in FOL.\nExample 4. Consider S = {[⇒ a] , [⇒ b] , [⇒ ¬(a ∧ b)]} ⊆ A. There are no attacks in S because attacks are defined syntactically (Equation 3.3, page 10). However, Conc (S) = {a, b,¬ (a ∧ b)} is clearly inconsistent in FOL.\nWe now show that if S has no attacks then Conc (S) is consistent in FOL.\nLemma 3.9. Let S be the output of Algorithm 1. If S2∩ ⇀= ∅ then Conc (S) is consistent.\nProof. By construction and Lemma 2.1, Conc (S) is deductively closed. Assume for contradiction that Conc (S) is inconsistent, then θ, ¬θ ∈ Conc (S) for some θ ∈ SL. Hence there are A,B ∈ S such that Conc(A) = θ and Conc(B) = ¬θ. If at least one of TopRule(A) or TopRule(B) are defeasible then at least one of A ⇀ B and B ⇀ A is the case, hence S2∩ ⇀6= ∅ – contradiction.\nNow consider the case where TopRule(A), T opRule(B) ∈ Rs are both strict. As W = Kn is consistent and the rules in Rs are sound, if A and B are both strict then it cannot be the case they have contradictory conclusions. Therefore, at least one of A and B are defeasible. WLOG say A is defeasible. Suppose by construction A = [A1, A2, . . . , Ai, . . . , An → θ] and B = [B1, B2, . . . , Bm → ¬θ], where Ai ⊆arg A is defeasible with conclusion ai (Section 2.2). By closure under transposition of Rs and the properties of S, we can construct the argument B(i) := [A1, A2, . . . , Ai−1, B,Ai+1, . . . , An → ¬ai], and by Lemma 2.1, B\n(i) ∈ S. If TopRule (Ai) is defeasible, then B (i) ⇀ Ai and hence S 2∩ ⇀6= ∅ – contradiction, so TopRule (Ai) is not defeasible. As Ai is defeasible we choose some subargument A′i ⊆arg Ai and repeat the above line of reasoning for B (i) and A′i. As all arguments are well-founded, this line of reasoning must terminate at some subargument of Ai whose top rule is defeasible, and hence S\n2∩ ⇀6= ∅ – contradiction. The result follows.\nLemma 3.10. The set S defeats all arguments outside of itself.\nProof. Let R := DR(S). Let B /∈ S be an arbitrary argument outside of S. We show there is an A ∈ S such that A →֒ B. Given that B /∈ S, there must be some rule r ∈ DR(B)−R that causes S to attack the subargument of B with top rule r, according to Algorithm 1, Line 4. Let B′ ⊆arg B such that TopRule(B ′) = r. Let A ∈ S be the attacker of B′ at r, such that Conc(A) = Cons(r).21 This means A ⇀ B′ and hence A ⇀ B. There are two possibilities: either this rule r ∈ DR(B) is <SP -greatest, or it is not.\nIf r is <SP -greatest, then Args(∅) ⊕ r contains attacking arguments, so A must be strict and hence A →֒ B. If r is not <SP -greatest, then consider the strict <SP -upper-set of r in 〈Rd, <SP 〉, T := {r ′ ∈ Rd r <SP r ′} 6= ∅. There are two sub-possibilities: either T ∩ R = ∅ or T ∩ R 6= ∅. If T ∩ R = ∅, then adding r to S will create an attack by Algorithm 1, Line 4, and this attack must originate from some A ∈ Args(∅) because no rule <SP -larger than r is used in the arguments of S, hence A →֒ B.\nIf T ∩ R 6= ∅, then adding r to S means its attacker A ⇀ B′ is in Args (T ∩R).22 Either A is strict or not strict (i.e. defeasible). If it is strict, then A →֒ B as before. If it is not strict, i.e. ∅ 6= DR(A) ⊆ T ∩ R, then by definition (∀s ∈ T ) r <SP s. As DR(A) ⊆ T ∩ R, we must also have (∀s ∈ DR(A)) r <SP s. Therefore, there is an r ∈ DR(B\n′) −DR(A) such that for all rules in DR(A), and hence DR(A)−DR(B′), r <SP s. By Equation 3.8, we conclude that B′ ≺SP A, and hence A →֒ B\n′. Therefore, by definition of →֒ and ⊆arg, A →֒ B.\nTheorem 3.11. The output of Algorithm 1, S, is a stable extension of DG (T+).\nProof. Immediate from Lemmata 3.8 and 3.10.\nWe also have a useful property relating the presence of an argument in a stable extension with its rules, which is independent of Algorithm 1.\nLemma 3.12. For a LPDT T+ and defeat graph DG (T+), if E is a stable extension of DG (T+), then A ∈ E ⇔ DR(A) ⊆ DR (E).\nProof. (⇒) If A ∈ E then DR(A) ⊆ ⋃\nA∈E DR(A) = DR(E) trivially. (⇐, contrapositive) If A /∈ E , then E →֒ A at some A′ ⊆arg A. Let r := TopRule (A\n′). Assume for contradiction that r ∈ DR(E), then (∃B ∈ E) r ∈ DR(B), so E →֒ B – contradiction, as E is cf. Therefore, r /∈ DR (E). But as r ∈ DR(A), DR(A) 6⊆ DR (E).\n21Note that A is appropriately chosen such that Conc(A) = Cons(r) is syntactic equality. This is always possible because Rs has all rules of proof of FOL. Therefore, if an argument C concludes θ, and we would want it to conclude φ, where φ ≡ θ, we can just append the strict rule (θ → φ) ∈ Rs to C to create a new argument D that concludes φ.\n22We have A ∈ Args (T ∩ R) because as Algorithm 1 adds the rules one by one according to <SP , if adding r to the rules in S and then creating all arguments (with all strict rules) creates an attack, then this attack must be due to some argument whose defeasible rules are amongst T ∩ R. This is because at the point where the algorithm excludes r, any defeasible arguments constructed then can only have their rules from T .\nWe have shown that given T+ and AG (T+), Algorithm 1 gives a unique output that is a stable extension (Theorem 3.11). We now show that this is the only stable extension that DG (T+) can have.\nTheorem 3.13. Let E be the stable extension that is the output of Algorithm 1. This is the unique stable extension of DG (T+).\nProof. Given DG (T+) = 〈A, →֒〉, let E be the output of Algorithm 1, and assume for contradiction that E ′ 6= E is some other stable extension of DG (T+). Let A′1 ∈ E ′ − E . There is an argument A2 ∈ E − E ′ such that A2 →֒ A ′ 1. There is an argument A′3 ∈ E ′ − E such that A′3 →֒ A2... and so on. We therefore construct a defeat chain of defeasible arguments\n· · · →֒ A′5 →֒ A4 →֒ A ′ 3 →֒ A2 →֒ A ′ 1, (3.32)\nwhere all primed arguments belong to E ′ and all unprimed arguments are in E . In general, suppose A →֒ B, then by Equation 2.3, A →֒ C ⊆arg B for some C, and A 6≺SP C. By Corollary 3.2, B -SP C. Assume for contradiction that A ≺SP B, then by Lemma 3.5, A ≺SP C – contradiction, so A 6≺SP B.\nEquation 3.32 thus becomes · · · 6≺SP A ′ 5 6≺SP A4 6≺SP A ′ 3 6≺SP A2 6≺SP A ′ 1.\nBy Lemma 3.5, this is equivalent to A′1 -SP A2 -SP A ′ 3 -SP A4 -SP A ′ 5 -SP · · · . By Equation 3.9 and Lemma 3.12, none of the adjacent arguments in this chain can have the same defeasible rules. This implies A′1 ≺SP A2 ≺SP A′3 ≺SP A4 ≺SP A ′ 5 ≺SP · · · . The corresponding chain for defeasible rules is, by Equation 3.8, DR (A′1) ⊳SP DR (A2) ⊳SP DR (A ′ 3) ⊳SP DR (A4) ⊳SP · · · . As Rd is a finite set, there are only finitely many possible sets of defeasible rules. This strictly ascending chain must therefore be finite, say of length n. Equation 3.32 must therefore be of finite length, terminating at an undefeated argument B, which may or may not be strict.\nB →֒ A′n−1 →֒ · · · →֒ A2 →֒ A ′ 1 or B →֒ An−1 →֒ · · · →֒ A2 →֒ A ′ 1,\nfor some n ∈ N+. In the first case, B ∈ E−E ′ is an undefeated argument, so E ′ is not a stable extension – contradiction. In the second case, by similar reasoning, E is not a stable extension – contradiction. There cannot be another stable extension E ′ of DG (T+), so E is the unique stable extension of DG (T+).\nThe defeat graphs DG (T+) of LPDTs T+ thus have a unique stable extension."
    }, {
      "heading" : "3.3.3 The Representation Theorem: Statement and Proof",
      "text" : "In this section we state and prove the representation theorem which relates the stable extension of DG (T+) := 〈A, →֒〉 with the extension of the corresponding LPDT T+ := 〈D, W, <+〉.\nTheorem 3.14. (The Representation Theorem) Let AG (T+) be the attack graph corresponding to an LPDT T+ with defeat graph DG (T+) under -SP .\n1. Let E be the extension of T+, which is unique (Section 2.3). Then there exists a unique stable extension E ⊆ A of DG (T+) such that Conc (E) = E.\n2. Let E ⊆ A be the unique stable extension of DG (T+) by Theorem 3.13, then Conc(E) is the extension of T+.\nProof. Proof of part 1: To prove the first statement we construct E in terms of E and show E is a stable extension of 〈A, →֒〉. By Theorem 3.13, this stable extension is unique. We finally show Conc(E) = E.\nGiven E, we let E := Args (f (NBD(E))) ⊆ A, where NBD(E) is defined in Equation 3.25 and Args ( · ) is defined by Equation 2.2. This set is unique from the properties of Args. For notational convenience we let R := f (NBD(E)). We show E is a stable extension.\nAssume for contradiction that E is not cf, which means there are arguments A,B ∈ E such that A →֒ B, which means A ⇀ B by Equation 2.3. Let a := Conc(A). As A ∈ E , Equation 2.2 and the definition of E means that DR(A) ⊆ R. This means from W and the defaults of f−1 (DR(A)) ⊆ D (f is defined by Equation 3.1), which are non-blocked defaults in E, it follows that a ∈ E. As E is deductively closed, this means ¬¬a ∈ E. Now let B′ ⊆arg B be the argument such that TopRule(B′) = (b ⇒ ¬a) for some appropriate intermediate conclusion b ∈ Conc (Sub(B)). As B ∈ E , this means (b ⇒ ¬a) ∈ R. By Equation 3.25, this means ¬¬a /∈ E – contradiction. Therefore, E is cf.\nTo show Args(R) defeats all other arguments, let B /∈ Args(R) be arbitrary. Let r ∈ DR(B)−R be some rule. Let B′ ⊆arg B be such that TopRule(B ′) = r. The rule r corresponds to a default f−1(r) = θ:φ φ /∈ NBD(E) (Equation 3.1). By Equation 3.25, we have two cases: either θ /∈ E or ¬φ ∈ E. Case 1: If ¬φ ∈ E, then we now show there exists an argument A ∈ Args(R) such that A →֒ B′ and hence A →֒ B, under -SP . By Equations 2.4 and 2.5, there is some i ∈ N such that ¬φ ∈ Ei. Suppose i = 0 then W |= ¬φ. Compactness means there is some W ′ ⊆fin W such that W\n′ |= ¬φ. We can construct an argument A such that Prem(A) = W ′ and Conc(A) = ¬φ as there will be appropriate combinations of strict rules in Rs and premises in Kn, so A ⇀ B. As DR(A) = ∅ ⊆ R, we must have A ∈ Args(R). As A is strict, A →֒ B is guaranteed by Corollary 3.3 of -SP .\nNow suppose that i > 0, then ¬φ ∈ Ej where j > 0 is the witness for i. Let dj ∈ D be the default that is <\n+-greatest active in the layer Ej , so the set of defaults that are used in concluding ¬φ (up to the application of deductive rules) is S := {d0, . . . , dj−1} ⊆ GDj−1 (<\n+) ⊆ NBD(E). We can construct an argument A such that Prem(A) ⊆ W , Conc(A) = ¬φ and DR(A) = f(S). Clearly, DR(A) = f(S) ⊆ f (NBD(E)) =: R and hence A ∈ Args (R). It is clear that A ⇀ B, so we need to show A 6≺SP B.\nGiven that ¬φ ∈ Ej , it must be the case that φ /∈ Ej . Therefore, f −1 (r) is not <+-greatest active for all extension layers E0, . . . , Ej−1. Suppose for contradiction that there is some rule s ∈ DR(A) such that s <SP r. Then by Equation 3.4, r must be <+-greatest active at some Ek for k < j − 1, which\nwould then result in φ in Ek+1, therefore preventing ¬φ ∈ Ej – contradiction. 23 Therefore, r is <SP -smaller than all rules in DR(A). By Equation 3.8, we must have B ≺SP A, and hence A 6≺SP B, so A →֒ B. Therefore, for the case of ¬φ ∈ E, Args(R) defeats all arguments outside it. Therefore, in all cases, if ¬φ ∈ E, there is some argument A ∈ E that defeats B.\nCase 2: We will assume θ /∈ E, and show that it leads to a contradiction with the method of infinite descent.\nIf θ /∈ E, then there is some proper subargument B′′ ⊂arg B ′ such that Conc(B′′) = θ. Since θ /∈ E then it is the case that neither DR (B′′) = ∅ nor in Args (f (NBD (E))). This is because if DR (B′′) = ∅ then W ⊇ Prem(B′′) |= θ so θ ∈ E0 ⊆ E by Equation 2.4. Further, if B\n′′ ∈ Args (f (NBD (E))) then f−1 (DR(B)) ⊆ NBD(E), so by Equation 3.25, we have θ ∈ E.\nTherefore, as B′′ is neither strict nor in Args (f (NBD (E))) there is some other defeasible rule s ∈ DR (B′′) − f (NBD (E)). We can repeat the above reasoning with the rule s instead of r: suppose s = θ ′:φ′\nφ′ , then either θ′ /∈ E or\n¬φ′ ∈ E. In the latter case we can construct an argument A′ ∈ E concluding ¬φ′ which then defeats B′′ as in the case when we assumed ¬φ ∈ E. In the former case we repeat the reasoning in the previous paragraph, but we cannot do this indefinitely as arguments are well-founded. We will end up with either a proper subargument of B′′ or an argument in Args (R) concluding θ. In both cases θ ∈ E is true, so assuming θ /∈ E will lead to contradiction by the method of infinite descent.\nTherefore, the only reason for r /∈ R is because ¬φ ∈ E. We have shown there is an argument A that defeats any argument containing the rule r. As r belongs to some arbitraryB /∈ E , this means E := Args(R) defeats all arguments outside of it and hence it is a stable extension.\nTo show that E = Conc (E), we show E ⊆ Conc (E) and Conc (E) ⊆ E. In the first case, let θ ∈ E so there is some i ∈ N such that θ ∈ Ei by Equations 2.4 and 2.5.\nIf θ ∈ E0, we have W |= θ so by compactness there is some ∆ ⊆fin W where ∆ |= θ. Given that Rs has all rules of proof we can construct a strict argument A such that Premn(A) = ∆ and Conc(A) = θ. As strict arguments are undefeated, A ∈ E so θ ∈ Conc (E).\nIf θ ∈ Ek for some k ∈ N +, we can construct a defeasible argument A concluding θ such that DR(A) ⊆ R and hence A ∈ E , so θ ∈ Conc (E). Specifically, we construct an argument whose defeasible rules correspond to the defaults added to E up to Ek.\nConversely, if θ ∈ Conc(E) there is an argument in E concluding θ. If this argument is strict then θ ∈ E0 ⊆ E, else, as the defeasible rules are in R then θ ∈ Ek ⊆ E for some k ∈ N\n+ that indicates when all of the appropriate defaults needed to conclude θ are included.\nProof of part 2: We show Conc(E) ⊆ E and E ⊆ Conc(E). For the former, if θ ∈ Conc(E) then there is some A ∈ E concluding θ. If A is strict\n23For this s ∈ DR(A), the assumption that s <SP r means that the antecedent of f −1(r)\nis already in the appropriate extension layer.\nthen θ ∈ E0 ⊆ E. If A is defeasible, then say DR(A) = {ri} k i=1 for some k ∈ N +. These defeasible rules do not introduce any inconsistency to E by Lemma 3.9. Consider the set of corresponding defaults {di} k i=1 ⊆ D to DR(A). We can choose the smallest index j ∈ N such that all of the conclusions of these defaults are included in Ej ⊆ E. This is because either {di} k i=1 ⊆ GD(E), or there is some di ∈ SAD(E), but that would mean cons(di) ∈ E so for some l ∈ N, cons(di) ∈ El. Therefore, under deductive closure, θ ∈ Ej+1 ⊆ E, so θ ∈ E. This shows that Conc (E) ⊆ E.\nConversely, let θ ∈ E, so there is some i ∈ N such that θ ∈ Ei. If i = 0, then there is a strict argument A, necessarily in E as it is undefeated, that concludes θ so θ ∈ Conc (E). If i > 0, then from θ ∈ Ei we can consider the defaults added to Ei, and use the corresponding defeasible rules to construct an argument A such that Prem(A) ⊆ W , Conc(A) = θ and DR(A) to contain exactly those defeasible rules. By definition of <SP and Algorithm 1, these defeasible rules are all present in E , so DR(A) ⊆ DR (E). By Lemma 3.12, A ∈ E . Therefore, θ ∈ Conc (E). This shows that E ⊆ Conc (E).\nTheorem 3.14 means that PDL, where the default priority < is a total order, is sound and complete with respect to its argumentation semantics; the inferences of PDL can be formally seen as the conclusions of justified arguments.\nGiven the definition of ≺SP and the translation of a LPDT to its defeat graph as described in Section 3.1, we can visualise the representation theorem in the following diagram:\nT+ DG ( T+ )\nE E\noo //\ntranslation ❴\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\nPDE\n❴\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\nstable extension\noo // Conc(E)=E"
    }, {
      "heading" : "3.4 Satisfaction of Rationality Postulates",
      "text" : "In this section, we prove directly that our instantiation of ASPIC+ to PDL satisfies the Caminada-Amgoud rationality postulates and hence is normatively rational. We do this by investigating some properties of the stable extension of this defeat graph. Notice that we do not appeal to the sufficient conditions articulated by ASPIC+ that, if satisfied, will guarantee normative rationality. We will discuss why in Section 5."
    }, {
      "heading" : "3.4.1 The Stable Extension is Grounded",
      "text" : "Lemma 3.15. Let T+ be an LPDT with attack graph AG (T+) and defeat graph DG (T+). Let χ : P (A) → P (A) be the characteristic function. Let E ⊆ A be the stable extension of DG (T+). Then (∃n ∈ N+) E ⊆ χn (∅), where χn denotes the nth iterate of χ.\nBefore we prove Lemma 3.15, we first establish some notation that will be used in the proof. Recall interval notation: for any toset 〈T,<〉 and a, b ∈ T , define the subsets:\n(a, b) := {x ∈ T a < x < b} , [a, b] := {x ∈ T a ≤ x ≤ b} ,\n[a, b) := {x ∈ T a ≤ x < b} and (a, b] := {x ∈ T a < x ≤ b} .\nRecall that if b ≤ a then (a, b) = [a, b) = (a, b] = ∅, and if b < a then [a, b] = ∅. As D is finite let N := |Rd|. Given the LPDT T\n+ with defeat graph DG (T+) and stable extension E , define the set, for 0 ≤ k ≤ N ,\nRd −DR (E) =: {r1, . . . , rk} , (3.33)\nwhere k = 0 means DR (E) = Rd, and k = N means DR (E) = ∅. WLOG, we arrange the indices for these rules such that rl+1 <SP rl, for 1 ≤ l ≤ k−1. This is the set containing the rules that do not feature in E .\nGiven the strict toset 〈Rd, <SP 〉, denote rmax := max<SP Rd and similarly for rmin. Both rmax and rmin are uniquely defined as <SP is total. To isolate the defeasible rules that do not make up the arguments in E , we partition Rd from smallest to largest in <SP as follows:\n[rmin, rk), {rk} , (rk, rk−1) , {rk−1} , . . . , {r2} , (r2, r1) , {r1} , (r1, rmax]. (3.34)\nThis places the defeasible rules that do not feature in E into their own singleton sets along the chain <SP . These singleton sets contain precisely the defeasible rules skipped over by Algorithm 1 when constructing E . Note the first and last of these sets may be empty, e.g. when rk = rmin. We name these sets: for 1 ≤ i ≤ k, Pi := {ri}. Similarly, for 2 ≤ i ≤ k, Ii := (ri, ri−1) ⊆ Rd. We also define I1 := (r1, rmax] ⊆ Rd and Ik+1 := [rmin, rk) ⊆ Rd. Equation 3.34 can be written as:\nIk+1, Pk, Ik, Pk−1, . . . , P2, I2, P1, I1. (3.35)\nNotice from Equation 3.34 that ⋃k+1\nj=1 Ij = Rd−{rk, rk−1, . . . , r2, r1} = DR (E). We define the following counterpart sets of arguments to those in Equation\n3.35. For 1 ≤ i ≤ k, define\nAPi := {A ∈ A DR(A) ∩ Pi 6= ∅} ⊆ A. (3.36)\nThese are the sets of defeasible arguments that have at least one rule excluded from E . By Lemma 3.12 and the definition of the Pi sets, it is easily shown that for all 1 ≤ i ≤ k, APi ∩ E = ∅. Further, for 1 ≤ i ≤ k + 1,\nAIi :=\n\n\n\nA ∈ A DR(A) ∩ Ii 6= ∅ and DR(A) ⊆\ni ⋃\nj=1\nIj\n\n\n\n. (3.37)\nThese are the sets of defeasible arguments where the arguments only have rules from these intervals (as subsets of DR (E)), with at least one such rule from the <SP -lowest ranked interval Ii. We also define\nAI0 := {A ∈ A DR(A) = ∅} = Args (∅) , (3.38)\nwhich by Equation 2.2 is the set of all strict arguments. Clearly AI0 ⊆ χ (∅).\nLemma 3.16. It is the case that AI1 ⊆ χ (∅).\nProof. The set AI1 is cf (conflict free): assume for contradiction that A,B ∈ AI1 such that A →֒ B. Then as DR(A), DR(B) ⊆ I1 ⊆ DR (E), by Equations 3.33 and 3.34 and Lemma 3.12, A,B ∈ E – contradiction, because E is cf. Now assume for contradiction that A ∈ AI1 is defeated, so there is some B ∈ A such that B →֒ A. Clearly if B ∈ E , then E is not cf because A ∈ E . Therefore, B /∈ E . By Lemma 3.12, DR(B) 6⊆ DR (E) so for some 1 ≤ i ≤ k, DR(B) ∩ Pi 6= ∅. However, by Equation 3.34, there is a rule in DR(B)−DR(A), namely ri, such that it is <SP -smaller than all rules in DR(A) (and hence <SP -smaller than all rules in DR(A)−DR(B)). Therefore, B ≺SP A, and hence B cannot defeat A. Therefore, all arguments in AI1 are also undefeated, so AI1 ⊆ χ (∅).\nFor the purposes of the proof of Lemma 3.15, we define, for i > k + 1,\nAIi = AIk+1. (3.39)\nNote that the sets of arguments in Equation 3.35 do not partition A, as an argument can conceivably have rules from two or more of the Ij sets. We now apply these ideas to prove Lemma 3.15.\nProof. (Proof of Lemma 3.15) Given our setup, let E be the stable extension of DG (T+). By Theorem 3.13, E is unique and could only have been constructed by Algorithm 1. Algorithm 1 begins with Args (∅), then adds rules in Rd from <SP -largest to <SP -smallest as long as the resulting set with the rule contains no arguments attacking each other. From the above notation, it is exactly the rules in the sets Pi that, when included, create arguments that attack each other. This is why these rules in Pi do not feature in E .\nWe use strong induction to show that for i ∈ N+, AIi ⊆ χ i (∅). The base case, i = 1, follows from Lemma 3.16. For the strong inductive step, assume AIj ⊆ χ j (∅) for all 1 ≤ j ≤ i. We will show that AIi+1 ⊆ χ i+1 (∅). Let A ∈ AIi+1 be arbitrary. This means DR(A) ⊆ ⋃i+1 j=1 Ij and DR(A) ∩ Ii+1 6= ∅ by Equation 3.37. Either A is defeated by an argument in ⋃i\nj=1 APj or it is not, where APj is defined in Equation 3.36. If A is not defeated by an argument in ⋃i\nj=1 APj , then A ∈ χ (∅) as it is undefeated; A cannot be defeated by some argument B in APj , for j > i, because in that case B ≺SP A. As χ is ⊆-monotonic, A ∈ χi+1 (∅). Otherwise, if ⋃i\nj=1 APj →֒ A, then there is some 1 ≤ j ≤ i such that APj →֒ A. Call the witness to j j0, so APj0 →֒ A. Say the\ndefeating argument is C ∈ APj0 . But by definition of APj0 , (\n∃B ∈\nj0 ⋃\ns=0\nAIs\n)\nB →֒ C, s = 0 is included as B may be strict,\n⇔ (∃0 ≤ s ≤ j0) (∃B ∈ AIs)B →֒ C ⇒ (∃0 ≤ s ≤ j0) (∃B ∈ χ s (∅))B →֒ C by our strong inductive hypothesis.\nThis means A is defended by χs (∅), so A ∈ χs+1 (∅), for some 0 ≤ s ≤ j0. As s ≤ j0 ≤ i, this means s ≤ i and hence s+ 1 ≤ i + 1. By ⊆-monotonicity of χ, A ∈ χi+1 (∅). This establishes the inductive step.\nHowever, this proof by induction proves this for all i ∈ N+. What happens when i > k+1? If i > k+1, then by Equation 3.39, AIi = AIk+1 ⊆ χ\nk+1 (∅) ⊆ χi (∅) and we have no more defeasible rules to add. As the sequence AIi stabilises the result holds for all i ∈ N+ trivially.\nNow, as ∅, χ (∅) , χ2 (∅) . . . form an ⊆-increasing sequence in P (A), we can take the union of the equations AIi ⊆ χ i (∅) and invoke monotonicity of χ:24\nk+1 ⋃\ni=1\nAIi ⊆ k+1 ⋃\ni=1\nχi (∅) = χk+1 (∅) .\nWe then take the union of both sides with the set of all strict arguments. The left hand side becomes E . This is because the union of the AIj sets from j = 0 to k + 1 means any argument in that set cannot have any rules in the Pk sets, and therefore DR(A) ⊆ DR (E) and hence A ∈ E by Lemma 3.12.\nAs the set of all strict arguments is contained in χ (∅) because they are undefeated, the right hand side stays the same. Therefore, we obtain E ⊆ χk+1 (∅), where 0 ≤ k ≤ N ∈ N is the number of defeasible rules blocked from E , which is a natural number.25 This shows the result.\nLemma 3.17. Let 〈A,→〉 be an abstract argumentation framework and χ its characteristic function. Let G ⊆ A be the grounded extension. Then (∀n ∈ N)χn (∅) ⊆ G.\nProof. Immediate by induction on n: χ is ⊆-monotonic and G is complete.\nWe now instantiate the abstract framework 〈A,⇀〉 in Lemma 3.17 to the defeat graph 〈A, →֒〉 of a LPDT.\nCorollary 3.18. Suppose we have an LPDT T+ with attack graph AG(T+) := 〈A,⇀,-SP 〉 and defeat graph DG(T\n+) := 〈A, →֒〉. The characteristic function χ is as usual. The stable extension E ⊆ A of DG(T+) is grounded.\nProof. From Lemma 3.15, there exists some n ∈ N such that E ⊆ χn (∅). From Lemma 3.17, we have χn (∅) ⊆ G, where G ⊆ A is the grounded extension. But by definition, G ⊆ E because stable extensions are complete. Therefore, we have, for this n ∈ N, G ⊆ E ⊆ χn (∅) ⊆ G, so E = G.\n24Strictly speaking the union should be over all i ∈ N but because the AIi sequence stabilises we only have to care about 0 ≤ i ≤ k + 1.\n25Notice if k = 0, there is no conflict, all arguments in E are undefeated, so E ⊆ χ (∅)."
    }, {
      "heading" : "3.4.2 The Trivialisation and Rationality Theorems",
      "text" : "The trivialisation theorem states that if the underlying default priority is total, then all of Dung’s argumentation semantics are equivalent.\nTheorem 3.19. (The Trivialisation Theorem) The defeat graph 〈A, →֒〉 of an LPDT T+ has a unique complete extension that is grounded, preferred and stable.\nProof. Let C be any complete extension of 〈A, →֒〉, which means C is cf and χ (C) = C. Let G be the grounded extension, then G ⊆ C by definition. As the (unique) stable extension E is grounded by Corollary 3.18, we have G = E , therefore E ⊆ C. This means either E = C or E ⊂ C. In the latter case, there will be some B /∈ E such that B ∈ C, but as E ⊂ C is stable, we must have some A ∈ E (so A ∈ C) such that A →֒ B. Therefore, C is not cf – contradiction. Therefore, C = E . As E is unique, C is unique. Therefore, 〈A, →֒〉 has a unique complete extension that is grounded, stable and hence preferred.\nWe now prove that this instantiation of ASPIC+ to PDL satisfies the requirements for normative rationality [10]. Recall that when instantiated to FOL, ClRs becomes deductive closure.\nTheorem 3.20. (The Rationality Theorem) Let 〈A, ⇀, -SP 〉 be the ASPIC + attack graph of PDL and let E be any of the complete extensions of the corresponding defeat graph 〈A, →֒〉. Our instantiation satisfies the Caminada-Amgoud rationality postulates.\nProof. By Theorem 3.13, 〈A, →֒〉 has a unique stable extension E , which is a complete and an admissible extension. It is sufficient to prove the postulates for E because by Theorem 3.19, 〈A, →֒〉 only has E as its sole complete extension.\n1. To show that E is subargument closed, recall that Algorithm 1 gives an explicit construction of E , which is of the form Args(R) for some R ⊆ Rd which is subargument closed (Equation 2.2).\n2. The representation theorem states that Conc (E) = E and as E is deductively closed, Conc (E) is closed under strict rules.\n3. As W is consistent and Conc (E) is the extension, Conc (E) must also be consistent and its deductive closure is consistent.\nThis shows the result.\nThe rationality theorem establishes that this instantiation of ASPIC+ to PDL satisfies all of the Caminada-Amgoud rationality postulates and is a normatively rational instantiation of ASPIC+.\nFinally, the consistency of E on the side of PDL allows us to establish a stronger notion of cf for E on the side of argumentation. This is already implicit in Algorithm 1 Line 4.\nCorollary 3.21. Let 〈D,W,<+〉 be an LPDT with attack graph 〈A,⇀,-SP 〉 and corresponding defeat graph 〈A, →֒〉 that has a unique stable extension E. We have E2∩ ⇀= ∅, i.e. no two arguments in E attack each other.\nProof. Given the hypotheses, assume for contradiction that A ⇀ B for A,B ∈ E . WLOGwe can assume thatConc(A) = θ and Conc(B) = ¬θ with TopRule(B) ∈ Rd, by Equation 3.3 and that E is subargument closed. Therefore, Conc (E) is inconsistent, because θ,¬θ ∈ Conc (E). This violates the Rationality Theorem – contradiction. Therefore, no two arguments in E attack each other."
    }, {
      "heading" : "3.4.3 Inconsistent Arguments",
      "text" : "We have stated in Section 2.2 that arguments are constrcted freely from the premises and rules. In this instantiation, it is possible to construct arguments that are inconsistent, either in their intermediate conclusions or their conclusion.\nExample 5. Consider the rules (⇒ a) and (⇒ ¬a) and arguments A = [⇒ a], B = [⇒ ¬a] and C = [A,B → ⊥]. Then C is inconsistent in its conclusion. Further, for any c ∈ SL the argument A+ := [A → (a ∨ c)], so given that our strict rules are the rules of proof in FOL, we can construct the argument D = [A+, B → c] for any c. The intermediate conclusions of D are inconsistent.\nWe call an argument inconsistent iff Conc (Sub(A)) ⊆ FL is an inconsistent set in FOL. It is possible to construct such arguments in A. We can ignore these arguments by focussing on A−{A ∈ A A is inconsistent} and restricting ⇀ in the usual way, but this seems inelegant especally when the process of argumentation is meant to resolve inconsistencies. If we do include inconsistent arguments, the very least is that they should not be justified. By Theorems 3.13 and 3.19, there is only one way of justifying arguments: an argument A is justified iff A ∈ E . Lemma 3.9 and Corollary 3.21 ensure that if A is inconsistent, then A /∈ E .\nIn summary, although it is possible to have inconsistent arguments in A, they can never be justified and we do not need to be concerned with them."
    }, {
      "heading" : "3.5 Summary",
      "text" : "In this section, we have provided an argumentative characterisation of PDL inference that is sound, complete and normatively rational, in the case where our default priority is a strict total order. We can construct ASPIC+ arguments and attacks (Section 3.1). The structure-preference relation, -SP , takes into account both the default priority < and the logical structure of arguments. This is motivated by how PDL adds defaults when constructing extensions (Section 3.2). The representation theorem states that under -SP , the PDL extension and the conclusion set of the stable extension correspond exactly (Section 3.3, Theorem 3.14). We can prove directly that the stable extension of interest satisfies the Caminada-Amgoud rationality postulates (Section 3.4, Theorem 3.20). As this is the only complete extension of our defeat graphs, our instantiation satisfies\nthe postulates. Finally, we do not need to explicitly prevent the construction of inconsistent arguments, because they are never justified (Section 3.4.3)."
    }, {
      "heading" : "4 On Lifting the Assumption of a Total Order",
      "text" : "Default Priority\nIn Section 3, we have provided an argumentative characterisation of PDL inference where the default priority < is a strict total order. It seems that we have lost generality but this is not the case because calculating an extension in PDL always presupposes a linearisation <+ of < (Section 2.3), and Theorem 3.14 shows that for any such linearisation the correspondence of inferences between PDL and its argumentation semantics holds.\nBut argumentation can also define argument preference relations based on an underlying partial order. We now investigate how to lift the assumption that < is total for the LPDT T+, such that the resulting multiple stable extensions each correspond to an extension of the underlying PDT T . Our underlying representation of PDL in ASPIC+ is the same as in Section 3.1, but now <D is a strict partial order."
    }, {
      "heading" : "4.1 The Argument Preference Relation based on Partial Order Default Priorities",
      "text" : "In Section 3.2, we devised the structure-preference (SP) argument preference relation -SP which captures the PDL idea of adding the “<\n+-greatest active” default (Equation 2.5). If we translate a PDT T directly into an argument graph AG (T ) without first linearising <, the generalised version of -SP should take into account the incomparabilities of rules while still respecting their logical structure. We formalise this idea by defining a string representation of the rules that will be used in an algorithm to calculate <D 7→ <SP for partial <D. We will give a variation of the Penguin Triangle (Example 8) as a running example."
    }, {
      "heading" : "4.1.1 A Representation of Rules and their Ordering using Strings",
      "text" : "Let rulenames be a set of characters, with as many characters as there are rules in Rd. Let g : Rd → rulenames be a bijection such that each r ∈ Rd has a single-character name26 g(r). Let ⋆ denote the Kleene star and ∗ denote string concatenation,27 and len : rulenames⋆ → N returns the number of letters of the string. We will also assume that in each string σ ∈ rulenames⋆ there is an index assocated with each letter starting from 0 and ending in len (σ) − 1. To iterate over the letters l of the string σ we will write l ∈ σ, which starts from the\n26By “name” we do not mean the naming function n : Rd → L in Section 2.2 (page 4), which is still undefined (n ≡ ∗) in this case, but just what we label the rules with, e.g. the defeasible rule r7 = (a ⇒ b) has the label or name r7.\n27This is abuse of notation as we had earlier stated ∗ refers to undefined quantities (Section 2.1). But there are few undefined quantities and the meaning of ∗ will be clear from context.\nletter at index 0 and terminates at the letter at index len (σ) − 1. The empty string is ε := “” with len (ε) = 0. We may put quotation marks around strings to emphasise that they are strings.\nFor R ⊆ Rd such that R := {r1, . . . , rk}, we can form the string g(r1) ∗ g(r2)∗ · · · ∗g(rk), written g(r1)g(r2) · · · g(rk). Notice that forming a string from a set imposes an order on the elements.\nExample 6. (Example 1 continued) Suppose we have ri := f (di) for f as in Equation 3.1. Suppose g (r1) = “a”, g (r2) = “b”, g (r3) = “c”, g (r4) = “d” and g (r5) = “e”. Then for the set S = {r1, r2, r5} we can form the strings (e.g.) “abe” or “bea”, depending on which order we choose the rules to be in.\nAs g is a bijection we can define the reverse process. Suppose we have a string σ. We define the set of rules that are encoded by the letters of σ as follows:\n⋃\nl∈σ\n{ g−1 (l) } . (4.1)\nNotice that we lose the information about the index, but we will see that it does not matter. Notice also that if σ = ε then we have the empty union so the set of rules encoded by ε is ∅.\nExample 7. (Example 6 continued) Suppose we want to find the set of the string “ace”. Applying Equation 4.1, we get the set {r1, r3, r5}.\nLastly, we can transform strings into total orders: for σ = σ1σ2 . . . σn, where for 1 ≤ i ≤ n the letter σi has index i− 1. 28 We can transform σ to the set\n{(σ1, σ2) , (σ1, σ3) , . . . , (σ1, σn) , (σ2, σ3) . . . , (σn−1, σn)} (4.2)\nusing two nested loops ranging over the letters of σ such that the pair of letters (σi, σj) is added to the set iff i < j. Intuitively, given a selected letter σi of a string, letters to the right of σi are larger than σi, and letters to the left of σi are smaller than σi."
    }, {
      "heading" : "4.1.2 Algorithm and Example Calculation",
      "text" : "We want to generalise the mapping <D 7→ <SP , defined in Section 3.2 for the case where <D is total, to arbitrary partial orders <D. Furthermore, we want to simultaneously capture all possible linearisations of <D. We now present the algorithm that calculates the generalised mapping <D 7→<SP in two parts.\nThe first stage of the algorithm is a non-recursive depth first search algorithm that returns the set of all strings representing the rules chosen in accordance with both the preference and the structure as described in Section 4.1.1. This is articulated in Algorithm 2, which defines the function StructurePreference1. This function takes 〈Rd, <D〉 as input and returns this set of strings.\n28Here, σi denotes one letter; the subscript i is not a separate letter to σ itself.\nThe second stage of the algorithm is to turn the output of Algorithm 2 into <SP . This is done by translating each string in the output of Algorithm 2 into a strict total order onRd, and then taking their intersection. This is articulated in Algorithm 3, which defines a function StructurePreference2, which takes as input a set of strings, and calculates <SP .\nAlgorithm 2 Calculating <SP from <D on Rd, Part 1 – generate a set of strings, each string is an order of the choice of rules from least preferred (the first letter, on the left) to the most preferred (the last letter, on the right), which essentially corrects <D for the argument structure and then linearises. Recall that in Line 11, ∗ refers to string concatenation. As Rd is finite, Algorithm 2 terminates. Throughout, Si is a set of strings, while R λ, T λ ⊆ Rd.\n1: function StructurePreference1(〈Rd, <D〉) 2: S0 ← {ε} 3: N ← |Rd| 4: for i = 0 to N do 5: Si+1 ← ∅ 6: for λ ∈ Si do 7: T λ ← ⋃\nl∈λ\n{ g−1 (l) }\n8: Rλ ← max<D [{ s ∈ Rd Ante(s) ⊆ Conc ( Args ( T λ ))} − T λ ]\n9: if Rλ = ∅ then return Si 10: for t ∈ g ( Rλ ) do 11: Si+1 ← Si+1 ∪ {t ∗ λ}\nThe intuition of Algorithm 2 is as follows: we initialise the algorithm (Line 2) and iterate N +1 times (Line 4), where N = |Rd| (Line 3). At each iteration Algorithm 2 chooses all of the most preferred applicable rules at that stage. Each choice may render more rules active for the next iterations. It iterates over all such possibilities and repeats this process until the N th iteration, where there are no more rules to be chosen and the algorithm terminates. The result is a set of strings, which are read from right to left, where the right-most letter is the first choice of most preferred applicable defeasible rule, and the left-most letter is the last choice, which usually corresponds to a blocked default.\nThe intuition of Algorithm 3 is that upon input of this set of strings, the algorithm turns each string into a strict total order over Rd as described in the end of Section 4.1.1 (Equation 4.2), and then takes the intersection of all such orders to return <SP . The intersection returns the “core” strict partial order which is the “smallest” change to the original <D that is compatible with all argument structures. Given 〈Rd, <D〉, we define:\n<SP :=StructurePreference2(StructurePreference1[〈Rd, <D〉])\n:=F (<D) . (4.3)\nThis is our method for calculating 〈Rd, <SP 〉 from 〈Rd, <D〉 where <D is partial.\nAlgorithm 3 Calculating <SP from <D on Rd, Part 2 – from the set of strings generated from Algorithm 2, we turn each string into a strict total order on Rd, and then take their intersection to return <SP .\n1: function StructurePreference2(S) 2: orders ← ∅ 3: for λ ∈ S do 4: <+SP← ∅ 5: for r ∈ λ do 6: for s ∈ λ do 7: if index(r) < index(s) then 8: <+SP←< + SP ∪{(r, s)} 9: orders ← orders ∪ {\n<+SP }\nreturn ⋂ orders\nExample 8. (Modified Penguin Triangle) Let W = ∅,\nD =\n{\nd1 := : a\na , d2 :=\na : b\nb , d3 :=\n: ¬b\n¬b\n}\nand consider the default priority <= {(d3, d2)}. 29 There are three possible linearisations of < giving two possible extensions:\nE1 :=Th ({a, b}) from d3 < + d2 < + d1 and d3 < + d1 < + d2, and E2 :=Th ({a,¬b}) from d1 < + d3 < + d2.\nLet ri := f (di) for i = 1, 2, 3 (Equation 3.1). We illustrate these arguments in Figure 4.1.\nClearly A and B attack each other at their conclusions. Putting <D= {(r3, r2)} into Equation 4.3, we get the following:\n• For Algorithm 2, we have S0 = {ε}, N = 3 and i = 0, 1, 2, 3.\nWhen i = 0, S1 = ∅, λ = ε, T λ = ∅ and Rλ = {r1, r3} 6= ∅. Therefore, S1 = {“r1”, “r3”}. Notice r3 is a <D-maximal applicable rule, because even though r3 <D r2, r2 is not applicable until r1 is applied.\n29Notice this is not the “usual” partial order priority that respects the specificity principle.\nWhen i = 1, S2 = ∅, and either λ = “r1” or λ = “r3”. The former gives S2 = {“r2r1”} and the latter gives S2 = {“r2r1”, “r1r3”}.\nWhen i = 2, S3 = ∅, λ = “r2r1” or λ = “r1r3”. In the former case, S3 = {“r3r2r1”}, and in the latter case, S3 = {“r3r2r1”, “r2r1r3”}.\nWhen i = 3, we get T λ = Rd so R λ = ∅, halting the algorithm with output S3.\n• Given S3 as input to Algorithm 3, we get the intersection of the words “r3r2r1” and “r2r1r3” when converted to chains, giving <SP= {(r2, r1)}.\nTherefore, Equation 4.3, returns <SP= F (<D) = {(r2, r1)}. If <D is arbitrary,30 we can repeat the above calculation and obtain the values of Equation 4.3,31 which are shown in Table 1."
    }, {
      "heading" : "4.1.3 Properties of the Generalised SP Order",
      "text" : "We prove some properties of F (Equation 4.3 and Algorithms 2 and 3) that will be useful in proving the representation theorem for the case where <D is a partial order (Theorem 4.11). It can easily be shown that F is a well-defined function from PO (Rd) to itself, where PO (Rd) is the set of all strict partial orders on Rd (Section 2.1). We show that the function F : PO (Rd) → PO (Rd) indeed generalises the definitions in Section 3.2. Recall that TO(X) is the set of all strict total orders on the set X .\nLemma 4.1. If <D∈ TO (Rd) then we recover <SP defined in Section 3.2.\nProof. If <D is total, then R λ on Algorithm 2 Line 8 is singleton. This means Line 10 has only one choice in Rλ, so Si for all 0 ≤ i ≤ N is singleton. Using the notation of Equation 3.4, Algorithm 2 returns {“aNaN−1 . . . a2a1”}. This gets transformed into Equation 3.5 through Algorithm 3, which is <SP for the case of <D total.\n30There are 19 partial orders on a set of three labelled elements. 31 We abbreviate the total order r3 <D r2 <D r1 as 321, <D:= {(r1, r2) , (r3, r2)} as\n(12,32), and <D= {(r1, r3)} as 13... etc. and the same applies to <SP .\nExample 9. (Example 8 continued) By restricting F to TO (Rd), we obtain the following subtable of Table 1, which indeed generalises the calculation for the case where the input <D is total.\nThe next result shows that given the input <D in Algorithm 2, each string in the output set of Algorithm 2, when transformed into its corresponding total order on Rd, is the output of Equation 4.3 for some linearisation < + D of <D.\nTheorem 4.2. Consider Algorithm 2 with input <D∈ PO (Rd). For each string σ in the output set of Algorithm 2, let <out denote σ transformed into a strict total order on Rd (Algorithm, 3). For each such <out there exists a linearisation <+D of <D such that <out= F ( <+D ) .\nProof. If <D is itself total, then the output of Algorithm 2 is singleton, which when converted to a chain by Algorithm 3 gives <out=<SP . Therefore, there exists a linearisation of <D, namely itself, such that <out= F (<D).\nIf <D is not total, then incomparable rules will cause R λ (Algorithm 2 Line 8) to not be singleton. Each element of Rλ will form a distinct element of the output set of Algorithm 2. Choosing a given rule r in Rλ to append to the string can also be interpreted as a resolution of this incomparability of <D through a linearisation < + D of <D that ranks r higher than the alternative choices. Reasoning in this way in all cases whenever Rλ is not singleton, we obtain a linearisation <+D of <D such that F ( <+D )\ncorresponds to one of the elements in the output SN of Algorithm 2.\nIt follows that Equation 4.3 incorporates all possible linearisations of <D in the following manner.\nCorollary 4.3. The output of Equation 4.3 is equal to\n<SP= F (<D) = ⋂\n< +\nD ⊇<D total\nF ( <+D ) ,\nwhere the intersection ranges over all linearisations of <D.\nProof. This is immediate from the definition of Algorithm 3 and Theorem 4.2.\nExample 10. (Example 9 continued) Consider <D= 23, which abbreviates <D= {(r2, r3)}. 23 has linearisations abbreviated as 123, 213 and 231 (see Footnote 31, page 37). By Table 2, these input linearisations returns, respectively, 213, 213 and 231. By Corollary 4.3, we get <SP to be the intersection of the sets representing the total orders 213 and 231. This gives (21, 23), which abbreviates <SP= {(r2, r1) , (r2, r3)}. This is consistent with Table 2.\nWe now relate the linearisations of the inputs and outputs of Table 1.\nTheorem 4.4. (The linearisation square) Let <D ∈ PO (Rd) and < + D be a linearisation of <D. F ( <+D ) =:<+SP is a linearisation of F (<D) =:<SP .\nProof. Let <SP be as given. Let < + D be a linearisation of <D. Suppose < + D is the input of Algorithm 2. This will give an output set consisting of a single string that Algorithm 3 translates into some strict linear order <+SP (say), by Theorem 4.1. Upon input <D to Algorithm 2, the string corresponding to < + SP will appear in the output set of Algorithm 2, because we can choose the rules in Rλ (Line 8) in accordance with the ranking of <+D ⊇ <D. By Algorithm 3, <+SP ⊇ F (<D) =<SP .\nThe linearisation square can be expressed in the following commutative diagram:\n<D <+D\nF (<D) F ( <+D )\n//\nlinearisation❴\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\nEquation 4.3\n❴\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\n✤\nEquation 4.3\n//\nlinearisation\nThe linearisation square states that the function F : PO (Rd) → PO (Rd) preserves linearisations.\nExample 11. (Example 10 continued) Consider Table 1 again. Let <D= 31. Let <+D= 321. We know that <SP= (21, 31). We also know that < + SP= 321. Clearly, 321 is a linearisation of (21, 31)."
    }, {
      "heading" : "4.1.4 The Generalised Argument Preference Relation for <D Partial",
      "text" : "The following result states that changing the partial order PDL default priority < to respect the logical dependencies of defaults while following the preference does not change the PDL extension. This generalises Lemma 3.7 (page 21) to the case where <D is not necessarily total.\nLemma 4.5. Let T := 〈D,W,<〉 and T ′ := 〈D,W,<′〉 be two PDTs such that <∼=<D and F (<D) ∼=< ′, then both PDTs have the same extensions\nProof. Denote Ext(T ) and Ext (T ′) to be the sets of extensions of the respective PDTs. We show that Ext(T ) = Ext (T ′).\n(⇒) Let E ∈ Ext (T ) be arbitrary. This means E is the unique extension of some LPDT T+ := 〈D,W,<+〉, where <+⊇< is a strict total order. Therefore, <+ ∼= <+D ⊇ <D\n∼= <, where <+D is a linearisation of <D. By the linearisation square (Theorem 4.4), F (\n<+D ) =:<+SP is a linearisation of F (<D) =:<SP . As\n<′ ∼=<SP , then < + SP ∼=< ′+, where < ′+ is some linearisation of <′. By Lemma 3.7, E is also the unique extension of the LPDT 〈 D,W,< ′+ 〉 , which means E\nis an extension of T ′ = 〈D,W,<′〉. Therefore, E ∈ Ext (T ′). (⇐) Let E ∈ Ext (T ′) be arbitrary. This means E is the unique extension of some LPDT T+ := 〈 D,W,< ′+ 〉 , where < ′+ ⊇ <′ is a strict total order. As\n< ′+ ∼=<+SP , which is a linearistaion of <SP , then by Theorem 4.2, there exists a linearisation <+D of <D such that < + D 7→ < + SP , given that <D 7→ <SP . By Lemma 3.7, E is the unique extension of T+ := 〈D,W,<+〉, where <+ ∼= <+D, which means E is an extension of T . Therefore, E ∈ Ext (T ). Therefore, Ext (T ) = Ext (T ′).\nExample 12. (Example 11 continued) Recall the setup of Example 8, where W = ∅ and\nD =\n{\nd1 := : a\na , d2 :=\na : b\nb , d3 :=\n: ¬b\n¬b\n}\n.\nConsider two strict partial orders on D, < and <′, where d1 < d2 only and d2 < ′ d1 only. This gives us two PDTs T = 〈D,W,<〉 and T ′ = 〈D,W,<′〉. Let <D ∼= <. By Table 1, F (<D) = 21 so F (<D) ∼= < ′. Both PDTs T and T ′ have the same extensions. In the case of T , we have linearisations 312, 132 and 123, with the first linearisation giving E1 := Th ({a, b}) and the latter two linearisations giving E2 := Th ({a,¬b}). In the case of T\n′, we have linearisations 321, 231 and 213, with the first linearisation giving E1 and the latter two linearisations giving E2. Therefore, both T and T\n′ have the same extensions.\nWe can now define the associated set comparison relation from this new <SP just like Equation 3.7: for Γ, Γ′ ⊆fin Rd,\nΓ ⊳SP Γ ′ ⇔ (∃x ∈ Γ− Γ′) (∀y ∈ Γ′ − Γ)x <SP y, (4.4)\nwhere given the partial order default priority <, order isomorphic to <D (Equation 3.1), <SP= F (<D) is the output of Equation 4.3. The associated strict argument preference is, for A,B ∈ A,\nA ≺SP B ⇔ DR(A) ⊳SP DR(B). (4.5)\nThe associated non-strict argument preference is\nA -SP B ⇔ [DR(A) ⊳SP DR(B) or DR(A) = DR(B)] , (4.6)\nThese equations are the same as Equations 3.8 and 3.9 respectively.32\nExample 13. (Example 8 continued) Suppose we define ≺SP by Equation 4.5 with this new <SP . We have both A 6≺SP B and B 6≺SP A. This means there are two stable extensions: E1 which contains A0 and A, and E2 which contains A0 and B. The conclusion set of these stable extensions correspond respectively to E1 and E2.\nSo given a PDT T where the default priority < is not necessarily total, we construct the set of arguments A and define the attack relation ⇀ as in Section 4. We define the non-strict argument preference relation -SP as in Equations 4.6, 4.5, 4.4 and 4.3, given < ∼= <D. The attack graph of the PDT T is the structure AG(T ) := 〈A,⇀,-SP 〉. The defeat graph of the PDT (T ) is the structure DG(T ) := 〈A, →֒〉, where →֒ is defined as in Equation 2.3 under the argument preference relation -SP ."
    }, {
      "heading" : "4.2 The Representation Theorem for Partial Order Default Priorities",
      "text" : "We now generalise Theorem 3.14 to the case where <D is a partial order. Our proof strategy is to leverage as much of Theorem 3.14 as possible. The difference here is that our default priority<∼=<D is now partial. In the previous section, we saw how the linearisation square (Theorem 4.4) related the lift <D 7→<SP to the lift <+D 7→< + SP where< + D is a linearisation of <D. We now apply the linearisation square to relate partial order <D with their linearisations < + D in the case of the defeat graphs generated and their stable extensions. Specifically, if <+D is a linearisation of <D, then the defeat graph of the former is a spanning subgraph of the latter. Further, the unique stable extension in the former case is still a well-defined stable extension in the latter case. The next two sections establish these results, which will then be used to prove the generalised representation theorem."
    }, {
      "heading" : "4.2.1 Linearisation of the Argument Preference Relation and Spanning Subgraphs",
      "text" : "Recall from graph theory that G′ := 〈V,E′〉 is a spanning subgraph of G := 〈V,E〉 iff E′ ⊆ E, and we write G′ ⊆span G. For spanning argument subframeworks, stable extensions are preserved as long as you do not add conflicts between arguments in the stable extension.\nLemma 4.6. Let AF := 〈A,→〉 be an abstract argumentation framework. Let AF ′ := 〈A,→′〉 be a spanning subgraph of AF . If E is a stable extension of AF ′ and E2∩ →= ∅, then E is also a stable extension of AF .\n32It can be shown that -SP in the partial order case is not transitive, unlike in the total case (Lemma 3.5, also recall Footnote 15), but is acyclic. We will discuss this in future work.\nProof. By assumption, E is cf because it is a stable extension. Let b /∈ E , then E →′ b, but as →′ ⊆ → by definition, we also have E → b. Therefore, E is a stable extension of AF .\nLinearising the structure preference order <SP on the rules also linearises the set comparison relation ⊳SP and the argument preference -SP by Lemma 3.4.\nLemma 4.7. Let <SP be the output of Equation 4.3 for some input <D. Let <+SP be a linearisation of <SP . Let the binary relations on Pfin (Rd), ⊳SP and ⊳+SP , be obtained by applying Equation 4.4 to <SP and < + SP respectively. Then\n1. ⊳SP ⊆ ⊳ + SP ,\n2. ≺SP ⊆ ≺ + SP , where ≺SP is the strict part of Equation 4.5 on ⊳SP and\nanalogously for ≺+SP on ⊳ + SP , and\n3. -SP ⊆- + SP .\nProof. (1) Let Γ, Γ′ ∈ Pfin (Rd) be arbitrary. Assume Γ ⊳SP Γ ′. Then by Equation 4.4, this is equivalent to (∃x ∈ Γ− Γ′) (∀y ∈ Γ′ − Γ)x <SP y, which by our assumption implies that (∃x ∈ Γ− Γ′) (∀y ∈ Γ′ − Γ)x <+SP y, and hence Γ ⊳+SP Γ\n′. (2) Let A,B ∈ A be arbitrary. We have A ≺SP B ⇔ DR(A) ⊳SP DR(B). From the first result, DR(A) ⊳SP DR(B) then DR(A) ⊳ + SP DR(B). (3) This follows trivially from Equation 4.5.\nWe now prove the converse of Lemma 4.7.\nLemma 4.8. Let T be a PDT, < ∼= <D and <SP= F (<D). Let < + SP be a linearisation of <SP . Let -SP and - + SP be the lift of <SP and < + SP respectively from Rd to an argument preference relation on A in the usual way (Equations 4.4 and 4.5). Let DG(T ) := 〈A, →֒〉 and DG+ (T ) := 〈A, →֒+〉 be the respective defeat graphs of the attack graphs AG(T ) := 〈A,⇀,-SP 〉 and AG\n+ (T ) := 〈\nA,⇀,-+SP 〉 . Then DG+ (T ) ⊆span DG(T ).\nProof. Clearly both DG(T ) and DG+(T ) have the same vertex set A. We show that →֒+ ⊆ →֒. Let A,B ∈ A be arbitrary such that A →֒+ B. Suppose B′ ⊆arg B is the argument defeated by A at its top rule. By Equation 2.3, A ⇀ B′ and A 6≺+SP B ′. It is sufficient to show that A 6≺SP B ′. By Lemma 4.7, we have ≺SP ⊆≺ + SP meaning that if A 6≺ + SP B ′ then A 6≺SP B ′. Hence, A →֒ B′ and so A →֒ B. It follows that →֒+ ⊆ →֒."
    }, {
      "heading" : "4.2.2 Existence of Stable Extensions in the Partial Order Case",
      "text" : "For a PDT T , its defeat graph DG (T ) has stable extensions that do not have to be unique.\nTheorem 4.9. Let T be a PDT, with attack graph AG(T ) and defeat graph DG(T ) where, as usual, < ∼= <D, <SP= F (<D) by Equation 4.3, and -SP is defined from <SP using Equations 4.4 and 4.5. The defeat graph DG(T ) has a stable extension that is not in general unique.\nProof. The PDT T has some extension E, which is the unique stable extension of an LPDT T+ := 〈D,W,<+〉, where<+ is the linearisation of< that generates E. Given that <∼=<D and < +∼=<+D, we know that < + D is also a linearisation of <D. By the linearisation square (Theorem 4.4), F ( <+D )\n=:<+SP is a linearisation of F (<D) =:<SP .\nThe LPDT T+ has an attack graph AG (T+) := 〈 A,⇀,-+SP 〉 , where -+SP is calculated from <+SP . As < + SP is a linearisation of <SP , the defeat graph of T+, DG (T+) := 〈A, →֒+〉 is a spanning subgraph of DG(T ) by Lemma 4.8. The LPDT T+ has E as its unique PDE. By the representation theorem for LPDTs (Theorem 3.14), there exists a unique stable extension E of DG (T+) such that Conc (E) = E. By Corollary 3.21, E2 ∩ ⇀= ∅. DG(T ) differs from DG (T+) by their argument preference relations, as the attack relation is the same for both. As no attacks are introduced to E , E is also cf in DG(T ) by Equation 2.3. Therefore, by Lemma 4.6, E is also a stable extension of DG(T ). Therefore, DG(T ) also has E as a stable extension.\nTo show that this stable extension is not in general unique, consider the PDT 〈{\nd1 := :a a , d2 := :¬a ¬a\n} ,∅,∅ 〉\n. We can construct the arguments A := [⇒ a] and B := [⇒ ¬a], which symmetrically attack each other on their conclusions. As <= ∅, we have <D=<SP= ∅ from Equation 4.3. Therefore, A 6≺SP B and B 6≺SP A and we have two stable extensions: one where A is justified (and B is not justified), and the other where B is justified (and A is not justified)."
    }, {
      "heading" : "4.2.3 Proof of the Representation Theorem",
      "text" : "We prove the representation theorem in this section. Our technique is to relate a partial order on the defaults < with one of its possible linearisations <+, and invoke the first representation theorem (Theorem 3.14) for this linearisation. We know given an extension E of some PDT T there is a linearisation <+ of < generating E. We now establish an analogous result on the side of argumentation: for every stable extension E of DG (T ), there is a linearisation <+SP of <SP on Rd such that < + SP constructs E via Algorithm 1.\nWe show <+SP exists given <SP by construction, which will make use of a partial linearisation of an order < on P . Let 〈P,<〉 be a poset and U ⊆ P . Let <U :=< ∩U\n2 be the partial order < restricted to U . Let <+U be a linearisation of <U on U . We define\n<parU := TrCl ( <+U ∪ < ) , (4.7)\nwhere TrCl denotes the transitive closure. It can be shown that given 〈P,<〉 and U , <parU is a strict partial order on P extending <, which is linear when restricted to the set U . Further, <parU is not unique because there could be many possible linearisations of < over U .\nLemma 4.10. Let T be a PDT with defeat graph DG(T ) where <SP lifts to -SP . Let E be a stable extension of DG(T ). There exists a linearisation < + SP of <SP such that E is the output of Algorithm 1 with < + SP as input.\nProof. Given E , let R+ := DR (E) and R− = Rd − R +. Define <0:=< par SP,R− , which is Equation 4.7 with 〈P,<〉 = 〈Rd, <SP 〉 and U = R −. As Rd is finite, WLOG let R− := {s1, s2, . . . , sm} for some m ∈ N, such that i < j ⇔ sj <0 si. so s1 is <0-greatest on R −. For 1 ≤ i ≤ m, define the set\nnonlower<i−1(si) :=: Ui := {r ∈ Rd r 6<i−1 si} . (4.8)\nFor 0 ≤ i ≤ m − 1 we extend <i to a new partial order <i+1:=< par i,Ui+1 , which is Equation 4.7 with 〈P,<〉 = 〈Rd, <i〉 and U = Ui (Equation 4.8), such that si is the <i-least element on the set Ui. Once we reach <m we take a final linearisation of<m to get< + SP .\n33 This construction therefore gives an increasing sequence of partial orders <SP⊆<0⊆<1⊆ · · · ⊆<m⊆< + SP . on Rd. Clearly, < + SP is a well-defined linearisation of <SP by construction. To show that <+SP generates E when input into Algorithm 1, consider si ∈ R−. We assume no defeasible rule is unnecessary, i.e. (∀r ∈ Rd) (∃A ∈ A) r ∈ DR(A). In other words, each defeasible rule is used in some argument.34 Therefore, there is some argument Bi ∈ A such that TopRule (Bi) = si. By how <SP is defined, si is the <SP -least rule in DR (Bi). By Lemma 3.12, Bi /∈ E so E →֒ Bi. Let Ai →֒ Bi for Ai ∈ E . This would mean Ai 6≺SP Bi.\nWe show that for the set of defeasible rules Ui associated with rule si as defined in Equation 4.8, (∀r ∈ DR (Ai)) r ∈ Ui. Assume for contradiction that (∃r ∈ DR (Ai)) r /∈ Ui, then there is some r0 ∈ DR (Ai), r0 <i−1 si. By the properties of Equation 4.7, we can show that r0 <i−1 si <i−1 si−1 <i−1 · · · <i−1 s1. Therefore, r0 cannot be in the sets Uj for any j < i, and so could not have been linearised above sj for j < i in any of the previous stages. Therefore, r0 <SP si. As si is <SP -least in DR (Bi) by being the top rule of Bi, r0 /∈ DR (Bi) and hence there is some rule, r0 ∈ DR (Ai)−DR (Bi), such that for all rules x ∈ DR (Bi)−DR (Ai), r0 <SP x. Therfore, Ai ≺SP Bi – contradiction, as Ai →֒ Bi. Therefore, all the defeasible rules of Ai are in Ui, and in the linearisation process where <i−1 is linearised over Ui into <i such that si is <i-minimal in Ui, we have ensured that at least one defeater of Bi will be constructed by Algorithm 1 and included in E prior to the consideration of the rule si. As i is arbitrary, we have shown that the final linearisation < + SP ensures that all arguments containing rules in R− are defeated and excluded from E . Therefore, Algorithm 1, upon input from <+SP , generates exactly E .\nWe give two concrete examples of the construction of <SP in Lemma 4.10.\nExample 14. Consider the PDT 〈{ d1 := :a a , d2 := :¬a ¬a } ,∅,∅ 〉\nfrom the proof of Theorem 4.9. Translating to argumentation, there are two argumentsA := [⇒ a] and B := [⇒ ¬a] which attack each other at their conclusions. Clearly, <SP= ∅ and there are two stable extensions: E1 such that A ∈ E1 and E2 such that B ∈ E2. Suppose we choose the stable extension E1 and construct a linearisation of ∅ that generates E1. We have R + = {r1} and R − = {r2}. Vacuously, <SP\n33Simple examples can be devised where <m is not a total order on Rd. 34This is a fair assumption to make given that PDTs typically do not have defaults that\nare excluded from all extensions.\nis already linear on {r2} so <0=<SP . We then consider nonlower<SP (r2) = {r1, r2}. We linearise <SP such that r2 is smaller than all other elements in nonlower<SP (r2), so r2 < + SP r1. This is indeed the linearisation of <SP that generates E1.\nExample 15. Let Kn = ∅ and r1 := (⇒ ¬b), r2 := (⇒ a), r3 := (a ⇒ b), r4 := (⇒ c), r5 := (c ⇒ ¬b), r6 := (⇒ b). Define A := [⇒ ¬b], B := [[⇒ a] ⇒ b], C := [[⇒ c] ⇒ ¬b] and D := [⇒ b]. We illustrate these arguments in Figure 4.2.\nSuppose <SP is such that r6 <SP r5 <SP r4, r5 <SP r3 <SP r1 and r3 <SP r2. It can be shown that D ≺SP C ≺SP B ≺SP A hence A →֒ B →֒ C →֒ D (notice A →֒ D as well). The stable extension therefore contains A, C and [⇒ a], so R− = {r3, r6}. As r6 <SP r3, <SP is already linear on R\n−, so <0=<SP . Now consider nonlower<0(r3) = {r1, r2, r3, r4} and linearise <SP over this set such that r3 is the smallest element in nonlower<0(r3), so suppose <1 is r3 <1 r1 <1 r2 <1 r4. Now consider r6, but nonlower<1(r6) = Rd and is already linear, so we take <+SP to be the chain 653124 when written in abbreviated form (see Footnote 31, page 37). This <+SP , when input into Algorithm 1, will generate E .\nWe now apply Lemma 4.10 to prove a more general representation theorem.\nTheorem 4.11. (The Representation Theorem for Partial Order Default Priorities) Let AG(T ) be the attack graph corresponding to a PDT T , where the default priority < is not necessarily total, with defeat graph DG(T ) under -SP as defined by Equations 4.3, 4.4 and 4.5.\n1. Let E be an extension of T . Then there exists a corresponding stable extension E ⊆ A of DG(T ) such that Conc (E) = E.\n2. Let E ⊆ A be a stable extension of DG(T ), then Conc(E) is an extension of T .\nProof. Proof of part 1: Let E be an extension of T , then there exists a LPDT T+ := 〈D,W,<+〉 where <+ is a linerisation of < that generates the extension E (Equation 2.5). Consider the defeat graph DG (T+). By Theorem 3.14, there exists a stable extension E of DG (T+) such that Conc (E) = E. Arguing as\nin the proof of Theorem 4.9 where DG (T+) ⊆span DG(T ), E is also a stable extension of DG(T ), and it satisfies Conc (E) = E.\nProof of part 2: Let E be a stable extension, which exists by Theorem 4.9. By Lemma 4.10, there is a linearisation <+SP of <SP such that Algorithm 1 returns E upon input <+SP . Consider the LPDT T + 1 := 〈 D,W,<+1 〉 , where <+1 ∼=<+SP . By Section 3, this has a defeat graph DG ( T+1 ) with unique stable extension E . The set Conc (E) is an extension of T+1 by Theorem 3.14. Clearly Conc (E) is also an extension of 〈D,W,<1〉, where <1 ∼= <SP . By Lemma 4.5, Conc (E) is also an extension of 〈D,W,<〉 = T .\nUnder the generalised SP argument preference-SP , this representation theorem means that PDL is also sound and complete with respect to its argumentation semantics in the case where the default priority < is not necessarily total."
    }, {
      "heading" : "4.3 Satisfaction of Rationality Postulates",
      "text" : "In this section we will state and prove a version of Theorem 3.20, which is that the rationality postulates [10] hold for the stable extensions of the defeat graph, instead for all complete extensions. We will discuss the possibility for a general proof in Section 5.\nTheorem 4.12. (Rationality Theorem for Stable Extensions) Let T := 〈D,W,<〉 be a PDT. Let its corresponding attack graph be AG(T ) := 〈A,⇀,-SP 〉 where < ∼= <D 7→ <SP by Equation 4.3, and -SP is defined in terms of <SP using Equations 4.4 and 4.5. Let DG(T ) := 〈A, →֒〉 be the corresponding defeat graph. All stable extensions of DG(T ) satisfy the Caminada-Amgoud rationality postulates.\nProof. Given T , let E be any stable extension of DG(T ).\n1. To show that E is subargument closed, let A ∈ E and let B ⊆arg A. Assume for contradiction that B /∈ E , then E →֒ B and hence there is some C ∈ E such that C →֒ B. Therefore, C →֒ A. This means E is not cf – contradiction. Therefore, B ∈ E as well, and E is thus subargument closed.\n2. Theorem 4.11 states that Conc (E) is an extension of T , which is deductively closed. Therefore, Conc (E) is closed under strict rules.\n3. As W is consistent and Conc (E) is an extension of T , Conc (E) must also be consistent and its deductive closure is consistent.\nThis shows the result.\nIn conclusion, all stable extensions are normatively rational. This generalises the rationality theorem (Theorem 3.20) to the case where <D is partial, although only for stable extensions."
    }, {
      "heading" : "4.4 Summary",
      "text" : "In this section, we have generalised our sound and complete instantiation of ASPIC+ to PDL to the case where the default priority is not necessarily a total order. The main challenge is generalising the SP argument preference -SP from a total default priority to a partial default priority. We devise a sorting F (<D) =<SP such that <SP sorts <D in a way that respects the argument structure, the defeasible rule preference <D, and the incomparability of rules (Section 4.1). This preference has the correct properties to preserve the correspondence between the inferences of the underlying PDT and the conclusions of justified arguments (Section 4.2, Theorem 4.11). We have also shown that each stable extension satisfies the rationality postulates (Section 4.3, Theorem 4.12)."
    }, {
      "heading" : "5 Conclusions",
      "text" : "We have endowed Brewka’s PDL [7] with argumentation semantics using ASPIC+ [16]. This is achieved by representing PDL in ASPIC+ (Sections 3.1 and 4), discussing which argument preference relations can be suitable for the correspondence of inferences (Sections 3.2 and 4.1), proving that the inferences do correspond under an appropriate preference relation -SP (Sections 3.3 and 4.2), and that this instantiation is rational (Sections 3.4 and 4.3). As explained in Section 1, this allows us to interpret the inferences of PDL as conclusions of justified arguments, clarifying the reasons for accepting or rejecting a conclusion. The argumentative characterisation of PDL provides for distributed reasoning in the course of deliberation and persuasion dialogues. This would allow BOID agents with PDL representations of mental attitudes to exchange arguments and counterarguments when deliberating about which goals to select, and thus which actions to pursue [9]."
    }, {
      "heading" : "5.1 Related Work",
      "text" : "As mentioned in Section 1, there are many existing argumentative characterisations of non-monotonic logics (e.g. [11, 12]). However, there has been relatively little work in using defeasible rules to represent defaults, because the defeasible components of arguments are often captured in the premises [5, 16]. Reiter’s default logic (DL) [19], as a partial special case35 of Brewka’s PDL [7, Proposition 6], has been endowed with sound and complete argumentation semantics by Dung [11, Section 4.1]. However, DL cannot handle priorities and as a result draws counter-intuitive inferences. We know that conflicts between defaults often occur and priorities are an intuitive and high-level way of resolving such conflicts [7, 8]. It is therefore important to investigate how preferences can also be incorporated into any argumentation semantics. ASPIC+ is a good framework to achieve this because it is designed to handle preferences.\n35i.e. in the case where all defaults are normal defaults."
    }, {
      "heading" : "5.2 Future Work",
      "text" : "Brewka’s preferred subtheories (PS) [6] has been endowed with argumentation semantics by Modgil and Prakken using ASPIC+ [16, Section 5.3.2]. Given that PS is a special case of PDL [6], it is interesting to see how the argumentation semantics are related. It can be shown that instantiating the argumentation semantics of PDL in this paper to the case of supernormal defaults and empty facts will recover an argumentation semantics isomorphic to the argumentation semantics of Modgil and Prakken. However, whereas Modgil and Prakken assume that arguments must be consistent, the results of Section 3.4.3 lifts this assumption when we specialise our argumentation semantics. We will articulate this in future work.\nIt will also be interesting to see how an argumentation semantics for Reiter’s normal DL [19, Section 3] can be recovered by setting <D= ∅ [7, Proposition 6], and comparing this to Dung’s argumentation semantics for DL. However, Dung’s argumentation semantics also accommodates non-normal defaults. How would ASPIC+ incorporate non-normal defaults? At first glance it should involve the naming function and undercuts (Section 2.2), but how can soundness and completeness be proven? How can the argumentation semantics help us understand the interaction of explicit default priority relations with the implicit priority of non-normal defaults [21]? Future work will explore further properties of this argumentation semantics.\nASPIC+ can be used to generalise PDL. For example, we know that extensions do not have to exist for non-normal default logic, which corresponds to the failure for stable extensions to exist in the argumentation semantics [11, Section 4.1]. We can then consider the justified arguments under different Dung semantics, but what would these other notions of justified arguments mean for PDL?\nAnother reason for considering different Dung semantics is to show whether the rationality postualtes holds for complete extensions in general. So far we have shown a special case of rationality for the stable extensions only (Section 4.3). What would the complete extensions look like in this case? How are they related to the other Dung semantics [11, Section 2.3]? Alternatively, one can invoke the theory of ASPIC+, which states that normative rationality automatically follows if the instantiation is well-defined with a reasonable argument preference relation [16, Definitions 12 and 18]. Although it is easy to see that our instantiation is well-defined if the underlying PDT is consistent, it is not obvious whether -SP in the partial order case is reasonable. This will be the subject of future work.\nFinally, we have argued that endowing PDL with argumentation semantics provides for distributed reasoning amongst agents (in particular BOID agents for which PDL has been used to generate individual agents’ goals). Such distributed reasoning in the form of dialogue can be formalised as a generalisation of argument game proof theories for Dung frameworks [15], whereby agents not only can submit arguments, but locutions that implicitly define arguments providing the reasons for a given claim. We will investigate this in future work."
    } ],
    "references" : [ {
      "title" : "A Dialogue Game Protocol for Multi-Agent Argument over Proposals for Action",
      "author" : [ "K. Atkinson", "T. Bench-Capon", "P. McBurney" ],
      "venue" : "Autonomous Agents and Multi-Agent Systems, 11(2):153–171,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Ranking Sets of Objects",
      "author" : [ "S. Barberà", "W. Bossert", "P.K. Pattanaik" ],
      "venue" : "S. Barberà, P. J. Hammond, and C. Seidl, editors, Handbook of Utility Theory, Volume 2 – Extensions, chapter 17, pages pp. 893 – 978. Springer Science + Business Media, 1st edition,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Introduction to Structured Argumentation",
      "author" : [ "P. Besnard", "A. Garcia", "A. Hunter", "S. Modgil", "H. Prakken", "G. Simari", "F. Toni" ],
      "venue" : "Argument & Computation, 5(1):1–4,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Handbook of the History of Logic, volume 8, chapter Nonmonotonic Reasoning, pages 557–632",
      "author" : [ "A. Bochman" ],
      "venue" : "Elsevier,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "An abstract, argumentation-theoretic approach to default reasoning",
      "author" : [ "A. Bondarenko", "P.M. Dung", "R.A. Kowalski", "F. Toni" ],
      "venue" : "Artificial Intelligence, 93(1):63–101,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Preferred Subtheories: An Extended Logical Framework for Default Reasoning",
      "author" : [ "G. Brewka" ],
      "venue" : "IJCAI, volume 89, pages 1043–1048,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "Adding Priorities and Specificity to Default Logic",
      "author" : [ "G. Brewka" ],
      "venue" : "Logics in Artificial Intelligence, pages 247–260. Springer,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1994
    }, {
      "title" : "Prioritizing Default Logic",
      "author" : [ "G. Brewka", "T. Eiter" ],
      "venue" : "Intellectics and Computational Logic, pages 27–45. Springer,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Goal Generation in the BOID Architecture",
      "author" : [ "J. Broersen", "M. Dastani", "J. Hulstijn", "L. van der Torre" ],
      "venue" : "Cognitive Science Quarterly Journal,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2002
    }, {
      "title" : "On the Evaluation of Argumentation Formalisms",
      "author" : [ "M. Caminada", "L. Amgoud" ],
      "venue" : "Artificial Intelligence, 171(5):286–310,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "On the Acceptability of Arguments and its Fundamental Role in Nonmonotonic Reasoning, Logic Programming and n-Person Games",
      "author" : [ "P.M. Dung" ],
      "venue" : "Artificial Intelligence, 77:321–357,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Argumentation Semantics for Defeasible Logic",
      "author" : [ "G. Governatori", "M.J. Maher", "G. Antoniou", "D. Billington" ],
      "venue" : "Journal of Logic and Computation, 14(5):675–702,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "What does a conditional knowledge base entail",
      "author" : [ "D. Lehmann", "M. Magidor" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1992
    }, {
      "title" : "An Argumentation Based Semantics for Agent Reasoning",
      "author" : [ "S. Modgil" ],
      "venue" : "M. Dastani, A. El Fallah Seghrouchni, J. Leite, and P. Torroni, editors, Languages, Methodologies and Development Tools for Multi-Agent Systems, volume 5118 of Lecture Notes in Computer Science, pages 37–53. Springer Berlin Heidelberg,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Proof Theories and Algorithms for Abstract Argumentation Frameworks",
      "author" : [ "S. Modgil", "M. Caminada" ],
      "venue" : "Argumentation in Artificial Intelligence, pages 105–129. Springer,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A General Account of Argumentation with Preferences",
      "author" : [ "S. Modgil", "H. Prakken" ],
      "venue" : "Artificial Intelligence, 195:361–397, February",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2013
    }, {
      "title" : "The Added Value of Argumentation",
      "author" : [ "S. Modgil", "F. Toni" ],
      "venue" : "Agreement Technologies,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2013
    }, {
      "title" : "An Abstract Framework for Argumentation with Structured Arguments",
      "author" : [ "H. Prakken" ],
      "venue" : "Argument and Computation, 1(2):93–124,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A Logic for Default Reasoning",
      "author" : [ "R. Reiter" ],
      "venue" : "Artificial Intelligence, 13:81–132,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1980
    }, {
      "title" : "Nonmonotonic reasoning",
      "author" : [ "R. Reiter" ],
      "venue" : "Annual Review of Computer Science, 2:147–186,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1987
    }, {
      "title" : "On Interacting Defaults",
      "author" : [ "R. Reiter", "G. Criscuolo" ],
      "venue" : "IJCAI, volume 81, pages 270–276,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1981
    }, {
      "title" : "Logic and Artificial Intelligence”, The Stanford Encyclopedia of Philosophy (Winter 2013 Edition), Edward N. Zalta (ed.), forthcoming URL = 〈http://plato.stanford.edu/archives/win2013/entries/logic-ai/",
      "author" : [ "R. Thomason" ],
      "venue" : null,
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2013
    }, {
      "title" : "Argumentation Semantics for Prioritised Default Logic",
      "author" : [ "A.P. Young", "S. Modgil", "O. Rodrigues" ],
      "venue" : "arXiv preprint arXiv:1506.08813,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Prioritised Default Logic as Rational Argumentation",
      "author" : [ "A.P. Young", "S. Modgil", "O. Rodrigues" ],
      "venue" : "J. Thangarajah, K. Tuyls, C. Jonker, and S. Marsella, editors, Proceedings of the 15th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2016),",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 22,
      "context" : "27 The results of Section 3 first appeared in the preprint [23] and have been published in the conference proceedings of AAMAS2016 [24].",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 23,
      "context" : "27 The results of Section 3 first appeared in the preprint [23] and have been published in the conference proceedings of AAMAS2016 [24].",
      "startOffset" : 131,
      "endOffset" : 135
    }, {
      "referenceID" : 10,
      "context" : "Dung’s abstract argumentation theory [11] has become established as a means for unifying various nonmonotonic logics (NMLs) [4,20,22], where the inferences of a given NML can be interpreted as conclusions of justified arguments.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 3,
      "context" : "Dung’s abstract argumentation theory [11] has become established as a means for unifying various nonmonotonic logics (NMLs) [4,20,22], where the inferences of a given NML can be interpreted as conclusions of justified arguments.",
      "startOffset" : 124,
      "endOffset" : 133
    }, {
      "referenceID" : 19,
      "context" : "Dung’s abstract argumentation theory [11] has become established as a means for unifying various nonmonotonic logics (NMLs) [4,20,22], where the inferences of a given NML can be interpreted as conclusions of justified arguments.",
      "startOffset" : 124,
      "endOffset" : 133
    }, {
      "referenceID" : 21,
      "context" : "Dung’s abstract argumentation theory [11] has become established as a means for unifying various nonmonotonic logics (NMLs) [4,20,22], where the inferences of a given NML can be interpreted as conclusions of justified arguments.",
      "startOffset" : 124,
      "endOffset" : 133
    }, {
      "referenceID" : 10,
      "context" : "This has already been done for default logic [11], logic programming [11], defeasible logic [12] and preferred subtheories [16].",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 10,
      "context" : "This has already been done for default logic [11], logic programming [11], defeasible logic [12] and preferred subtheories [16].",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 11,
      "context" : "This has already been done for default logic [11], logic programming [11], defeasible logic [12] and preferred subtheories [16].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 15,
      "context" : "This has already been done for default logic [11], logic programming [11], defeasible logic [12] and preferred subtheories [16].",
      "startOffset" : 123,
      "endOffset" : 127
    }, {
      "referenceID" : 14,
      "context" : "This allows the application of argument game proof theories [15] to the process of inference in these NMLs, and the generalisation of these dialectical proof theories to distributed reasoning amongst computational agents, where agents can engage in argumentation-based dialogues [1, 14, 17].",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 0,
      "context" : "This allows the application of argument game proof theories [15] to the process of inference in these NMLs, and the generalisation of these dialectical proof theories to distributed reasoning amongst computational agents, where agents can engage in argumentation-based dialogues [1, 14, 17].",
      "startOffset" : 279,
      "endOffset" : 290
    }, {
      "referenceID" : 13,
      "context" : "This allows the application of argument game proof theories [15] to the process of inference in these NMLs, and the generalisation of these dialectical proof theories to distributed reasoning amongst computational agents, where agents can engage in argumentation-based dialogues [1, 14, 17].",
      "startOffset" : 279,
      "endOffset" : 290
    }, {
      "referenceID" : 16,
      "context" : "This allows the application of argument game proof theories [15] to the process of inference in these NMLs, and the generalisation of these dialectical proof theories to distributed reasoning amongst computational agents, where agents can engage in argumentation-based dialogues [1, 14, 17].",
      "startOffset" : 279,
      "endOffset" : 290
    }, {
      "referenceID" : 2,
      "context" : "Abstract argumentation has been upgraded to structured argumentation theory [3], one example of which is the ASPIC framework for structured argumentation [16].",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 15,
      "context" : "Abstract argumentation has been upgraded to structured argumentation theory [3], one example of which is the ASPIC framework for structured argumentation [16].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 9,
      "context" : "The advantages of ASPIC are that the framework provides a systematic and general method of endowing non-monotonic logics with argumentation semantics, and identifies sufficient conditions on the underlying logic and preference relations that guarantee the satisfaction of various normatively rational desiderata [10].",
      "startOffset" : 312,
      "endOffset" : 316
    }, {
      "referenceID" : 6,
      "context" : "This paper endows Brewka’s prioritised default logic (PDL) [7] with argumentation semantics.",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 18,
      "context" : "PDL is an important NML because it upgrades default logic (DL) [19] with an explicit priority relation over defaults, so that, for example, one can account for recent information taking priority over information in the distant past.",
      "startOffset" : 63,
      "endOffset" : 67
    }, {
      "referenceID" : 8,
      "context" : "PDL has also been used to represent the (possibly conflicting) beliefs, obligations, intentions and desires (BOID) of agents, and model how these different categories of mental attitudes override each other in order to generate goals and actions that attain those goals [9].",
      "startOffset" : 270,
      "endOffset" : 273
    }, {
      "referenceID" : 9,
      "context" : "We then investigate some properties and directly prove that the normative rationality postulates of [10] are satisfied (Section 3.",
      "startOffset" : 100,
      "endOffset" : 104
    }, {
      "referenceID" : 9,
      "context" : "2) and prove a partial result concerning the satisfaction of the rationality postulates of [10] (Section 4.",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 10,
      "context" : "2 The ASPIC Framework Abstract argumentation abstracts from the internal logical structure of arguments, the nature of defeats and how they are determined by preferences, and consideration of the conclusions of the arguments [11].",
      "startOffset" : 225,
      "endOffset" : 229
    }, {
      "referenceID" : 9,
      "context" : "However, these features are referenced when studying whether any given logical instantiation of a framework yields complete extensions that satisfy the rationality postulates of [10].",
      "startOffset" : 178,
      "endOffset" : 182
    }, {
      "referenceID" : 15,
      "context" : "ASPIC [16] provides a structured account of abstract argumentation, allowing one to reference the above features, while at the same time accommodating a wide range of instantiating logics and preference relations in a principled manner.",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 9,
      "context" : "ASPIC then identifies conditions under which complete extensions defined by the arguments, attacks and preferences, satisfy the rationality postulates of [10].",
      "startOffset" : 154,
      "endOffset" : 158
    }, {
      "referenceID" : 10,
      "context" : "We now recap the key definitions of [11].",
      "startOffset" : 36,
      "endOffset" : 40
    }, {
      "referenceID" : 9,
      "context" : "Instantiations of ASPIC should satisfy some properties to ensure they are rational [10].",
      "startOffset" : 83,
      "endOffset" : 87
    }, {
      "referenceID" : 15,
      "context" : "Given an instantiation let 〈A, ⇀, -〉 be its ASPIC attack graph Note that [16] studies two different notions of cf sets: one where no two arguments attack each other, and the other where no two arguments defeat each other.",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 17,
      "context" : "in [18].",
      "startOffset" : 3,
      "endOffset" : 7
    }, {
      "referenceID" : 1,
      "context" : "Note there are many other ways to lift a preference < on a set of objects X to compare subsets of X in various ways that are “compatible” with < [2].",
      "startOffset" : 145,
      "endOffset" : 148
    }, {
      "referenceID" : 6,
      "context" : "3 Brewka’s Prioritised Default Logic In this section we recap Brewka’s prioritised default logic (PDL) [7].",
      "startOffset" : 103,
      "endOffset" : 106
    }, {
      "referenceID" : 6,
      "context" : "first order formulae without free variables 8 We have defined the order dually to [7] so as to comply with orderings over the ASPIC defeasible inference rules.",
      "startOffset" : 82,
      "endOffset" : 85
    }, {
      "referenceID" : 9,
      "context" : "We now prove that this instantiation of ASPIC to PDL satisfies the requirements for normative rationality [10].",
      "startOffset" : 106,
      "endOffset" : 110
    }, {
      "referenceID" : 9,
      "context" : "20, which is that the rationality postulates [10] hold for the stable extensions of the defeat graph, instead for all complete extensions.",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 6,
      "context" : "5 Conclusions We have endowed Brewka’s PDL [7] with argumentation semantics using ASPIC [16].",
      "startOffset" : 43,
      "endOffset" : 46
    }, {
      "referenceID" : 15,
      "context" : "5 Conclusions We have endowed Brewka’s PDL [7] with argumentation semantics using ASPIC [16].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 8,
      "context" : "This would allow BOID agents with PDL representations of mental attitudes to exchange arguments and counterarguments when deliberating about which goals to select, and thus which actions to pursue [9].",
      "startOffset" : 197,
      "endOffset" : 200
    }, {
      "referenceID" : 10,
      "context" : "[11, 12]).",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 11,
      "context" : "[11, 12]).",
      "startOffset" : 0,
      "endOffset" : 8
    }, {
      "referenceID" : 4,
      "context" : "However, there has been relatively little work in using defeasible rules to represent defaults, because the defeasible components of arguments are often captured in the premises [5, 16].",
      "startOffset" : 178,
      "endOffset" : 185
    }, {
      "referenceID" : 15,
      "context" : "However, there has been relatively little work in using defeasible rules to represent defaults, because the defeasible components of arguments are often captured in the premises [5, 16].",
      "startOffset" : 178,
      "endOffset" : 185
    }, {
      "referenceID" : 18,
      "context" : "Reiter’s default logic (DL) [19], as a partial special case of Brewka’s PDL [7, Proposition 6], has been endowed with sound and complete argumentation semantics by Dung [11, Section 4.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 6,
      "context" : "We know that conflicts between defaults often occur and priorities are an intuitive and high-level way of resolving such conflicts [7, 8].",
      "startOffset" : 131,
      "endOffset" : 137
    }, {
      "referenceID" : 7,
      "context" : "We know that conflicts between defaults often occur and priorities are an intuitive and high-level way of resolving such conflicts [7, 8].",
      "startOffset" : 131,
      "endOffset" : 137
    }, {
      "referenceID" : 5,
      "context" : "2 Future Work Brewka’s preferred subtheories (PS) [6] has been endowed with argumentation semantics by Modgil and Prakken using ASPIC [16, Section 5.",
      "startOffset" : 50,
      "endOffset" : 53
    }, {
      "referenceID" : 5,
      "context" : "Given that PS is a special case of PDL [6], it is interesting to see how the argumentation semantics are related.",
      "startOffset" : 39,
      "endOffset" : 42
    }, {
      "referenceID" : 20,
      "context" : "2), but how can soundness and completeness be proven? How can the argumentation semantics help us understand the interaction of explicit default priority relations with the implicit priority of non-normal defaults [21]? Future work will explore further properties of this argumentation semantics.",
      "startOffset" : 214,
      "endOffset" : 218
    }, {
      "referenceID" : 14,
      "context" : "Such distributed reasoning in the form of dialogue can be formalised as a generalisation of argument game proof theories for Dung frameworks [15], whereby agents not only can submit arguments, but locutions that implicitly define arguments providing the reasons for a given claim.",
      "startOffset" : 141,
      "endOffset" : 145
    } ],
    "year" : 2016,
    "abstractText" : "We express Brewka’s prioritised default logic (PDL) as argumentation using ASPIC. By representing PDL as argumentation and designing an argument preference relation that takes the argument structure into account, we prove that the conclusions of the justified arguments correspond to the PDL extensions. We will first assume that the default priority is total, and then generalise to the case where it is a partial order. This provides a characterisation of non-monotonic inference in PDL as an exchange of argument and counter-argument, providing a basis for distributed non-monotonic reasoning in the form of dialogue.",
    "creator" : "LaTeX with hyperref package"
  }
}