{
  "name" : "1412.1044.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "Problem Theory",
    "authors" : [ "Ramón Casares" ],
    "emails" : [ "papa@ramoncasares.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n41 2.\n10 44\nv6 [\ncs .A\nI] 2\nS ep\n2 01\n6\nProblem Theory\nRamón Casares\norcid: 0000-0003-4973-3128\nThe Turing machine, as it was presented by Turing himself, models\nthe calculations done by a person. This means that we can com-\npute whatever any Turing machine can compute, and therefore we\nare Turing complete. The question addressed here is why, Why\nare we Turing complete? Being Turing complete also means that\nsomehow our brain implements the function that a universal Turing\nmachine implements. The point is that evolution achieved Turing\ncompleteness, and then the explanation should be evolutionary, but\nour explanation is mathematical. The trick is to introduce a mathe-\nmatical theory of problems, under the basic assumption that solving\nmore problems provides more survival opportunities. So we build\na problem theory by fusing set and computing theories. Then we\nconstruct a series of resolvers, where each resolver is defined by its\ncomputing capacity, that exhibits the following property: all prob-\nlems solved by a resolver are also solved by the next resolver in the\nseries if certain condition is satisfied. The last of the conditions\nis to be Turing complete. This series defines a resolvers hierarchy\nthat could be seen as a framework for the evolution of cognition.\nThen the answer to our question would be: to solve most problems.\nBy the way, the problem theory defines adaptation, perception, and\nlearning, and it shows that there are just three ways to resolve any\nproblem: routine, trial, and analogy. And, most importantly, this\ntheory demonstrates how problems can be used to found mathe-\nmatics and computing on biology.\nKeywords: problem solving; adaptation, perception & learning; Turing\ncompleteness; resolvers hierarchy; evolution of cognition.\nThis is arXiv:1412.1044 version 20160902, and it is licensed as cc-by. Any comments on it to papa@ramoncasares.com are welcome.\nProblem Theory\n§1 Introduction . . . . . . . . . . . . . . . . . . . . . . . 3\n§1.1 Object . . . . . . . . . . . . . . . . . . . . . . . . . 3 §1.2 Contents . . . . . . . . . . . . . . . . . . . . . . . . 4\n§2 Theory . . . . . . . . . . . . . . . . . . . . . . . . . 5\n§2.1 Problem . . . . . . . . . . . . . . . . . . . . . . . . 5 §2.2 Solution . . . . . . . . . . . . . . . . . . . . . . . . 6 §2.3 Resolution . . . . . . . . . . . . . . . . . . . . . . . 6 §2.4 Eight Concepts . . . . . . . . . . . . . . . . . . . . . . 7\n§3 Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n§3.1 Problems . . . . . . . . . . . . . . . . . . . . . . . . 7 §3.2 Solutions . . . . . . . . . . . . . . . . . . . . . . . . 9 §3.3 Routines and Trials . . . . . . . . . . . . . . . . . . . 11 §3.4 Analogies . . . . . . . . . . . . . . . . . . . . . . . 12 §3.5 Metaproblems . . . . . . . . . . . . . . . . . . . . . 14 §3.6 Resolution Typology . . . . . . . . . . . . . . . . . . . 16\n§4 Computers . . . . . . . . . . . . . . . . . . . . . . . . 17\n§4.1 Turing Machine . . . . . . . . . . . . . . . . . . . . . 17 §4.2 Turing Completeness . . . . . . . . . . . . . . . . . . . 19 §4.3 Turing’s Thesis . . . . . . . . . . . . . . . . . . . . . 22 §4.4 Full Resolution Machine . . . . . . . . . . . . . . . . . 24 §4.5 Problem Topology . . . . . . . . . . . . . . . . . . . . 27\n§5 Resolvers . . . . . . . . . . . . . . . . . . . . . . . . 29\n§5.1 Semantics and Syntax . . . . . . . . . . . . . . . . . . 29 §5.2 Mechanism . . . . . . . . . . . . . . . . . . . . . . 31 §5.3 Adapter . . . . . . . . . . . . . . . . . . . . . . . 32 §5.4 Perceiver . . . . . . . . . . . . . . . . . . . . . . . 34 §5.5 Learner . . . . . . . . . . . . . . . . . . . . . . . 36 §5.6 Subject . . . . . . . . . . . . . . . . . . . . . . . 38 §5.7 Resolvers Hierarchy . . . . . . . . . . . . . . . . . . . 39\n§6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . 41\n§6.1 Purpose . . . . . . . . . . . . . . . . . . . . . . . 41 §6.2 Countability . . . . . . . . . . . . . . . . . . . . . . 42 §6.3 Intuition . . . . . . . . . . . . . . . . . . . . . . . 43\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . 44\n§1 Introduction\nDevoid of problems, thinking is useless.\nWarning This paper does not explain how to solve, nor how to resolve, any problem.\n§1.1 Object ¶1 · The object of this paper is to present a mathematical theory of problems. The resulting problem theory provides meaning to set theory and to computing theory. ¶2 · Problems are nearly everywhere. We can say that mathematics is all about mathematical problems, but also that physics is all about physical problems, and philosophy is all about philosophical problems. I said nearly because there are not problems in a river; a river just flows. So, where are problems? ¶3 · This problem theory gives an answer: There are problems where there is freedom. Determinists will surely object, but they should note that if there were only uncertainty, and not the possibility of doing otherwise, then problem resolving would be purposeless and absurd. Nevertheless, in this theory freedom cannot exist by itself, but freedom is always limited by a condition and both together, freedom and a condition, are a problem. In fact, the resolution of any problem is the process of spending all of its freedom while still satisfying the condition. So resolving is fighting freedom away. And, if people fight for freedom, it is because we want problems; in fact, not having any problem is boring. But I would say more, we are devices exquisitely selected to resolve problems, because surviving is literally the problem of being dead or alive: “To be, or not to be—that is the question.” ¶4 · I am digressing, sorry! The point is that problems are related to sets at the very bottom: for each problem there is a condition that determines if anything is a solution to it or not, so for each problem there is a set, the set of its solutions, and the condition is its characteristic function. This means that problems and sets are just two names for the same thing. So problem theory, being just a rewording of set theory, would be a better foundation for mathematics than set theory, because problems are more related to thinking than sets are. ¶5 · We have just seen how problems and solutions fit with sets, but we have seen nothing about resolutions, that is, the ways to go from a problem to its solutions. It is a fact that computing is helping us in resolving many problems. Perhaps too many: How our modern society would subsist without computers? I am digressing again, sorry! The right question is: What is the relation between problem resolving and computing? ¶6 · Computing is the mechanical manipulation of strings of symbols. Mechanical in the sense that the manipulations do not take into account the meaning of the symbols, but they just obey blindly a finite set of well-defined rules. Being meaningless, what could be the purpose of computing? Historically, computing resulted from two apparently different pursuits: the foundation of mathematics, and the enhancement of calculating machines. The second, the development of mechanical aids to calculation, is easier to understand. When we learn the algorithm for division we readily appreciate that those fixed rules can be better applied by a machine than by a person. This explains why an arithmetic calculator comes handy when resolving a problem that requires performing a numerical division. And it could also help us to understand why computation was seen as the ideal for mathematical rigor, and then how computing relates to the foundations of mathematics.\n¶7 · But, again, what is the purpose of mathematical formalization? Is it true that a complete formalization of mathematics would render it meaningless? What would be the use of something meaningless? And again, the arithmetic calculator, dividing for us, answers the three questions: formalization prevents mistakes and assures that nothing has been taken for granted, and, while it is literally meaningless, it is not useless if the formalism helps us in resolving problems. Though pending on an if, formalism is not yet lost. This paper cuts that Gordian knot by showing that problem resolving is computing.\n¶8 · In fact, that ‘resolving is computing’ comes from the founding paper of computing. Turing (1936) proved that the Entscheidungsproblem, which is the German word for ‘decision problem’, is unsolvable, because it cannot be solved by any Turing machine. For this proof to be valid, ‘solved by a Turing machine’ has to be equal to ‘solved’, and therefore ‘resolved by computing’ has to be redundant.\n¶9 · Summarizing, a problem is a set, and resolving is computing. This is how this problem theory relates to set and computing theories at the highest level of abstraction. For a more detailed view you should continue reading this paper.\n§1.2 Contents\n¶1 · The object of this paper is to introduce a mathematical theory of problems. Because our approach is minimalist, aiming to keep only what is essential, we will define a problem theory from first principles. Section §2 contains this problem theory, including its eight concepts: problem, with freedom and condition; resolution, with routine, trial and analogy; and solution. Some care is advisable to distinguish ‘solution’ from ‘resolution’, because while they are usually considered synonyms, they are very distinct concepts in this theory: a solution is a state, and a resolution is a transition. Then that ‘a problem is resolved unsolvable’ achieves a very precise meaning.\n¶2 · Section §3 translates the problem theory to set theory. Subsection §3.1 defines what a problem is, and what is the set of its solutions is defined in Subsection §3.2. Then, in Subsection §3.3, we develop the first two ways to resolve a problem, by routine and by trial, while we devote Subsection §3.4 to the third way, by analogy. The conclusion of these two subsections is that there is a general form that includes the three forms. Then we observe that looking for a resolution to a problem is also a problem, the metaproblem, so Subsection §3.5 deals with metaproblems. The last subsection of this section, Subsection §3.6, shows that there is only one level of problem meta-ness and that there are five types of resolution. ¶3 · The next section, Section §4, is about computing. In Subsection §4.1 we present the Turing machine, concluding that all computing is inside countable sets. In Subsection §4.2 we deal with universal computers and Turing completeness. Then, in Subsection §4.3, we explain that Turing’s thesis implies that everything is an expression, that resolving is computing, and that all problem sets are countable. In Subsection §4.4, we introduce the full resolution machine, and we show some equivalences between problem theory and computing theory. In the last subsection of this section, Subsection §4.5, we show that there are five types of problem.\n¶4 · Section §5 is about resolvers, that is, devices that resolve problems. In the first subsection, §5.1, we present the practical scenario, where functions are not solutions, so we distinguish the semantics of solutions from the syntax of functions, and we define the range of a resolver as the set of problems that the resolver solves, and the power of a\nresolver as the set of problems that the resolver resolves. Then we construct a series of five resolvers: ◦ Mechanism, Subsection §5.2, is any device that implements a semantic unconditional computation. We show that mechanisms can resolve problems by routine.\n◦ Adapter, in §5.3, is any device that implements a semantic conditional computation. We show that adapters can resolve problems by trial. ◦ Perceiver, in §5.4, is any device that implements a semantic functional computation or a syntactic unconditional computation. We show that perceivers can resolve problems by analogy and metaproblems by routine. ◦ Learner, in §5.5, is any device that implements a syntactic conditional computation. We show that learners can resolve metaproblems by trial. ◦ Subject, in §5.6, is any device that implements a syntactic functional computation. We show that subjects can resolve metaproblems by analogy.\nIn addition, we show that the range and power of each resolver in the series includes the range and power of the previous one, provided that a specific condition is satisfied. The last of these conditions requires the subject to be Turing complete. So, in the last subsection of this section, §5.7, we summarize the findings of the section: we show that there is a hierarchy of five types of resolver, and that the problem theory is complete. The theory is complete because Turing completeness is the maximum computing capacity, and this means that there are exactly three ways to resolve any problem: routine, trial, and analogy. Finally, we argue that we are the Turing complete subjects that have resulted from an evolution of resolvers of the survival problem.\n¶5 · The paper finishes with some conclusions, in Section §6. In the first subsection, §6.1, we explain how problem theory provides purpose and meaning to set theory and to computing theory. In the next subsection, §6.2, we argue that countableness is the golden mean that keeps paradoxes under control. And in the last subsection, §6.3, we explore what would be the implications of non-computable ways of resolving, as intuition.\n§2 Theory\n§2.1 Problem ¶1 · Every problem is made up of freedom and of a condition. There have to be possibilities and freedom to choose among them, because if there is only necessity and fatality, then there is neither a problem nor is there a decision to make. The different possible options could work, or not, as solutions to the problem, so that in every problem a certain condition that will determine if an option is valid or not as a solution to the problem must exist.\nProblem {\nFreedom Condition\n§2.2 Solution ¶1 · A fundamental distinction that we must make is between the solution and the resolution of a problem. Resolving is to searching as solving is to finding, and please note that one can search for something that does not exist.\nResolving · Searching Solving · Finding\nThus, resolution is the process that attempts to reach the solutions to the problem, while a solution of the problem is any use of freedom that satisfies the condition. In the statetransition jargon: a problem is a state of ignorance, a solution is a state of satisfaction, and a resolution is a transition from uncertainty to certainty.\nProblem Resolution−−−−−−−−−−−−→ Solution\n¶2 · We can explain this with another analogy. The problem is defined by the tension that exists between two opposites: freedom, free from any limits, and the condition, which is pure limit. This tension is the cause of the resolution process. But once the condition is fulfilled and freedom is exhausted, the solution annihilates the problem. The resolution is, then, a process of annihilation that eliminates freedom as well as the condition of the problem, in order to produce the solution.\nFreedom Condition ︸ ︷︷ ︸\nProblem\n} Resolution−−−−−−−−−−−−→ Solution\n¶3 · A mathematical example may also be useful in order to distinguish resolution from solution. In a problem of arithmetical calculation, the solution is a number and the resolution is an algorithm such as the algorithm for division, for example.\n§2.3 Resolution ¶1 · There are three ways to resolve a problem: routine, trial, and analogy.\nResolution\n \n Routine Trial Analogy\n¶2 · To resolve a problem by routine, that is, by knowing or without reasoning, it is necessary to know the solutions, and it is necessary to know that they solve that problem. ¶3 · If the solutions to a problem are not known, but it is known a set of possible solutions, then we can use a trial and error procedure, that is, we can try the possible solutions. To resolve by trial is to test each possible solution until the set of possible solutions is exhausted or a halting condition is met. There are two tasks when we try: to test if a particular possibility satisfies the problem condition, and to govern the process determining the order of the tests and when to halt. There are several ways to govern the process, that is, there is some freedom in governing the trial, and so, if we also put\na condition on it, for example a temporal milestone, then governing is a problem. And there are three ways to resolve a problem (da capo). ¶4 · By analogy we mean to transform a problem into a different one, called question, which is usually composed of several subproblems. This works well if the subproblems are easier to resolve than the original problem. There are usually several ways to transform any problem (there is freedom), but only those transformations that result in questions that can be resolved are valid (which is a condition), so applying an analogy to a problem is a problem. There are three ways to resolve the analogy, the question, and each of its subproblems: routine, trial, and analogy (da capo). If we could translate a problem into an analogue question, and we could find a solution to that question, called answer, and we could perform the inverse translation on it, then we would have found a solution to the original problem.\nProblem Solution ↓ ↑ Question −→ Answer\n§2.4 Eight Concepts ¶1 · Lastly we are ready to list the eight concepts of the problem theory. They are: problem, with freedom and condition; resolution, with routine, trial, and analogy; and solution.\nProblem Theory\n \n \nProblem {\nFreedom Condition\nResolution\n \n Routine Trial Analogy\nSolution\n§3 Sets\n§3.1 Problems\n§3.1.1 Notation We will refer to the set of problems as P. We will refer to the set of resolutions as R. We will refer to the set of solutions as S.\nDefinition A resolution takes a problem and returns the set of the solutions to the problem. Then resolutions are R = P → 2S, where 2S is the powerset, or the set of the subsets, of S.\n§3.1.2 Notation ⊤ stands for ‘true’, and ⊥ for ‘false’. We will refer to the set of these Boolean values as B. B = {⊤,⊥}. Comment ⊤ = ¬⊥ and ⊥ = ¬⊤. Also [P = ⊤] = P and [P = ⊥] = ¬P . §3.1.3 Notation Given s ∈ S ⊆ S and f ∈ F ⊆ (S → S), so f : S → S and f(s) ∈ S,\nwe will use the following rewriting rules: f(S) = { f(s) | s ∈ S }, F (s) = { f(s) | f ∈ F }, and F (S) = { f(s) | s∈S × f ∈F }.\nComment As f(s) ∈ S, then f(S) ∈ 2S, F (s) ∈ 2S, and F (S) ∈ 2S. Proposition If s ∈ S and f ∈ F , then f(S) ⊆ F (S) and F (s) ⊆ F (S).\n§3.1.4 Definition Problem π is x?Pπ(x), where Pπ is any predicate, or Boolean-valued function, on S; so Pπ : S → B, where Pπ(x) = ⊤ means that x is a solution of π, and Pπ(x) = ⊥ means that x is not a solution of π.\nComment A problem π = x?Pπ(x) is made up of freedom and of a condition, as defined in Section §2. The condition is Pπ, and freedom is represented by the free variable x, which is free to take any value in S, x ∈ S.\n§3.1.5 Definition A function ∗f is effectively calculable if there is a purely mechanical process to find ∗f(s) for any s. Comment This definition of effective calculability was stated by Turing (1938), §2. Comment If the result of the calculation is finite, then an effective calculation has to\ncomplete it. If the result of the calculation is infinite, then an effective calculation has to proceed forever towards the result.\nNotation We will refer to the set of effectively calculable functions as ∗F.\n§3.1.6 Definition A problem π is expressible if its condition Pπ is an effectively calculable function. Comment The result of a condition is in set B = {⊤,⊥}, so it is always finite. Therefore a problem is not expressible if for some x we cannot calculate whether x is a solution or not in a finite time.\n§3.1.7 Definition The condition isomorphism is the natural isomorphism that relates each problem π with its condition Pπ: for each predicate P there is a problem, x?P (x), and for each problem, π = x?Pπ(x) there is a predicate, Pπ. That is, P ⇔ (S → B) : x?Pπ(x) ↔ Pπ.\nComment Using the condition isomorphism, two problems are equal if they have the same condition, that is, π = ρ ⇔ Pπ = Pρ.\nComment The condition isomorphism abstracts freedom away.\n§3.1.8 Theorem The set of problems is the set of predicates, that is, P = S → B. Proof P ∼= S → B, by the condition isomorphism, see §3.1.7, and, abstracting freedom,\nP = S → B. But freedom has to be abstracted away from mathematics because freedom is free of form and it cannot be counted nor measured. ⋄\nComment Although in mathematics we cannot deal with freedom, it is an essential part of problems, see §2.1. In any case, what defines problem π is its condition Pπ.\n§3.1.9 Lemma The name of the free variable is not important, it can be replaced: x?P (x) = y?P (y). Proof By the condition isomorphism, and §3.1.8, both problems, x?P (x) and y?P (y), are equal, x?P (x) = y?P (y), because they have the same condition, P . ⋄\nComment This means that the rule of α-conversion stands for problem expressions. See Curry & Feys (1958), Section 3D.\n§3.1.10 Definition Let π and ρ be two problems. Then π∧ρ = x?Pπ(x)∧Pρ(x), and π ∨ ρ = x?Pπ(x) ∨ Pρ(x), and π̄ = x?¬Pπ(x). Comment In other words, Pπ∧ρ(x) = Pπ(x) ∧ Pρ(x), Pπ∨ρ(x) = Pπ(x) ∨ Pρ(x), and Pπ̄(x) = ¬Pπ(x).\nComment This provides a way to compose, or decompose, problems.\n§3.1.11 Definition A problem τ is tautological if its condition is a tautology; Pτ is a tautology, if ∀x, Pτ (x) = ⊤. A problem τ̄ is contradictory if its condition is a contradiction; Pτ̄ is a contradiction, if ∀x, Pτ̄ (x) = ⊥.\nLemma Both τ and τ̄ are expressible. Proof Because Pτ and Pτ̄ are effectively calculable, see §3.1.6 and §3.1.5. ⋄\n§3.1.12 Theorem 〈P,∨,∧,¬, τ̄ , τ〉 is a Boolean algebra, where τ̄ is the neutral for ∨, and τ is the neutral for ∧. Proof Because Pπ(x) ∈ B. In detail, ∀π, ρ, σ ∈ P: 1o. (π ∨ ρ) ∨ σ = x?Pπ∨ρ(x) ∨ Pσ(x) = x? (Pπ(x) ∨ Pρ(x)) ∨ Pσ(x) =\nx?Pπ(x) ∨ (Pρ(x) ∨ Pσ(x)) = x?Pπ(x) ∨ Pρ∨σ(x) = π ∨ (ρ ∨ σ). 1a. (π ∧ ρ) ∧ σ = x?Pπ∧ρ(x) ∧ Pσ(x) = x? (Pπ(x) ∧ Pρ(x)) ∧ Pσ(x) = x?Pπ(x) ∧ (Pρ(x) ∧ Pσ(x)) = x?Pπ(x) ∧ Pρ∧σ(x) = π ∧ (ρ ∧ σ). 2o. π ∨ ρ = x?Pπ(x) ∨ Pρ(x) = x?Pρ(x) ∨ Pπ(x) = ρ ∨ π. 2a. π ∧ ρ = x?Pπ(x) ∧ Pρ(x) = x?Pρ(x) ∧ Pπ(x) = ρ ∧ π. 3o. π ∨ τ̄ = x?Pπ(x) ∨ Pτ̄ (x) = x?Pπ(x) ∨ ⊥ = x?Pπ(x) = π. 3a. π ∧ τ = x?Pπ(x) ∧ Pτ (x) = x?Pπ(x) ∧ ⊤ = x?Pπ(x) = π. 4o. π ∨ π̄ = x?Pπ(x) ∨ Pπ̄(x) = x?Pπ(x) ∨ ¬Pπ(x) = x?⊤ = x?Pτ (x) = τ . 4a. π ∧ π̄ = x?Pπ(x) ∧ Pπ̄(x) = x?Pπ(x) ∧ ¬Pπ(x) = x?⊥ = x?Pτ̄ (x) = τ̄ . 5o. π ∨ (ρ ∧ σ) = x?Pπ(x) ∨ Pρ∧σ(x) = x?Pπ(x) ∨ (Pρ(x) ∧ Pσ(x)) =\nx? (Pπ(x)∨Pρ(x))∧ (Pπ(x)∨Pσ(x)) = x?Pπ∨ρ(x)∧Pπ∨σ(x) = (π ∨ ρ)∧ (π ∨ σ). 5a. π ∧ (ρ ∨ σ) = x?Pπ(x) ∧ Pρ∨σ(x) = x?Pπ(x) ∧ (Pρ(x) ∨ Pσ(x)) =\nx? (Pπ(x)∧Pρ(x))∨ (Pπ(x)∧Pσ(x)) = x?Pπ∧ρ(x)∨Pπ∧σ(x) = (π ∧ ρ)∨ (π ∧ σ). ⋄\n§3.2 Solutions\n§3.2.1 Theorem Everything is in S. In other words, S is the set of everything. Proof Anything, let us call it s, is a solution to problem x? [x = s], because equality\nis reflexive, and therefore everything satisfies the condition of being equal to itself. ⋄ Comment Freedom is complete, because x is free to take any value; x ∈ S is not a\nrestriction. And Pπ : S → B is a predicate on everything. Comment Some paradoxes derive from this theorem, see §3.2.12. For a constructive\nvision of S, see Section §5. See also Subsection §6.2. Corollary P ⊂ S and R ⊂ S. Even B ⊂ S. Comment If you are a teacher looking for a problem to ask in an exam, then your\nsolution is a problem, so P ⊂ S makes sense. And if you are a mathematician looking for an algorithm to resolve some kind of problems, then your solution is a resolution, so R ⊂ S makes sense. There are many yes-or-no questions, so B ⊂ S makes sense.\n§3.2.2 Notation Let Σπ be the (possibly infinite) set of all the solutions to problem π. So Σπ ⊆ S, or Σπ ∈ 2S, and Σπ = { s | Pπ(s) }.\nComment A solution of the problem is any use of freedom that satisfies the condition, see Section §2, so s is a solution of problem π, if Pπ(s) stands.\nComment The condition of the problem π is the characteristic function of its set of solutions, that is, Pπ is the characteristic function of Σπ.\n§3.2.3 Lemma Σπ∨ρ = Σπ ∪ Σρ, and Σπ∧ρ = Σπ ∩ Σρ, and Σπ̄ = Σπ. Proof Just apply the definitions in §3.1.10:\nΣπ∨ρ = { s | Pπ∨ρ(s) } = { s | Pπ(s) ∨ Pρ(s) } = { s | s ∈ Σπ ∨ s ∈ Σρ } = Σπ ∪ Σρ. Σπ∧ρ = { s | Pπ∧ρ(s) } = { s | Pπ(s) ∧ Pρ(s) } = { s | s ∈ Σπ ∧ s ∈ Σρ } = Σπ ∩ Σρ. Σπ̄ = { s | Pπ̄(s) } = { s | ¬Pπ(s) } = { s | s /∈ Σπ } = Σπ. ⋄\n§3.2.4 Lemma For a tautological problem, x?Pτ (x), everything is a solution, Στ = S. For a contradictory problem, x?Pτ̄ (x), nothing is a solution, Στ̄ = ∅. Proof Στ = { s | Pτ (s) } = { s | ⊤ } = S. Στ̄ = { s | Pτ̄ (s) } = { s | ⊥ } = {} = ∅. ⋄\n§3.2.5 Lemma Σπ ∪ Σπ̄ = S and Σπ ∩ Σπ̄ = ∅. Proof Σπ ∪Σπ̄ = { s | Pπ(s) }∪ { s | ¬Pπ(s) } = { s | Pπ(s)∨¬Pπ(s) } = { s | ⊤ } = S.\nΣπ ∩ Σπ̄ = { s | Pπ(s) } ∩ { s | ¬Pπ(s) } = { s | Pπ(s) ∧ ¬Pπ(s) } = { s | ⊥ } = ∅. ⋄\n§3.2.6 Lemma The solutions of π ∧ ρ are solutions of π and of ρ. Proof ∀s ∈ S; s ∈ Σπ∧ρ ⇔ s ∈ Σπ ∩ Σρ ⇔ s ∈ Σπ ∧ s ∈ Σρ. ⋄ Comment The reader is free to explore this Boolean landscape, but here we will close\nwith the following theorems.\n§3.2.7 Theorem 〈2S,∪,∩,−, ∅, S〉 is a Boolean algebra, where ∅ is the neutral for ∪, and S is the neutral for ∩. Proof The powerset of a set M , with the operations of union ∪, intersection ∩, and complement with respect to setM , noted Q, is a typical example of a Boolean algebra. In detail, ∀Q,R, S ∈ 2S: 1o. (Q ∪ R) ∪ S = Q ∪ (R ∪ S). 1a. (Q ∩R) ∩ S = Q ∩ (R ∩ S). 2o. Q ∪ R = R ∪Q. 2a. Q ∩R = R ∩Q. 3o. Q ∪ ∅ = Q. 3a. Q ∩ S = Q. 4o. Q ∪Q = S. 4a. Q ∩Q = ∅. 5o. Q ∪ (R ∩ S) = (Q ∪ R) ∩ (Q ∪ S). 5a. Q ∩ (R ∪ S) = (Q ∩ R) ∪ (Q ∩ S). ⋄\n§3.2.8 Theorem 〈P,∨,∧,¬, τ̄ , τ〉 is isomorphic to 〈2S,∪,∩,−, ∅, S〉, that is, P ∼= 2S. Proof We define the bijection Σ that relates each problem π with the set of its solutions\nΣπ: for every problem π ∈ P there is a set, the set of its solutions, Σπ ∈ 2S, and for every set S ∈ 2S there is a problem, πS = x? [x ∈ S], where πS ∈ P. Now, by Lemma §3.2.3, the bijection translates properly all three operations, ∨ ↔ ∪, ∧ ↔ ∩, ¬ ↔ −, and, by Lemma §3.2.4, also the two neutrals, τ̄ ↔ ∅, τ ↔ S. ⋄ Comment We will call P ∼= 2S the set isomorphism. That is, P ⇔ 2S : π ↔ Σπ. Comment Using the set isomorphism, two problems are equal if they have the same\nsolutions, that is, π = ρ ⇔ Σπ = Σρ.\n§3.2.9 Theorem The set of problems is equal to the powerset of the solutions, that is, P = 2S. Proof The equality P = 2S derives directly from the set isomorphism P ∼= 2S, see §3.2.8, because no property was abstracted out. ⋄\n§3.2.10 Definition The set of singletons is: S1 = {S ∈ 2S | [ |S| = 1 ] }. Proposition S1 ⊂ 2S, because ∀S ∈ S1, S ∈ 2S, but ∅ ∈ 2S and ∅ /∈ S1.\n§3.2.11 Definition The singleton isomorphism is the isomorphism between S and S1 that relates each s ∈ S to the set {s} ∈ S1, and the converse. That is, S ∼= S1, and S ⇔ S1 : s ↔ {s}.\nComment We can extend any operation on S to S1. For example, for any binary operation ∗ on S, we define {a} ∗ {b} = {a ∗ b}. Comment From the singleton isomorphism: S ∼= S1 ⊂ 2S.\n§3.2.12 Lemma The set of solutions S is a proper subset of the set of problems P, that is, S ⊂ P. Proof By the singleton isomorphism, see §3.2.11, S ∼= S1, and, by the set isomorphism, see §3.2.8, for each singleton there is a problem, so S1 ⊂ P, and then S ∼= S1 ⊂ P. ⋄ Paradox We have both, S ⊂ P and, by §3.2.1, P ⊂ S. Comment If we only accept computable functions and computable sets, then S∗ 6⊂ P∗,\nsee Subsection §6.2.\n§3.2.13 Definition A problem π is solved if a solution of π is known. Comment To solve a problem, given the set of its solutions Σπ, a choice function\nfc : 2 S \\ ∅ → S is needed.\n§3.2.14 Definition A problem is unsolvable if Σπ = {} = ∅, that is, if |Σπ| = 0. A problem is solvable if |Σπ| > 0.\nComment If a problem has not any solution, then it is unsolvable. If a problem has a solution, then it can be solved. A problem is solvable if it can be solved. Comment Solved implies solvable, but not the converse: Solved ⇒ Solvable.\n§3.3 Routines and Trials\n§3.3.1 Definition We will refer to the routine of problem π as Rπ. The routine is the set of the solutions to the problem, a set that is known, see §2.3. Then Rπ = Σπ.\nComment The routine of problem π, Rπ, is then, or an extensive definition of Σπ, Σπ = {s1, . . . , sn}, or a procedure P that generates all problem π solutions and then halts. If the number of solutions is infinite, |Σπ| ≥ ℵ0, then Rπ has to be a procedure P that keeps generating solutions forever.\n§3.3.2 Definition A trial on problem π over the set of possible solutions S, written Tπ(S), returns the set of those elements in S that satisfy the problem condition Pπ, see §2.3. Then Tπ(S) = { s ∈ S | Pπ(s) }.\nComment Mathematically we will ignore the practical problem of governing the trial. Practically we will need a halt condition to truncate the calculations that are too long (or infinite), and some ordering on the tests to fit the execution of the tests to the available calculating machinery.\n§3.3.3 Definition To test if a possible solution s ∈ S is a solution to problem π, is to replace the free variable with s. So, being π = x?Pπ(x), then to test if s is a solution is to calculate Pπ(s). Comment Testing is a calculation S → B.\n§3.3.4 Remark Replacing variables in expressions requires not confusing free with bound variables, nor bound with free variables.\nComment This means that the rule of β-conversion and the rules γ for substitution stand for testing. See Curry & Feys (1958), Section 3D for β-conversion, and Section 3E for substitution (the rules γ).\n§3.3.5 Theorem A trial on problem π over the set S is equal to the intersection of S with the set of the solutions Σπ, that is, Tπ(S) = S ∩ Σπ. Proof Tπ(S) = { s ∈ S | Pπ(s) } = { s | s ∈ S ∧ Pπ(s) } = { s | s ∈ S ∧ s ∈ Σπ } = { s | s ∈ S } ∩ { s | s ∈ Σπ } = S ∩ Σπ. ⋄ Corollary Any trial is a subset of the set of solutions, Tπ(S) ⊆ Σπ. Proof Tπ(S) = S ∩ Σπ ⊆ Σπ. ⋄ Corollary Any trial is a subset of the routine, that is, Tπ(S) ⊆ Σπ = Rπ.\n§3.3.6 Lemma If S is a superset of Σπ, then a trial on problem π over S is equal to Σπ, and the converse, that is, Σπ ⊆ S ⇔ Tπ(S) = Σπ. Proof Σπ ⊆ S ⇔ S ∩ Σπ = Σπ ⇔ Tπ(S) = Σπ, using Theorem §3.3.5. ⋄ Corollary If S is a superset of Σπ, then a trial on problem π over S is equal to the\nroutine of π, and the converse, that is, Σπ ⊆ S ⇔ Tπ(S) = Rπ. Proof Σπ ⊆ S ⇔ S ∩ Σπ = Σπ ⇔ Tπ(S) = Rπ. ⋄ Corollary A trial on problem π over the whole S is equal to Σπ, that is, Tπ(S) = Σπ. Proof Because Σπ ⊆ S. ⋄ Comment Tπ(S) is an exhaustive search.\n§3.3.7 Theorem The routine is a trial over all the solutions, that is, Rπ = Tπ(Σπ). Proof By Theorem §3.3.5, Tπ(Σπ) = Σπ ∩ Σπ = Σπ = Rπ. ⋄ Comment Tπ(Rπ) = Tπ(Σπ) = Σπ = Rπ.\n§3.4 Analogies\n§3.4.1 Definition If A is an analogy, and π = x?Pπ(x) is a problem, then Aπ is another problem Aπ = x?PAπ(x). That is, A : P → P.\nComment So analogies transform a condition into a condition, Pπ into PAπ in this example. Comment Taking advantage of problem decomposition, see §3.1.10, the result of an analogy, Aπ, can be a composition of problems that are easier to resolve than the original problem, π, see §2.3.\n§3.4.2 Definition If Σπ = ΣAπ, then we say that the analogy is conservative. Comment If an analogy is not conservative, then a function TA to translate ΣAπ to Σπ\nis required, because otherwise the analogy would be useless.\n§3.4.3 Notation We will call function TA the translating function of analogy A. TA : 2S → 2S and TA(ΣAπ) = Σπ.\n§3.4.4 Lemma An analogy followed by another one is an analogy. Proof Because any analogy transforms a problem into a problem: P → P. ⋄ Corollary Analogies can be chained.\n§3.4.5 Lemma Using only analogies we cannot resolve any problem. Proof Because using analogies we only get problems. ⋄ Comment While routines R and trials T (S) are functions that return a set, P → 2S,\nanalogies A are functions that return a function, P → P. §3.4.6 Notation We will write A ◦ T to express the composition of functions, where\nA is applied first and then T .\nComment [A ◦ T ](x) = T (A(x)). Diagram: x A−−→A(x) T−−→T (A(x)). Comment If A1 and A2 are analogies, then A1◦A2 is also an analogy, by Lemma §3.4.4. §3.4.7 Definition To resolve a problem by analogy A is to compose A◦ℜ◦TA, where\nℜ is any resolution, and TA is the translating function of A. Diagrams:\nπ A−−→Aπ ℜ−−→ΣAπ TA−−→Σπ or P A−−→P ℜ−−→ 2S TA−−→ 2S .\nComment Analogy A is a translation from some original problem domain to some analogue problem domain. Then, by Lemma §3.4.5, we need a resolution ℜ to resolve the analogue problem. And, finally, we need to translate the solutions back to the original domain.\n§3.4.8 Lemma The translating function of the composition A ◦ A′ is TA′ ◦ TA. Proof If ℜ = A′ ◦ℜ′ ◦ TA′ then we get A ◦ (A′ ◦ℜ′ ◦ TA′) ◦ TA = A ◦A′ ◦ℜ′ ◦ TA′ ◦ TA =\n(A ◦ A′) ◦ ℜ′ ◦ (TA′ ◦ TA), because function composition is associative. Diagram:\nP A−−→P A\n′ −−→P ℜ ′ −−→ 2S TA′−−−→ 2S ︸ ︷︷ ︸\nℜ\nTA−−→ 2S. ⋄\nCorollary The translating function of the composition A1 ◦A2 . . . ◦An is TAn ◦ . . . ◦ TA2 ◦ TA1. That is: TA1◦A2...◦An = TAn ◦ . . . ◦ TA2 ◦ TA1 . Comment This is how analogies can be chained.\n§3.4.9 Definition The identity function, written I, transforms anything into itself: ∀x, I(x) = x. Comment The identity function I is an effectively calculable function, see §3.1.5. It is λ-definable; in λ-calculus, I = (λx.x).\nComment Identity I transforms π into π, I(π) = π, and Pπ into Pπ, I(Pπ) = Pπ. Comment Identity I can work as an analogy: Iπ = I(π) = π.\n§3.4.10 Lemma The translating function of the identity analogy is the identity function: TI = I. Proof Because I(Σπ) = Σπ. Diagram: π I−→π ℜ−−→Σπ I−→Σπ. ⋄ Comment The identity analogy is conservative, see §3.4.2. §3.4.11 Lemma The identity I followed by any function f , or any function f followed\nby identity I, is equal to the function: ∀f, I ◦ f = f = f ◦ I. Proof ∀f, ∀x, [I ◦ f ](x) = f(I(x)) = f(x) = I(f(x)) = [f ◦ I](x). ⋄ Comment I ◦ ℜ(Iπ) ◦ TI = I ◦ ℜ(π) ◦ I = ℜ(π).\n§3.4.12 Theorem A ◦ TAπ(S) ◦ TA, where A is an analogy, TAπ(S) is a trial, and TA is the translating function of A, is the general form of a resolution.\nProof If the analogy is the identity I, then the general form is reduced to Tπ(S), because TI = I, Iπ = π, so I◦TIπ(S)◦I = Tπ(S), which is a trial. By Theorem §3.3.7, a routine is a specific trial, Rπ = Tπ(Rπ), so I ◦ Tπ(Rπ) ◦ I = Tπ(Rπ) = Rπ reduces the general form to the routine. Resolving by analogy is, by definition, A ◦ ℜ ◦ TA, and analogies can be chained, by Lemma §3.4.4, so a chain of analogies is an analogy, A1◦A2◦ . . .◦An = A, and by Lemma §3.4.8, TA = TA1◦A2◦...◦An = TAn ◦ . . .◦TA2 ◦TA1 . Then A1 ◦ A2 ◦ . . . ◦ An ◦ TAπ(S) ◦ TAn ◦ . . . ◦ TA2 ◦ TA1 = A ◦ TAπ(S) ◦ TA. ⋄ Summary There are three ways to resolve a problem: routine Rπ = I ◦Tπ(Rπ)◦ I, trial Tπ(S) = I◦Tπ(S)◦I, and analogy A1◦. . .◦An◦TAπ(S)◦TAn◦. . .◦TA1 = A◦TAπ(S)◦TA.\n§3.5 Metaproblems\n§3.5.1 Definition A resolution ℜ : P → 2S is a valid resolution for a problem π if it finds all the solutions of problem π and then halts. In other words, ℜ is a valid resolution for π if it satisfies two conditions: that ℜ(π) is effectively calculable, and that ℜ fits problem π, that is, that ℜ(π) = Σπ. Comment If Σπ is infinite, |Σπ| ≥ ℵ0, then a valid ℜ(π) does not halt, but it keeps building Σπ forever.\n§3.5.2 Definition A problem π is resolved if a valid resolution for π is known. Comment To solve a problem we have to find one solution, see §3.2.13. To resolve a\nproblem we have to find all the solutions. To resolve a problem is to exhaust the problem.\n§3.5.3 Lemma Once a problem is resolved, we can thereafter resolve it by routine. Proof Once a problem is resolved, we know all of its solutions, Σπ, and knowing Σπ,\nwe know its routine resolution, because Rπ = Σπ, see §3.3.1. ⋄ Proposition If π ∧ ρ is solvable, then by resolving π ∧ ρ both π and ρ are solved. §3.5.4 Definition A problem is resolvable if there is a valid resolution for the problem,\nsee §3.5.1, that is, if there is a resolution ℜ such that ℜ(π) is effectively calculable, and ℜ(π) = Σπ. Otherwise, the problem is unresolvable.\nComment A problem is resolvable if it can be resolved. Comment Resolved implies resolvable, but not the converse: Resolved ⇒ Resolvable. §3.5.5 Definition For any Boolean-valued function P : S → B, we define the function\nP̌ : B → 2S, called the inverse of condition P , as follows:\nP̌ (⊤) = { x | [P (x) = ⊤] }, P̌ (⊥) = { x | [P (x) = ⊥] }.\n§3.5.6 Lemma If Pπ(x) is the condition of a problem π, then P̌π(⊤) = Σπ and P̌π(⊥) = Σπ = Σπ̄. Proof Because P̌π(⊤) = { x | [Pπ(x) = ⊤] } = { x | Pπ(x) } = Σπ, and P̌π(⊥) = { x | [Pπ(x) = ⊥] } = { x | ¬Pπ(x) } = Σπ = Σπ̄, by Lemma §3.2.3. ⋄\n§3.5.7 Theorem The inverse of the condition of a problem, provided it is an effectively calculable function, resolves the problem and its complementary by routine. Proof By §3.5.6 and §3.3.1, P̌π(⊤) = Σπ = Rπ, then P̌π(⊤) is the routine resolution of π, if P̌π(⊤) is effectively calculable, see §3.1.5. And if P̌π(⊥) is effectively calculable, then it resolves the complementary problem by routine, P̌π(⊥) = Σπ̄ = Rπ̄. ⋄\nComment It is a nice theorem, but how can we find the inverse of a condition?\n§3.5.8 Definition The metaproblem of a problem, written Ππ, is the problem of finding the valid resolutions for problem π. In other words, if π = x?Pπ(x), then Ππ = ℜ? [ℜ(π) = Σπ].\nComment The solutions of the metaproblems are the resolutions, ΠS = R. Comment The condition of the metaproblem, PΠπ, is [ℜ(π) = Σπ], that is, PΠπ(ℜ) =\n[ℜ(π) = Σπ], or using an α-conversion, PΠπ(x) = [x(π) = Σπ]. §3.5.9 Lemma A metaproblem is a problem, that is, ΠP ⊂ P. Proof Because Ππ = x?PΠπ(x), but some problems are not metaproblems. ⋄ Comment A metaproblem is a problem because it has its two ingredients: there are\nseveral ways to resolve a problem, so there is freedom, but only the valid resolutions resolve the problem, so there is a condition.\n§3.5.10 Definition The metacondition PΠ is PΠ(p, r) = [r(p) = Σp], for any problem p ∈ P, and for any resolution r ∈ R.\nComment Using another α-conversion, PΠ(π, x) = [x(π) = Σπ] = PΠπ(x). Comment Ππ = x?PΠ(π, x).\n§3.5.11 Definition Metaresolving is resolving the metaproblem to resolve the problem.\nComment Metaresolving is a kind of analogy. Diagram:\nπ Π−−→Ππ Πℜ−−−→ΣΠπ = {ℜ | [ℜ(π) = Σπ] } fc−−→ℜc (π)−−→ℜc(π) = Σπ .\nFunction fc is a choice function, and the last calculation, noted (π), means to apply π as the argument, not as the function. If you only metasolve, then you don’t need to choose. In any case, the translating function of metaresolving is TΠ = fc ◦ (π). Then we can draw the following diagrams:\nπ Π−−→Ππ Πℜ−−−→ΣΠπ TΠ−−→Σπ or P Π−−→ΠP Πℜ−−−→ 2ΠS = 2R TΠ−−→ 2S .\n§3.5.12 Lemma The metaproblem Ππ of some problem π is solvable if, and only if, the problem π is resolvable, that is, Ππ is solvable ⇔ π is resolvable. Proof If Ππ is solvable, then there is a solution to it, see §3.2.14, and that solution is a valid resolution for π, see §3.5.8, and then π is resolvable, see §3.5.4. If π is resolvable, then there is a valid resolution for it, see §3.5.4, and that resolution is a solution of its metaproblem Ππ, see §3.5.8, and then Ππ is solvable, see §3.2.14. ⋄\nCorollary To solve the metaproblem Ππ of problem π is to resolve problem π. Proof Because to resolve problem π is to find a valid resolution for π, see §3.5.2, and\nto solve the metaproblem Ππ is to find a solution to Ππ, see §3.2.13, which is also to find a valid resolution for π, see §3.5.8. ⋄\nComment And again, R = ΠS.\n§3.5.13 Lemma The set of the valid resolutions for problem π is the routine resolution of its metaproblem Ππ, that is, {ℜ | [ℜ(π) = Σπ] } = RΠπ. Proof RΠπ = ΣΠπ, by the definition of routine, see §3.3.1. And ΣΠπ = {ℜ | [ℜ(π) = Σπ] }, by the definition of Ππ, see §3.5.8. ⋄\n§3.6 Resolution Typology\n§3.6.1 Definition The metan-metaproblem of π, ΠnΠπ, is (the metaproblem of)n the metaproblem of π, where n ∈ N. Special case The meta-metaproblem of π, ΠΠπ = Π1Ππ, is the metaproblem of the metaproblem of π. Examples Π0Ππ = Ππ. Π1Ππ = ΠΠπ = Π2π. Π2Ππ = ΠΠΠπ = Π3π. Comment From ΠS = R, we get ΠΠS = ΠR and ΠnΠS = ΠnR. Comment The condition of the metan-metaproblem of π, PΠnΠπ, where n ∈ N, is:\nPΠnΠπ(x) = [x(Π nπ) = ΣΠnπ].\nExamples PΠ0Ππ(x) = [x(Π 0π) = ΣΠ0π] = [x(π) = Σπ] = PΠπ(x).\nPΠ1Ππ(x) = [x(Π 1π) = ΣΠ1π] = [x(Ππ) = ΣΠπ] = PΠΠπ(x).\n§3.6.2 Lemma A metan-metaproblem is a problem, where n ∈ N. Proof If n > 0, then ΠnΠπ = x?PΠnΠπ(x). For n = 0, see §3.5.9. ⋄ Corollary ⋃\nn∈N Π nΠP ⊂ P.\n§3.6.3 Definition The metan-metacondition PΠnΠ, with n ∈ N, p ∈ P, and r ∈ R is: PΠnΠ(p, r) = [r(Π\nnp) = ΣΠnp]. Comment Using an α-conversion, PΠnΠ(π, x) = [x(Π\nnπ) = ΣΠnπ] = PΠnΠπ(x). Example PΠ1Π(π, x) = PΠΠ(π, x) = [x(Ππ) = ΣΠπ] = [x(Π 1π) = ΣΠ1π].\n§3.6.4 Lemma PΠnΠ(π, x) = PΠ(Πnπ, x), where n ∈ N. Proof By §3.5.10, PΠ(Πnπ, x) = [x(Πnπ) = ΣΠnπ] = PΠnΠ(π, x). ⋄ Special Case PΠΠ(π, x) = PΠ(Ππ, x). Comment The meta-metacondition is the metacondition of the metaproblem.\n§3.6.5 Lemma A metan-metaproblem is a metaproblem, where n ∈ N. Proof If n > 0, ΠnΠπ = x?PΠ(Π\nnπ, x), and Π0Ππ = Ππ = x?PΠ(π, x). ⋄ Corollary ⋃\nn∈N Π nΠP = ΠP.\n§3.6.6 Lemma We have the following infinite series of mathematical objects: S, P = 2S, R = ΠS = 2S → 2S, ΠP = 22S→2S , ΠR = ΠΠS = 22S→2S → 22S→2S , . . . Proof P = S → B = 2S, by Theorems §3.1.8 and §3.2.9. ΠS = R, by the metaproblem definition, see §3.5.8, and R = P → 2S = 2S → 2S. ΠP = ΠS → B = R → B = 2R = 22S→2S . ΠR = ΠP → 2ΠS = 2R → 2R = 22S→2S → 22S→2S . And so on. ⋄\n§3.6.7 Theorem There is only one level of problem meta-ness. Proof By Lemma §3.6.5, because every metan-metaproblem is a metaproblem, and\nevery metaproblem is a meta0-metaproblem, so ⋃ n∈NΠ nΠP = ΠP ⊂ P. ⋄\nComment While a problem condition is any predicate, P (x), a metaproblem condition is a specific kind of predicate, namely, PΠ(p, r) = [r(p) = Σp]. And any meta\nnmetaproblem condition, PΠnΠ, is the same specific predicate PΠ, see §3.6.4.\nComment We are assuming that functions are free to take functions as arguments. See that, in predicate PΠ(p, r) = [r(p) = Σp], argument r is a function in Π\nnR that takes p ∈ ΠnP as argument. Therefore, the theorem holds unconditionally for λ-definable functions, including predicates, see §4.2.9. And then, under Church’s thesis, see §4.3.1, the theorem is true for effectively calculable functions, and in particular, it is true for expressible and for resolvable problems, see §3.1.6 and §3.5.4.\n§3.6.8 Theorem There are five types of resolution. Proof From Theorem §3.4.12 we get three types for the resolution of problems: Rπ,\nTπ(S), and A ◦ TAπ(S) ◦ TA. This shows that there are several ways of resolving, so choosing a resolution that find solutions to the original problem π is another problem, the metaproblem Ππ, see §3.5.8. Then we should get another three for the resolution of the metaproblem, but, by §3.5.13, the set of the resolutions of a problem is the routine resolution of its metaproblem, so we only add two more for the metaproblem: TΠπ(R), and A ◦ TAΠπ(R) ◦ TA. Finally, by §3.6.7, we do not need to go deeper into metan-metaproblems. ⋄ Comment We will call them: routine Rπ, trial Tπ(S), analogy A ◦ TAπ(S) ◦ TA, metatrial TΠπ(R), and meta-analogy A ◦ TAΠπ(R) ◦ TA. The first three can also be called meta-routines.\n§3.6.9 Remark The diagram for the meta-trial, or trial of the metaproblem, is:\nπ Π−−→Ππ TΠπ(R)−−−−−→ΣΠπ TΠ−−→Σπ .\nAnd the diagram for the meta-analogy, or analogy of the metaproblem, is:\nπ Π−−→Ππ A−−→AΠπ TAΠπ(R)−−−−−−→ΣAΠπ TA−−→ΣΠπ TΠ−−→Σπ .\nSee that A : ΠP → ΠP = 22S→2S → 22S→2S and TA : 2ΠS → 2ΠS = 22 S→2S → 22S→2S , using §3.6.6. Both are functions taking sets of functions on sets to sets and returning sets of functions on sets to sets.\n§4 Computers\n§4.1 Turing Machine\n§4.1.1 Definition A computation is any manipulation of a string of symbols, irrespective of the symbols meanings, but according to a finite set of well-defined rules.\nComment Computing is any mechanical transformation of a string of symbols.\n§4.1.2 Definition A computing device, or computer, is any mechanism that can perform computations.\nComment The prototype of computing device is a Turing machine, see Turing (1936).\n§4.1.3 Notation The Turing machine has two parts: the processor P, which is a finite state automaton, and an infinite tape, 〈 〉, which in any moment contains only a finite number of symbols.\nComment In the case of a processor of a Turing machine, the output alphabet O, that is, the finite set of output symbols, has to be: O = I+×{l, h, r}, where I is the finite not empty input alphabet, I+ = I ∪ {b}, where b /∈ I is blank, and l, h, and r mean left, halt, and right. Then its transition function is T : S × I+ → S × I+ × {l, h, r}, where S is the finite set of internal states. And the strings that the Turing machine transforms are sequences of symbols taken from set I.\n§4.1.4 Notation We will refer to the set of Turing machines as T. We will refer to the set of the strings of symbols as E.\nComment Because all Turing machines tapes are equal, the processor defines the Turing machine, and therefore we will refer to the Turing machine with processor P as the Turing machine P, and then P ∈ T. We will refer to the string of symbols written on the tape as the expression e ∈ E.\n§4.1.5 Lemma The set of expressions is countable, that is, |E| = |N| = ℵ0. Proof Let I be any finite alphabet, and s its cardinality, that is, s is the number of\nsymbols, s = |I| > 0. We write In the set of strings of length n, so |In| = sn. Then E = ⋃\nn∈N I n, and we can define a bijection between E and N this way: it maps the\nempty string in I0 to 0, it maps the s strings in I1 to the next s numbers, it maps the s2 strings in I2 to the next s2 numbers, and so on. Note that ordering the symbols in I, we can order alphabetically the strings in each In. ⋄ Comment Most real numbers are not expressible. See Turing (1936) §10 for details; but, for example, transcendental numbers π and e are computable, page 256.\n§4.1.6 Notation We will use the notation P〈e〉 →֒ r to indicate that, if we write the expression e ∈ E on the tape of the Turing machine with processor P and we leave it running, then when it halts we will find the expression r ∈ E on the tape. If, on the contrary, the Turing machine P does not halt when we write the expression w, then we would say that w is a paradox in P, and we would indicate this as follows: P〈w〉 →֒ ∞.\n§4.1.7 Definition E+ = E ∪ {∞}. Comment Some computations do not halt, so we need ∞ to refer to them. Note that\n∞ /∈ E, but ∞ ∈ E+. So E ⊂ E+.\n§4.1.8 Definition For each Turing machine P ∈ T we define a function FP : E → E+, this way:\nFP(e) = { r if P〈e〉 →֒ r ∞ if P〈e〉 →֒ ∞ .\nComment If ∀e ∈ E, FP(e) = FQ(e), then we say that Turing machines P and Q are behaviorally equivalent, P ≡F Q, or that P and Q implement the same function.\n§4.1.9 Definition We say that a function is computable if there is a Turing machine that implements the function.\n§4.1.10 Lemma For each Turing machine we can define a unique finite string of symbols, that is, ∃c : T → E such that P = Q ⇔ c(P) = c(Q). Proof Proved by Turing (1936), §5. Turing machines are defined by their processors, which are finite state automata. And every finite state automaton is defined by the table that describes its transition function T in full, which is a finite table of expressions referring to internal states, input symbols, and output symbols. A table can be converted to a string just using an additional symbol for the end of line, and another symbol for the end of cell. To assure uniqueness, we have to impose some order on the lines and on the cells. ⋄ Comment c(P) ∈ E is the string of symbols that represents the Turing machine P ∈ T. §4.1.11 Notation We will refer to p = c(P) as a program, and to the set of programs\nas P. The set of programs is a proper subset of the set of expressions, P ⊂ E. §4.1.12 Definition The program isomorphism is the natural isomorphism that relates\neach Turing machine P ∈ T with the expression describing it, c(P) = p ∈ P. That is, T ⇔ P : P ↔ c(P). Comment Now, T ∼= P ⊂ E. §4.1.13 Lemma The set of Turing machines is countable, that is, |T| = |N| = ℵ0. Proof Proved by Turing (1936), §5. Using the program isomorphism, see §4.1.12, we\norder the Turing machines according to its corresponding program p = c(P). We can order the programs, because they are finite strings of symbols, for example first by length, and then those of a given length by some kind of alphabetical order. Once ordered, we can assign a natural number to each one. ⋄\n§4.1.14 Theorem All computing sets are countable, that is, |T| = |E| = ℵ0. Proof By Lemmas §4.1.5 and §4.1.13. ⋄ Comment All computing is about countable sets. Computing is counting.\n§4.2 Turing Completeness\n§4.2.1 Theorem There is a Turing machine, called universal Turing machine, U , that can compute anything that any Turing machine can compute. That is:\n∃U ∈ T | ∀P ∈ T, ∀d ∈ E, U〈c(P) d〉 = P〈d〉.\nProof Proved by Turing (1936), §6 and §7. ⋄ Comment The equality means that if P〈d〉 →֒ r then U〈c(P) d〉 →֒ r, and the converse,\nand also that if P〈d〉 →֒ ∞ then U〈c(P) d〉 →֒ ∞, and the converse. That is, U〈c(P)〉 ≡F P. To complete the definition, if e /∈ P, then U〈e d〉 →֒ e d.\n§4.2.2 Notation We will refer to the set of universal Turing machines as U. Comment The set of universal Turing machines is a proper subset of the set of Turing\nmachines, U ⊂ T. §4.2.3 Lemma For each universal Turing machine U there is a universal program u. Proof Universal Turing machines are Turing machines, and u = c(U). Then, by the\nprogram isomorphism, see §4.1.12, u = U . ⋄ Comment Given u = c(U) and p = c(P), then U〈p d〉 = P〈d〉 and U〈u p d〉 = U〈p d〉,\nso u is the identity for programs, and U〈u u p d〉 = U〈u p d〉 = U〈p d〉 = P〈d〉.\n§4.2.4 Definition The terminating condition Pσ : T → B is:\nPσ(P) = {⊥ if ∃w ∈ E, P〈w〉 →֒ ∞ ⊤ otherwise .\nComment A terminating Turing machine always halts. There are not paradoxes in a terminating Turing machine. While Turing machines implement partial functions, E → E+, see §4.1.8, terminating Turing machines implement total functions, E → E.\n§4.2.5 Definition The terminating problem is σ = p?Pσ(p). The non-terminating problem is σ̄ = p? ¬Pσ(p).\nComment The terminating problem follows from the condition isomorphism of problems, see §3.1.7, applied to the terminating condition Pσ. The non-terminating problem is derived from the terminating one by negation, see §3.1.10.\nComment The set of terminating Turing machines is Σσ, and the set of non-terminating Turing machines is Σσ̄. Proposition Σσ and Σσ̄ are a partition of T, because Σσ ∩Σσ̄ = ∅ and Σσ ∪Σσ̄ = T. §4.2.6 Definition We will call a = c(Pσ) ∈ E, where Pσ ∈ Σσ, an algorithm. Comment ∀d, Pσ〈d〉 →֒ r 6= ∞ ⇔ ∀d, U〈a d〉 →֒ r 6= ∞. Comment An algorithm is the expression of a computation that always halts. Notation We will refer to the set of algorithms as A. Comment A ⊂ P ⊂ E. §4.2.7 Lemma Universal Turing machines are non-terminating, that is, U ⊂ Σσ̄ ⊂ T. Proof Because there are paradoxes in some Turing machines. For example, for Turing\nmachine W, that has not any h (halt) in its transition table, every expression is a paradox. That is, ∃P ∈ T, ∃w ∈ E, P〈w〉 →֒ ∞ ⇒ ∀U ∈ U, U〈c(P) w〉 →֒ ∞. ⋄ Comment If expression w is a paradox in P, then expression c(P) w is a paradox in U . Then, U ∈ Σσ̄.\n§4.2.8 Definition A computing device is Turing complete if it can compute whatever any Turing machine can compute. We will call every Turing complete device a universal computer. Comment The prototype of universal computer is a universal Turing machine, U . Comment The Turing machine, as it was presented by Turing (1936), models the\ncalculations done by a person. This means that we can compute whatever any Turing machine can compute provided we have enough time and memory, and therefore we are Turing complete provided we have enough time and memory.\n§4.2.9 Theorem All universal computers are equivalent. Proof Gödel and Herbrand recursiveness, Church λ-definability, and Turing com-\nputability are equivalent, because Kleene (1936) showed that every recursive function is λ-definable, and the converse, and then Turing (1937) showed that every λ-definable function is computable, and that every computable function is recursive. ⋄\nComment A universal Turing machine is equivalent to a λ-calculus interpreter, where a λ-calculus interpreter is a device that can perform any λ-calculus reduction. A universal Turing machine is equivalent to a mathematician calculating formally, and without errors, any recursive function.\nComment The universal Turing machine, the λ-calculus interpreter, and the mathematician, who is a person, are equal in computing power. And all of them are Turing complete.\n§4.2.10 Proviso Whenever we apply a general statement to a finite universal computing device, we should add a cautious ‘provided it has enough time and memory’.\nComment Although the finite universal computer can perform each and every step of the computation exactly the same as the unrestricted universal computer, the finite universal computer could meet some limitations of time or memory that would prevent it to complete the computation. In that case, the same finite universal computer, provided with some additional time and some more memory, would perform some more computing steps exactly the same as the unrestricted universal computer. This extension procedure can be repeated as desired to close the gap between the finite and the unrestricted universal computer.\nComment We will understand that the proviso ‘provided it has enough time and memory’ is implicitly stated whenever we refer to a finite universal computing device.\n§4.2.11 Convention Because all universal computers are equivalent, we can use any of them, let us call the one used U , and then drop every U from the formulas, and just examine expressions, that is, elements in E. In case we need to note a non-halting computation, we will use ∞.\nComment Using the convention is as if we were always looking inside the tape of U . Given a universal computer, U , computing is about expressions manipulating expressions. Example Formula U〈c(P) d〉 →֒ r is reduced to 〈c(P) d〉 →֒ r, and even to 〈p d〉 →֒ r, using the rewriting rule: ∀P ∈ T, c(P) = p. If the universal computer is a λ-calculus interpreter, then this is usually written as the β-reduction (p d) → r, where the left hand side is a λ-application, and p is defined by some λ-abstraction.\n§4.2.12 Definition For each program p ∈ P we define a function Fp : E → E+, this way:\nFp(e) = { r if 〈p e〉 →֒ r ∞ if 〈p e〉 →֒ ∞ .\nComment If ∀e ∈ E, Fp(e) = Fq(e), then we say that programs p and q are behaviorally equivalent, p ≡F q, or that p and q implement the same function.\n§4.2.13 Theorem ∀P ∈ T, FP = Fp, where p = c(P). Proof ∀d ∈ E, ∀P ∈ T, Fp(d) = FP(d), see §4.1.8, because U〈c(P) d〉 = P〈d〉, by\nTheorem §4.2.1, and therefore FP = Fp when the universal computer is a universal Turing machine, U . Theorem §4.2.9 extends it to every universal computer. ⋄ Comment P and p implement the same function. Comment This theorem is a consequence of the program isomorphism, see §4.1.12. In\nother words, T ∼= P implies that ≡F ↔ ≡F, so P ≡F Q ⇔ p ≡F q. Corollary FU = Fu, where u = c(U).\n§4.3 Turing’s Thesis\n§4.3.1 Thesis What is effectively calculable is computable. Comment This is Church’s thesis, or rather Turing’s thesis, as it was expressed by\nGandy (1980). There, ‘something is effectively calculable’ if its results can be found by some purely mechanical process, see §3.1.5, and ‘computable’ means that the same results will be found by some Turing machine. Then, ∗F ⊆ T. Comment ‘What is computable is effectively calculable’, or T ⊆ ∗F, is the converse of Turing’s thesis. And it is obvious that if a Turing machine can compute a function, then the function is effectively calculable, see §3.1.5, by a Turing machine. Therefore, ∗F = T, and |∗F| = ℵ0, by §4.1.13.\n§4.3.2 Remark An effectively calculable function is not an input to output mapping; it is a process to calculate the output from the input.\nExample To multiply a number expressed in binary by two we can append a ‘0’ to it, which is an effectively calculable function that we will call app0. But the complete memoization of the same function, which we will call memoby2, is not effectively calculable because it would require an infinite quantity of memory. And therefore, app0 6= memoby2.\n§4.3.3 Notation We will call every universe where the Turing’s thesis is true a Turing universe. When we want to note that something is true in a Turing universe, we will use an asterisk, so A ∗ = B means that A = B if the Turing’s thesis stands. Examples ∗F ∗ = T and |∗F| ∗= ℵ0.\nComment The Turing’s thesis affirms that this is a Turing universe. In any Turing universe the Turing’s thesis is a law of nature, as it was defended by Post (1936), last paragraph. Then a Turing universe can also be called a Post universe.\nComment While the Turing’s thesis is true, you can ignore the asterisks.\n§4.3.4 Theorem Universal computers are* the most capable computing devices. Proof If Turing’s thesis stands, see §4.3.1, then anything that any mechanism can\neffectively calculate can be computed by some Turing machine, and therefore, by Theorem §4.2.1, it can be computed by any universal Turing machine, and finally, by Theorem §4.2.9, it can be computed by any universal computer. ⋄\n§4.3.5 Lemma There are definable functions that no Turing machine can compute. Proof You can use a diagonal argument, or work from other theorems that use the\ndiagonal argument. For example, the set of Turing machines is countable, see §4.1.13, |T| = |N| = ℵ0, while the possible number of predicates on natural numbers, that is, the number of functions N → B, is 2|N| = 2ℵ0, which is not countable, |T| = |N| = ℵ0 < 2ℵ0 = 2|N|. This uses Cantor’s theorem, |S| < |2S|, with its diagonal argument. So there are not enough Turing machines to compute every definable function. ⋄\nCorollary Universal computers cannot compute every definable function. Comment If the Turing’s thesis stands, see §4.3.1, then it follows that there are defin-\nable functions that are not effectively calculable, see §3.1.5. Comment There are* more mappings than processes.\n§4.3.6 Definition The identity Turing machine, I, just halts. Comment It does nearly nothing. But, wait!\n§4.3.7 Lemma ∀x ∈ E, I〈x〉 →֒ x, where I is the identity Turing machine. Proof Whatever expression x ∈ E is written on the tape of I, that very same expression\nx is written when I halts, because halting is all what I does. ⋄ Comment I does not touch the expression. §4.3.8 Lemma The identity Turing machine is terminating, that is, I ∈ Σσ. Proof The identity Turing machine, which just halts, is terminating, see §4.2.5, be-\ncause it always halts; it only halts. ⋄ Comment I behaves, because sometimes ‘you can look, but you better not touch’. §4.3.9 Lemma The identity Turing machine I : E → E is* the identity function i :\nS → S such that ∀x ∈ S, i(x) = x, that is, I ∗= i. Proof The identity function i is an effectively calculable function, see §3.1.5. There-\nfore, if the Turing’s thesis stands, see §4.3.1, then there is a Turing machine J such that ∀x ∈ E, J 〈x〉 →֒ x. By Lemma §4.3.7, that Turing machine J is the identity Turing machine I. ⋄ Comment If i = c(I), then U〈i p d〉 = I〈p d〉 →֒ p d, and U〈u p d〉 = U〈p d〉 = P〈d〉 →֒ r, or ∞, see §4.2.3. Then i is the literal identity for expressions, or quotation, and u is the functional identity for programs, or evaluation. Both are computable, but I ∈ Σσ and U ∈ Σσ̄, see §4.2.7.\n§4.3.10 Theorem Everything is* an expression, that is, E ∗= S. Proof S is the set of everything, see §3.2.1. In computing, there are only computing\ndevices, T, and expressions, E, see §4.1.4. But then, by the program isomorphism, see §4.1.12, computing devices are expressions, T ⊂ E. Therefore, in computing everything is an expression. And now, if the Turing’s thesis stands, see §4.3.1, then Lemma §4.3.9 also stands, so ∀x ∈ S, x = i(x) ∗= I〈x〉 →֒ x ∈ E. The converse, ∀x ∈ E, x ←֓ I〈x〉 = i(x) = x ∈ S, holds irrespective of Turing’s thesis. Therefore, S ∗ = E. ⋄ Comment We will write x to indicate a computing point of view of x, but ∀x, x ∗= x. For example, i ∗ = i.\n§4.3.11 Lemma The set of solutions S is* countable, that is, |S| ∗= ℵ0. Proof S ∗ = E, by §4.3.10, and |E| = |N| = ℵ0, by §4.1.5, therefore |S| ∗= |E| = ℵ0. ⋄ Comment We will refer to the set of solutions in a Turing universe as S∗. So we can also write this lemma as |S∗| = ℵ0.\n§4.3.12 Theorem Resolving is* computing, that is, T ∗= R. Proof From Theorem §4.3.10, everything is* an expression, and taking transitions\nand not states, it follows that whatever transforms expressions in computing theory, that is, a Turing machine P, or its equivalent program p, or a λ-function of the λcalculus, is* equivalent to whatever transforms sets in set theory, that is, an effectively calculable function, and it is* also equivalent to whatever transforms problems in problem theory, that is, a resolution ℜ. Therefore, resolving is* computing, R ∗= T. ⋄\nComment ∗f ∗≡ P ≡ p ∗≡ ℜ, and ∗F ∗= T ∗= R. Comment We can define functions that are not effectively calculable, see §4.3.5. Those functions that cannot effectively calculate, cannot therefore transform, and they are, in this sense, useless; we can define them, but we cannot use them.\nCorollary Metasolutions are* effectively calculable functions, that is, ΠS ∗ = ∗F. Proof Because R = ΠS, see §3.5.8, so ΠS = R ∗= ∗F. ⋄ §4.3.13 Lemma The set of resolutions R is* countable, that is, |R| ∗= ℵ0. Proof R ∗ = T, by §4.3.12, and |T| = |N| = ℵ0, by §4.1.13, therefore |R| ∗= |T| = ℵ0. ⋄ Comment We will refer to the set of resolutions in a Turing universe as R∗. So we can also write this lemma as |R∗| = ℵ0.\n§4.3.14 Lemma Predicate Pδs, where Pδs(x) = [x = s], is* effectively calculable. Proof Both s and x are* expressions, by §4.3.10, so both are finite strings of symbols,\ns = s1s2 . . . sn, and x = x1x2 . . . xm. Then we can define a Turing machine with n+2 states, that starts in state 1, and that when some string x is written on its tape, it scans the string x, symbol by symbol, from the leftest one, this way: 1) in state i, with 1 ≤ i ≤ n, if the read symbol is si, then it writes a blank, goes to state i + 1, and moves to the right, but if the read symbol is not si, then it writes a blank, goes to state 0, and moves to the right; 2) in state n+ 1, if the read symbol is blank, then it writes a ⊤, goes to state 0, and halts, but if the read symbol is not blank, then it writes a blank, goes to state 0, and moves to the right; 3) in state 0, if the read symbol is not blank, then it writes a blank, goes to state 0, and moves to the right, but if the read symbol is blank, then it writes a ⊥, goes to state 0, and halts. This Turing machine implements Pδs , and therefore Pδs is computable. ⋄ Corollary Problem δs = x? [x = s] is* expressible. Proof Because problem δs condition Pδs is* effectively calculable, see §3.1.6. ⋄ Comment Problem δs is used in the proof of Theorem §3.2.1. Corollary The only solution to problem δs is s, so Σδs = {s} ∈ S1. Proof Because Σδs = { x | Pδs(x) } = { x | [x = s] } = {s}. ⋄ §4.3.15 Lemma The set of problems P is* countable, that is, |P| ∗= ℵ0. Comment We will refer to the set of problems in a Turing universe as P∗. So we can\nalso write this lemma as |P∗| = ℵ0. If the condition of a problem is computable, then the problem is in P∗; δs ∈ P∗, for example. Proof Problem δs is* expressible, see §4.3.14. Then, δS∗ = { δs | s ∈ S∗ } ⊆ P∗ because each δs ∈ P∗, and |δS∗| = |S∗| because there is a bijection δS∗ ⇔ S∗ : δs ↔ s. Also, by Theorem §4.3.10, P∗ ⊆ E. Therefore, δS∗ ⊆ P∗ ⊆ E, and |δS∗| = |S∗| = ℵ0 = |E|, and then, by the Cantor-Bernstein-Schröder theorem, |P∗| = ℵ0. ⋄ Comment The Cantor-Bernstein-Schröder theorem is Theorem B of §2, page 484, in Cantor (1895). We have really used the equivalent Theorem C, in the same page.\n§4.3.16 Theorem All problem sets are* countable, that is, |S∗| = |P∗| = |R∗| = ℵ0. Proof By Lemmas §4.3.11, §4.3.15, and §4.3.13. ⋄ §4.4 Full Resolution Machine\n§4.4.1 Definition A full resolution machine is a device that can execute any resolution. §4.4.2 Theorem A full resolution machine is* a Turing complete device. Proof By Theorem §4.3.12, resolving is* computing, ℜ ∗≡ P. This means that to\nachieve the maximum resolving power is* to achieve the maximum computing power, which is* the computing power of a universal computer, by Theorem §4.3.4. Therefore, in a Turing universe a full resolution machine has to be Turing complete. ⋄\nComment To execute any resolution ℜ : P → 2S, the full resolution machine has to calculate functions that can take functions and that can return functions without limitations, as 22\nS→2S → 22S→2S for meta-analogies, see §3.6.9. Then a full resolution machine has to execute every possible function, and therefore, in a Turing universe, it has to execute every computable function, and then it has to be a λ-calculus interpreter, or an equivalent computing device, for example U .\nComment This means that problem resolving is* equal to computing, and then full problem resolving is* equal to universal computing.\nCorollary A full resolution machine* is a universal computer. Proof Because a full resolution machine is* a universal computer. ⋄ Comment Now we will state two equivalences between computing theory and problem\ntheory concepts that are true in any Turing universe, and that are needed to show the limitations of full resolution machines.\n§4.4.3 Definition A set is recursively enumerable if there is a Turing machine that generates all of its members, and then halts.\nComment If the set is infinite, the Turing machine will keep generating its members forever.\nDefinition A set is computable if it is recursively enumerable.\n§4.4.4 Theorem Resolvable in problem theory is* equivalent to recursively enumerable in computing theory, that is,\nResolvable ∗ = Recursively Enumerable .\nProof To see that a problem is resolvable if, and only if, the set of its solutions is recursively enumerable, just compare the definition of resolvable problem, in §3.5.4, with the definition of recursively enumerable set, in §4.4.3. The only remaining gap is to equate the valid resolution ℜ of the resolvable problem to the Turing machine of the recursively enumerable set, a gap that we can bridge with the help of Theorem §4.3.12. Finally see that, by the set isomorphism, see §3.2.9, we can refer interchangeably to the problem π or to the set of its solutions Σπ. Then we can say that a problem is recursively enumerable, or that a set is resolvable. ⋄\n§4.4.5 Definition A set is recursive if its characteristic function can be computed by a Turing machine that always halts.\n§4.4.6 Theorem Expressible in problem theory is* equivalent to recursive in computing theory, that is,\nExpressible ∗ = Recursive .\nProof The condition of a problem, Pπ, is the characteristic function of the set of its solutions, because Σπ = { s | Pπ(s) }, see §3.2.2. Then, if the set of all the solutions to a problem is a recursive set, see §4.4.5, then the condition Pπ can be computed by a Turing machine that always halts. So the condition Pπ is an effectively calculable function, and therefore the problem is expressible, see §3.1.6. If Turing’s thesis, §4.3.1, is true, then the converse is also true; just go backwards from expressible to recursive. Finally, by the set isomorphism, see §3.2.9, we can refer interchangeably to the problem π or to the set of its solutions Σπ. Then, we can say that a problem is recursive, or that a set is expressible. ⋄\n§4.4.7 Lemma The limitations of full resolution machines are* the limitations of universal computers. Proof Because a full resolution machine is* a universal computer, see §4.4.2. ⋄ Comment Even if universal computers are the most capable computers, they cannot\ncompute everything, see §4.3.5. Now we will present three limits related to problems. §4.4.8 Lemma A full resolution machine can* execute any resolution, but it cannot*\nexpress some problems. Proof There is a recursively enumerable set that is not recursive; this is the last\ntheorem in Post (1944) §1. Translating, by Theorems §4.4.4 and §4.4.6, to problem theory: there is* a resolvable problem that is* not expressible. ⋄\nComment This is the problem limit of full resolution machines*. Comment That last theorem in Post (1944) §1, page 291, is an abstract form of Gödel’s\nincompleteness theorem, see Post (1944) §2. §4.4.9 Lemma A full resolution machine can* execute any resolution, but it cannot*\nresolve some problems. Proof Let us call κ some problem that is resolvable but not expressible, see §4.4.8.\nThis means that ∃ℜ | ℜ(κ) = Σκ, but 6 ∃Pκ | Pκ(x) = [x ∈ Σκ]. Note that |Σκ| ≥ ℵ0, because otherwise ∃Pκ. Then its metaproblem Πκ is solvable but not resolvable. Πκ is solvable because κ is resolvable, see §3.5.12, or, easier, because ℜ is a solution to Πκ. For Πκ to be resolvable there should be a resolution that would find ‘all the solutions of Πκ’, that is, ‘all the valid resolutions for κ’. But, whenever a possible valid resolution for κ, let us call it ℜ′, generates a value not yet generated by ℜ, let us call it z, we cannot decide whether z ∈ Σκ and it will be eventually generated by ℜ, or if z /∈ Σκ and it will never be generated by ℜ; remember that κ is not expressible, 6 ∃Pκ. And, not being able to decide on z, we cannot decide whether ℜ′ is a valid resolution for κ or not. ⋄\nComment This is the resolution limit of full resolution machines*. Comment Problem κ is named after the complete set K of Post (1944), §3. §4.4.10 Lemma A full resolution machine can execute any resolution, but it cannot\nsolve some problems. Proof Simply because some problems have not any solution, Σπ = {} = ∅. ⋄ Comment This is the solution limit of full resolution machines, which also applies to\nfull resolution machines*. Comment An unsolvable problem can be resolved by showing that it has not any\nsolution. For example, the decision problem of the halting problem, ∆η, see §4.5.4 below, was resolved unsolvable by Turing (1936), §8.\n§4.4.11 Theorem A full resolution machine* can execute any resolution, but it cannot express some problems (problem limit), and it cannot resolve some problems (resolution limit), and it cannot solve some problems (solution limit). Proof By Lemmas §4.4.8, §4.4.9, and §4.4.10. ⋄ Comment Full resolution machines* have limitations on each of the three main con-\ncepts of the problem theory.\nProblem Resolution−−−−−−−−−−−−→{ Solution }\n§4.5 Problem Topology\n§4.5.1 Definition The decision problem of a problem π = x?Pπ(x), written ∆π, is:\n∆π = P? [P ∈ Σσ] ∧ [∀(x ∗= x), P〈x〉 ∗= Pπ(x)].\nComment A solution to the decision problem ∆π of some original problem π is a Turing machine P that always halts and that computes the original problem condition Pπ for any input. Decision problems are only defined in Turing universes, where x ∗ = x\nby Theorem §4.3.10. Comment This definition follows Post (1944), page 287.\n§4.5.2 Definition The halting condition Pη : T× E → B is:\nPη(P, d) = {⊥ if P〈d〉 →֒ ∞ ⊤ otherwise .\n§4.5.3 Definition The halting problem is η = (p, d)?Pη(p, d). Comment The halting problem η corresponds to the halting condition Pη by the con-\ndition isomorphism of problems, see §3.1.7. Comment Pσ(p) = ∧ d∈E Pη(p, d), see §4.2.5, so σ = ∧\nd∈E η, by §3.1.7 and §3.1.10. §4.5.4 Definition The decision problem of the halting problem, ∆η, is:\n∆η = H? [H ∈ Σσ] ∧ [∀P ∈ T, ∀d ∈ E, H〈c(P) d〉 = Pη(P, d)].\n§4.5.5 Theorem The decision problem of the halting problem ∆η has not any solution. Proof Turing (1936), §8, resolved that ∆η is unsolvable. ⋄ Comment There is not any Turing machine that always halts and that compute Pη for\neach possible input. There is not any algorithm a ∈ A that would compute Pη(p, d) for every pair (p, d) ∈ P× E.\n§4.5.6 Lemma The decision problem ∆π of some problem π is solvable if, and only if, the problem π is expressible*, that is, ∆π is solvable ⇔ π is expressible*.\nProof From solvable to expressible. That the decision problem ∆π is solvable, see §4.5.1, means that there is a Turing machine that always halts, and that computes Pπ for each possible input. Therefore, Pπ is effectively calculable, see §3.1.5, by a Turing machine, and then the problem π is expressible, see §3.1.6, and then it is also expressible*. Now from expressible to solvable. If a problem π es expressible, then its condition Pπ is an effectively calculable function, see §3.1.6. Then, if the Turing’s thesis stands, see §4.3.1, that is, if it is expressible*, then there is a Turing machine P that can compute Pπ exactly as the effectively calculable function. P always halts, because Pπ is a condition, so its result is finite. Therefore, the decision problem ∆π of the problem has a solution, P, and then ∆π is solvable, see §3.2.14. ⋄\nCorollary The halting problem η is not expressible*. Proof The decision problem of the halting problem, ∆η, is not solvable, see §4.5.5,\nand then the halting problem η is not expressible*. ⋄ Comment The halting problem η is inexpressible*, but solvable. While the decision\nproblem of the halting problem ∆η is unsolvable, the halting problem η has many solutions.\n§4.5.7 Theorem The following equivalences stand: ∆π is solvable\n∗⇔ π is expressible, Ππ is solvable ⇔ π is resolvable, π is solvable ⇔ π is solvable.\nProof The last one is trivial, and the other two equivalences were already proved by Lemmas §4.5.6 and §3.5.12. ⋄\n§4.5.8 Definition A problem π can be: expressible* (E) or not expressible* (E), resolvable* (R) or not resolvable* (R), and solvable (S) or not solvable (S). Comment An expressible problem is* equivalent to a recursive set, by Theorem §4.4.6, a resolvable problem is* equivalent to a recursively enumerable set, by Theorem §4.4.4, and an unsolvable problem is equivalent to an empty set. Comment Then R is the set of computable sets, see §4.4.3. Comment Not every combination is possible.\n§4.5.9 Lemma If a problem is expressible*, then it is resolvable*, that is, E ⊂ R. Proof Because every recursive set is recursively enumerable, E ⊆ R. This is a corollary\nto the first theorem in Post (1944) §1. And E 6= R, see the proof of Lemma §4.4.8. To translate between sets and problems we use Theorems §4.4.4 and §4.4.6. ⋄ Comment The first theorem in Post (1944) §1, page 290, states that a setM is recursive if and only if both the set M and its complement M are recursively enumerable.\n§4.5.10 Lemma If a problem is not solvable, then it is expressible*, that is, S ⊂ E . Proof If a problem ν is not solvable, ν ∈ S, then Σν = {}, see §3.2.14. So ν is a\ncontradictory problem, see §3.1.11, and its condition Pν is the contradiction Pτ̄ , that is, ∀x, Pν(x) = Pτ̄ (x) = ⊥. So Pν = Pτ̄ is an effectively calculable function, see §3.1.5, and therefore ν is expressible, see §3.1.6, and then expressible*. And S 6= E , because (x? [2x = x2]) ∈ S ∩ E . ⋄ Comment Being expressible*, by Lemma §4.5.9, ν is also resolvable*: S ⊂ E ⊂ R. §4.5.11 Theorem Regarding expressibility* E , resolvability* R, and solvability S, the\ntopology of the problem space is:\nS ⊂ E ⊂ R ⊂ P .\nProof By Lemmas §4.5.9 and §4.5.10. As shown in the table, these lemmas prevent four of the eight combinations, and the examples show that the other four do exist.\nE R S Example & Comment ⊤ ⊤ ⊤ x? [2x = x2] ⊤ ⊤ ⊥ x? [2x = x2] ∧ [x > 2] ⊤ ⊥ ⊤ None, by Lemma §4.5.9 ⊤ ⊥ ⊥ None, by Lemma §4.5.9 ⊥ ⊤ ⊤ κ, see §4.4.9 ⊥ ⊤ ⊥ None, by Lemma §4.5.10 ⊥ ⊥ ⊤ Πκ, see §4.4.9 ⊥ ⊥ ⊥ None, by Lemma §4.5.10 ⋄\nCorollary Then, { S, E ∩ S,R ∩ E ,R} is a partition of P.\nComment See below, in §6.2, that E ∗= P, and then P∗ ⊂ P. Also R ∗= 2S. §4.5.12 Definition We say that a problem is finite, if the set of its solutions is finite.\nWe will refer to the set of finite problems as F . That is, F = { π | |Σπ| < ℵ0 }. §4.5.13 Lemma The set of finite problems F is a proper subset of the set of expressible\nproblems E . The set of not solvable problems S is a proper subset of the set of finite problems F . That is, S ⊂ F ⊂ E . Proof F ⊂ E because all finite sets are recursive, but not the converse. S ⊂ F because ∀ν ∈ S, |Σν | = 0 < ℵ0, but (x? [2x = x2]) ∈ S ∩ F . ⋄ Proposition Including F , the topology of P is: S ⊂ F ⊂ E ⊂ R ⊂ P. Corollary The topology S ⊂ F ⊂ E ⊂ R ⊂ P partitions the problem space P into\nfive non-empty places: S, F ∩ S, E ∩ F , R∩ E , and R. §4.5.14 Remark The upper part of this topology is further refined by the so called\nTuring degrees of unsolvability, that we will call Turing degrees of inexpressibility. Turing degree zero, 0, corresponds to the first three places, because E = 0. Comment Then, |E| = |0| = ℵ0, |R| = ℵ0, and |P| = 2ℵ0 > ℵ0. To complete the cardinalities, |S| = 1, so |S| = 2ℵ0, and |F| = ℵ0.\n§4.5.15 Remark Noting Ep the set of problems defined by a condition that can be computed in polynomial time, and Rp the set of problems that can be resolved in polynomial time, then Ep ⊂ E and Rp ⊂ R. The so called ‘P = NP?’ question asks if Ep = Rp, because P = Ep and NP = Rp, and then it should be called the ‘Ep = Rp?’ question. See that the general question ‘E = R?’ was answered negatively by Lemma §4.5.9, because E ⊂ R, and that Ep ⊆ Rp. Comment A similar question is ‘Ep \\ {∅} = Sp?’, where Sp is the set of problems that can be solved in polynomial time, so Sp ⊂ S. The corresponding general question is also answered negatively, because P = S ∪ {∅}, so E \\ {∅} ⊂ S.\n§5 Resolvers\n§5.1 Semantics and Syntax\n§5.1.1 Remark In this Section §5, we will always be inside a Turing universe, see §4.3.3, and accordingly we will drop every asterisk. Though some results do not depend on Turing’s thesis, by now the reader should know when it is the case.\n§5.1.2 Definition A resolver is a device that takes problems and returns solutions. Comment A resolver executes resolutions. Comment After Theorem §4.3.12, we can equate a resolution ℜ ∈ R to the computing\ndevice that executes the resolution P ∈ T, that is, ℜ = P. §5.1.3 Definition We will call the domain of S semantics. We will call the domain of\nS → S syntax. Comment As λ-calculus shows, we only need functions to implement any syntax. Comment By Theorem §3.2.1, everything is in S, including S → S. But this is both\nmathematically impossible, by Cantor’s theorem, and practically not interesting. Example Using a practical example, if the problem is the survival problem, so some\nbehaviors keep the resolver alive, and the rest cause the death of the resolver, then S\nis the set of behaviors, and it does not include anything that is not a behavior, not even predicates on behaviors, nor functions. Note that the condition of the survival problem, which is satisfied if the resolver does not die, is a predicate on behaviors.\n§5.1.4 Remark In this Section §5, we will assume that S is not the set of everything, and, in particular, we will assume that there is not any function in S. We will focus on the survival problem, and then assume that S is the set of behaviors, or finite state automata, but you can think that S = N, or any other countable set, see §4.3.11. Then we will build a series of resolvers, from the simplest one implementing one element of S, to more complex resolvers that have to implement functions in order to look for resolutions to deal with metaproblems.\n§5.1.5 Definition A problem type, for example PΨ, is a subset of the set of problems, that is, PΨ ⊆ P. We will note SΨ the set of the solutions to the type of problems PΨ. That is, ∀πΨ ∈ PΨ, ΣπΨ ⊆ SΨ ⊆ S. Comment The survival problem is not a single problem, but a type of problems, PΩ; each living being faces a different survival problem. But, in this case as in many others, what it is certain is that the solutions to any of these problems is of a specific kind. For example, while eating can be a solution, imagining how to eat is not a solution, even though it can help us to get something to eat, because it can be a metasolution. Then SΩ is the set of behaviors.\n§5.1.6 Remark Metaproblems Ππ are a type of problem, ΠP = PΠ, and its solutions are resolutions, ΠS = SΠ = R, see §3.5.8.\n§5.1.7 Lemma If the set of the solutions to some type of problem is finite, 0 < |SΓ| < ℵ0, then each and every problem of that type is expressible and resolvable. Proof Because those problems are in F , so Lemma §4.5.13 apply. ⋄ Comment If 0 < |SΓ| = N < ℵ0, then |PΓ| = 2N < ℵ0 and |RΓ| = (2N )2 N\n< ℵ0. In the finite case, |SΓ| < |PΓ| < |RΓ| < ℵ0.\n§5.1.8 Definition A constant function Ks : S → S is: ∀s ∈ S, ∀x ∈ S, Ks(x) = s. Comment Every constant function Ks is effectively calculable, see §3.1.5. They are\nλ-definable; in λ-calculus, K = (λsx.s). This is because our λ-calculus includes the K combinator, and so we refer to the λK-calculus simply as λ-calculus. Special cases Tautology: K⊤ = Pτ . Contradiction: K⊥ = Pτ̄ . See §3.1.11. §5.1.9 Definition The constant isomorphism is the natural isomorphism between S\nand the set of constant functions K that relates each s ∈ S with Ks ∈ (S → S). That is, S ⇔ K : s ↔ Ks.\nComment We can extend any operation on S to K. For example, for any binary operation ∗ on S, we define ∀x, [Ka ∗Kb](x) = Ka(x) ∗Kb(x) = a ∗ b = Ka∗b(x). Comment Semantics is included in syntax, that is, S ∼= K ⊂ (S → S). §5.1.10 Remark A semantic function f : S → S is a syntactic element, f ∈ (S → S),\nbut it is not a syntactic function f ∈ ((S → S) → (S → S)), because the semantic function f takes semantic elements and returns semantic elements, while, using the constant isomorphism, the syntactic function f is not restricted. In particular, a semantic function cannot take a function, and a semantic function cannot return a function.\nComment In semantics, literal identity i is the identity, see §4.3.9, because there are not higher order functions in semantics. But, different syntactic objects can refer to the same semantic object, as in f(x) = y, which means that f(x) and y are two syntactic objects that refer to the same semantic object. Then, there are two identities in syntax: literal identity i, or quotation, which is the semantic function that just returns what it takes, and functional identity u, or evaluation, which is the syntactic function that follows the references and returns the final one, see §4.2.3. Note also that a syntactic object can refer to no semantic object, and then we say that the syntactic object is a paradox.\n§5.1.11 Definition The range of a resolver ℜ, noted Ξℜ, is the set of the problems for which ℜ provides a non-empty subset of solutions, and only of solutions, that is, Ξℜ = { π | ℜ(π)⊆Σπ ∧ ℜ(π) 6=∅ }.\nComment The range of a resolver is the set of the problems that the resolver solves.\n§5.1.12 Definition The power of a resolver ℜ, noted Φℜ, is the set of the problems that the resolver ℜ resolves, that is, Φℜ = { π | ℜ(π) = Σπ }. Comment In practice, if |Σπ| > 1, it is not sensible to generate all the solutions, Σπ, when just one solution solves the problem. In these cases the range of the resolver is more important than its power.\n§5.1.13 Theorem ∀ℜ, S ∩ Φℜ ⊆ Ξℜ. Proof Because ∀π ∈ Φℜ ∩ S, we have that π ∈ Φℜ so ℜ(π) = Σπ, see §5.1.12, and\nthen ℜ(π) ⊆ Σπ, and also that π ∈ S, so |Σπ| > 0 ⇔ Σπ 6= ∅, see §4.5.8 and §3.2.14, and then ℜ(π) = Σπ 6= ∅, and therefore π ∈ Ξℜ, see §5.1.11. ⋄ Comment For solvable problems, Φℜ ⊆ Ξℜ, so they are easier to solve than to resolve. But unsolvable problems, some of them resolved, are impossible to solve!\n§5.1.14 Definition We will say that the resources of a resolver are in a set if the capability implemented in the resolver belongs to that set. Comment Now we will construct a series of resolvers ℜn, from the minimal one that only implements one solution, and then growing naturally step by step. Each resolver will implement just one element out of its resources Notation We will use {· ℜn ·} to refer to the set of all the resolvers of step n.\n§5.2 Mechanism\n§5.2.1 Definition A mechanism ℜ0 is any resolver that implements one member of S. We will note ℜ0[s], where s ∈ S, the mechanism that implements s, that is, ℜ0[s] = s ∈ S. Then the mechanisms resources are in S, and {· ℜ0 ·} = S. Comment Mechanism ℜ0[s] returns s unconditionally. Comment A mechanism ℜ0 implements a semantic unconditional computation.\n§5.2.2 Notation As resolutions return sets of elements in S, to normalize the situation of mechanisms ℜ0 we will use the singleton isomorphism, see §3.2.11, and we will write ℜ0[{s}] to mean the singleton {s}, that is, ℜ0[{s}] = {ℜ0[s]} = {s} ∈ 2S.\n§5.2.3 Lemma ∀s ∈ S, Ξℜ0[{s}] = { π | Pπ(s) }. Proof Just applying the definition of range, see §5.1.11, to the definition of mechanism,\nwe get: Ξℜ0[{s}] = { π | ℜ0[{s}]⊆Σπ ∧ ℜ0[{s}] 6= ∅ } = { π | {s}⊆Σπ ∧ {s} 6= ∅ } = { π | s∈Σπ ∧ ⊤} = { π | s ∈ Σπ } = { π | Pπ(s) }. ⋄ Comment The range of the mechanism ℜ0[s] is the set of problems for which s is a solution.\n§5.2.4 Lemma ∀s ∈ S, Φℜ0[{s}] = {δs}. Proof Just applying the definition of power, see §5.1.12, to the definition of mechanism,\nwe get: Φℜ0[{s}] = { π | ℜ0[{s}] = Σπ } = { π | {s} = Σπ } = {δs}, the last equation because Σδs = {s}, see §4.3.14. ⋄ Comment Mechanism ℜ0[s] only resolves problem δs. §5.2.5 Lemma Any singleton routine resolution Rπ = {s} can be implemented by the\nmechanism ℜ0[Rπ]. Proof If Rπ = {s}, then Rπ = {s} = {ℜ0[s]} = ℜ0[{s}] = ℜ0[Rπ]. ⋄ Comment In theory, we can equal any finite routine resolution to a union of a finite\nnumber of mechanisms, Rπ = Σπ = ⋃ s∈Σπ{s} = ⋃ s∈Σπ{ℜ0[s]}. §5.2.6 Summary In practice, it only makes sense to implement one solution, as ℜ0[s]\ndoes. Without conditional calculations, the mechanism could not control when to apply one result or any of the others, so it would gain nothing implementing more than one.\nComment The mechanism is a body capable of one behavior. Example A mechanism can only survive in a specific and very stable environment, as\nit is the case of some extremophile archaea.\n§5.3 Adapter\n§5.3.1 Definition An adapter ℜ1 is any resolver that implements one condition on the members of S. We will note ℜ1[PS ] the adapter that implements PS , where PS ∈ (S → B), that is, ℜ1[PS ] = PS ∈ (S → B). Then the adapters resources are in S → B, and {· ℜ1 ·} = (S → B). Comment An adapter ℜ1 implements a semantic conditional computation. §5.3.2 Lemma Each adapter ℜ1[PS ] implements one set of elements of S. Proof Because every predicate PS defines a set S = { s ∈ S | PS(s) } ∈ 2S. The\ncondition PS is the characteristic function of S, ∀s ∈ S, PS(s) = [s ∈ S]. ⋄ Comment We will write ℜ1[PS ] = ℜ1[S] = S ∈ 2S. Only effectively calculable con-\nditions are implementable, and then adapters can only implement expressible, or recursive, sets, E . Then, ℜ1[PS ] = ℜ1[S] = S ∈ E .\n§5.3.3 Lemma Every mechanism ℜ0 is an adapter ℜ1, that is, {· ℜ0 ·} ⊂ {· ℜ1 ·}. Proof For each mechanism ℜ0[s], which implements s ∈ S, there is an adapter ℜ1[Pδs],\nsee §4.3.14, that implements the singleton {s} ∈ (S → B). But not every set is a singleton. Summarizing, {· ℜ0 ·} = S ⊂ (S → B) = {· ℜ1 ·}. ⋄ Comment In Cantor’s paradise, but out of Turing universes, by the singleton (§3.2.11) and the set (§3.2.8) isomorphisms: {· ℜ0 ·} = S ∼= S1 ⊂ 2S ∼= (S → B) = {· ℜ1 ·}.\n§5.3.4 Lemma ℜ1[S] = ⋃ s∈S{ℜ0[s]}. Proof Because ℜ0[s] = s, so ⋃ s∈S{ℜ0[s]} = ⋃\ns∈S{s} = S = ℜ1[S]. ⋄ Comment The results are the same, but not the implementation, because while the\nadapter ℜ1[S] implements a condition, the union of mechanisms ⋃ s∈S{ℜ0[s]} works unconditionally. Thus, the output of the union of mechanisms is independent of any problem, and then the union cannot implement ℜ1[PS ∧ Pπ] = ℜ1[S ∩ Σπ], for example, so it cannot implement any trial, see Theorem §3.3.5.\n§5.3.5 Lemma ∀S ∈ 2S, ∀π ∈ P, Ξℜ1[S ∩ Σπ] = { π | S ∩ Σπ 6= ∅ }. Proof Because Ξℜ1[S ∩ Σπ] = { π | (ℜ1[S ∩ Σπ] ⊆ Σπ) ∧ (ℜ1[S ∩ Σπ] 6= ∅) } =\n{ π | (S ∩ Σπ ⊆ Σπ) ∧ (S ∩ Σπ 6= ∅) } = { π | ⊤ ∧ (S ∩ Σπ 6= ∅) } = { π | S ∩ Σπ 6= ∅ }. ⋄\nComment The range of the adapter ℜ1[S ∩ Σπ] is the set of problems that have any solution in S. The adapter ℜ1[S∩Σπ] solves any problem such that any of its solutions are in S. Corollary If S ⊂ S′, then Ξℜ1[S ∩ Σπ] ⊂ Ξℜ1[S′ ∩ Σπ]. Proof In that case, if a solution to a problem is in S, then it is also in S′. But there\nare also solutions in S′ that are not in S. ⋄ §5.3.6 Lemma If s ∈ S, then ∀π ∈ P, Ξℜ0[{s}] ⊆ Ξℜ1[S ∩ Σπ]. Proof By Lemma §5.2.3, ∀π ∈ Ξℜ0[{s}], Pπ(s), that is, s ∈ Σπ, so, if s ∈ S, then\nS ∩ Σπ 6= ∅, and therefore π ∈ Ξℜ1[S ∩ Σπ], by Lemma §5.3.5. ⋄ Definition We will call s ∈ S the adapter condition. If the adapter condition holds,\nthen the adapter ℜ1[S ∩ Σπ] solves any problem that the mechanism ℜ0[s] solves. Corollary If {s} ⊂ S, then Ξℜ0[{s}] ⊂ Ξℜ1[S ∩ Σπ]. Proof Because, if t ∈ S and t 6= s, then δt ∈ Ξℜ1[S ∩ Σπ] but δt 6∈ Ξℜ0[{s}]. ⋄ Proposition If {s} ⊂ S, then Ξℜ0[{s}] 6⊂ Ξℜ1[S].\nBecause δs ∈ Ξℜ0[{s}], but δs 6∈ Ξℜ1[S]. §5.3.7 Lemma ∀S ∈ 2S, ∀π ∈ P, Φℜ1[S ∩ Σπ] = 2S . Proof Because Φℜ1[S ∩ Σπ] = { π | ℜ1[S ∩ Σπ] = Σπ } = { π | S ∩ Σπ = Σπ } =\n{ π | Σπ ⊆ S } = 2S , where the last equality uses the set isomorphism, see §3.2.8. ⋄ Comment The power of the adapter ℜ1[S ∩ Σπ] is the powerset of S. The adapter\nℜ1[S ∩ Σπ] resolves any problem such that all of its solutions are in S. Corollary If S ⊂ S′, then Φℜ1[S ∩ Σπ] ⊂ Φℜ1[S′ ∩ Σπ]. Proof Just because, if S ⊂ S′, then 2S ⊂ 2S′ . ⋄ §5.3.8 Lemma If s ∈ S, then ∀π ∈ P, Φℜ0[{s}] ⊂ Φℜ1[S ∩ Σπ]. Proof Using the set isomorphism, see §3.2.8, δs = Σδs = {s}, and then, if s ∈ S,\nΦℜ0[{s}] = {δs} = {{s}} ⊂ 2S = Φℜ1[S ∩ Σπ], by Lemmas §5.2.4 and §5.3.7. ⋄ Comment If the adapter condition holds, s ∈ S, then the adapter ℜ1[S ∩ Σπ] resolves\nany problem that the mechanism ℜ0[s] resolves, and more. Proposition If {s} ⊂ S, then Φℜ0[{s}] 6⊂ Φℜ1[S], because δs 6∈ Φℜ1[S] = {S}. §5.3.9 Lemma Any effectively calculable trial resolution Tπ(S) can be implemented by\nthe adapter ℜ1[S ∩ Σπ]. Proof Tπ(S) = { s ∈ S | s ∈ Σπ } = { s | s∈S ∧ s∈Σπ } = { s | PS(s) ∧ Pπ(s) }. Then\nTπ(S) . = ℜ1[PS ∧Pπ] = ℜ1[S ∩Σπ]. The equality is dotted because, if the trial is not an effectively calculable function, then it cannot be implemented. ⋄\n§5.3.10 Summary In practice, an adapter ℜ1[PS∧Pπ] = ℜ1[S∩Σπ] has a body capable of several behaviors that provides the set S of behaviors. If the current behavior were not satisfying the adapter condition Pπ, which is interpreted as an error, then the adapter would change its behavior trying another one in S.\nComment The adapter is a body capable of several behaviors, and a governor that selects the current behavior.\nExample A deciduous tree, which switches its behavior with seasons, is an adapter.\n§5.4 Perceiver\n§5.4.1 Definition A perceiver ℜ2 is any resolver that implements one transformation of the elements in S into the elements in S. We will note ℜ2[f ] the perceiver that implements f , where f ∈ (S → S), that is, ℜ2[f ] = f ∈ (S → S). Then the perceiver resources are in S → S, and {· ℜ2 ·} = (S → S). Comment From a semantic point of view, a perceiver ℜ2 implements a semantic functional computation. From a syntactic point of view, a perceiver ℜ2 implements a syntactic unconditional computation.\n§5.4.2 Remark Perceivers are to syntax as mechanisms are to semantics. Comment When solutions are functions S → S, then a perceiver does what a mech-\nanism does, which is to return a solution unconditionally. That is, perceivers on metaproblems are as mechanisms on problems. But, perceivers can go further. Comment The perceiver ℜ2[f ] implements function f from S to S, that is, f : S → S. Then, ∀s ∈ S, ℜ2[f ](s) = f(s) ∈ S.\n§5.4.3 Notation By the rewriting rules in §3.1.3, ℜ2[f ](S) = {ℜ2[f ](s) | s ∈ S } ∈ 2S. Then ℜ2[f ](S) returns a set of solutions, as any well-behaved resolution should do. Comment The perceiver ℜ2[f ](S) implements f , meaning that f is hardwired in the perceiver, while S is just data. We will call what is implemented hardware, and what is data software. We write the hardware between brackets, and the software between parentheses. We will assume that coding software costs less than implementing hardware, or, in fewer words, that software is cheaper than hardware\n§5.4.4 Lemma Every adapter ℜ1 is a perceiver ℜ2, that is, {· ℜ1 ·} ⊂ {· ℜ2 ·}. Proof Because B ⊂ S, and then (S → B) ⊂ (S → S). So\n{· ℜ1 ·} = (S → B) ⊂ (S → S) = {· ℜ2 ·}. ⋄ Comment Each adapter implements one condition PS ∈ (S → B). And any condition\nPS ∈ (S → B) is also a function PS ∈ (S → S), because B ⊂ S. Therefore, for each adapter ℜ1[PS ], which implements condition PS , there is a perceiver ℜ2[PS ] that implements the function PS , and then we write ℜ1[PS ] = PS = ℜ2[PS ]. Comment Again, ℜ1[PS ] = ℜ2[PS ] explains that the results are the same, but not the implementation.\n§5.4.5 Lemma ∀S ∈ 2S, ℜ1[S] = ℜ2[i](S). Proof Function i : S → S is the semantic identity, i = i see §5.1.10, so ∀s ∈ S, i(s) = s,\nand ℜ2[i](S) = {ℜ2[i](s) | s ∈ S } = { i(s) | s ∈ S } = { s | s ∈ S } = S = ℜ1[S]. ⋄ Comment The same perceiver hardware ℜ2[i], just by changing its software, can em-\nulate different adapters: ℜ2[i](S) = ℜ1[S], and ℜ2[i](S′) = ℜ1[S′]. Then the perceiver ℜ2[i](S) is more flexible than the adapter ℜ1[S], because S is hardwired in the adapter, while it is easily replaceable data for the perceiver.\n§5.4.6 Lemma ∀S ∈ 2S, Ξℜ1[S] = Ξℜ2[i](S) and Φℜ1[S] = Φℜ2[i](S). Proof Because, by Lemma §5.4.5, ℜ1[S] = ℜ2[i](S). ⋄ Definition The perceiver condition is satisfied if it implements the semantic identity i. Comment If the perceiver condition holds, then the perceiver ℜ2[i](S) solves any prob-\nlem solved by the adapter ℜ1[S], and the perceiver ℜ2[i](S) resolves any problem resolved by the adapter ℜ1[S].\nRemark Semantic identity i is the ideal for perception.\n§5.4.7 Corollary Ξℜ2[i](S ∩Σπ) = Ξℜ1[S ∩Σπ] and Φℜ2[i](S ∩Σπ) = Φℜ1[S ∩Σπ]. Proof By Lemma §5.4.6. ⋄ Comment The same perceiver hardware ℜ2[i] can be tuned to a different trial just by\nchanging its software, from ℜ2[i](S ∩ Σπ) to ℜ2[i](S′ ∩ Σρ), for example. Proposition If S ⊂ S′, then Ξℜ2[i](S ∩Σπ) ⊂ Ξℜ2[i](S′ ∩Σπ), and Φℜ2[i](S ∩Σπ) ⊂\nΦℜ2[i](S′ ∩ Σπ), by Lemma §5.4.5 and corollaries to Lemmas §5.3.5 and §5.3.7. §5.4.8 Definition A function on sets F : 2S → 2S is elementable if it exists an\neffectively calculable function f : S → S such that ∀S, F (S) = { f(s) | s ∈ S }. Comment We write F (S) = f(S), by the rules in §3.1.3. Note the three requirements:\nthat f is a semantic function, f : S → S, that f is effectively calculable, and that F (S) = f(S). Proposition Set identity I : 2S → 2S | ∀S ∈ 2S, I(S) = S, is elementable by semantic identity i, because ∀S ∈ 2S, i(S) = { i(s) | s ∈ S } = { s | s ∈ S } = S = I(S).\n§5.4.9 Lemma Any analogy resolution A ◦ TAπ(S) ◦ TA can be implemented by the tri-perceiver ℜ2[Ta](ℜ2[i](S ∩ ℜ2[a](Σπ))), if A is elementable by a, and TA by Ta. Proof An analogy resolution is A ◦ TAπ(S) ◦ TA. Both A and TA are functions from sets to sets, TA : 2S → 2S and A : (P → P) = (2S → 2S), so if both A and TA are elementable, then a perceiver can implement them. We have a and Ta, which are both semantic functions such that A(S) = a(S), and TA(S) = Ta(S). Then Paπ = a(Pπ) = ℜ2[a](Pπ) = ℜ2[a](Σπ) implements the first third, Taπ(S) = ℜ1[PS ∧ Paπ] = ℜ1[PS ∧ ℜ2[a](Pπ)] = ℜ1[S ∩ ℜ2[a](Σπ)] implements the second third, see §5.3.9, and using §5.4.5, ℜ2[Ta](ℜ2[i](S ∩ ℜ2[a](Σπ))) implements the whole analogy resolution a ◦ Taπ(S) ◦ Ta. ⋄ Corollary Identity analogy I ◦ TIπ(S) ◦ TI can be implemented by the bi-perceiver ℜ2[i](S ∩ ℜ2[i](Σπ)), which uses the identity perceiver ℜ2[i] twice. Proof ℜ2[Ti](ℜ2[i](S∩ℜ2[i](Σπ))) = ℜ2[i](ℜ2[i](S∩ℜ2[i](Σπ))) = ℜ2[i](S∩ℜ2[i](Σπ)), because set identity I is elementable by semantic identity i, and TI = I, so it is also elementable by Ti = i, and i ◦ i = i. ⋄\n§5.4.10 Summary While an adapter uses a trial and error resolution, and this means that error is part of the usual procedure, a perceiver executes the trial and error inside itself. If the analogy provides a good model, then the internal trial is as good as the external one, with the advantage that the errors are only simulated errors. More to the point, if the problem the resolver faces is the survival problem, then the adapter errors are literally death errors, or at least pain, while the perceiver errors are just mental previsions of what not to do. See that, if the perceiver implements the identity analogy, as ℜ2[i] does, then the model is good, because the internal problem is equal to the external one. And the perceiver ℜ2[i] is more flexible than the adapter.\nComment The perceiver is a body capable of several behaviors, a governor that selects the current behavior, and a simulator that internalizes behaviors.\nExample The perceiver governor determines what to do based upon an internal interpretation. According to Lettvin et al. (1959), a frog is a perceiver that uses an internal routine. Frog’s i is such that any dark point that moves rapidly in its field of vision is a fly which it will try to eat.\n§5.5 Learner\n§5.5.1 Definition A learner ℜ3 is any resolver that implements one condition on the members of S → S. We will note ℜ3[PF ] the learner that implements PF , where PF ∈ ((S → S) → B), that is, ℜ1[PF ] = PF ∈ ((S → S) → B). Then the learners resources are in (S → S) → B, and {· ℜ3 ·} = ((S → S) → B). Comment A learner ℜ3 implements a syntactic conditional computation.\n§5.5.2 Remark Learners are to syntax as adapters are to semantics. Comment When solutions are functions S → S, then a learner does what an adapter\ndoes, which is to return a predicate on solutions. That is, learners on metaproblems are as adapters on problems. But, learners can go further.\n§5.5.3 Lemma Each learner ℜ3[PF ] implements one set of members of (S → S). Proof Because every predicate PF : (S → S) → B defines a set\nF = { f ∈ (S → S) | PF (f) } ∈ 2S→S. The condition PF is the characteristic function of F , ∀f ∈ (S → S), PF (f) = [f ∈ F ]. ⋄ Comment We will write ℜ3[PF ] = ℜ3[F ] = F ∈ 2S→S. Comment The learner ℜ3[F ] implements F ∈ 2S→S. So ∀s ∈ S, ℜ3[F ](s) = F (s) ∈ 2S,\nbecause F (s) = { f(s) | f ∈ F }, by the rewriting rules in §3.1.3, and then ℜ3[F ](s) returns a set of solutions, as any well-behaved resolution should do. Also, by the same rules, ℜ3[F ](S) = F (S) = { f(s) | s∈S × f ∈F } ∈ 2S.\n§5.5.4 Lemma Every perceiver ℜ2 is a learner ℜ3, that is, {· ℜ2 ·} ⊂ {· ℜ3 ·}. Proof For each perceiver ℜ2[f ], which implements f ∈ (S → S), there is a learner\nℜ3[Pδf ], see §4.3.14, that implements the singleton {f} ∈ ((S → S) → B). But not every set is a singleton. Then, {· ℜ2 ·} = (S → S) ⊂ ((S → S) → B) = {· ℜ3 ·}. ⋄\n§5.5.5 Lemma ℜ3[F ] = ⋃ f∈F {ℜ2[f ]}. Proof Because ℜ2[f ] = f , so ⋃ f∈F {ℜ2[f ]} = ⋃\nf∈F {f} = F = ℜ3[F ]. ⋄ Comment Again, the results are the same, but not the implementation. The union of\nperceivers ⋃ f∈F {ℜ2[f ]} cannot select a function to use, so it cannot implement any meta-trial, as ℜ3[R ∩ ΣΠπ] does, see §5.5.11.\nComment These are not sets of solutions, but sets of semantic functions.\n§5.5.6 Lemma ∀f ∈ F , ∀S ∈ 2S, ℜ2[f ](S) ⊆ ℜ3[F ](S). Proof If f ∈ F , then f(S) = { f(s) | s ∈ S } ⊆ { f ′(s) | s∈S × f ′∈F } = F (S). ⋄\n§5.5.7 Notation We will rewrite ℜ1[ℜ3[F ](S) ∩ Σπ] as ℜ3[F ](S ∩ Σπ). Comment We can write ℜ1[ℜ3[F ](S) ∩Σπ] = ℜ3[F ](S ∩ Σπ), because any learner can\nimplement semantic conditions, that is, because {· ℜ1 ·} ⊂ {· ℜ3 ·}.\n§5.5.8 Lemma If f ∈ F , then ∀S ∈ 2S, ∀π ∈ P, Ξℜ2[f ](S) ⊆ Ξℜ3[F ](S ∩ Σπ). Proof Firstly see that, if f ∈ F , then f(S) ⊆ F (S), by §3.1.3, so, f(S) ∩ Σπ ⊆\nF (S) ∩ Σπ. Secondly see that ∀π ∈ Ξℜ2[f ](S), f(S) ∩ Σπ = f(S) 6= ∅. This is because Ξℜ2[f ](S) = { π | f(S) ⊆ Σπ ∧ f(S) 6= ∅ }. Now, taking both together, ∀π ∈ Ξℜ2[f ](S), ∅ 6= f(S) = f(S)∩Σπ ⊆ F (S) ∩Σπ, so for these π, F (S) ∩Σπ 6= ∅. Then these π ∈ { π | F (S) ∩ Σπ ⊆ Σπ ∧ F (S) ∩ Σπ 6= ∅ } = Ξℜ1[ℜ3[F ](S) ∩ Σπ], because F (S) ∩ Σπ ⊆ Σπ is always true. ⋄ Definition We will call f ∈ F the learner condition. If the learner condition holds, then the learner ℜ3[F ](S ∩Σπ) solves any problem that the perceiver ℜ2[f ](S) solves.\n§5.5.9 Lemma If f ∈ F , then ∀S ∈ 2S, ∀π ∈ P, Φℜ2[f ](S) ⊆ Φℜ3[F ](S ∩ Σπ). Proof If f ∈ F , then f(S) ⊆ F (S), see §3.1.3, so, f(S) ∩ Σπ ⊆ F (S) ∩ Σπ. Now\n∀π ∈ Φℜ2[f ](S), f(S) = Σπ, and then for these π, Σπ = f(S)∩Σπ ⊆ F (S)∩Σπ ⊆ Σπ. Therefore, for these π, F (S) ∩ Σπ = Σπ, and Φℜ2[f ](S) ⊆ { π | F (S) ∩ Σπ = Σπ } = Φℜ1[ℜ3[F ](S) ∩ Σπ]. ⋄ Comment If the learner condition holds, f ∈ F , then the learner ℜ3[F ](S ∩Σπ) resolves any problem that the perceiver ℜ2[f ](S) resolves.\n§5.5.10 Corollary In particular, if i ∈ R, then Ξℜ2[i](S ∩ Σπ) ⊆ Ξℜ3[R](S ∩ Σπ) and Φℜ2[i](S ∩ Σπ) ⊆ Φℜ3[R](S ∩ Σπ). Proof By Lemmas §5.5.8 and §5.5.9. See that Ξℜ3[R](S∩Σπ ∩Σπ) ⊆ Ξℜ3[R](S ∩Σπ), and Φℜ3[R](S ∩Σπ ∩ Σπ) ⊆ Φℜ3[R](S ∩ Σπ), because ℜ3[R](S ∩Σπ) ⊆ ℜ3[R](S), so corollaries to Lemmas §5.3.5 and §5.3.7 apply (the equal case is trivial). ⋄\n§5.5.11 Lemma Any meta-trial resolution TΠπ(R) can be implemented by the learner ℜ3[R ∩ ΣΠπ], if PR and PΠπ are elementable. Comment The diagram for the meta-trial, or trial of the metaproblem, see §3.6.9, is:\nπ Π−−→Ππ TΠπ(R)−−−−−→ΣΠπ TΠ−−→Σπ .\nComment A learner solves metaproblems by trial, as an adapter solves problems by trial. The following correlations stand: ℜ3 ↔ ℜ1, Ππ ↔ π, R ↔ S, and then ℜ3[R ∩ΣΠπ] ↔ ℜ1[S ∩Σπ]. Therefore, ℜ3[R ∩ΣΠπ] compares to ℜ2[i], where i ∈ R, as ℜ1[S ∩ Σπ] compares to ℜ0[s], where s ∈ S. Proof TΠπ(R) = { r ∈ R | r ∈ ΣΠπ } = { r | r∈R ∧ r∈ΣΠπ } = { r | PR(r)∧PΠπ(r) }. In the meta-trial TΠπ(R), R is a set of resolutions, where R = (P → 2S) = (2S → 2S), that is, PR : (2\nS → 2S) → B, and the condition of the metaproblem Ππ is also PΠπ : R → B = (P → 2S) → B = (2S → 2S) → B. So if both PR and PΠπ are elementable by ℘R and ℘Ππ, then both of them, and its conjunction, are implementable. Then TΠπ(R) = { r | PR(r) ∧ PΠπ(r) } .= ℜ3[℘R ∧ ℘Ππ] = ℜ3[R ∩ ΣΠπ]. ⋄\n§5.5.12 Summary Perceiver success depends crucially on the analogy, that is, on how much the analogy resembles the identity i. And a learner can adapt the analogy to the problem it is facing, because the learner ℜ3[R] implements a set of functions R from which it can select another analogy when the current one fails. Adapting the analogy is also known as modeling. So a learner can apply different analogies, but a learner can also apply a routine if it knows a solution, because the routine is more efficient, or a trial, when the model is not good enough or too pessimistic.\nComment The learner is a body capable of several behaviors, a governor that selects the current behavior, a simulator that internalizes behaviors, and a modeler that adjusts the model used by the simulator.\nExample Where there is modeling and simulation there is learning, because enhancing the model prevents repeating errors. A dog is a learner.\n§5.6 Subject\n§5.6.1 Definition A subject ℜ4 is any resolver that implements one transformation of the elements in S → S into the elements in S → S. We will note ℜ4[f] the subject that implements f, where f ∈ ((S → S) → (S → S)), that is, ℜ4[f] = f ∈ ((S → S) → (S → S)). Then the subject resources are in (S → S) → (S → S), and {· ℜ4 ·} = ((S → S) → (S → S)). Comment A subject ℜ4 implements a syntactic functional computation. §5.6.2 Remark Subjects are to syntax as perceivers are to semantics. Comment When solutions are functions S → S, then a subject does what a perceiver\ndoes, which is to return a function on solutions to solutions. That is, subjects on metaproblems are as perceivers on problems. But, subjects can go further. Comment The subject ℜ4[f] implements function f from S → S to S → S, that is, f : (S → S) → (S → S). Then, ∀f ∈ (S → S), ℜ4[f](f) = f(f) ∈ (S → S).\n§5.6.3 Notation As resolutions return sets of elements in S, to normalize the situation of subjects, for which ℜ4[f](f)(s) ∈ S, we will use the rewriting rules in §3.1.3 to get ℜ4[f](F )(S) = {ℜ4[f](f)(s) | s∈S × f ∈F } ∈ 2S. Comment Subject ℜ4[f](F )(S) has two software levels: semantics (S) and syntax (F ). §5.6.4 Lemma Every learner ℜ3 is a subject ℜ4, that is, {· ℜ3 ·} ⊂ {· ℜ4 ·}. Proof First we define set B = {K⊤, K⊥}, both functions S → S, see §5.1.8. Next we\ndefine the the natural isomorphism between B and B, mapping ⊤ to the function that always returns ⊤, which is K⊤ = Pτ , and ⊥ to the function that always returns ⊥, which is K⊥ = Pτ̄ , see §3.1.11. And so B ⇔ B : ⊤ ↔ K⊤,⊥ ↔ K⊥, and B ∼= B ⊂ (S → S). Then, ((S → S) → B) ⊂ ((S → S) → (S → S)), and therefore {· ℜ3 ·} = ((S → S) → B) ⊂ ((S → S) → (S → S)) = {· ℜ4 ·}. ⋄ Comment Each learner implements one condition PF ∈ ((S → S) → B). And any condition on functions PF ∈ ((S → S) → B) is also a function on functions to functions PF ∈ ((S → S) → (S → S)), because B ⊂ (S → S). Therefore, for each learner ℜ3[PF ], which implements condition PF , there is a subject ℜ4[PF ] that implements the function PF , and then we write ℜ3[PF ] = PF = ℜ4[PF ]. Comment Again, ℜ3[PF ] = ℜ4[PF ] explains that the results are the same, but not the implementation.\n§5.6.5 Lemma ∀F ∈ 2S→S, ∀S ∈ 2S, ℜ3[F ](S) = ℜ4[u](F )(S). Comment Function u is the identity for programs, see §4.2.3, or functional identity, or\nevaluation, see §4.3.9. Function u is syntactic because it is not restricted to semantic objects, see §5.1.10. Syntactic function u is equivalent to λ-calculus I = (λx.x), see §3.4.9: ∀f ∈ S → S, u(f) = f and ∀s ∈ S, u(f)(s) = f(s). Proof By the rewriting rules in §3.1.3, ℜ4[u](F )(S) = {ℜ4[u](f)(s) | s∈S× f ∈F } = { u(f)(s) | s∈S × f ∈F } = { f(s) | s∈S × f ∈F } = F (S) = ℜ3[F ](S). ⋄ Corollary ∀F ∈ 2S→S, ℜ3[F ] = ℜ4[u](F ).\n§5.6.6 Lemma ∀F ∈ 2S→S, ∀S ∈ 2S, Ξℜ3[F ](S) = Ξℜ4[u](F )(S) and Φℜ3[F ](S) = Φℜ4[u](F )(S). Proof Because, by Lemma §5.6.5, ℜ3[F ](S) = ℜ4[u](F )(S). ⋄ Definition The subject condition is satisfied if it implements the functional identity u. Comment If the subject condition holds, then the subject ℜ4[u](F )(S) solves any prob-\nlem solved by the learner ℜ3[F ](S), and also the subject ℜ4[u](F )(S) resolves any problem resolved by the learner ℜ3[F ](S).\nRemark Functional identity u is the ideal for reason.\n§5.6.7 Corollary In particular, Ξℜ4[u](R)(S ∩ Σπ) = Ξℜ3[R](S ∩ Σπ) and Φℜ4[u](R)(S ∩ Σπ) = Φℜ3[R](S ∩ Σπ). Proof By Lemma §5.6.6. ⋄ Comment Subject ℜ4[u](R)(S∩Σπ) is more flexible than learner ℜ3[R](S∩Σπ), because\nR is software for the subject while it is hardware in the learner, and software is cheaper than hardware, see §5.4.3.\n§5.6.8 Theorem Subject ℜ4[u] is a full resolution machine. Proof By Theorem §4.2.1 and Lemma §4.2.3, ℜ4[u] = u = c(U), so using the program\nisomorphism, see §4.1.12, ℜ4[u] = U , which is a Turing complete device, and therefore is a full resolution machine, by Theorem §4.4.2. ⋄\n§5.6.9 Lemma Any effectively calculable resolution ℜ can be implemented by the subject ℜ4[u]. Proof By Theorem §5.6.8. ⋄ Corollary Any effectively calculable meta-analogy resolution A ◦ TAΠπ(R) ◦ TA can\nbe implemented by the subject ℜ4[u], including metaresolving, see §3.5.11. §5.6.10 Summary The subject, by internalizing metaproblems, prevents meta-errors,\nthat is, the subject can test internally a resolution before executing it. The subject is also more flexible than the learner, because subject modeling is done in software, instead of in hardware. And subject ℜ4[u] can reason about any model. This means that subject ℜ4[u] is a resolver that can calculate solutions, but also problems and resolutions without limits; it can represent the problem it is facing to itself, and it can represent itself to itself. In this sense, the subject ℜ4[u] is conscious.\nComment The subject is a body capable of several behaviors, a governor that selects the current behavior, a simulator that internalizes behaviors, a modeler that adjusts the model used by the simulator, and a reason that internalizes resolutions.\nExample It seems that only our species, Homo sapiens, is Turing complete. We deal with the evolution to Turing completeness and its relation to language in Casares (2016b).\n§5.7 Resolvers Hierarchy\n§5.7.1 Theorem There is a hierarchy of resolvers: {· ℜ0 ·} ⊂ {· ℜ1 ·} ⊂ {· ℜ2 ·} ⊂ {· ℜ3 ·} ⊂ {· ℜ4 ·}. Proof Because S ⊂ (S → B) ⊂ (S → S) ⊂ ((S → S) → B) ⊂ ((S → S) → (S → S)), by Lemmas §5.3.3, §5.4.4, §5.5.4, and §5.6.4. There are not more types of resolvers, because there is not a resolver more capable than ℜ4[u] = U , by Theorems §5.6.8 and §4.3.4. ⋄\n§5.7.2 Summary This table groups concepts closely related from problem theory, as trial, computing theory, as adapter ℜ1, and set theory, as S ∈ S → B.\nSemantics Syntax\nRoutine Meta-routine one Mechanism ℜ0 Perceiver ℜ2 element\ns ∈ S f ∈ (S → S) Trial Meta-trial\nsome Adapter ℜ1 Learner ℜ3 set S ∈ S → B F ∈ (S → S) → B Analogy Meta-analogy\nany Perceiver ℜ2 Subject ℜ4 function f ∈ S → S f ∈ (S → S) → (S → S)\nS S → S Elements Functions\nComment A perceiver is a syntactic mechanism. A learner is a syntactic adapter. A subject is a syntactic perceiver. A subject is a syntactic2 mechanism.\n§5.7.3 Theorem The problem theory is complete. Proof Aside from definitions, the problem theory posits that there are three ways to\nresolve a problem: routine, trial, and analogy; see §2.3. Adding the metaproblem of the problem, we get five ways to resolve a problem and its metaproblem, which are the basic three plus meta-trial and meta-analogy, see §3.6.8. For each way there is a resolver, see Lemmas §5.2.5, §5.3.9, §5.4.9, §5.5.11, and §5.6.9, and the resources of each resolver are in a series of mathematical objects of increasing generality that covers everything until syntactic functions, see §5.7.1 and §5.7.2. Now, to execute metaanalogies, 22\nS→2S → 22S→2S, see §3.6.9, or at least the elementable ones, see §5.4.8, we need subjects, which implement syntactic functions (S → S) → (S → S). And there is a subject that is a Turing complete device, ℜ4[u], see §5.6.8, so it has the maximum computing power, see §4.3.4, and then the maximum resolving power, see §4.4.2. This means that there are not more resolvers beyond the subject, and therefore that the series is complete, and then that the problem theory covers everything and is complete. ⋄\nComment It also means that no more resolutions are needed, although we could do without routine, for example, by using Theorem §3.3.7, and then reducing routines to trials. Nevertheless, a routine is not a trial, because a semantic element is not a semantic set, or because a mechanism implementing a routine is not an adapter implementing a trial, see comment to Lemma §5.3.4. Comment This theorem is true if the Turing’s thesis is true, see §4.3.1. Conversely, if this theorem is true, then ‘what is effectively calculable to resolve problems is computable’.\n§5.7.4 Remark Provided that a bigger range means more survival opportunities, that software is cheaper than hardware, that the adapter, the perceiver, the learner, and the subject conditions are satisfied in some environments, and that in each step the increasing of complexity was overcome by its fitness, then an evolution of resolvers —mechanism to adapter to perceiver to learner to subject— should follow.\nComment Although depending on conditions, see Lemmas §5.3.6, §5.4.6, §5.5.8, and §5.6.6, the evolution of resolvers is directed, and its final singularity is the Turing complete subject ℜ4[u]. Comment In detail, the strictest evolution of resolvers is: Ξℜ0[s] {s}⊂S⊂ Ξℜ1[S ∩Σπ]\nS⊂S′⊂ Ξℜ2[i](S′∩ Σπ) {i}⊂R ⊆ Ξℜ3[R](S′ ∩ Σπ) R⊂R′\n⊆ Ξℜ4[u](R′)(S′ ∩ Σπ). §5.7.5 Thesis We are the result of an evolution of resolvers of the survival problem. Argument The resolvers hierarchy suggests an evolution of resolvers of the survival\nproblem, see §5.7.4. And lacking of better explanations, that we are Turing complete resolvers, that is, subjects ℜ4[u] = U , see §4.2.8, suggests that we are indeed the result of an evolution of resolvers of the survival problem.\nComment Our species is Turing complete. Therefore we must explain the evolution of Turing completeness.\n§6 Conclusion\n§6.1 Purpose ¶1 · The problem theory is the union of set theory and computing theory. The integration of the two theories is achieved by using a new vocabulary to refer to old concepts, but mainly by giving the old theories a purpose that they did not have: to resolve problems. For example, a set defined by intension is named a problem, and the same set defined by extension is named its set of solutions. While both still refer to the same set, as it is the case in set theory, the status of each of them is now very different: one is a question and the other is an answer. And when the problem theory states that computing is resolving, it is calling a set resolvable if it is recursively enumerable, but mainly it is saying that the transition from intension to extension has to be calculated, because it is not written magically in “The Book”; someone has to write it. ¶2 · The purpose of resolving problems is not final, but the main conclusion of the paper, the Thesis §5.7.5, is nearly ultimate: We are Turing complete subjects because we are the result of an evolution of resolvers of the survival problem. In other words, we resolve problems to survive. So, if survival is indeed the ultimate purpose, then the problem theory provides purpose and meaning to set theory and to computing theory. ¶3 · The final Thesis §5.7.5 also closes a loop, because a Turing complete resolver ℜ4[u] can model everything, and then everything can be a solution, as it is stated in Theorem §3.2.1. But those everythings are not absolute, but limited to what is computable, see §4.4.11. That is, if Turing’s thesis stands, see §4.3.1, then everything is everything that is computable. This way a restriction of computing theory, countability, is inherited by problem theory and transferred to set theory; see the details below in Subsection §6.2. The other question that requires some more elaboration is the status of the Turing’s thesis itself, which we will postpone until Subsection §6.3. ¶4 · Nevertheless, besides that main Thesis §5.7.5, the problem theory concepts presented in this paper can be used to model, understand, and classify both natural and artificial resolvers, because the paper provides definitions, theorems, and taxonomies for resolvers, and also for problems. And, by the way, the paper defines adaptation, perception, and learning, and it shows that there are just three ways to resolve any problem: routine, trial, and analogy.\n§6.2 Countability ¶1 · In computing everything is countable, see §4.1.14, and the problem theory in Turing universes inherited countability from computing theory, see §4.3.16. In a Turing universe, see §4.3.3, the limits of calculation are the limits of computing, and then there are only computable functions, including predicates, see §4.1.9, and computable sets, see §4.4.3. Then the problem theory in Turing universes is consistent if and only if computing is consistent. And computing is consistent, as a corollary to Church-Rosser theorem in λ-calculus, see Curry & Feys (1958) Chapter 4. ¶2 · Therefore, our way to control paradoxes in set theory, and then in this paper, is to confine ourselves to Turing universes. But don’t worry; if this is a Turing universe, as it seems to be, then we are only excluding imaginary universes. ¶3 · For example, the mathematical theorem that states that everything is a solution is proved, and it makes sense, see §3.2.1. But it also causes paradoxes, because from it we derive P ⊂ S, but P 1= (S → B) 2= 2S, and then |P| 3= |2S| 4= 2|S| > |S|, by Cantor’s theorem. It is not a paradox in a Turing universe because the forth equality is false in it. The second equality is false in a Turing universe because, as we saw in Lemma §4.4.8, there are resolvable problems that are not expressible, so (S → B) ∗⊂ 2S. The third equality is true, though it follows the second one! And the forth equality is false in a Turing universe because the number of computable sets is countable, so, if |S∗| = ℵ0, then |2S|∗ = ℵ0 < 2ℵ0 = 2|S\n∗|, that is, |2S| ∗< 2|S|. Therefore, P∗⊂ S∗ is true, but P∗ is the set of computable predicates, that is, P∗ = E of §4.5.8, and [2S]∗ ⊂ S∗ is also true, but [2S]∗ is the set of computable sets, that is, [2S]∗ = R of §4.5.8. The conclusion is that S∗, the set of solutions, is the set of everything that is computable. ¶4 · We have just rejected the uncountable case, where |P| > ℵ0, but there are two other possibilities: the (infinite) countable case, where |S∗| = |P∗| = |R∗| = ℵ0, see §4.3.16; and the finite case, where |SΓ| < |PΓ| < |RΓ| < ℵ0, see §5.1.7. ¶5 · We are finite, so it would be natural to restrict our investigations to the finite case, calling for finiteness instead of calling for countableness. But the finite case is trivial, and more importantly, the difference between an unrestricted universal computer and a finite universal computer is not qualitative but quantitative. There is not any step of any calculation that an unrestricted universal computer can compute and a finite universal computer cannot compute, see §4.2.10. So in the limit, that is, without time nor memory restrictions, we are universal computers. And note that those restrictions are variable, and that they can be relaxed nearly as desired just spending some more time, or building a faster computer machine, or using some more external memory. In the case of a Turing machine, the external memory is the tape, and the internal memory is where its processor keeps the internal state, see §4.1.3. Note also that we can code a program to generate every natural number, although we cannot follow the computation till its end. Summarizing: we are better defined saying that we are qualitatively universal Turing machines, but with some unspecified quantitative limitations, than saying that we are qualitatively finite state automata, because finite state automata are not expandable. ¶6 · Finally, the rejections of finiteness and uncountableness imply that countableness is the golden mean. This is Pythagorean heaven revisited, everything is countable, but this time we have rescued the terrifying √ 2, and other irrational numbers. As Kronecker said:\n“God made counting numbers; all else is the work of man”.\n§6.3 Intuition ¶1 · Is it possible to resolve a non-computable problem? A problem is computable if, by definition, see §4.4.3 and §4.4.4, a Turing machine can execute a valid resolution of the problem, so the non-computable problem would not be resolved by computing, but by other means. My answer to the question is ‘no’, because I think that a problem is resolvable if, and only if, the problem is computable, see §4.3.12. ¶2 · Nevertheless you may think otherwise, and say that there is another way of resolving, let us call it ‘intuition’, that is not computable. If that were the case, then the problem theory with its mathematical formulation, as presented in this paper, would capture the concept of ‘computable problem’, but not the whole concept of ‘problem’. In order to see this, please consider the following two statements: ◦ Some problems are computable. ◦ A universal computer can execute any computable resolution.\nEven if you believe that there are resolvable problems that are not computable, you can still decide easily that both are true; the first is a fact, and the second is a theorem. And then everything in this paper would still be true of computable problems, computable resolutions, and computable solutions. ¶3 · The key point in this discussion is that ‘intuition’ would refute Turing’s thesis, see §4.3.1, because if there were ‘intuitive’ resolutions, then we could effectively calculate what is not computable. Turing’s thesis is not a theorem, and we follow Post (1936) in considering Turing’s thesis to be a law of nature that states a limitation of our own species calculating capacity, see Casares (2016a), by which we are bound to see ourselves as a final singularity. Summarizing: If Turing’s thesis were eventually false, then this problem theory would be about computable problems. But, while Turing’s thesis remains valid, the problem theory is about problems, the set of effectively calculable functions is countable (§4.3.1), universal computers are the most capable computing devices (§4.3.4), everything is an expression (§4.3.10), resolving is computing (§4.3.12), and the problem theory is complete (§5.7.3)."
    } ],
    "references" : [ {
      "title" : "Turing, “On Computable Numbers, with an Application to the Entscheidungsproblem”; in Proceedings of the London Mathematical Society",
      "author" : [ "M. Alan" ],
      "venue" : "vol. s242,",
      "citeRegEx" : "Alan,? \\Q1937\\E",
      "shortCiteRegEx" : "Alan",
      "year" : 1937
    }, {
      "title" : "Turing, “Systems of Logic Based on Ordinals”; Princeton University PhD dissertation",
      "author" : [ "M. Alan" ],
      "venue" : "Submitted 17 May,",
      "citeRegEx" : "Alan,? \\Q1938\\E",
      "shortCiteRegEx" : "Alan",
      "year" : 1938
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "The Turing machine, as it was presented by Turing himself, models the calculations done by a person. This means that we can compute whatever any Turing machine can compute, and therefore we are Turing complete. The question addressed here is why, Why are we Turing complete? Being Turing complete also means that somehow our brain implements the function that a universal Turing machine implements. The point is that evolution achieved Turing completeness, and then the explanation should be evolutionary, but our explanation is mathematical. The trick is to introduce a mathematical theory of problems, under the basic assumption that solving more problems provides more survival opportunities. So we build a problem theory by fusing set and computing theories. Then we construct a series of resolvers, where each resolver is defined by its computing capacity, that exhibits the following property: all problems solved by a resolver are also solved by the next resolver in the series if certain condition is satisfied. The last of the conditions is to be Turing complete. This series defines a resolvers hierarchy that could be seen as a framework for the evolution of cognition. Then the answer to our question would be: to solve most problems. By the way, the problem theory defines adaptation, perception, and learning, and it shows that there are just three ways to resolve any problem: routine, trial, and analogy. And, most importantly, this theory demonstrates how problems can be used to found mathematics and computing on biology.",
    "creator" : "dvips(k) 5.991 Copyright 2011 Radical Eye Software"
  }
}