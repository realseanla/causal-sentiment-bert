{
  "name" : "1604.02006.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "vhonavar@ist.psu.edu;  Web", "markhill@cs.wisc.edu;  Web", "yelick@berkeley.edu;  " ],
    "sections" : [ {
      "heading" : null,
      "text" : "   1  \nACCELERATING  SCIENCE:  A  COMPUTING  RESEARCH  AGENDA   Vasant  G.  Honavar1,  Mark  D.  Hill2,  and  Katherine  Yelick3  \nComputing  Community  Consortium   2/19/2016  \n   Version  1  \n  \nAbstract  \nThe  emergence  of  “big  data”  offers  unprecedented  opportunities  for  not  only  accelerating  scientific   advances   but   also   enabling   new   modes   of   discovery.   Scientific   progress   in   many   disciplines   is   increasingly  enabled  by  our  ability  to  examine  natural  phenomena  through  the  computational  lens,   i.e.,  using  algorithmic  or  information  processing  abstractions  of  the  underlying  processes;  and  our   ability   to  acquire,   share,   integrate  and  analyze  disparate   types  of  data.  However,   there   is  a  huge   gap  between  our  ability  to  acquire,  store,  and  process  data  and  our  ability  to  make  effective  use  of   the   data   to   advance   discovery.   Despite   successful   automation   of   routine   aspects   of   data   management  and  analytics,  most  elements  of  the  scientific  process  currently  require  considerable   human  expertise  and  effort.  Accelerating  science  to  keep  pace  with  the  rate  of  data  acquisition  and   data   processing   calls   for   the   development   of   algorithmic   or   information   processing   abstractions,   coupled  with  formal  methods  and  tools  for  modeling  and  simulation  of  natural  processes  as  well  as   major   innovations   in   cognitive   tools   for   scientists,   i.e.,   computational   tools   that   leverage   and   extend   the   reach   of   human   intellect,   and   partner   with   humans   on   a   broad   range   of   tasks   in   scientific  discovery   (e.g.,   identifying,  prioritizing   formulating  questions,  designing,  prioritizing  and   executing  experiments  designed  to  answer  a  chosen  question,  drawing   inferences  and  evaluating   the   results,   and   formulating   new   questions,   in   a   closed-‐loop   fashion).   This   calls   for   concerted   research   agenda   aimed   at:   Development,   analysis,   integration,   sharing,   and   simulation   of   algorithmic   or   information   processing   abstractions   of   natural   processes,   coupled   with   formal   methods  and  tools   for   their  analyses  and  simulation;   Innovations   in  cognitive   tools   that  augment   and  extend  human  intellect  and  partner  with  humans  in  all  aspects  of  science.  This  in  turn  requires:   the  formalization,  development,  analysis,  of  algorithmic  or   information  processing  abstractions  of   various   aspects   of   the   scientific   process;   the   development   of   computational   artifacts   (representations,  processes,  protocols,  workflows,  software)  that  embody  such  understanding;  and   the   integration   of   the   resulting   cognitive   tools   into   collaborative   human-‐machine   systems   and   infrastructure  to  advance  science.    \nOVERVIEW  \nTycho  Brahe  gathered  considerable  and  accurate  data  on  the  movement  of  the  planets  (“big  data”  for   his  time).  However,  this  data  did  not  find  real  value  until  Johannes  Kepler  used   it  to  discover  his  three  \n                                                                                                                 1  Professor   and   Edward   Frymoyer   Chair,   College   of   Information   Sciences   and   Technology,   Professor   of   Computer   Science,   Bioinformatics  and  Computational  Biology  and  Neuroscience  Graduate  Programs,  Director,  Center   for  Big  Data  Analytics  and   Discovery   Informatics,   and  Associate  Director,   Institute   for   Cyberscience,   Pennsylvania   State  University,   University   Park,      PA   16802.  Email:  vhonavar@ist.psu.edu;  Web:  http://faculty.ist.psu.edu/vhonavar     2  John   P.  Morgridge   and   Gene   P.   Amdahl   Professor   and   Chair,   Department   of   Computer   Sciences,   University   of  Wisconsin-‐ Madison,  Madison,  WI  53706.  Email:  markhill@cs.wisc.edu;  Web:  http://pages.cs.wisc.edu/~markhill/   3  Professor,   Computer   Science   Division,   University   of   California   at   Berkeley,   Berkeley,   CA   94720   and   Associate   Laboratory   Director   of   Computing   Sciences,   Lawrence   Berkeley   National   Laboratory.   Email:      yelick@berkeley.edu;   Web:   http://www.cs.berkeley.edu/~yelick/    \n   2  \nlaws  of  planetary  motion.  Later  Isaac  Newton  used  these  laws  and  other  data  to  derive  his  unified  laws   of  motion,  and  lay  the  foundations  of  classical  physics.  To  do  so,  he  had  to  invent  calculus  for  describing   such  things  as  rates  of  change.  Brahe,  Kepler,  and  Newton  were  all  engaged  in  the  practice  of  science,  a   systematic   process   for   acquiring   knowledge   through   observation   or   experimentation   and   developing   theories  to  describe  and  explain  natural  phenomena.  The  past  centuries  have  witnessed  major  scientific   breakthroughs  as  a  result  of  advances  in  instruments  of  observation,  formalisms  for  describing  the  laws   of  nature,  and  improved  tools  for  calculation.  \nToday,  the  experimental  instruments  are  more  powerful,  the  scientific  questions  more  complex,  and  the   mathematical,   statistical   and   computational   methods   for   analyzing   data   have   become   more   sophisticated.      The   resulting   emergence   of   “big   data”   offers   unprecedented   opportunities   for   accelerating   science.   Arguably,      “big   data”  accelerates  Brahe’s   part   of   the  scientific  endeavor,   and   increasingly,  Kepler’s  part,  with   the   increasing  use  of  machine   learning   for  building  models   from  data.   Nevertheless,  many  aspects  of  the  scientific  process  (designing,  prioritizing  and  executing  experiments,   organizing   data,   integrating   data,   identifying   patterns,   drawing   inferences   and   interpreting   results)   constitute  an  even  greater  bottleneck  than  ever.    \nThe  goal  of   this  white  paper   is   to  articulate  a   research  agenda   for  developing  cognitive   tools   that   can   augment  human  intellect,  and  partner  with  humans  on  all  aspects  of  the  scientific  process,  including  in   particular,   those   that   are   exacerbated   by   “big   data.”   We  argue   that   there   is   great   opportunity  for   dramatically   accelerating   science   and   enabling   new   modes   of   scientific   discovery,   perhaps   even   empowering  and  enabling  the  future  likes  of  Kepler  or  Newton  in  the  era  of  big  data.  \nThe   benefits   of   accelerating   science   extend  well   beyond   the   scientific   community   to   all   of   humanity.   Imagine:   Precision   health   regimens   that   take   into   account   not   only   one’s   genetic   makeup,   but   also   environment,  and  lifestyle;  Personalized  education  that  optimizes  curriculum,  pedagogy,  etc.  to  optimize   the   learning   outcomes   for   each   individual;   Precision   agriculture   that   optimizes   everything   from   the   choice  of  crops  to  water  and  fertilizer  use  to  optimize  yield  and  impact  on  the  environment.  These  are   just   a   start,   however,   as   in   the   21st   century  we   should   be   able   to   invent   technologies   undreamed  of   in  this  century’s  early  years,  as  who  in  1900  could  have  anticipated  20th  century  advances,  such  as  the   Internet  (no  computers  yet)  or  DNA  sequencing  (DNA  structure  unknown)?  \nACCELERATING  SCIENCE:  THE  VALUE  PROPOSITION  \nImagine  a  world  in  which  scientists  work  with  cognitive  tools  that  can  \n• Given  access  to  literature  and  data:     • Create  and  share  a  knowledge  base  that  summarizes  what  we  know  about  a  scientific  question  \n(annotated  with  uncertainty,  provenance,  and  underlying  assumptions);     • Summarize   and   prioritize   questions   that   need   to   be   answered   to   achieve   an   overall   scientific  \nobjective  (e.g.,  understanding  the  molecular  mechanisms  that  underlie  cancer);     • Identify   and   rank   alternative   explanations   of   an   observation   based   on   the   current   state   of  \nscientific  understanding  in  a  given  field;     • Design  and  prioritize  study  techniques;     • Construct  a  computational  model,  e.g.,  a  network  of  genes  that  orchestrate  a  specific  biological  \nprocess  of  interest,  that  make  experimentally  testable  predictions.     • Given  a  conjecture:    \n• Identify  data  that  support  or  refute  the  conjecture;     • Identify  simulations  that  can  interpret  the  theory,  e.g.,  over  time  or  in  various  physical  settings;   • Design  and  prioritize,  orchestrate,  and  execute  experiments.  \n   3  \n• Given  an  experimental  design,  experimental  results,  and  access  to  literature:     • Create  a  plan  for  replicating  the  study  and  validating  the  claims;     • Generate  and  rank  alternative  interpretations  of  the  data;     • Document  the  study,  communicate  results;     • Integrate  results  into  the  larger  body  of  knowledge  within  or  across  disciplines.   • Given  a  collection  of  experimental  and  observational  studies:   • Infer   a   causal   effect   of   interest,   e.g.,   the   role   of   a   specific   gene  or   combination  of   genes   in   a  \nspecific  biological  process;   • Calculate   scientific   parameters,   e.g.,   geophysical   characteristics   affecting   earthquakes,   by  \nsolving  an  inverse  problem  by  comparing  simulations  to  the  observations.     • Given  a  scientific  question  and  a  network  of  researchers,  assemble  a  team  that  is  best  equipped  to  \nanswer  the  question.   • Track  scientific  progress,  evolution  of  scientific  disciplines,  and  scientific  impact.    \nCognitive   tools   for   acclerating   science   could   lead   to   dramatic   increases   in   scientific   productivity   by   increasing  efficiency  of  the  key  steps  in  scientific  process,  and  in  the  quality  of  science  that  is  carried  out   (by  reducing  error,  enhancing  reproducibility),  allow  scientific  treatment  of  topics  that  were  previously   impossible   to   address,   and   enable   new   modes   of   discovery   that   leverage   large   amounts   of   data,   knowledge,  and  automated   inference.  The  sections   that   follow  attempt   to   further   flesh  out  our  vision   for  accelerating  science  by  accelerating  increasingly  larger  fractions  of  the  scientific  process.    \nTHE  SCIENTIFIC  PROCESS  \nTo   understand   where   the   major   bottlenecks  to  scientific  progress  are,  it  is   useful   to   revisit   a   simplified   model   or   template   of   the   scientific   process   (See   Hacking,   1983;   Chalmers,   1999;   Rosenberg,   2000   for   reviews).   Figure   1   summarizes   the   key   elements   of   the   scientific  process.  \nTypically,   scientific   inquiry   starts   with   a   question   within   a   domain   of   study,   e.g.,   biology.   With   the   question   in   hand,   one   has   to   assemble   the   background   information   and   acquire   the   data   necessary   to   answer   the   question.   Then   one   proceeds   to   construct   one   or  more  models   from  data   (and   background   information).   Choosing   a   small   set   of   models   from   among   a   much   larger   set   of   candidates   involves   additional   considerations   (simplicity,  consistency  with  what  else   is  known),  etc.  The  models  can  be  used  to  advance  hypotheses   that   result,   ideally,   in   testable   predictions.   The   observations   or   experiments   designed   to   test   the   predictions  yield  additional  data  that  feed  into  the  larger  scientific  process.  Science  is  a  social  endeavor,   with  multiple  individuals  and  teams,  driven  by  intrinsic  as  well  as  extrinsic  incentives.  Scientific  findings   go   through   peer   review,   communication,   and   publication,   and   replication   before   they   are   integrated   into  the  larger  body  of  knowledge  in  the  relevant  discipline.    \nIt   is  worth   noting   that   there   is   considerable   variability   across   scientific   disciplines,   e.g.,   in   cosmology,   where   there   is   little   possibility   of   executing  designed  experiments,   one   typically   has   to  make  do  with   observational  data  or  the  results  of  ‘natural’  experiments.  Nevertheless,  it  is  clear  that  the  processes  of  \nFigure  1:  A  Cartoon  of  the  Scientific  Process  \n   4  \nacquiring,   organizing,   verifying,   validating,   integrating,   analyzing,   reasoning   with,   and   communicating   information   (models,   hypotheses,   theories,   explanations)   about   natural   and   built   systems   lie   at   the   heart  of  the  scientific  enterprise.    \nACCELERATING  SCIENCE:  TRADITIONAL  ENABLERS  \nMajor  scientific  advances  are  often  enabled  by:  \n• Advances   in   the   instruments   of   observation   (new  measurement   devices   or  methods   or  making   it   possible  to  acquire  data  of  new  modalities,  higher  resolution  in  time  or  space,  or  in  larger  volumes   than  previously  possible).    \n• Development  of  mathematical  models  and  methods  for  representing  and  reasoning  about  scientific   hypotheses  and  theories  (e.g.,  the  invention  of  calculus  by  Newton  and  Leibnitz  that  were  necessary   for  the  advances  in  physics);  \n• Development  of  effective  tools  for  data  analysis  and  simulation  (e.g.,  the  invention  of  the  computer   that   enabled   among   other   things,   solution   of   systems   of   linear   equations,   simulation   of   complex   models  of  physical,  biological,  and  cognitive  processes);  \n• Cross-‐fertilization   and   integration   of   concepts,   experimental   methods,   data,   tools,   hypotheses,   theories,   across   disciplines   (e.g.,   the   emergence   of   molecular   biology   through   convergence   of   biological  and  physical  sciences).    \nIn  what  follows,  we  argue  that  the  emergence  of  big  data  and  the  ability  to  examine  natural  processes   using  the  computational  lens  (Karp,  2011),  offer  the  possibility  of  rapid  acceleration  of  science.  However,   realizing  this  requires  algorithmic  or   information  processing  abstractions  of  natural  processes,  coupled   with   formal   methods   and   tools   for   their   analyses   and   simulation;   cognitive   tools   that   augment   and   extend  human  intellect  and  partner  with  humans  in  all  aspects  of  science.  \nACCELERATING  SCIENCE:  THE  DRIVERS  \nNew   technology   in   sensors,   detectors,   sequencing,   imaging   and   simulation   offers   unprecedented   opportunities   for   not   only   accelerating   scientific   advances,   but   also   enabling   new  modes   of   scientific   discovery.   New   scientific   advances   in  many   disciplines   are   increasingly   being   driven   by   our   ability   to   acquire,  share,  integrate  and  analyze  disparate  types  of  data,  leading  to  what  has  been  suggested  to  be   a  new  scientific  paradigm,  namely  data-‐intensive  science  (Hey,  Tansley,  and  Tolle,  2009).  The  resulting   challenges   in   storage,   organization,   curation,   access,   sharing,   management,   processing,   analytics,   statistics,   and   visualization   s   are   widely   recognized   and   form   the   focus   of   much   current   research.   Modern  data  analytics  techniques  that  integrate  sophisticated  probabilistic  models,  statistical  inference,   and   scalable   data   structures   and   algorithms   into  machine   learning   systems  have   resulted   in   powerful   ways   to   extract   actionable   knowledge   from  data   in   virtually   every   area   of   human   endeavor.   Creative   applications   of   data   analytics   are   enabling   biologists   to   gain   insights   into   how   living   systems   acquire,   encode,   process,   and   transmit   information;   neuroscientists   to   uncover   the   neural   bases   of   cognition;   health  scientists  to  not  only  diagnose  and  treat  diseases  but  also  help  individuals  make  healthy  choices;   economists   to   understand   markets;   physical   scientists   to   improve   our   basic   understanding   of   the   physical  world,   security   analysts   to   uncover   threats   to   national   security;   social   scientists   to   study   the   evolution  and  dynamics  of  social  networks;  and  scholars  to  gain  new  understandings  of  literature,  arts,   history,   and   cultures   through   advances   in   the   digital   humanities.   However,   despite,   and   perhaps   because   of,   advances   in   “big   data”   technologies   for   data   acquisition,   management   and   analytics,   (bottom  left  of  Figure  1),  the  other  largely  manual,  and  labor-‐intensive  aspects  the  scientific  process  (the   rest  of  Figure  1)  have  become  the  rate  limiting  steps  in  scientific  progress.    \n   5  \nConsider  for  example,  the  task  of  identifying  a  question  for  investigation  in  a  domain  of  inquiry,  e.g.,  the   Life  Sciences.  This  is  a  non-‐trivial  task  that  requires  a  good  grasp  of  the  current  state  of  knowledge,  the   expertise  and   skills  needed,   the   instruments  of  observation  available,   the  experimental  manipulations   that   are   possible,   the   data   analysis   and   interpretation   tools   available,   etc.  Understanding   the   current   state  of   knowledge   requires  mastery  of   the   relevant   scientific   literature  which,  much   like  many  other   kinds   of   “big   data”,   is   growing   at   an   exponential   rate.   For   example,   in   2011,   the   number   of   peer-‐ reviewed  biomedical  research  articles  appearing   in  Pubmed  exceeded  2700  articles  per  day.  The  sheer   volume  and  the  rate  of  growth  of  scientific  literature  makes  it  impossible  for  a  scientist  to  keep  up  with   advances   that   might   have   a   bearing   on   the   questions   being   pursued   in   his   or   her   laboratory.   The   magnitude   of   this   challenge   is   further   compounded   by   the   fact   that   many   scientific   investigations   increasingly  need  to    draw  on  data  from  a  multitude  of  databases    (e.g.,  Genbank,  Protein  Data  Bank,  etc.   in  the  life  sciences)  and  expertise  and  results  from  multiple  disciplines.    \nAs   another   example,   consider   the   task   of   designing   an   optimal   experiment   that   provides   the   most   valuable   information  at   the   lowest   cost   to  help  answer  a   chosen   scientific  question   requires  a   careful   exploration  of  the  space  of  possible  experiments,  their  relative  cost,  risk,  and  feasibility,  in  the  context   of   all   that   is   known.   This   challenge   is   further   compounded   by   the   varying   degrees   of   uncertainty   associated  with  the  scientific  findings.    \nThe   components   of   the   scientific   process   present   similar   challenges.   This      underscores   the   need   for   much  improved  cognitive  tools  tools  for  assisting  scientists  with  the  rate-‐limiting  steps  of  the  scientific   process.  \nACCELERATING  SCIENCE:  FEASIBILITY    \nIn  what  follows,  we  argue  that  computation  increasingly  serves  as:   Ø A  language  for  science,  a  role  not  unlike  that  played  by  mathematics  over  the  past  many  centuries;  \nand     Ø A   powerful   formal   framework   and   exploratory   apparatus   for   the   conduct   of   science.   These  \ndevelopments      together   set   the   stage   for   developing   the   cognitive   tools   needed   to   accelerate   science.  \nComputing  as  a  language  of  science  \nIt   was   nearly   a   century   ago   that   Rutherford   said   “All   science   is   either   stamp   collecting   or   physics”.   Advances   in   computing,   storage,   and   communication   technologies   have  made   it   possible   to   organize,   annotate,   link,   share,  and  analyze   increasingly  voluminous,  exquisitely  diverse  data,  or   in  Rutherford’s   words,   ‘stamp  collections’.  Recall  that   it  was  the   invention  of  calculus  by  Newton  and  Leibnitz  that  for   the   first   time   allowed   precise   descriptions   of   rate   of   change,   and   hence   fundamental   constructs   of   classical   physics   such   as   velocity   and   acceleration,   and   the   Newton’s   laws   that   specified   how   they   related  to  each  other,  that  helped  transform  the  study  of  the  physical  universe  from  “stamp  collecting”   to  “physics,”  from  a  descriptive  science  into  a  predictive  science.  While  whether  there  exist  analogs  of   the  simple  laws  of  classical  physics  for  complex  biological,  cognitive,  economic,  and  social  systems  might   be   debatable,   that   the   invention   of   calculus   by   Newton   and   Leibnitz   is   what   made   possible   the   emergence  of  physics  is  not.    \nMathematics  is  generally  regarded  as  the  language  of  science.  Algorithms—precise  recipes  that  describe   the   relationships   between   and   the   processes   that   operate   on   the   entities   that   make   up   the   world   around   us—offer   a   means   for   expressing   constructive   mathematics4.   Algorithms   allow   us   to   at   least                                                                                                                    4  Constructive  mathematics  is  distinguished  from  its  traditional  counterpart,  classical  mathematics,  by  the  strict  interpretation   of  the  phrase  “there  exists”  as  “we  can  construct”  (Bridges  and  Palmgren,  2013).  \n   6  \napproximate   anything   that   is   describable,   including   highly   non-‐linear   phenomena   that   cannot   be   described   using   equations   that   have   closed-‐form   solutions.   There   is   a   growing   recognition   that   processes  of  interest  in  biological,  social,  and  cognitive  sciences  can  be  viewed  as  essentially  information   processes.    Arguably,  \"applied  computer  science  is  now  playing  the  role  which  mathematics  did  from  the   seventeenth  through  the  twentieth  centuries:  providing  an  orderly,   formal  framework  and  exploratory   apparatus  for  other  sciences”  (Djorgovski,  2005).    \nThis  allows  us  to  examine  biological,  cognitive,  and  social  processes  through  a  computational  lens,  that  is,   in   terms   of   information   processing   abstractions   (Karp,   2011).   Hence,   we   understand   a   phenomenon   when  we  have  an  algorithm   that  describes   it   at   the  desired   level  of   abstraction.   Thus,  we  will   have  a   theory   of   protein   folding  when  we   can   specify   an   algorithm   that   takes   as   input,   a   linear   sequence  of   amino  acids   that  make  up  the  protein   (and  the  relevant   features  of   the  cellular  environment   in  which   folding  is  to  occur),  and  produces  as  output,  a  description  of  the  3-‐dimensional  structure  of  the  protein   (or   more   precisely,   a   set   of   stable   configurations).   Examination   of   natural   processes   through   the   computational  lens  sheds  new  light  on  old  scientific  problems  in  the  respective  scientific  disciplines.    For   example,  Holland’s   and  Valiant’s   examinations   of   biological   evolution   through   the   computational   lens   provide  new  insights  into  evolution  of  complex  organisms  (Holland,  1975;  Valiant,  2009).  Roughgarden’s   work   shows  how  computational   complexity   sheds  new   light  on   the   “bounded   rationality”  of  decision-‐ makers   (Roughgarden,   2010).   Kleinberg’s   work   has   provided   a   new   perspective   on   fundamental   questions,  e.g.,  the  small  world  phenomenon  (Kleinberg,  2000),  in  the  social  sciences.  \nExamination   of   a   natural   process   through   the   computational   lens   necessarily   requires   algorithmic   or   information  processing  abstractions  of  the  relevant  natural  entities,  relations,  and  processes.  Once  such   abstractions  are  created,  they  become  first  class  computational  artifacts   in  their  own  right  that  can  be   analyzed,  shared,  and  integrated  with  other  related  artifacts,  contributing  to  the  acceleration  of  science.    \nComputing  as  a  formal  framework  for  science  \nThe   scientific   enterprise   (See   Figure   1),   entails   acquiring,   organizing,   verifying,   validating,   integrating,   analyzing,  reasoning  with,  and  communicating  descriptions  of  scientific  artifacts,  namely,  experiments,   data,  models,  hypotheses,  theories,  and  explanations  associated  with  natural  or  built  systems  lie  at  the   heart   of   the   scientific   enterprise.   Hence,   computing,   the   science   of   information   processing,   offers   a   powerful  formal  framework  and  exploratory  apparatus  for  the  conduct  of  science  (Djorgovski,  2005).  It   also  offers  the  theoretical  and  experimental  tools  for  the  study  of  the  feasibility,  structure,  expression,   and,  when  appropriate,  automation  of  (aspects  of)  the  scientific  process,  the  structure  and  organization   of   collaborative   teams,   modeling   the   evolution   of   scientific   disciplines,   and  measuring   the   impact   of   scientific  discoveries.    \nAccelerating   science   through   automation   of   aspects   the   scientific   process   has   been   a   topic   of   considerable   interest   in   computer   science   (Duda   et   al.,   1979;   deJong   and   Rip,   1987;   Langley,   1981;   Langley  et  al.,  1987;  Lindsay  et  al.,  1980;  Dzeroski  et  al.,  2007;  Shrager  and  Langley,  1990;  Valdez-‐Perez,   1999;  Bradley  et  al.,  2001;  Glymour,  2004)  as  well  as  cognitive  science  (Klahr,  2000).  Intelligent  software   agents  are  already  widely  used  in  many  aspects  of  scientific  activity.     However,  this  work  falls  short  of   accelerating  most  aspects  of  science  (Waltz  and  Buchanan,  2009).  \nRecent   advances   in   robotics   for   data   acquisition,   data   bases   and   knowledge   bases   that   capture   the   relevant  background  knowledge  in  specific  disciplines,  open  access  to  large  bodies  of  scientific  literature,   technologies  for  connecting  resources  and  experts,  and  for  constructing  and  sharing  scientific  workflows   have  led  to  a  renewed  interest  in  the  topic.    For  example,    King  et  al.  (2009)  have  demonstrated  a  robot   scientist   capable   of   generating   and   testing   hypotheses,   and   choosing   the   experiment   to   try   next,   to   understand   the   functional   genomics   of   yeast   (S.   cerevisiae).   Schmidt   and   Lipson   (2009)   have   demonstrated   a   system   that   discovers   compact   equations   describe   complex   nonlinear   dynamical  \n   7  \nsystems,   from   observations.   These   demonstrations   suggest   the   possibility   of   accelerating   science   by   automating  some  aspects  of  the  scientific  process.    \n  \nACCELERATING  SCIENCE:  A  RESEARCH  AGENDA  IN  COMPUTER  AND  INFORMATION  SCIENCES  \nAccelerating   science   to   keep   pace   with   the   rate   of   data   acquisition   and   data   processing   calls   for   concerted  research  efforts  that  encompass  both:  \n• Development,   analysis,   integration,   sharing,   and   simulation   of   algorithmic   or   information   processing  abstractions  of  natural  processes,   coupled  with   formal  methods  and   tools   for   their   analyses  and  simulation;  \n• Innovations   in   cognitive   tools   that   augment   and   extend   human   intellect   and   partner   with   humans  in  all  aspects  of  science.  \nIn  what  follows,  we  elaborate  on  each  of  these  in  turn.    \nAlgorithmic  Abstractions  for  Accelerating  Science  \nThe   success   of   computational   lens   in   shedding   new   light   on   long-‐standing   questions   in   biological,   cognitive,   and   social   sciences   is   contributing   to   their   transformation   from   descriptive   sciences   into   predictive   sciences.   However,   in   most   disciplines,   this   transformation   is   far   from   complete.   In   many   areas,  such  abstractions  are  scarce.  In  others,  the  abstractions  and  the  hypotheses  that  they  offer  have   remained    untested,  at  least  in  part,  due  in  part  to  the  limitations  of  our  instruments  of  observation  and   experimentation  and   in  part  due  to   the  cost  and  complexity  of   the  scientific  enterprise.   In  order   for  a   broad  range  of  sciences  and  scientists  to  benefit  from  the  use  of  computational  lens  in    their  respective   disciplines,   there   is   an   urgent   need   for   developing,   sharing,   analyzing,   and   integrating   computational   abstractions   or   representations      of   the   key   entities,   relationships,   and   processes   of   interest   in   the   respective  scientific  disciplines.  For  example,  progress  in  life  sciences  has  been  accelerated  substantially   with   the   emergence   of   gene   ontology   (Ashburner   et   al.,   2000).  Much  work   remains   to   be   done   in   a   similar   vein   in   other   scientific   disciplines.   Of   particular   interest   are   system-‐level,   mechanistic,   computational  models  of  biological,  cognitive,  and  social  systems  that  enable  the  integration  of  different   processes   into   coherent   and   rigorous   representations   that   can   be   analyzed,   simulated,   integrated,   shared,   validated   against   experimental   data,   and   used   to   guide   experimental   investigations.   Such   abstractions,   coupled   with   formal   methods   for   their   analysis,   can   provide   rich   defined   modeling   languages   with   precise   syntax   and   semantics   that   can   be   analyzed   systematically   and   efficiently   for   certain  properties  of  interest.  For  example,  a  question  of  interest  to  a  cancer  biologist,  e.g.  whether  the   up-‐regulation  of  genes  A  and  B  and  down-‐regulation  of  gene  C  could  possibly  take  a  cell  from  a  healthy   state  to  a  cancerous  state  can  be  translated  into  a  reachability  query  against  a  model  of  a  cell  where  the   state   of   the   cell   encodes   the   expression   levels   of   the   genes.  While   there   has   been   some   progress   in   developing   such   abstractions   for   molecular   and   systems   biology   (Priami,   2009;   Bernot   et   al.,   2004;   Danos   and   Laneve,   2004;   Fisher   and   Henzinger,   2007),  much  work   remains   to   be   done,   especially   in   relation   to   formalisms   that   allow   specification   of   models   that   take   into   account   uncertainty   and   variability,  as  well  as  couplings  across  multiple  levels  of  abstraction,  e.g.,  molecules,  cells,  tissues,  organs,   organisms.   Similar   advances   are   needed   in   other   scientific   disciplines.   Of   particular   interest   are   formalisms  for  bridging  models  not  only  across  levels  of  abstraction,  but  also,  disciplinary  boundaries,  to   allow   studies   of   complex   interactions,   e.g.,   those   that   couple   food,   energy,   water,   environment,   and   people.    \n  \n   8  \nCognitive  Tools  for  Accelerating  Science  \nIn   order   for   science   to   keep   pace   with   the   rate   of   data   acquisition   and   data   processing,   there   is   an   urgent  need   for   innovations   in   cognitive   tools   (Saloman  et  al.,  1991)   for   scientists,   i.e.,   computational   tools  that  leverage  and  extend  human  intellect  (Engelbart,  1962),  and  partner  with  humans  on  a  broader   range   of   tasks   involved   in   scientific   discovery   (formulating   a   question,   designing,   prioritizing   and   executing  experiments  designed  to  answer  the  question,  drawing  inferences  and  evaluating  the  results,   and   formulating   new   questions,   in   a   closed-‐loop   fashion).   This   calls   for   for   deeper   understanding   formalization,  and  algorithmic  abstractions  of,  various  aspects  of  the  scientific  process;  development  of   the   computational   artifacts   (representations,   processes,   software)   that   embody   such   understanding;   and   the   integration   of   the   resulting   artifacts   into   collaborative   human-‐machine   systems   to   advance   science   (by   augmenting,   and  whenever   feasible,   replacing   individual   or   collective  human  efforts).   The   resulting  computer  programs  would  need  to  close  the  loop  from  designing  experiments  to  acquiring  and   analyzing  data  to  generating  and  refining  hypotheses  back  to  designing  new  experiments.    \nAccelerating   science   calls   for   programs   that   can   access   and   ingest   information   and   background   knowledge  relevant  to  any  scientific  question.  As  search  engines  and  digital  libraries  return  more  articles   in   response   to  a  query   than  anyone  can   read,  e.g.,  Google   returns  about  3.67  million  hits   for   “cancer   biology”,   there   is   a   need   for   programs   that   can   read,   assess   the   quality   and   trustworthiness   of,   and   interpret  such   information.  Machine  reading      (Etzioni  et  al.,  2006)     and   information  extraction  (Niu  et.   al.,  2012)  are  already  active  areas  of  research  in  computer  science  that  have  been  successfully  applied  in   the   life   sciences   (Hunter  and  Cohen,  2006;  Mallory  et  al.,  2015)  and   found   their  way   into  commercial   technology  such  as  IBM  Watson  (Ferrucci,  et  al.,  2013).  Of  particular  interest  are  methods  for  extracting   scientific   claims   from   literature   and   linking   them   to   supporting   assumptions,   observations   or   experiments,  answering  questions,  quantifying  uncertainty  associated  with  the  answers,  etc.  \nAnother   active   area   of   research   is   literature-‐based   discovery   (Swanson   and   Smalheiser,   1997;   Smalheiser,  2012),  which  has  had  some  success  in  finding  new  relationships  between  existing  knowledge   from  literature  spanning  two  or  more  topics  (Cameron  et  al.,  2013).  Other  work  on  text  analytics  has  led   to  powerful  methods  for  understanding  the  evolution  of  scientific  disciplines  (Börner  et  al.,  2004;  Sinatra   et  al.,  2015),   recommending  collaborators   (Chen  et  al.,  2011),  and  choosing  experiments  to  accelerate   collective  discovery  (Rzhetsky  et  al.,  2015).  However,  many  challenges  remain,  e.g.,  drawing  inferences   from  disparate  collections  of  literature,  and  increasingly,  scientific  databases  and  knowledge  bases  that   contain   information   of   varying   degrees   of   quality   and   reliability,   tracking   the   evolution   of   disciplines,   identifying  major  gaps  in  scientific  knowledge,  and  areas  ripe  for  breakthroughs.    \nAn  emerging  area  of   research   focuses  on  data  driven  approaches   to   characterizing,   and  modeling   the   evolution  of  scientific  disciplines.  For  example,  the  results  of  a  recent  analysis  of  the  Physics   literature   (Sinatra  et  al.,  2015)  calls  into  question  the  conventional  narrative  of  physics  as  one  of  paradigm  shifts   (Kuhn,  1996),  divorced  from  other  sciences,  and  shows  that  physics  has  always  been  in  a  constant  dialog   with  other  disciplines  from  mathematics  to  chemistry  and  even  theology,  a  dialog  that  is  largely  driven   by  the  idea  that  complex  phenomena  can  be  understood  in  terms  of  a  small  number  of  universal  laws.   Such  analyses  could  allow  us   to  understand   the  evolution  of   scientific  disciplines,  and   the   impact  of  a   scientific   discovery   within   and   beyond   the   discipline,   and   identify   unexplored   areas   that   are   ripe   for   investigation.    \nWith   the   exponential   growth   in   scientific   literature,   often   with   conflicting   scientific   arguments,   supported  by  observations  of  variable  quality  and  analyses  made  under  differing  assumptions,  there  is  a   dire   need   for   tools   for   managing   conflicting   arguments,   tracking   changes   in   the   validity   of   the   observations   and   assumptions   that   they   rely   on,   and   support   justifiable   conclusions.   While   there   is   considerable  work  on  computational  argumentation  systems  (Besnard  and  Hunter,  2008),  much  work  is  \n   9  \nneeded  to  develop  argumentation  formalisms  and  tools  that  can  help  accelerate  science.  Of  particular   interest   are   expressive   yet   computationally   tractable   languages   for   representing   and   reasoning   with   scientific  arguments,  and  their  uncertainty  and  provenance.    \nA   shift   in   emphasis   from   accelerating   data   collection   and   data   processing   to   accelerating   the   entire   scientific   process   calls   for   representation   and   modeling   languages   with   precise   formal   semantics   for   describing,   sharing,   and   communicating   scientific   observations   (including   measurement   models)   experiments,  data,  models,  theories,  conjectures,  and  hypotheses.  The  increasing  reliance  on  cognitive   tools   requires   that   the   all   of   these   be   specified   in   a   form   that   can   be   processed   by   computers;   and   queries  against  them  be  translated  into  precise  computational  problems.    \nEven  the  relatively  mundane  task  of  data  collection  presents  many  questions   including  deciding  which   variables  to  measure,  why,  and  how  i.e.,  the  instrument  to  use  (if  one  exists)  or  to  design  (if  need  be).   Scientific  workflows  (Gil  et  al.,  2007;  Davidson  and  Freire,  2008)  already  provide  useful  ways  to  describe,   manage,   share,   track   data   provenance   within,   and   reproduce   complex   scientific   analyses.   Scientific   systems  are  already  being  used  for  data  analyses  in  the  life  sciences  (Hull  et  al.,  2006).  However,  there  is   a  need  for  languages  and  tools  for  describing  the  measurement  process,  the  data  models  for  describing   observations  using   standard  ontologies   (when   they  exist),   establishing   semantics  preserving  mappings   across  data  models.  There  is  an  urgent  need  for  precise  languages  and  tools  for  describing  experiments,   methods   for   quantifying   the   marginal   utility   of   experiments,   determining   the   scientific   as   well   as   economic   feasibility   of   experiments,   comparing   alternative   experiments,   and   choosing   optimal   experiments   (in   a   given   context).   The   same   holds   for   hypotheses,   conjectures,   theories,   scientific   workflows,  and  other  scientific  artifacts.  \nMachine  learning  currently  offers  one  of  the  most  cost-‐effective  approaches  to  constructing  predictive   models   from   data   (Ghahramani,   2015;   Jordan   and   Mitchell,   2015)   across   a   number   of   disciplines   including   biological   sciences   (Baldi   and   Brunak,   2001),   brain   sciences   (Pereira   et   al.,   2009),   learning   sciences   (Romero   and   Ventura,   2010),   biomedical   and   health   sciences   (Jensen   et   al.,   2012),   environmental  science  (Hampton  et  al.,  2013),  and  climate  science  (Faghmous  et  al.,  2014).  For  example,   in   biological   sciences,   machine   learning   algorithms   are   routinely   used   to   build   predictors   of   gene   structure   (McAuliffe   et   al.,   2004),   molecular   interactions   and   interfaces   (Xue   et   al.,   2015),   and   to   uncover   regulatory   interactions   between   genes   (Segal   et   al.,   2003).   However,   such  models   are   often   complex  hard   for  scientists   to  comprehend,  and  therefore  to  use  to  gain  mechanistic   insights   into   the   underlying  phenomena.  Consider  for  example,  a  support  vector  machine  using  a  non-‐linear  kernel  that   predicts  whether   a   target   gene   of   interest   is   turned   on   or   off   based   on   the   previous   states   of   a   few   hundred   other   genes.   Such   a   model,   its   high   predictive   accuracy,   is   virtually   useless   with   regard   to   helping   to   uncover   the   underlying   genetic   regulatory   network.   There   has   been   some   progress   in   extracting  comprehensible  knowledge  from  complex  predictive  models  (Pazzani  et  al.,  1997).  A  related   topic   in   which   there   has   been   considerable   interest   has   to   do   with   methods   for   incorporating   prior   knowledge  into  machine  learning    (Heckerman  et  al.,  1995;  Fung  et  al.,  2002;  Cohen,  2014,  Faghmous  et   al.,  2014)  as  well  as  cognitive  modeling  (Tenenbaum  et  al.,  2006).    However,  there  remains  a  significant   language   gap   between   model   builders   and   model   users.   This   language   gap   presents   challenges   in   exploiting  prior  knowledge  to  guide  model  construction,  and  in  interpreting  predictive  models  produced   by  machine   learning   in  advancing  scientific  understanding  of   the  underlying  domain.         For  example,   in   life   sciences,   directed   labeled   graph   representations   of   gene   regulatory   networks   (Honavar,   2013)   wherein  nodes  denote  genes  and  directed  edges  denote  regulatory  influences,  and  the  +  or  -‐  labels  on   the  edges  denote  the  excitatory  or  inhibitory  influences  are  likely  to  be  much  more  useful  in  refining  our   understanding  the  underlying  process,  and  in  suggesting  further  experiments,  than  a  black  box  support   vector  machine  with  a  complex  nonlinear  kernel  that  provides  the  same  prediction.  Hence,  there  is  an  \n   10  \nurgent   need   for   a   new   generation   of   machine   learning   algorithms   that   that   can   incorporate   prior   knowledge   and   constraints   from   a   variety   of   sources,   e.g.,   from   physics,   and   produce   models   are   expressed  in  forms  that  are  easy  to  communicate  to  disciplinary  scientists.    \nThere  has  been  much  progress  on  methods  and  tools  for   integrating  data  from  disparate  data  sources   (Lenzerini,  2002;  Doan  et  al.,  2012;  Haas,  2015);  describing  data  semantics  using  expressive  yet  tractable   fragments  of  logic  (Berners-‐Lee  et  al.,  2001;  Baader  and  Nutt,  2003;  Calvanese  et  al.,  2007;  Horrocks  et   al.,   1999),   and  more   recently,   on   the  more   complex   problem   of   sharing   knowledge   across   disparate   knowledge   bases   (Bao   et   al.,   2009;   Cuenca   Grau   et   al.,   2008;   Kutz   et   al.,   2004;   Borgida   and   Serafini,   2003).   Yet  many   challenges   remain,   especially   as   they   relate   to   integration  of   data   and   knowledge  at   different  levels  of  abstraction,  differing  levels  of  uncertainty,  trustworthiness,  etc.  \n  Answering  complex  questions  increasingly  requires  synthesizing  the  findings    from  data  from  disparate   observational   and   experimental   studies   to   draw   valid   conclusions.   Conclusions   that   are   obtained   in   a   laboratory   setting   may   not   hold   exactly   a   setting   that   differs   in   many   aspects   from   that   of   the   laboratory.  Often,  individual  studies,  for  practical  reasons  e.g.,  cost,  complexity  of  the  studies,  focus  on   the  relationship  between  a  selected  set  of  experimental  variables  and  a  specific  outcome  variable.  This   means  arriving  at  meaningful  answers  to  questions  of  interest  invariably  requires  synthesize  the  findings   from   multiple   such   studies,   carried   out   under   related,   but   different   experimental   settings,   under   possibly  different  experimental  constraints  (e.g.,  experiments  that  can  be  performed  on  a  mouse  cannot   be   carried   out   on   human   subjects).      While   causal   discovery   from   disparate   observations   and   experiments  is  an  active  topic  of  research  (e.g.,  Bareinboim  et  al.,  2013),  a  great  deal  of  work  is  needed   to  characterize  the  precise  conditions  under  which  findings  of  disparate  observational  and  experimental   studies   can   be   synthesized,   and   to   develop   cognitive   tools   for   synthesizing   such   findings   when   it   is   appropriate  to  do  so.  \nWhile  we  have  effective  tools  to  assist  scientists  in  routine  aspects  of  data  management  and  analytics,   barring  a   few  proof-‐of-‐concept  demonstrations   (e.g.,  King  et  al.,  2009),  most  of   the  other  steps   in   the   scientific   process   currently   constitute   rate   limiting   steps   in   scientific   progress.   These   include:     Characterizing  the  current  state  of  knowledge  in  a  discipline  and  identifying  the  gaps  in  the  current  state   of  knowledge;  Generating  and  prioritizing  questions  that  are  ripe  for  investigation  based  on  the  current   scientific  priorities  and  the  current  state  of  knowledge;  Designing,  prioritizing,  planning,  and  executing   experiments;   Analyzing   and   interpreting   results;   Generating   and   verifying   hypotheses;   Drawing   and   justifying   conclusions;  Validating   scientific   claims;  Replicating   studies;  Documenting   studies;  Recording   scientific   workflows   and   tracking   provenance   of   data   and   results;      Reviewing   and   Communicating   results;   Integrating   results   into   the   larger   body   of   knowledge   within   or   across   disciplines.   Hence,   accelerating  science  requires  a  rich  model  of  the  entire  scientific  process  (See  Figure  1)  as  well  as  deep   knowledge  of  the  scientific  area  under  investigation  (Honavar,  2014).    \nBecause   science   is   increasingly   a   collaborative   endeavor,   we   need:   sharable   and   communicable   representations   and   processes,   as   well   as   organizational   and   social   structures   and   processes,   that   facilitate  collaborative  science,  including  mechanisms  for  sharing  data,  experimental  protocols,  analysis   tools,   data   and   knowledge   representations,   abstractions,   and   visualizations,   tasks,   mental   models,   scientific   workflows,   mechanisms   for   decomposing   tasks,   assigning   tasks,   integrating   results,   incentivizing   participants,   and   engaging   large   numbers   of   participants  with   varying   levels   of   expertise   and  ability  in  the  scientific  process  through  citizen  science  (Gill  and  Hirsh,  2012;  Bonney  et  al.,  2014).  \nSUMMARY  AND  RECOMMENDATIONS  \nThe   recent   advances   in   sensing,   measurement,   storage   and   communication   technologies   and   the   resulting  emergence  of  “big  data”  offer  unprecedented  opportunities  for  not  only  accelerating  scientific  \n   11  \nadvances,   but   also   enabling   new   modes   of   discovery.   Scientific   progress   in   many   disciplines   is   increasingly  driven  by  advances  in  our  ability  to:    \n• Examine  natural  phenomena  through  the  computational  lens,  i.e.,  using  algorithmic  or  information   processing  abstractions  of  the  underlying  processes;  \n• Acquire,   share,   integrate,  analyze,  and  build  predictive  and  causal  models   from  disparate   types  of   data.    \nHowever,  there  is  a  huge  gap  between  our  ability  to  acquire,  store,  and  process  data  and  our  ability  to   make  effective  use  of  the  data  to  advance  science.  Despite  successful  automation  of  routine  aspects  of   data   management   and   analytics,   most   elements   of   the   scientific   process   currently   constitute   rate-‐ limiting  steps  in  the  scientific  process.    \nAccelerating  science  to  keep  pace  with  the  rate  of  data  acquisition  and  data  processing  calls  for  focused   investments  in  a  research  program  that  encompasses  both:  \n• Development,  analysis,  integration,  sharing,  and  simulation  of  algorithmic  or  information  processing   abstractions   of   natural   processes,   coupled   with   formal  methods   and   tools   for   their   analyses   and   simulation;  \n• Innovations  in  cognitive  tools  that  augment  and  extend  human  intellect  and  partner  with  humans  in   all  aspects  of  science.  This  requires:  \n§ The  formalization,  development,  analysis,  of  algorithmic  or  information  processing  abstractions   of  various  aspects  of  the  scientific  process;  \n§ The  development  of  computational  artifacts  (representations,  processes,  software)  that  embody   such  understanding;  and    \n§ The   integration  of   the  resulting  cognitive  tools   into  collaborative  human-‐machine  systems  and   infrastructure  to  advance  science.    \nOf  particular  urgency  are  investments  in:  \n§ Algorithmic  abstractions  of:    \nØ The  natural  entities,  relations,  and  processes  of  interest  in  specific  scientific  disciplines;  \nØ Formal  methods  and  tools  for  their  analyses  and  simulation;  \nØ Formalisms  for  specification  of  models  that  take  into  account  uncertainty,  and  variability;    \nØ Couplings  across  multiple  levels  of  abstraction  and  spatial  and  temporal  granularity;   § Cognitive  tools  for:  \nØ Mapping  the  current  state  of  knowledge  in  a  discipline  and  identifying  the  major  gaps;     Ø Generating   and   prioritizing   questions   that   are   ripe   for   investigation   based   on   the   current  \nscientific  priorities  and  the  gaps  in  the  current  state  of  knowledge;     Ø Machine  reading,  including  methods  for  extracting  and  organizing  descriptions  of  experimental  \nprotocols,   scientific   claims,   supporting   assumptions,   and   validating   scientific   claims   from   scientific  literature,  and  increasingly  scientific  databases  and  knowledge  bases;  \nØ Literature-‐based   discovery,   including   methods   for   drawing   inferences   and   generating   hypotheses   from   existing   knowledge   in   the   literature   (augmented   with   discipline-‐specific   databases  and  knowledge  bases  of  varying  quality  when  appropriate),  and  ranking  the  resulting   hypotheses;  \n   12  \nØ Expressing,   reasoning  with,  updating   scientific  arguments   (along  with   supporting  assumptions,   facts,  observations),  including  languages  and  inference  techniques  for  managing  multiple,  often   conflicting  arguments,  assessing  the  plausibility  of  arguments,  their  uncertainty  and  provenance;  \nØ Observing   and   experimenting,   including   languages   and   formalisms   for   describing   and   harmonizing   the   measurement   process   and   data   models,   capturing   and   managing   data   provenance,  describing,  quantifying   the  utility,   cost,   and   feasibility  of   experiments,   comparing   alternative  experiments,  and  choosing  optimal  experiments  (in  a  given  context);  \nØ Navigating  the  spaces  of  hypotheses,  conjectures,  theories,  and  the  supporting  observations  and   experiments;  \nØ Analyzing   and   interpreting   the   results   of   observations   and   experiments,   including   machine   learning   methods   that:   explicitly   model   the   measurement   process,   including   its   bias,   noise,   resolution;  incorporate  constraints  e.g.,  those  derived  from  physics,  into  data-‐driven  inference;   close   the   gap   between   model   builders   and   model   users   by   producing   models   that   are   expressible  in  representations  familiar  to  the  disciplinary  scientists;  \nØ Synthesizing,  in  a  principled  manner,  the  findings  in  a  target  setting  from  disparate  experimental   and   observational   studies   (e.g.,   implications   to   human   health   of   experiments   with   mouse   models);    \nØ Documenting,  sharing,  reviewing,  replicating,  and  communicating  entire  scientific  studies  in  the   form  of  reproducible  and  extensible  scientific  workflows;  \nØ Communicating   results   of   scientific   studies   and   integrating   the   results   into   the   larger   body   of   knowledge  within  or  across  disciplines;  \nØ Collabortating,   communicating,   and   forming   teams  with   other   scientists   with   complementary   knowledge,   skills,   expertise,   and   perspectives   on   problems   of   common   interest   (including   problems  that  span  disciplinary  boundaries  or  levels  of  abstraction);  \nØ Organizing  and  participating   in   citizen   science  projects,   including   tools   for  decomposing   tasks,   assigning   tasks,   integrating   results,   incentivizing   participants,   and   engaging   large   numbers   of   participants  with  varying  levels  of  expertise  and  ability  in  the  scientific  process;  \nØ Cognitive   tools   for   tracking   scientific   progress,   the   evolution   of   scientific   disciplines      and   scientific  impact.  \n§ Multi-‐disciplinary,  interdisciplinary,  and  trans-‐disciplinary  teams  that  bring  together:   Ø Experimental   scientists   in   a   discipline,   e.g.,   the   biomedical   sciences,   with   information   and  \ncomputer   scientists,   mathematicians,   etc.,   to   develop   algorithmic   or   information   processing   abstractions  to  support  theoretical  and  experimental  investigations;  \nØ Organizational  and  social  scientists  and  cognitive  scientists  to  study  such  teams,  learn  how  best   to  organize  and  incentivize  such  teams  and  develop  a  science  of  team  science;  \nØ Experimental   scientists   in   one   or   more   disciplines,   computer   and   information   scientists   and   engineers,  organizational  and  social  scientists,  cognitive  scientists,  and  philosophers  of  science   to   design,   implement,   and   study   end-‐to-‐end   systems   that   flexibly   integrate   the   relevant   cognitive  tools   into  complex  scientific  workflows  to  solve  broad  classes  of  problems   in  specific   domains,  e.g.,  understanding  complex  interactions  between  food,  energy,  water,  environment,   and  populations.  \n§ Interdisciplinary   graduate   and   undergraduate   curricula   and   research   based   training   programs   to   prepare:    \n   13  \nØ A  diverse  cadre  of  computer  and  information  scientists  and  engineers  with  adequate  knowledge   of   one   or   more   scientific   disciplines   to   design,   construct,   analyze   and   apply   algorithmic   abstractions,  cognitive  tools,  and  end-‐to-‐end  scientific  workflows  in  those  disciplines;  \nØ A  new  generation  of  natural,  social,  and  cognitive  science  researchers  and  practitioners  fluent  in   the  use  of   algorithmic   abstractions   and   cognitive   tools   to   dramatically   accelerate   and   explore   new  modes  of  discovery  within  and  across  disciplines.  \nA  research  agenda  focused  on  accelerating  science  can  be  expected  to  yield:  \n§ Fundamental   advances   in   multiple   areas   of   computer   and   information   sciences,   including,   theory   of   computation,   complexity   theory,   algorithms,   formal   methods,   knowledge   representation  and  inference,  information  integration,  machine  reading,  software  engineering,   machine   learning,   causal   inference,   multi-‐objective   optimization,   argumentation   systems,   planning,   decision   making,   computational   organization   theory,   robotics,   human-‐computer-‐ robot  interaction,  among  others;  \n§ Cognitive   tools   that   could   dramatically   accelerate   scientific   progress,   by   leveraging   and   extending   the   reach   of   human   intellect,   and   partnering   with   scientists,   including   citizen   scientists,  with  a  broad  range  of  skills  and  expertise.  \nThis  white   paper   has   sought   to   articulate   a   research   agenda   for   developing   cognitive   tools   that  can   augment  human  intellect  and  partner  with  humans  on  the  scientific  process.  The  resulting  new  cognitive   tools   can   help   realize   the   transformative   potential   of   big   data   in   many   sciences,   by   dramatically   accelerating  science.    The  benefits  of  accelerating  science  extend  well  beyond  the  scientific  community   to  all  of  humanity:  Precision  health  regimens  that  take  into  account  not  only  one’s  genetic  makeup,  but   also   environment,   and   lifestyle;   Personalized   education   that   optimizes   curriculum,   pedagogy,   etc.   to   optimize  the  learning  outcomes  for  each  individual;  Precision  agriculture  that  optimizes  everything  from   the  choice  of  crops  to  water  and  fertilizer  use  to  optimize  yield  and  impact  on  the  environment.        Acknowledgements   This   material   is   based   upon   work   supported   by   the   National   Science   Foundation   under   Grant   No.   (1136993).  Any  opinions,   findings,  and  conclusions  or  recommendations  expressed   in  this  material  are   those  of  the  author(s)  and  do  not  necessarily  reflect  the  views  of  the  National  Science  Foundation.  The   article   has   benefited   from  discussions  with   and   feedback   from   the  broader   scientific   community,   and   current  and  former  members  of  the  Computing  Community  Consortium  Council,  especially  Greg  Hager,   Cynthia   Dwork,   Liz   Bradley,   Klara   Nahrstedt,   Elizabeth   Mynatt,   Ben   Zorn,   Susan   Davidson,   Susan   Graham.  \nREFERENCES  \n1. Ashburner,  M.,  Ball,   C.A.,  Blake,   J.A.,  Botstein,  D.,  Butler,  H.,   Cherry,   J.M.,  Davis,  A.P.,  Dolinski,   K.,   Dwight,  S.S.,  and  J.T.  Eppig,  J.T.  (2000).  Gene  Ontology:  tool  for  the  unification  of  biology.  The  Gene   Ontology  Consortium.  Nature  Genetics,  25:25–29  \n2. Baader,   F.   and  Nutt,  W.   (2003).   Basic   description   logics.   In  Description   logic   handbook   pp.   43-‐95.   Springer.   3. Baldi,  P.  and  Brunak,  S.,  2001.  Bioinformatics:  the  machine  learning  approach.  MIT  press.   4. Bao,   J.,   Voutsadakis,   G.,   Slutzki,   G.   and   Honavar,   V.   (2009).   Package-‐based   description   logics.   In  \nModular  Ontologies  (pp.  349-‐371).  Springer  Berlin  Heidelberg.   5. Bareinboim,  E.,  Lee,  S.,  Honavar,  V.  and  Pearl,  J.  (2013).  Transportability  from  multiple  environments  \nwith  limited  experiments.  In  Advances  in  Neural  Information  Processing  Systems:  pp.  136-‐144.  \n   14  \n6. Berners-‐Lee,  T.,  Hendler,   J.  and  Lassila,  O.   (2001).  The  semantic  web.  Scientific  American,  284:.28-‐ 37.  \n7. Bernot   G,   Comet   JP,   Richard   A,   Guespin   J.   (2004).   Application   of   formal   methods   to   biological   regulatory  networks:  extending  Thomas’  asynchronous  logical  approach  with  temporal  logic.  Journal   of  theoretical  biology.  229(3):  339-‐47.  \n8. Besnard,  P.,  and  Hunter,  A.  (2008)  Elements  of  argumentation.  Cambridge:  MIT  press.   9. Bonney,  R.,   Shirk,   J.L.,  Phillips,   T.B.,  Wiggins,  A.,  Ballard,  H.L.,  Miller-‐Rushing,  A.J.   and  Parrish,   J.K.,  \n(2014).  Next  steps  for  citizen  science.  Science,  343(6178),  pp.1436-‐1437.   10. Borgida,  A.  and  Serafini,  L.  (2003).  Distributed  description  logics:  Assimilating  information  from  peer  \nsources.  Journal  on  data  semantics  1:  153-‐184.   11. Börner,   K.,  Maru,   J.T.   and  Goldstone,  R.L.,   2004.   The   simultaneous  evolution  of   author   and  paper  \nnetworks.  Proceedings  of  the  National  Academy  of  Sciences,  101  (suppl  1):  5266-‐5273.   12. Bradley   E,   Easley   M,   Stolle   R.   (2001)   Reasoning   about   nonlinear   system   identification.   Artificial  \nIntelligence.  2001  Dec  31;133(1):139-‐88.   13. Bridges,   D.   and   Palmgren,   E.   (2013),   Constructive  Mathematics.   In:   The   Stanford   Encyclopedia   of  \nPhilosophy  Edward  N.  Zalta  (ed.),  http://plato.stanford.edu/archives/win2013/entries/mathematics-‐ constructive/.  \n14. Calvanese,  D.,  De  Giacomo,  G.,  Lembo,  D.,  Lenzerini,  M.  and  Rosati,  R.   (2007).  Tractable  reasoning   and   efficient   query   answering   in   description   logics:   The   DL-‐Lite   family.   Journal   of   Automated   reasoning,  39:385-‐429.  \n15. Cameron,  D.,  Bodenreider,  O.,  Yalamanchili,  H.,  Danh,  T.,  Vallabhaneni,  S.,  Thirunarayan,  K.,  Sheth,   A.P.   and   Rindflesch,   T.C.   (2013).   A   graph-‐based   recovery   and   decomposition   of   Swanson’s   hypothesis  using  semantic  predications.  Journal  of  biomedical  informatics,  46:238-‐251.  \n16. Carlson,  A.,  Betteridge,  J.,  Kisiel,  B.,  Settles,  B.,  Hruschka  Jr,  E.R.  and  Mitchell,  T.M.  (2010).  Toward   an  Architecture  for  Never-‐Ending  Language  Learning.  In  AAAI  pp.  1306-‐1313.   17. Chalmers,  A.F.  (1999).  What  is  this  thing  called  Science?  University  of  Queensland  Press.   18. Chen,   H.H.,   Gou,   L.,   Zhang,   X.   and   Giles,   C.L.,   2011,   June.   Collabseer:   A   Search   Engine   for  \ncollaboration  discovery.  In  Proceedings  of  the  11th  annual  international  ACM/IEEE  joint  conference   on  Digital  libraries  pp.  231-‐240.  ACM.  \n19. Cohen,  W.W.   (2014)   Compiling   prior   knowledge   into   an   explicit   bias.   In   Proceedings   of   the  Ninth   International  Conference  on  Machine  Learning  pp.  102-‐110.   20. Cuenca  Grau,  B.,  Horrocks,  I.,  Kazakov,  Y.  and  Sattler,  U.  (2008).  Modular  reuse  of  ontologies:  Theory   and  practice.  Journal  of  Artificial  Intelligence  Research,  pp.  273-‐318.   21. Danos  V,  Laneve  C.  (2004).  Formal  molecular  biology.  Theoretical  Computer  Science.  325(1):  69-‐110.   22. Davidson,   S.B.   and   Freire,   J.   (2008).   Provenance   and   scientific   workflows:   challenges   and  \nopportunities.   In  Proceedings  of  the  2008  ACM  SIGMOD  international  conference  on  Management   of  data,  pp.  1345-‐1350.  ACM.   23. de  Jong,  H.  and  Rip,  A.  (1997).  The  Computer  Revolution  in  Science:  Steps  Towards  the  Realization  of   Computer-‐Supported  Discovery  Environments  Artificial  Intelligence  91:  225-‐256.   24. Djorgovski   (2005).   V.   In:   Proc.   of   CAMP05,   \"Computer   Architectures   for  Machine   Perception\",   Di   Gesu  &  D.  Tegolo  (Ed).    IEEE  Press.  pp.  125-‐132.  \n25. Doan,  A.,  Halevy,  A.  and  Ives,  Z.  (2012).  Principles  of  data  integration.  Elsevier.   26. Duda,  R.O.,  Gaschnig,  J.,  Hart,  P.E.  (1979)  in:  Expert  Systems  in  the  Microelectronic  Age,  D.  Michie,  \nEd.  Edinburgh  Univ.Press.  pp.  153–167.  \n   15  \n27. Dzeroski,  S.,  Langley,  P.,  and  Todorovski,  L.  (2007).  Computational  Discovery  of  Scientific  Knowledge.   In:   Dzeroski,   S.,   Todorovski,   L.   (Eds.)   (2007),   Computational   discovery   of   communicable   scientific   knowledge.  Berlin:  Springer.   28. Engelbart,   D.C.,   2001.   Augmenting   human   intellect:   a   conceptual   framework   (1962).   PACKER,   Randall   and   JORDAN,  Ken.  Multimedia.   From  Wagner   to  Virtual  Reality.  New  York:  WW  Norton  &   Company,  pp.64-‐90.   29. Faghmous,  J.H.,  Banerjee,  A.,  Shekhar,  S.,  Steinbach,  M.,  Kumar,  V.,  Ganguly,  A.R.  and  Samatova,  N.   (2014).  Theory-‐guided  data  science  for  climate  change.  Computer,  11:74-‐78.  \n30. Ferrucci,   David   A.,   Anthony   Levas,   Sugato   Bagchi,   David   Gondek,   and   Erik   T.   Mueller.   Watson:   beyond  jeopardy!  Artif.  Intell.  199  (2013):  93-‐105.   31. Fisher  J,  Henzinger  TA.  (2007).  Executable  cell  biology.  Nature  biotechnology.  25(11):  1239-‐49.   32. Fung,  G.M.,  Mangasarian,  O.L.   and  Shavlik,   J.W.   (2002).  Knowledge-‐based   support  vector  machine  \nclassifiers.  In  Advances  in  neural  information  processing  systems  pp.  521-‐528.   33. Etzioni,  Oren,  Michele  Banko,   and  Michael   J.   Cafarella.  Machine  Reading.   In  AAAI,   pp.   1517-‐1519.  \n2006.   34. Gil,  Y.,  Deelman,  E.,  Ellisman,  M.,  Fahringer,  T.,  Fox,  G.,  Gannon,  D.,  Goble,  C.,  Livny,  M.,  Moreau,  L.  \nand  Myers,   J.   (2007).  Examining  the  challenges  of  scientific  workflows.   IEEE  Computer,  40(12):  26-‐ 34.  \n35. Gil,   Y.   and   Hirsh,   Y.   (2012).   Discovery   Informatics:   AI   Opportunities   in   Scientific   Discovery.   AAAI   Technical  Report  FS-‐12-‐03.    \n36. Ghahramani,   Z.   (2015).   Probabilistic  machine   learning   and   artificial   intelligence.   Nature,   521:452-‐ 459.   37. Glymour,  C.  (2004).  The  automation  of  Discovery.  Daedalus  Winter  2004,  pp.  69-‐77.   38. Haas,  L.M.  (2015)  The  Power  Behind  the  Throne:  Information  Integration  in  the  Age  of  Data-‐Driven  \nDiscovery.   In  Proceedings  of   the  2015  ACM  SIGMOD   International  Conference  on  Management  of   Data.  pp.  661-‐661).  ACM.  \n39. Hacking,   I.   (1983).  Representing  and   Intervening.   Introductory  Topics   in   the  Philosophy  of  Science.   Cambridge  University  Press.   40. Hampton,  S.E.,  Strasser,  C.A.,  Tewksbury,  J.J.,  Gram,  W.K.,  Budden,  A.E.,  Batcheller,  A.L.,  Duke,  C.S.   and   Porter,   J.H.   (2013).   Big   data   and   the   future   of   ecology.   Frontiers   in   Ecology   and   the   Environment,  11:156-‐162.   41. Heckerman,  D.,  Geiger,  D.  and  Chickering,  D.M.,  1995.  Learning  Bayesian  networks:  The  combination   of  knowledge  and  statistical  data.  Machine  learning,  20:197-‐243.   42. Hey,  Tansley,  S.  and  Tolle,  K.M.  (Ed)  2009.  The  fourth  paradigm:  data-‐intensive  scientific  discovery.   Redmond,  WA:  Microsoft  Research  \n43. Holland,   J.H.   (1975).   Adaptation   in   natural   and   artificial   systems:   an   introductory   analysis   with   applications  to  biology,  control,  and  artificial  intelligence.  U  Michigan  Press.   44. Honavar,   V.   (2013).   From  Data  Analytics   to  Discovery   Informatics.   In:  Data   Science:  Unlocking   the   Power   of   Big   Data.   National   Institutes   of   Health   Videocast.   http://videocast.nih.gov/summary.asp?bhjs=0&File=17798.   45. Honavar,  V.  (2014).  The  promise  and  potential  of  big  data:  A  case  for  discovery  informatics.  Review   of  Policy  Research,  31(4),  pp.326-‐330.   46. Horrocks,   I.,   Sattler,   U.   and   Tobies,   S.   (1999),   September.   Practical   reasoning   for   expressive   description  logics.  In  Logic  for  Programming  and  Automated  Reasoning.  pp.  161-‐180.  Springer  Berlin   Heidelberg.  \n   16  \n47. Hull,  D.,  Wolstencroft,  K.,  Stevens,  R.,  Goble,  C.,  Pocock,  M.R.,  Li,  P.  and  Oinn,  T.,  2006.  Taverna:  a   tool  for  building  and  running  workflows  of  services.  Nucleic  acids  research,  34  (suppl  2),  pp.  W729-‐ W732.   48. Hunter,   L.   and   Cohen,   K.B.   (2006).   Biomedical   language   processing:   what's   beyond   PubMed?   Molecular  cell,  21(5):  589-‐594.  \n49. Jensen,   P.B.,   Jensen,   L.J.   and   Brunak,   S.   (2012).  Mining   electronic   health   records:   towards   better   research  applications  and  clinical  care.  Nature  Reviews  Genetics,  13:395-‐405.   50. Jordan,   M.I.   and   Mitchell,   T.M.   (2015).   Machine   learning:   Trends,   perspectives,   and   prospects.   Science,  349:255-‐260.   51. Karp   RM.   (2011).   Understanding   science   through   the   computational   lens.   Journal   of   Computer   Science  and  Technology,  26(4):  569-‐77.  \n52. Klahr,   D.   (2000).   Exploring   Science:   The   Cognition   and   Development   of   Discovery   Processes,   Cambridge,  MA:  MIT  Press.   53. Kleinberg   J.   (2000).   The   small-‐world   phenomenon:   An   algorithmic   perspective.   In:   Proceedings   of   the  thirty-‐second  annual  ACM  symposium  on  Theory  of  computing.  pp.  163-‐170.  ACM.   54. Kuhn,  T.  S.  (1996).  The  Structure  of  Scientific  Revolutions  (3rd  ed.).  University  of  Chicago  Press.   55. Kutz,   O.,   Lutz,   C.,  Wolter,   F.   and   Zakharyaschev,  M.   (2004).   E-‐connections   of   abstract   description  \nsystems.  Artificial  intelligence,  156:  1-‐73.   56. Langley,  P.  (1981)  Data‐driven  discovery  of  physical  laws.  Cognitive  Science,  5(1),  pp.31-‐54.   57. Langley,   P.,   Simon,   H.A.,   Bradshaw,   G.L.,   and   Zytkow,   J.M.   (1987).   Scientific   discovery:  \nComputational  explorations  of  the  creative  processes.  Cambridge,  MA:  MIT  Press.   58. Lenzerini,  M.  (2002).  Data  integration:  A  theoretical  perspective.   In  Proceedings  of  the  twenty-‐first  \nACM  SIGMOD-‐SIGACT-‐SIGART  symposium  on  Principles  of  database  systems  pp.  233-‐246.  ACM.   59. Lindsay,  R.K.,  Buchanan,  B.G.,   Feigenbaum,  E.A.,  and  Lederberg,   J.   (1980).  Applications  of  Artificial  \nIntelligence  for  Organic  Chemistry:  The  DENDRAL  Project,  McGraw-‐Hill.   60. Mallory   EK,   Zhang   C,   Ré   C,   Altman   RB.   Large-‐scale   extraction   of   gene   interactions   from   full   text  \nliterature  using  DeepDive.  Bioinformatics.  2015  btv476.   61. McAuliffe,  J.D.,  Pachter,  L.  and  Jordan,  M.I.  (2004).  Multiple-‐sequence  functional  annotation  and  the  \ngeneralized  hidden  Markov  phylogeny.  Bioinformatics,  20:1850-‐1860.   62. Niu,  F,  Zhang  C,  Ré  C,  Shavlik  J.W.  (2012).  DeepDive:  Web-‐scale  Knowledge-‐base  Construction  using  \nStatistical  Learning  and  Inference.  VLDS  12:25-‐8.   63. Pazzani,  M.J.,  Mani,  S.  and  Shankle,  W.R.,  1997.  Beyond  Concise  and  Colorful:   Learning   Intelligible  \nRules.  In  KDD  (Vol.  97,  pp.  235-‐238).   64. Pereira,   F.,  Mitchell,   T.   and   Botvinick,  M.   (2009).  Machine   learning   classifiers   and   fMRI:   a   tutorial  \noverview.  Neuroimage,  45(1):  S199-‐S209.   65. Priami  C.  (2009).  Algorithmic  systems  biology.  Communications  of  the  ACM.  52(5):  80-‐8.   66. Romero,   C.   and   Ventura,   S.   (2010).   Educational   data   mining:   a   review   of   the   state   of   the   art.  \nSystems,  Man,  and  Cybernetics,  Part  C:  Applications  and  Reviews,  IEEE  Transactions  on,  40:601-‐618.   67. Rosenberg,  A.  (2000).  Philosophy  of  Science.  Routledge  Press.   68. Roughgarden  T.  (2010).  Algorithmic  game  theory.  Communications  of  the  ACM.  53(7):78-‐86.   69. Rzhetsky,   A.,   Foster,   J.G.,   Foster,   I.T.   and   Evans,   J.A.   (2015).   Choosing   experiments   to   accelerate  \ncollective  discovery.  Proceedings  of  the  National  Academy  of  Sciences,  112(47):14569-‐14574.   70. Salomon,   G.,   Perkins,   D.N.   and   Globerson,   T.   (1991).   Partners   in   cognition:   Extending   human  \nintelligence  with  intelligent  technologies.  Educational  researcher,  20(3),  pp.2-‐9.   71. Schmidt,  M.  and  Lipson,  H.  (2009).  Distilling  free-‐form  natural  laws  from  experimental  data.  Science,  \n324(5923),  pp.81-‐85.  \n   17  \n72. Segal,  E.,  Shapira,  M.,  Regev,  A.,  Pe'er,  D.,  Botstein,  D.,  Koller,  D.  and  Friedman,  N.  (2003).  Module   networks:   identifying   regulatory   modules   and   their   condition-‐specific   regulators   from   gene   expression  data.  Nature  genetics,  34:166-‐176.   73. Shrager,   J.,   &   Langley,   P.   (Eds.)   (1990).   Computational   models   of   scientific   discovery   and   theory   formation.  San  Mateo,  CA:  Morgan  Kaufmann.  \n74. Sinatra   R,   Deville   P,   Szell  M,  Wang   D,   Barabási   A.L.   (2015).   A   century   of   physics.   Nature   Physics.   11(10):791-‐6.   75. Smalheiser,  N.R.  (2012),  Literature-‐based  discovery:  Beyond  the  ABCs.  J.  Am.  Soc.  Inf.  Sci.,  63:  218– 224.  doi:  10.1002/asi.21599   76. Swanson  DR,  Smalheiser  NR.  An  interactive  system  for  finding  complementary  literatures:  a  stimulus   to  scientific  discovery.  Artificial  Intelligence  1997;  91:  183-‐203.  \n77. Tenenbaum,   J.B.,   Griffiths,   T.L.   and   Kemp,   C.   (2006).   Theory-‐based   Bayesian   models   of   inductive   learning  and  reasoning.  Trends  in  cognitive  sciences,  10:309-‐318.   78. Valdez-‐Perez,  R.E.  (1999).  Principles  of  Human-‐Computer  Collaboration  for  Knowledge  Discovery  in   Science  Artificial  Intelligence  107:335-‐346.     79. Valiant,  L.G.  (2009).  Evolvability.  Journal  of  the  ACM  (JACM),  56(1),  DOI  =  10.1145/1462153.1462156   http://doi.acm.org/10.1145/1462153.1462156  \n80. Waltz,  D.  and  Buchanan,  B.G.,  2009.  Automating  science.  Science,  324(5923),  pp.43-‐44.   81. Xue,   L.C.,   Dobbs,   D.,   Bonvin,   A.M.   and   Honavar,   V.   (2015).   Computational   prediction   of   protein  \ninterfaces:  A  review  of  data  driven  methods.  FEBS  letters,  589:3516-‐3526.   82. Zytkow,  J.M.,  Zhu,  J.  and  Hussam,  A.  (1990)  Automated  Discovery  in  a  Chemistry  Laboratory.  In  AAAI  \npp.  889-‐894.  \n  \n  \n                  For  citation  use:  Honavar  V.,  Hill  M.,  &  Yelick  K.  (2016).  Accelerating  Science:  A  Computing  Research   Agenda:  A  white  paper  prepared  for  the  Computing  Community  Consortium  committee  of  the   Computing  Research  Association.  http://cra.org/ccc/resources/ccc-‐led-‐whitepapers/                          This  material  is  based  upon  work  supported  by  the  National  Science  Foundation  under  Grant  No.   (1136993).  Any  opinions,  findings,  and  conclusions  or  recommendations  expressed  in  this  material   are  those  of  the  author(s)  and  do  not  necessarily  reflect  the  views  of  the  National  Science   Foundation.  "
    } ],
    "references" : [ {
      "title" : "Gene Ontology: tool for the unification of biology",
      "author" : [ "M. Ashburner", "C.A. Ball", "J.A. Blake", "D. Botstein", "H. Butler", "J.M. Cherry", "A.P. Davis", "K. Dolinski", "S.S. Dwight", "J.T.J.T. Eppig" ],
      "venue" : "The Gene Ontology Consortium. Nature Genetics,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2000
    }, {
      "title" : "Basic description logics. In Description logic handbook",
      "author" : [ "F. Baader", "W. Nutt" ],
      "venue" : null,
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2003
    }, {
      "title" : "Bioinformatics: the machine learning approach",
      "author" : [ "P. Baldi", "S. Brunak" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2001
    }, {
      "title" : "Package-­‐based description logics. In Modular Ontologies (pp. 349-­‐371)",
      "author" : [ "J. Bao", "G. Voutsadakis", "G. Slutzki", "V. Honavar" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2009
    }, {
      "title" : "Transportability from multiple environments with limited experiments",
      "author" : [ "E. Bareinboim", "S. Lee", "V. Honavar", "J. Pearl" ],
      "venue" : "In Advances in Neural Information Processing Systems: pp. 136-­‐144",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2013
    }, {
      "title" : "The semantic web",
      "author" : [ "T. Berners-­‐Lee", "J. Hendler", "O. Lassila" ],
      "venue" : "Scientific American,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2001
    }, {
      "title" : "Application of formal methods to biological regulatory networks: extending Thomas’ asynchronous logical approach with temporal logic",
      "author" : [ "G Bernot", "JP Comet", "A Richard", "J. Guespin" ],
      "venue" : "Journal of theoretical biology",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2004
    }, {
      "title" : "Elements of argumentation",
      "author" : [ "P. Besnard", "A. Hunter" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "Next steps for citizen science",
      "author" : [ "R. Bonney", "J.L. Shirk", "T.B. Phillips", "A. Wiggins", "H.L. Ballard", "A.J. Miller-­‐Rushing", "J.K. Parrish" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2014
    }, {
      "title" : "Distributed description logics: Assimilating information from peer sources",
      "author" : [ "A. Borgida", "L. Serafini" ],
      "venue" : "Journal on data semantics",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2003
    }, {
      "title" : "The simultaneous evolution of author and paper networks",
      "author" : [ "K. Börner", "J.T. Maru", "R.L. Goldstone" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2004
    }, {
      "title" : "Reasoning about nonlinear system identification",
      "author" : [ "E Bradley", "M Easley", "R. Stolle" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2001
    }, {
      "title" : "Constructive Mathematics. In: The Stanford Encyclopedia of Philosophy Edward N. Zalta (ed.), http://plato.stanford.edu/archives/win2013/entries/mathematics-­‐ constructive",
      "author" : [ "D. Bridges", "E. Palmgren" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2013
    }, {
      "title" : "Tractable reasoning and efficient query answering in description logics: The DL-­‐Lite family",
      "author" : [ "D. Calvanese", "G. De Giacomo", "D. Lembo", "M. Lenzerini", "R. Rosati" ],
      "venue" : "Journal of Automated reasoning,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2007
    }, {
      "title" : "A graph-­‐based recovery and decomposition of Swanson’s hypothesis using semantic predications",
      "author" : [ "D. Cameron", "O. Bodenreider", "H. Yalamanchili", "T. Danh", "S. Vallabhaneni", "K. Thirunarayan", "A.P. Sheth", "T.C. Rindflesch" ],
      "venue" : "Journal of biomedical informatics,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2013
    }, {
      "title" : "Toward an Architecture for Never-­‐Ending Language Learning",
      "author" : [ "A. Carlson", "J. Betteridge", "B. Kisiel", "B. Settles", "E.R. Hruschka Jr.", "T.M. Mitchell" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2010
    }, {
      "title" : "What is this thing called Science",
      "author" : [ "A.F. Chalmers" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1999
    }, {
      "title" : "Collabseer: A Search Engine for collaboration discovery",
      "author" : [ "H.H. Chen", "L. Gou", "X. Zhang", "C.L. Giles", "June" ],
      "venue" : "In Proceedings of the 11th annual international ACM/IEEE joint conference on Digital libraries pp. 231-­‐240",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2011
    }, {
      "title" : "Compiling prior knowledge into an explicit bias",
      "author" : [ "W.W. Cohen" ],
      "venue" : "In Proceedings of the Ninth International Conference on Machine Learning",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2014
    }, {
      "title" : "Modular reuse of ontologies: Theory and practice",
      "author" : [ "B. Cuenca Grau", "I. Horrocks", "Y. Kazakov", "U. Sattler" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2008
    }, {
      "title" : "Formal molecular biology",
      "author" : [ "V Danos", "C. Laneve" ],
      "venue" : "Theoretical Computer Science",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2004
    }, {
      "title" : "Provenance and scientific workflows: challenges and opportunities",
      "author" : [ "S.B. Davidson", "J. Freire" ],
      "venue" : "In Proceedings of the 2008 ACM SIGMOD international conference on Management of data,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2008
    }, {
      "title" : "The Computer Revolution in Science: Steps Towards the Realization of Computer-­‐Supported Discovery Environments",
      "author" : [ "H. de Jong", "A. Rip" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1997
    }, {
      "title" : "Principles of data integration",
      "author" : [ "A. Doan", "A. Halevy", "Z. Ives" ],
      "venue" : null,
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2012
    }, {
      "title" : "Computational Discovery of Scientific Knowledge",
      "author" : [ "S. Dzeroski", "P. Langley", "L. Todorovski" ],
      "venue" : null,
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2007
    }, {
      "title" : "Augmenting human intellect: a conceptual framework",
      "author" : [ "D.C. Engelbart" ],
      "venue" : "Multimedia. From Wagner to Virtual Reality. New York: WW Norton & Company,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2001
    }, {
      "title" : "Theory-­‐guided data science for climate change",
      "author" : [ "J.H. Faghmous", "A. Banerjee", "S. Shekhar", "M. Steinbach", "V. Kumar", "A.R. Ganguly", "N. Samatova" ],
      "venue" : null,
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2014
    }, {
      "title" : "Executable cell biology",
      "author" : [ "Fisher J", "Henzinger TA" ],
      "venue" : "Nature biotechnology",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2007
    }, {
      "title" : "Knowledge-­‐based support vector machine classifiers. In Advances in neural information processing systems",
      "author" : [ "G.M. Fung", "O.L. Mangasarian", "J.W. Shavlik" ],
      "venue" : null,
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2002
    }, {
      "title" : "Examining the challenges of scientific workflows",
      "author" : [ "Y. Gil", "E. Deelman", "M. Ellisman", "T. Fahringer", "G. Fox", "D. Gannon", "C. Goble", "M. Livny", "L. Moreau", "J. Myers" ],
      "venue" : "IEEE Computer,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2007
    }, {
      "title" : "Discovery Informatics: AI Opportunities in Scientific Discovery",
      "author" : [ "Y. Gil", "Y. Hirsh" ],
      "venue" : "AAAI Technical Report FS-­‐12-­‐03",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2012
    }, {
      "title" : "Probabilistic machine learning and artificial intelligence",
      "author" : [ "Z. Ghahramani" ],
      "venue" : null,
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2015
    }, {
      "title" : "The automation of Discovery",
      "author" : [ "C. Glymour" ],
      "venue" : "Daedalus Winter",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2004
    }, {
      "title" : "The Power Behind the Throne: Information Integration in the Age of Data-­‐Driven Discovery",
      "author" : [ "L.M. Haas" ],
      "venue" : "In Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2015
    }, {
      "title" : "Representing and Intervening",
      "author" : [ "I. Hacking" ],
      "venue" : "Introductory Topics in the Philosophy of Science",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 1983
    }, {
      "title" : "Big data and the future of ecology",
      "author" : [ "S.E. Hampton", "C.A. Strasser", "J.J. Tewksbury", "W.K. Gram", "A.E. Budden", "A.L. Batcheller", "C.S. Duke", "J.H. Porter" ],
      "venue" : "Frontiers in Ecology and the Environment,",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2013
    }, {
      "title" : "Learning Bayesian networks: The combination of knowledge and statistical data",
      "author" : [ "D. Heckerman", "D. Geiger", "D.M. Chickering" ],
      "venue" : "Machine learning,",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 1995
    }, {
      "title" : "The fourth paradigm: data-­‐intensive scientific discovery",
      "author" : [ "Hey", "S. Tansley", "K.M. Tolle" ],
      "venue" : null,
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2009
    }, {
      "title" : "Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence",
      "author" : [ "J.H. Holland" ],
      "venue" : null,
      "citeRegEx" : "43",
      "shortCiteRegEx" : "43",
      "year" : 1975
    }, {
      "title" : "From Data Analytics to Discovery Informatics. In: Data Science: Unlocking the Power of Big Data",
      "author" : [ "V. Honavar" ],
      "venue" : "National Institutes of Health Videocast. http://videocast.nih.gov/summary.asp?bhjs=0&File=17798",
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 2013
    }, {
      "title" : "The promise and potential of big data: A case for discovery informatics",
      "author" : [ "V. Honavar" ],
      "venue" : "Review of Policy Research,",
      "citeRegEx" : "45",
      "shortCiteRegEx" : "45",
      "year" : 2014
    }, {
      "title" : "September. Practical reasoning for expressive description logics. In Logic for Programming and Automated Reasoning. pp. 161-­‐180",
      "author" : [ "I. Horrocks", "U. Sattler", "S. Tobies" ],
      "venue" : null,
      "citeRegEx" : "46",
      "shortCiteRegEx" : "46",
      "year" : 1999
    }, {
      "title" : "Taverna: a tool for building and running workflows of services",
      "author" : [ "D. Hull", "K. Wolstencroft", "R. Stevens", "C. Goble", "M.R. Pocock", "P. Li", "T. Oinn" ],
      "venue" : "Nucleic acids research,",
      "citeRegEx" : "47",
      "shortCiteRegEx" : "47",
      "year" : 2006
    }, {
      "title" : "Biomedical language processing: what's beyond PubMed",
      "author" : [ "L. Hunter", "K.B. Cohen" ],
      "venue" : "Molecular cell,",
      "citeRegEx" : "48",
      "shortCiteRegEx" : "48",
      "year" : 2006
    }, {
      "title" : "Mining electronic health records: towards better research applications and clinical care",
      "author" : [ "P.B. Jensen", "L.J. Jensen", "S. Brunak" ],
      "venue" : "Nature Reviews Genetics,",
      "citeRegEx" : "49",
      "shortCiteRegEx" : "49",
      "year" : 2012
    }, {
      "title" : "Machine learning: Trends, perspectives, and prospects",
      "author" : [ "M.I. Jordan", "T.M. Mitchell" ],
      "venue" : "Science,",
      "citeRegEx" : "50",
      "shortCiteRegEx" : "50",
      "year" : 2015
    }, {
      "title" : "Understanding science through the computational lens",
      "author" : [ "Karp RM" ],
      "venue" : "Journal of Computer Science and Technology,",
      "citeRegEx" : "51",
      "shortCiteRegEx" : "51",
      "year" : 2011
    }, {
      "title" : "Exploring Science: The Cognition and Development of Discovery Processes",
      "author" : [ "D. Klahr" ],
      "venue" : null,
      "citeRegEx" : "52",
      "shortCiteRegEx" : "52",
      "year" : 2000
    }, {
      "title" : "The small-­‐world phenomenon: An algorithmic perspective",
      "author" : [ "J. Kleinberg" ],
      "venue" : "Proceedings of the thirty-­‐second annual ACM symposium on Theory of computing",
      "citeRegEx" : "53",
      "shortCiteRegEx" : "53",
      "year" : 2000
    }, {
      "title" : "The Structure of Scientific Revolutions (3rd ed.)",
      "author" : [ "T.S. Kuhn" ],
      "venue" : null,
      "citeRegEx" : "54",
      "shortCiteRegEx" : "54",
      "year" : 1996
    }, {
      "title" : "E-­‐connections of abstract description systems",
      "author" : [ "O. Kutz", "C. Lutz", "F. Wolter", "M. Zakharyaschev" ],
      "venue" : "Artificial intelligence,",
      "citeRegEx" : "55",
      "shortCiteRegEx" : "55",
      "year" : 2004
    }, {
      "title" : "Data‐driven discovery of physical laws",
      "author" : [ "P. Langley" ],
      "venue" : "Cognitive Science,",
      "citeRegEx" : "56",
      "shortCiteRegEx" : "56",
      "year" : 1981
    }, {
      "title" : "Scientific discovery: Computational explorations of the creative processes",
      "author" : [ "P. Langley", "H.A. Simon", "G.L. Bradshaw", "J.M. Zytkow" ],
      "venue" : null,
      "citeRegEx" : "57",
      "shortCiteRegEx" : "57",
      "year" : 1987
    }, {
      "title" : "Data integration: A theoretical perspective",
      "author" : [ "M. Lenzerini" ],
      "venue" : "In Proceedings of the twenty-­‐first ACM SIGMOD-­‐SIGACT-­‐SIGART symposium on Principles of database systems pp. 233-­‐246",
      "citeRegEx" : "58",
      "shortCiteRegEx" : "58",
      "year" : 2002
    }, {
      "title" : "Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project, McGraw-­‐Hill",
      "author" : [ "R.K. Lindsay", "B.G. Buchanan", "E.A. Feigenbaum", "J. Lederberg" ],
      "venue" : null,
      "citeRegEx" : "59",
      "shortCiteRegEx" : "59",
      "year" : 1980
    }, {
      "title" : "Large-­‐scale extraction of gene interactions from full text literature using DeepDive",
      "author" : [ "EK Mallory", "C Zhang", "C Ré", "RB. Altman" ],
      "venue" : null,
      "citeRegEx" : "60",
      "shortCiteRegEx" : "60",
      "year" : 2015
    }, {
      "title" : "Multiple-­‐sequence functional annotation and the generalized hidden Markov phylogeny",
      "author" : [ "J.D. McAuliffe", "L. Pachter", "M.I. Jordan" ],
      "venue" : null,
      "citeRegEx" : "61",
      "shortCiteRegEx" : "61",
      "year" : 2004
    }, {
      "title" : "DeepDive: Web-­‐scale Knowledge-­‐base Construction using Statistical Learning and Inference",
      "author" : [ "Niu F", "C Zhang", "C Ré", "J.W. Shavlik" ],
      "venue" : "VLDS",
      "citeRegEx" : "62",
      "shortCiteRegEx" : "62",
      "year" : 2012
    }, {
      "title" : "Beyond Concise and Colorful: Learning Intelligible Rules",
      "author" : [ "M.J. Pazzani", "S. Mani", "W.R. Shankle" ],
      "venue" : "In KDD (Vol",
      "citeRegEx" : "63",
      "shortCiteRegEx" : "63",
      "year" : 1997
    }, {
      "title" : "Machine learning classifiers and fMRI: a tutorial overview",
      "author" : [ "F. Pereira", "T. Mitchell", "M. Botvinick" ],
      "venue" : null,
      "citeRegEx" : "64",
      "shortCiteRegEx" : "64",
      "year" : 2009
    }, {
      "title" : "Algorithmic systems biology",
      "author" : [ "C. Priami" ],
      "venue" : "Communications of the ACM",
      "citeRegEx" : "65",
      "shortCiteRegEx" : "65",
      "year" : 2009
    }, {
      "title" : "Educational data mining: a review of the state of the art. Systems, Man, and Cybernetics, Part C: Applications and Reviews",
      "author" : [ "C. Romero", "S. Ventura" ],
      "venue" : "IEEE Transactions on,",
      "citeRegEx" : "66",
      "shortCiteRegEx" : "66",
      "year" : 2010
    }, {
      "title" : "Algorithmic game theory",
      "author" : [ "T. Roughgarden" ],
      "venue" : "Communications of the ACM",
      "citeRegEx" : "68",
      "shortCiteRegEx" : "68",
      "year" : 2010
    }, {
      "title" : "Choosing experiments to accelerate collective discovery",
      "author" : [ "A. Rzhetsky", "J.G. Foster", "I.T. Foster", "J.A. Evans" ],
      "venue" : "Proceedings of the National Academy of Sciences,",
      "citeRegEx" : "69",
      "shortCiteRegEx" : "69",
      "year" : 2015
    }, {
      "title" : "Partners in cognition: Extending human intelligence with intelligent technologies",
      "author" : [ "G. Salomon", "D.N. Perkins", "T. Globerson" ],
      "venue" : "Educational researcher,",
      "citeRegEx" : "70",
      "shortCiteRegEx" : "70",
      "year" : 1991
    }, {
      "title" : "Distilling free-­‐form natural laws from experimental data",
      "author" : [ "M. Schmidt", "H. Lipson" ],
      "venue" : null,
      "citeRegEx" : "71",
      "shortCiteRegEx" : "71",
      "year" : 2009
    }, {
      "title" : "Module networks: identifying regulatory modules and their condition-­‐specific regulators from gene expression data",
      "author" : [ "E. Segal", "M. Shapira", "A. Regev", "D. Pe'er", "D. Botstein", "D. Koller", "N. Friedman" ],
      "venue" : "Nature genetics,",
      "citeRegEx" : "72",
      "shortCiteRegEx" : "72",
      "year" : 2003
    }, {
      "title" : "Computational models of scientific discovery and theory formation",
      "author" : [ "J. Shrager", "P. Langley" ],
      "venue" : null,
      "citeRegEx" : "73",
      "shortCiteRegEx" : "73",
      "year" : 1990
    }, {
      "title" : "Literature-­‐based discovery: Beyond the ABCs",
      "author" : [ "N.R. Smalheiser" ],
      "venue" : "J. Am. Soc. Inf. Sci.,",
      "citeRegEx" : "75",
      "shortCiteRegEx" : "75",
      "year" : 2012
    }, {
      "title" : "An interactive system for finding complementary literatures: a stimulus to scientific discovery",
      "author" : [ "Swanson DR", "Smalheiser NR" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "76",
      "shortCiteRegEx" : "76",
      "year" : 1997
    }, {
      "title" : "Theory-­‐based Bayesian models of inductive learning and reasoning",
      "author" : [ "J.B. Tenenbaum", "T.L. Griffiths", "C. Kemp" ],
      "venue" : "Trends in cognitive sciences,",
      "citeRegEx" : "77",
      "shortCiteRegEx" : "77",
      "year" : 2006
    }, {
      "title" : "Principles of Human-­‐Computer Collaboration for Knowledge Discovery in Science Artificial Intelligence 107:335-­‐346",
      "author" : [ "R.E. Valdez-­‐Perez" ],
      "venue" : null,
      "citeRegEx" : "78",
      "shortCiteRegEx" : "78",
      "year" : 1999
    }, {
      "title" : "Computational prediction of protein interfaces: A review of data driven methods",
      "author" : [ "L.C. Xue", "D. Dobbs", "A.M. Bonvin", "V. Honavar" ],
      "venue" : "FEBS letters,",
      "citeRegEx" : "81",
      "shortCiteRegEx" : "81",
      "year" : 2015
    }, {
      "title" : "Automated Discovery in a Chemistry Laboratory",
      "author" : [ "J.M. Zytkow", "J. Zhu", "A. Hussam" ],
      "venue" : "Any opinions,",
      "citeRegEx" : "82",
      "shortCiteRegEx" : "82",
      "year" : 1990
    } ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "The\t\r  emergence\t\r  of\t\r  “big\t\r  data”\t\r  offers\t\r  unprecedented\t\r  opportunities\t\r  for\t\r  not\t\r  only\t\r  accelerating\t\r  scientific advances\t\r   but\t\r   also\t\r   enabling\t\r   new\t\r   modes\t\r   of\t\r   discovery.\t\r   Scientific\t\r   progress\t\r   in\t\r   many\t\r   disciplines\t\r   is increasingly\t\r  enabled\t\r  by\t\r  our\t\r  ability\t\r  to\t\r  examine\t\r  natural\t\r  phenomena\t\r  through\t\r  the\t\r  computational\t\r  lens, i.e.,\t\r  using\t\r  algorithmic\t\r  or\t\r  information\t\r  processing\t\r  abstractions\t\r  of\t\r  the\t\r  underlying\t\r  processes;\t\r  and\t\r  our ability\t\r   to\t\r  acquire,\t\r   share,\t\r   integrate\t\r  and\t\r  analyze\t\r  disparate\t\r   types\t\r  of\t\r  data.\t\r  However,\t\r   there\t\r   is\t\r  a\t\r  huge gap\t\r  between\t\r  our\t\r  ability\t\r  to\t\r  acquire,\t\r  store,\t\r  and\t\r  process\t\r  data\t\r  and\t\r  our\t\r  ability\t\r  to\t\r  make\t\r  effective\t\r  use\t\r  of the\t\r   data\t\r   to\t\r   advance\t\r   discovery.\t\r   Despite\t\r   successful\t\r   automation\t\r   of\t\r   routine\t\r   aspects\t\r   of\t\r   data management\t\r  and\t\r  analytics,\t\r  most\t\r  elements\t\r  of\t\r  the\t\r  scientific\t\r  process\t\r  currently\t\r  require\t\r  considerable human\t\r  expertise\t\r  and\t\r  effort.\t\r  Accelerating\t\r  science\t\r  to\t\r  keep\t\r  pace\t\r  with\t\r  the\t\r  rate\t\r  of\t\r  data\t\r  acquisition\t\r  and data\t\r   processing\t\r   calls\t\r   for\t\r   the\t\r   development\t\r   of\t\r   algorithmic\t\r   or\t\r   information\t\r   processing\t\r   abstractions, coupled\t\r  with\t\r  formal\t\r  methods\t\r  and\t\r  tools\t\r  for\t\r  modeling\t\r  and\t\r  simulation\t\r  of\t\r  natural\t\r  processes\t\r  as\t\r  well\t\r  as major\t\r   innovations\t\r   in\t\r   cognitive\t\r   tools\t\r   for\t\r   scientists,\t\r   i.e.,\t\r   computational\t\r   tools\t\r   that\t\r   leverage\t\r   and extend\t\r   the\t\r   reach\t\r   of\t\r   human\t\r   intellect,\t\r   and\t\r   partner\t\r   with\t\r   humans\t\r   on\t\r   a\t\r   broad\t\r   range\t\r   of\t\r   tasks\t\r   in scientific\t\r  discovery\t\r   (e.g.,\t\r   identifying,\t\r  prioritizing\t\r   formulating\t\r  questions,\t\r  designing,\t\r  prioritizing\t\r  and executing\t\r  experiments\t\r  designed\t\r  to\t\r  answer\t\r  a\t\r  chosen\t\r  question,\t\r  drawing\t\r   inferences\t\r  and\t\r  evaluating the\t\r   results,\t\r   and\t\r   formulating\t\r   new\t\r   questions,\t\r   in\t\r   a\t\r   closed-­‐loop\t\r   fashion).\t\r   This\t\r   calls\t\r   for\t\r   concerted research\t\r   agenda\t\r   aimed\t\r   at:\t\r   Development,\t\r   analysis,\t\r   integration,\t\r   sharing,\t\r   and\t\r   simulation\t\r   of algorithmic\t\r   or\t\r   information\t\r   processing\t\r   abstractions\t\r   of\t\r   natural\t\r   processes,\t\r   coupled\t\r   with\t\r   formal methods\t\r  and\t\r  tools\t\r   for\t\r   their\t\r  analyses\t\r  and\t\r  simulation;\t\r   Innovations\t\r   in\t\r  cognitive\t\r   tools\t\r   that\t\r  augment and\t\r  extend\t\r  human\t\r  intellect\t\r  and\t\r  partner\t\r  with\t\r  humans\t\r  in\t\r  all\t\r  aspects\t\r  of\t\r  science.\t\r  This\t\r  in\t\r  turn\t\r  requires: the\t\r  formalization,\t\r  development,\t\r  analysis,\t\r  of\t\r  algorithmic\t\r  or\t\r   information\t\r  processing\t\r  abstractions\t\r  of various\t\r   aspects\t\r   of\t\r   the\t\r   scientific\t\r   process;\t\r   the\t\r   development\t\r   of\t\r   computational\t\r   artifacts (representations,\t\r  processes,\t\r  protocols,\t\r  workflows,\t\r  software)\t\r  that\t\r  embody\t\r  such\t\r  understanding;\t\r  and the\t\r   integration\t\r   of\t\r   the\t\r   resulting\t\r   cognitive\t\r   tools\t\r   into\t\r   collaborative\t\r   human-­‐machine\t\r   systems\t\r   and infrastructure\t\r  to\t\r  advance\t\r  science.",
    "creator" : "Word"
  }
}