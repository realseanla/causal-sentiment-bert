{
  "name" : "1305.1704.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "The Extended Parameter Filter",
    "authors" : [ "Yusuf B. Erol", "Lei Li", "Bharath Ramsundar", "Stuart Russell" ],
    "emails" : [ "yberol@eecs.berkeley.edu", "leili@cs.berkeley.edu", "rbharath@stanford.edu", "russell@cs.berkeley.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Yusuf B. Erol† yberol@eecs.berkeley.edu Lei Li† leili@cs.berkeley.edu Bharath Ramsundar rbharath@stanford.edu\nComputer Science Department, Stanford University\nStuart Russell† russell@cs.berkeley.edu †EECS Department, University of California, Berkeley\nAbstract\nThe parameters of temporal models, such as dynamic Bayesian networks, may be modelled in a Bayesian context as static or atemporal variables that influence transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost that grows linearly with the length of the observation sequence. Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. In this paper, we demonstrate a connection between Storvik’s filter and a Kalman filter in parameter space and establish more general conditions under which Storvik’s filter works. Drawing on an analogy to the extended Kalman filter, we develop and analyze, both theoretically and experimentally, a Taylor approximation to the parameter posterior that allows Storvik’s method to be applied to a broader class of models. Our experiments on both synthetic examples and real applications show improvement over existing methods."
    }, {
      "heading" : "1. Introduction",
      "text" : "Dynamic Bayesian networks are widely used to model the processes underlying sequential data such as speech signals, financial time series, genetic sequences, and medical or physiological signals. State estimation\nAppearing in Proceedings of the 30 th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. Copyright 2013 by the author(s)/owner(s).\n000 001 002 003 004 005 006 007 008 009 010 011 012 013 014 015 016 017 018 019 020 021 022 023 024 025 026 027 028 029 030 031 032 033 034 035 036 037 038 039 040 041 042 043 044 045 046 047 048 049 050 051 052 053 054\n055 056 057 058 059 060 061 062 063 064 065 066 067 068 069 070 071\n078 079 080 081 082 083 084 085 086 087 088 089 090 091 092 093 094 095 096 097 098 099 100 101 102 103 104 105 106 107 108 109\nThe Extended Parameter Filter Abstract The parameters of temporal models such as dynamic Bayesian networks may be viewed in the Bayesian context as static or atemporal variables that influence the transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost\nthat grows linearly with the length of the ob-\nservation sequence. Storvik (2002) devised a\nmethod for incremental computation of ex-\nact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. In this paper, we demonstrate a connection between Storvik’s filter and a Kalman filter in parameter sp ce a d establish more general conditions under which it works. Drawing on an analogy to the extended Kalman filter, we develop and an lyze, both theoretically and experimentally, a Taylor approximation to the parameter posterior that allows Storvik’s ethod to be applied to a broader class of models. Our experiments on both synthetic examples and real applications show improvement over existing methods. 1. Introduction Dynamic Bayesian networks are widely used to model the process s un erlying sequential data such as speech signals, financial time series, genetic sequences, and medical or physiological signals. State estimation or filtering—computing the posterior distribution over the state of a partially observable Markov process from a sequence of observations—is one of the most widely studied problems in control theory, statistics and AI. Exact filtering is intractable except for certain special cases (linear–Gaussian models and discrete HMMs), but approximate filtering using the particle filter (a sePreliminary work. Under review by the International Conference on Machine Learning (ICML). Do not distribute.\nθ X1 Y1 X2 Y2 X3 Y3 · · · XT YT\nquential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008). In the machine learning context, model parameters may be represented by static parameter variables that define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) converges to a delta function at the true value in the limit of infinitely many observations. Unfortunately, particle filters fail for such models: the algorithm samples parameter values for each particle at time t= 0, but these remain fixed; over time, the particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009); Carvalho et al. (2010) describe several algorithms that have been proposed to solve this degeneracy problem, but the issue remains open because known algorithms either suffer from bias or computational inefficiency. For example, the “artificial dynamics” approach (Liu and West, 2001) introduces a stochastic transition model for the parameter variables, allowing exploration of parameter space, but this may result in biased estimates. Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution. The particle MCMC algorithm (An-\nFigure 1. A state-space mo l with static parameters θ. X1:T are latent states and Y1:T are observations.\nor filtering—computing the posterior distribution over the state of a partially observable Markov process from a sequence of observations—is one of the most widely s udied problems in control theory, statistics and AI. Exact filtering is intractable except f r certain special c ses (linear–Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011). In the machine learning context, model parameters may be represented by static parameter variables tha define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) conv rges to a delta function at the true value in the li it of infinitely many observations. Unfortunately, particle filters fail for such models: the algorith samples p rameter values for each particle at time t= 0, but these remain fixed; over time, th particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable.\nKantas et al. (2009) and Carvalho et al. (2010) describe several algorithms that have been proposed to\nar X\niv :1\n30 5.\n17 04\nv1 [\nst at\n.M L\n] 8\nM ay\n2 01\n3\nsolve this degeneracy problem, but the issue remains open because known algorithms either suffer from bias or computational inefficiency. For example, the “artificial dynamics” approach (Liu and West, 2001) introduces a stochastic transition model for the parameter variables, allowing exploration of the parameter space, but this may result in biased estimates. Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution. The particle MCMC algorithm (Andrieu et al., 2010) converges to the true posterior, but requires computation growing with T , the length of the data sequence.\nThe resample-move algorithm (Gilks and Berzuini, 2001) includes Gibbs sampling of parameter variables—that is, in Figure 1, P (θ | X1, . . . , XT ). This method requires O(T ) computation per sample, leading Gilks and Berzuini to propose a sampling rate proportional to 1/T to preserve constant-time updates. Storvik (2002) and Polson et al. (2008) observe that a fixed-dimensional sufficient statistic (if one exists) for θ can be updated in constant time. Storvik describes an algorithm for a specific family of linear-in-parameters transition models.\nWe show that Storvik’s algorithm is a special case of the Kalman filter in parameter space and identify a more general class of separable systems to which the same approach can be applied. By analogy with the extended Kalman filter, we propose a new algorithm, the extended parameter filter (EPF), that computes a separable approximation to the parameter posterior and allows a fixed-dimensional (approximate) sufficient statistic to be maintained. The method is quite general: for example, with a polynomial approximation scheme such as Taylor expansion any analytic posterior can be handled.\nSection 2 briefly reviews particle filters and Storvik’s method and introduces our notion of separable models. Section 3 describes the EPF algorithm, and Section 4 discusses the details of a polynomial approximation scheme for arbitrary densities, which Section 4.2 then applies to estimate posterior distributions of static parameters. Section 5 provides empirical results comparing the EPF to other algorithms. All details of proofs are given in the appendix of the full version (Erol et al., 2013)."
    }, {
      "heading" : "2. Background",
      "text" : "In this section, we review state-space dynamical models and the basic framework of approximate filtering\nalgorithms."
    }, {
      "heading" : "2.1. State-space model and filtering",
      "text" : "Let Θ be a parameter space for a partially observable Markov process {Xt}t≥0 , {Yt}t≥0 as shown in Figure 1 and defined as follows:\nX0 ∼ p(x0 |θ) (1) Xt |xt−1 ∼ p(xt |xt−1, θ) (2) Yt |xt ∼ p(yt |xt, θ) (3)\nHere the state variables Xt are unobserved and the observations Yt are assumed conditionally independent of other observations given Xt. We assume in this section that states Xt, observations Yt, and parameters θ are real-valued vectors in d, m, and p dimensions respectively. Here both the transition and sensor models are parameterized by θ. For simplicity, we will assume in the following sections that only the transition model is parameterized by θ; however, the results in this paper can be generalized to cover sensor model parameters.\nThe filtering density p(xt | y0:t, θ) obeys the following recursion:\np(xt |y0:t, θ) = p(yt |xt, θ)p(xt |y0:t−1, θ)\np(yt |y0:t−1, θ)\n= p(yt |xt, θ)\np(yt |y0:t−1, θ)\n∫ p(xt−1 |y0:t−1, θ)p(xt |xt−1, θ)dxt−1\n(4)\nwhere the update steps for p(xt | y0:t−1, θ) and p(yt | y0:t−1, θ) involve the evaluation of integrals that are not in general tractable."
    }, {
      "heading" : "2.2. Particle filtering",
      "text" : "With known parameters, particle filters can approximate the posterior distribution over the hidden state Xt by a set of samples. The canonical example is the sequential importance sampling-resampling algorithm (SIR) (Algorithm 1).\nThe SIR filter has various appealing properties. It is modular, efficient, and easy to implement. The filter takes constant time per update, regardless of time T , and as the number of particles N →∞, the empirical filtering density converges to the true marginal posterior density under suitable assumptions.\nParticle filters can accommodate unknown parameters by adding parameter variables into the state vector with an “identity function” transition model. As noted in Section 1 this approach leads to degeneracy problems—especially for high-dimensional parameter\nAlgorithm 1: Sequential importance samplingresampling (SIR)\nInput: N : number of particles; y0, . . . , yT : observation sequence Output: x̄1:N1:T initialize { xi0 }\n; for t = 1, . . . , T do\nfor i = 1, . . . , N do sample xit ∼ p(xt |xit−1); wit ← p(yt |xit);\nsample {\n1 N , x̄ i t\n} ←Multinomial { wit, x i t } ;{\nxit } ← { x̄it } ;\nspaces. To ensure that some particle has initial parameter values with bounded error, the number of particles must grow exponentially with the dimension of the parameter space."
    }, {
      "heading" : "2.3. Storvik’s algorithm",
      "text" : "To avoid the degeneracy problem, Storvik (2002) modifies the SIR algorithm by adding a Gibbs sampling step for θ conditioned on the state trajectory in each particle (see Algorithm 2). The algorithm is developed in the SIS framework and consequently inherits the theoretical guarantees of SIS. Storvik considers unknown parameters in the state evolution model and assumes a perfectly known sensor model. His analysis can be generalized to unknown sensor models.\nStorvik’s approach becomes efficient in an on-line setting when a fixed-dimensional sufficient statistic St exists for the static parameter (i.e., when p(θ|x0:t) = p(θ|St) holds). The important property of this algorithm is that the parameter value simulated at time t does not depend on the values simulated previously. This property prevents the impoverishment of the parameter values in particles.\nOne limitation of the algorithm is that it can only be applied to models with fixed-dimensional sufficient statistics. However, Storvik (2002) analyze the sufficient statistics for a specific family.\nStorvik (2002) shows how to obtain a sufficient statistic in the context of what he calls the Gaussian system process, a transition model satisfying the equation\nxt = F T t θ + t, t ∼ N(0,Q) (5)\nwhere θ is the vector of unknown parameters with a prior of N(θ0,C0) and Ft = F(xt−1) is a matrix where elements are possibly nonlinear functions of xt−1. An arbitrary but known observation model\nAlgorithm 2: Storvik’s filter.\nInput: N : number of particles; y0, . . . , yT : observation sequence Output: x̄1:N1:T , θ 1:N\ninitialize { xi0 }\n; for t = 1, . . . , T do\nfor i = 1, . . . , N do sample θi ∼ p(θ|xi0:t−1); sample xit ∼ p(xt|xit−1, θi); wi ← p(yt|xit);\nsample {\n1 N , x̄ i t\n} ←Multinomial { wit, x i t } ;{\nxit } ← { x̄it } ;\nis assumed. Then the standard theory states that θ |x0:t ∼ N(mt,Ct) where the recursions for the mean and the covariance matrix are as follows:\nDt = F T t Ct−1Ft + Q Ct = Ct−1 −Ct−1FtD−1t FTt Ct−1 mt = mt−1 + Ct−1FtD −1 t (xt − FTt mt−1) (6)\nThus, mt and Ct constitute a fixed-dimensional sufficient statistic for θ.\nThese updates are in fact a special case of Kalman filtering applied to the parameter space. Matching terms with the standard KF update equations (Kalman, 1960), we find that the transition matrix for the KF is the identity matrix, the transition noise covariance matrix is the zero matrix, the observation matrix for the KF is Ft, and the observation noise covariance matrix is Q. This correspondence is of course what one would expect, since the true parameter values are fixed (i.e., an identity transition). See the supplementary material (Erol et al., 2013) for the derivation."
    }, {
      "heading" : "2.4. Separability",
      "text" : "In this section, we define a condition under which there exist efficient updates to parameters. Again, we focus on the state-space model as described in Figure 1 and Equation (3). The model in Equation (3) can also be expressed as\nxt = fθ(xt−1) + vt\nyt = g(xt) + wt (7)\nfor some suitable fθ, g, vt, and wt.\nDefinition 1. A system is separable if the transition function fθ(xt−1) can be written as fθ(xt−1) = l(xt−1)\nTh(θ) for some l(·) and h(·) and if the stochastic i.i.d. noise vt has log-polynomial density.\nTheorem 1. For a separable system, there exist fixeddimensional sufficient statistics for the Gibbs density, p(θ | x0:T ).\nThe proof is straightforward by the Fisher–Neyman factorization theorem; more details are given in the supplementary material of the full version (Erol et al., 2013).\nThe Gaussian system process models defined in Equation (5) are separable, since the transition function FTt θ = (Ft)\nT θ, but the property—and therefore Storvik’s algorithm—applies to a much broader class of systems. Moreover, as we now show, non-separable systems may in some cases be well-approximated by separable systems, constructed by polynomial density approximation steps applied to either the Gibbs distribution p(θ | x0:t) or to the transition model."
    }, {
      "heading" : "3. The extended parameter filter",
      "text" : "Let us consider the following model.\nxt = fθ(xt−1) + vt; vt ∼ N(0,Σ) (8)\nwhere x ∈ Rd,θ ∈ Rp and fθ(·) : Rd → Rd is a vectorvalued function parameterized by θ. We assume that the transition function fθ may be non-separable. Our algorithm will create a polynomial approximation to either the transition function or to the Gibbs distribution, p(θ | x0:t). To illustrate, let us consider the transition model fθ(xt−1) = sin(θxt−1). It is apparent that this transition model is non-separable. If we approximate the transition function with a Taylor series in θ centered around zero\nfθ(xt−1) ≈ f̂θ(xt−1) = xt−1θ − 1\n3! x3t−1θ 3 + . . . (9)\nand use f̂ as an approximate transition model, the system will become separable. Then, Storvik’s filter can be applied in constant time per update. This Taylor approximation leads to a log-polynomial density of the form of Equation (12).\nOur approach is analogous to that of the extended Kalman filter (EKF). EKF linearizes nonlinear transitions around the current estimates of the mean and covariance and uses Kalman filter updates for state estimation (Welch and Bishop, 1995). Our proposed algorithm, which we call the extended parameter filter (EPF), approximates a non-separable system with a separable one, using a polynomial approximation of some arbitrary order. This separable, approximate model is well-suited for Storvik’s filter and allows for\nAlgorithm 3: Extended Parameter Filter\nResult: Approximate the Gibbs density p(θ | x0:t, y0:t) with the log-polynomial density p̂(θ | x0:t, y0:t) Output: x̃1 . . . x̃N\ninitialize { xi0 }\nand Si0 ← 0; for t = 1, . . . , T do\nfor i = 1, . . . , N do Sit = update(S i t−1, xt−1) ; // update\nstatistics for polynomial approximation log(p̂(θ|x̄0:t−1, y0:t−1)) sample θi ∼ p̂(θ | x̄i0:t−1, y0:t−1) = p̂(θ | Sit) ; sample xit ∼ p(xt | x̄it−1, θi) ; wi ← p(yt | xit, θi);\nsample {\n1 N , x̄ i t, S̄ i t\n} ←Multinomial { wit, x i t, S i t } ;{\nxit, S i t } ← { x̄it, S̄ i t } ;\nconstant time updates to the Gibbs density of the parameters.\nAlthough we have described an analogy to the EKF, it is important to note that the EPF can effectively use higher-order approximations instead of just first-order linearizations as in EKF. In EKF, higher order approximations lead to intractable integrals. The prediction integral for EKF\np(xt | y0:t−1) = ∫ p(xt−1 | y0:t−1)p(xt | xt−1)dxt−1\ncan be calculated for linear Gaussian transitions, in which case the mean and the covariance matrix are the tracked sufficient statistic. However, in the case of quadratic transitions (or any higher-order transitions), the above integral is no longer analytically tractable.\nIn the case of EPF, the transition model is the identity transition and hence the prediction step is trivial. The filtering recursion is\np(θ | x0:t) ∝ p(xt | xt−1, θ)p(θ | x0:t−1). (10)\nWe approximate the transition p(xt | xt−1, θ) with a log-polynomial density p̂ (log-polynomial in θ), so that the Gibbs density, which satisfies the recursions in equation 10, has a fixed log-polynomial structure at each time step. Due to the polynomial structure, the approximate Gibbs density can be tracked in terms of its sufficient statistic (i.e., in terms of the coefficients of the polynomial). The log-polynomial structure is derived in Section 4.2. Pseudo-code for EPF is shown in Algorithm 3.\nNote that the approximated Gibbs density will be a log-multivariate polynomial density of fixed order\n(proportional to the order of the polynomial approximation). Sampling from such a density is not straightforward but can be done by Monte Carlo sampling. We suggest slice sampling (Neal, 2003) or the MetropolisHastings algorithm (Robert and Casella, 2005) for this purpose. Although some approximate sampling scheme is necessary, sampling from the approximated density remains a constant-time operation when the dimension of p̂ remains constant.\nIt is also important to note that performing a polynomial approximation for a p-dimensional parameter space may not be an easy task. However, we can reduce the computational complexity of such approximations by exploiting locality properties. For instance, if fθ(·) = hθ1,...,θp−1(·) + gθp(·), where h is separable and g is non-separable, we only need to approximate g.\nIn section 4, we discuss the validity of the approximation in terms of the KL-divergence between the true and approximate densities. In section 4.1, we analyze the distance between an arbitrary density and its approximate form with respect to the order of the polynomial. We show that the distance goes to zero superexponentially. Section 4.2 analyzes the error for the static parameter estimation problem and introduces the form of the log-polynomial approximation."
    }, {
      "heading" : "4. Approximating the conditional distribution of parameters",
      "text" : "In this section, we construct approximate sufficient statistics for arbitrary one–dimensional state space models. We do so by exploiting log-polynomial approximations to arbitrary probability densities. We prove that such approximations can be made arbitrarily accurate. Then, we analyze the error introduced by log-polynomial approximation for the arbitrary one– dimensional model."
    }, {
      "heading" : "4.1. Taylor approximation to an arbitrary density",
      "text" : "Let us assume a distribution p (known only up to a normalization constant) expressed in the form p(x) ∝ exp(S(x)), where S(x) is an analytic function on the support of the distribution. In general we need a Monte Carlo method to sample from this arbitrary density. In this section, we describe an alternative, simpler sampling method. We propose that with a polynomial approximation P (x) (Taylor, Chebyshev etc.) of sufficient order to the function S(x), we may sample from a distribution p̂ ∝ exp(P (x)) with a simpler (i.e. log-polynomial) structure. We show that the distance between the distributions p and p̂ reduces to\n0 as the order of the approximation increases.\nThe following theorem is based on Taylor approximations; however, the theorem can be generalized to handle any polynomial approximation scheme. The proof is given in (Erol et al., 2013).\nTheorem 2. Let S(x) be a M + 1 times differentiable function with bounded derivatives, and let P (x) be its M -th order Taylor approximation. Then the KLdivergence between distributions p and p̂ converges to 0, super-exponentially as the order of approximation M →∞.\nWe validate the Taylor approximation approach for the log-density S(x) = −x2+5 sin2(x). Figure 2 shows the result for this case."
    }, {
      "heading" : "4.2. Online approximation of the Gibbs density of the parameter",
      "text" : "In our analysis, we will assume the following model.\nxt = fθ(xt−1) + vt, vt ∼ N(0, σ2) yt = g(xt) + wt, wt ∼ N(0, σ2o)\nThe posterior distribution for the static parameter is\np(θ|x0:T ) ∝ p(θ) T∏ t=1 p(xt|xt−1, θ).\nThe product term, which requires linear time, is the bottleneck for this computation. A polynomial approximation to the transition function fθ(·) (the Taylor approximation around θ = 0) is:\nfθ(xt−1) = h(xt−1, θ) = M∑ i=0 1 i! dih(xt−1, θ i) dθ ∣∣ θ=0︸ ︷︷ ︸\nHi(xt−1)\nθi +RM (θ)\n= M∑ i=0 Hi(xt−1)θ i +RM (θ) = f̂(θ) +RM (θ)\nwhere RM is the error for the M -dimensional Taylor approximation. We define coefficients J ixt−1 to satisfy(∑M\ni=0H i(xt−1)θ\ni )2\n= J2Mxt−1θ 2M + · · ·+ J0xt−1θ0.\nLet p̂(θ | x0:T ) denote the approximation to p(θ | x0:T ) obtained by using the polynomial approximation to fθ introduced above. Theorem 3. p̂(θ | x0:T ) is in the exponential family with the log-polynomial density\nlog p(θ)+ (12) θ1 ... θM θM+1\n... θ2M\n T\n︸ ︷︷ ︸ T (θ)T\n.  1 σ2 ∑T k=1 xkH 1(xk−1)− 12σ2 ∑T k=1 J 1 xk−1 ... 1 σ2 ∑T k=1 xkH M (xk−1)− 12σ2 ∑T k=1 J M xk−1 − 1 2σ2 ∑T k=1 J M+1 xk−1 ...\n− 1 2σ2 ∑T k=1 J 2M xk−1  ︸ ︷︷ ︸\nη(x0,...,xt)\nThe proof is given in the supplementary material.\nThis form has finite dimensional sufficient statistics. Standard sampling from p(θ | x0:t) requires O(t) time, whereas with the polynomial approximation we can sample from this structured density of fixed dimension in constant time (given that sufficient statistics were tracked). We can furthermore prove that sampling from this exponential form approximation is asymptotically correct.\nTheorem 4. Let pT (θ | x0:T ) denote the Gibbs distribution and p̂T (θ | x0:T ) its order M exponential family approximation. Assume that parameter θ has support Sθ and finite variance. Then as M →∞, T →∞, the KL divergence between pT and p̂T goes to zero.\nlim M,T→∞\nDKL(pT || p̂T ) = 0\nThe proof is given in the supplementary material (Erol et al., 2013). Note that the analysis above can be generalized to higher dimensional parameters. The one dimensional case is discussed for ease of exposition.\nIn the general case, an order M Taylor expansion for a p dimensional parameter vector θ will have Mp terms. Then each update of the sufficient statistics will cost O(Mp) per particle, per time step, yielding the total complexity O(NTMp). However, as noted before, we can often exploit the local structure of fθ to speed up the update step. Notice that in either case, the update cost per time step is fixed (independent of T )."
    }, {
      "heading" : "5. Experiments",
      "text" : "The algorithm is implemented for three specific cases. Note that the models discussed do not satisfy the Gaussian process model assumption of Storvik (2002)."
    }, {
      "heading" : "5.1. Single parameter nonlinear model",
      "text" : "Consider the following model with sinusoid transition dynamics (SIN):\nxt = sin(θxt−1) + vt, vt ∼ N(0, σ2) yt = xt + wt, wt ∼ N(0, σ2obs) (13)\nwhere σ = 1, σobs = 0.1 and the Gaussian prior for parameter θ is N(0, 0.22). The observation sequence is generated by sampling from SIN with true parameter value θ = 0.7.\nFigure 3 shows how the Gibbs density p(θ | x0:t) shrinks with respect to time, hence verifying identifiability for this model. Notice that as T grows, the densities concentrate around the true parameter value.\nA Taylor approximation around θ = 0 has been applied to the transition function sin(θxt). Figure 4(a) shows the approximate densities for different polynomial orders for T = 1024. Notice that as the polynomial order increases, the approximate densities converge to the true density p(θ | x0:1024). The KL-divergence DKL(p || p̂) for different polynomial orders (N) and different data lengths (T) is illus-\ntrated in Figure 4(b). The results are consistent with the theory developed in Section 4.1.\nThe degeneracy of a bootstrap filter with N = 50000 particles can be seen from figure 5(a). The Liu– West approach with N = 50000 particles is shown in 5(b). The perturbation is θt = ρθt−1 + (1 − ρ)θ̄t−1+ √ 1− ρ2 std(θt−1)N(0, 1), where ρ = 0.9. Notice that even with N = 50000 particles and large perturbations, the Liu–West approach converges slowly compared to our method. Furthermore, for highdimensional spaces, tuning the perturbation parameter ρ for Liu–West becomes difficult.\nThe EPF has been implemented on this model with N = 1000 particles with a 7-th order Taylor approximation to the posterior. The time complexity is O(NT ). The mean and the standard deviation of the particles are shown in figure 5(c)."
    }, {
      "heading" : "5.2. Cauchy dynamical system",
      "text" : "We consider the following model.\nxt = axt−1 + Cauchy(0, γ) (14)\nyt = xt +N(0, σobs) (15)\nHere Cauchy is the Cauchy distribution centered at 0 and with shape parameter γ = 1. We use a = 0.7, σobs = 10, where the prior for the AR(1) parameter is N(0, 0.22). This model represents autoregressive time evolution with heavy-tailed noise. Such heavy-tailed noises are observed in network traffic data and clickstream data. The standard Cauchy distribution we use is\nfv(v; 0, 1) = 1\nπ(1 + v2) = exp\n( − log(π)− log(1 + v2) ) .\nWe approximate log(1 + v2) by v2 − v4/2 + v6/3 − v8/4 + . . . (the Taylor approximation at 0).\nFigure 6(a) shows the simulated hidden state and the observations (σobs = 10). Notice that the simulated process differs substantially from a standard AR(1) process due to the heavy-tailed noise. Storvik’s filter cannot handle this model since the necessary sufficient statistics do not exist.\nFigure 6(b) displays the mean value estimated by a bootstrap filter with N = 50000 particles. As before the bootstrap filter is unable to perform meaningful inference. Figure 6(c) shows the performance of the Liu–West filter with both N = 100 and N = 10000 particles. The Liu–West filter does not converge for N = 100 particles and converges slowly for N = 10000 particles. Figure 6(d) demonstrates the rapid convergence of the EPF for only N = 100 particles with 10th order approximation. The time complexity is O(NT ).\nOur empirical results confirm that the EPF proves useful for models with heavy-tailed stochastic perturbations."
    }, {
      "heading" : "5.3. Smooth Transition AR model",
      "text" : "The smooth transition AR (STAR) model is a smooth generalization of the self-exciting threshold autoregressive (SETAR) model, (van Dijk et al., 2002). It is generally expressed in the following form.\nxt = (a1xt−1 + a2xt−2 + · · ·+ apxt−p) [1−G(xt−d; γ, c)] + (b1xt−1 + b2xt−2 + · · ·+ bpxt−p) [G(xt−d; γ, c)] + t\nwhere t is i.i.d. Gaussian with mean zero and variance σ2 and G(·) is a nonlinear function of xt−d, where d > 0. We will use the logistic function\nG(yt−d; γ, c) = 1\n1 + exp (−γ(xt−d − c)) (16)\nFor high γ values, the logistic function converges to the indicator function, I(xt−d > c), forcing STAR to\nconverge to SETAR (SETAR corresponds to a switching linear–Gaussian system). We will use p = 1 = d, where a1 = 0.9 and b1 = 0.1 and σ = 1 (corresponding to two different AR(1) processes with high and low memory). We attempt to estimate parameters γ, c of the logistic function, which have true values γ = 1 and c = 3. Data (of length T = 1000) is generated from the model under fixed parameter values and with observation model yt = xt + wt, where wt is additive Gaussian noise with mean zero and standard deviation σobs = 0.1. Figure 7(a) shows the shrinkage of the Gibbs density p(γ, c | x0:T ), verifying identifiability.\nThe non-separable logistic term is approximated as\n1\n1 + exp (−γ(xt−1 − c)) ≈ 1 2 − 1 4 γ(c− xt−1) + 1 48 γ3(c− xt−1)3 + . . .\nFigure 7(b) displays the failure of the Liu–West filter for N = 50000 particles. Figure 7(c) shows the mean values for γ, c from EPF for only N = 100 particles with 9th order Taylor approximation. Sampling from the log-polynomial approximate density is done through the random-walk Metropolis–Hastings algo-\nrithm. For each particle path, at each time step t, the Metropolis–Hastings sampler is initialized from the parameter values at t − 1. The burn-in period is set to be 0, so only one MH step is taken per time step (i.e., if a proposed sample is more likely it is accepted, else it is rejected with a specific probability). The whole filter has time complexity O(NT )."
    }, {
      "heading" : "6. Conclusion",
      "text" : "Learning the parameters of temporal probability models remains a significant open problem for practical applications. We have proposed the extended parameter filter (EPF), a novel approximate inference algorithm that combines Gibbs sampling of parameters with computation of approximate sufficient statistics. The update time for EPF is independent of the length of the observation sequence. Moreover, the algorithm has provable error bounds and handles a wide variety of models. Our experiments confirm these properties and illustrate difficult cases on which EPF works well.\nOne limitation of our algorithm is the complexity of Taylor approximation for high-dimensional parameter vectors. We noted that, in some cases, the process can be decomposed into lower-dimensional subproblems. Automating this step would be beneficial."
    }, {
      "heading" : "A. Storvik’s filter as a Kalman filter",
      "text" : "Let us consider the following model.\nxt = Axt−1 + vt, vt ∼ N(0,Q) yt = Hxt + wt, wt ∼ N(0,R) (17)\nWe will call the MMSE estimate Kalman filter returns as xt|t = E[xt | y0:t] and the variance Pt|t = cov(xt | y0:t). Then the update for the conditional mean estimate is as follows.\nxt|t = Axt−1|t−1\n+ Pt|t−1H T (HPt|t−1H T + R)−1︸ ︷︷ ︸ Kt (yt −HAxt−1|t−1)\nwhere as for the estimation covariance\nPt|t−1 = APt−1|t−1A T + Q\nPt|t = (I−KtH)Pt|t−1 (18)\nMatching the terms above to the updates in equation 6, one will obtain a linear model for which the transition matrix is A = I, the observation matrix is H = Ft, the state noise covariance matrix is Q = 0, and the observation noise covariance matrix is R = Q"
    }, {
      "heading" : "B. Proof of theorem 1",
      "text" : "Let us assume that x ∈ Rd,θ ∈ Rp and fθ(·) : Rd → Rd is a vector valued function parameterized by θ. Moreover, due to the assumption of separability fθ(xt−1) = l(xt−1)\nTh(θ), where we assume that l(·) : Rd → Rm×d and h(·) : Rp → Rm and m is an arbitrary constant. The stochastic perturbance will have the logpolynomial density p(vt) ∝ exp(Λ1vt + vTt Λ2vt + . . . ) Let us analyze the case of p(vt) ∝ exp(Λ1vt+vTt Λ2vt), for mathematical simplicity.\nProof.\nlog p(θ | x0:T ) ∝ log p(θ) + T∑ t=1 log p(xt | xt−1, θ)\n∝ log p(θ) + T∑ t=1 Λ1 ( xt − l(xt−1)Th(θ) ) +\n( xt − l(xt−1)Th(θ) )T Λ2 ( xt − l(xt−1)Th(θ) ) ∝ log p(θ) +\n( T∑ t=1 −(Λ1 + 2xTt Λ2)l(xt−1)T )\n︸ ︷︷ ︸ S1\nh(θ)\n+ hT (θ) ( T∑ t=1 l(xt−1)Λ2l T (xt−1) ) ︸ ︷︷ ︸\nS2\nh(θ) + constants\nTherefore, sufficient statistics (S1 ∈ R1×m and S2 ∈ Rm×m) exist. The analysis can be generalized for higher-order terms in vt in similar fashion."
    }, {
      "heading" : "C. Proof of theorem 2",
      "text" : "Proposition 1. Let S(x) be a M + 1 times differentiable function and P (x) its order M Taylor approximation. Let I = (x − a, x + a) be an open interval around x. Let R(x) be the remainder function, so that S(x) = P (x) +R(x). Suppose there exists constant U such that\n∀y ∈ I, ∣∣∣f (k+1)(y)∣∣∣ ≤ U\nWe may then bound\n∀y ∈ I, |R(y)| ≤ U a M+1\n(M + 1)!\nWe define the following terms\n= U aM+1\n(M + 1)!\nZ = ∫ I exp(S(x))dx\nẐ = ∫ I exp(P (x))dx\nSince exp(·) is monotone and increasing and |S(x)− P (x)| ≤ , we can derive tight bounds relating Z and Ẑ.\nZ = ∫ I exp(S(x))dx ≤ ∫ I exp(P (x) + )dx\n= Ẑ exp( )\nZ = ∫ I exp(S(x))dx ≥ ∫ I exp(P (x)− )dx\n= Ẑ exp(− )\nProof. DKL(p||p̂) = ∫ I ln ( p(x) p̂(x) ) p(x)dx\n= ∫ I ( S(x)− P (x) + ln(Ẑ)− ln(Z) ) p(x)dx\n≤ ∫ I |S(x)− P (x)| p(x)dx\n+ ∫ I ∣∣∣ln(Ẑ)− ln(Z)∣∣∣ p(x)dx ≤ 2 ∝ a M+1\n(M + 1)! ≈ 1√\n2π(M + 1)!\n( ae\nM + 1 )M+1 where the last approximation follows from Stirling’s approximation. Therefore, DKL(p||p̂) → 0 as M → ∞."
    }, {
      "heading" : "D. Proof of theorem 3",
      "text" : "Proof. log p̂(θ | x0:T ) = log ( p(θ)\nT∏ k=0\np̂(xk|xk−1, θ) )\n= log p(θ) + T∑ k=0 log p̂(xk | xk−1, θ)\nWe can calculate the form of log p̂(xk | xk−1, θ) explicitly.\nlog p̂(xk | xk−1, θ) = logN (f̂(xk−1, θ), σ2) = − log(σ √ 2π)− (xk − f̂(xk−1, θ)) 2\n2σ2\n= − log(σ √ 2π)− x 2 k − 2xkf̂(xk−1, θ) + f̂(xk−1, θ)2\n2σ2\n= − log(σ √ 2π)− x 2 k 2σ2 − ∑M i=0 xkH i(xk−1)θ i σ2\n+\n∑2M i=0 J i xk−1 θi\n2σ2\nUsing this expansion, we calculate log p̂(θ | x0:T ) = log p(θ) + T∑ k=0 log p̂(xk | xk−1, θ)\n= log p(θ)− (T + 1) log(σ √ 2π)\n− 1 2σ2 ( T∑ k=0 x2k ) − T (θ)T η(x0, . . . , xT )\nwhere we expand T (θ)T η(x0, . . . , xT ) as in 3. The form for log p̂(θ | x0:T ) is in the exponential family."
    }, {
      "heading" : "E. Proof of theorem 4",
      "text" : "Proof. Assume that function f has bounded derivatives and bounded support I. Then the maximum error satisfies ∣∣∣fθ(xk−1)− f̂θ(xk−1)∣∣∣ ≤ k. It follows\nthat f̂θ(xk−1) 2 − fθ(xk−1)2 = − 2k − 2f̂θ(xk−1) k ≈ −2f̂θ(xk−1) k. Then the KL-divergence between the real posterior and the approximated posterior satisfies the following formula.\nDKL(pT ||p̂T ) (19)\n= ∫ Sθ ( 1 σ2 T∑ k=1 k(xk − f̂θ(xk−1)) ) pT (θ|x0:T )dθ\nMoreover, recall that as T →∞ the posterior shrinks to δ(θ− θ∗) by the assumption of identifiability. Then we can rewrite the KL-divergence as (assuming Taylor approximation centered around θc)\nlim T→∞\nDKL(pT ||p̂T ) (20)\n= 1\nσ2 lim T→∞ T∑ k=1 k ∫ Sθ (xk − f̂θ(xk−1))pT (θ|x0:T )dθ\n= 1\nσ2 lim T→∞ T∑ k=1\nk· (21)( xk −\nM∑ i=0 Hi(xk−1) ∫ Sθ (θ − θc)ip(θ|x0:T )dθ )\n= 1\nσ2 lim T→∞ T∑ k=1 k\n( xk −\nM∑ i=0 Hi(xk−1)(θ ∗ − θc)i\n)\nIf the center of the Taylor approximation θc is the true parameter value θ∗, we can show that\nlim T→∞\nDKL(pT ||p̂T ) = 1\nσ2 lim T→∞ T∑ k=1 k (xk − fθ∗(xk−1)))\n= 1\nσ2 lim T→∞ T∑ k=1 kvk = 0 (22)\nwhere the final statement follows from law of large numbers. Thus, as T →∞, the Taylor approximation of any order will converge to the true posterior given that θc = θ ∗. For an arbitrary center value θc,\nDKL(pT ||p̂T ) = 1\nσ2 T∑ k=1 k\n( xk −\nM∑ i=0 Hi(xk−1)(θ ∗ − θc)i ) (23)\nNotice that k ∝ 1(M+1)! (by our assumptions that f has bounded derivative and is supported on interval I) and Hi(·) ∝ 1M ! . The inner summation will be bounded since M ! > aM ,∀a ∈ R as M → ∞. Therefore, as M →∞, DKL(p||p̂)→ 0."
    } ],
    "references" : [ {
      "title" : "On-line parameter estimation in general state-space models",
      "author" : [ "C. Andrieu", "A. Doucet", "V. Tadic" ],
      "venue" : "In Proceedings of the 44th Conference on Decision and Control,",
      "citeRegEx" : "Andrieu et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Andrieu et al\\.",
      "year" : 2005
    }, {
      "title" : "Particle Markov chain Monte Carlo methods",
      "author" : [ "Christophe Andrieu", "Arnaud Doucet", "Roman Holenstein" ],
      "venue" : "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
      "citeRegEx" : "Andrieu et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Andrieu et al\\.",
      "year" : 2010
    }, {
      "title" : "A tutorial on particle filters for on-line non-linear/non-Gaussian Bayesian tracking",
      "author" : [ "Sanjeev Arulampalam", "Simon Maskell", "Neil Gordon", "Tim Clapp" ],
      "venue" : "IEEE Transactions on Signal Processing,",
      "citeRegEx" : "Arulampalam et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Arulampalam et al\\.",
      "year" : 2002
    }, {
      "title" : "Particle Learning and Smoothing",
      "author" : [ "Carlos M. Carvalho", "Michael S. Johannes", "Hedibert F. Lopes", "Nicholas G. Polson" ],
      "venue" : "Statistical Science,",
      "citeRegEx" : "Carvalho et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Carvalho et al\\.",
      "year" : 2010
    }, {
      "title" : "A tutorial on particle filtering and smoothing: fifteen years later",
      "author" : [ "Arnaud Doucet", "Adam M. Johansen" ],
      "venue" : "The Oxford Handbook of Nonlinear Filtering,",
      "citeRegEx" : "Doucet and Johansen.,? \\Q2011\\E",
      "shortCiteRegEx" : "Doucet and Johansen.",
      "year" : 2011
    }, {
      "title" : "The extended parameter filter",
      "author" : [ "Yusuf Erol", "Lei Li", "Bharath Ramsundar", "Stuart J. Russell" ],
      "venue" : "Technical Report UCB/EECS-2013-48, EECS Department,",
      "citeRegEx" : "Erol et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Erol et al\\.",
      "year" : 2013
    }, {
      "title" : "Following a moving target – Monte Carlo inference for dynamic bayesian models",
      "author" : [ "Walter R. Gilks", "Carlo Berzuini" ],
      "venue" : "Journal of the Royal Statistical Society. Series B (Statistical Methodology),",
      "citeRegEx" : "Gilks and Berzuini.,? \\Q2001\\E",
      "shortCiteRegEx" : "Gilks and Berzuini.",
      "year" : 2001
    }, {
      "title" : "A new approach to linear filtering and prediction problems",
      "author" : [ "Rudolf E. Kalman" ],
      "venue" : "Transactions of the ASME – Journal of Basic Engineering,",
      "citeRegEx" : "Kalman.,? \\Q1960\\E",
      "shortCiteRegEx" : "Kalman.",
      "year" : 1960
    }, {
      "title" : "Combined parameter and state estimation in simulation-based filtering",
      "author" : [ "Jane Liu", "Mike West" ],
      "venue" : "In Sequential Monte Carlo Methods in Practice",
      "citeRegEx" : "Liu and West.,? \\Q2001\\E",
      "shortCiteRegEx" : "Liu and West.",
      "year" : 2001
    }, {
      "title" : "Practical filtering with sequential parameter learning",
      "author" : [ "Nicholas G. Polson", "Jonathan R. Stroud", "Peter Müller" ],
      "venue" : "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
      "citeRegEx" : "Polson et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Polson et al\\.",
      "year" : 2008
    }, {
      "title" : "Monte Carlo Statistical Methods",
      "author" : [ "Christian P. Robert", "George Casella" ],
      "venue" : null,
      "citeRegEx" : "Robert and Casella.,? \\Q2005\\E",
      "shortCiteRegEx" : "Robert and Casella.",
      "year" : 2005
    }, {
      "title" : "Particle filters for state-space models with the presence of unknown static paramaters",
      "author" : [ "Geir Storvik" ],
      "venue" : "IEEE Transactions on Signal Processing,",
      "citeRegEx" : "Storvik.,? \\Q2002\\E",
      "shortCiteRegEx" : "Storvik.",
      "year" : 2002
    }, {
      "title" : "Smooth transition autoregressive models – a survey of recent developments",
      "author" : [ "Dick van Dijk", "Timo Tersvirta", "Philip Hans Franses" ],
      "venue" : "Econometric Reviews,",
      "citeRegEx" : "Dijk et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Dijk et al\\.",
      "year" : 2002
    }, {
      "title" : "An introduction to the Kalman filter",
      "author" : [ "Greg Welch", "Gary Bishop" ],
      "venue" : null,
      "citeRegEx" : "Welch and Bishop.,? \\Q1995\\E",
      "shortCiteRegEx" : "Welch and Bishop.",
      "year" : 1995
    } ],
    "referenceMentions" : [ {
      "referenceID" : 10,
      "context" : "Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant.",
      "startOffset" : 0,
      "endOffset" : 15
    }, {
      "referenceID" : 10,
      "context" : "Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant.",
      "startOffset" : 0,
      "endOffset" : 15
    }, {
      "referenceID" : 2,
      "context" : "quential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008).",
      "startOffset" : 72,
      "endOffset" : 125
    }, {
      "referenceID" : 8,
      "context" : "For example, the “artificial dynamics” approach (Liu and West, 2001) introduces a stochastic transition model for the parameter variables, allowing exploration of parameter space, but this may result in biased estimates.",
      "startOffset" : 48,
      "endOffset" : 68
    }, {
      "referenceID" : 0,
      "context" : "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution.",
      "startOffset" : 21,
      "endOffset" : 43
    }, {
      "referenceID" : 0,
      "context" : "quential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008). In the machine learning context, model parameters may be represented by static parameter variables that define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) converges to a delta function at the true value in the limit of infinitely many observations. Unfortunately, particle filters fail for such models: the algorithm samples parameter values for each particle at time t= 0, but these remain fixed; over time, the particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009); Carvalho et al.",
      "startOffset" : 73,
      "endOffset" : 1028
    }, {
      "referenceID" : 0,
      "context" : "quential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008). In the machine learning context, model parameters may be represented by static parameter variables that define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) converges to a delta function at the true value in the limit of infinitely many observations. Unfortunately, particle filters fail for such models: the algorithm samples parameter values for each particle at time t= 0, but these remain fixed; over time, the particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009); Carvalho et al. (2010) describe several algorithms that have been proposed to solve this degeneracy problem, but the issue remains open because known algorithms either suffer from bias or computational inefficiency.",
      "startOffset" : 73,
      "endOffset" : 1052
    }, {
      "referenceID" : 2,
      "context" : "Exact filtering is intractable except f r certain special c ses (linear–Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011).",
      "startOffset" : 233,
      "endOffset" : 286
    }, {
      "referenceID" : 4,
      "context" : "Exact filtering is intractable except f r certain special c ses (linear–Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011).",
      "startOffset" : 233,
      "endOffset" : 286
    }, {
      "referenceID" : 2,
      "context" : "Exact filtering is intractable except f r certain special c ses (linear–Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011). In the machine learning context, model parameters may be represented by static parameter variables tha define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) conv rges to a delta function at the true value in the li it of infinitely many observations. Unfortunately, particle filters fail for such models: the algorith samples p rameter values for each particle at time t= 0, but these remain fixed; over time, th particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009) and Carvalho et al.",
      "startOffset" : 234,
      "endOffset" : 1186
    }, {
      "referenceID" : 2,
      "context" : "Exact filtering is intractable except f r certain special c ses (linear–Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011). In the machine learning context, model parameters may be represented by static parameter variables tha define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) conv rges to a delta function at the true value in the li it of infinitely many observations. Unfortunately, particle filters fail for such models: the algorith samples p rameter values for each particle at time t= 0, but these remain fixed; over time, th particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009) and Carvalho et al. (2010) describe several algorithms that have been proposed to ar X iv :1 30 5.",
      "startOffset" : 234,
      "endOffset" : 1213
    }, {
      "referenceID" : 8,
      "context" : "For example, the “artificial dynamics” approach (Liu and West, 2001) introduces a stochastic transition model for the parameter variables, allowing exploration of the parameter space, but this may result in biased estimates.",
      "startOffset" : 48,
      "endOffset" : 68
    }, {
      "referenceID" : 0,
      "context" : "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution.",
      "startOffset" : 21,
      "endOffset" : 43
    }, {
      "referenceID" : 1,
      "context" : "The particle MCMC algorithm (Andrieu et al., 2010) converges to the true posterior, but requires computation growing with T , the length of the data sequence.",
      "startOffset" : 28,
      "endOffset" : 50
    }, {
      "referenceID" : 6,
      "context" : "The resample-move algorithm (Gilks and Berzuini, 2001) includes Gibbs sampling of parameter variables—that is, in Figure 1, P (θ | X1, .",
      "startOffset" : 28,
      "endOffset" : 54
    }, {
      "referenceID" : 0,
      "context" : "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution. The particle MCMC algorithm (Andrieu et al., 2010) converges to the true posterior, but requires computation growing with T , the length of the data sequence. The resample-move algorithm (Gilks and Berzuini, 2001) includes Gibbs sampling of parameter variables—that is, in Figure 1, P (θ | X1, . . . , XT ). This method requires O(T ) computation per sample, leading Gilks and Berzuini to propose a sampling rate proportional to 1/T to preserve constant-time updates. Storvik (2002) and Polson et al.",
      "startOffset" : 22,
      "endOffset" : 673
    }, {
      "referenceID" : 0,
      "context" : "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution. The particle MCMC algorithm (Andrieu et al., 2010) converges to the true posterior, but requires computation growing with T , the length of the data sequence. The resample-move algorithm (Gilks and Berzuini, 2001) includes Gibbs sampling of parameter variables—that is, in Figure 1, P (θ | X1, . . . , XT ). This method requires O(T ) computation per sample, leading Gilks and Berzuini to propose a sampling rate proportional to 1/T to preserve constant-time updates. Storvik (2002) and Polson et al. (2008) observe that a fixed-dimensional sufficient statistic (if one exists) for θ can be updated in constant time.",
      "startOffset" : 22,
      "endOffset" : 698
    }, {
      "referenceID" : 5,
      "context" : "All details of proofs are given in the appendix of the full version (Erol et al., 2013).",
      "startOffset" : 68,
      "endOffset" : 87
    }, {
      "referenceID" : 11,
      "context" : "To avoid the degeneracy problem, Storvik (2002) modifies the SIR algorithm by adding a Gibbs sampling step for θ conditioned on the state trajectory in each particle (see Algorithm 2).",
      "startOffset" : 33,
      "endOffset" : 48
    }, {
      "referenceID" : 7,
      "context" : "Matching terms with the standard KF update equations (Kalman, 1960), we find that the transition matrix for the KF is the identity matrix, the transition noise covariance matrix is the zero matrix, the observation matrix for the KF is Ft, and the observation noise covariance matrix is Q.",
      "startOffset" : 53,
      "endOffset" : 67
    }, {
      "referenceID" : 5,
      "context" : "See the supplementary material (Erol et al., 2013) for the derivation.",
      "startOffset" : 31,
      "endOffset" : 50
    }, {
      "referenceID" : 5,
      "context" : "The proof is straightforward by the Fisher–Neyman factorization theorem; more details are given in the supplementary material of the full version (Erol et al., 2013).",
      "startOffset" : 146,
      "endOffset" : 165
    }, {
      "referenceID" : 13,
      "context" : "EKF linearizes nonlinear transitions around the current estimates of the mean and covariance and uses Kalman filter updates for state estimation (Welch and Bishop, 1995).",
      "startOffset" : 145,
      "endOffset" : 169
    }, {
      "referenceID" : 10,
      "context" : "We suggest slice sampling (Neal, 2003) or the MetropolisHastings algorithm (Robert and Casella, 2005) for this purpose.",
      "startOffset" : 75,
      "endOffset" : 101
    }, {
      "referenceID" : 5,
      "context" : "The proof is given in (Erol et al., 2013).",
      "startOffset" : 22,
      "endOffset" : 41
    }, {
      "referenceID" : 5,
      "context" : "The proof is given in the supplementary material (Erol et al., 2013).",
      "startOffset" : 49,
      "endOffset" : 68
    }, {
      "referenceID" : 11,
      "context" : "Note that the models discussed do not satisfy the Gaussian process model assumption of Storvik (2002). 0 0.",
      "startOffset" : 87,
      "endOffset" : 102
    } ],
    "year" : 2013,
    "abstractText" : "The parameters of temporal models, such as dynamic Bayesian networks, may be modelled in a Bayesian context as static or atemporal variables that influence transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost that grows linearly with the length of the observation sequence. Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. In this paper, we demonstrate a connection between Storvik’s filter and a Kalman filter in parameter space and establish more general conditions under which Storvik’s filter works. Drawing on an analogy to the extended Kalman filter, we develop and analyze, both theoretically and experimentally, a Taylor approximation to the parameter posterior that allows Storvik’s method to be applied to a broader class of models. Our experiments on both synthetic examples and real applications show improvement over existing methods.",
    "creator" : "LaTeX with hyperref package"
  }
}