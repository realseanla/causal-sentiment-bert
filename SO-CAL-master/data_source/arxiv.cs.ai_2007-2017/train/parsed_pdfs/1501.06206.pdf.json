{
  "name" : "1501.06206.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Dynamics of Belief: Abduction, Horn Knowledge Base And Database Updates",
    "authors" : [ "Radhakrishnan Delhibabu" ],
    "emails" : [ "delhibabu@kbsg.rwth-aachen.de" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Keyword: AGM, Belief Revision, Belief Update, Horn Knowledge Base Dynamics, Kernel Change, Abduction, Hyber Tableaux, Magic Set, View update, Update Propagation."
    }, {
      "heading" : "1 Introduction",
      "text" : "We live in a constantly changing world, and consequently our beliefs have to be revised whenever there is new information. When we encounter a new piece of information that contradicts our current beliefs, we revise our beliefs rationally.\nar X\niv :1\n50 1.\n06 20\n6v 2\n[ cs\n.L O\n] 2\n7 Ja\nn 20\nIn the last three decades, the field of computer science has grown substantially beyond mere number crunching, and aspires to imitate rational thinking of human beings. A separate branch of study, artificial intelligence (AI) has evolved, with a number of researchers attempting to represent and manipulate knowledge in a computer system. Much work has been devoted to study the statics of the knowledge, i.e. representing and deducting from fixed knowledge, resulting in the development of expert systems. The field of logic programming, conceived in last seventies, has proved to be an important tool for handling static knowledge. However, such fixed Horn knowledge based systems can not imitate human thinking, unless they are accomplish revising their knowledge in the light of new information. As mentioned before, this revision has to take place rationally. This has led to a completely new line of research, the dynamics of belief.\nStudies in dynamics of belief are twofold: What does it mean to rationally revise a belief state? How can a belief state be represented in a computer and revised? The first question is more philosophical theory, and a lot of works have been carried out from epistemological perspective to formalize belief dynamics. The second question is computation oriented, and has been addressed differently from various perspectives of application. For example, a lot of algorithms have been proposed in logic programming to revise a Horn knowledge base or a database represented as a logic program; number of algorithms are there to carry out a view update in a rational database; algorithm to carry out diagnosis; algorithm for abduction reasoning and so on. We need the concept of ”change” in some form or other and thus need some axiomatic characterization to ensure that the algorithms are rational. Unfortunately, till this date, these two tracks remain separate, with minimal sharing of concepts and results. The primary purpose of the paper is to study these two developments and integrate them.\nWhen a new piece of information is added to a Horn knowledge base (Delgrande 2008 and Delgrande & Peppas 2011), (Papini 2000) it may become inconsistent. Revision means modifying the Horn knowledge base in order to maintain consistency, by keeping the new information and removing the least possible previous information. In our case, update means revision and contraction, that is insertion and deletion in database perspective. Previous works (Aravindan & Dung 1994), (Aravindan 1995) have explained connections between contraction and knowledge base dynamics. Our Horn knowledge base dynamics is defined in two parts: an immutable part (Horn formulae) and updatable part (literals) (for definition and properties see the works of Nebel 1998, Segerberg 1998, Hansson et al 2001 and Fermé & Hansson 2001). Knowledge bases have a set of integrity constraints. In the case of finite knowledge bases, it is sometimes hard to see how the update relations should be modified to accomplish certain Horn knowledge base updates. ."
    }, {
      "heading" : "2 Motivation",
      "text" : "In the general case of arbitrary formulae, the revision problem for knowledge bases is hard to solve. So we restrict the revision problem to Horn formulae. The connection between belief change and database change is an interesting one since so far the two communities have independently considered two problems that are very similar, and our aim is to bring out this connection.\nWe aim to bridge the gap between philosophical and database theory. In such a case, Hansson’s (Hansson 1997) kernel change is related to the abductive method. Aliseda’s (Aliseda 2006) book on abductive reasoning is one of our key motivation. Wrobel’s (Wrobel 1995) definition of first-order theory revision was helpful to frame our algorithm. On the other hand, we are dealing with the view update problem. Keller and Minker’s (Keller 1985 and Minker 1996) work is one the motivation for the view update problem. In Figure 1 understand the concept of view update problem in rational way. Figure show that foundation form Belief Revision theory, intermediate step handle to Horn knowledge base, this step very impairment that agent have background knowledge and he/she made decision with postulate may require to process next step. Target of the application is connect database updates via Horn knowledge base with abduction reasoning. All clear procedure shown in each section.\nFollowing example illustrates the motivation of the paper:\nExample 1. Consider a database with an (immutable) rule that a staff member is a person who is currently working in a research group under a chair. Additional (updatable) facts are that matthias and gerhard are group chairs, and\ndelhibabu and aravindan are staff members in group infor1. Our first integrity constraint (IC) is that each research group has only one chair ie. ∀x, y, z (y=z)← group chair(x,y) ∧ group chair(x,z). Second integrity constraint is that a person can be a chair for only one research group ie. ∀x, y, z (y=z)← group chair(y,x) ∧ group chair(z,x).\nImmutable part: staff chair(x,y)← staff group(x,z),group chair(z,y).\nUpdatable part: group chair(infor1,matthias)← group chair(infor2,gerhard)← staff group(delhibabu,infor1)← staff group(aravindan,infor1)←\nSuppose we want to update this database with the information, staff chair(aravindan,gerhard); From the immutable part, we can deduce that this can be achieved by asserting staff group(aravindan,z) ∧ group chair(z,gerhard)\nIf we are restricted to definite clauses, there are three plausible ways to do this: first case is, aravindan and gerhard belong to infor1, i.e, staff group(aravindan,infor1) ∧ group chair(info1,gerhard). We need to delete both base facts group - chair(infor1,matthias)← and group chair(infor2,gerhard)←, because our first IC as well as second IC would be violated otherwise. In order to change the view, we need to insert group chair(infor1,gerhard)← as a base fact. Assume that we have an algorithm that deletes the base facts staff group(delhibabu,infor1)← from the database. But, no rational person will agree with such an algorithm, because the fact staff group(delhibabu,infor1)← is not ”relevant” to the view atom.\nSecond case, aravindan and gerhard belong to infor2, that is staff group(aravindan,infor2) ∧ group chair(infor2,gerhard). Simply, insert the new fact staff group(aravindan,infor2)← to change the view. Suppose an algorithm deletes the base facts staff group(aravindan,infor1)← from the database, then it can not be ”rational” since these facts are not ”relevant” to the view atom.\nThird case, aravindan and gerhard belong to infor3 (free assignment of the group value), that is staff group(aravindan,infor3) ∧ group chair(info3,gerhard). Suppose, we insert new base fact group chair(infor3,gerhard) ←, our second IC does not follow. Suppose an algorithm inserts the new base fact staff group(aravindan,infor2)← or staff group(aravindan,infor1)← is deleted, then it can not be ”rational”.\nThe above example highlights the need for some kind of ”relevance policy” to be adopted when a view atom is to be inserted to a deductive database. How many such axioms and policies do we need to characterize a ”good” view update? When are we sure that our algorithm for view update is ”rational”? Clearly, there is a need for an axiomatic characterization of view updates. By axiomatic characterization, we mean explicitly listing all the rationality axioms that are to be satisfied by any algorithm for view update.\nThe basic idea in (Behrend & Manthey 2008), (Aravindan & Baumgartner 1997) is to employ the model generation property of hyper tableaux and magic set to generate models, and read off diagnosis from them. One specific feature\nof this diagnosis algorithm is the use of semantics (by transforming the system description and the observation using an initial model of the correctly working system) in guiding the search for a diagnosis. This semantical guidance by program transformation turns out to be useful for database updates as well. More specifically we use a (least) Herbrand model of the given database to transform it along with the update request into a logic program in such a way that the models of this transformed program stand for possible updates.\nWe discuss two ways of transforming the given database together with the view update (insert and delete) request into a logic program resulting in two variants of view update algorithms. In the first variant, a simple and straightforward transformation is employed. Unfortunately, not all models of the transformed program represent a rational update using this approach. The second variant of the algorithm uses the least Herbrand model of the given database for the transformation. In fact what we referred to as offline preprocessing before is exactly this computation of the least Herbrand model. This variant is very meaningful in applications where views are materialized for efficient query answering. The advantage of using the least Herbrand model for the transformation is that all models of the transformed logic program (not just the minimal ones) stand for a rational update.\nWhen dealing with the revision of a Horn knowledge base (both insertions and deletions), there are other ways to change a Horn knowledge base and it has to be performed automatically also (Fermé 1992 and Rodrigues& Benevidas 1994). Considering the information, change is precious and must be preserved as much as possible. The principle of minimal change (Gärdenfors 1998, Dalal 1988 and Herzig & Rifi 1999), (Schulte 1999) can provide a reasonable strategy. On the other hand, practical implementations have to handle contradictory, uncertain, or imprecise information, so several problems can arise: how to define efficient change in the style of Carlos Alchourrón, Peter Gärdenfors, and David Makinson (AGM) (Alchourron et al. 1985b); what result has to be chosen (Lakemeyer 1995), (Lobo & Trajcevski 1997), (Nayak et al. 2006); and finally, according to a practical point of view, what computational model to explore for the Horn knowledge base revision has to be provided?\nThe rest of the paper is organized as follows: First we start with preliminaries in Section 3. In Section 4, we give a quick overview of belief changes and belief update. In Section 5, we introduce knowledge base dynamics along with the concept of generalized revision, and revision operator for knowledge base. Section 6 studies the relationship between knowledge base dynamics and abduction and shows how abductive procedures could be used to realize revision. In Section 7, we give a quick overview of belief update versus knowledge base update. In Section 8, we discuss an important application of knowledge base dynamics in providing an axiomatic characterization for insertion view atoms to databases; and nature of view update problem for incomplete to complete information shown. We give a quick overview of belief update versus database update in Section 9. In Section 10, we provide an abductive framework for Horn knowledge base dynamics in first order version. In Section 11, we give brief overview\nof related works. In Section 12, we draw conclusions with a summary of our contribution and indicate future directions of our investigation."
    }, {
      "heading" : "3 Preliminaries",
      "text" : "We consider a propositional language LP defined from a finite set of propositional variables P and the standard connectives. We use a, b, x, y, ...ϕ, φ, ψ, ... for propositional formulae. Sets of formulae are denoted by upper case Roman letters A,B, F,K, ..... A literal is an atom (positive literal), or a negation of an atom (negative literal).\nFor any formula ϕ, we write E(ϕ) to mean the set of the elementary letters that occur in ϕ. The same notation also applies to a set of formulae. For any set F of formulae, L(F ) represents the sub-language generated by E(F ), i.e. the set of all formulae ϕ with E(ϕ) ⊆ E(F ).\nHorn formulae are defined (Delgrande & Peppas 2011) as follows:\n1. Every a ∈ Φ where Φ ∈ LP ∪ {⊥} , a and ¬a are Horn clauses. 2. a← a1∧a2∧ ...∧an is a Horn clause, where n ≥ 0 and a, ai ∈ Φ (1 ≤ i ≤ n). 3. Every Horn clause is a Horn formula, a is called head and ai is body of the\nHorn formula. 4. If ϕ and ψ are Horn formulae, so is ϕ ∧ ψ.\nA definite Horn clause is a finite set of literals (atoms) that contains exactly one positive literal which is called the head of the clause. The set of negative literals of this definite Horn clause is called the body of the clause. A Horn clause is non-recursive, if the head literal does not occur in its body. We usually denote a Horn clause as head←body. Let LH be the set of all Horn formulae with respect to LP . A formula φ is a syntactic consequence within LP of a set Γ of formulas if there is a formal proof in LP of φ from the set Γ `LP φ.\nA Horn logic with stratified negation (Jackson & Schulte 2008) is similar to a set of Horn formulae. An immutable part is a function-free clause of the form a ← a1 ∧ a2 ∧ ... ∧ an, with n ≥ 1 where a is an atom denoting the immutable part’s head and a1 ∧ a2 ∧ ... ∧ an are literals. i.e. positive or negative atoms, representing the body of the Horn clauses.\nFormally, a finite Horn knowledge base KB (Horn or Horn logic with stratified negation) is defined as a finite set of formulae from language LH, and divided into three parts: an immutable theory KBI is a Horn formula (head←body), which is the fixed part of the knowledge; updatable theory KBU is a Horn clause (head←); and integrity constraint KBIC representing a set of clauses (Horn logic with stratified negation) (←body).\nDefinition 1 (Horn Knowledge Base). A Horn knowledge base, KB is a finite set of Horn formulae from language LH, s.t KB = KBI ∪KBU ∪KBIC , KBI ∩KBU = ∅ and KBU ∩KBIC = ∅.\nHorn knowledge base change deals with situations in which an agent has to modify its beliefs about the world, usually due to new or previously unknown\nincoming information, also represented as formulae of the language. Common operations of interest in Horn knowledge base change are the expansion of an agent’s current Horn knowledge base KB by a given Horn clause ϕ (usually denoted as KB+ϕ), where the basic idea is to add regardless of the consequences, and the revision of its current beliefs by ϕ (denoted as KB * ϕ), where the intuition is to incorporate ϕ into the current beliefs in some way while ensuring consistency of the resulting theory at the same time. Perhaps the most basic operation in Horn knowledge base change, like belief change, is that of contraction AGM (Alchourron et al. 1985b), which is intended to represent situations in which an agent has to give up ϕ from its current stock of beliefs (denoted as KB-ϕ).\nDefinition 2 (AGM Contraction). Let KB be a Horn knowledge base, and α a belief that is present in KB. Then contraction of KB by α, denoted as KB−α, is a consistent belief set that ignore α\nDefinition 3 (Levi Identity). Let - be an AGM contraction operator for KB. A way to define a revision is by using Generalized Levi Identity:\nKB ∗ α = (KB − ¬α) ∪ α\nThen, the revision can be trivially achieved by expansion, and the axiomatic characterization could be straightforwardly obtained from the corresponding characterizations of the traditional models (Alchourron, CE et al 1985). The aim of our work is not to define revision from contraction, but rather to construct and axiomatically characterize revision operators in a direct way."
    }, {
      "heading" : "4 Belief Changes",
      "text" : "Working at an abstract philosophical level, the aim of belief dynamics is to formalize the rationality of change, without worrying much about the syntactic representation of belief. However, it is not possible to completely ignore belief representation, and works on belief dynamics assume as little necessary things as possible about the representation of the belief. In this Section based on Konieczny’s (Konieczny 2011) work, we recall the definition of the main belief change operators and the links between them. We focus on the classical case, where the belief represent use propositional logic. This is a very quick presentation of belief change theory. For a complete introduction the reader is referred to seminal books on belief revision ((Gärdenfors 1992 & 1998), (Hansson 1997a), (Rott 2001)) or the recent special issue of Journal of Philosophical Logic on the 25 Years of AGM Theory (Ferme & Hansson 2011).\nA belief base K is a finite set of propositional formulae. In order to simplify the notations we identify the base K with the formula. which is the conjunction of the formulae of K 1 1 There are two major interpretations of belief bases. One of them, supported by Dalal\n1998, uses belief bases as mere expressive devices; hence if Cn(B1) = Cn(B2) then\nBelief revision aims at changing the status of some beliefs in the base that are contradicted by a more reliable piece of information. Several principles are govern this revision operation:\n– First is the primacy of update principle: the new piece of information has to be accepted in the belief base after the revision. This is due to the hypothesis that the new piece of information is more reliable than the current beliefs 2 – Second is the principle of coherence: the new belief base after the revision should be a consistent belief base. Asking the beliefs to be consistent is a natural requirement if one wants to conduct reasoning tasks from her belief base – Third is the principle of minimal change: the new belief base after the revision should be as close as possible from the current belief base. This important principle aims at ensuring that no unnecessary information (noise) is added to the beliefs during the revision process, and that no unnecessary information is lost during the process: information/beliefs are usually costly to obtain, we do not want to throw them away without any serious reason.\nlet ψ and µ be two formulae denoting respectively the belief base, and a new piece of information. Then ψ ◦ µ is a formula representing the new belief base. An operator ◦ is an AGM belief revision operator if it satisfies the following properties.\nDefinition 4 (Belief revision).\n(R1) ψ ◦ µ implies µ. (R2) If ψ ∧ µ is satisfiable, then ψ ◦ µ ≡ ψ ∧ µ. (R3) If µ is satisfiable, then so is ψ ◦ µ. (R4) If ψ1 ≡ ψ2 and µ1 ≡ µ2, then ψ1 ◦ µ1 ≡ ψ2 ◦ µ2. (R5) (ψ ◦ µ) ∧ φ implies ψ ◦ (µ ∧ φ). (R6) If (ψ ◦ µ) ∧ φ is satisfiable, then ψ ◦ (µ ∧ φ) implies (ψ ◦ µ) ∧ φ.\nWhen one works with a finite propositional language the above postulates, proposed by Katsuno and Mendelzon (Katsuno, H & Mendelzon, AO. 1991b), are equivalent to AGM ((Alchourron et al 1985b) and (Gärdenfors 1998)) (R1) states that the new piece of information must be believed after the revision. (R2) says that when there is no conflict between the new piece of information and the current belief, the revision is just the conjunction. (R3) says that revision always a consistent belief base, unless the new piece of information is not consistent. (R4) is an irrelevance of syntax condition, it states that logically equivalent bases\nB1 and B2 represent the same belief state and yield the same outcome under all operations of change. The other, more common approach treats inclusion in the belief base as epistemically significant. The belief base contains those sentences that have an epistemic standing of their own (Ferme 2011) 2 If this is not the case one should use a non-prioritized revision operator (Hansson 1997b)\nmust lead to the same result. (R5) and (R6) give conditions on the revision by a conjunction.\nAGM also defined contraction operators, that aim to remove some piece of information from the beliefs of the agent. These contraction operators are closely related to revision operators, since each contraction operator can be used to define a revision operator, through the Levy identity and conversely each revision operator can be used to define a contraction operator through the Harper identity ((Alchourron et al 1985b) and (Gärdenfors 1998)). So one can study indifferently revision or contraction operators. So we focus on revision here.\nSeveral representation theorems, that give constructive ways to define AGM revision/ contraction operators, have been proposed, such as partial meet contraction/revision (Alchourron et al 1985b), epistemic entrenchments (Gärdenfors 1992) and (Gärdenfors & Makinson 1988), safe contraction (Alchourron et al 1985a), etc. In (Katsuno & Mendelzon 1991b and 1992) (Benferhat et al. 2005), Katsuno and Mendelzon give a representation theorem, showing that each revision operator corresponds to a faithful assignment, that associates to each base a plausibility preorder on interpretations (this idea can be traced back to Grove systems of spheres (Grove 1988)).\nAssume a total pre-order ≤ψ on W (set of possible world). That is to say, KB = min(W,≤ψ). As usual we take ≤ψ to be an ordering of plausibility on the worlds, with worlds lower down in the ordering seen as more plausible. In what follows 'ψ will always denote the symmetric closure of ≤ψ, i.e., W1 'ψ W2 iff both W1 ≤ψ W2 and W2 ≤ψ W1.\nDefinition 5 ((Konieczny 2011)). A faithful assignment is a function mapping each base ψ to a pre-order ≤ψ over interpretations such that\n1. if ω |= ψ and ω′ |= ψ, then ω 'ψ ω′ 2. if ω |= ψ and ω′ 6|= ψ, then ω <ψ ω′ 3. if ψ ≡ ψ′, then ≤ψ=≤ψ′\nTheorem 1 ((Katsuno & Mendelzon 1991b and 1991b)). An operator ◦ is an AGM revision operator (i.e. it satisfies (R1)-(R6)) if and only if there exists a faithful assignment that maps each base ψ to a total pre-order ≤ψ such that mod(ψ ◦ µ)= min(mod(µ),≤ψ).\nProof. Follows from the definition 5 and the result of Konieczny 2011.\nOne of the main problems of this characterization of belief revision is that it does not constrain the operators enough for ensuring a good behavior when we do iteratively several revisions. So one needs to add more postulates and to represent the beliefs of the agent with a more complex structure than a simple belief base. In (Darwiche & Pearl 1997) Darwiche and Pearl proposed a convincing extension of AGM revision. This proposal have improved by an additional condition in ((Booth & Meyer 2006) and (Jin & Thielscher 2007), (Konieczny, et al. 2010) and (Konieczny & Pino Prez 2008)) define improvement operators that are a generalization of iterated revision operators.\nWhereas belief revision should be used to improve the beliefs by incorporating more reliable pieces of evidence, belief update operators aim at maintaining the belief base up-to-date, by allowing modifications of the base according to a reported change in the world. This distinction between revision and update was made clear in Katsuno & Mendelzon 1991 and 1992, where Katsuno & Mendelzon 1991 proposed postulates for belief update.\nDefinition 6 (Belief Update). An operator is a (partial) update operator if it satisfied the properties (U1)(U8). It is a total update operator if it satisfies the property (U1)-(U5),(U8),(U9).\n(U1) ψ µ implies µ. (U2) ifψ implies µ, then ψ µ ≡ ψ (U3) ifψ not implies ⊥ and µ not implies ⊥ then ψ µ not implies ⊥ (U4) If ψ1 ≡ ψ2 and µ1 ≡ µ2, then ψ1 µ1 ≡ ψ2 µ2. (U5) If (ψ µ) ∧ φ implies ψ (µ ∧ φ) (U6) If (ψ µ1) implies µ2 and (ψ µ2) implies µ2 then ψ µ1 ≡ ψ µ2 (U7) If ψ is a complete formula, then (ψ µ1) ∧ (ψ µ2) implies ψ (µ1 ∨ µ2) (U8) (ψ1 ∨ ψ2) µ ≡ (ψ1 µ) ∨ (ψ2 µ) (U9) If ψ is a complete formula and (ψ µ) ∧ ψ not implies ⊥ then ψ (µ ∧ ψ)\nimplies (ψ µ) ∧ ψ\nMost of these postulates are close to the ones of revision. The main differences lie in postulate (U2) that is much weaker than (R2): conversely to revision, even if the new piece of information is consistent with the belief base, the result is generally not simply the conjunction. This illustrates the fact that revision can be seen as a selection process of the most plausible worlds of the current beliefs with respect to the new piece information, whereas update is a transition process: each world of the current beliefs have to be translated to the closest world allowed by the new piece of information. This world-by-world treatment is expressed by postulate (U8).\nAs for revision, there is a representation theorem in terms of faithful assignment.\nDefinition 7 ([25]). A faithful assignment is a function mapping each interpretation ω to a pre-order ≤ω over interpretations such that if ω , ω′, then ω <ω ω ′\nTheorem 2. An update operator satisfies (U1)-(U8) if and only if there exists a faithful assignment that maps each interpretation ω to a partial pre-order ≤ω such that mod(ψ µ)= ⋃ ω|=ψ min(mod(µ),≤ω).\nProof. Follows from the observation and the result of Konieczny 2011.\nBut there is also a second theorem corresponding to total pre-orders.\nTheorem 3. An update operator satisfies (U1)-(U5), (U8) and (U9) if and only if there exists a faithful assignment that maps each interpretation ω to a total preorder ≤ω such that mod(ψ µ)= ⋃ ω|=ψ min(mod(µ),≤ω).\nProof. Follows from the observation and the result of Konieczny 2011.\nDefinition 8 ([3]). Let M=(W.w) be a K-model and µ a formula. A k-model M ′ = (W ′, w′) is called a possible resulting k-model after updating M with µ if and only if the following conditions hold:\n1. M’|= µ; 2. there does not exist another k-model M ′′ = (W ′′, w′′) such that M ′′ |= µ and\nM ′′ <M M ′.\nThe set of all possible resulting k-models after updating M with µ as Res(M,µ).\nTheorem 4. Knowledge update operator defined in definition 8 satisfies (U1)(U9).\nProof. Follows from the definition 8 and the result of Baral & Zhang 2005.\nNote 1. Horn knowledge base is a subset of belief base, KB ⊆ B, so everything that follows for belief base, also follows for Horn Knowledge base."
    }, {
      "heading" : "5 Horn Knowledge base dynamics",
      "text" : "In the AGM framework, a belief set is represented by a deductively closed set of propositional formulae. While such sets are infinite, they can’t always be finitely representable. However, working with deductively closed, infinite belief sets is not very attractive from a computational point of view. The AGM approach to belief dynamics is very attractive in its capture the rationality of change, but it is not always easy to implement either Horn formula based partial meet revision or generalized kernel revision. In artificial intelligence and database applications, what is required is to represent the knowledge using a finite Horn knowledge base. Further, a certain part of the knowledge is treated as immutable and should not be changed.\nAGM (Alchourron et al. 1985b) proposed a formal framework in which revision is interpreted as belief change. In this section, we focus on the Horn knowledge base revision and propose new rationality postulates that are adopted from AGM postulates for revision.\nDefinition 9. Let KB be a Horn knowledge base with an immutable part KBI . Let α and β be any two Horn clauses from LH. Then, α and β are said to be KB-equivalent iff the following condition is satisfied: ∀ set of Horn clauses E ⊆ LH and IC: KBI ∪ E ∪ IC ` α iff KBI ∪ E ∪ IC ` β.\nThese postulates stem from three main principles: the new item of information has to appear in the revised Horn knowledge base, the revised base has to be consistent and revision operation has to change the least possible beliefs. Now we consider the revision of a Horn clause α with respect to KB, written as KB ∗ α. The rationality postulates for revising α from KB can be formulated.\nDefinition 10 (Rationality postulates for Horn knowledge base revision).\n(KB*1) Closure: KB ∗ α is a Horn knowledge base. (KB*2) Weak Success: if α is consistent with KBI ∪KBIC then α ⊆ KB ∗ α. (KB*3.1) Inclusion: KB ∗ α ⊆ Cn(KB ∪ α). (KB*3.2) Immutable-inclusion: KBI ⊆ Cn(KB ∗ α). (KB*4.1) Vacuity 1: if α is inconsistent with KBI ∪KBIC then KB ∗α = KB. (KB*4.2) Vacuity 2: if KB ∪ α 0⊥ then KB ∗ α = KB ∪ α. (KB*5) Consistency: if α is consistent with KBI ∪KBIC then KB ∗ α con-\nsistent with KBI ∪KBIC . (KB*6) Preservation: If α and β are KB-equivalent, then KB ∗ α↔ KB ∗ β. (KB*7.1) Strong relevance: KB ∗ α ` α if KBI 0 ¬α (KB*7.2) Relevance: If β ∈ KB\\KB ∗ α, then there is a set KB′ such that\nKB ∗ α ⊆ KB′ ⊆ KB ∪ α, KB′ is consistent KBI ∪ KBIC with α, but KB′ ∪ {β} is inconsistent KBI ∪KBIC with α. (KB*7.3) Weak relevance: If β ∈ KB\\KB ∗α, then there is a set KB′ such that KB′ ⊆ KB ∪ α, KB′ is consistent KBI ∪KBIC with α, but KB′ ∪ {β} is inconsistent KBI ∪KBIC with α.\nTo revise KB by α, only those informations that are relevant to α in some sense can be added (as example in the introduction illustrates). (KB ∗ 7.1) is very strong axiom allowing only minimum changes, and certain rational revision can not be carried out. So, relaxing this condition (example with more details can be found in (Aravindan 1995, Hansson, SO 1997a, Ferme & Hansson 2011 and Falappa, MA et al 2012), this can be weakened to relevance. (KB ∗ 7.2) is relevance policy that still can not permit rational revisions, so we need to go next step. With (KB ∗ 7.3) the relevance axiom is further weakened and it is referred to as ”core-retainment”."
    }, {
      "heading" : "5.1 Revision function",
      "text" : "Suppose that we want to revise Horn knowledge base KB with respect to a single clause without using negation. We may construct revision using generalizing techniques from classical belief (base) revision (Falappa et al. 2012). Partial meet revision operator is syntax dependent and based on the foundational approach. In order to define it, first we need to define α-consistent-remainders.\nDefinition 11 (Remainder Set). Let a Horn knowledge base KB be a set of Horn formulae, where α is Horn clause. The α-consistent-remainders of KB, noted by KB ↓> α, is the set of KB′ such that:\n1. KB′ ⊆ KB, ensuring that KBI ⊆ KB′ and KBIC ⊆ KB′. 2. KB′ ∪ α is consistent with KBI ∪KBIC . 3. For any KB” such that KB′ ⊂ KB′′ ⊆ KB then KB′′ ∪ α is inconsistent\nwith KBI ∪KBIC .\nThat is, KB ↓> α is the set of maximal KB-subsets consistent with α.\nExample 2. Suppose that KB={KBI : p← a∧ b, p← a, q ← a∧ b; KBU : a←, b←; KBIC : ∅} and α= ← p. Then we have that:\n- KB ↓> α= {{p← a ∧ b}, {p← a},{← a}, {← b}}.\nRevision by a Horn clause is based on the concept of a α-consistent-remainders. In order to complete the construction, we must define a selection function that selects consistent remainders."
    }, {
      "heading" : "5.2 Principle of minimal change",
      "text" : "Let a Horn knowledge base KB be a set of Horn formulae and ψ is a Horn clause such that KB = {φ | ψ ` φ} is derived by φ. Now we consider the revision of a Horn clause α wrt KB, that is KB ∗ α.\nThe principle of minimal change (PMC) leads to the definition of orders between interpretations. Let I be the set of all the interpretations and Mod(ψ) be the set of models of ψ. A pre-order on I, denoted ≤ψ is linked with ψ. The relation <ψ is defined from ≤ψ as usual:\nI <ψ I ′ iff I ≤ψ I ′ and I ′ ψ I.\nThe pre-order ≤ψ is faithful to ψ if it verifies the following conditions:\n1) If I, I ′ ∈Mod(ψ) then I <ψ I ′ does not hold; 2) If I ∈Mod(ψ) and I ′ <Mod(ψ) then I <ψ I ′ holds; 3) if ψ ≡ φ then ≤ψ=≤φ.\nA minimal interpretation may thus be defined by: M⊆ I, the set of minimal interpretations inM according to ≤ψ is denoted Min(M,≤ψ). And I is minimal in M according to ≤ψ, if I ∈ M and there is no I ′ ∈M such that I ′ <ψ I.\nRevision operation * satisfies the postulates (KB*1) to (KB*6) and (KB*7.3) if and only if there exists a total pre-order ≤ψ such that:\nMod(ψ ∗ φ) = Min(Mod(φ),≤ψ).\nDefinition 12 (Selection function). Let KB be a Horn knowledge base. γ is a selection function for KB iff for all Horn clauses α\n1. If KB ↓> α , ∅ then ∅ , γ(KB ↓> α) ⊆ KB ↓> α. 2. If KB ↓> α = ∅ then γ(KB ↓> α) = {KB}\nObservation 1 Let KB, KB’ be an Horn knowledge base, KB’ be consistent. Suppose that α ∈ KB and α ∈ KB′. Then α ∈ X for all X ∈ KB ↓> KB′ and, therefore, α ∈ ⋂ (KB ↓> KB′).\nFrom the above observation and definition 11 it follows that all the Horn knowledge base of KB∩α are ”protected”, in the sense that they are included in the intersection of any collection of remainders. That is, a consolidated selection function selects a subset of the set KB ↓> α whose elements all contain the set KB ∩ α.\nDefinition 13 (Partial meet revision). Let KB be a Horn knowledge base with an immutable part KBI and γ a selection function for KB. The partial meet revision on KB that is generated by γ is the operator ∗γ such that, for all Horn clauses α:\nKB ∗γ α = { ∩γ(KB ↓> α) ∪ α if α is consistent with KBI ∪KBIC\nKB otherwise.\nAn operator * is a generalized revision (partial meet revision) on KB if and only if there is a selection function γ for KB such that for all Horn clauses α, KB*α = KB∗γα.\nExample 3. Given KB={KBI : p← a ∧ b, p← a, q ← a ∧ b; KBU : a←, b←; KBIC : ∅}, α= ← p and KB ↓> α= {{p ← a ∧ b}, {p ← a}, {← a}, {← b}}. We have two possible results for the selection function and its associated partial meet revision operator\nγ1(KB ↓> α) = {← p} and KB ∗γ1 α = {p← a ∧ b,← a,← b} γ2(KB ↓> α) = {← p} and KB ∗γ2 α = {p← a,← a}\nThe partial meet revision on KB that is generated by γ2 gives minimal interpretation with respect to PMC.\nTheorem 5. For every Horn knowledge base KB, ∗ is a generalized revision function iff it satisfies the postulates (KB*1) to (KB*6) and (KB*7.3).\nProof. (If part) * satisfies (KB*1) to (KB*6) and (KB*7.3). We must show that ∗ is a generalized revision. When KBI ` α, (KB*1) to (KB*6) and (KB*7.3) imply that KB ∗ α = KB is coinciding with generalized revision.\nWhen KBI ` ¬α, the required result follows from the two observations: 1. ∃KB′ ∈ KB ↓> α s.t.KB ∗ α ⊆ KB′ (when KB ∗ α = KB ∪ {α})\nLet γ be an selection function for KB and ∗γ be the generalized revision on KB that is generated by γ. Since * satisfies closure (KB*1), KB ∗γ α is KB contained in α. Also, satisfaction of weak success postulate (KB*2) ensures that α ⊆ KB∗γα. Every element of KB ↓> α is a inclusion maximal subset that does drive α, and so any subset of KB that does derive α must be contained in a member of KB ↓> α.\n2. ⋂\n(KB ↓> α) ⊆ KB ∗γ α (when KB ∗ α = KB ∪ {α}) Consider any β ∈ ⋂ (KB ↓> α). Assume that β < KB ∗ α. Since * satisfies weak relevance postulate (KB*7.3), it follows that there exists a set KB’ s.t. KB′ ⊆ KB ∪ α; KB′ is consistent with α; and KB′ ∪ {β} is inconsistent with α. But this contradicts the that β is present in every maximal subset of KB that does derive α. Hence β must not be in KB ∗γ α.\n(Only if part) Let KB ∗ α be a generalized revision of α for KB. We have to show that KB ∗ α satisfies the postulate (KB*1) to (KB*6) and (KB*7.3).\nLet γ be an selection function for KB and ∗γ be the generalized revision on KB that is generated by γ.\nClosure Since KB ∗γ α is a Horn knowledge base, this postulate is trivially shown. Weak Success Suppose that α is consistent. Then it is trivial by definition that α ⊆ KB ∗γ α. Inclusion Since every X ∈ KB ↓> α is such that X ⊆ KB then this postulate is trivially shown. Immutable-inclusion Since every X ∈ KB ↓> α is such that X ⊆ KBI then this postulate is trivially shown. Vacuity 1 Trivial by definition. Vacuity 2 If KB∪{α} is consistent then KB ↓> α = {{KB}}. Hence KB ∗γ α\n= KB ∪ {α}. Consistency Suppose that α is consistent. Then KB ↓> α ,= ∅ and by defini-\ntion, every X ∈ KB ↓> α is consistent with α. Therefore, the intersection of any subset of KB ↓> α is consistent with α. Finally, KB ∗γ α is consistent. Uniformity If α and β are KB-equivalent, then KB ↓> α = KB ↓> β Weak relevance Suppose that KB ↓> α , ∅. Let β ∈ KB. Then there is\nsome X ∈ KB ↓> α such that β < X. Therefore, there is some X such that β < X ⊆ KB, X ∪ α is consistent but X ∪ α ∪ {β} is inconsistent. Suppose that KB ↓> α = {∅} in which case α is inconsistent. By definition, KB ∗γ α = KB and weak relevance is vacuously satisfied."
    }, {
      "heading" : "5.3 Horn knowledge base revision with hitting set",
      "text" : "In this section, we show that Horn knowledge base revision has an interesting connection with kernel change via hitting set."
    }, {
      "heading" : "Kernel revision system",
      "text" : "To revise a Horn formula α from a Horn knowledge base KB, the idea of kernel revision is to keep at least one element from every inclusion-minimal subset of KB that derives α. Because of the immutable-inclusion postulate, no Horn formula from KBI can be deleted.\nDefinition 14 (Kernel sets). Let a Horn knowledge base KB be a set of Horn formulae, where α is Horn clause. The α-inconsistent kernel of KB, noted by KB⊥⊥α, is the set of KB′ such that:\n1. KB′ ⊆ KB ensuring that KBI ⊆ KB′ and KBIC ⊆ KB′. 2. KB′ ∪ α is inconsistent with KBI ∪KBIC . 3. For any KB” such that KB′′ ⊂ KB′ ⊆ KB then KB′′∪α is consistent with\nKBI ∪KBIC .\nThat is, given a consistent α, KB⊥⊥α is the set of minimal KB-subsets inconsistent with α.\nExample 4. Suppose that KB={KBI : p← a ∧ b, p← a, q ← a ∧ b; KBU : a← , b←; KBIC : ∅} and α= ← p. Then we have that:\nKB⊥⊥α= {{p← a ∧ b}, {p← a}}.\nRevision by a Horn clause is based on the concept of a α-inconsistent-kernels. In order to complete the construction, we must define a incision function that cuts in each inconsistent-kernel.\nDefinition 15 (Incision function). Let KB be a set of Horn formulae. σ is a incision function for KB if and only if, for all consistent Horn clauses α\n1. σ(KB⊥⊥α) ⊆ ⋃ KB⊥⊥α 2. If KB′ ∈ KB⊥⊥α then KB′ ∩ (σ(KB⊥⊥α)) , 0\nDefinition 16 (Hitting set). A hitting set H for KB⊥⊥α is defined as a set s.t. (i) H ⊆ ⋃ (KB⊥⊥α), (ii) H∩KBI is empty and (iii) ∀X ∈ KB⊥⊥α, X , ∅ and X ∩KBU is not empty, then X ∩H , ∅.\nA hitting set is said to be maximal when H consists of all updatable statements from ⋃ (KB⊥⊥α) and minimal if no proper subset of H is a hitting set for KB⊥⊥α.\nObservation 2 Let KB, KB’ be an Horn knowledge base, KB’ be consistent. Suppose that α ∈ KB and α ∈ KB′. Then α < ⋃ (KB⊥⊥KB′) and, therefore,\nKB′ ∩ ⋃ (KB⊥⊥KB′) = 0\nFrom the above observation and definition 15 it follows that all the Horn knowledge base of α are ”protected”, in the sense that they can not be considered for removing by the consolidated incision function. That is, a consolidated incision function selects among the sentences of KB\\α that make KB ∪ α inconsistent.\nDefinition 17 (Generalized Kernel revision). An incision function for KB is a function s.t. for all α, σ(KB⊥⊥α) is a hitting set for KB⊥⊥α. Generalized kernel revision on KB that is generated by σ is the operator ∗σ such that, for all Horn clauses α:\nKB ∗σ α = {\n(KB\\σ(KB⊥⊥α) ∪ α if α is consistent KBI ∪KBIC KB otherwise.\nAn operator ∗ is a generalized kernel revision for KB if and only if there is an incision function σ for KB such that for all Horn clauses α, KB ∗α = KB ∗σ α.\nFrom the definition of hitting set, it is clear that when KB ` ¬α, α is the hitting set of KB⊥⊥α. On the other hand, when KBI ` α, the definition ensures that only updatable elements are inserted, and α does follow from the revision. Thus, weak success (KB*2), immutable-inclusion (KB*3.2) and vacuity (KB*4.1) are satisfied by generalized kernel revision of α from KB.\nExample 5. Given KB={KBI : p ← a ∧ b, p ← a, q ← a ∧ b; KBU : a ←, b ← ; KBIC : ∅ }, α= ← p and KB⊥⊥α = {{p ← a ∧ b}, {p ← a}}. We have two possible results for the incision function and its associated kernel revision operator:\nσ1(KB⊥⊥α) = {p← a ∧ b} and KB ∗σ1 α = {{← a}, {← b}}, σ2(KB⊥⊥α) = {p← a} and KB ∗σ2 α = {{← a}}.\nIncision function σ2 produces minimal hitting set for KB⊥⊥α.\nTheorem 6. For every Horn knowledge base KB, ∗σ is a generalized kernel revision function iff it satisfies the postulates (KB*1) to (KB*6) and (KB*7.3).\nProof. (If part) * satisfies (KB*1) to (KB*6) and (KB*7.3). We must show that ∗ is a generalized kernel revision. Let σ be a incision function and α Horn formula. When KBI ` α, (KB*1) to (KB*6) and (KB*7.3) imply that KB ∗ α = KB coincides with generalized revision and follow PMC.\nWhen KBI ` ¬α, the required result follows from the two observations:\n1. ∃KB′ ∈ KB⊥⊥α s.t.KB ∗ α ⊆ KB′ (when KBI ` α) Let σ be an incision function for KB and ∗σ be the generalized revision on KB that is generated by σ. Since * satisfies closure (KB*1), KB ∗σ α is KB contained in α. Also, satisfaction of weak success postulate (KB*2) ensures that α ⊆ KB ∗σ α. Every element of KB⊥⊥α is a inclusion minimal subset that does derive α, and so any subset of KB that does derive α must be contained in a member of KB⊥⊥α.\n2. ⋂\n(KB⊥⊥α) ⊆ KB ∗σ α (when KBI ` α) Consider any β ∈ ⋂ (KB⊥⊥α). Assume that β < KB ∗ α. Since * satisfies weak relevance postulate (KB*7.3), it follows that there exists a set KB’ s.t. KB′ ⊆ KB ∪ α; KB′ is a consistent with α; and KB′ ∪ {β} is inconsistent with α. But this contradicts that β is present in every minimal subset of KB that does derive α. Hence β must not be in KB ∗σ α.\n(Only if part) Let KB ∗ α be a generalized revision of α for KB. We have to show that KB ∗ α satisfies the postulate (KB*1) to (KB*6) and (KB*7.3).\nLet σ be an incision function for KB and ∗σ be the generalized revision on KB that is generated by σ.\nClosure Since KB ∗σ α is a Horn knowledge base, this postulate is trivially shown. Weak Success Suppose that α is consistent. Then it is trivial by definition that α ⊆ KB ∗σ α. Inclusion Trivial by definition. Immutable-inclusion Since every X ∈ KB⊥⊥α is such that X ⊆ KBI then\nthis postulate is trivially shown. Vacuity 1 Trivial by definition.\nVacuity 2 If KB ∪{α} is consistent then KB⊥⊥α = {{KB}}. Hence KB ∗σ α = KB ∪ {α}. Consistency Suppose that α is consistent. Then KB⊥⊥α ,= ∅ and by definition, every X ∈ KB⊥⊥α is consistent with α. Therefore, the intersection of any subset of KB⊥⊥α is consistent with α. Finally, KB ∗σ α is consistent. Uniformity If α and β are KB-equivalent, then KB⊥⊥α = KB⊥⊥β Weak relevance Let β ∈ KB and β < KB ∗σ α. Then KB ∗σ α , KB and,\nfrom the definition of ∗σ,it follows that:\nKB ∗σ α=(KB\\σ(KB⊥⊥α)) ∪ α\nTherefore, from β < (KB\\σ(KB⊥⊥α)) ∪ α and β ∈ KB, we can conclude that β ∈ σ(KB⊥⊥α). By definition σ(KB⊥⊥α) ⊆ ⋃ KB⊥⊥α, and it follows that there is some X ∈ KB⊥⊥α such that β ∈ X. X is a minimal KB-subset inconsistent with α. Let Y = X\\{β}. Then Y is such that Y ⊂ X ⊆ KB ⊆ KB ∪ α. Y is consistent with α but Y ∪ {β} is consistent with α.\nFrom the Theorem 5 and 6, it immediately follows that a revision operation on a Horn knowledge base is a generalized kernel revision iff it is a generalized revision. The following theorem formalizes this with additional insights into the relationship between kernel and generalized revisions.\nTheorem 7.\n1. A revision operation over a Horn knowledge base KB is a generalized kernel revision over KB iff it is a generalized revision over KB. 2. When the incision function σ is minimal, i.e. the hitting set defined by σ is inclusion-minimal, then the generalized kernel revision defined by σ is a partial meet revision of α from KB. 3. When the incision function σ is maximal, i.e. σ(KB⊥⊥α) consists of all updatable statements from ⋃ (KB⊥⊥α), then the kernel contraction defined\nby σ is the minimal generalized revision of α from KB.\nProof. Follows from the Definition 16, Theorem 5 and 6"
    }, {
      "heading" : "6 Knowledge base dynamics and abduction",
      "text" : "In this Section, we study the relationship between Horn knowledge base dynamics, discussed in the previous Section, and abduction that was introduced by the philosopher Peirce (see Aliseda 2006, Boutilier & Beche 1995 and Pagnucco 1996). We show how an abduction grammar could be used to realize revision with an immutability condition. A special subset of literals (atoms) of language LH, abducibles Ab, are designated for abductive reasoning. Our work is based on atoms (literals), so we combine Christiansen and Dahl (Christiansen & Dahl 2009) grammars approach. Simply, we want to compute abducibles for Horn knowledge base (Horn or Horn logic with stratified negation).\nExample 6. Consider a Horn logic with stratified negation knowledge base KB with immutable part KBI , updatable part KBU and integrity constraint KBIC .\nKBI : flies(x)← bird(x), not ab(x), KBU :bird(tweety)← KBIC : ∅ ab(x)← broken wing(x) bird(opus)←\nbroken wing(tweety)←\nIf we observe that tweety flies, there is a good reason to assume that the wound has already healed. Then, removing the fact broken wing(tweety) from the KB explains the observation flies(tweety). On the other hand, suppose that we later notice that opus does not fly anymore. Since flies(opus) is entailed by KBI , we now have to revise the Horn knowledge base to block the derivation of flies(opus) by assuming, for instance, broken wing(opus). In nonmonotonic theories, deletion of formulae may introduce new formulae, thus positive (∆+) and negative (∆−) explanations play a complementary role in accounting for an observation in nonmonotonic theories. (more explanation in Sakama & Inoue 2003)\nDefinition 18 (Abductive grammar). A abductive grammar Γ is a 6-tuple 〈N,T, IC, KB,R, S〉 where:\n- N are nonterminal symbols in the immutable part (KBI). - T is a set of terminal symbols in the updatable part (KBU ). - IC is the set of integrity constraints for the Horn knowledge base (KBIC). - KB is the Horn knowledge base which consists of KB = KBI∪KBU∪KBIC . - R is a set of rules, R ⊆ KB. - S is the revision of literals (atoms), called the start symbol.\nExample 7. Consider a Horn knowledge base KB (with immutable part KBI , updatable part KBU and integrity constraint KBIC) and a Horn clause α (p is α) be revise.\nKBI : p← q ∧ a KBU : a← KBIC :← b p← r ∧ b r ← q ← c ∧ d r ← e ∧ f p← b\nKB be a Horn knowledge base, represented by the grammar (Γ = 〈N,T,KB,R, S〉) as follows:\nN={p} T={a,b,c,d,e,f,q,r} IC={b} KB=KBI ∪KBU ∪KBIC R={p← q, a; p← r, b; q ← c, d; r ← e, f ; p← b; a; r}\nS={p}\nDefinition 19 (Constraint system). A constraint system for abduction is a pair 〈KBAb, KBBG〉, where KBAb(∆) is a set of propositions (abducibles) and KBBG a background Horn knowledge base.\nNote 2. In the sequel, without any loss of generality, we assume that KBI is a set of rules and KBU is a set of abducibles from Horn knowledge base perspective. With respect to the considered grammars, KBBG is a set all Horn formulae from R and KBAb is set of abducibles from T.\nNote 3. Given a Horn knowledge base KB and a Horn clause α, the problem of abduction is to explain α in terms of an abduction, i.e. to generate a set of abducibles KBAb, ∆ s.t. KBBG ∪∆ ` α.\nDefinition 20 (Minimal abductive explanation). Let KB be a Horn knowledge base and α an observation to be explained. Then, for a set of abducibles (KBAb), ∆ is said to be an abductive explanation with respect to KBBG iff KBBG ∪ ∆ ` α. ∆ is said to be minimal with respect to KBBG iff no proper subset of ∆ is an abductive explanation for α, i.e. @∆′ s.t. KBBG ∪∆′ ` α.\nSince an incision function is adding and removing only updatable elements from each member of the kernel set, to compute a generalized revision of α from KB, we need to compute only the abduction in every α-kernel of KB. So, it is now necessary to characterize precisely the abducibles present in every α-kernel of KB. The notion of minimal abductive explanation is not enough to capture this, and we introduce locally minimal and KB-closed abductive explanations explanations.\nDefinition 21 (Local minimal abductive explanations). Let KBBG′ be a subset of KBBG, s.t ∆ is a minimal abductive explanation of α with respect to KBBG′ (for some ∆). Then ∆ is called local minimal for α with respect to KBBG.\nExample 8. From example 7, suppose {p ← q ∧ a, p ← a}, where a and f are abducibles in the grammar system R. Clearly, ∆1 = {a} is the only minimal abductive explanation for p with respect to R. ∆2 = {a, q} is an abductive explanation for p with respect to R, but not a minimal one. However, ∆2 is a locally minimal abductive explanation for p with respect to R, since it is a minimal explanation for p with respect to {p← q ∧ a} which is a subset of R.\nThe concept of locally minimal abductive explanation is computationally attractive, since minimal abductive explanation is more expensive to compute (Aravindan 1995). To find a minimal admissible and denial literal (atom) from KBAb that is positive and negative literal (atom) from KBAb, we need to introduce a constraint system (C) with integrity constraint (IC).\nDefinition 22 (Constraint abduction system). A constrained abductive grammar is a pair 〈Γ,C〉, where Γ is an abductive grammar and C a constraint system for abduction, Γ=〈N,T,R, S〉 and C=〈KBBG,KBAb, IC〉.\nGiven a constrained abductive grammar 〈Γ,C〉 as above, the constrained abductive recognition problem for τ ∈ T ∗ is the problem of finding an admissible and denial knowledge base (Horn knowledge base contained set of positive and negative literal (atoms)) from KBAb and such that τ ∈ LP (ΓKBAb) where LP (ΓKBAb) is propositional language over abducibles in Γ , where ΓKBAb = 〈N,T,KBBG ∪KBAb, R, S〉. In this case, KBAb is called a constrained (abductive) system of τ . Such that KBAb is minimal whenever no proper subset of it is in τ given 〈Γ,C〉.\nExample 9. We extend example 7, in order to show that C is constraint system C, with C =〈KBBG,KBAb, IC〉\nKBBG = {p← q, a; p← r, b; q ← c, d; r ← e, f ; p← b; a; r} KBAb = {a, b, c, d, e, f, q, r} IC ={← b}\nNote 4. Let KBAb ∈ ({∆+, ∆−}). Here ∆+ refers to admission Horn knowledge base (positive atoms) and ∆− refers to denial Horn knowledge base (negative atoms) with respect to given α. The abduction problem is to explain ∆ with abducibles (KBAb), s.t. KBBG ∪∆+ ∪∆− |= α and KBBG ∪∆+ |= α∪∆− are both consistent with IC.\nAn admission and denial Horn knowledge base, based on 〈KBBG,KBAb〉 is a set KBAb of atoms (literals) whose propositions are in KBAb such that KBBG ∪KBAb is consistent with IC.\nExample 10. From Example 9 and Note 4, the constraint system C, with C =〈KBBG,KBAb, IC〉\nKBBG = {p← q, a; p← r, b; q ← c, d; r ← e, f ; p← b; a; r} KBAb = {∆+ = {a, c, d, e, f, q, r} and ∆− = {a, b, r}} IC ={← b}\nDefinition 23 (KB-closed abductive explanations). For a set of abducibles (KBAb), ∆+ and ∆− are said to be closed abductive explanations with respect to KBBG iff KBBG ∪ ∆+ ∪ ∆− |= α and KBBG ∪ ∆+ |= α ∪ ∆−. ∆+ and ∆− are said to be minimal with respect to KBBG iff no proper subset of ∆+ and ∆− is an abductive explanation for α, i.e. @∆+ ′ ( ∆+ and @∆− ′\n( ∆− s.t. KBBG ∪∆+ ′ ∪∆− ′ |= α and KBBG ∪∆+ ′ |= α∪∆− ′ both consistent with IC.\nKB-closed abductive explanations are also known as KB-closed local minimal explanations.\nObservation 3 Let KBBG′ be a smallest subset of KBBG s.t, ∆+ and ∆− minimal abductive explanations of α with respect to KBAb′ and KBBG′ (for some ∆+ and ∆−). Then ∆+ and ∆− are called locally minimal for α with respect to KBAb′ and KBBG and consistent with IC.\nExample 11. ∆+ = {a, c, d} and ∆− = {c} with respect to IC are only locally minimal abductive explanations for p with respect to KBBG′ (more explanations can be found in (Lu W 1999)).\nFrom example 10 and definition 23, we want to show that the constraint system C, with C =〈KBBG,KBAb, IC〉\nKBBG = {p← q, a; q ← c, d; a; c; d} KBAb = {∆+ = {a, c, d} and ∆− = {b, r}} and IC ={← b}\nNow, we need to connect the grammar system Γ to the Horn (stratified) knowledge base KB, such that KBI ∪ KBU ∪ KBIC = KBBG ∪ KBAb ∪ IC holds. The connection between locally minimal abductive explanation for α with respect to KBI and α-kernel of KB, which is shown by the following lemma immediately follows from their respective definitions.\nObservation 4\n1. Let KB be a Horn (stratified) knowledge base and α a Horn clause s.t. 0 ¬α. Let ∆+ and ∆− be a KB-closed locally minimal abductive explanation for α with respect to KBI . Then, there exists an α-kernel X of KB s.t. X∩KBU = ∆+ ∪∆−. 2. Let KB be a Horn (Horn logic with stratified negation) knowledge base and α a Horn clause s.t. 0 ¬α. Let X be a α-kernel of KB and ∆+∪∆− = X∩KBU . Then, ∆+ and ∆− are KB - closed locally minimal abductive explanations for α with respect to KBI .\nProof.\n1. The fact that 0 ¬α and there exists a KB - closed locally minimal abductive explanation for α with respect to KBI , it is clear that there exists at least one α- kernel of KB. Suppose ∆ (∆ ∈ ∆+ ∪∆−) is empty (i.e. KBI |= ¬α), then the required result follows immediately. If not, since ∆ is a locally minimal abductive explanation, there exists a minimal subset KB′I ⊆ KBI , s.t. ∆ is minimal abductive explanation of α with respect to KB′I . Since, ∆ is KB-closed, it is not difficult to see that KB′I ∪∆+ ∪∆− is a α - kernel of KB. 2. Since X is a α - kernel of KB and ∆ is the set of all abducibles in X, it follows that ∆+ ∪∆− is a minimal abductive explanation of ∆ with respect to X\\∆− ∪ ∆+. It is obvious that ∆+ ∪ ∆− is KB- closed, and so ∆ is a KB-closed locally minimal abductive explanation for α with respect to KBI .\nTheorem 8. Consider a constrained abductive grammar AG = 〈Γ,C〉 with Γ = 〈N,T,KB,R, S〉 and C = 〈KBBG,KBAb, IC〉. Construct a abductive grammar ∆(AG) = 〈N,T,KBBG, R, S〉 by having, for any (∆+) (or) (∆−) from KBAb, the set of acceptable results for accommodate (α,KBBG ∈ ∆+) being of the form (KBAb\\∆+) where (∆+ ∈ KBAb′). ∆+ is a locally minimal set of atoms (literals) KBBG∪∆+ and KBBG∪∆+ |= α is consistent with IC; if (∆−) exists procedure is similar, (like denial (∆−) being of the form (KBAb\\∆−). ∆− is a locally minimal set of atoms (literals) KBBG ∪ ∆− and KBBG ∪ ∆− |= α is consistent with IC), otherwise accommodate (α,KBBG ∈ ∆−) is not possible.\nProof. From Observation 3, Let KBBG′ be a smallest subset of KBBG s.t, ∆+ and ∆− minimal abductive explanations of α with respect to KBAb′ and KBBG′ (for some ∆+ and ∆−). Then ∆+ and ∆− are called locally minimal for α with respect to KBAb′ and KBBG and consistent with IC.\nFrom Observation 4, (∆−) is follow to the kernel of KB and ∆ is the set of all abducibles in (α,KBBG ∈ ∆+), it follows that ∆+ ∪∆− is a minimal abductive explanation of ∆ with respect to KB\\∆− ∪∆+. It is obvious that ∆+ ∪∆− is KB- closed, and so ∆ is a KB-closed locally minimal abductive explanation for α with respect to KBI .\n(∆−) is not follow from KB - closed locally minimal abductive explanation for α with respect to KBI , it is clear that there exists at least one α- kernel of KB.\nAn immediate consequence of the above observation 4 is that it is enough to compute all the KB-closed locally minimal abductive explanations for α with respect to KBI in order to revise α from KB. Thus, a well-known abductive procedure to compute an abductive explanation for α with respect to KBI could be used:\nTheorem 9. Let KB be a Horn (stratified) knowledge base and α a Horn clause.\n1. If Algorithm 1 produces KB′ as a result of revision α to KB, then KB′ is a generalized revision of α from KB. 2. If KB′ is a generalized revision of α from KB, then there exists an incision function σ s.t. KB′ is produced by Algorithm 1 as a result of revision α from KB, using σ.\nProof. Follows from Observation 4 and Theorem 7"
    }, {
      "heading" : "6.1 Generalized revision algorithm",
      "text" : "The problem of Horn knowledge base revision is concerned with determining how a request to change can be appropriately translated into one or more atoms or literals. In this section we develop a new generalized revision algorithm. Note that it is enough to compute all the KB-locally minimal abduction explanations for α with respect to KBI ∪ KBU ∪ KBIC . If α is consistent with KB then a well-known abductive procedure for compute an abductive explanation for α\nwith respect to KBI could be used to compute kernel revision.\nAlgorithm 1 Generalized revision algorithm Input : A Horn knowledge base KB = KBI ∪KBU ∪KBIC\nand a Horn clause α to be revised. Output: A new Horn knowledge base KB′ = KBI ∪KB∗U ∪KBIC ,\ns.t. KB′is a generalized revision α to KB. Procedure KB(KB,α)\nbegin 1. Let V:= {c ∈ KBIC | KBI ∪KBIC inconsistent with α with respect to c}\nP := N := ∅ and KB′ = KB 2. While (V , ∅)\nselect a subset V ′ ⊆ V For each v ∈ V ′, select a literal to be\nremove (add to N) or a literal to be added (add to P) with respect to KB Let KB := KR(KB,P,N)\nLet V:= {c ∈ KBIC | KBI inconsistent with α with respect to c} return\n3. Produce a new Horn knowledge base KB′ end.\nProcedure KR(KB,∆+, ∆−) begin\n1. Let P := {e ∈ ∆+| KBI 6|= e} and N := {e ∈ ∆−| KBI |= e} 2. While (P , 0) or (N , 0)\nselect a subset P ′ ⊆ P or N ′ ⊆ N Construct a set S1 = {X | X is a KB-closed locally\nminimal abductive wrt P explanation for α wrt KBI}. Construct a set S2 = {X | X is a KB-closed locally\nminimal abductive wrt N explanation for α wrt KBI}. 3. Determine a hitting set σ(S1) and σ(S2)\nIf ((N = 0) and (P , 0)) Produce KB′ = KBI ∪ {(KBU ∪ σ(S1)} else Produce KB′ = KBI ∪ {(KBU\\σ(S2) ∪ σ(S1)} end if If ((N , 0) and (P = 0)) Produce KB′ = KBI ∪ {(KBU\\σ(S2)} else Produce KB′ = KBI ∪ {(KBU\\σ(S2) ∪ σ(S1)} end if\n4. return KB′ end."
    }, {
      "heading" : "Reasoning about Abduction",
      "text" : "Definition 24 ((Teniente & Olive 1995)). Let KB=(KBI ,KBU ,KBIC) be a Horn knowledge base, T is updatable part from KB. We define the abduction framework 〈KBBG,KBAb, IC〉. After Algorithm 1 is executed, u is derived part from KB′. The abduction explanation for u in 〈KBI ∪KB∗U ,KBIC〉 is any set Ti, where Ti ⊆ KBAb such that: KBI ∪KB∗U ∪ T |= u.\nAn explanation Ti is minimal if no proper subset of Ti is also an explanation, i.e. if it does not exist any explanation Tj for u such that Tj ⊂ Ti"
    }, {
      "heading" : "Reasoning about Deduction",
      "text" : "Definition 25 ((Teniente & Olive 1995)). Let KB=(KBI ,KBU ,KBIC) be a Horn knowledge base, T is updatable part from KB. After Algorithm 1 is executed, u is derived part from KB′. The deduction consequence on u due to the application of T , KBI ∪KB∗U ∪ T ∪ u is the answer to any question.\nExample 12. Consider a Horn knowledge base KB with immutable part KBI , updatable part KBU and integrity constraint KBIC , compute closed local minimum with respect to to p.\nKBI : p← q ∧ a KBU : a← KBIC :← b p← r ∧ b r ← q ← c ∧ d r ← e ∧ f p← b\nFrom algorithm 1, the above example execute following steps:\nStep number with execution\n(Input) KBI : p← q ∧ a, p← r ∧ b, q ← c ∧ d, r ← e ∧ f, p← b KBU : a←, r ← KBIC :← b\n(0) {p← q, a; p← r, b; q ← c, d; r ← e, f ; p← b; a; r} (1) {V = b} (2) {P = {a, c, d, e, f, q, r} and N = {a, r}}\n(2.1) {∆+ = {a, c, d, e, f, q, r} and ∆− = {a, r}} (2.2) {∆+ = {a, c, d} and ∆− = {}}\n(3) {p← q, a; q ← c, d; a; c; d; r} (Output) KBI : p← q ∧ a, p← r ∧ b, q ← c ∧ d, r ← e ∧ f, p← a, p← b\nKB∗U : a←, c←, d←, r ← KBIC :← b\nTheorem 10. Let KB be a Horn knowledge base and α is (Horn or Horn logic with stratified negation) formula.\n1. If Algorithm 1 produced KB’ as a result of revising α from KB, then KB’ satisfies all the rationality postulates (KB*1) to (KB*6) and (KB*7.3).\n2. Suppose KB′′ satisfies all these rationality postulates for revising α from KB, then KB′′ can be produced by Algorithm 1.\nProof. Follows from Theorem 6 and Theorem 9"
    }, {
      "heading" : "7 Belief update VS Knowledge base update",
      "text" : "In this section we give overview of how belief update is related to knowledge base update. This section is motivated by the works of Konieczny 2011 and Baral & Zhang 2005."
    }, {
      "heading" : "7.1 Belief revision vs Belief update",
      "text" : "Intuitively, revision operators bring a minimal change to the base by selecting the most plausible models among the models of the new information. Whereas update operators Konieczny 2011 bring a minimal change to each possible world (model) of the base in order to take into account the change described by the new information, whatever the possible world.\nTheorem 11 ([29]). If ◦ is a revision operator (i.e. it satisfies (R1)-(R6)), then the update operator defined by ψ µ = ∨ w|=ψ ψ{w} ◦ µ is an update operator that satisfies (U1)-(U9).\nThis theorem states that update can be viewed as a kind of pointwise revision."
    }, {
      "heading" : "7.2 Knowledge base revision vs Knowledge base update",
      "text" : "Generalized revision algorithm brings principle of minimal change, according to new information; how a request to change Horn knowledge base can be appropriately translated into one or more literals. Whereas update operators (Baral & Zhang 2005). bring a minimal change to each possible world (model) of the base in order to take into account the change described by the new information.\nTheorem 12 ([3]). If ∗σ is a revision operator (i.e. it satisfies (KB*1)-(KB*6) and (KB*7.3) and Theorem 9 and Lemma 4), then the update operator defined by ψ µ = ∨ w|=ψ ψ{w} ∗σ µ is an update operator that satisfies (U1)-(U9)."
    }, {
      "heading" : "7.3 Belief update vs Knowledge base update",
      "text" : "Formally speaking, both updates are aiming at maintaining the base of the knowledge or belief up-to-date.\nTheorem 13. If ◦ are revision operators (i.e. they satisfy (R1)-(R6)), then the update operator defined by ψ µ = ∨ w|=ψ ψ{w} ◦ µ is an update operator that satisfies (U1)-(U9)."
    }, {
      "heading" : "8 Deductive database",
      "text" : "A Deductive database DDB consists of three parts: an intensional database IDB (KBI), a set of definite program clauses, extensional database EDB (KBU ), a set of ground facts; and integrity constraints IC. The intuitive meaning of DDB is provided by the Least Herbrand model semantics and all the inferences are carried out through SLD-derivation. All the predicates that are defined in IDB are referred to as view predicates and those defined in EDB are referred to as base predicates. Extending this notion, an atom with a view predicate is said to be a view atom, and similarly an atom with base predicate is a base atom. Further we assume that IDB does not contain any unit clauses and no predicate defined in a given DDB is both view and base.\nTwo kinds of view updates can be carried out on a DDB: An atom, that does not currently follow from DDB, can be inserted, or an atom, that currently follows from DDB can be deleted. When an atom A is to be updated, the view update problem is to insert or delete only some relevant EDB facts, so that the modified EDB together with IDB will satisfy the update of A to DDB.\nNote that a DDB can be considered as a Horn knowledge base to be revised. The IDB is the immutable part of the Horn knowledge base dynamics, while the EDB forms the updatable part. In general, it is assumed that the language underlying a DDB is fixed and the semantics of DDB is the least Herbrand model over this fixed language. We assume that there are no function symbols implying that the Herbrand Base is finite. Therefore, the IDB is practically a shorthand of its ground instantiation 3 written as IDBG. In the sequel, technically we mean IDBG when we refer simply to IDB. Thus, a DDB represents a Horn knowledge base dynamics where the immutable part is given by IDBG and updatable part is the EDB. Hence, the rationality postulates (KB*1)-(KB*6) and (KB*7.3) provide an axiomatic characterization for updating (insert and delete) a view atom A into a definite database DDB.\nBut before discussing the rationality postulates and algorithm, we want to make it precise, how a relational database, along with operations on relations,\n3 a ground instantiation of a definite program P is the set of clauses obtained by substituting terms in the Herbrand Universe for variables in P in all possible ways\ncan be represented by definite deductive database. We assume the reader is familiar with relational database concepts. A relation scheme R can be thought of as a base predicate whose arguments define the attributes A of the scheme. Its relational extension r, is a finite set of base atoms R(A) containing the predicate R. A database schema consists of finite collection of relational schemes < R1, . . . , Rn >, and a relational database is a specific extension of database schema, denoted as < r1, . . . , rn >. In our context, relational database can be represented by EDB = ⋃ i=1,...,nRi(Ai).\nJoin is a binary operator for combining two relations. Let r and s be two relational extensions of schema R (with attributes R) and S (with attributes S), respectively. Let T = R ∪ S. The join of r and s, written as r ⊗ s, is the relational extension q(T) of all tuples t over T such that there are tr ∈ r and ts ∈ s, with tr = t(R) and ts = t(S). Join can be captured by a constraint clause Q(T)← R(R), S(S).\nLet us consider two relational schemes R and S from Example 1, with attributes R={Group,Chair} and S={Staff,Group}.Consider the following extensions r and s: (see definition and properties of similarity in works of Christiansen (Christiansen & Rekouts 2007) and Godfrey (Godfrey et al. 1998)).\nThe following rule, T(Staff,Group,Chair)← S(Staff,Group),R(Group,Chair) represents the join of s and r, which is given in Table 5.2:\nOur first integrity constraint (IC) is that each research group has only one chair ie. ∀x, y, z (y=z) ← group chair(x,y) ∧ group chair(x,z). Second integrity constraint is that a person can be a chair for only one research group ie. ∀x, y, z (y=z)← group chair(y,x) ∧ group chair(z,x).\nAn update request U = A, where A is a set of base facts that are not true in KB. Then, we need to find a transaction T = Tins ∪ Tdel, where Tins(∆i) (resp.\nTdel(∆j)) is the set of facts, such that U is true in DDB′ = ((EDB − Tdel ∪ Tins)∪ IDB ∪ IC). Since we consider stratifiable (definite) deductive databases, SLD-trees can be used to compute the required abductive explanations. The idea is to get all EDB facts used in a SLD-derivation of A with respect to DDB, and construct that as an abductive explanation for A with respect to IDBG.\nTraditional methods translate a view update request into a transaction combining insertions and deletions of base relations for satisfying the request (Mota-Herranz et al. 2000). Furthermore, a stratifiable (definite) deductive database can be considered as a knowledge base, and thus the rationality postulates and insertion algorithm from the previous section can be applied for solving view update requests in deductive databases.\nThere are two ways to find minimal elements (insertion and deletion) in the presence of integrity constraints. Algorithm 2 first checks consistency with integrity constraints and then reduces steps with abductive explanation for A . Algorithm 3 is doing vice versa, but both algorithm outputs are similar.\nAlgorithm 2 Algorithm to compute all DDB-closed locally minimal abductive explanation of an atom(literals)\nInput : A definite deductive database DDB = IDB ∪ EDB ∪ IC an literals A\nOutput : Set of all DDB-closed locally minimal abductive explanations for A wrt IDBG\nbegin 1. Let V := {c ∈ IC | IDB ∪ IC inconsistent with A wrt c }\nWhile (V , 0) Construct a complete SLD-tree for← A wrt DDB.\nFor every successful branch i: construct ∆i = {D | D ∈ EDB and D is used as an input clause in branch i} For every unsuccessful branch j: construct ∆j = {D | D ∈ EDB and D is used as an input clause in branch j}\nProduce set of all ∆i and ∆j computed in the previous step as the result. return\n2. Produce all DDB-closed locally minimal abductive explanations in ∆i and ∆j\nend.\nHorn knowledge base revision algorithm 1, may be applied to compute all DDB-closed locally minimal abductive explanation of an atom (literals). Unfortunately, this algorithm does not work as intended for any deductive database, and a counter example is produced below. Thus, general algorithms 2 and 3 produced some unexpected sets in addition to locally minimal abductive explanations\nAlgorithm 3 Algorithm to compute all DDB-closed locally minimal abductive explanation of an atom(literals)\nInput : A definite deductive database DDB = IDB ∪ EDB ∪ IC an literals A\nOutput : Set of all DDB-closed locally minimal abductive explanations for A wrt IDBG\nbegin 1. Construct a complete SLD-tree for← A wrt DDB.\nFor every successful branch i: construct ∆i = {D | D ∈ EDB and D is used as an input clause in branch i} For every unsuccessful branch j: construct ∆j = {D | D ∈ EDB and D is used as an input clause in branch j}\n2. Let V := {c ∈ IC | IDB ∪ IC inconsistent with A wrt c } While (V , 0)\nProduce set of all ∆i and ∆j is consistent with IC as the result. return Produce all DDB-closed locally minimal abductive explanations in ∆i and ∆j\nend.\nExample 14. Consider a stratifiable (definite) deductive database DDB as follows:"
    }, {
      "heading" : "IDB : p← a ∧ e EDB : e← IC :← b",
      "text" : "q ← a ∧ f f ← p← b ∧ f q ← b ∧ e p← q q ← a\nSuppose we want to insert p. First, we need to check consistency with IC and afterwards, we have to find ∆i and ∆j via tree deduction.\n(Input) IDB : p← a ∧ e, q ← a ∧ f, p← b ∧ f, q ← b ∧ e, p← q, q ← a EDB : e←, f ← IC :← b\n(0) {p← a, e; q ← a, f ; p← b, f ; q ← b, e; p← q; q ← a; e; f} (1) {V = b} (2) ← p\n← a, e\n← q\n← a, f ← a ← b, e\n← b, f\n(3-4) ∆i = {a, e} and ∆j = {} (5) p← a, e; q ← a, f ; p← q; q ← a; b; e; f\n(Output) IDB : p← a ∧ e, q ← a ∧ f, p← q, q ← a EDB′ : a←, e←, f ← IC :← b\nFrom the step, it is easy to conclude which branches are consistent with respect to IC (indicated in the depicted tree by the symbol ). For the next step, we need to find minimal accommodate (positive literal) and denial literal (negative literal) with with respect to to p. The subgoals of the tree are ← a, e and ← a, f , which are minimal tree deductions of only facts. Clearly, ∆i = {a, e} and ∆j = {f} with respect to IC, are the only locally minimal abductive explanations for p with respect to IDBG, but these result are not closed-locally minimal explanations.\nFor processing a given view update request, a set of all explanations for that atom has to be generated through a complete SLD-tree. The resulting hitting set of these explanations is then a base update of the EDB satsifying the view update request. We present a different approach which is also rational. The generation of a hitting set is carried out through a hyper tableaux calculus (bottom-up) for implementing the deletion process as well as through the magic sets approach (top-down) for performing insertions focussed on the particular goal given."
    }, {
      "heading" : "8.1 View update method",
      "text" : "View update (Behrend & Manthey 2008) aims at determining one or more base relation updates such that all given update requests with respect to derived relations are satisfied after the base updates have been successfully applied.\nDefinition 26 (View update). Let DDB = 〈IDB,EDB, IC〉 be a stratifiable (definite) deductive database DDB(D). A VU request νD is a pair 〈ν+D, ν − D〉 where ν+D and ν − D are sets of ground atoms representing the facts to be inserted into D or deleted from D, resp., such that pred(ν+D ∪ ν − D) ⊆ pred(IDB), ν + D ∩ ν − D = ∅, ν+D ∩ PMD = ∅ and ν − D ⊆ PMD.\nNote that we consider again true view updates only, i.e. ground atoms which are presently not derivable for atoms to be inserted, or are derivable for atoms to be deleted, respectively. A method for view update determines sets of alternative updates satisfying a given request. A set of updates leaving the given database consistent after its execution is called VU realization.\nDefinition 27 (Induced update). Let DDB = 〈IDB,EDB, IC〉 be a stratifiable (definite) deductive database and DDB = νD a VU request. A VU realization is a base update uD which leads to an induced update uD→D′ from D to D′ such that ν+D ⊆ PMD′ and ν − D ∩ PMD′ = ∅.\nThere may be infinitely many realizations and even realizations of infinite size which satisfy a given VU request. A breadth-first search (BFS) is employed for determining a set of minimal realizations τD = {u1D, . . . , uiD}. Any uiD is minimal in the sense that none of its updates can be removed without losing the property of being a realization for νD."
    }, {
      "heading" : "Magic Set (Top-down computation):",
      "text" : "Given a VU request νDDB , view update methods usually determine further VU requests in order to find relevant base updates. Similar to delta relations for UP we will use the notion VU relation to access individual view updates with respect to the relations of our system. For each relation p ∈ pred(IDB ∪EDB) we use the VU relation ∇+p (x) for tuples to be inserted into DDB and ∇−p (x) for tuples to be deleted from DDB. The initial set of delta facts resulting from a given VU request is again represented by so-called VU seeds.\nDefinition 28 (View update seeds). Let DDB(D) be a stratifiable (definite) deductive database and νDDB = 〈ν+D, ν − D〉 a VU request. The set of VU seeds vu seeds(νD) with respect to νD is defined as follows:\nvu seeds(νD) := { ∇πp (c1, . . . , cn)|p(c1, . . . , cn) ∈ νπD and π ∈ {+,−} } .\nDefinition 29 (View update rules). Let IDB be a normalized stratifiable (definite) deductive rule set. The set of VU rules for true view updates is denoted IDB∇ and is defined as the smallest set satisfying the following conditions:\n1. For each rule of the form p(x) ← q(y) ∧ r(z) ∈ IDB with vars(p(x)) = (vars(q(y)) ∪ vars(r(z))) the following three VU rules are in IDB∇:\n∇+p (x) ∧ ¬q(y)→ ∇+q (y) ∇−p (x)→ ∇−q (y) ∨∇−r (z) ∇+p (x) ∧ ¬r(z)→ ∇+r (z)\n2. For each rule of the form p(x) ← q(x) ∧ ¬r(x) ∈ IDB the following three VU rules are in IDB∇:\n∇+p (x) ∧ ¬q(x)→ ∇+q (x) ∇−p (x)→ ∇−q (x) ∨∇+r (x) ∇+p (x) ∧ r(x)→ ∇−r (x)\n3. For each two rules of the form p(x) ← q(x) and p(x) ← r(x) the following three VU rules are in IDB∇:\n∇−p (x) ∧ q(x)→ ∇−q (x) ∇+p (x)→ ∇+q (x) ∨∇+r (x) ∇−p (x) ∧ r(x)→ ∇−r (x)\n4. a) For each relation p defined by a single rule p(x) ← q(y) ∈ IDB with vars(p(x)) = vars(q(y)) the following two VU rules are in IDB∇:\n∇+p (x)→ ∇+q (y) ∇−p (x)→ ∇−q (y)\nb) For each relation p defined by a single rule p← ¬q ∈ IDB the following two VU rules are in IDB∇:\n∇+p → ∇−q ∇−p → ∇+q 5. Assume without loss of generality that each projection rule in IDB is of the\nform p(x) ← q(x, Y ) ∈ IDB with Y < vars(p(x)). Then the following two VU rules\n∇−p(x) ∧ q(x, Y )→ ∇−q (x, Y ) ∇+p (x)→ ∇+q (x, c1) ∨ . . . ∨∇+q (x, cn) ∨∇+q (x, cnew)\nare in IDB∇ where all ci are constants from the Herbrand universe UDDB of DDB and cnew is a new constant, i.e. cnew < UDDB.\nTheorem 14. Let DDB = 〈IDB,EDB, IC〉 be a stratifiable (definite)deductive database(D), νD a view update request and τD = {u1D, . . . , unD} the corresponding set of minimal realizations. Let D∇ = 〈EDB ∪ vu seeds(νD), IDB ∪ IDB∇〉 be the transformed deductive database of D. Then the VU relations in PM∇D with respect to base relations of D correctly represent all direct consequences of νD. That is, for each realization uiD = 〈ui + D , u i− D 〉 ∈ τD the following condition holds:\n∃p(t) ∈ ui + D : ∇+p (t) ∈MS∇D ∨ ∃p(t) ∈ ui − D : ∇−p (t) ∈MS∇D .\nProof. Follows from the result of (Behrend & Manthey 2008)."
    }, {
      "heading" : "Hyper Tableau (Bottom-up computation):",
      "text" : "In (Aravindan & Baumgartner 1997) a variant of clausal normal form tableaux called ”hyper tableaux” is introduced for view deletion method. Since the hyper tableaux calculus constitutes the basis for our view update algorithm, Clauses, i.e. multisets of literals, are usually written as the disjunction A1 ∨ A2 ∨ · · · ∨ Am ∨ not B1 ∨ not B2 · · · ∨ not Bn (M ≥ 0, n ≥ 0). The literals A1, A2, . . . Am (resp. B1, B2, . . . , Bn) are called the head (resp. body) of a clause. With L we denote the complement of a literal L. Two literals L and K are complementary if L = K.\nFrom now on D always denotes a finite ground clause set, also called database, and Σ denotes its signature, i.e. the set of all predicate symbols occurring in it. We consider finite ordered trees T where the nodes, except the root node, are labeled with literals. In the following we will represent a branch b in T by the sequence b = L1, L2, . . . , Ln (n ≥ 0) of its literal labels, where L1 labels an immediate successor of the root node, and Ln labels the leaf of b. The branch b is called regular iff Li , Lj for 1 ≤ i, j ≤ n and i , j, otherwise it is called irregular. The tree T is regular iff every of its branches is regular, otherwise it is irregular. The set of branch literals of b is lit(b) = {L1, L2, . . . , Ln}. For brevity, we will write expressions like A ∈ b instead of A ∈ lit(b). In order to memorize the fact that a branch contains a contradiction, we allow to label a branch as either open or closed. A tableau is closed if each of its branches is closed, otherwise it is open.\nDefinition 30 (Hyper Tableau). A literal set is called inconsistent iff it contains a pair of complementary literals, otherwise it is called consistent. Hyper tableaux for D are inductively defined as follows:\nInitialization step: The empty tree, consisting of the root node only, is a hyper tableau for D. Its single branch is marked as ”open”.\nHyper extension step: If (1) T is an open hyper tableau for D with open branch b, and (2) C = A1∨A2∨· · ·∨Am ← B1∧B2 · · ·∧Bn is a clause fromD (n ≥ 0,m ≥ 0), called extending clause in this context, and (3) {B1, B2, . . . , Bn} ⊆ b (equivalently, we say that C is applicable to b)then the tree T is a hyper tableau for D, where T is obtained from T by extension of b by C: replace b in T by the new branches\n(b, A1), (b, A2), . . . , (b, Am), (b,¬B1), (b,¬B2), . . . , (b,¬Bn)\nand then mark every inconsistent new branch as ”closed”, and the other new branches as ”open”.\nThe applicability condition of an extension expresses that all body literals have to be satisfied by the branch to be extended. From now on, we consider only regular hyper tableaux. This restriction guarantees that for finite clause sets no branch can be extended infinitely often. Hence, in particular, no open finished branch can be extended any further. This fact will be made use of below occasionally. Notice as an immediate consequence of the above definition that open branches never contain negative literals.\nThis paper work focused on stratified (definite) deductive database without any auxiliary variable. In magic set rule play in minimal case, our future goal is similar foundation using auxiliary variable (Deductive Databases) side and more details found in Behrend’s (Behrend & Manthey 2008) work."
    }, {
      "heading" : "8.2 View update algorithm",
      "text" : "The key idea of the algorithm presented in this paper is to transform the given database along with the view update request into a logic program and apply known minimality techniques to solve the original view update problem. The intuition behind the transformation is to obtain a logic program in such a way that each (minimal) model of this transformed program represent a way to update the given view atom. We present two variants of our algorithm. The one that is discussed in this section employs a trivial transformation procedure but has to look for minimal models; and another performs a costly transformation, but dispenses with the requirement of computing the minimal models."
    }, {
      "heading" : "Minimality test",
      "text" : "We start presenting an algorithm for stratifiable (definite) deductive databases by first defining precisely how the given database is transformed into a logic program for the view deletion process (Aravindan & Baumgartner 1997)\nDefinition 31 (IDB Transformation). Given an IDB and a set of ground atoms S, the transformation of IDB with respect to S is obtained by translating each clause C ∈ IDB as follows: Every atom A in the body (resp. head) of C that is also in S is moved to the head (resp. body) as ¬A.\nNote 5. If IDB is a stratifiable deductive database then the transformation introduced above is not necessary.\nDefinition 32 (IDB∗ Transformation). Let IDB∪EDB be a given database. Let S0 = EDB ∪{A | A is a ground IDB atom}. Then, IDB∗ is defined as the transformation of IDB with respect to S0.\nNote 6. IDB∗ is in general a logic program. The negative literals (¬A) appearing in the clauses are intuitively interpreted as deletion of the corresponding atom (A) from the database. Technically, a literal ¬A is to be read as a positive atom, by taking the ¬-sign as part of the predicate symbol. To be more precise, we treat ¬A as an atom with respect to IDB∗, but as a negative literal with respect to IDB.\nNote that there are no facts in IDB∗. So when we add a delete request such as ¬A to this, the added request is the only fact and any bottom-up reasoning strategy is fully focused on the goal (here the delete request)\nDefinition 33 (Update Tableaux Hitting Set). An update tableau for a database IDB ∪ EDB and delete request ¬A is a hyper tableau T for IDB∗ ∪ {¬A←} such that every open branch is finished. For every open finished branch b in T we define the hitting set (of b in T ) as HS(b) = {A ∈ EDB|¬A ∈ b}.\nThe next step is to consider the view insertion process (Behrend & Manthey 2008):\nDefinition 34 (IDB• Transformation). Let IDB∪EDB be a given database. Let S1 = EDB ∪ {A | A is a ground IDB atom} (that is either body or head empty). Then, IDB• is defined as the transformation of IDB with respect to S1.\nNote 7. IDB is in general a (stratifiable) logic program. The positive literals (A) appearing in the clauses are intuitively interpreted as an insertion of the corresponding atom (A) from the database.\nDefinition 35 (Update magic Hitting Set). An update magic set rule for a database IDB ∪ EDB and insertion request A is a magic set rule M for IDB• ∪ {A←} such that every close branch is finished. For every close finished branch b in M we define the magic set rule (of b in M) as HS(b) = {A ∈ EDB|A ∈ b}.\nExample 15. Given stratifiable (definite) deductive database DDB = IDB ∪ EDB ∪ IC and insert p."
    }, {
      "heading" : "IDB : p← a ∧ e EDB : a← IC : ∅",
      "text" : "q ← a ∧ e c← p← a ∧ f q ← c\nIDB∗ Transformation:\nIDB∗ : ¬a ∨ ¬e← ¬p EDB : a← IC : ∅ ¬a ∨ ¬e← ¬q c← ¬a ∨ ¬f ← ¬p ¬c← ¬q\nIDB• Transformation: (Body empty)\nIDB• : p ∨ ¬a ∨ ¬e← EDB : a← IC : ∅ q ∨ ¬a ∨ ¬e← c← p ∨ ¬a ∨ ¬f ← q ∨ ¬c←\nIDB• Transformation: (Head empty)\nIDB• : ← ¬p ∧ a ∧ e EDB : a← IC : ∅ ← ¬q ∧ a ∧ e c← ← ¬p ∧ a ∧ f ← ¬q ∧ c\nThe set S0 is determined by all the IDB atoms and the current EDB atoms and in our case it is {p, q, a, c, e, f}. IDB∗ and IDB• is the transformation of IDB with respect to S0 which is given above.\nSuppose a ground view atom A is to be insert. Then, an update tableau for IDB• with insert request A (IDB∗ with delete request ¬A) is built. The intuition is that the set of EDB atoms appearing in a model (open/close branch) constitute a hitting set, and removing/adding this set from EDB should achieve the required view insertion. Unfortunately, this does not result in a rational insertion, as relevance policy may be violated.\nExample 16. Let us continue with example 15 Suppose the view atom p is to be insert. Then according to the above proposal, an update tableau for IDB• ( IDB∗ ) and p (¬p) is to be built. This is illustrated in the accompanying figure below. As shown, open/close branches constitute two hitting sets {a} and {f, a} ({¬a} and {¬f,¬a}). It is not difficult to see that {f, a}({¬f,¬a}) does not satisfy any of the relevance policies (KB*7.1) or (KB*7.2) or (KB*7.3). Hence simple model computation using hyper tableau calculus does not result in rational hitting sets. The branch is closed if the corresponding hitting set does not satisfy this strong relevance postulate.\nDefinition 36 (Minimality test). Let T be an update tableau for IDB∗ ∪ EDB and delete request ¬A. We say that open finished branch b in T satisfies the strong minimality test iff ∀s ∈ HS(b) : IDB∗ ∪ EDB\\HS(b) ∪ {s} ` ¬A.\nDefinition 37 (Update Tableau satisfying strong minimality). An update tableau for given IDB ∪ EDB and delete request ¬A is transformed into an update tableau satisfying strong minimality by marking every open finished branch as closed which does not satisfy strong minimality.\nThe next step is to consider the view insertion process (Behrend & Manthey 2008):\nDefinition 38 (Minimality test). Let M be an update magic set rule for IDB ∪ EDB and insert request A. We say that close finished branch b in M satisfies the strong minimality test iff ∀s ∈ HS(b) : IDB•∪EDB\\HS(b)∪{s} ` A.\nDefinition 39 (Update magic set rule satisfying strong minimality). An update magic set rule for given IDB∪EDB and insert request A is transformed into an update magic set rule satisfying strong minimality by marking every close finished branch as open which does not satisfy strong minimality.\nExample 17. Continuing with the above example, after constructing the branch corresponding to the hitting set {f, a}({¬f,¬a}), the strong minimality test is carried out as follows: It is checked if the resulting database with each member of hitting set implies the insert atom p. For example, IDB∪EDB\\{f, a}∪{a} 0 p, and hence this branch fails the strong minimality test.\nInterestingly, this minimality test is equivalent to the groundedness test used for generating minimal models of logic programs. The key idea of the groundedness test is to check if the members in the model are implied by the program together with the negation/positive of the atoms not present in the model. The groundedness test for generating minimal models can be stated\nas follows: Let T be an update tableau for IDB ∪ EDB and insert request A.We say that open finished branch b in T satisfies the groundedness test iff ∀s ∈ HS(b) : IDB• ∪ EDB\\HS(b) ∪ {A} ` s, similar for IDB∗ (∀s ∈ HS(b) : IDB∗ ∪ EDB\\HS(b) ∪ {¬A} ` ¬s). It is not difficult to see that this is equivalent to the minimality test. This means that every minimal model (minimal with respect to the base atoms) of IDB∗ ∪ {A} provides a minimal hitting set for insertion the ground view atom A.\nAlgorithm 4 View update Algorithm based on minimality test Input : A stratifiable (definite) deductive database DDB = IDB ∪ EDB ∪ IC\nan literals A Output: A new stratifiable (definite) database IDB ∪ EDB′ ∪ IC\nbegin 1. Let V := {c ∈ IC | IDB ∪ IC inconsistent with A with respect to c }\nWhile (V , ∅) 2. Construct a complete SLD-tree for← A with respect to DDB. 3. For every successful branch i:construct ∆i = {D | D ∈ EDB}\nand D is used as an input clause in branch i. Construct a branch i of an update tableau satisfying minimality\nfor IDB ∪ EDB and delete request ¬A. Produce IDB ∪ EDB\\HS(i) as a result\n4. For every unsuccessful branch j:construct ∆j = {D | D ∈ EDB} and D is used as an input clause in branch j.\nConstruct a branch j of an update magic set rule satisfying minimality for IDB ∪ EDB and insert request A. Produce IDB ∪ EDB\\HS(j) as a result Let V := {c ∈ IC | IDB ∪ IC inconsistent with A with respect to c }\nreturn 5. Produce DDB as the result.\nend.\nThis means that every minimal model (minimal with respect to the base atoms) of IDB∗∪{¬A} (IDB•∪{A} )provides a minimal hitting set for deleting the ground view atom A. Similarly, IDB∗ ∪ {A} provides a minimal hitting set for inserting the ground view atom A. We are formally present our algorithms.\nGiven a database and a view atom to be updated, we first transform the database into a logic program and use hyper tableaux calculus to generate models of this transformed program for deletion of an atom. Second, magic sets transformed rules are used is used to generate models of this transformed program for determining an induced insertion of an atom. Models that do not represent rational update are filtered out using the strong minimality test. The procedure for stratifiable (definite) deductive databases is presented in Algorithms in 4 and 5.\nAlgorithm 5 View update Algorithm based on minimality test Input : A stratifiable (definite) deductive database DDB = IDB ∪ EDB ∪ IC\nan literals A Output: A new stratifiable (definite) database IDB ∪ EDB′ ∪ IC\nbegin 1. Construct a complete SLD-tree for← A with respect to DDB. 2. For every successful branch i:construct ∆i = {D | D ∈ EDB}\nand D is used as an input clause in branch i. 3. For every unsuccessful branch j:construct ∆j = {D | D ∈ EDB} and D is used as an input clause in branch j. 4. Let V := {c ∈ IC | IDB ∪ IC inconsistent with A with respect to c }\nWhile (V , ∅) Construct a branch i of an update tableau satisfying minimality\nfor IDB ∪ EDB and delete request ¬A. Produce IDB ∪ EDB\\HS(i) as a result\nConstruct a branch j of an update magic set rule satisfying minimality for IDB ∪ EDB and insert request A. Produce IDB ∪ EDB\\HS(j) as a result Let V := {c ∈ IC | IDB ∪ IC inconsistent with A with respect to c }\nreturn 5. Produce DDB as the result.\nend.\nLemma 1. The strong minimality test and the groundedness test are equivalent.\nProof. Follows from the result of (Aravindan & Baumgartner 1997).\nExample 18."
    }, {
      "heading" : "IDB : p← a ∧ e EDB : a← IC :← b",
      "text" : "q ← a ∧ e f ← p← b ∧ f q ← b ∧ f p← g ∧ a q ← p\nSuppose we want to insert p. First, we need to check consistency with IC and afterwards, we have to find ∆i and ∆j via tree deduction.\nFrom algorithm 4 or 5 (only different is checking IC condition), the above example execute following steps:\nStep number with execution\n(Input) IDB : p← a ∧ e; q ← a ∧ e; p← b ∧ f ; q ← b ∧ f ; p← g ∧ a; q ← p EDB : a←, f ← IC :← b\n(0) {p← a, e; q ← a, e; p← b, f ; q ← b, f ; p← g, a; q ← p; a; f}\n(1) {V = b}\n(2.1) a. a\ne\nq p\nb. f\nb\na\ne\nq p\nc. f\nb\na\ne\nq p\nq d. g\nf\nb\na\ne\nq p\nq\ne. g\nf\nb\na\ne\nq\np\nq\n(2.2) a. a\ne\nq p\nb. a\ne\nq p\nc. a\ne\nq p\nq d. g\na\ne\nq p\nq\ne. g\na\ne\nq\np\nq\n(3-4) ∆i = {a, e, g} and ∆j = {}\n(5) p← a, e; q ← a, e; p← g, a; q ← p; a; e; f ; g (Output) IDB : p← a ∧ e; q ← a ∧ e; p← g ∧ a; q ← p\nEDB′ : a←, e←, f ←, g ← IC :← b\nTo show the rationality of this approach, we study how this is related to the previous approach presented in the last section, i.e. generating explanations and computing hitting sets of these explanations. To better understand the relationship it is imperative to study where the explanations are in the hyper tableau approach and magic set rules. We first define the notion of an EDB-cut and then view update seeds.\nDefinition 40 (EDB-Cut). Let T be update tableau with open branches b1, b2, . . . , bn. A set S = {A1, A2, . . . , An} ⊆ EDB is said to be EDB-cut of T iff ¬Ai ∈ bi (Ai ∈ bi), for 1 ≤ i ≤ n.\nDefinition 41 (EDB seeds). Let M be an update seeds with close branches b1, b2, . . . ,bn. A set S = {A1, A2, . . . , An} ⊆ EDB is said to be a EDB-seeds of M iff EDB seeds vu seeds(νD) with respect to νD is defined as follows:\nvu seeds(νD) := { ∇πp (c1, . . . , cn)|p(c1, . . . , cn) ∈ νπD and π ∈ {+,−} } .\nLemma 2. Let T be an update tableau for IDB ∪ EDB and update request A. Similarly, for M be an update magic set rule. Let S be the set of all EDB-closed minimal abductive explanations for A with respect to. IDB. Let S′ be the set of all EDB-cuts of T and EDB-seeds of M . Then the following hold\n• S ⊆ S′.\n• ∀∆′ ∈ S′ : ∃∆ ∈ Ss.t.∆ ⊆ ∆′.\nProof.\n1. Consider a ∆(∆ ∈ ∆i ∪ ∆j) ∈ S. We need to show that ∆ is generated by algorithm 4 at step 2. From observation 4, it is clear that there exists a A-kernel X of DDBG s.t. X ∩ EDB = ∆j and X ∪ EDB = ∆i. Since X ` A, there must exist a successful derivation for A using only the elements of X as input clauses and similarly X 0 A. Consequently ∆ must have been constructed at step 2. 2. Consider a ∆′((∆′ ∈ ∆i ∪∆j) ∈ S′. Let ∆′ be constructed from a successful (unsuccessful) branch i via ∆i(∆j). Let X be the set of all input clauses used in the refutation i. Clearly X ` A(X 0 A). Further, there exists a minimal (with respect to set-inclusion) subset Y of X that derives A (i.e. no proper subset of Y derives A). Let ∆ = Y ∩ EDB (Y ∪ EDB). Since IDB does not (does) have any unit clauses, Y must contain some EDB facts, and so ∆ is not empty (empty) and obviously ∆ ⊆ ∆′. But, Y need not (need) be a A-kernel for IDBG since Y is not ground in general. But it stands for several A-kernels with the same (different) EDB facts ∆ in them. Thus, from observation 4, ∆ is a DDB-closed locally minimal abductive explanation for A with respect to IDBG and is contained in ∆′. minimal.\nThe above lemma precisely characterizes what explanations are generated by an update tableau. It is obvious then that a branch cuts through all the explanations and constitutes a hitting set for all the generated explanations. This is formalized below.\nLemma 3. Let S and S′ be sets of sets s.t. S ⊆ S′ and every member of S′\\S contains an element of S. Then, a set H is a minimal hitting set for S iff it is a minimal hitting set for S′.\nProof.\n1. (Only if part) Suppose H is a minimal hitting set for S. Since S ⊆ S′, it follows that H ⊆ ⋃ S′. Further, H hits every element of S′, which is evident\nfrom the fact that every element of S′ contains an element of S. Hence H is a hitting set for S′. By the same arguments, it is not difficult to see that H is minimal for S′ too.\n(If part) Given that H is a minimal hitting set for S′, we have to show that it is a minimal hitting set for S too. Assume that there is an element E ∈ H that is not in ⋃ S. This means that E is selected from some Y ∈ S′\\S. But Y contains an element of S, say X. Since X is also a member of S′, one member of X must appear in H. This implies that two elements have been\nselected from Y and hence H is not minimal. This is a contradiction and hence H ⊆ ⋃ S. Since S ⊆ S′, it is clear that H hits every element in S, and so H is a hitting set for S. It remains to be shown that H is minimal. Assume the contrary, that a proper subset H ′ of H is a hitting set for S. Then from the proof of the only if part, it follows that H ′ is a hitting set for S′ too, and contradicts the fact that H is a minimal hitting set for S′ . Hence, H must be a minimal hitting set for S.\nLemma 4. Let T be an update tableau for IDB ∪ EDB and update request A that satisfies the strong minimality test. Similarly, for M be an updating magic set rule. Then, for every open (close) finished branch b in T , HS(b) (M , HS(b)) is a minimal hitting set of all the abductive explanations of A.\nProof. Follows from the Observation 4 (minimal test) in and (Behrend & Manthey 2008).\nSo, Algorithms 4 and 5 generate a minimal hitting set (in polynomial space) of all EDB-closed locally minimal abductive explanations of the view atom to be deleted. From the belief dynamics results recalled in section 5.3, it immediately follows that Algorithms 4 and 5 are rational, and satisfy the strong relevance postulate (KB*7.1).\nTheorem 15. Algorithms 4 and 5 are rational, in the sense that they satisfy all the rationality postulates (KB*1)-(KB*6) and the strong relevance postulate (KB*7.1). Further, any update that satisfies these postulates can be computed by these algorithms.\nProof. Follows from Observation 4,4 and Theorem 7."
    }, {
      "heading" : "8.3 Materialized view",
      "text" : "In many cases, the view update to be materialized, i.e. the least Herbrand Model is computed and kept, for efficient query answering. In such a situation, rational hitting sets can be computed without performing any minimality test. The idea is to transform the given IDB with respect to the materialized view.\nDefinition 42 (IDB+ Transformation). Let IDB∪EDB be a given database. Let S be the Least Herbrand Model of this database. Then, IDB+ is defined as the transformation of IDB with respect to S.\nNote 8. If IDB is a stratifiable deductive database then the transformation introduced above is not necessary.\nDefinition 43 (Update Tableau based on Materialized view). An update tableau based on materialized view for a database IDB∪EDB and delete request ¬A is a hyper tableau T for IDB+ ∪ {¬A ←} such that every open branch is finished.\nDefinition 44 (IDB− Transformation). Let IDB∪EDB be a given database. Let S1 be the Least Herbrand Model of this database (that is either body or head empty). Then, IDB− is defined as the transformation of IDB with respect to S1.\nDefinition 45 (Update magic set rule based on Materialized view). An update magic set rule based on materialized view for a database IDB ∪ EDB and insert request A is a magic set M for IDB+ ∪ {A←} such that every close branch is finished.\nNow the claim is that every model of IDB+ ∪ {¬A ←} (A ←) constitutes a rational hitting set for the deletion and insertion of the ground view atom A. So, the algorithm works as follows: Given a database and a view update request, we first transform the database with respect to its Least Herbrand Model (computation of the Least Herbrand Model can be done as a offline preprocessing step. Note that it serves as materialized view for efficient query answering). Then the hyper tableaux calculus (magic set rule) is used to compute models of this transformed program. Each model represents a rational way of accomplishing the given view update request. This is formalized in Algorithms 6 and 7.\nLike the approach with minimality test, this algorithm runs on not polynomial space. This approach require minimality test, but our focus on integrity constrain open/close branch. Again, this requires some offline pre-processing of computing the Least Herbrand Model. Note that, our future direction to construct minimality test, this method may generate a non-minimal (but rational) hitting set.\nExample 19. Given stratifiable (definite) deductive database DDB = IDB ∪ EDB ∪ IC and insert p."
    }, {
      "heading" : "IDB : p← a EDB : c← IC : ∅",
      "text" : "q ← a d←\nq ← c ∧ b q ← p\nIDB+ Transformation:\nIDB+ : ¬a← ¬p EDB : c← IC : ∅ ¬a← ¬q d←\n¬c ∨ ¬b← ¬p ¬p← ¬q\nIDB− Transformation: (Body empty)\nIDB− : p ∨ ¬a← EDB : c← IC : ∅ q ∨ ¬a← d←\nq ∨ ¬c ∨ ¬b← q ∨ ¬p←\nIDB− Transformation: (Head empty)\nThe Least Herbrand Model of this database is {p, q, a, b}. The transformed database IDB+ and IDB− based on this model, together with an update tableaux for insertion request p based on materialised view is as above figure:\nObserve that the last two clauses are never used and the necessarily failing attempt of deleting t to delete p is never made, thus greatly reducing the search space. Also note that the two cuts with only EDB atoms {a, b} and {a} are exactly the two locally minimal explanations for p. The two open branches provide the two models of IDB+ ∪ {¬p} (IDB− ∪ {p} which stand for the hitting sets {a, b} and {a}. Clearly, {a, b} not minimal.\nAlgorithm 6 View update algorithm based on Materialized view Input : A stratifiable (definite) deductive database DDB = IDB ∪ EDB ∪ IC\nan literals A Output: A new stratifiable (definite) database IDB ∪ EDB′ ∪ IC\nbegin 1. Let V := {c ∈ IC | IDB ∪ IC inconsistent with A with respect to c }\nWhile (V , ∅) 2. Construct a complete SLD-tree for← A with respect to DDB. 3. For every successful branch i:construct ∆i = {D | D ∈ EDB}\nand D is used as an input clause in branch i. Construct a branch i of an update tableau based on view\nfor IDB ∪ EDB and delete request ¬A. Produce IDB ∪ EDB\\HS(i) as a result\n4. For every unsuccessful branch j:construct ∆j = {D | D ∈ EDB} and D is used as an input clause in branch j.\nConstruct a branch j of an update magic set rule based on view for IDB ∪ EDB and insert request A.\nProduce IDB ∪ EDB\\HS(j) as a result Let V := {c ∈ IC | IDB ∪ IC inconsistent with A with respect to c }\nreturn 5. Produce DDB as the result.\nend.\nExample 20."
    }, {
      "heading" : "IDB : p← a EDB : f ← IC :← b",
      "text" : "q ← a g ←\np← b ∧ f q ← b ∧ f p← g ∧ a\nSuppose we want to insert p. First, we need to check consistency with IC and afterwards, we have to find ∆i and ∆j via tree deduction.\nFrom algorithm 6 or 7 (only different is checking IC condition), the above example execute following steps:\nAlgorithm 7 View update algorithm based on Materialized view Input : A stratifiable (definite) deductive database DDB = IDB ∪ EDB ∪ IC\nan literals A Output: A new stratifiable (definite) database IDB ∪ EDB′ ∪ IC\nbegin 1. Construct a complete SLD-tree for← A with respect to DDB. 2. For every successful branch i:construct ∆i = {D | D ∈ EDB}\nand D is used as an input clause in branch i. 3. For every unsuccessful branch j:construct ∆j = {D | D ∈ EDB} and D is used as an input clause in branch j. 4. Let V := {c ∈ IC | IDB ∪ IC inconsistent with A with respect to c }\nWhile (V , ∅) Construct a branch i of an update tableau satisfying based on view\nfor IDB ∪ EDB and delete request A. Produce IDB ∪ EDB\\HS(i) as a result\nConstruct a branch j of an update magic set rule based on view for IDB ∪ EDB and insert request A.\nProduce IDB ∪ EDB\\HS(j) as a result Let V := {c ∈ IC | IDB ∪ IC inconsistent with A with respect to c }\nreturn 5. Produce DDB as the result.\nend.\nStep number with execution\n(Input) IDB : p← a, q ← a, p← b ∧ f, q ← b ∧ f, p← g ∧ a EDB : f ←, g ← IC :← b\n(0) {p← a; q ← a; p← b, f ; q ← b, f ; p← g, a; b; g}\n(1) {V = b}\n(2.1) a. a\nq p\nb. f\nb\na\nq p\nc. f\nb\na\nq p\ng\nd. g\nf\nb\na\nq\np\ng\n(2.2) a. a\nq p\nb. a\nq p\nc. a\nq p\ng\nd. g\na\nq\np\ng\n(3-4) ∆i = {a, g} and ∆j = {} (5) p← a; q ← a; p← g ∧ a; a, f, g\n(Output) IDB : p← a, q ← a, p← g ∧ a EDB′ : a←; f ←; g ← IC :← b\nThis approach for view update may not satisfy (KB*7.1) in general. But, as shown in the sequel, conformation to (KB*7.3) is guaranteed and thus this approach results in rational update.\nLemma 5. Let T be an update tableau based on a materialized view for IDB ∪ EDB and delete request ¬A (A), Similarly, let M be an update magic set rule. Let S be the set of all EDB-closed locally minimal abductive explanations for A with respect to IDB. Let S′ be the set of all EDB-cuts of T and EDB-seeds of M . Then, the following hold:\n• S ⊆ S′. • ∀∆′ ∈ S′ : ∃∆ ∈ S s.t. ∆ ⊆ ∆′. • ∀∆′ ∈ S′ : ∆′ ⊆ ⋃ S.\nProof.\n1. Consider a ∆(∆ ∈ ∆i ∪ ∆j) ∈ S. We need to show that ∆ is generated by algorithm 6 at step 2. From observation 4, it is clear that there exists a A-kernel X of DDBG s.t. X ∩ EDB = ∆j and X ∪ EDB = ∆i. Since X ` A, there must exist a successful derivation for A using only the elements of X as input clauses and similarly X 0 A. Consequently ∆ must have been constructed at step 2. 2. Consider a ∆′((∆′ ∈ ∆i ∪∆j) ∈ S′. Let ∆′ be constructed from a successful(unsuccessful) branch i via ∆i(∆j). Let X be the set of all input clauses used in the refutation i. Clearly X ` A(X 0 A). Further, there exists a minimal (with respect to set-inclusion) subset Y of X that derives A (i.e. no proper subset of Y derives A. Let ∆ = Y ∩ EDB (Y ∪ EDB). Since IDB does not (does) have any unit clauses, Y must contain some EDB facts, and so ∆ is not empty (empty) and obviously ∆ ⊆ ∆′. But, Y need not (need) be a A-kernel for IDBG since Y is not ground in general. But it stands for several A-kernels with the same (different) EDB facts ∆ in them. Thus, from observation 4, ∆ is a DDB-closed locally minimal abductive explanation for A with respect to IDBG and is contained in ∆′. minimal.\nLemma 6. Let S and S’ be sets of sets s.t. S ⊆ S′ and for every member X of S′\\S: X is a superset of some member of S and X is a subset of ⋃ S. Then, a set H is a hitting set for S iff it is a hitting set for S’\nProof.\n1. (If part) Given that H is a hitting set for S′, we have to show that it is a hitting set for S too. First of all, observe that ⋃ S = ⋃ S′, and so H ⊆ ⋃ S.\nMoreover, by definition, for every non-empty member X of S′, H ∩X is not empty. Since S ⊆ S′, it follows that H is a hitting set for S too.\n(Only if part) Suppose H is a hitting set for S. As observed above, H ⊆⋃ S′ . By definition, for every non-empty member X ∈ S, X ∩ H is not empty. Since every member of S′ is a superset of some member of S, it is clear that H hits every member of S′, and hence a hitting set for S′ .\nLemma 7. Let T and M as in Lemma 5. Then HS(b) is a rational hitting set for A, for every open finished branch b in T (close finished branch b in M).\nProof. Follows from the observation 4 (materialized view) in and (Behrend & Manthey 2008)\nTheorem 16. Algorithms 6 and 7 are rational, in the sense that they satisfy all the rationality postulates (KB*1) to (KB*6) and (KB*7.3).\nProof. Follows from Observation 4,7 and Theorem 7."
    }, {
      "heading" : "8.4 Incomplete to Complete Information",
      "text" : "Many of the proposals in the literature on incomplete databases have focussed on the extension of the relational model by the introduction of null values. In this section, we show how view update provides completion of incomplete information. More detailed surveys of this area can be found in (Meyden 1998).\nThe earliest extension of the relational model to incomplete information was that of Codd (Codd 1979) who suggested that missing values should be represented in tables by placing a special null value symbol ′∗′ at any table location for which the value is unknown. Table 5.3, shows an example of a database using this convention. Codd proposed an extension to the relational algebra for tables containing such nulls, based on three valued logic and a null substitution principle.\nIn terms of our general semantic scheme, the intended semantics of a database D consisting of Codd tables can be described by defining Mod(D) to be the set of structures MD′ , where D′ ranges over the relational databases obtained by replacing each occurrence of ′∗′ in the database D by some domain value. Different values may be substituted for different occurrences.\nA plausible integrity constraint on the meaning of a relational operator on tables in T is that the result should be a table that represents the set of relations obtained by pointwise application of the operator on the models of these tables. For example, if R and S are tables in T then the result of the join R Z S should be equal to a table T in T such that\nMod(T ) = {r Z t | r ∈Mod(R), s ∈Mod(S)}\nIn case the definitions of the operators satisfy this integrity constraint (with respect to the definition of the semantics Mod on T ).\nLet us consider what above equation requires if we take R and S to be the Codd Tables 5.3. First of all, note that in each model, if we take the value of the null in the tuple (delhibabu,*) to be v, then the join will contain one tuples (delhibabu, v), which include the value v. If T is to be a Codd table, it will need to contain tuples (delhibabu,X) to generate each of these tuples, where X are either constants or ’*’. We now face a problem. First, X cannot be a constant c, for whatever the choice of c we can find an instance r ∈Mod(R) and s ∈Mod(S) for which the tuple (delhibabu, c) does not occur in r Z s. If they were, X would have their values in models of T assigned independently.\nHere the repetition of ∗ indicates that the same value is to be occurrence of the null in constructing a model of the table. Unfortunately, this extension does not suffice to satisfy the integrity constraint (∀x, y, z (y=x) ← group chair(x,y) ∧ group chair(x,z)).\nIn the model of these tables in which ∗ = infor1, the join contains the tuple (delhibabu, infor1) and (infor1, aravindan).\nThe following table shows completion of incomplete information with application of integrity constraint and redundancy:"
    }, {
      "heading" : "8.5 A Comparative Study of view update algorithm and integrity constraint with our axiomatic method",
      "text" : "During the process of updating database, two interrelated problems could arise. On one hand, when an update is applied to the database, integrity constraints could become inconsistent with request, then stop the process. On the other hand, when an update request consist on updating some derived predicate, a view update mechanism must be applied to translate the update request into correct updates on the underlying base facts. Our work focus on the integrity constraint maintenance approach. In this section, we extend Mayol and Teniente’s (Mayol & Teniente 1999) survey for view update and integrity constraint.\nThe main aspects that must be taken into account during the process of view update and integrity constraint enforcement are the following: the problem addressed, the considered database schema, the allowed update requests, the used technique, update change and the obtained solutions. These six aspects provide the basic dimensions to be taken into account. We explain each dimension in this section and results are presented in Appendix.\nProblem Addressed\n(Type) - What kind of program to be used (stratified (S), Horn clause (H), Disjunctive database (D), Normal Logic program (N) and Other (O)). (View Update) - Whether they are able to deal with view update or not (indicated by Yes or No in the second column in the appendix section). (integrity-constraint Enforcement) - Whether they incorporate an integrity constraint checking (C)or an integrity constraint maintenance (M) or both apply (C-M) approach (indicated by check or maintain in the third column). (Run/Comp) - Whether the method follows a run-time (transaction) or a compiletime approach (indicated by Run or Compile in the fourth column).\nDatabase Schema Considered\n(Definition Language) - The language mostly used is logic (L), although some methods use a relational language (R) and also uses an object-oriented (OO). (The DB Schema Contains Views) - All methods that deal with view update need views to be defined in the database schema. Some of other method allow to define views. (Restrictions Imposed on the Integrity Constraints) - Some proposals impose certain restrictions on the kind of integrity constraints that can be defined and, thus, handled by their methods. (Static vs Dynamic Integrity Constraints) - Integrity constraints may be either static (S), and impose restrictions involving only a certain state of the database, or dynamic (D).\nUpdate Request Allowed\n(Multiple Update Request) - An update request is multiple if it contains several updates to be applied together to the database. (Update Operators) - Traditionally, three different basic update operators are distinguished: insertion (ι), deletion (δ) and modification (χ). Modification can always be simulated by a deletion followed by an insertion.\nUpdate Processing Mechanism\n(Applied Technique) - The techniques applied by these methods can be classified according to four different kinds of procedures, unfolding, SLD, active and predefined programs, respectively. (Taking Base Facts into Account - Base facts can either be taken into account or not during update processing.\n(User Participation) - User participation during update processing or not.\nUpdate Changing Mechanism\n(Type of modification) - Changing table by singleton like atom (S), sets of each types of modification(SS) and group of changes (G). (Changing Base Fact) - Base fact can be changed either using principle of minimal change or complete change (maximal change). (Changing View Definition) - Whether update process view definition is changed or not.\nObtained Solution\n(Our Axiom follow) - When update process done, we are comparing our axiomatized method and which relevance policy holds ((KB*1) to (KB*6),(KB*7.1),(KB*7.2) and (KB*7.3) is enumerated 1 to 9) (Soundness) - A method is correct if it only obtains solutions that satisfy the requested update, note NP mean Not Proved. (Completeness) - A method is complete if it is able to obtain all solutions that satisfy a given update request.\nResults of each method according to these features are summarized in Appendix."
    }, {
      "heading" : "9 Belief Update Vs Database Update",
      "text" : "In this section we give overview of how belief update is related to database update. This section is motivated by works of Hansson’s (Hansson 1991) and Keller’s (Keller 1985)"
    }, {
      "heading" : "9.1 View update vs Database update",
      "text" : "The view update problem exists already three decades Chen & Liao 2010 and Minker 1996. We are taking proof from Keller 1985, given a view definition of the question of choosing a view update translator arises.\nThis requires understanding the ways in which individual view update requests may be satisfied by database updates. Any particular view update request may result in a view state that does not correspond to any database state. Such a view update request may not be translated without relaxing the constraint which precludes view side effects. Otherwise, the update request is rejected by the view update translator. If we are lucky, there will be precisely one way to perform the database update that results in the desired view update. Since the view is many-to-one, the new view state may correspond to many database states. Of these database states, we would like to choose one that is ”as close as possible”, under some measure, to the original database state. That is, we would like to minimize the effect of the view update on the database."
    }, {
      "heading" : "9.2 Belief update vs Database update",
      "text" : "If we look closely to the section (6.3 and 8.1), we easily find the following results. With evidence of Hansson’s (Hansson 1991) and Liberatore (Liberatore & Schaerf 2004). Here BR and BU mean Belief Revision and Belief Update, respectively."
    }, {
      "heading" : "10 Abductive framework for Horn knowledge base dynamics",
      "text" : "As discussed in Section 5, we introduced Horn knowledge base dynamics to deal with two important points: first, to handle belief states that need not be\ndeductively closed; and the second point is the ability to declare certain parts of the belief as immutable. There is yet another, radically new approach to handle this problem, and this Section addresses this. In fact, this approach is very close to the Hansson’s (Hansson 1992) dyadic representation of belief. In the similar abduction model by Boutilier & Beche 1995 and Pagnucco 1996 Here, we consider the immutable part as defining a new logical system. By a logical system, we mean that it defines its own consequence relation and closure operator. Based on this, we provide an abductive framework for Horn knowledge base dynamics.\nA first order language consists of an alphabet A of a language L. We assume a countable universe of variables Var, ranged over x,y,z, and a countable universe of relation (i.e. predicate) symbols, ranged over by A are finite. The following defines FOL, the language of first order logic with equality and binary relations:\nϕ ::= x = x | a(x, x) | ¬ϕ | ∨ φ | ∧ φ | ∃X : φ.\nHere φ ⊆ FOL and X ⊆ V ar are finite sets of formulae and variables, respectively.\nDefinition 46 (Normal Logic Program (NLP) [22]). By an alphabet A of a language L we mean disjoint sets of constants, predicate symbols, and function symbols, with at least one constant. In addition, any alphabet is assumed to contain a countably infinite set of distinguished variable symbols. A term over A is defined recursively as either a variable, a constant or an expression of the form f(t1, ..., tn) where f is a function symbol of A, n its arity, and the ti are terms. An atom over A is an expression of the form P (t1, ..., tn) where P is a predicate symbol of A and the ti are terms. A literal is either an atom A or its default negation not A. We dub default literals those of the form not A. A term (atom or literal) is said ground if it does not contain variables. The set of all ground terms (atoms) of A is called the Herbrand universe (base) of A. A Normal Logic Program is a possibly infinite set of rules (with no infinite descending chains of syntactical dependency) of the form:\nH ← B1, ..., Bn, not C1, ..., not Cm, (with m, n ≥ 0)\nWhere H,Bi and Cj are atoms, and each rule stands for all its ground instances. In conformity with the standard convention, we write rules of the form H ← also simply as H (known as fact). An NLP P is called definite if none of its rules contain default literals. H is the head of the rule r, denoted by head(r), and body(r) denotes the set {B1, ..., Bn, not C1, ..., not Cm} of all the literals in the body of r.\nWhen doing problem modeling with logic programs, rules of the form\n⊥ ← B1, ..., Bn, not C1, ..., not Cm, (with m, n ≥ 0)\nwith a non-empty body are known as a type of integrity constraints (ICs), specifically denials, and they are normally used to prune out unwanted candidate solutions. We abuse the not default negation notation applying it to\nnon-empty sets of literals too: we write not S to denote {not s : s ∈ S}, and duality of not not a ≡ a. When S is an arbitrary, non-empty set of literals S = {B1, ..., Bn, not C1, ..., not Cm} we use:\n- S+ denotes the set {B1, . . . , Bn} of positive literals in S . - S− denotes the set {not C1, . . . , not Cm} of negative literals in S . - |S| = S+ ∪ (not S−) denotes the set {B1, . . . , Bn, C1, . . . , Cm} of atoms of S.\nAs expected, we say a set of literals S is consistent iff S+ ∩ |S−| = ∅. We also write heads(P ) to denote the set of heads of non-IC rules of a (possibly constrained) program P , i.e. heads(P ) = {head(r) : r ∈ P}\\{⊥}, and facts(P ) to denote the set of facts of P - facts(P ) = {head(r) : r ∈ P ∧ body(r) = ∅}.\nDefinition 47 (Level mapping[4]). Let P be a normal logic program and BP its Herbrand base. A level mapping for P is a function ‖: BP → N of ground atoms to natural numbers. The mapping ‖ is also extended to ground literals by assigning | ¬A | = | A | for all ground atoms A ∈ BP . For every ground literal L, | L | is called as the level of L in P.\nDefinition 48 (Acyclic program [4]). Let P be a normal logic program and ‖ a level mapping for P. P is called as acyclic with respect to ‖ if for every ground clause H ← L1, ..., Ln (with n ≥ 0 and finit) in P the level of A is higher then the level of every Li (1 ≤i≤ n). Moreover P is called acyclic if P is acyclic with respect to some level mapping for P.\nUnlike Horn knowledge base dynamics, where knowledge is defined as a set of sentences, here we wish to define a Horn knowledge base KB with respect to a language L, as an abductive framework < P,Ab, IC,K >, where,\n* P is an acyclic normal logic program with all abducibles in P at level 0 and no non-abducible at level 0. P is referred to as a logical system. This in conjunction with the integrity constraints corresponds to immutable part of the Horn knowledge base, here P is defined by immutable part. This is discussed further in the next subsection;\n* Ab is a set of atoms from L, called the abducibles. This notion is required in an abductive framework, and this corresponds to the atoms that may appear in the updatable part of the knowledge;\n* IC is the set of integrity constraints, a set of sentences from language L. This specifies the integrity of a Horn knowledge base and forms a part of the knowledge that can not be modified over time;\n* K is a set of sentences from L. It is the current knowledge, and the only part of KB that changes over time. This corresponds to the updatable part of the Horn knowledge base. The main requirement here is that no sentence in K can have an atom that does not appear in Ab."
    }, {
      "heading" : "10.1 Logical system",
      "text" : "The main idea of our approach is to consider the immutable part of the knowledge to define a new logical system. By a logical system, we mean that P defines its own consequence relation |=P and its closure Cnp. Given P , we have the Herbrand Base HBP and GP , the ground instantiation of P .\nAn abductive interpretation I is a set of abducibles, i.e. I ⊆ Ab. How I interprets all the ground atoms of L 4 is defined, inductively on the level of atoms with respect to P , as follows:\n* An atom A at level 0 (note that only abducibles are at level 0) is interpreted as: A is true in I iff A ∈ I, else it is false in I. * An atom (literal) A at level n is interpreted as: A is true in I iff ∃ clause A← L1, . . . , Ln in GP s.t. ∀Lj (1 ≤ j ≤ n) if Lj is an atom then Lj is true in I, else if Lj is a negative literal ¬Bj , then Bj is false in I.\nThis interpretation of ground atoms can be extended, in the usual way, to interpret sentences in L, as follows (where α and β are sentences):\n* ¬α is true in I iff α is false in I. * α ∧ β is true in I iff both α and β are true in I. * α ∨ β is true in I iff either α is true in I or β is true in I. * ∀α is true in I iff all ground instantiations of α are true in I. * ∃α is true in I iff some ground instantiation of α is true in I.\nGiven a sentence α in L, an abductive interpretation I is said to be an abductive model of α iff α is true in I. Extending this to a set of sentences K, I is a abductive model of K iff I is an abductive model of every sentence α in K.\nGiven a set of sentences K and a sentence α, α is said to be a P -consequence of K, written as K |=P α, iff every abductive model of K is an abductive model of α also. Putting it in other words, letMod(K) be the set of all abductive models of K. Then α is a P -consequence of K iff α is true in all abductive interpretations in Mod(K). The consequence operator CnP is then defined as CnP (K) = {α | K |=P α} = {α | α is true in all abductive interpretations in Mod(K)}. K is said to be P-consistent iff there is no expression α s.t. α ∈ CnP (K) and ¬α ∈ CnP (K). Two sentences α and β are said to be P -equivalent to each other, written as α ≡ β, iff they have the same set of abductive models , i.e. Mod(α) = Mod(β)."
    }, {
      "heading" : "Properties of consequences operator",
      "text" : "Since a new consequence operator is defined, it is reasonable, to ask whether it satisfies certain properties that are required in the Horn knowledge base dynamics context. Here, we observe that all the required properties, listed by various researchers in Horn knowledge base dynamics, are satisfied by the defined consequence operator. The following propositions follow from the above definitions, and can be verified easily. 4 the set of all the ground atoms of L, in fact depends of L, and is given as HBP , the\nHerbrand Base of P\nCnP satisfies inclusion, i.e. K ⊆ CnP (K).\nCnP satisfies iteration, i.e. CnP (K) = CnP (CnP (K)).\nAnther interesting property is monotony, i.e. if K ⊆ K ′, then CnP (K) ⊆ CnP (K ′). CnP satisfies monotony. To see this, first observe that Mod(K ′) ⊆ Mod(K).\nCnP satisfies superclassicality , i.e. if α can be derived from K by first order classical logic, then α ∈ CnP (K).\nCnP satisfies deduction , i.e. if β ∈ CnP (K ∪ {α}), then (β ← α) ∈ Cn(K). CnP satisfies compactness , i.e. if α ∈ CnP (K), then α ∈ CnP (K ′) for some\nfinite subset K ′ of K.\nStatics of a Horn knowledge base The statics of a Horn knowledge base KB, is given by the current knowledge K and the integrity constraints IC. An abductive interpretation M is an abductive model of KB iff it is an abductive model of K ∪ IC. Let Mod(KB) be the set of all abductive models of KB. The belief set represented by KB, written as KB• is given as,\nKB• = CnP (K ∪ IC) = {α|α is true in every abductive model of KB}.\nA belief (represented by a sentence in L) α is accepted in KB iff α ∈ KB• (i.e. α is true in every model of KB). α is rejected in KB iff ¬α ∈ KB• (i.e. α is false in every model of KB). Note that there may exist a sentence α s.t. α is neither accepted nor rejected in KB (i.e. α is true in some but not all models of KB), and so KB represents a partial description of the world.\nTwo Horn knowledge bases KB1 and KB2 are said to be equivalent to each other, written as KB1 ≡ KB2, iff they are based on the same logical system and their current knowledge are P -equivalent, i.e. P1 = P2, Ab1 = Ab2, IC1 = IC2 and K1 ≡ K2. Obviously, two equivalent Horn knowledge bases KB1 and KB2 represent the same belief set, i.e. KB•1 = KB•2 ."
    }, {
      "heading" : "10.2 Horn knowledge base dynamics",
      "text" : "In AGM (Alchourron et al. 1985b) three kinds of belief dynamics are defined: expansion, contraction and revision. We consider all of them, one by one, in the sequel."
    }, {
      "heading" : "Expansion",
      "text" : "Let α be new information that has to be added to a knowledge base KB. Suppose ¬α is not accepted in KB. Then, obviously α is P - consistent with IC, and KB can be expanded by α, by modifying K as follows:\nKB + α ≡< P,Ab, IC,K ∪ {α} >\nNote that we do not force the presence of α in the new K, but only say that α must be in the belief set represented by the expanded Horn knowledge base. If in case ¬α is accepted in KB (in other words, α is inconsistent with IC), then expansion of KB by α results in a inconsistent Horn knowledge base with no abductive models, i.e. (KB + α)• is the set of all sentences in L.\nPutting it in model-theoretic terms, KB can be expanded by a sentence α, when α is not false in all models of KB. The expansion is defined as:\nMod(KB + α) = Mod(KB) ∩Mod(α).\nIf α is false in all models of KB, then clearly Mod(KB+α) is empty, implying that expanded Horn knowledge base is inconsistent."
    }, {
      "heading" : "Revision",
      "text" : "As usual, for revising and contracting a Horn knowledge base, the rationality of the change is discussed first. Later a construction is provided that complies with the proposed rationality postulates."
    }, {
      "heading" : "Rationality postulates",
      "text" : "Let KB =< P,Ab, IC,K > be revised by a sentence α to result in a new Horn knowledge base KB u α =< P ′, Ab′, IC ′,K ′ >. When a Horn knowledge base is revised, we do not (generally) wish to modify the underlying logical system P or the set of abducibles Ab. This is refereed to as inferential constancy by Hansson (Hansson 1991 & 1992).\n(u1) (Inferential constancy) P ′ = P and Ab′ = Ab,IC ′ = IC. (u2) (Success)α is accepted in KB u α , i.e. α is true in all models of KB u α. (u3) (Consistency) α is satisfiable and P -consistent with IC iff KB u α is Pconsistent, i.e. Mod({α} ∪ IC) is not empty iff Mod(KB u α) is not empty. (u4) (Vacuity) If ¬α is not accepted in KB, then KB u α ≡ KB + α, i.e. if α is not false in all models of KB, then Mod(KB u α) = Mod(KB) ∩Mod(α). (u5) (Preservation)If KB ≡ KB′ and α ≡ β, then KB u α ≡ KB′ u β, i.e. if\nMod(KB) = Mod(KB′) and Mod(α) = Mod(β), then Mod(KB u α) = Mod(KB u β).\n(u6) (Extended Vacuity 1)(KB u α) + β implies KB u (α ∧ β), i.e. (Mod(KB u α) ∩Mod(β)) ⊆Mod(KB u (α ∧ β)). (u7) (Extended Vacuity 2)If ¬β is not accepted in (KB u α), then KB u (α ∧ β) implies (KB u α) + β, i.e. if β is not false in all models of KB u α, then Mod(KB u (α ∧ β)) ⊆ (Mod(KB u α) ∩Mod(β))."
    }, {
      "heading" : "Construction",
      "text" : "Let S stand for the set of all abductive interpretations that are consistent with IC, i.e. S = Mod(IC). We do not consider abductive interpretations that are not models of IC, simply because IC does not change during revision. Observe that when IC is empty, S is the set of all abductive interpretations. Given a Horn\nknowledge base KB, and two abductive interpretations I1 and I2 from S, we can compare how close these interpretations are to KB by using an order ≤KB among abductive interpretations in S. I1 <KB I2 iff I1 ≤KB I2 and I2 KB I1.\nLet F ⊆ S. An abductive interpretation I ∈ F is minimal in F with respect to ≤KB if there is no I ′ ∈ F s.t. I ′ <KB I. Let, Min(F ,≤KB) = {I | I is minimal in F with respect to ≤KB}.\nFor any Horn knowledge base KB, the following are desired properties of ≤KB :\n(≤ 1) (Pre-order)≤KB is a pre-order , i.e. it is transitive and reflexive. (≤ 2) (Connectivity)≤KB is total in S, i.e. ∀I1, I2 ∈ S: either I1 ≤KB I2 or I2 ≤KB I1. (≤ 3) (Faithfulness)≤KB is faithful to KB, i.e. I ∈Min(S,≤KB) iff I ∈Mod(KB). (≤ 4) (Minimality)For any non-empty subset F of S, Min(F ,≤KB) is not empty. (≤ 5) (Preservance)] For any Horn knowledge base KB’, if KB ≡ KB′ then\n≤KB=≤KB′ .\nLet KB (and consequently K) be revised by a sentence α, and ≤KB be a rational order that satisfies (≤ 1) to (≤ 5). Then the abductive models of the revised Horn knowledge base are given precisely by: Min(Mod({α}∪IC),≤KB). Note that, this construction does not say what the resulting K is, but merely says what should be the abductive models of the new Horn knowledge base."
    }, {
      "heading" : "Representation theorem",
      "text" : "Now, we proceed to show that revision of KB by α, as constructed above, satisfies all the rationality postulates stipulated in the beginning of this section. This is formalized by the following lemma.\nLemma 8. Let KB be a Horn knowledge base, ≤KB an order among S that satisfies (≤ 1) to (≤ 5). Let a revision operator u be defined as: for any sentence α, Mod(KB u α) = Min(Mod({α} ∪ IC),≤KB). Then u satisfies all the rationality postulates for revision (u1) to (u7).\nProof.(u1) P ′ = P and Ab′ = Ab and IC ′ = IC This is satisfied obviously, since our construction does not touch P and Ab, and IC follows from every abductive interpretation in Mod(KB u α). (u2) α is accepted in KB u α Note that every abductive interpretation M ∈ Mod(KB + α) is a model of α. Hence α is accepted in KB u α. (u3) α is satisfiable and P -consistent with IC iff KB u α is P -consistent. If part: If KB u α is P -consistent , then Mod(KB u α) is not empty. This implies that Mod({α} ∪ IC) is not empty, and hence α is satisfiable and P -consistent with IC. Only if part: If α is satisfiable and P-consistent with IC, then Mod({α}∪IC) is not empty, and (≤ 4) ensures that Mod(KB u α) is not empty. Thus, KB u α is P -consistent.\n(u4) If ¬α is not accepted in KB, then KB u α ≡ KB + α. We have to establish thatMin(Mod({α}∪IC),≤KB) = Mod(KB)∩Mod(α). Since ¬α is not accepted in KB, Mod(KB)∩Mod(α) is not empty. The required result follows immediately from the fact that ≤KB is faithful to KB (i.e. satisfies ≤ 3), which selects only and all those models of α which are also models of KB. (u5) If KB ≡ KB′ and α ≡ β then KB u α = KB′ u β (≤ 5) ensures that ≤KB=≤KB′ . The required result follows immediately from this and the fact that Mod(α) = Mod(β). (u6) (KB u α) + β implies KB u (α ∧ β). We consider this in two cases. When ¬β is accepted in KBuα, (KBuα)+β is the set of all sentences from L, and the postulate follows immediately. Instead when ¬β is not accepted in KB u α, this postulates coincides with the next one. (u7) If ¬β is not accepted in KB u α, then KB u (α ∧ β) implies (KB u α) + β. Together with the second case of previous postulate, we need to show that KB u (α ∧ β) = (KB u α) + β. In other words, we have to establish that Min(Mod({α ∧ β} ∪ IC),≤KB) = Mod(KB u α) ∩Mod(β). For the sake of simplicity, let us represent Min(Mod({α ∧ β} ∪ IC),≤KB) by P, and Mod(KB u α) ∩Mod(β), which is the same as Min(Mod({α} ∪ IC),≤KB ) ∩Mod(β), by Q. The required result is obtained in two parts:\n1) ∀ (abductive interpretation)M: if M ∈ P , then M ∈ Q Obviously M ∈ Mod(β). Assume that M < Min(Mod({α} ∪ IC),≤KB). This can happen in two cases, and we show that both the cases lead to contradiction. Case A: No model of β is selected by ≤KB from Mod({α} ∪ IC). But this contradicts our initial condition that ¬β is not accepted in KB u α. Case B: Some model, say M ′, of β is selected by ≤KB from Mod({α}∪ IC). Since M is not selected, it follows that M ′ <KB M . But then this contradicts our initial assumption that M ∈ P . So, P ⊆ Q. 2) ∀ (abductive interpretation)M: if M ∈ Q, then M ∈ P M ∈ Q implies that M is a model of both α and β, and M is selected by ≤KB from Mod({α}∪IC). Note that Mod({α∧β}∪IC) ⊆Mod({α}∪IC). Since M is selected by ≤KB in a bigger set (i.e. Mod({α}∪IC)), ≤KB must select M from its subset Mod({α ∧ β} ∪ IC) also. Hence Q ⊆ P .\nBut, that is not all. Any rational revision of KB by α, that satisfies all the rationality postulates, can be constructed by our construction method, and this is formalized below.\nLemma 9. Let KB be a Horn knowledge base and u a revision operator that satisfies all the rationality postulates for revision (u1) to (u7). Then, there exists an order ≤KB among S, that satisfies (≤ 1) to (≤ 5), and for any sentence α, Mod(KB u α) is given in Min(Mod({α} ∪ IC),≤KB).\nProof. Let us construct an order ≤KB among interpretations in S as follows: For any two abductive interpretations I and I ′ in S, define I ≤KB I ′ iff either\nI ∈ Mod(KB) or I ∈ Mod(KB u form(I, I ′)), where form(I, I ′) stands for sentence whose only models are I and I ′. We will show that ≤KB thus constructed satisfies (≤ 1) to (≤ 5) and Min(Mod({α} ∪ IC),≤KB) = Mod(KB u α).\nFirst, we show that Min(Mod({α} ∪ IC),≤KB) = Mod(KB u α).Suppose α is not satisfiable, i.e. Mod(α) is empty, or α does not satisfy IC, then there are no abductive models of {α} ∪ IC, and hence Min(Mod({α} ∪ IC),≤KB) is empty. From (u3), we infer that Mod(KB u α) is also empty. When α is satisfiable and α satisfies IC, the required result is obtained in two parts:\n1) If I ∈Min(Mod({α} ∪ IC),≤KB), then I ∈Mod(KB u α) Since α is satisfiable and consistent with IC, (u3) implies that there exists at least one model, say I ′, for KBuα. From (u1), it is clear that I ′ is a model of IC, from (u2) we also get that I ′ is a model of α, and consequently I ≤KB I ′ (because I ∈ Min(Mod({α} ∪ IC),≤KB)). Suppose I ∈ Mod(KB), then (u4) immediately gives I ∈ Mod(KB u α). If not, from our definition of ≤KB, it is clear that I ∈Mod(KBuform(I, I ′)). Note that α∧form(I, I ′) ≡ form(I, I ′), since both I and I ′ are models of α. From (u6) and (u7), we get Mod(KBuα)∩{I, I ′} = Mod(KBuform(I, I ′)). Since I ∈Mod(KBu form(I, I ′)), it immediately follows that I ∈Mod(KB u α). 2) If I ∈Mod(KB u α), then I ∈Min(Mod({α} ∪ IC),≤KB). From (u1) we get I is a model of IC, and from (u2), we obtain I ∈Mod(α). Suppose I ∈ Mod(KB), then from our definition of ≤KB, we get I ≤KB I ′, for any other model I ′ of α and IC, and hence I ∈ Min(Mod({α} ∪ IC),≤KB). Instead, if I is not a model of KB, then, to get the required result, we should show that I ∈Mod(KB u form(I, I ′)), for every model I ′ of α and IC. As we have observed previously, from (u6) and (u7), we get Mod(KBuα)∩{I, I ′} = Mod(KBuform(I, I ′)). Since I ∈Mod(KBuα), it immediately follows that I ∈Mod(KBuform(I, I ′)). Hence I ≤KB I ′ for any model I ′ of α and IC, and consequently, I ∈Min(Mod({α}∪IC),≤KB ).\nNow we proceed to show that the order ≤KB among S, constructed as per our definition, satisfies all the rationality axioms (≤ 1) to (≤ 5).\n(≤ 1) ≤KB is a pre-order. Note that we need to consider only abductive interpretations from S. From (u2) and (u3), we have Mod(KB u form(I, I ′)) = {I}, and so I ≤KB I. Thus ≤KB satisfies reflexivity. let I1 ∈ Mod(IC) and I2 < Mod(IC). Clearly, it is possible that two interpretations I1 and I2 are not models of KB, and Mod(KB u form(I1, I2)) = {I1}. So, I1 ≤KB I2 does not necessarily imply I2 ≤KB I1, and thus ≤KB satisfies anti-symmetry. To show the transitivity, we have to prove that I1 ≤KB I3, when I1 ≤KB I2 and I2 ≤KB I3 hold. Suppose I1 ∈Mod(KB), then I1 ≤KB I3 follows immediately from our definition of ≤KB. On the other case, when I1 <Mod(KB), we first observe that I1 ∈Mod(KBuform(I1, I2)), which follows from definition of ≤KB and I1 ≤KB I2. Also observe that I2 <Mod(KB). If I2 were\na model of KB, then it follows from (u4) that Mod(KB u form(I1, I2)) = Mod(KB)∩{I1, I2} = {I2}, which is a contradiction, and so I2 <Mod(KB). This, together with I2 ≤KB I3, implies that I2 ∈ Mod(KB u form(I2, I3)). Now consider Mod(KB+ form(I1, I2, I3)). Since u satisfies (u2) and (u3), it follows that this is a non-empty subset of {I1, I2, I3}. We claim that Mod(KB u form(I1, I2, I3))∩{I1, I2} can not be empty. If it is empty, then it means that Mod(KB u form(I1, I2, I3)) = {I3}. Since u satisfies (u6) and (u7), this further implies that Mod(KB u form(I2, I3)) = Mod(KB u form(I1, I2, I3))∩{I2, I3} = {I3}. This contradicts our observation that I2 ∈ Mod(KBuform(I2, I3)), and so Mod(KBuform(I1, I2, I3))∩{I1, I2} can not be empty. Using (u6) and (u7) again, we get Mod(KBuform(I1, I2)) = Mod(KB u form(I1, I2, I3))∩{I1, I2}. Since we know that I1 ∈Mod(KB u form(I1, I2)), it follows that I1 ∈ Mod(KB u form(I1, I2, I3)). From (u6) and (u7) we also get Mod(KBuform(I1, I3)) = Mod(KB+form(I1, I2, I3))∩ {I1, I3}, which clearly implies that I1 ∈Mod(KB u form(I1, I3)). From our definition of ≤KB, we now obtain I1 ≤KB I3. Thus, ≤KB is a pre-order.\n(≤ 2) ≤KB is total. Since u satisfies (u2) and (u3), for any two abductive interpretations I and I ′ in S, it follows that Mod(KB u form(I, I ′)) is a non-empty subset of {I, I ′}. Hence, ≤KB is total. (≤ 3) ≤KB is faithful to KB. From our definition of ≤KB, it follows that ∀I1, I2 ∈Mod(KB) : I1 <KB I2 does not hold. Suppose I1 ∈ Mod(KB) and I2 < Mod(KB). Then, we have I1 ≤KB I2. Since u satisfies (u4), we also have Mod(KB u form(I1, I2)) = {I1}. Thus, from our definition of ≤KB, we can not have I2 ≤KB I1. So, if I1 ∈ Mod(KB) and I2 < Mod(KB), then I1 <KB I2 holds. Thus, ≤KB is faithful to KB.\n(≤ 4) For any non-empty subset F of S, Min(F ,≤KB) is not empty. Let α be a sentence such that Mod({α} ∪ IC) = F . We have already shown that Mod(KB u α) = Min(F ,≤KB). Since, u satisfies (u3), it follows that Mod(KB u α) is not empty, and thus Min(F ,≤KB) is not empty. (≤ 5) If KB ≡ KB′, then ≤KB=≤KB′ . This follows immediately from the fact that u satisfies (u5).\nThus, the order among interpretations ≤KB , constructed as per our definition, satisfies (≤ 1) to (≤ 5), and Mod(KB uα) = Min(Mod({α}∪ IC),≤KB).\nSo, we have a one to one correspondence between the axiomatization and the construction, which is highly desirable, and this is summarized by the following representation theorem.\nTheorem 17. Let KB be revised by α, and KB u α be obtained by the construction discussed above. Then, u is a revision operator iff it satisfies all the rationality postulates (u1) to (u7).\nProof. Follows from Lemma 8 and Lemma 9"
    }, {
      "heading" : "Contraction",
      "text" : "Contraction of a sentence from a Horn knowledge base KB is studied in the same way as that of revision. We first discuss the rationality of change during contraction and proceed to provide a construction for contraction using duality between revision and contraction."
    }, {
      "heading" : "Rationality Postulates",
      "text" : "Let KB =< P,Ab, IC,K > be contracted by a sentence α to result in a new Horn knowledge base KB−̇α =< P ′, Ab′, IC ′,K ′ >.\n(−̇1) (Inferential Constancy)P ′ = P and Ab′ = Ab and IC ′ = IC. (−̇2) (Success)If α < CnP (KB), then α is not accepted in KB−̇α, i.e. if α is not\ntrue in all the abductive interpretations, then α is not true in all abductive interpretations in Mod(KB−̇α).\n(−̇3) (Inclusion)∀ (belief) β:if β is accepted in KB−̇α, then β is accepted in KB, i.e. Mod(KB) ⊆Mod(KB−̇α). (−̇4) (Vacuity)If α is not accepted in KB, then KB−̇α = KB, i.e. if α is not true in all the abductive models of KB, then Mod(KB−̇α) = Mod(KB). (−̇5) (Recovery)(KB−̇α)+α impliesKB, i.e.Mod(KB−̇α)∩Mod(α) ⊆Mod(KB). (−̇6) (Preservation)If KB ≡ KB′ and α ≡ β, then KB−̇α = KB′−̇β, i.e. if\nMod(KB) = Mod(KB′) and Mod(α) = Mod(β), then Mod(KB−̇α) = Mod(KB′−̇β).\n(−̇7) (Conjunction 1) KB−̇(α∧ β) implies KB−̇α∩KB−̇β, i.e. Mod(KB−̇(α∧ β)) ⊆Mod(KB−̇α) ∪Mod(KB−̇β). (−̇8) (Conjunction 2)If α is not accepted in KB−̇(α ∧ β), then KB−̇α implies KB−̇(α ∧ β), i.e. if α is not true in all the models of KB−̇(α ∧ β), then Mod(KB−̇α) ⊆Mod(KB−̇(α ∧ β)).\nBefore providing a construction for contraction, we wish to study the duality between revision and contraction. The Levi and Harper identities still holds in our case, and is discussed in the sequel.\nRelationship between contraction and revision Contraction and revision are related to each other. Given a contraction function −̇, a revision function u can be obtained as follows:\n(Levi Identity) Mod(KB u α) = Mod(KB−̇¬α) ∩Mod(α)\nThe following theorem formally states that Levi identity holds in our approach.\nTheorem 18. Let −̇ be a contraction operator that satisfies all the rationality postulates (−̇1) to (−̇8). Then, the revision function u, obtained from −̇ using the Levi Identity, satisfies all the rationality postulates (u1) to (u7).\nProof. Let KB =< P,Ab, IC,K > be contracted by a sentence α to result in a new Horn knowledge base KB−̇α =< P ′, Ab′, IC ′,K ′ >.\n(u1) (Inferential constancy) P ′ = P and Ab′ = Ab,IC ′ = IC. (u2) (Success)α is accepted inKBuα , i.e. α is true in all models of (Mod(KB−̇¬α)∩ Mod(α)). (u3) (Consistency) α is satisfiable and P -consistent with IC iff KB u α is P-\nconsistent, i.e. (Mod({α} ∪ IC)) is not empty iff Mod(KB−̇¬α) ∩Mod(α) is not empty.\n(u4) (Vacuity) If ¬α is not accepted in KB, then KB u α ≡ KB + α, i.e. if α is not false in all models of KB, then (Mod(KB u α)) = (Mod(KB−̇¬α) ∩ Mod(α)) ∩Mod(α) (u5) (Preservation)If KB ≡ KB′ and α ≡ β, then KB u α ≡ KB′ u β, i.e. if Mod(KB) = Mod(KB′) and Mod(α) = Mod(β), then (Mod(KB−̇¬α) ∩ Mod(α)) = (Mod(KB−̇¬β) ∩Mod(β)). (u6) (Extended Vacuity 1)(KB u α) + β implies ((KB−̇¬α) ∩ (α)) ∧ β), i.e. (Mod(KB u α) ∩Mod(β)) ⊆Mod(KB u (α ∧ β)). (u7) (Extended Vacuity 2)If ¬β is not accepted in (KB u α), then ((KB−̇¬α) ∩ (α))∧ β) implies (KB uα) + β, i.e. if β is not false in all models of KB uα, then Mod(KB u (α ∧ β)) ⊆ (Mod(KB u α) ∩Mod(β)).\nSimilarly, a contraction function −̇ can be constructed using the given revision function u as follows:\n(Harper Identity) Mod(KB−̇α) = Mod(KB) ∪Mod(KB u ¬α)\nTheorem 19. Let u be a revision operator that satisfies all the rationality postulates (u1) to (u7). Then, the contraction function −̇, obtained from u using the Harper Identity, satisfies all the rationality postulates (−̇1) to (−̇8).\nProof. Let KB =< P,Ab, IC,K > be contracted by a sentence α to result in a new Horn knowledge base KB−̇α =< P ′, Ab′, IC ′,K ′ >.\n(−̇1) (Inferential Constancy)P ′ = P and Ab′ = Ab and IC ′ = IC. (−̇2) (Success)If α < CnP (KB), then α is not accepted in KB−̇α, i.e. if α is not\ntrue in all the abductive interpretations, then α is not true in all abductive interpretations in Mod(KB) ∪Mod(KB u ¬α).\n(−̇3) (Inclusion)∀ (belief) β:if β is accepted in KB−̇α, then β is accepted in KB, i.e. Mod(KB) ⊆ (Mod(KB) ∪Mod(KB u ¬α)). (−̇4) (Vacuity)If α is not accepted in KB, then KB−̇α = KB, i.e. if α is not true in all the abductive models of KB, then Mod(KB−̇α) = Mod(KB). (−̇5) (Recovery)(KB−̇α)+α impliesKB, i.e. (Mod(KB−̇α)∩Mod(α)) ⊆Mod(KB). (−̇6) (Preservation)If KB ≡ KB′ and α ≡ β, then KB−̇α = KB′−̇β, i.e.\nif Mod(KB) = Mod(KB′) and Mod(α) = Mod(β), then (Mod(KB) ∪ Mod(KB u ¬α)) = (Mod(KB) ∪Mod(KB u ¬β)).\n(−̇7) (Conjunction 1) KB−̇(α∧ β) implies KB−̇α∩KB−̇β, i.e. Mod(KB−̇(α∧ β)) ⊆ (Mod(KB) ∪Mod(KB u ¬α)) ∪ (Mod(KB) ∪Mod(KB u ¬β)). (−̇8) (Conjunction 2)If α is not accepted in KB−̇(α ∧ β), then KB−̇α implies KB−̇(α ∧ β), i.e. if α is not true in all the models of KB−̇(α ∧ β), then (Mod(KB) ∪Mod(KB u ¬α)) ⊆Mod(KB−̇(α ∧ β))."
    }, {
      "heading" : "Construction",
      "text" : "Given the construction for revision, based on order among interpretation in S, a construction for contraction can be provided as:\nMod(KB−̇α) = Mod(KB) ∪Min(Mod({¬α} ∪ IC),≤KB), where ≤KB is the relation among interpretations in S that satisfies the rationality axioms (≤ 1) to (≤ 5). As in the case of revision, this construction says what should be the models of the resulting Horn knowledge base, and does not explicitly say what the resulting Horn knowledge base is."
    }, {
      "heading" : "Representation theorem",
      "text" : "Since the construction for contraction is based on a rational contraction for revision, the following lemma and theorem follow obviously. Lemma 10. Let KB be a Horn knowledge base, ≤KB an order among S that satisfies (≤ 1) to (≤ 5). Let a contraction operator −̇ be defined as: for any sentence α, Mod(KB−̇α) = Mod(KB) ∪Min(Mod({¬α} ∪ IC),≤KB). Then −̇ satisfies all the rationality postulates for contraction (−̇1) to (−̇8). Proof. Follows from Theorem 17 and Theorem 19 Lemma 11. Let KB be a Horn knowledge base and −̇ a contraction operator that satisfies all the rationality postulates for contraction (−̇1) to (−̇8). Then, there exists an order ≤KB among S, that satisfies(≤ 1) to (≤ 5), and for any sentence α, Mod(KB−̇α) is given as Mod(KB)∪Min(Mod({¬α}∪IC),≤KB). Proof. Follows from Theorem 18 and Theorem 19. Theorem 20. Let KB be contracted by α, and KB−̇α be obtained by the construction discussed above. Then −̇ is a contraction operator iff it satisfies all the rationality postulates (−̇1) to (−̇8). Proof. Follows from Lemma 10 and Lemma 11"
    }, {
      "heading" : "10.3 Relationship with the coherence approach of AGM",
      "text" : "Given Horn knowledge base KB =< P,Ab, IC,K > represents a belief set KB• that is closed under CnP . We have defined how KB can be expanded, revised, or contracted. The question now is: does our foundational approach (with respect to classical first-order logic) on KB coincide with coherence approach (with respect to our consequence operator CnP ) of AGM on KB•? There is a problem in answering this question (similar practical problem Baral & Zhang 2005) , since our approach, we require IC to be immutable, and only the current knowledge K is allowed to change. On the contrary, AGM approach treat every sentence in KB• equally, and can throw out sentences from CnP (IC). One way to solve this problem is to assume that sentences in CnP (IC) are more entrenched than others. However, one-to-one correspondence can be established, when IC is empty. The key is our consequence operator CnP , and in the following, we show that coherence approach of AGM with this consequence operator, is exactly same as our foundational approach, when IC is empty."
    }, {
      "heading" : "Expansion",
      "text" : "Expansion inAGM (Alchourron et al. 1985b) framework is defined asKB#α = CnP (KB• ∪ {α}), is is easy to see that this is equivalent to our definition of expansion (when IC is empty), and is formalized below.\nTheorem 21. Let KB + α be an expansion of KB by α. Then (KB + α)• = KB#α.\nProof. By our definition of expansion, (KB+α)• = CnP (IC ∪K ∪{α}), which is clearly the same set as CnP (KB• ∪ {α})."
    }, {
      "heading" : "Revision",
      "text" : "AGM puts forward rationality postulates (∗1) to (∗8) to be satisfied by a revision operator on KB•. reproduced below:\n(*1) (Closure) KB• ∗ α is a belief set. (*2) (Success) α ∈ KB• ∗ α. (*3) (Expansion 1) KB• ∗ α ⊆ KB•#α. (*4) (Expansion 2) If ¬α < KB•, then KB•#α ⊆ KB• ∗ α. (*5) (Consistency)KB• ∗ α is inconsistent iff ` ¬α. (*6) (Preservation) If ` α↔ β, then KB• ∗ α = KB• ∗ β. (*7) (Conjunction 1) KB• ∗ (α ∧ β) ⊆ (KB• ∗ α)#β. (*8) (Conjunction 2) If ¬β < KB• ∗ α, then,(KB• ∗ α)#β ⊆ KB• ∗ (α ∧ β).\nThe equivalence between our approach and AGM approach is brought out by the following two theorems.\nTheorem 22. Let KB a Horn knowledge base with an empty IC and u be a revision function that satisfies all the rationality postulates (u1) to (u7). Let a revision operator ∗ on KB• be defined as: for any sentence α, KB• ∗ α = (KBuα)•. The revision operator *, thus defined satisfies all the AGM -postulates for revision (∗1) to (∗8).\nProof.\n(*1) KB• ∗ α is a belief set. This follows immediately, because (KB u α)• is closed with respect to CnP . (*2) α ∈ KB• ∗ α. This follows from the fact that u satisfies (u2). (*3) KB• ∗ α ⊆ KB•#α.\n(*4) If ¬α < KB•, then KB•#α ⊆ KB• ∗ α. These two postulates follow from (u4) and theorem 21. (*5) KB• ∗ α is inconsistent iff ` ¬α. This follows from from (u3) and our assumption that IC is empty. (*6) If ` α↔ β, then KB• ∗ α = KB• ∗ β. This corresponds to (u5). (*7) KB• ∗ (α ∧ β) ⊆ (KB• ∗ α)#β. This follows from (u6) and theorem 21.\n(*8) If ¬β < KB• ∗ α, then,(KB• ∗ α)#β ⊆ KB• ∗ (α ∧ β). This follows from (u7) and theorem 21\nTheorem 23. Let KB a Horn knowledge base with an empty IC and * a revision operator that satisfies all the AGM -postulates (∗1) to (∗8). Let a revision function + on KB be defined as: for any sentence α, (KB u α)• = KB• ∗ α. The revision function +, thus defined, satisfies all the rationality postulates (u1) to (u7).\nProof.\n(u1) P,Ab and IC do not change. Obvious. (u2) α is accepted in KB u α. Follows from (∗2). (u3) If α is satisfiable and consistent with IC, then KB u α is consistent. Since we have assumed IC to be empty, this directly corresponds to (∗5). (u4) If ¬α is not accepted in KB, then KB u α ≡ KB + α. Follows from (∗3) and (∗4). (+5) If KB ≡ KB′ and α ≡ β, then KB u α ≡ KB′ u β. Since KB ≡ KB′ they represent same belief set, i.e. KB• = KB′•. Now, this postulate follows immediately from (∗6). (u6) (KB u α) + β implies KB u (α ∧ β). Corresponds to (∗7). (u7) If ¬β is not accepted in KB u α, then KB u (α ∧ β) implies (KB u α) + β. Corresponds to (∗8)."
    }, {
      "heading" : "Contraction",
      "text" : "AGM puts forward rationality postulates (−1) to (−8) to be satisfied by a contraction operator on closed set KB•, reproduced below:\n(−1) (Closure) KB• − α is a belief set. (−2) (Inclusion) KB• − α ⊆ KB•. (−3) (Vacuity) If α < KB•, then KB• − α = KB•. (−4) (Success) If 0 α, then α < KB• − α. (−5) (Preservation) If ` α↔ β, then KB• − α = KB• − β. (−6) (Recovery) KB• ⊂ (KB• − α) + α. (−7) (Conjunction 1)KB• − α ∩KB• − β ⊆ KB• − (α ∧ β). (−8) (Conjunction 2) If α < KB• − (α ∧ β), then KB• − (α ∧ β) ⊆ KB• − α.\nAs in the case of revision, the equivalence is brought out by the following theorems. Since contraction is constructed in terms of revision, these theorems are trivial.\nCorollary 1. Let KB be a Horn knowledge base with an empty IC and −̇ be a contraction function that satisfies all the rationality postulates (−̇1) to (−̇8). Let a contraction operator − on KB• be defined as: for any sentence α, KB•−α = (KB−̇α)•. The contraction operator −, thus defined, satisfies all the AGM - postulates for contraction (−1) to (−8).\nProof. Follows from Theorem 18 and Theorem 22\nCorollary 2. Let KB be a Horn knowledge base with an empty IC and − be a contraction operator that satisfies all the AGM - postulates (−1) to (−8). Let a contraction function −̇ on KB be defined as: for any sentence α, (KB−̇α)• = KB• − α. The contraction function −̇, thus defined, satisfies all the rationality postulates (−̇1) to (−̇8).\nProof. Follows from Theorem 19 and Theorem 23"
    }, {
      "heading" : "10.4 Realizing Horn knowledge base dynamics using abductive explanations",
      "text" : "In this section, we explore how belief dynamics can be realized in practice (see (Aravindan & Dung 1994), (Aravindan 1995) and (Bessant et al. 1998)). Here, we will see how revision can be implemented based on the construction using models of revising sentence and an order among them. The notion of abduction proves to be useful and is explained in the sequel.\nLet α be a sentence in L. An abductive explanation for α with respect to KB is a set of abductive literals 5 ∆ s.t. ∆ consistent with IC and ∆ |=P α (that is α ∈ CnP (∆)). Further ∆ is said to be minimal iff no proper subset of ∆ is an abductive explanation for α.\nThe basic idea to implement revision of a Horn knowledge base KB by a sentence α, is to realize Mod({α} ∪ IC) in terms of abductive explanations for α with respect to KB. We first provide a useful lemma.\nDefinition 49. Let KB be a Horn knowledge base, α a sentence, and ∆1 and ∆2 be two minimal abductive explanations for α with respect to KB. Then, the disjunction of ∆1 and ∆2, written as ∆1 ∨∆2, is given as:\n∆1 ∨∆2 = (∆1 ∩∆2) ∪ {α ∨ β|α ∈ ∆1\\∆2 and β ∈ ∆2\\∆1}.\nExtending this to ∆•, a set of minimal abductive explanations for α with respect to KB, ∨∆• is given by the disjunction of all elements of ∆•.\nLemma 12. Let KB be a Horn knowledge base, α a sentence,and ∆1 and ∆2 be two minimal abductive explanations for α with respect to KB. Then,Mod(∆1 ∨ ∆2) = Mod(∆1) ∪Mod(∆2).\nProof. First we show that every model of ∆1 is a model of ∆1 ∨∆2. Clearly, a model M of ∆1 satisfies all the sentences in (∆1 ∩∆2). The other sentences in (∆1 ∨∆2) are of the form α ∨ β, where α is from ∆1 and β is from ∆2. Since M is a model of ∆1, α is true in M , and hence all such sentences are satisfied by M . Hence M is a model of ∆1∨∆2 too. Similarly, it can be shown that every model of ∆2 is a model of ∆1 ∨∆2 too. 5 An abductive literal is either an abducible A from Ab, or its negation ¬A.\nNow, it remains to be shown that every model M of ∆1∨∆2 is either a model of ∆1 or a model of ∆2. We will now show that if M is not a model of ∆2, then it must be a model of ∆1. Since M satisfies all the sentences in (∆1 ∩∆2), we need only to show that M also satisfies all the sentences in ∆1\\∆2. For every element α ∈ ∆1\\∆2: there exists a subset of (∆1 ∨ ∆2), {α ∨ β|β ∈ ∆2\\∆2}. M satisfies all the sentences in this subset. Suppose M does not satisfy α, then it must satisfy all β ∈ ∆1\\∆2. This implies that M is a model of ∆2, which is a contradictory to our assumption. Hence M must satisfy α, and thus a model ∆1. Similarly, it can be shown that M must be a model of ∆2 if it is not a model of ∆1.\nAs one would expect, all the models of revising sentence α can be realized in terms abductive explanations for α, and the relationship is precisely stated below.\nLemma 13. Let KB be a Horn knowledge base, α a sentence, and ∆• the set of all minimal abductive explanations for α with respect to KB. Then Mod({α} ∪ IC) = Mod(∨∆•).\nProof. It can be easily verified that every model M of a minimal abductive explanation is also a model of α. Since every minimal abductive explanation satisfies IC, M is a model of α ∪ IC. It remains to be shown that every model M of {α} ∪ IC is a model of one of the minimal abductive explanations for α with respect to KB. This can be verified by observing that a minimal abductive explanation for α with respect to KB can be obtained from M .\nThus, we have a way to generate all the models of {α} ∪ IC, and we just need to select a subset of this based on an order that satisfies (≤ 1) to (≤ 5). Suppose we have such an order that satisfies all the required postulates, then this order can be mapped to a particular set of abductive explanations for α with respect to KB. This is stated precisely in the following theorem. An important implication of this theorem is that there is no need to compute all the abductive explanations for α with respect to KB. However, it does not say which abductive explanations need to be computed.\nTheorem 24. Let KB be a Horn knowledge base, and ≤KB be an order among abductive interpretations in S that satisfies all the rationality axioms (≤ 1) to (≤ 5). Then, for every sentence α, there exists ∆• a set of minimal abductive explanations for α with respect to KB, s.t. Min(Mod({α} ∪ IC),≤KB) is a subset of Mod(∨∆•), and this does not hold for any proper subset of ∆•.\nProof. From Lemma 12 and Lemma 13, it is clear that Mod({α} ∪ IC) is the union of all the models of all minimal abductive explanations of α with respect to KB. Min selects a subset of this, and the theorem follows immediately. .\nThe above theorem 24, is still not very useful in realizing revision. We need to have an order among all the interpretations that satisfies all the required axioms, and need to compute all the abductive explanations for α with respect to KB.\nThe need to compute all abductive explanations arises from the fact that the converse of the above theorem does not hold in general. This scheme requires an universal order ≤, in the sense that same order can be used for any Horn knowledge base. Otherwise, it would be necessary to specify the new order to be used for further modifying (KB u α). However, even if the order can be worked out, it is not desirable to demand all abductive explanations of α with respect to KB be computed. So, it is desirable to work out, when the converse of the above theorem is true. The following theorem says that, suppose α is rejected in KB, then revision of KB by α can be worked out in terms of some abductive explanations for α with respect to KB.\nTheorem 25. Let KB be a Horn knowledge base, and a revision function u be defined as: for any sentence α that is rejected in KB, Mod(KB u α) is a non-empty subset of Mod(∨∆•), where ∆• is a set of all minimal abductive explanations for α with respect to KB. Then, there exists an order ≤KB among abductive interpretations in S, s.t. ≤KB satisfies all the rationality axioms (≤ 1) to (≤ 5) and Mod(KB u α) = Min(Mod({α} ∪ IC),≤KB).\nProof. Let us construct an order ≤KB among interpretations in S as follows: For any two abductive interpretations I and I ′ in S, define I ≤KB I ′ iff either I ∈ Mod(∨∆•) or I ∈ Mod(KB u form(I, I ′)), where form(I, I ′) stands for sentence whose only models are I and I ′. We will show that ≤KB thus constructed satisfies (≤ 1) to (≤ 5) and Min(Mod({α} ∪ IC),≤KB) = Mod(KB u α).\nFirst, we show that Min(Mod({α} ∪ IC),≤KB) = Mod(KB u α).Suppose α is not satisfiable, i.e. Mod(α) is empty, or α does not satisfy IC, then there are no abductive models of {α} ∪ IC, and hence Min(Mod({α} ∪ IC),≤KB) is empty. From (u3), we infer that Mod(KB u α) is also empty. When α is satisfiable and α satisfies IC, the required result is obtained in two parts:\n1) If I ∈Min(Mod({α} ∪ IC),≤KB), then I ∈Mod(KB u α) Since α is satisfiable and consistent with IC, (u3) implies that there exists at least one model, say I ′, for KBuα. From (u1), it is clear that I ′ is a model of IC, from (u2) we also get that I ′ is a model of α, and consequently I ≤KB I ′ (because I ∈ Min(Mod({α} ∪ IC),≤KB)). Suppose I ∈ (Mod(∨∆•)), then (u4) immediately gives I ∈ Mod(KB u α). If not, from our definition of ≤KB, it is clear that I ∈Mod(KBuform(I, I ′)). Note that α∧form(I, I ′) ≡ form(I, I ′), since both I and I ′ are models of α. From (u6) and (u7), we get Mod(KBuα)∩{I, I ′} = Mod(KBuform(I, I ′)). Since I ∈Mod(KBu form(I, I ′)), it immediately follows that I ∈Mod(KB u α). 2) If I ∈Mod(KB u α), then I ∈Min(Mod({α} ∪ IC),≤KB). From (u1) we get I is a model of IC, and from (u2), we obtain I ∈Mod(α). Suppose I ∈ (Mod(∨∆•)), then from our definition of ≤KB, we get I ≤KB I ′, for any other model I ′ of α and IC, and hence I ∈ Min(Mod({α} ∪ IC),≤KB). Instead, if I is not a model of KB, then, to get the required result, we should show that I ∈Mod(KB u form(I, I ′)), for every model I ′ of α and IC. As we have observed previously, from (u6) and (u7), we get Mod(KBuα)∩{I, I ′} = Mod(KBuform(I, I ′)). Since I ∈Mod(KBuα),\nit immediately follows that I ∈Mod(KBuform(I, I ′)). Hence I ≤KB I ′ for any model I ′ of α and IC, and consequently, I ∈Min(Mod({α}∪IC),≤KB ).\nEvery model of Mod(KB u α) is strictly minimal than all other interpretations. It is easy to verify that such a pre-order satisfies (≤ 1) to (≤ 5). In particular, since α is rejected in KB, (≤ 3) faithfulness is satisfied, and since non-empty subset of Mod(∨∆•) is selected, (≤ 4) is also satisfied.\nAn important corollary of this theorem is that, revision of KB by α can be realized just by computing one abductive explanation of α with respect to KB, and is stated below.\nCorollary 3. Let KB be a Horn knowledge base, and a revision function u be defined as: for any sentence α that is rejected in KB, Mod(KB u α) is a nonempty subset of Mod(∆), where ∆ is an abductive explanations for α with respect to KB. Then, there exists an order ≤KB among abductive interpretations in S, s.t. ≤KB satisfies all the rationality axioms (≤ 1) to (≤ 5) and Mod(KBuα) = Min(Mod({α} ∪ IC),≤KB).\nThe precondition that α is rejected in KB is not a serious limitation in various applications such as database updates and diagnosis, where close world assumption is employed to infer negative information. For example, in diagnosis it is generally assumed that all components are functioning normally, unless otherwise there is specific information against it. Hence, a Horn knowledge base in diagnosis either accepts or rejects normality of a component, and there is no ”don’t know” third state. In other words, in these applications the Horn knowledge base is assumed to be complete. Hence, when such a complete Horn knowledge base is revised by α, either α is already accepted in KB or rejected in KB, and so the above scheme works fine."
    }, {
      "heading" : "11 Related Works",
      "text" : "We begin by recalling previous work on view deletion. Aravindan (Aravindan & Dung 1994), (Aravindan 1995), defines a contraction operator in view deletion with respect to a set of formulae or sentences using Hansson’s (Hansson 1997a) belief change. Similar to our approach (Delhibabu & Lakemeyer 2013, Delhibabu & Behrend, 2014, Delhibabu 2014a, Delhibabu 2014b) he focused on set of formulae or sentences in knowledge base revision for view update with respect to insertion and deletion and formulae are considered at the same level. Aravindan proposed different ways to change knowledge base via only database deletion, devising particular postulate which is shown to be necessary and sufficient for such an update process.\nOur Horn knowledge base consists of two parts, immutable part and updatable part, but our focus is on minimal change computations. The related works are, Eiter (Eiter & Makino 2007), Langlois (Langlois et al. 2008) and Delgrande\n(Delgrande & Peppas 2011) are focus on Horn revision with different perspectives like prime implication, logical closure and belief level. Segerberg (Segerberg 1998) defined a new modeling technique for belief revision in terms of irrevocability on prioritized revision. Hansson constructed five types of non-prioritized belief revision. Makinson (Makinson 1997) developed dialogue form of revision AGM. Papini (Papini 2000) defined a new version of knowledge base revision. In this paper, we considered the immutable part as a Horn clause (Fermé & Hansson 2001 shown shielded contraction similar to immutable part, the success postulate does not hold in general; some non-tautological beliefs are shielded from contraction and cannot be given up. Shielded contraction has close connections with credibility limited revision shown Hansson et al 2001) and the updatable part as an atom (literal). Knowledge bases have a set of integrity constraints.\nHansson’s (Hansson 1997a) kernel change is related to abductive method. Aliseda’s (Aliseda 2006) book on abductive reasoning is one of the motivation step. Christiansen’s (Christiansen & Dahl 2009) work on dynamics of abductive logic grammars exactly fits our minimal change (insertion and deletion). Wrobel’s (Wrobel 1995) definition of first order theory revision was helpful to frame our algorithm.\nOn the other hand, we are dealing with view update problem. Keller’s (Keller 1985) thesis is motivation of the view update problem. There are many papers related to the view update problem (for example, the recent survey paper on view update by Chen and Liao (Chen & Liao 2010) and the survey paper on view update algorithms by Mayol and Teniente (Mayol & Teniente 1999). More similar to our work is the paper presented by Bessant (Bessant et al. 1998), which introduces a local search-based heuristic technique that empirically proves to be often viable, even in the context of very large propositional applications. Laurent (Laurent et al. 1998), considers updates in a deductive database in which every insertion or deletion of a fact can be performed in a deterministic way.\nFurthermore, and at a first sight more related to our work, some work has been done on ”core-retainment” (Hansson 1991) in the model of language splitting introduced by Parikh (Parikh 1999). More recently, Doukari (Doukari et al. 2008), Özçep (Özçep 2012) and Wu (Wu et al. 2011) applied similar ideas for dealing with knowledge base dynamics. These works represent motivation step for our future work. Second, we are dealing with how to change minimally in the theory of ”principle of minimal change”, but current focus is on finding second best abductive explanation (Liberatore & Schaerf 2004 and 2012), 2-valued minimal hypothesis for each normal program (Pinto & Pereira 2011). Our work reflected in the current trends on Ontology systems and description logics (Qi and Yang (Qi & Yang 2008) and Kogalovsky (Kogalovsky 2012)). Finally, when we presented Horn knowledge base change in abduction framework, we did not talk about compilability and complexity (see the works of Liberatore (Liberatore 1997) and Zanuttini (Zanuttini 2003)).\nThe significance of our work can be summarized in the following:\n– To define a new kind of revision operator on Horn knowledge base and obtain axiomatic characterization for it.\n– To propose new generalized revision algorithm for Horn knowledge base dynamics, and study its connections with kernel change and abduction procedure. – To develop a new view insertion algorithm for databases. – To design a new view update algorithm for stratifiable Deductive Database\n(DDB), using an axiomatic method based on Hyper tableaux and magic sets. – To study an abductive framework for Horn knowledge base dynamics. – To present a comparative study of view update algorithms and integrity\nconstraint. – Finally, to shown connection between belief update versus database update."
    }, {
      "heading" : "12 Conclusion and remarks",
      "text" : "The main contribution of this research is to provide a link between theory of belief dynamics and concrete applications such as view updates in databases. We argued for generalization of belief dynamics theory in two respects: to handle certain part of knowledge as immutable; and dropping the requirement that belief state be deductively closed. The intended generalization was achieved by introducing the concept of Horn knowledge base dynamics and generalized revision for the same. Further, we studied the relationship between Horn knowledge base dynamics and abduction resulting in a generalized algorithm for revision based on abductive procedures. The successfully demonstrated how Horn knowledge base dynamics provide an axiomatic characterization for update an literals to a stratifiable (definite) deductive database.\nIn bridging the gap between belief dynamics and view updates, we observe that a balance has to be achieved between computational efficiency and rationality. While rationally attractive notions of generalized revision prove to be computationally inefficient, the rationality behind efficient algorithms based on incomplete trees is not clear at all. From the belief dynamics point of view, we may have to sacrifice some postulates, vacuity, to gain computational efficiency. Further weakening of relevance has to be explored, to provide declarative semantics for algorithms based on incomplete trees.\nOn the other hand, from the database side, we should explore various ways of optimizing the algorithms that would comply with the proposed declarative semantics. We believe that partial deduction and loop detection techniques, will play an important role in optimizing algorithms. Note that, loop detection could be carried out during partial deduction, and complete SLD-trees can be effectively constructed wrt a partial deduction (with loop check) of a database, rather than wrt database itself. Moreover, we would anyway need a partial deduction for optimization of query evaluation.\nWe have presented two variants of an algorithm for update a view atom from a definite database. The key idea of this approach is to transform the given database into a logic program in such a way that updates can be read off from the models of this transformed program. We have also shown that this algorithm is rational in the sense that it satisfies the rationality postulates that are justified\nfrom philosophical angle. In the second variant, where materialized view is used for the transformation, after generating a hitting set and removing corresponding EDB atoms, we easily move to the new materialized view. An obvious way is to recompute the view from scratch using the new EDB (i.e., compute the Least Herbrand Model of the new updated database from scratch) but it is certainly interesting to look for more efficient methods.\nThough we have discussed only about view updates, we believe that Horn knowledge base dynamics can also be applied to other applications such as view maintenance, diagnosis, and we plan to explore it further (see works (Biskup 2012) and (Caroprese et al. 2012)). Still, a lot of developments are possible, for improving existing operators or for defining new classes of change operators. In the relation of Horn KB revision with hitting set as to be describe similar construction for description logic. In particular assuming the T-Box to the hitting set and the rest with the A-Box (Delgrande, JP & Wassermann 2013). We did not talk about complexity (see the works of Liberatore ((Liberatore 1997) and (Liberatore & Schaerf 2004)), Caroprese (Caroprese 2012), Calvanese’s (Calvanese 2012), and Cong (Cong et al. 2012)). In this thesis answer impotent question for experimental people that is,any real life application for AGM in 25 year theory? (Ferme & Hansson 2011). The revision and update are more challenging in logical view update problem (database theory), we extended the theory to combine our results similar in the Konieczny’s (Konieczny 2011) and Nayak’s (Nayak 2011)."
    }, {
      "heading" : "Acknowledgement",
      "text" : "I would like to thanks Chandrabose Aravindan and Gerhard Lakemeyer both my Indian and Germany PhD supervisor, give encourage to write the paper. I owe my deepest gratitude to Ramaswamy Ramanujam from Institute of Mathematical Sciences and Ulrich Furbach from University Koblenz-Landau for my PhD thesis member. I thank to my PhD thesis examiner’s Eduardo Fermé from University of Madeira, Mohua Banerjee from Indian Institute of Technology Kanpur and Arindama Singh form Indian Institute of Technology Madras. The author acknowledges the support of SSN College of Engineering research funds and RWTH Aachen, where he is visiting scholar with an Erasmus Mundus External Cooperation Window India4EU by the European Commission.\nM et\nho d\nP ro\nbl em\nD at\nab as\ne sc\nhe m\na U\np da\nte re\nq. M\nec ha\nni sm\nU p\nda te\nC ha\nng e\nSo lu\nti on\ns\nT yp\ne V\nie w\nIC R\nun /\nD ef\n. V\nie w\nIC K\nin d\nof M\nul .U\npd at\ne Te\nch -\nB as\ne U\nse r\nT yp\ne B\nas e\nV ie\nw A\nxi om\nSo un\nd. C\nom pl\net e.\nU pd\nat e\nE nf\nor ce\n. C\nom p.\nLa ng\n. de\nf. IC\nO pe\nra t.\nni qu\ne Fa\nct s\nPa rt\n. fa\nct s\nde f.\n[6 9]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nN o\nι δ\nSL D\nN F\nN o\nN o\nS Ye\ns N\no 1-\n6, 9\nN o\nN ot pr ov\ned\n[8 6]\nN Ye\ns M\nai nt\nai n\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ\nSL D\nN F\nN o\nN o\nS Ye\ns N\no —\nN o\nN o\n[9 6]\nS Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ\n— Ye\ns N\no SS\nYe s\nYe s\n1- 6,\n7 N\not N ot pr ov ed pr ov\ned\n[1 18\n] N\nN o\nM ai\nnt ai\nn R\nun Lo\ngi c\nYe s\nYe s\nSt at\nic Ye\ns ι δ\n— Ye\ns N\no S\nYe s\nN o\n1- 6,\n7 N\no N o pr ov ed\npr ov\ned\n[7 0]\nS Ye\ns C\nhe ck\nC om\np. R\nel at\nio n.\nN o\nN o\nSt at\nic Ye\ns ι δ χ\npr ed\nef .\nYe s\nN o\nG Ye\ns N\no —\nN o\nN o\nM ai\nnt ai\nn R\nun Lo\ngi c\nP ro\ngr am\ns\n[5 1]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns N\no St\nat ic\nYe s\nι δ\npr ed\nef Ye\ns N\no S\nYe s\nN o\n1- 6,\n7 N\not N o P ro gr am s P ro ve d\n[1 46\n] S\nYe s\nC he\nck R\nun Lo\ngi c\nYe s\nYe s\nSt at\nic Ye\ns ι δ χ\nSL D\nN F\nN o\nN o\nSS Ye\ns N\no 1-\n6, 7\nYe s\nN o\nM ai\nnt ai\nn\n[7 1]\nN Ye\ns M\nai nt\nai n\nR un\nLo gi\nc Ye\ns N\no St\nat ic\nYe s\nι δ\nU nf\nol d\nYe s\nN o\nSS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[1 14\n] N\nYe s\nM ai\nnt ai\nn C\nom p.\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ χ\nSL D\nN F\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nN ot\nN ot\nR un\nD yn\nam ic\npr ov\ned pr\nov ed\n[1 50\n] S\nYe s\nM ai\nnt ai\nn R\nun Lo\ngi c\nYe s\nYe s\nSt at\nic Ye\ns ι δ\nU nf\nol d.\nN o\nYe s\nS Ye\ns N\no 1-\n6, 7\nN ot\nN o\npr ov\ned\n[8 ]\nH Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ\nSL D\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[2 6]\nN N\no M\nai nt\nai n\nC om\np R\nel at\nio n\nYe s\nLi m\nite d\nSt at\nic Ye\ns ι δ χ\nA ct\niv e\nYe s\nYe s\nS Ye\ns N\no —\nN o\nN o\nR un\nLo gi\nc\n[6 6]\nN N\no M\nai nt\nai n\nC om\np R\nel at\nio n\nN o\nFl at\nSt at\nic Ye\ns ι δ χ\nA ct\niv e\nYe s\nYe s\nS Ye\ns N\no —\nN o\nN o\nR un\nLo gi\nc Li\nm ite\nd D\nyn am\nic\n[2 9]\nH Ye\ns C\nhe ck\nC om\np. O\n-O C\nla ss\nLi m\nite d\nSt at\nic Ye\ns ι δ\nA ct\niv e\nYe s\nN o\nSS Ye\ns N\no 1-\n6, 9\nN o\nYe s\nM ai\nnt ai\nn R\nun A\ntt .\n[3 7]\nN Ye\ns M\nai nt\nai n\nR un\nLo gi\nc Ye\ns Fl\nat St\nat ic\nYe s\nι δ\nU nf\nol d.\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nN ot\nYe s\nLi m\nite d\npr ov\ned\n[1 07\n] N\nYe s\nM ai\nnt ai\nn R\nun Lo\ngi c\nYe s\nLi m\nite d\nSt at\nic N\no ι δ\nA ct\niv e\nYe s\nN o\nSS Ye\ns N\no 1-\n6, 7\nYe s\nN ot pr ov\ned\n[1 45\n] N\nYe s\nM ai\nnt ai\nn C\nom p\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ\nSL D\nN F\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\nR un\nD yn\nam ic\n[1 38\n] S\nYe s\nM ai\nnt ai\nn C\nom p\nLo gi\nc N\no Fl\nat St\nat ic\nYe s\nι δ\npr ed\nef —\nYe s\nG N\no Ye\ns —\nN o\nN ot\nLi m\nite d\nP ro\ngr am\ns pr\nov ed\nT ab\n. 1.\nSu m\nm ar\ny of\nvi ew\n-u pd\nat e\nan d\nin te\ngr ity\nco ns\ntr ai\nnt w\nith ou\nr ax\nio m\nat ic\nm et\nho d\nA pp\nen di\nx A\nM et\nho d\nP ro\nbl em\nD at\nab as\ne sc\nhe m\na U\np da\nte re\nq. M\nec ha\nni sm\nU p\nda te\nC ha\nng e\nSo lu\nti on\ns\nT yp\ne V\nie w\nIC R\nun /\nD ef\n. V\nie w\nIC K\nin d\nof M\nul .U\npd at\ne Te\nch -\nB as\ne U\nse r\nT yp\ne B\nas e\nV ie\nw A\nxi om\nSo un\nd. C\nom pl\net e.\nU pd\nat e\nE nf\nor ce\n. C\nom p.\nLa ng\n. de\nf. IC\nO pe\nra t.\nni qu\ne Fa\nct s\nPa rt\n. fa\nct s\nde f.\n[1 44\n] N\nN o\nM ai\nnt ai\nn C\nom p\nLo gi\nc Ye\ns Li\nm ite\nd St\nat ic\nYe s\nι δ χ\nP re\nde f\nYe s\nN o\nS Ye\ns N\no 1-\n6, 7\nYe s\nN o\nP ro\ngr am\n[1 0]\nH Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Li\nm ite\nd St\nat ic\nYe s\nι δ\nSL D\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[4 0]\nN Ye\ns M\nai nt\nai n\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ\nSL D\nN F\nN o\nN o\nS Ye\ns N\no 1-\n6, 7\nN o\nN ot P ro\nve d\n[1 05\n] N\nYe s\nM ai\nnt ai\nn R\nun Lo\ngi c\nYe s\nFl at\nSt at\nic Ye\ns ι δ\nU nf\nol d\nN o\nYe s\nG Ye\ns N\no 1-\n6, 7\nN ot\nN o\nLi m\nite d\npr ov\ned\n[1 51\n] H\nN o\nM ai\nnt ai\nn C\nom p.\nR el\nat io\nn Ye\ns Li\nm ite\nd St\nat ic\nYe s\nι δ χ\nU nf\nol d\nYe s\nN o\nS Ye\ns N\no 1-\n6, 7\nN ot\nN ot\nR un\nD yn\nam ic\npr ov\ned pr\nov ed\n[1 09\n] N\nN o\nM ai\nnt ai\nn C\nom p\nLo gi\nc N\no Fl\nat St\nat ic\nYe s\nι δ\nA ct\niv e\nYe s\nN o\nG N\no N\no —\nN o\nN o\nR es\nto re\nR un\nLi m\nite d\nD yn\nam ic\n[1 39\n] N\nN o\nM ai\nnt ai\nn C\nom p\nR el\nat io\nn N\no Fl\nat St\nat ic\nYe s\nι δ\nA ct\niv e\nYe s\nN o\nS N\no N\no —\nN o\nN o\nR un\nLi m\nite d\n[1 08\n] N\nYe s\nC he\nck R\nun Lo\ngi c\nYe s\nLi m\nite d\nSt at\nic Ye\ns ι δ\nSL D\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[1 ]\nO N\no M\nai nt\nai n\nR un\nLo gi\nc Ye\ns Li\nm ite\nd St\nat ic\nYe s\nι δ\n— Ye\ns N\no S\nYe s\nN o\n— N\no N\no\n[1 40\n] N\nN o\nM ai\nnt ai\nn C\nom p\nR el\nat io\nn N\no Li\nm ite\nd St\nat ic\nYe s\nι δ\nP re\nde f\nN o\nN o\nG N\no N\no —\nN o\nN o\nP ro\ngr am\n[7 2]\nN N\no M\nai nt\nai n\nC om\np Lo\ngi c\nYe s\nLi m\nite d\nSt at\nic Ye\ns ι δ\n— N\no N\no S\nN o\nN o\n— N\no N\no\n[3 0]\nN N\no M\nai nt\nai n\nC om\np. R\nel at\nio n\nYe s\nLi m\nite d\nSt at\nic Ye\ns ι δ\n— Ye\ns N\no S\nYe s\nN o\n— N\not N ot R un D yn am ic pr ov ed pr ov\ned\n[5 2]\nH Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ\nP re\nde f\nYe s\nN o\nS Ye\ns N\no 1-\n6, 7\nYe s\nN ot\nP ro\ngr am\ns pr\nov ed\n[7 8]\nO Ye\ns C\nhe ck\nR un\nR el\nat io\nn Ye\ns Li\nm ite\nd St\nat ic\nN o\nι δ\nU nf\nol d\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[1 4]\nO Ye\ns C\nhe ck\nR un\nR el\nat io\nn Ye\ns Li\nm ite\nd St\nat ic\nN o\nι δ\nU nf\nol d\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[5 6]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ\nSL D\nN F\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[1 32\n] N\nN o\nM ai\nnt ai\nn R\nun Lo\ngi c\nYe s\nLi m\nite d\nSt at\nic Ye\ns ι δ\nP re\nde f\nYe s\nN o\nS Ye\ns N\no 1-\n6, 7\nYe s\nN ot\nP ro\ngr am\ns pr\nov ed\n[8 1]\nO N\no M\nai nt\nai n\nC om\np R\nel at\nio n\nYe s\nLi m\nite d\nSt at\nic Ye\ns ι δ\n— Ye\ns N\no S\nYe s\nN o\n— N\no N\no\nM et\nho d\nP ro\nbl em\nD at\nab as\ne sc\nhe m\na U\np da\nte re\nq. M\nec ha\nni sm\nU p\nda te\nC ha\nng e\nSo lu\nti on\ns\nT yp\ne V\nie w\nIC R\nun /\nD ef\n. V\nie w\nIC K\nin d\nof M\nul .U\npd at\ne Te\nch -\nB as\ne U\nse r\nT yp\ne B\nas e\nV ie\nw A\nxi om\nSo un\nd. C\nom pl\net e.\nU pd\nat e\nE nf\nor ce\n. C\nom p.\nLa ng\n. de\nf. IC\nO pe\nra t.\nni qu\ne Fa\nct s\nPa rt\n. fa\nct s\nde f.\n[1 35\n] N\nYe s\nC he\nck R\nun Lo\ngi c\nN o\nLi m\nite d\nSt at\nic Ye\ns ι δ\nSL D\nN F\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\n[5 7]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nN o\nι δ\nSL D\nN F\nN o\nN o\nS Ye\ns N\no 1-\n6, 9\nN ot\nN o pr ov\ned\n[1 13\n] N\nYe s\nC he\nck R\nun Lo\ngi c\nYe s\nYe s\nSt at\nic N\no ι δ χ\nSL D\nYe s\nN o\nS Ye\ns N\no —\nN o\nN o\nM ai\nnt ai\nn\n[1 9]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nN o\nι δ χ\nSL D\nYe s\nN o\nSS Ye\ns N\no 1-\n6, 7\nYe s\nN ot\nM ai\nnt ai\nn C\nom p\npr ov\ned\n[3 1]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ χ\nP re\nde f\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\nM ai\nnt ai\nn D\nyn am\nic P\nro gr\nam\n[2 5]\nN Ye\ns C\nhe ck\nC om\np Lo\ngi c\nYe s\nYe s\nD yn\nam ic\nYe s\nι δ\nP re\nde f\nYe s\nN o\nS Ye\ns N\no —\nN ot\nN o\nP ro\ngr am\ns P\nro ve\nd pr\nov ed\n[3 2]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ χ\nP re\nde f\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s\nM ai\nnt ai\nn D\nyn am\nic P\nro gr\nam\n[3 5]\nN N\no M\nai nt\nai n\nC om\np Lo\ngi c\nYe s\nN o\n— Ye\ns ι δ\n— Ye\ns N\no S\nYe s\nN o\n— N\no N\no\n[1 54\n] N\nN o\nM ai\nnt ai\nn R\nun R\nel at\nio n\nYe s\nN o\n— Ye\ns ι δ χ\nU nf\nol d\nYe s\nN o\nSS N\no N\no —\nN ot\nN ot\npr ov\ned pr\nov ed\n[7 9]\nO N\no M\nai nt\nai n\nC om\np. Lo\ngi c\nYe s\nN o\n— Ye\ns ι δ\n— -\nYe s\nN o\nG N\no N\no —\nYe s\nN ot\nR un\npr ov\ned\n[1 5]\nS Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Fl\nat St\nat ic\nYe s\nι δ\nSL D\nN F\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nN ot\nLi m\nite d\npr ov\ned\n[5 3]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ\n— Ye\ns N\no S\nYe s\nN o\n— N\no N\no\n[2 7]\nO N\no M\nai nt\nai n\nR un\nR el\nat io\nn Ye\ns N\no St\nat ic\nYe s\nι δ\nSL D\nYe s\nYe s\nG N\no N\no —\nN ot\nN ot\npr ov\ned pr\nov ed\n[1 6]\nO N\no M\nai nt\nai n\nC om\np R\nel at\nio n\nYe s\nN o\nSt at\nic Ye\ns ι δ χ\n— Ye\ns N\no SS\nYe s\nN o\n— N\no N\no\n[4 ]\nO N\no M\nai nt\nai n\nC om\np. R\nel at\nio n\nN o\nLi m\nite d\nSt at\nic Ye\ns ι δ\n— Ye\ns N\no G\nYe s\nN o\n— N\no N o R un D yn am ic\n[1 11\n] N\nN o\nM ai\nnt ai\nn C\nom p\nR el\nat io\nn N\no Ye\ns St\nat ic\nYe s\nι δ χ\nU nf\nol d\nN o\nYe s\nSS N\no N\no —\nN o\nN o\n[1 37\n] N\nN o\nC he\nck C\nom p\nLo gi\nc N\no Ye\ns St\nat ic\nYe s\nι δ\nA ct\niv e\nYe s\nN o\nG Ye\ns N\no —\nN o\nN o\n[4 1]\nN Ye\ns C\nhe ck\nR un\nLo gi\nc Ye\ns Ye\ns St\nat ic\nYe s\nι δ\nSL D\nYe s\nN o\nS Ye\ns N\no 1-\n6, 9\nYe s\nYe s"
    } ],
    "references" : [ {
      "title" : "Automated selection of materialized views and indexes in SQL databases",
      "author" : [ "S Agrawal", "S Chaudhuri" ],
      "venue" : "Proceedings of the 26th International Conference on Very Large Data Bases, ed",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2008
    }, {
      "title" : "On the logic of theory change: Safe contraction",
      "author" : [ "CE Alchourron", "D Makinson" ],
      "venue" : "Studia Logica,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1985
    }, {
      "title" : "On the logic of theory change: Partial meet contraction and revision functions",
      "author" : [ "CE Alchourron", "Gärdenfors", "D Makinson" ],
      "venue" : "Journal of Symbolic Logic",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1985
    }, {
      "title" : "Filtering XML content for publication and presentation on the web’,Digital Information Management (ICDIM)",
      "author" : [ "L Alexandre", "J Coelho" ],
      "venue" : null,
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2011
    }, {
      "title" : "Abductive Resoning Logic Investigations into Discovery and Explanation",
      "author" : [ "A Aliseda" ],
      "venue" : "Springer book series,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2006
    }, {
      "title" : "Abductive Reasoning: Challenges Ahead",
      "author" : [ "A Aliseda" ],
      "venue" : "THEORIA, vol. 22,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2007
    }, {
      "title" : "Acyclic Programs",
      "author" : [ "Apt", "K.P", "M Bezem" ],
      "venue" : "New Generation Computing,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1991
    }, {
      "title" : "Belief Dynamics, Abduction, and Database",
      "author" : [ "C Aravindan", "PM Dung" ],
      "venue" : "Logics in Artificial Intelligence Lecture Notes in Computer Science, ed",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1994
    }, {
      "title" : "Dynamics of Belief: Epistmology, Abduction and Database Updat",
      "author" : [ "C Aravindan" ],
      "venue" : "Phd Thesis,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1995
    }, {
      "title" : "A Rational and Efficient Algorithm for View Deletion in Databases",
      "author" : [ "C Aravindan", "P Baumgartner" ],
      "venue" : "Logic Programming proceedng International Symposium,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1997
    }, {
      "title" : "2004,’Coherent Integration of Databases by Abductive Logic Programming’,Journal",
      "author" : [ "O Arieli", "M Denecker", "BV Nuffelen", "M Bruynooghe" ],
      "venue" : "Artificial Intelligence Research,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2004
    }, {
      "title" : "Knowledge updates: Semantics and complexity issues",
      "author" : [ "C Baral", "Y Zhang" ],
      "venue" : "Atificial Intelligence,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2005
    }, {
      "title" : "Semantically Guided Theorem Proving for Diagnosis Applications",
      "author" : [ "P Baumgartner", "P Fröhlich", "U Furbach", "W Nejdl" ],
      "venue" : "Fifteenth International Joint Conference on. Artificial Intelligence,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1997
    }, {
      "title" : "On solving the view selection problem in distributed data warehouse architectures",
      "author" : [ "A Bauer", "W Lehne" ],
      "venue" : "15th International Conference on Scientific and Statistical Database Management,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2003
    }, {
      "title" : "A Transformation-Based Approach to View Updating in Stratifiable Deductive Databases",
      "author" : [ "A Behrend", "R Manthey" ],
      "venue" : "Foundations of Information and Knowledge Systems Lecture Notes in Computer Science, ed. Hartmannp, S,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2008
    }, {
      "title" : "A cooperative approach to view selection and placement in P2P systems",
      "author" : [ "Z Bellahsene", "M Cart", "N Kadi" ],
      "venue" : "Proceedings of the 2010 international conference on On the move to meaningful internet systems,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2010
    }, {
      "title" : "Revision of partially ordered information: Axiomatization, semantics and iteration",
      "author" : [ "S Benferhat", "S Lagrue", "O Papini" ],
      "venue" : "International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2005
    }, {
      "title" : "Combining Nonmonotonic Reasoning and Belief Revision: A Practical Approach’, Artificial Intelligence: Methodology, Systems, and Applications Lecture Notes in Computer Science, ed",
      "author" : [ "B Bessant", "E Grégoire", "P Marquis", "L SaÏs" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1998
    }, {
      "title" : "Efficient Integrity Checking over XML Documents",
      "author" : [ "D Braga", "A Campi", "D Martinenghi" ],
      "venue" : "Current Trends in Database Technology EDBT 2006 Lecture Notes in Computer Science, ed",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2006
    }, {
      "title" : "Inference-usability confinement by maintaining inference-proof views of an information system",
      "author" : [ "J Biskup" ],
      "venue" : "Journal International Journal of Computational Science and Engineering,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2012
    }, {
      "title" : "Admissible and restrained revision",
      "author" : [ "R Booth", "T Meyer" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2006
    }, {
      "title" : "Abduction as belief revision",
      "author" : [ "C Boutilier", "V Beche" ],
      "venue" : "Artificial Intelligence, vol. 77,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 1995
    }, {
      "title" : "The ViewUpdate Problem for Indefinite Databases",
      "author" : [ "L Caroprese", "I Trubitsyna", "M Truszczynski" ],
      "venue" : "Logics in Artificial Intelligence Lecture Notes in Computer Science,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2012
    }, {
      "title" : "View-based query answering in Description Logics Semantics and complexity",
      "author" : [ "D Calvanese", "GD Giacomob", "M Lenzerinib", "R Rosatib" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2012
    }, {
      "title" : "View Updating Through Active Integrity Constraints",
      "author" : [ "L Caroprese", "I Trubitsyna", "E Zumpano" ],
      "venue" : "Logic Programming Lecture Notes in Computer Science,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2007
    }, {
      "title" : "Automatic Generation of Production Rules for Integrity Maintenance",
      "author" : [ "S Ceri", "P Fraternali", "S Paraboschi", "L Tanca" ],
      "venue" : "ACM Transactions on Database Systems,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1994
    }, {
      "title" : "Towards materialized view selection for distributed databases",
      "author" : [ "LWF Chaves", "E Buchmann", "F Hueske", "K Böhm" ],
      "venue" : "Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2009
    }, {
      "title" : "A Comparative Study of View Update Problem",
      "author" : [ "H Chen", "H Liao" ],
      "venue" : "Data Storage and Data Engineering,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2010
    }, {
      "title" : "An Execution Model for Limited Ambiguity Rules and Its Application to Derived Data Update",
      "author" : [ "IA Chen", "R Hull", "D McLeod" ],
      "venue" : "ACM Transactions on Database Systems, vol. 20,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1995
    }, {
      "title" : "The view-selection problem has an exponential-time lower bound for conjunctive queries and views",
      "author" : [ "R Chirkova" ],
      "venue" : "ACM Symposium on Principles of Database Systems,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2002
    }, {
      "title" : "On Simplification of Database Integrity Constraints",
      "author" : [ "H Christiansen", "D Martinenghi" ],
      "venue" : "Fundamenta Informaticae,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2006
    }, {
      "title" : "Integrity Checking and Maintenance with Active Rules in XML Databases",
      "author" : [ "H Christiansen", "M Rekouts" ],
      "venue" : "Databases BNCOD Workshops,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2007
    }, {
      "title" : "Abductive Logic Grammars’, Logic, Language, Information and Computation Lecture Notes in Computer Science, ed",
      "author" : [ "H Christiansen" ],
      "venue" : null,
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2009
    }, {
      "title" : "Extending the Database Relational Model to Capture More Meaning",
      "author" : [ "EF Codd" ],
      "venue" : "ACM Transactions on Database Systems,",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 1979
    }, {
      "title" : "Type-Based Static and Dynamic Website Verification",
      "author" : [ "J Coelho", "M Florido" ],
      "venue" : "Internet and Web Applications and Services,",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2007
    }, {
      "title" : "On the Complexity of View Update Analysis and Its Application to Annotation Propagation",
      "author" : [ "G Cong", "W Fan", "F Geerts", "J Li", "J Luo" ],
      "venue" : "Journal IEEE Transactions on Knowledge and Data Engineering,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2012
    }, {
      "title" : "The Role of Abduction in Database View Updating",
      "author" : [ "L Console", "ML Sapino", "DT Dupré" ],
      "venue" : "Journal of Intelligent Information Systems,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 1995
    }, {
      "title" : "Investigations into a Theory of Base Revision: Preliminary report",
      "author" : [ "M Dalal" ],
      "venue" : "In Seventh National Converence on Artificial Intelligence, (AAAI), St. Paul,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 1988
    }, {
      "title" : "On the logic of iterated belief revision",
      "author" : [ "A Darwiche", "J Pearl" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 1997
    }, {
      "title" : "One Abductive Logic Programming Procedure for two kind of Updates",
      "author" : [ "H Decker" ],
      "venue" : "Proceedings Workshop DINAMICS at Int. Logic Programming Symposium,",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 1997
    }, {
      "title" : "A Rational and Efficient Algorithm for View Revision in Databases",
      "author" : [ "R. Delhibabu", "G. Lakemeyer" ],
      "venue" : "Applied Mathematics & Information Sciences,",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2013
    }, {
      "title" : "An Abductive Framework for Horn Knowledge Base Dynamics",
      "author" : [ "R Delhibabu" ],
      "venue" : "Applied Mathematics & Information Sciences,",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2014
    }, {
      "title" : "Comparative Study of View Update Algorithms in Rational Choice Theory’, Applied Intelligence - Accepted",
      "author" : [ "R Delhibabu" ],
      "venue" : null,
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 2014
    }, {
      "title" : "A Better Understanding of the Dynamics of Belief Update VS Database Update",
      "author" : [ "R Delhibabu" ],
      "venue" : "Studia Logica - Submitted",
      "citeRegEx" : "45",
      "shortCiteRegEx" : "45",
      "year" : 2014
    }, {
      "title" : "Horn Clause Belief Change: Contraction Functions",
      "author" : [ "JP Delgrande" ],
      "venue" : null,
      "citeRegEx" : "46",
      "shortCiteRegEx" : "46",
      "year" : 2008
    }, {
      "title" : "Revising Horn Theories’, of the Twenty-Second international joint conference on",
      "author" : [ "JP Delgrande", "P Peppas" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "47",
      "shortCiteRegEx" : "47",
      "year" : 2011
    }, {
      "title" : "Horn Clause Contraction Functions",
      "author" : [ "JP Delgrande", "R Wassermann" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "48",
      "shortCiteRegEx" : "48",
      "year" : 2013
    }, {
      "title" : "Abduction in Logic Programming",
      "author" : [ "M Denecker" ],
      "venue" : "Computational Logic: Logic Programming and Beyond,",
      "citeRegEx" : "49",
      "shortCiteRegEx" : "49",
      "year" : 2002
    }, {
      "title" : "Materialized View Selection in Data Warehousing: A Survey",
      "author" : [ "Dhote", "C. A", "MS Ali" ],
      "venue" : "Journal of Applied Sciences,",
      "citeRegEx" : "50",
      "shortCiteRegEx" : "50",
      "year" : 2009
    }, {
      "title" : "Incremental evaluation of datalog queries",
      "author" : [ "G Dong" ],
      "venue" : "In Database Theory - ICDT, ed. Biskup, J, Berlin, Germany,",
      "citeRegEx" : "51",
      "shortCiteRegEx" : "51",
      "year" : 1992
    }, {
      "title" : "Integrity Constraint Enforcement by Means of Trigger Templates",
      "author" : [ "E Domı́nguez", "J Lloret", "MA Zapataet" ],
      "venue" : "Advances in Information Systems Lecture Notes in Computer Science, ed. Domĺłnguez, E, Izmir, Turkey,",
      "citeRegEx" : "52",
      "shortCiteRegEx" : "52",
      "year" : 2002
    }, {
      "title" : "Model-Driven, ViewBased Evolution of Relational Databases",
      "author" : [ "E Domı́nguez", "J Lloret", "AL Rubio", "MA Zapata" ],
      "venue" : "Database and Expert Systems Applications Lecture Notes in Computer Science, ed",
      "citeRegEx" : "53",
      "shortCiteRegEx" : "53",
      "year" : 2008
    }, {
      "title" : "A New Framework for Local Belief Revision",
      "author" : [ "O Doukari", "R Jeansoulin", "E Würbelet" ],
      "venue" : "Advances in Artificial Intelligence Lecture Notes in Computer Science,",
      "citeRegEx" : "54",
      "shortCiteRegEx" : "54",
      "year" : 2008
    }, {
      "title" : "On computing all abductive explanations from a propositional Horn theory",
      "author" : [ "T Eiter" ],
      "venue" : "Journal of ACM,",
      "citeRegEx" : "55",
      "shortCiteRegEx" : "55",
      "year" : 2007
    }, {
      "title" : "Handling Existential Derived Predicates in View Updating",
      "author" : [ "C Farré", "E Teniente", "T Urpí" ],
      "venue" : "Logic Programming Lecture Notes in Computer Science,",
      "citeRegEx" : "56",
      "shortCiteRegEx" : "56",
      "year" : 2003
    }, {
      "title" : "A New Approach for Checking Schema Validation Properties",
      "author" : [ "C Farré", "E Teniente", "T Urpí" ],
      "venue" : "Database and Expert Systems Applications Lecture Notes in Computer Science, ed",
      "citeRegEx" : "57",
      "shortCiteRegEx" : "57",
      "year" : 2004
    }, {
      "title" : "Prioritized and Non-prioritized Multiple Change on Belief Bases",
      "author" : [ "MA Falappa", "G Kern-Isberner", "MDL Reis", "GR Simari" ],
      "venue" : "Journal of Philosophical Logic, vol. 41,",
      "citeRegEx" : "58",
      "shortCiteRegEx" : "58",
      "year" : 2012
    }, {
      "title" : "Shielded Contraction’, Frontiers in Belief Revision",
      "author" : [ "EL Fermé", "SO Hansson" ],
      "venue" : "Applied Logic Series, Kluwer Academic Publishers,",
      "citeRegEx" : "60",
      "shortCiteRegEx" : "60",
      "year" : 2001
    }, {
      "title" : "AGM 25 Years - Twenty-Five Years of Research in Belief Change",
      "author" : [ "EL Fermé", "SO Hansson" ],
      "venue" : "Journal of Philosophical Logic, vol. 40,",
      "citeRegEx" : "61",
      "shortCiteRegEx" : "61",
      "year" : 2011
    }, {
      "title" : "A Review of Repairing Techniques for Integrity Maintenance’, Rules in Database Systems Workshops in Computing, ed",
      "author" : [ "P Fraternali", "S Paraboschi" ],
      "venue" : null,
      "citeRegEx" : "62",
      "shortCiteRegEx" : "62",
      "year" : 1993
    }, {
      "title" : "Belief Revision",
      "author" : [ "P Gärdenfors" ],
      "venue" : null,
      "citeRegEx" : "63",
      "shortCiteRegEx" : "63",
      "year" : 1992
    }, {
      "title" : "Knowledge in flux",
      "author" : [ "P Gärdenfors" ],
      "venue" : null,
      "citeRegEx" : "64",
      "shortCiteRegEx" : "64",
      "year" : 1998
    }, {
      "title" : "Revisions of knowledge systems using epistemic entrenchment",
      "author" : [ "P Gärdenfors", "D Makinson" ],
      "venue" : "Proceedings of the Second Conference on Theoretical Aspects of Reasoning about Knowledge,",
      "citeRegEx" : "65",
      "shortCiteRegEx" : "65",
      "year" : 1988
    }, {
      "title" : "Specifying Reactive Integrity Control for Active Databases",
      "author" : [ "M Gertz" ],
      "venue" : "Research Issues in Data Engineering, Active Database Systems,",
      "citeRegEx" : "66",
      "shortCiteRegEx" : "66",
      "year" : 1994
    }, {
      "title" : "Integrity Constraints: Semantics and Applications’, Logics for Databases and Information Systems, Kluwer Academic Publishers",
      "author" : [ "P Godfrey", "J Grant", "J Gryz", "J Minker" ],
      "venue" : null,
      "citeRegEx" : "67",
      "shortCiteRegEx" : "67",
      "year" : 1998
    }, {
      "title" : "Two modellings for theory change",
      "author" : [ "A Grove" ],
      "venue" : "Journal of Philosophical Logic,",
      "citeRegEx" : "68",
      "shortCiteRegEx" : "68",
      "year" : 1988
    }, {
      "title" : "Updating Knowledge Bases",
      "author" : [ "A Guessoum", "JW Lloyd" ],
      "venue" : "New Generation Computing, vol. 8,",
      "citeRegEx" : "69",
      "shortCiteRegEx" : "69",
      "year" : 1990
    }, {
      "title" : "Counting solutions to the view maintenance problem",
      "author" : [ "A Gupta", "D Katiyar" ],
      "venue" : "Proceedings of the Workshop on Deductive Databases held in conjunction with the Joint International Conference and Symposium on Logic Programming,",
      "citeRegEx" : "70",
      "shortCiteRegEx" : "70",
      "year" : 1992
    }, {
      "title" : "Maintaining views incrementally",
      "author" : [ "A Gupta", "IS Mumick", "VS Subrahmanian" ],
      "venue" : "Proceedings of the 1993 ACM SIGMOD international conference on Management of data,",
      "citeRegEx" : "71",
      "shortCiteRegEx" : "71",
      "year" : 1993
    }, {
      "title" : "Answering queries using views: A survey",
      "author" : [ "AY Halevy" ],
      "venue" : "Journal The VLDB Journal,",
      "citeRegEx" : "72",
      "shortCiteRegEx" : "72",
      "year" : 2001
    }, {
      "title" : "Belief contraction without recovery",
      "author" : [ "SO Hansson" ],
      "venue" : "Studia Logica, vol. 50,no",
      "citeRegEx" : "73",
      "shortCiteRegEx" : "73",
      "year" : 1991
    }, {
      "title" : "A dyadic representation of belief",
      "author" : [ "SO Hansson" ],
      "venue" : null,
      "citeRegEx" : "74",
      "shortCiteRegEx" : "74",
      "year" : 1992
    }, {
      "title" : "A Textbook of Belief Dynamics",
      "author" : [ "SO Hansson" ],
      "venue" : null,
      "citeRegEx" : "75",
      "shortCiteRegEx" : "75",
      "year" : 1997
    }, {
      "title" : "Theoria’, Special Issue on non-prioritized belief revision, Wiley, Chichester, vol",
      "author" : [ "SO Hansson" ],
      "venue" : null,
      "citeRegEx" : "76",
      "shortCiteRegEx" : "76",
      "year" : 1997
    }, {
      "title" : "Credibility-Limited Revision",
      "author" : [ "SO Hansson", "EL Fermé", "J Cantwell", "Falappa M" ],
      "venue" : "Journal of Symbolic Logic, vol. 66,",
      "citeRegEx" : "77",
      "shortCiteRegEx" : "77",
      "year" : 2001
    }, {
      "title" : "Uniqueness of Update Strategies for Database Views",
      "author" : [ "SJ Hegner" ],
      "venue" : "Proceedings of the Second International Symposium on Foundations of Information and Knowledge Systems,",
      "citeRegEx" : "78",
      "shortCiteRegEx" : "78",
      "year" : 2002
    }, {
      "title" : "A Model of Database Components and their Interconnection Based upon Communicating Views",
      "author" : [ "SJ Hegner" ],
      "venue" : "Proceeding of the 2008 conference on Information Modelling and Knowledge Bases XIX,",
      "citeRegEx" : "79",
      "shortCiteRegEx" : "79",
      "year" : 2007
    }, {
      "title" : "Propositional Belief Base Update and Minimal Change",
      "author" : [ "A Herzig", "O Rifi" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "80",
      "shortCiteRegEx" : "80",
      "year" : 1999
    }, {
      "title" : "Applying evolutionary algorithms to materialized view selection in a data warehouse",
      "author" : [ "JT Horng", "JY Chang", "BJ Liu" ],
      "venue" : "Soft Computing,",
      "citeRegEx" : "81",
      "shortCiteRegEx" : "81",
      "year" : 2003
    }, {
      "title" : "Comparing Abductive Theories",
      "author" : [ "K Inoue", "C Sakama" ],
      "venue" : "Proceedings of the 2008 conference on ECAI 2008: 18th European Conference on Artificial Intelligence,",
      "citeRegEx" : "82",
      "shortCiteRegEx" : "82",
      "year" : 2008
    }, {
      "title" : "Abductive Equivalence in First-order Logic",
      "author" : [ "K Inoue", "C Sakama" ],
      "venue" : "Logic Journal of the IGPL,",
      "citeRegEx" : "83",
      "shortCiteRegEx" : "83",
      "year" : 2006
    }, {
      "title" : "Model Generation for Horn Logic with Stratified Negation",
      "author" : [ "EK Jackson", "W. Schulte" ],
      "venue" : "Proceedings of the 28th IFIP WG 6.1 international conference on Formal Techniques for Networked and Distributed Systems,",
      "citeRegEx" : "84",
      "shortCiteRegEx" : "84",
      "year" : 2008
    }, {
      "title" : "Iterated belief revision, revised",
      "author" : [ "Y Jin", "M Thielscher" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "85",
      "shortCiteRegEx" : "85",
      "year" : 2007
    }, {
      "title" : "Database Updates Through Abduction",
      "author" : [ "AC Kakas", "P Mancarella" ],
      "venue" : "Proceedings of the 16th International Conference on Very Large Data Bases,",
      "citeRegEx" : "86",
      "shortCiteRegEx" : "86",
      "year" : 1990
    }, {
      "title" : "Propositional knowledge base revision and minimal change",
      "author" : [ "H Katsuno", "Mendelzon", "AO" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "87",
      "shortCiteRegEx" : "87",
      "year" : 1991
    }, {
      "title" : "On the difference between updating a knowledge base and revising it",
      "author" : [ "H Katsuno", "AO Mendelzon" ],
      "venue" : null,
      "citeRegEx" : "88",
      "shortCiteRegEx" : "88",
      "year" : 1992
    }, {
      "title" : "Updating Relational Databases Through Views",
      "author" : [ "A Keller" ],
      "venue" : null,
      "citeRegEx" : "89",
      "shortCiteRegEx" : "89",
      "year" : 1985
    }, {
      "title" : "Ontology-based data access systems",
      "author" : [ "MR Kogalovsky" ],
      "venue" : "Programming and Computer Software,",
      "citeRegEx" : "90",
      "shortCiteRegEx" : "90",
      "year" : 2012
    }, {
      "title" : "Improvement operators",
      "author" : [ "S Konieczny", "R Pino Pérez" ],
      "venue" : "Proceedings Eleventh International Conference on Principles of Knowledge Representation and Reasoning,",
      "citeRegEx" : "92",
      "shortCiteRegEx" : "92",
      "year" : 2008
    }, {
      "title" : "Taxonomy of improvement operators and the problem of minimal change",
      "author" : [ "S Konieczny", "MM Grespan", "RP Pérez" ],
      "venue" : "Proceedings of the Twelfth International Conference on the Principles of Knowledge Representation and Reasoning,",
      "citeRegEx" : "93",
      "shortCiteRegEx" : "93",
      "year" : 2010
    }, {
      "title" : "Dynamics of Beliefs",
      "author" : [ "S Konieczny" ],
      "venue" : "Scalable Uncertainty Management Lecture Notes in Computer Science,",
      "citeRegEx" : "94",
      "shortCiteRegEx" : "94",
      "year" : 2011
    }, {
      "title" : "Logic without model theory",
      "author" : [ "R Kowalski" ],
      "venue" : "Technical Report,",
      "citeRegEx" : "95",
      "shortCiteRegEx" : "95",
      "year" : 1994
    }, {
      "title" : "A Logical Account of Relevance",
      "author" : [ "G Lakemeyer" ],
      "venue" : "International Joint Conference on AI,",
      "citeRegEx" : "97",
      "shortCiteRegEx" : "97",
      "year" : 1995
    }, {
      "title" : "Horn Complements: Towards Horn-to-Horn Belief Revision",
      "author" : [ "M Langlois", "RH Sloan", "B Szörényi", "G Thrán" ],
      "venue" : "Proceedings of the 23rd national conference on Artificial intelligence,",
      "citeRegEx" : "98",
      "shortCiteRegEx" : "98",
      "year" : 2008
    }, {
      "title" : "Updating Intensional Predicates in Deductive Databases",
      "author" : [ "D Laurent", "VP V. Luonga", "N Spyratosa" ],
      "venue" : "Data & Knowledge Engineering,",
      "citeRegEx" : "99",
      "shortCiteRegEx" : "99",
      "year" : 1998
    }, {
      "title" : "Speeding up materialized view selection in data warehouses using a randomized algorithm",
      "author" : [ "M Lee", "J Hammer" ],
      "venue" : "International Journal of Cooperative Information Systems,",
      "citeRegEx" : "100",
      "shortCiteRegEx" : "100",
      "year" : 2001
    }, {
      "title" : "The Complexity of Belief Update (Extended in 2003)",
      "author" : [ "P Liberatore" ],
      "venue" : "proceedings of the Fifteenth International Joint Conference on Artificial Intelligence1,",
      "citeRegEx" : "101",
      "shortCiteRegEx" : "101",
      "year" : 1997
    }, {
      "title" : "The Compactness of Belief Revision and Update Operators",
      "author" : [ "P Liberatore", "M Schaerf" ],
      "venue" : "Fundamenta Informaticae,",
      "citeRegEx" : "102",
      "shortCiteRegEx" : "102",
      "year" : 2004
    }, {
      "title" : "On the Complexity of Finding Second-Best Abductive Explanations",
      "author" : [ "P Liberatore", "M Schaerf" ],
      "venue" : "CoRR abs/1204.5859",
      "citeRegEx" : "103",
      "shortCiteRegEx" : "103",
      "year" : 2012
    }, {
      "title" : "Minimal and Consistent Evolution of Knowledge Bases",
      "author" : [ "J Lobo", "G Trajcevski" ],
      "venue" : "Journal of Applied Non-Classical Logics, vol:7,",
      "citeRegEx" : "105",
      "shortCiteRegEx" : "105",
      "year" : 1997
    }, {
      "title" : "Materialized View Selection: A Survey’, IGI book chapter, View Management Techniques and Their Application to Data Stream Management’, DOI: 10.4018/978-1-60566-816-1.ch005",
      "author" : [ "X Li" ],
      "venue" : null,
      "citeRegEx" : "106",
      "shortCiteRegEx" : "106",
      "year" : 2010
    }, {
      "title" : "Efficient maintenance of materialized mediated views",
      "author" : [ "JJ Lu", "G Moerkotte", "J Schue", "VS Subrahmanian" ],
      "venue" : "Proceedings of the 1995 ACM SIGMOD international conference on Management of data, vol.3,",
      "citeRegEx" : "107",
      "shortCiteRegEx" : "107",
      "year" : 1995
    }, {
      "title" : "View Updates in Disjunctive Deductive Databases Based on SLDResolution",
      "author" : [ "W Lu" ],
      "venue" : "Proceedings of the 6th International Workshop on Knowledge Representation meets Databases,",
      "citeRegEx" : "108",
      "shortCiteRegEx" : "108",
      "year" : 1999
    }, {
      "title" : "Maintaining and Restoring Database Consistency with Update Rules",
      "author" : [ "S Maabout" ],
      "venue" : "Workshop DYNAMICS, Joint International Conference and Symposium on Logic Programming",
      "citeRegEx" : "109",
      "shortCiteRegEx" : "109",
      "year" : 1998
    }, {
      "title" : "Screened Revision",
      "author" : [ "D Makinson" ],
      "venue" : "Theoria, vol. 63,",
      "citeRegEx" : "110",
      "shortCiteRegEx" : "110",
      "year" : 1997
    }, {
      "title" : "Modeling view selection as a constraint satisfaction problem",
      "author" : [ "I Mami", "R Coletta", "Z Bellahseneet" ],
      "venue" : "Database and Expert Systems Applications Lecture Notes in Computer Science, ed",
      "citeRegEx" : "111",
      "shortCiteRegEx" : "111",
      "year" : 2011
    }, {
      "title" : "A survey of view selection methods]",
      "author" : [ "I Mami", "Z Bellahsene" ],
      "venue" : "ACM SIGMOD Record,",
      "citeRegEx" : "112",
      "shortCiteRegEx" : "112",
      "year" : 2012
    }, {
      "title" : "Efficient Integrity Checking for Databases with Recursive Views",
      "author" : [ "D Martinenghi", "H Christiansen" ],
      "venue" : "Advances in Databases and Information Systems Lecture Notes in Computer Science, ed. Eder, J, Tallinn, Estonia,",
      "citeRegEx" : "113",
      "shortCiteRegEx" : "113",
      "year" : 2005
    }, {
      "title" : "Incorporating Modification Requests in Updating Consistent Knowledge Bases",
      "author" : [ "E Mayol", "E Teniente" ],
      "venue" : "Fourth Int. Works. on the Deductive Approach to Information Systems and Databases,",
      "citeRegEx" : "114",
      "shortCiteRegEx" : "114",
      "year" : 1993
    }, {
      "title" : "A Survey of Current Methods for Integrity Constraint Maintenance and View Updating",
      "author" : [ "E Mayol", "E Teniente" ],
      "venue" : "Advances in Conceptual Modeling Lecture Notes in Computer Science,",
      "citeRegEx" : "115",
      "shortCiteRegEx" : "115",
      "year" : 1999
    }, {
      "title" : "Logical Approaches to Incomplete Information: A Survey’, Logics for Databases and Information",
      "author" : [ "R Meyden" ],
      "venue" : null,
      "citeRegEx" : "116",
      "shortCiteRegEx" : "116",
      "year" : 1998
    }, {
      "title" : "Logic and Databases: A 20 Year Retrospective",
      "author" : [ "J Minker" ],
      "venue" : "Logic in Databases,",
      "citeRegEx" : "117",
      "shortCiteRegEx" : "117",
      "year" : 1996
    }, {
      "title" : "Reactive Consistency Control in Deductive Databases",
      "author" : [ "G Moerkotte" ],
      "venue" : "ACM Transactions on Database Systems,",
      "citeRegEx" : "118",
      "shortCiteRegEx" : "118",
      "year" : 1991
    }, {
      "title" : "Transaction Trees for Knowledge Revision",
      "author" : [ "L Mota-Herranz", "M Celma-Gimĺęnez", "H Decker" ],
      "venue" : "Flexible Query Answering Systems Advances in Soft Computing, ed. Prof. Larsen, HL,",
      "citeRegEx" : "119",
      "shortCiteRegEx" : "119",
      "year" : 2000
    }, {
      "title" : "Forgetting and Knowledge Update",
      "author" : [ "A Nayak", "Y Chen", "F Lin" ],
      "venue" : "AI 2006: Advances in Artificial Intelligence Lecture Notes in Computer Science,",
      "citeRegEx" : "120",
      "shortCiteRegEx" : "120",
      "year" : 2006
    }, {
      "title" : "Is Revision a Special Kind of Update?",
      "author" : [ "A Nayak" ],
      "venue" : "AI 2011: Advances in Artificial Intelligence Lecture Notes in Computer Science,",
      "citeRegEx" : "121",
      "shortCiteRegEx" : "121",
      "year" : 2011
    }, {
      "title" : "How Hard is it to Revise a Belief Base?",
      "author" : [ "B Nebel" ],
      "venue" : "Handbook of Defeasible Reasoning and Uncertainty Management Systems,",
      "citeRegEx" : "122",
      "shortCiteRegEx" : "122",
      "year" : 1998
    }, {
      "title" : "Knowledge-Base Revision Using Implications as Hypotheses",
      "author" : [ "Ö Özçep" ],
      "venue" : "KI 2012: Advances in Artificial Intelligence Lecture Notes in Computer Science, ed. Glimm, B, Saarbrücken, Germany,",
      "citeRegEx" : "123",
      "shortCiteRegEx" : "123",
      "year" : 2012
    }, {
      "title" : "Beliefs, belief revision, and splitting languages",
      "author" : [ "R Parikh" ],
      "venue" : "Journal of Logic, language, and Computation,",
      "citeRegEx" : "124",
      "shortCiteRegEx" : "124",
      "year" : 1999
    }, {
      "title" : "The Role of Abductive Reasoning within the Process of Belief Revision",
      "author" : [ "M Pagnucco" ],
      "venue" : "PhD Thesis,",
      "citeRegEx" : "125",
      "shortCiteRegEx" : "125",
      "year" : 1996
    }, {
      "title" : "Knowledge-base revision’, The Knowledge Engineering",
      "author" : [ "O Papini" ],
      "venue" : "Review, vol. 15,",
      "citeRegEx" : "126",
      "shortCiteRegEx" : "126",
      "year" : 2000
    }, {
      "title" : "Each normal logic program has a 2-valued Minimal Hypotheses semantics",
      "author" : [ "AM Pinto", "LM Pereira" ],
      "venue" : "19th International Conference on Applications of Declarative Programming and Knowledge Management,",
      "citeRegEx" : "127",
      "shortCiteRegEx" : "127",
      "year" : 2011
    }, {
      "title" : "A Survey of Revision Approaches in Description Logics’, Description Logics",
      "author" : [ "G Qi", "F Yang" ],
      "venue" : "Proceedings of the 2nd International Conference on Web Reasoning and Rule Systems,",
      "citeRegEx" : "128",
      "shortCiteRegEx" : "128",
      "year" : 2008
    }, {
      "title" : "Belief Revision in Pseudo-Definite Sets",
      "author" : [ "Rodrigues", "Benevidas M" ],
      "venue" : "In Proceeding of the 11th Brazilian Symposium on AI",
      "citeRegEx" : "129",
      "shortCiteRegEx" : "129",
      "year" : 1994
    }, {
      "title" : "Change, choice and inference: a study of belief revision and nonmonotonic reasoning’, Oxford logic guides",
      "author" : [ "H Rott" ],
      "venue" : null,
      "citeRegEx" : "130",
      "shortCiteRegEx" : "130",
      "year" : 2001
    }, {
      "title" : "Interleaving belief revision and reasoning: preliminary report",
      "author" : [ "Sadri. F", "F Toni" ],
      "venue" : "In Proceedings of Convegno Italiano di Logica Computazionale",
      "citeRegEx" : "131",
      "shortCiteRegEx" : "131",
      "year" : 2005
    }, {
      "title" : "Incremental Evaluation of Tabled Logic Programs",
      "author" : [ "D Saha", "CR Ramakrishnan" ],
      "venue" : "Logic Programming Lecture Notes in Computer Science Volume,",
      "citeRegEx" : "132",
      "shortCiteRegEx" : "132",
      "year" : 2003
    }, {
      "title" : "Dishonest Reasoning by Abduction",
      "author" : [ "C Sakama" ],
      "venue" : "Proceedings of the TwentySecond international joint conference on Artificial Intelligence,",
      "citeRegEx" : "133",
      "shortCiteRegEx" : "133",
      "year" : 2011
    }, {
      "title" : "Equivalence issues in abduction and induction",
      "author" : [ "C Sakama", "K Inoue" ],
      "venue" : "Journal of Applied Logic, vol.7,",
      "citeRegEx" : "134",
      "shortCiteRegEx" : "134",
      "year" : 2009
    }, {
      "title" : "An abductive framework for computing Horn knowledge base updates",
      "author" : [ "C Sakama", "K Inoue" ],
      "venue" : "Journal Theory and Practice of Logic Programming,",
      "citeRegEx" : "135",
      "shortCiteRegEx" : "135",
      "year" : 2003
    }, {
      "title" : "Updating Extended Logic Programs through Abduction’, Logic Programming and Nonmonotonic Reasoning Lecture Notes in Computer Science, ed",
      "author" : [ "C Sakama", "K Inoue" ],
      "venue" : null,
      "citeRegEx" : "136",
      "shortCiteRegEx" : "136",
      "year" : 1999
    }, {
      "title" : "Database Integrity Mechanism between OLTP and Offline Data",
      "author" : [ "M Salman", "NU Rehmanet", "M Shahid" ],
      "venue" : "Proceedings of the 4th Asian conference on Intelligent Information and Database Systems,",
      "citeRegEx" : "137",
      "shortCiteRegEx" : "137",
      "year" : 2012
    }, {
      "title" : "Tailoring Consistent Specializations as a Natural Approach to Consistency Enforcement’, 6th Int. Workshop on Foundations of Models and Languages for Data and Objects: Integrity in Databases",
      "author" : [ "KD Schewe" ],
      "venue" : null,
      "citeRegEx" : "138",
      "shortCiteRegEx" : "138",
      "year" : 1996
    }, {
      "title" : "Consistency Enforcement in Entity-Relationship and Object Oriented Models",
      "author" : [ "KD Schewe" ],
      "venue" : "Data & Knowledge Eng,",
      "citeRegEx" : "139",
      "shortCiteRegEx" : "139",
      "year" : 1998
    }, {
      "title" : "Controlled Automation of Consistency Enforcement",
      "author" : [ "KD Schewe" ],
      "venue" : "Proceedings of the 15th IEEE international conference on Automated software engineering,",
      "citeRegEx" : "140",
      "shortCiteRegEx" : "140",
      "year" : 2000
    }, {
      "title" : "Minimal Belief Change and Pareto-Optimality",
      "author" : [ "O Schulte" ],
      "venue" : "Australian Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "141",
      "shortCiteRegEx" : "141",
      "year" : 1999
    }, {
      "title" : "Irrevocable Belief Revision in Dynamic Doxastic Logic",
      "author" : [ "K Segerberg" ],
      "venue" : "Notre Dame Journal of Formal Logic, vol. 39,",
      "citeRegEx" : "142",
      "shortCiteRegEx" : "142",
      "year" : 1998
    }, {
      "title" : "Deductive Databases: Challenges, Opportunities and Future Directions (Panel Discussion)",
      "author" : [ "A Siebes", "S Tsur", "JD Ullman", "L Vieille", "C Zaniolo" ],
      "venue" : "Proceedings of the International Workshop on Logic in Databases,",
      "citeRegEx" : "143",
      "shortCiteRegEx" : "143",
      "year" : 1996
    }, {
      "title" : "Incremental maintenance of externally materialized views",
      "author" : [ "M Staudt", "M Jarke" ],
      "venue" : "22th International Conference on Very Large Data Bases,",
      "citeRegEx" : "144",
      "shortCiteRegEx" : "144",
      "year" : 1996
    }, {
      "title" : "A method for change computation in deductive databases",
      "author" : [ "T Urṕı", "A Olivé" ],
      "venue" : "Proceedings of the 18th International Conference on Very Large Data Bases,",
      "citeRegEx" : "146",
      "shortCiteRegEx" : "146",
      "year" : 1992
    }, {
      "title" : "Abductive Logics in a Belief Revision Framework",
      "author" : [ "B Walliser", "D Zwirnet", "H Zwirn" ],
      "venue" : "Journal of Logic, Language and Information, vol:14,",
      "citeRegEx" : "147",
      "shortCiteRegEx" : "147",
      "year" : 2005
    }, {
      "title" : "First order Theory Refinement’, IOS Frontier in AI and Application Series, Advances in ILP, ed",
      "author" : [ "S Wrobel" ],
      "venue" : null,
      "citeRegEx" : "148",
      "shortCiteRegEx" : "148",
      "year" : 1995
    }, {
      "title" : "Language Splitting and Relevance-Based Belief Change in Horn Logic",
      "author" : [ "M Wu", "D Zhang", "M Zhang" ],
      "venue" : "Twenty-Fifth AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "149",
      "shortCiteRegEx" : "149",
      "year" : 2011
    }, {
      "title" : "On Updates and Inconsistency Repairing in Knowledge Bases",
      "author" : [ "B Wüthrich" ],
      "venue" : "IEEE 9th International Conference on Data Engineering,",
      "citeRegEx" : "150",
      "shortCiteRegEx" : "150",
      "year" : 1993
    }, {
      "title" : "Algorithms for materialized view design in data warehousing environment",
      "author" : [ "J Yang", "K Karlapalem", "Q Liet" ],
      "venue" : "Proceedings of the 23rd International Conference on Very Large Data Bases,",
      "citeRegEx" : "151",
      "shortCiteRegEx" : "151",
      "year" : 1997
    }, {
      "title" : "New Polynomial Classes for Logic-Based Abduction",
      "author" : [ "B Zanuttini" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "152",
      "shortCiteRegEx" : "152",
      "year" : 2003
    }, {
      "title" : "Genetic algorithm for materialized view selection in data warehouse environments’, DataWarehousing and Knowledge Discovery, Lecture Notes in Computer Science, ed",
      "author" : [ "C Zhang", "Y Yang" ],
      "venue" : null,
      "citeRegEx" : "153",
      "shortCiteRegEx" : "153",
      "year" : 1999
    }, {
      "title" : "Dynamic materialized views",
      "author" : [ "J Zhou", "PA Larson", "J Goldstein", "L Ding" ],
      "venue" : "IEEE 23rd International Conference on Data Enginering,",
      "citeRegEx" : "154",
      "shortCiteRegEx" : "154",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 24,
      "context" : "Definition 7 ([25]).",
      "startOffset" : 14,
      "endOffset" : 18
    }, {
      "referenceID" : 2,
      "context" : "Definition 8 ([3]).",
      "startOffset" : 14,
      "endOffset" : 17
    }, {
      "referenceID" : 28,
      "context" : "Theorem 11 ([29]).",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 2,
      "context" : "Theorem 12 ([3]).",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 21,
      "context" : "Definition 46 (Normal Logic Program (NLP) [22]).",
      "startOffset" : 42,
      "endOffset" : 46
    }, {
      "referenceID" : 3,
      "context" : "Definition 47 (Level mapping[4]).",
      "startOffset" : 28,
      "endOffset" : 31
    }, {
      "referenceID" : 3,
      "context" : "Definition 48 (Acyclic program [4]).",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 5,
      "context" : "[6 9] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o ι δ SL D N F N o N o S Ye s N o 16, 9 N o N ot pr ov ed",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 8,
      "context" : "[6 9] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o ι δ SL D N F N o N o S Ye s N o 16, 9 N o N ot pr ov ed",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 7,
      "context" : "[8 6] N Ye s M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s ι δ SL D N F N o N o S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 5,
      "context" : "[8 6] N Ye s M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s ι δ SL D N F N o N o S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 8,
      "context" : "[9 6] S Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ — Ye s N o SS Ye s Ye s 16, 7 N ot N ot",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 5,
      "context" : "[9 6] S Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ — Ye s N o SS Ye s Ye s 16, 7 N ot N ot",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 18 ] N N o M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s ι δ — Ye s N o S Ye s N o 16, 7 N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 17,
      "context" : "[1 18 ] N N o M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s ι δ — Ye s N o S Ye s N o 16, 7 N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 6,
      "context" : "[7 0] S Ye s C he ck C om p.",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 4,
      "context" : "[5 1] N Ye s C he ck R un Lo gi c Ye s N o St at ic Ye s ι δ pr ed ef Ye s N o S Ye s N o 16, 7 N ot N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[5 1] N Ye s C he ck R un Lo gi c Ye s N o St at ic Ye s ι δ pr ed ef Ye s N o S Ye s N o 16, 7 N ot N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 46 ] S Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ χ SL D N F N o N o SS Ye s N o 16, 7 Ye s N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 44,
      "context" : "[1 46 ] S Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ χ SL D N F N o N o SS Ye s N o 16, 7 Ye s N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 6,
      "context" : "[7 1] N Ye s M ai nt ai n R un Lo gi c Ye s N o St at ic Ye s ι δ U nf ol d Ye s N o SS Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[7 1] N Ye s M ai nt ai n R un Lo gi c Ye s N o St at ic Ye s ι δ U nf ol d Ye s N o SS Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 14 ] N Ye s M ai nt ai n C om p.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 13,
      "context" : "[1 14 ] N Ye s M ai nt ai n C om p.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 50 ] S Ye s M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s ι δ U nf ol d.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 48,
      "context" : "[1 50 ] S Ye s M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s ι δ U nf ol d.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 7,
      "context" : "[8 ] H Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ SL D Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 1,
      "context" : "[2 6] N N o M ai nt ai n C om p R el at io n Ye s Li m ite d St at ic Ye s ι δ χ A ct iv e Ye s Ye s S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 5,
      "context" : "[2 6] N N o M ai nt ai n C om p R el at io n Ye s Li m ite d St at ic Ye s ι δ χ A ct iv e Ye s Ye s S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 5,
      "context" : "[6 6] N N o M ai nt ai n C om p R el at io n N o Fl at St at ic Ye s ι δ χ A ct iv e Ye s Ye s S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 5,
      "context" : "[6 6] N N o M ai nt ai n C om p R el at io n N o Fl at St at ic Ye s ι δ χ A ct iv e Ye s Ye s S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 1,
      "context" : "[2 9] H Ye s C he ck C om p.",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 8,
      "context" : "[2 9] H Ye s C he ck C om p.",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 2,
      "context" : "[3 7] N Ye s M ai nt ai n R un Lo gi c Ye s Fl at St at ic Ye s ι δ U nf ol d.",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 6,
      "context" : "[3 7] N Ye s M ai nt ai n R un Lo gi c Ye s Fl at St at ic Ye s ι δ U nf ol d.",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 07 ] N Ye s M ai nt ai n R un Lo gi c Ye s Li m ite d St at ic N o ι δ A ct iv e Ye s N o SS Ye s N o 16, 7 Ye s N ot pr ov ed",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 45 ] N Ye s M ai nt ai n C om p Lo gi c Ye s Ye s St at ic Ye s ι δ SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 43,
      "context" : "[1 45 ] N Ye s M ai nt ai n C om p Lo gi c Ye s Ye s St at ic Ye s ι δ SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 38 ] S Ye s M ai nt ai n C om p Lo gi c N o Fl at St at ic Ye s ι δ pr ed ef — Ye s G N o Ye s — N o N ot",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 37,
      "context" : "[1 38 ] S Ye s M ai nt ai n C om p Lo gi c N o Fl at St at ic Ye s ι δ pr ed ef — Ye s G N o Ye s — N o N ot",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 44 ] N N o M ai nt ai n C om p Lo gi c Ye s Li m ite d St at ic Ye s ι δ χ P re de f Ye s N o S Ye s N o 16, 7 Ye s N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 42,
      "context" : "[1 44 ] N N o M ai nt ai n C om p Lo gi c Ye s Li m ite d St at ic Ye s ι δ χ P re de f Ye s N o S Ye s N o 16, 7 Ye s N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 0] H Ye s C he ck R un Lo gi c Ye s Li m ite d St at ic Ye s ι δ SL D Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 3,
      "context" : "[4 0] N Ye s M ai nt ai n R un Lo gi c Ye s Ye s St at ic Ye s ι δ SL D N F N o N o S Ye s N o 16, 7 N o N ot P ro ve d",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 05 ] N Ye s M ai nt ai n R un Lo gi c Ye s Fl at St at ic Ye s ι δ U nf ol d N o Ye s G Ye s N o 16, 7 N ot N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 51 ] H N o M ai nt ai n C om p.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 49,
      "context" : "[1 51 ] H N o M ai nt ai n C om p.",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 09 ] N N o M ai nt ai n C om p Lo gi c N o Fl at St at ic Ye s ι δ A ct iv e Ye s N o G N o N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 39 ] N N o M ai nt ai n C om p R el at io n N o Fl at St at ic Ye s ι δ A ct iv e Ye s N o S N o N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 38,
      "context" : "[1 39 ] N N o M ai nt ai n C om p R el at io n N o Fl at St at ic Ye s ι δ A ct iv e Ye s N o S N o N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 08 ] N Ye s C he ck R un Lo gi c Ye s Li m ite d St at ic Ye s ι δ SL D Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 ] O N o M ai nt ai n R un Lo gi c Ye s Li m ite d St at ic Ye s ι δ — Ye s N o S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 0,
      "context" : "[1 40 ] N N o M ai nt ai n C om p R el at io n N o Li m ite d St at ic Ye s ι δ P re de f N o N o G N o N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 39,
      "context" : "[1 40 ] N N o M ai nt ai n C om p R el at io n N o Li m ite d St at ic Ye s ι δ P re de f N o N o G N o N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 6,
      "context" : "[7 2] N N o M ai nt ai n C om p Lo gi c Ye s Li m ite d St at ic Ye s ι δ — N o N o S N o N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 1,
      "context" : "[7 2] N N o M ai nt ai n C om p Lo gi c Ye s Li m ite d St at ic Ye s ι δ — N o N o S N o N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 2,
      "context" : "[3 0] N N o M ai nt ai n C om p.",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 4,
      "context" : "[5 2] H Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ P re de f Ye s N o S Ye s N o 16, 7 Ye s N ot",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 1,
      "context" : "[5 2] H Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ P re de f Ye s N o S Ye s N o 16, 7 Ye s N ot",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 6,
      "context" : "[7 8] O Ye s C he ck R un R el at io n Ye s Li m ite d St at ic N o ι δ U nf ol d Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 7,
      "context" : "[7 8] O Ye s C he ck R un R el at io n Ye s Li m ite d St at ic N o ι δ U nf ol d Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 4] O Ye s C he ck R un R el at io n Ye s Li m ite d St at ic N o ι δ U nf ol d Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 3,
      "context" : "[1 4] O Ye s C he ck R un R el at io n Ye s Li m ite d St at ic N o ι δ U nf ol d Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 4,
      "context" : "[5 6] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 5,
      "context" : "[5 6] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 32 ] N N o M ai nt ai n R un Lo gi c Ye s Li m ite d St at ic Ye s ι δ P re de f Ye s N o S Ye s N o 16, 7 Ye s N ot",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 31,
      "context" : "[1 32 ] N N o M ai nt ai n R un Lo gi c Ye s Li m ite d St at ic Ye s ι δ P re de f Ye s N o S Ye s N o 16, 7 Ye s N ot",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 7,
      "context" : "[8 1] O N o M ai nt ai n C om p R el at io n Ye s Li m ite d St at ic Ye s ι δ — Ye s N o S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[8 1] O N o M ai nt ai n C om p R el at io n Ye s Li m ite d St at ic Ye s ι δ — Ye s N o S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 35 ] N Ye s C he ck R un Lo gi c N o Li m ite d St at ic Ye s ι δ SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 34,
      "context" : "[1 35 ] N Ye s C he ck R un Lo gi c N o Li m ite d St at ic Ye s ι δ SL D N F Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 4,
      "context" : "[5 7] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o ι δ SL D N F N o N o S Ye s N o 16, 9 N ot N o pr ov ed",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 6,
      "context" : "[5 7] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o ι δ SL D N F N o N o S Ye s N o 16, 9 N ot N o pr ov ed",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 13 ] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o ι δ χ SL D Ye s N o S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 12,
      "context" : "[1 13 ] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o ι δ χ SL D Ye s N o S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 9] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o ι δ χ SL D Ye s N o SS Ye s N o 16, 7 Ye s N ot",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 8,
      "context" : "[1 9] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic N o ι δ χ SL D Ye s N o SS Ye s N o 16, 7 Ye s N ot",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 2,
      "context" : "[3 1] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ χ P re de f Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[3 1] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ χ P re de f Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 1,
      "context" : "[2 5] N Ye s C he ck C om p Lo gi c Ye s Ye s D yn am ic Ye s ι δ P re de f Ye s N o S Ye s N o — N ot N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 4,
      "context" : "[2 5] N Ye s C he ck C om p Lo gi c Ye s Ye s D yn am ic Ye s ι δ P re de f Ye s N o S Ye s N o — N ot N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 2,
      "context" : "[3 2] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ χ P re de f Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 1,
      "context" : "[3 2] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ χ P re de f Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 2,
      "context" : "[3 5] N N o M ai nt ai n C om p Lo gi c Ye s N o — Ye s ι δ — Ye s N o S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 4,
      "context" : "[3 5] N N o M ai nt ai n C om p Lo gi c Ye s N o — Ye s ι δ — Ye s N o S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 54 ] N N o M ai nt ai n R un R el at io n Ye s N o — Ye s ι δ χ U nf ol d Ye s N o SS N o N o — N ot N ot",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 52,
      "context" : "[1 54 ] N N o M ai nt ai n R un R el at io n Ye s N o — Ye s ι δ χ U nf ol d Ye s N o SS N o N o — N ot N ot",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 6,
      "context" : "[7 9] O N o M ai nt ai n C om p.",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 8,
      "context" : "[7 9] O N o M ai nt ai n C om p.",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 5] S Ye s C he ck R un Lo gi c Ye s Fl at St at ic Ye s ι δ SL D N F Ye s N o S Ye s N o 16, 9 Ye s N ot",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 4,
      "context" : "[1 5] S Ye s C he ck R un Lo gi c Ye s Fl at St at ic Ye s ι δ SL D N F Ye s N o S Ye s N o 16, 9 Ye s N ot",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 4,
      "context" : "[5 3] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ — Ye s N o S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 2,
      "context" : "[5 3] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ — Ye s N o S Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 1,
      "context" : "[2 7] O N o M ai nt ai n R un R el at io n Ye s N o St at ic Ye s ι δ SL D Ye s Ye s G N o N o — N ot N ot",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 6,
      "context" : "[2 7] O N o M ai nt ai n R un R el at io n Ye s N o St at ic Ye s ι δ SL D Ye s Ye s G N o N o — N ot N ot",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[1 6] O N o M ai nt ai n C om p R el at io n Ye s N o St at ic Ye s ι δ χ — Ye s N o SS Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 5,
      "context" : "[1 6] O N o M ai nt ai n C om p R el at io n Ye s N o St at ic Ye s ι δ χ — Ye s N o SS Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 3,
      "context" : "[4 ] O N o M ai nt ai n C om p.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 0,
      "context" : "[1 11 ] N N o M ai nt ai n C om p R el at io n N o Ye s St at ic Ye s ι δ χ U nf ol d N o Ye s SS N o N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 10,
      "context" : "[1 11 ] N N o M ai nt ai n C om p R el at io n N o Ye s St at ic Ye s ι δ χ U nf ol d N o Ye s SS N o N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 0,
      "context" : "[1 37 ] N N o C he ck C om p Lo gi c N o Ye s St at ic Ye s ι δ A ct iv e Ye s N o G Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 36,
      "context" : "[1 37 ] N N o C he ck C om p Lo gi c N o Ye s St at ic Ye s ι δ A ct iv e Ye s N o G Ye s N o — N o N o",
      "startOffset" : 0,
      "endOffset" : 7
    }, {
      "referenceID" : 3,
      "context" : "[4 1] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ SL D Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    }, {
      "referenceID" : 0,
      "context" : "[4 1] N Ye s C he ck R un Lo gi c Ye s Ye s St at ic Ye s ι δ SL D Ye s N o S Ye s N o 16, 9 Ye s Ye s",
      "startOffset" : 0,
      "endOffset" : 5
    } ],
    "year" : 2015,
    "abstractText" : "The dynamics of belief and knowledge is one of the major components of any autonomous system that should be able to incorporate new pieces of information. In order to apply the rationality result of belief dynamics theory to various practical problems, it should be generalized in two respects: first it should allow a certain part of belief to be declared as immutable; and second, the belief state need not be deductively closed. Such a generalization of belief dynamics, referred to as base dynamics, is presented in this paper, along with the concept of a generalized revision algorithm for knowledge bases (Horn or Horn logic with stratified negation). We show that knowledge base dynamics has an interesting connection with kernel change via hitting set and abduction. In this paper, we show how techniques from disjunctive logic programming can be used for efficient (deductive) database updates. The key idea is to transform the given database together with the update request into a disjunctive (datalog) logic program and apply disjunctive techniques (such as minimal model reasoning) to solve the original update problem. The approach extends and integrates standard techniques for efficient query answering and integrity checking. The generation of a hitting set is carried out through a hyper tableaux calculus and magic set that is focused on the goal of minimality. The present paper provides a comparative study of view update algorithms in rational approach. For, understand the basic concepts with abduction, we provide an abductive framework for knowledge base dynamics. Finally, we demonstrate how belief base dynamics can provide an axiomatic characterization for insertion a view atom to the database. We give a quick overview of the main operators for belief change, in particular, belief update versus database update. Keyword: AGM, Belief Revision, Belief Update, Horn Knowledge Base Dynamics, Kernel Change, Abduction, Hyber Tableaux, Magic Set, View update, Update Propagation.",
    "creator" : "LaTeX with hyperref package"
  }
}