{
  "name" : "1403.0461.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Timed Soft Concurrent Constraint Programs: An Interleaved and a Parallel Approach",
    "authors" : [ "Stefano Bistarelli", "Maurizio Gabbrielli", "Maria Chiara Meo", "Francesco Santini" ],
    "emails" : [ "vista@dmi.unipg.it", "gabbri@cs.unibo.it", "cmeo@unich.it", "F.Santini@cwi.nl" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\nWe propose a timed and soft extension of Concurrent Constraint Programming. The time extension is based on the hypothesis of bounded asynchrony: the computation takes a bounded period of time and is measured by a discrete global clock. Action prefixing is then considered as the syntactic marker which distinguishes a time instant from the next one. Supported by soft constraints instead of crisp ones, tell and ask agents are now equipped with a preference (or consistency) threshold which is used to determine their success or suspension. In the paper we provide a language to describe the agents behavior, together with its operational and denotational semantics, for which we also prove the compositionality and correctness properties. After presenting a semantics using maximal parallelism of actions, we also describe a version for their interleaving on a single processor (with maximal parallelism for time elapsing). Coordinating agents that need to take decisions both on preference values and time events may benefit from this language. To appear in Theory and Practice of Logic Programming (TPLP).\nKEYWORDS: Soft Concurrent Constraint Programming, Timed Concurrent Constraint Programming, Interleaving, Parallelism."
    }, {
      "heading" : "1 Introduction",
      "text" : "Time is a particularly important aspect of cooperative environments. In many “reallife” computer applications, the activities have a temporal duration (that can be even interrupted) and the coordination of such activities has to take into consideration this timeliness property. The interacting actors are mutually influenced by their actions, meaning that A reacts accordingly to the timing and quantitative aspects related to B ’s behavior, and vice versa. In fact, these interactions can be often related to quantities to be measured or minimized/maximized, in order to take actions depending from these scores: consider, for example, some generic communicating agents that need to take decisions on a (monetary) cost or a (fuzzy) preference for a shared resource. They both need to coordinate through time-dependent and preference-based decisions.\nA practical example of such agents corresponds, for example, to software agents that need to negotiate some service-level agreement on a resource, or a service, with time-related side-conditions. For instance, a fitting example is given by auction schemes, where the seller/bidder agents need to agree on a preference for a given prize (e.g., a monetary cost). At the same time, the agents have to respect some timeout and alarm events, respectively representing the absence and the presence of bids for the prize (for instance). The language we present in this paper is well suited for this kind of interactions, as Section 5 shows with examples.\nThe Timed Concurrent Constraint Programming (tccp), a timed extension of the pure formalism of Concurrent Constraint Programming (ccp) (Saraswat 1989), has been introduced in (de Boer et al. 2000). The language is based on the hypothesis of bounded asynchrony (Saraswat et al. 1996): computation takes a bounded period of time rather than being instantaneous as in the concurrent synchronous languages ESTEREL (Berry and Gonthier 1992), LUSTRE (Halbwachs et al. 1991), SIGNAL (le Guernic et al. 1991) and Statecharts (Harel 1987). Time itself is measured by a discrete global clock, i.e., the internal clock of the tccp process. In (de Boer et al. 2000) the authors also introduced timed reactive sequences, which describe the reaction of a tccp process to the input of the external environment, at each moment in time. Formally, such a reaction is a pair of constraints 〈c, d〉, where c is the input and d is the constraint produced by the process in response to c.\nSoft constraints (Bistarelli 2004; Bistarelli et al. 1997) extend classical constraints\nto represent multiple consistency levels, and thus provide a way to express preferences, fuzziness, and uncertainty. The ccp framework has been extended to work with soft constraints (Bistarelli et al. 2006), and the resulting framework is named Soft Concurrent Constraint Programming (sccp). With respect to ccp, in sccp the tell and ask agents are equipped with a preference (or consistency) threshold, which is used to determine their success, failure, or suspension, as well as to prune the search; these preferences should preferably be satisfied but not necessarily (i.e. overconstrained problems). We adopt soft constraints instead of crisp ones, since classic constraints show evident limitations when trying to represent real-life scenarios, where the knowledge is not completely available nor crisp.\nIn this paper, we introduce a timed and soft extension of ccp that we call Timed\nSoft Concurrent Constraint Programming (tsccp), inheriting from both tccp and sccp at the same time. In tsccp, we directly introduce a timed interpretation of the usual programming constructs of sccp, by identifying a time-unit with the time needed for the execution of a basic sccp action (ask and tell), and by interpreting action prefixing as the next-time operator. An explicit timing primitive is also introduced in order to allow for the specification of timeouts. In the first place, the parallel operator of tsccp is first interpreted in terms of maximal parallelism, as in (de Boer et al. 2000). Secondly, we also consider a different paradigm, where the parallel operator is interpreted in terms of interleaving, however assuming maximal parallelism for actions depending on time. In other words, time passes for all the parallel processes involved in a computation. This approach, analogous to that one adopted in (de Boer et al. 2004), is different from that one of (de Boer et al. 2000; Bistarelli et al. 2008) (where maximal parallelism was assumed for any kind of action), and it is also different from the one considered in (Busi et al. 2000), where time does not elapse for timeout constructs. This can be accomplished by allowing all the time-only dependent actions (τ -transitions) to concurrently run with at most one action manipulating the store (a ω-transition).\nThe paper extends the results in (Bistarelli et al. 2008) by providing new semantics that allows maximal parallelism for time elapsing and an interleaving model for basic computation steps (see Section 7). This new language is called tsccp with interleaving, i.e., tsccp-i, to distinguish it from the version allowing maximal parallelism of all actions. According to the maximal parallelism policy (applied, for example, in the original works as (Saraswat 1989) and (Saraswat et al. 1994)), at each moment every enabled agent of the system is activated, while in the interleaving paradigm only one of the enabled agents is executed instead. This second paradigm is more realistic if we consider limited resources, since it does not imply the existence of an unbounded number of processors. However, in (de Boer et al. 2000) it is shown that the notion of maximal parallelism of tsccp is more expressive than the notion of interleaving parallelism of other concurrent constraint languages. The presence of maximal parallelism can force the computation to discard some (non-enabled) branches which could became enabled later on (because of the information produced by parallel agents), while this is not possible when considering an interleaving model. Therefore, tsccp is sensitive to delays in adding constraints to the store, whereas this is not the case for ccp and tsccp-i.\nThe rest of the paper is organized as follows: in Section 2 we summarize the most important background notions and frameworks from which tsccp derives, i.e. tccp and sccp. In Section 3 we present the tsccp language, and in Section 4 describes the operational semantics of tscc agents. Section 5 better explains the programming idioms as timeout and interrupt, exemplifies the use of timed paradigms in the tscc language and shows an application example on modeling an auction interaction among several bidders and a single auctioneer. Section 6 describes the denotational semantics for tsccp, and proves the denotational model correctness with the aid of connected reactive sequences. Section 7 explains the semantics for interleaving with maximal parallelism of time-elapsing actions (i.e. the tsccp-i language), while Section 8 describes a timeline for the execution of three parallel agents in tsccp-i.\nSection 9 describes the denotational semantics of tsccp-i and proves the correctness of the denotational model. Section 10 reports the related work and, at last, Section 11 concludes by also indicating future research."
    }, {
      "heading" : "2 Background",
      "text" : ""
    }, {
      "heading" : "2.1 Soft Constraints",
      "text" : "A soft constraint (Bistarelli et al. 1997; Bistarelli 2004) may be seen as a constraint where each instantiation of its variables has an associated value from a partially ordered set which can be interpreted as a set of preference values. Combining constraints will then have to take into account such additional values, and thus the formalism has also to provide suitable operations for combination (×) and comparison (+) of tuples of values and constraints. This is why this formalization is based on the concept of c-semiring (Bistarelli et al. 1997; Bistarelli 2004), called just semiring in the rest of the paper.\nSemirings. A semiring is a tuple 〈A,+,×,0,1〉 such that: i) A is a set and 0,1 ∈ A; ii) + is commutative, associative and 0 is its unit element; iii) × is associative, distributes over +, 1 is its unit element and 0 is its absorbing element. A c-semiring is a semiring 〈A,+,×,0,1〉 such that: + is idempotent, 1 is its absorbing element and × is commutative. Let us consider the relation ≤S over A such that a ≤S b iff a + b = b. Then, it is possible to prove that (see (Bistarelli et al. 1997)): i) ≤S is a partial order; ii) + and × are monotone on ≤S ; iii) 0 is its minimum and 1 its maximum; iv) 〈A,≤S〉 is a complete lattice (a complete lattice is a partially ordered set in which all subsets have both a supremum and an infimum) and, for all a, b ∈ A, a + b = lub(a, b) (where lub is the least upper bound).\nMoreover, if × is idempotent, then: + distributes over ×; 〈A,≤S〉 is a complete distributive lattice and × its glb (greatest lower bound). Informally, the relation ≤S gives us a way to compare semiring values and constraints. In fact, when we have a ≤S b, we will say that b is better than a. In the following, when the semiring will be clear from the context, a ≤S b will be often indicated by a ≤ b.\nConstraint System. Given a semiring S = 〈A,+,×,0,1〉 and an ordered set of variables V over a finite domain D , a soft constraint is a function which, given an assignment η : V → D of the variables, returns a value of the semiring. Using this notation C = η → A is the set of all possible constraints that can be built starting from S , D and V .\nAny function in C involves all the variables in V , but we impose that it depends on the assignment of only a finite subset of them. So, for instance, a binary constraint cx ,y over variables x and y, is a function cx ,y : (V → D) → A, but it depends only on the assignment of variables {x , y} ⊆ V (the support of the constraint, or scope). Note that cη[v := d1] means cη ′ where η′ is η modified with the assignment v := d1 (that is the operator [ ] has precedence over application). Note also that cη is the application of a constraint function c : (V → D) → A to a function η : V → D ; what we obtain, is a semiring value cη.\nThe partial order ≤S over C can be easily extended among constraints by defining\nc1 ⊑ c2 ⇔ c1η ≤ c2η, for each possible η.\nCombining and projecting soft constraints. Given the set C, the combination function ⊗ : C×C → C is defined as (c1⊗c2)η = c1η×c2η (see also (Bistarelli et al. 1997; Bistarelli 2004; Bistarelli et al. 2006)). Informally, performing the ⊗ between two constraints means building a new constraint whose support involves all the variables of the original ones, and which associates with each tuple of domain values for such variables a semiring element which is obtained by multiplying the elements associated by the original constraints to the appropriate sub-tuples.\nGiven a constraint c ∈ C and a variable v ∈ V , the projection (Bistarelli et al. 1997;\nBistarelli 2004; Bistarelli et al. 2006) of c over V − {v}, written c ⇓(V−{v}) is the constraint c′ s.t. c′η = ∑\nd∈D cη[v := d ]. Informally, projecting means eliminating\nsome variables from the support. This is done by associating with each tuple over the remaining variables a semiring element which is the sum of the elements associated by the original constraint to all the extensions of this tuple over the eliminated variables.\nWe define also a function ā (Bistarelli 2004; Bistarelli et al. 2006) as the function that returns the semiring value a for all assignments η, that is, āη = a. We will usually write ā simply as a. An example of constants that will be useful later are 0̄ and 1̄ that represent respectively the constraints associating 0 and 1 to all the assignment of domain values.\nSolutions. A SCSP (Bistarelli 2004) is defined as P = 〈V ,D ,C , S 〉, where C is the set of constraints defined over variables in V (each with domain D), and whose preference is determined by semiring S . The best level of consistency notion is defined as blevel(P) = Sol(P) ⇓∅, where Sol(P) = ⊗ C (Bistarelli 2004). A problem P is α-consistent if blevel(P) = α (Bistarelli 2004). P is instead simply “consistent” iff there exists α >S 0 such that P is α-consistent. P is inconsistent if it is not consistent.\nExample 1 Figure 1 shows a weighted SCSP as a graph: the weighted semiring is used, i.e. 〈R+∪ {∞},min, +̂, ∞, 0〉 (+̂ is the arithmetic plus operation). Variables and constraints are represented respectively by nodes and arcs (unary for c1-c3, and binary for c2); D = {a, b}. The solution of the CSP in Figure 1 associates a semiring element to\nevery domain value of variables X and Y by combining all the constraints together, i.e. Sol(P) = ⊗ C . For instance, for the tuple 〈a, a〉 (that is, X = Y = a), we have to compute the sum of 1 (which is the value assigned to X = a in constraint c1), 5 (〈X = a,Y = a〉 in c2) and 5 (Y = a in c3): the value for this tuple is 11. The solution X = a,Y = b is a 7-consistent solution, where 7 corresponds to the blevel of P , i.e., Sol(P) ⇓∅= 7."
    }, {
      "heading" : "2.2 Concurrent Constraint Programming over Soft Constraints",
      "text" : "The basic idea underlying ccp (Saraswat 1989) is that computation progresses via monotonic accumulation of information in a constraint global store. Information is produced by the concurrent and asynchronous activity of several agents which can add (tell) a constraint to the store. Dually, agents can also check (ask) whether a constraint is entailed by the store, thus allowing synchronization among different agents. The ccp languages are defined parametrically w.r.t. a given constraint system. The notion of constraint system has been formalized in (Saraswat and Rinard 1990) following Scott’s treatment of information systems. Soft constraints over a semiring S = 〈A,+,×,0,1〉 and an ordered set of variables V (over a domain D) have been showed to form a constraint system “à la Saraswat”, thus leading to the definition of Soft Concurrent Constraint Programmingg (sccp) (Bistarelli et al. 1997; Bistarelli 2004; Bistarelli et al. 2006).\nConsider the set C and the partial order ⊑. Then an entailment relation ⊢⊆\n℘(C) × C is defined s.t. for each C ∈ ℘(C) and c ∈ C, we have C ⊢ c ⇔ ⊗ C ⊑ c (see also (Bistarelli 2004; Bistarelli et al. 2006)). Note that in this setting the notion of token (constraint) and of set of tokens (set of constraints) closed under entailment is used indifferently. In fact, given a set of constraint functions C1, its closure w.r.t. entailment is a set C̄1 that contains all the constraints greater than ⊗ C1. This set is univocally representable by the constraint function ⊗\nC1. The definition of the\nentailment operator ⊢ on top of C, and of the ⊑ relation, lead to the notion of soft constraint system. It is also important to notice that in (Saraswat 1989) it is claimed that a constraint system is a complete algebraic lattice. In the sccp framework, algebraicity is not required (Bistarelli et al. 2006) instead, since the algebraic nature of the structure C strictly depends on the properties of the semiring1.\nTo treat the hiding operator of the language, a general notion of existential quantifier is introduced by using notions similar to those used in cylindric algebras. Consider a set of variables V with domain D and the corresponding soft constraint system C. For each x ∈ V , the hiding function (Bistarelli 2004; Bistarelli et al. 2006) is the function (∃xc)η = ∑\ndi∈D cη[x := di ]. To make the hiding operator computa-\ntionally tractable, it is required that the number of domain elements in D , having semiring values different from 0, is finite (Bistarelli et al. 2006). In this way, to compute the sum needed for (∃x c)η, we can consider just a finite number of elements\n1 Notice that we do not aim at computing the closure of the entailment relation, but only to use the entailment relation to establish if a constraint is entailed by the current store, and this can be established even if the lattice is not algebraic (that is even if the times operator is not idempotent).\n(those different from 0), since 0 is the unit element of the sum. Note that by using the hiding function we can represent the ⇓ operator defined in Section 2.1. In fact, for any constraint c and any variable x ⊆ V , c ⇓V−x= ∃xc (Bistarelli et al. 2006).\nTo model parameter passing also diagonal elements have to be defined. Consider a set of variables V and the corresponding soft constraint system. Then, for each x , y ∈ V , a diagonal constraint is defined as dxy ∈ C s.t., dxyη[x := a, y := b] = 1 if a = b, and dxyη[x := a, y := b] = 0 if a 6= b (Bistarelli 2004; Bistarelli et al. 2006).\nTheorem 1 (cylindric constraint system (Bistarelli et al. 2006))\nConsider a semiring S = 〈A,+,×,0,1〉, a domain of the variables D , an ordered set of variables V , and the corresponding structure C. Then, SC = 〈C,⊗,0,1, ∃x , dxy〉, is a cylindric constraint system."
    }, {
      "heading" : "2.3 Timed Concurrent Constraint Programming",
      "text" : "A timed extension of ccp, called tccp has been introduced in (de Boer et al. 2000). Similarly to other existing timed extensions of ccp defined in (Saraswat et al. 1996), tccp is a language for reactive programming designed around the hypothesis of bounded asynchrony (as introduced in (Saraswat et al. 1996): computation takes a bounded period of time rather than being instantaneous).\nWhen querying the store for some information that is not present (yet), a ccp agent will simply suspend until the required information has arrived. In timed applications however often one cannot wait indefinitely for an event. Consider for example the case of a connection to a web service providing some on-line banking facility. In case the connection cannot be established, after a reasonable amount of time an appropriate time-out message has to be communicated to the user. A timed language should then allow us to specify that, in case a given time bound is exceeded (i.e. a time-out occurs), the wait is interrupted and an alternative action is taken. Moreover, in some cases it is also necessary to have a preemption mechanism which allows one to abort an active process A and to start a process B when a specific (abnormal) event occurs.\nIn order to be able to specify these timing constraints tccp introduces a discrete global clock and assumes that ask and tell actions take one time-unit. Computation evolves in steps of one time-unit, so called clock-cycles. Action prefixing is the syntactic marker which distinguishes a time instant from the next one and it is assumed that parallel processes are executed on different processors, which implies that, at each moment, every enabled agent of the system is activated. This assumption gives rise to what is called maximal parallelism. The time in between two successive moments of the global clock intuitively corresponds to the response time of the underlying constraint system. Thus all parallel agents are synchronized by the response time of the underlying constraint system. Since the store is monotonically increasing and one can have dynamic process creation, clearly the previous assumptions imply that the constraint solver takes a constant time (no matter how big the store is), and that there is an unbounded number of processors. However, one can impose suitable restriction on programs, thus ensuring that the (significant\npart of the) store and the number of processes do not exceed a fixed bound; these restrictions would still allow significant forms of recursion with parameters.\nFurthermore, a timing construct of the form now c then A else B is introduced in tccp, whose semantics is the following: if the constraint c is entailed by the store at the current time t , then the above agent behaves as A at time t , otherwise it behaves as B at time t . This basic construct allows to derive such timing mechanisms as time-out and preemption (de Boer et al. 2000; Saraswat et al. 1996). The instantaneous reaction can be obtained by evaluating nowc in parallel with A and B , within the same time-unit. At the end of this time-unit, the store will be updated by using either the constraint produced by A, or that one produced by B , depending on the result of the evaluation of nowc. Clearly, since A and B could contain nested now then else agents, a limit for the number of these nested agents should be fixed. Note that, for recursive programs, such a limit is ensured by the presence of the procedure-call, since we assume that the evaluation of such calls takes one time-unit."
    }, {
      "heading" : "3 Timed Soft Concurrent Constraint Programming",
      "text" : "In this section we present the tsccp language, which originates from both tccp and sccp. To obtain this aim, we extend the syntax of the cc language with the timing construct nowc thenA elseB (inherited from tccp), and also in order to directly handle the cut level as in sccp. This means that the syntax and semantics of the tell, ask and nowagents have to be enriched with a threshold that is used to check when the agents may succeed, or suspend.\nDefinition 1 (tsccp Language) Given a soft constraint system 〈S ,D ,V 〉, the corresponding structure C, any semiring value a, soft constraints φ, c ∈ C and any tuple of variables x , the syntax of the tsccp language is given by the following grammar:\nP ::= F .A F ::= p(x ) :: A | F · F A ::= success | tell(c) →φ A | tell(c) → a A | E | A ‖ A | ∃xA | p(x ) |\nΣni=1Ei | nowφ c then A else A | now a c then A else A\nE ::= ask(c) →φ A | ask(c) → a A\nwhere, as usual, P is the class of processes, F is the class of sequences of procedure declarations (or clauses), A is the class of agents. In a tsccp process P = F .A, A is the initial agent, to be executed in the context of the set of declarations F . The agent success represents a successful termination, so it may not make any further transition.\nIn the following, given an agentA, we denote by Fv(A) the set of the free variables of A (namely, the variables which do not appear in the scope of the ∃ quantifier). Besides the use of soft constraints (see Section 2.2) instead of crisp ones, there are two fundamental differences between tsccp and ccp. The first main difference w.r.t. the original cc syntax is the presence of a semiring element a and of a constraint\nφ to be checked whenever an ask or tell operation is performed. More precisely, the level a (respectively, φ) will be used as a cut level to prune computations that are not good enough. The second main difference with respect to ccp (but, this time, also with respect to sccp) is instead the presence of the nowc then A else B construct introduced in Section 2.3. Even for this construct, the level a (or φ) is used as a cut level to prune computations.\nAction prefixing is denoted by →, non-determinism is introduced via the guarded choice construct Σni=1Ei , parallel composition is denoted by ‖, and a notion of locality is introduced by the agent ∃xA, which behaves like A with x considered local to A, thus hiding the information on x provided by the external environment.\nIn the next subsection we formally describe the operational semantics of tsccp. In order to simplify the notation, in the following we will usually write a tsccp process P = F .A simply as the corresponding agent A.\n4 An Operational Semantics for tsccp Agents\nThe operational model of tscc agents can be formally described by a transition system T = (Conf ,−→) where we assume that each transition step takes exactly one time-unit. Configurations in Conf are pairs consisting of a process and of a constraint in C, representing the common store shared by all the agents. The transition relation −→⊆ Conf ×Conf is the least relation satisfying the rules R1R17 in Figure 2, and it characterizes the (temporal) evolution of the system. So, 〈A, σ〉 −→ 〈B , δ〉 means that, if at time t we have the process A and the store σ, then at time t + 1 we have the process B and the store δ.\nLet us now briefly discuss the rules in Figure 2. Here is a brief description of the\ntransition rules:\nValued-tell. The valued-tell rule checks for the a-consistency of the Soft Con-\nstraint Satisfaction Problem (Bistarelli 2004) (SCSP) defined by the store σ ⊗ c. A SCSP P is a-consistent if blevel(P) = a, where blevel(P) = Sol(P) ⇓∅, i.e., the best level of consistency of the problem P is a semiring value representing the least upper bound among the values yielded by the solutions. Rule R1 can be applied only if the store σ ⊗ c is b-consistent with b 6< a2. In this case the agent evolves to the new agent A over the store σ ⊗ c. Note that different choices of the cut level a could possibly lead to different computations. Finally, note that the updated store σ ⊗ c will be visible only starting from the next time instant, since each transition step involves exactly one time-unit. Tell. The tell action is a finer check of the store. In this case (see rule R2), a\npointwise comparison between the store σ⊗ c and the constraint φ is performed. The idea is to perform an overall check of the store, and to continue the computation only if there is the possibility to compute a solution not worse than φ. Note that this notion of tell could be also applied to the classical cc framework:\n2 Notice that we use b 6< a instead of b ≥ a because we can possibly deal with partial orders. The same holds also for 6⊏ instead of ⊒.\nthe tell operation would succeed when the set of tuples satisfying constraint φ is not a superset of the set of tuples allowed by σ ∩ c.3 As for the valued tell, the updated store σ ⊗ c will be visible only since the next time instant. In the following, let us use tell(c) → A and tell(c) as a shorthand for tell(c) →0̄ A and tell(c) →0̄ success, respectively. Valued-ask. The semantics of the valued-ask is extended in a way similar to what\nwe have done for the valued-tell action. This means that, to apply the rule R3, we need to check if the store σ entails the constraint c, and also if σ is “consistent enough” w.r.t. the threshold a set by the programmer.\nAsk. In rule R4, we check if the store σ entails the constraint c, but, similarly to\nrule R2, we also compare a finer (pointwise) threshold φ to the store σ. As for the tell action, let us use ask(c) → A as a shorthand for ask(c) →0̄ A. Parallelism. Rules R5 and R6 model the parallel composition operator in terms\nof maximal parallelism: the agent A ‖ B executes in one time-unit all the initial enabled actions of A and B . Considering rule R5 (where maximal parallelism is accomplished in practice), notice that the ordering of the operands in σ⊗δ⊗δ′ is not relevant, since ⊗ is commutative and associative. Moreover, for the same two properties, if σ⊗δ = σ⊗γ and σ⊗δ′ = σ⊗γ′, we have that σ⊗δ⊗δ′ = σ⊗γ⊗γ′. Therefore the resulting store σ ⊗ δ ⊗ δ′ is independent from the choice of the constraint δ such that 〈A, σ〉 −→ 〈A′, σ′〉 and σ′ = σ ⊗ δ (analogously for δ′).\nNondeterminism. According to rule R7, the guarded choice operator gives rise\nto global non-determinism: the external environment can affect the choice, since ask(cj ) is enabled at time t (and Aj is started at time t + 1) if and only if the store σ entails cj (and if it is compatible with the threshold too), and σ can be modified by other agents.\nValued-now and Now. RulesR8-R11 show that the agent nowa c then A else\nB behaves as A or B depending on the fact that c is or is not entailed by the store, provided that the current store σ is compatible with the threshold. Differently from the case of the ask, here the evaluation of the guard is instantaneous: if current store σ is compatible with the threshold a, 〈A, σ〉 (〈B , σ〉) can make a transition at time t and c is (is not) entailed by the store σ, then the agent nowa c then A else B can make the same transition at time t . Moreover, observe that in any case the control is passed either to A (if c is entailed by the current store σ and σ is compatible with the threshold) or to B (in case σ does not entail c and σ is compatible with the threshold). Analogously for the not-valued version, i.e., nowφ c then A else B (see rules R12-R15). Finally, we use now c then A else B as a shorthand for the agent now0̄ c then A else B Hiding variables. The agent ∃xA behaves like A, with x considered local to A, as\nshow by rule R16. This is obtained by substituting the variable x for a variable y, which we assume to be new and not used by any other process. Standard renaming techniques can be used to ensure this; in rule R16, A[x/y] denotes the process obtained from A by replacing the variable x for the variable y.\n3 Notice that the ⊗ operator in the crisp case reduces to set intersection.\nProcedure-calls. Rule R17 treats the case of a procedure-call when the actual\nparameter equals the formal parameter. We do not need more rules since, for the sake of simplicity, here and in the following we assume that the set F of procedure declarations is closed w.r.t. parameter names: that is, for every procedure-call p(y) appearing in a process F.A, we assume that, if the original declaration for p in F is p(x ) :: A, then F contains also the declaration p(y) :: ∃x (tell(dxy ) ‖ A). 4 Moreover, we assume that if p(x ) :: A ∈ F , then Fv(A) ⊆ x .\nUsing the transition system described by (the rules in) Figure 2, we can now define our notion of observables, which considers the results of successful terminating computations that the agent A can perform for each tsccp process P = F .A. Here and in the following, given a transition relation −→, we denote by −→∗ its reflexive and transitive closure.\nDefinition 2 (Observables) Let P = F .A be a tsccp process. We define\nOmpio (P) = {γ ⇓Fv(A)| 〈A,1〉 −→ ∗ 〈Success, γ〉}\nwhere Success is any agent which contains only occurrences of the agent success and of the operator ‖."
    }, {
      "heading" : "5 Programming Idioms and Examples",
      "text" : "We can consider the primitives in Definition 1 to derive the soft version of the programming idioms in (de Boer et al. 2000), which are typical of reactive programming.\nDelay. The delay constructs tell(c) t −→φ A or ask(c) t −→φ A are used to delay the\nexecution of agent A after the execution of tell(c) or ask(c); t is the number of the time-units of delay. Therefore, in addiction to a constraint φ, in tsccp the transition arrow can have also a number of delay slots. This idiom can be defined by induction: the base case is 0\n−→φ A ≡→φ A, and the inductive\nstep is n+1 −→φ A ≡→φ tell(1̄) n −→0̄ A. The valued version can be defined in an analogous way.\nTimeout. The timed guarded choice agent Σni=1ask(ci) →i Ai timeout(m)B waits at\nmost m time-units (m ≥ 0) for the satisfaction of one of the guards; notice that all the ask actions have a soft transition arrow, i.e. →i is either of the form →φi or → ai , as in Figure 2. Before this time-out, the process behaves just like the guarded choice: as soon as there exist enabled guards, one of them (and the corresponding branch) is nondeterministically selected. After waiting for m time-units, if no guard is enabled, the timed choice agent behaves as B . Timeout constructs can be assembled through the composition of several\n4 Here the (original) formal parameter is identified as a local alias of the actual parameter. Alternatively, we could have introduced a new rule treating explicitly this case, as it was in the original ccp papers.\nnowφ c then A else B primitives (or their valued version), as explained in (de Boer et al. 2000) for the (crisp) tccp language. The timeout can be defined inductively as follows: let us denote by A the agent Σni=1ask(ci) →i Ai . In the base case, that ism = 0, we define Σ n i=1ask(ci) →i Ai timeout(0)B as the agent:\nnow1 c1 then A\nelse ( now2 c2 then A\nelse (. . . ( nown cn then A else ask(1̄) → B) . . .))\nwhere for i = 1, . . . , n, either nowi = nowφi if →i is of the form →φi or nowi = now ai if →i is of the form → ai . Because of the operational semantics explained in rules R8-R11 (see Figure 2), if a guard ci is true, then the agent Σni=1ask(ci) →i Ai is evaluated in the same time slot. Otherwise, if no guard ci is true, the agent B is evaluated in the next time slot. Then, by inductively reasoning on the number of time-units m, we can define Σni=1ask(ci) →i Ai timeout(m)B as\nΣni=1ask(ci) →i Ai timeout(0) (Σ n i=1ask(ci) →i Ai timeout(m − 1)B).\nWatchdog. Watchdogs are used to interrupt the activity of a process on a signal from a\nspecific event. The idiom do A watchingφ c behaves as A, as long as c is not entailed by the store and the current store is compatible with the threshold; when c is entailed and the current store is compatible with the threshold, the process A is immediately aborted. The reaction is instantaneous, in the sense that A is aborted at the same time instant of the detection of the entailment of c. However, according to the computational model, if c is detected at time t , then c has to be produced at time t ′ with t ′ < t . Thus, we have a form of weak preemption. As well as timeouts, also watchdog agents can be defined in terms of the other basic constructs of the language (see Figure 3). In the following we assume that there exists an (injective) renaming function ρ which, given a procedure name p, returns a new name ρ(p) that is not used elsewhere in the program. Moreover, let us use nowφ c else B as a shorthand for nowφ c then success else B , where we assume that, for any procedure p declared as p(x ) :: A, a declaration ρ(p)(x ) :: do ρ(A) watchingφ c is added, where ρ(A) denotes the agent obtained from A by replacing in it each occurrence of any procedure q by ρ(q). The assumption in the case of the ∃xA agent is needed for correctness. In practical cases, it can be satisfied by suitably renaming the variables associated to signals. In the following →′ is either of the form →ψ or → a . Analogously for now′. The translation in Figure 3 can be easily extended to the case of the agent do A watchingφ c else B , which behaves as the previous watchdog and also activates the process B when A is aborted (i.e., when c is entailed and the current state is compatible with the threshold). In the following we will then use also this form of watchdog.\nc1 : ({x} → N) → R + s.t. c1(x) = x + 3 c2 : ({x} → N) → R + s.t. c2(x) = x + 5\nc3 : ({x} → N) → R + s.t. c3(x) = 2x + 8\nWith this small set of idioms, we have now enough expressiveness to describe complex interactions. For the following examples on the new programming idioms, we consider the Weighted semiring 〈R+ ∪ {+∞},min,+,+∞, 0〉 (Bistarelli 2004; Bistarelli et al. 1997) and the (weighted) soft constraints in Figure 4. We first provide simple program examples in order to explain as more details as possible on how a computation of tsccp agents proceeds. In Section 5.1 we show a more complex example describing the classical actions during a negotiation process; the aim of that example is instead to show the expressivity of the tsccp language, without analyzing its execution in detail.\nExample 2 (Delay)\nAs a first very simple example, suppose to have two agents A1,A2 of the form: A1 :: tell(1̄) 2 −→ +∞ tell(c2) → +∞ success and A2 :: tell(1̄) 1 −→ +∞ ask(c1) → 9 success; their concurrent evaluation in the 1̄ ≡ 0̄ empty store is:\n〈(tell(0̄) 2 −→+∞ tell(c2)→ +∞ success) ‖ (tell(0̄) 1 −→+∞ ask(c1) → 9 success), 0̄〉.\nThe timeline for this parallel execution is described in Figure 5. For the evaluation of tell and ask we respectively consider the rules R1 and R3 in Figure 2, since both transitions are a-valued. However, both these two actions are delayed: three time-units for the tell(c2) of A1 (including the first tell(0̄)), and two time-units for the ask(c1) of A2 (including the first tell(0̄)). As explained before, this can be obtained by adding 1̄ to the store with a tell action respectively three, and two times. Therefore, the parallel agent A1 ‖ A2 corresponds to:\n(tell(0̄) →+∞ tell(0̄) → +∞ tell(0̄) →+∞ tell(c2) → +∞ success) ‖\n(tell(0̄) →+∞ tell(0̄) →+∞ ask(c1) → 9 success).\nThis agent is interpreted by using R5-R6 in Figure 2 in terms of maximal parallelism, i.e., all the actions are executed in parallel. The first two tell of A1 and A2 can be simultaneously executed by using ruleR1: the precondition (0̄⊗0̄) ⇓∅= 0 6< 9 of the rule is then satisfied. The store does not change since 0̄⊗ 0̄ = 0̄. At this point, the ask action of A2 is not enabled because 0̄ 6⊢ c1, that is the precondition σ ⊢ c1 of R3 is not satisfied. Therefore, the processor can only be allocated to A1 and, since (0̄⊗ 0̄) ⇓∅= 0 6< +∞ is true (i.e. the precondition of R1 is satisfied), at t = 3 the computation is in the state:\n〈tell(c2) → +∞ success ‖ ask(c1) → 9 success, 0̄〉.\nNow the tell can be executed because (0̄⊗ c2) ⇓∅= 5 6< +∞: therefore, the store\nbecomes equal to 0̄⊗ c2 = c2:\n〈success ‖ ask(c1) → 9 success, c2〉.\nAt t = 5 (see Figure 5) we can successfully terminate the program: in the store σ = c2 the ask is finally enabled at t = 4, according to the two preconditions of rule R3, i.e., c2 ⊢ c1 and c2 ⇓∅= 5 6< 9: therefore we have A1 ‖ A2 :: 〈success ‖ success, c2〉.\nExample 3 (Timeout) In this second example we evaluate a timeout construct. Suppose we have two agents A1 and A2 of the form:\nA1 :: ((ask(c1) → +∞ success) + (ask(c2) → +∞ success)) timeout(1)\nask(c1) → +∞ success\nand\nA2 :: tell(0̄) 2 −→+∞ tell(c3) → +∞ success\nThe description of agent A1 is a shortcut for the following agent, as previously\nexplained in the definition of the timeout:\nnow+∞ c1 then B else (now +∞ c2 then B else\n(ask(1̄) → now+∞ c1 then B else\n(now+∞ c2 then B else (ask(1̄) → ask(c1) → +∞ success)))).\nwhere B :: (ask(c1) → +∞ success + ask(c2) → +∞ success). Their concurrent evaluation in the 1̄ ≡ 0̄ empty store is:\n〈(B timeout(1) ask(c1) → +∞ success ‖ tell(0̄) 2 −→+∞ tell(c3) → +∞ success), 0̄〉.\nThe timeline for this parallel execution is given in Figure 6. At t = 0 the store is empty (i.e., σ = 0̄), thus both constraints c1 and c2 asked by the nondeterministic choice agent A1 are not entailed. In A2, the tell of c3, which would entail both c1 and c2, is delayed by three time-units: in the first three time-units, tell(0̄) → +∞ is executed according to the delay construct, as shown in Example 2. At t = 2 the timeout is triggered in A1, since, according to R1, R6 and R9 (see Figure 2), the time elapsing in the timeout construct can be executed together with the delay-tell actions of A2. After the timeout triggering, agent A1 is however blocked, since c1 is not entailed by the current empty store, and the precondition of the ask (rule R3) is not satisfied. A2 can execute the last delay-tell, and then perform the tell(c3) operation at t = 3; the store becomes σ = 0̄ ⊗ c3 = c3. This finally unblocks A1 at t = 4, since, according to the precondition of rule R3, σ ⊑ c1 (i.e., c3 ⊑ c1). Finally, at t = 5 we have 〈success ‖ success, c3〉.\nExample 4 (Watchdog) In this example let\nA1 :: do (tell(c1) → +∞ ask(c3) → +∞ success) watching+∞(c2) else\n( tell(c3) → +∞ success )\nand\nA2 :: tell(c2) → +∞ success.\nWe evaluate the following watchguard construct with two agents A1 and A2 in\nparallel:\n〈(do (tell(c1) → +∞ ask(c3) → +∞ success) watching+∞(c2) else\n( tell(c3) → +∞ success ) ‖ tell(c2) → +∞ success), 0̄〉.\nAccording to Figure 3, agent A1 is translated in the following way, where the agent B is a shorthand for the “else” branch of the watchdog, that is tell(c3) → +∞ success:\nnow+∞ c2 then B else (tell(c1) → +∞ now+∞ c2 then B else\n(ask(c3) → +∞ now+∞ c2 then B else success)).\nThe execution timeline for this parallel agent is shown in Figure 7. In the first time-unit we have that σ = 0̄ 6⊑ c2, i.e., the store does not imply the guard of the now+∞, and therefore the interruption of the watchguard in A1 is not triggered yet. Thus, in the first time-unit, both tell(c1) → +∞ of agent A1 and tell(c2) → +∞ of agent A2 are executed. At time t = 1, the interruption of the watchguard is immediately activated (i.e. now+∞c2), since the store is now equal to c1 ⊗ c2 = c3 and c3 ⊢ c2 (rule R8 in Figure 2). Therefore, tell(c3) → +∞ of agent B in A1 is executed, while A2 already corresponds to the success agent)."
    }, {
      "heading" : "5.1 An Auction Example",
      "text" : "In Figure 8 we model the negotiation and the management of a generic service offered with a sort of auction: auctions, as other forms of negotiation, naturally need both timed and quantitative means to describe the interactions among agents. We reckon that an auction provides one of the most suitable example where to show the expressivity of the tsccp language, since both time and preference (for a service or\nan object) are considered. In the following of the description we consider a buyout auction (Gallien and Gupta 2007), where the auctioneer improves the service and the related consumed resources (or, alternatively, its money price), bid after bid. When one (ore more) of the bidders agrees with the offer, it bids for it and the auction is immediately declared as over.\nThe auctioneer (i.e. AUCTIONEER in Figure 8) begins by offering a service described with the soft constraint cA1 . We suppose that the cost associated to the soft constraint is expressed in terms of computational capabilities needed to support the execution of the service: e.g., ci ⊑ cj means that the service described by ci needs more computational resources than cj . By choosing the proper semiring, this load can be expressed as a percentage of the CPU use, or in terms of money, for example; we left this preference generic in the example, since we focus on the interaction among the agents.\nWe suppose that a constraint can be defined over three domains of QoS features: availability, reliability and execution time. For instance, cA1 is defined as availability > 95%∧ reliability > 99%∧ execution time < 3sec. Clearly, providing a higher availability or reliability, and a lower execution time implies raising the computational resources to support this improvement, thus worsening the preference of the store.\nAfter the offer, the auctioneer gives time to the bidders (each of them described with a possibly different agent BIDDERi in Figure 8) to make their offer, since the choice of the winner is delayed by tsell time-units (as in many real-world auction schemes). A level aA is used to effectively check that the global consistency of the store is enough good, i.e., the computational power would not be already consumed under the given threshold. After the winner is nondeterministically chosen among all the bidders asking for the service, the auctioneer becomes a supervisor of the\nused resource by executing the agent CHECK . Otherwise, if no offer is received within wA time-units, a timeout interrupts the wait and the auctioneer improves the offered service by adding a new constraint: for example, in tell(cA2), cA2 could be equivalent to execution time < 1sec, thus reducing the latency of the service (from 3 to 1 second) and consequently raising, at the same time, its computational cost (i.e., σ = cA1 ⊗ cA2 ⊑ cA1 means that we worsen the consistency level of the store). The same offer/wait process is repeated three times in Figure 8.\nEach of the bidders in Figure 8 executes its own task (i.e., TASKi , left generic since not in the scope of the example), but as soon as the offered resource meets its demand (i.e. cBi is satisfied by the store: σ ⊑ cBi ), the bidder is interrupted and then asks to use the service. The time needed to react and make an offer is modeled with tbuyi : fast bidders will have more chances to win the auction, if their request arrives before the choice of the auctioneer. If one of the bidders wins, then it becomes a user of the resource, by executing USERi .\nThe agentUSERi uses the service (through the agentUSE SERVICEi , left generic in Figure 8), but it stops (using agent STOPi , left generic in Figure 8) as soon as the service is interrupted, i.e., as the store satisfies service = interrupt. On the other side, agent CHECK waits for the use termination, but it interrupts the user if the computation takes too long (more than wC time-units), or if the user absorbs the computational capabilities beyond a given threshold, i.e. as soon as the ccheck becomes implied by the store (i.e. σ ⊑ ccheck): in fact, USE SERVICEi could be allowed to ask for more power by “telling” some more constraints to the store. To interrupt the service use, agent CHECK performs a tell(service = interrupt). All the agents INIT , left generic in Figure 8, can be used to initialize the computation. In order to avoid a heavy notation in Figure 8, we do not show the preference associated to constraints and the consistency check label on the transition arrows, when they are not significative for the example description. Also the φCheck, φBidder and φUser thresholds of the watchguard constructs are not detailed.\nFinally, in the following we model a more refined behaviour of the auctioneer, which accepts the bidding with the highest value, where CHECK , BIDDERi and USERi are defined as in Figure 8.\nMany other real-life automated tasks can be modeled with the tsccp language.\nFor example, a quality-driven composition of web services: the agents that represent different web services can add to the store their functionalities (represented by soft constraints) with tell actions; the final store models their composition. The consistency level of the store represents (for example) the total monetary cost of the obtained service, or a value representing the consistency of the integrated functionalities. The reason is that, when we compose the services offered by different providers, we cannot be sure of how much they are compatible. A client wishing to use the composed service can perform an ask with a threshold such that it prevents the client from paying a high price, or having an unreliable service. Softness is also useful to model incomplete service specifications that may evolve incrementally and, in general, for non-functional aspects."
    }, {
      "heading" : "6 The Denotational Model",
      "text" : "In this section we define a denotational characterization of the operational semantics obtained by following the construction in (de Boer et al. 2000), and by using timed reactive sequences to represent tsccp computations. These sequences are similar to those used in the semantics of dataflow languages (Jonsson 1985), imperative languages (Brookes 1993) and (timed) ccp (de Boer and Palamidessi 1991; de Boer et al. 2000).\nThe denotational model associates with a process a set of timed reactive sequences of the form 〈σ1, γ1〉 · · · 〈σn , γn〉〈σ, σ〉 where a pair of constraints 〈σi , γi〉 represents a reaction of the given process at time i : intuitively, the process transforms the global store from σi to γi or, in other words, σi is the assumption on the external environment while γi is the contribution of the process itself (which always entails the assumption). The last pair denotes a “stuttering step” in which the agent Success has been reached. Since the basic actions of tsccp are monotonic and we can also model a new input of the external environment by a corresponding tell operation, it is natural to assume that reactive sequences are monotonic. Thus, in the following we assume that each timed reactive sequence 〈σ1, γ1〉 · · · 〈σn−1, γn−1〉〈σn , σn〉 satisfies the conditions γi ⊢ σi and σj ⊢ γj−1, for any i ∈ [1, n − 1] and j ∈ [2, n].\nThe set of all reactive sequences is denoted by S, its typical elements by s , s1 . . ., while sets of reactive sequences are denoted by S , S1 . . ., and ε indicates the empty reactive sequence. Furthermore, the symbol · denotes the operator that concatenates sequences. In the following, Process denotes the set of tsccp processes.\nOperationally, the reactive sequences of an agent are generated as follows.\nDefinition 3 (Processes Semantics)\nWe define the semantics R ∈ Process → P(S) by\nR(F .A) = {〈σ, σ′〉 · w ∈ S | 〈A, σ〉 −→ 〈B, σ′〉 and w ∈ R(F .B)}\n∪ {〈σ, σ〉 · w ∈ S | 〈A, σ〉 6−→ and\neither A 6= Success and w ∈ R(F .A) or A = Success and w ∈ R(F .A) ∪ {ε}}.\nFormally R is defined as the least fixed-point of the operator Φ ∈ (Process →\nP(S)) → Process → P(S) defined by\nΦ(I )(F .A) = {〈σ, δ〉 · w ∈ S | 〈A, σ〉 −→ 〈B, δ〉 and w ∈ I (F .B)}\n∪ {〈σ, σ〉 · w ∈ S | 〈A, σ〉 6−→ and\neither A 6= Success and w ∈ I (F .A) or A = Success and w ∈ I (F .A) ∪ {ε}}.\nThe ordering on Process → P(S) is that of (point-wise extended) set-inclusion, and since it is straightforward to check that Φ is continuous, standard results ensure that the least fixpoint exists (and it is equal to ⊔n≥0Φ n(⊥)).\nNote that R(F .A) is the union of the set of all successful reactive sequences that start with a reaction of A, and the set of all successful reactive sequences that start with a stuttering step of A. In fact, when an agent is blocked, i.e., it cannot react to the input of the environment, a stuttering step is generated. After such a stuttering step, the computation can either continue with the further evaluation of A (possibly generating more stuttering steps), or it can terminate if A is the Success agent. Note also that, since the Success agent used in the transition system cannot make any move, an arbitrary (finite) sequence of stuttering steps is always appended to each reactive sequence."
    }, {
      "heading" : "6.1 Correctness",
      "text" : "The observables Ompio (P) describing the input/output pairs of successful computations can be obtained from R(P) by considering suitable sequences, namely those sequences which do not perform assumptions on the store. In fact, note that some reactive sequences do not correspond to real computations: Clearly, when considering a real computation no further contribution from the environment is possible. This means that, at each step, the assumption on the current store must be equal to the store produced by the previous step. In other words, for any two consecutive steps 〈σi , σ ′ i〉〈σi+1, σ ′ i+1〉 we must have σ ′ i = σi+1. Thus, we are led to the following.\nDefinition 4 (Connected Sequences) Let s = 〈σ1, σ ′ 1〉〈σ2, σ ′ 2〉 · · · 〈σn , σn〉 be a reactive sequence. We say that s is connected if σ1 = 1 and σi = σ ′ i−1 for each i , 2 ≤ i ≤ n.\nAccording to the previous definition, a sequence is connected if all the information assumed on the store is produced by the process itself. To be defined as connected, a sequence must also have 1 as the initial constraint. A connected sequence s = 〈1, σ1〉〈σ1, σ2〉 · · · 〈σn , σn〉 represents a tsccp computation of a process F .A, where 1 is the input constraint and σn ⇓Fv(A) is the result. From the above discussion we can derive the following property:\nProposition 1 (Correctness) For any process P = F .A we have\nOmpio (P) = {σn ⇓Fv(A)| there exists a connected sequence s ∈ R(P) such that\ns = 〈1, σ1〉〈σ1, σ2〉 · · · 〈σn , σn〉}.\nProof From the close correspondence between the rules of the transition system and the definition of the denotational semantics, we have that s ∈ R(P) if and only if s = 〈σ1, σ ′ 1〉〈σ2, σ ′ 2〉 · · · 〈σn , σn〉, A1 = A, An = Success and for i ∈ [1, n − 1],\n• either 〈Ai , σi〉 −→ 〈Ai+1, σ ′ i〉 • or 〈Ai , σi〉 6−→, Ai+1 = Ai and σ ′ i = σi .\nThen there exists a connected sequence s ∈ R(P) if and only if s = 〈σ1, σ2〉〈σ2, σ3〉 · · · 〈σn , σn〉, A1 = A, σ1 = 1, An = Success and for i ∈ [1, n − 1], 〈Ai , σi〉 −→ 〈Ai+1, σi+1〉. Therefore, the proof follows by definition of O mp io (P)."
    }, {
      "heading" : "6.2 Compositionality of the Denotational Semantics for tsccp Processes",
      "text" : "In order to prove the compositionality of the denotational semantics, we now introduce a semantics [[F .A]](e), which is compositional by definition and where, for technical reasons, we explicitly represent the environment e that associates a denotation to each procedure identifier. More precisely, assuming that Pvar denotes the set of procedure identifiers, Env = Pvar → P(S), with typical element e, is the set of environments. Given e ∈ Env , p ∈ Pvar and f ∈ P(S), we denote by e ′ = e{f /p} the new environment such that e ′(p) = f and e ′(p′) = e(p′) for each procedure identifier p′ 6= p.\nGiven a process F .A, the denotational semantics [[F .A]] : Env → P(S) is defined by the equations in Figure 10, where µ denotes the least fixpoint with respect to the subset inclusion of elements of P(S). The semantic operators appearing in Figure 10 are formally defined as follows; intuitively they reflect the operational behavior of their syntactic counterparts in terms of reactive sequences.5 We first need the following definition.\nDefinition 5 Let σ, φ and c be constraints in C and let a ∈ A. We say that\n• σ ≻a c, if (σ ⊢ c and σ ⇓∅ 6< a) while σ ≻φ c, if (σ ⊢ c and σ 6⊏ φ).\nDefinition 6 (Semantic operators) Let S , Si be sets of reactive sequences, c, ci be constraints and let ≻i be either of the form ≻ai or ≻φi . Then we define the operators ˜tell , ∑̃ , ‖̃, ˜now and ∃̃x as follows: The (valued) tell operator\n˜tell a (c, S ) = {s ∈ S | s = 〈σ, σ ⊗ c〉 · s ′, σ ⊗ c ⇓∅ 6< a and s ′ ∈ S }.\n˜tellφ(c, S ) = {s ∈ S | s = 〈σ, σ ⊗ c〉 · s ′, σ ⊗ c 6⊏ φ and s ′ ∈ S }.\n5 In Figure 10 the syntactic operator →i is either of the form → ai or →φi .\nThe guarded choice ∑̃n\ni=1 ci ≻i Si = {s · s ′ ∈ S | s = 〈σ1, σ1〉 · · · 〈σm , σm〉, σj 6≻i ci for each j ∈ [1,m-1], i ∈ [1, n],\nσm ≻h ch and s ′ ∈ Sh for an h ∈ [1, n] }.\nThe parallel composition Let ‖̃ ∈ S ×S → S be the (commutative and associative) partial operator defined as follows:\n〈σ1, σ1 ⊗ γ1〉 · · · 〈σn , σn ⊗ γn〉〈σ, σ〉 ‖̃ 〈σ1, σ1 ⊗ δ1〉 · · · 〈σn , σn ⊗ δn〉〈σ, σ〉 = 〈σ1, σ1 ⊗ γ1 ⊗ δ1〉 · · · 〈σn , σn ⊗ γn ⊗ δn〉〈σ, σ〉.\nWe define S1‖̃S2 as the point-wise extension of the above operator to sets.\nThe (valued) now operator\n˜nowa(c, S1, S2) = {s ∈ S | s = 〈σ, σ ′〉 · s ′, σ ⇓∅ 6< a and\neither σ ⊢ c and s ∈ S1 or σ 6⊢ c and s ∈ S2 }.\n˜nowφ(c, S1, S2) = {s ∈ S | s = 〈σ, σ ′〉 · s ′, σ 6⊏ φ and\neither σ ⊢ c and s ∈ S1 or σ 6⊢ c and s ∈ S2 }.\nThe hiding operator The semantic hiding operator can be defined as follows:\n∃̃xS = {s ∈ S | there exists s ′ ∈ S such that s = s ′[x/y] with y new }\nwhere s ′[x/y] denotes the sequence obtained from s ′ by replacing the variable x for the variable y, which we assume to be new.6\nObviously, the semantic (valued) tell operator reflects the operational behavior of the syntactic (valued) tell. Concerning the semantic choice operator, a sequence in ∑̃n\ni=1ci ≻i Si consists of an initial period of waiting for a store which satisfies\none of the guards. During this waiting period, only the environment is active by producing the constraints σj , while the process itself generates the stuttering steps 〈σj , σj 〉. When the store is strong enough to satisfy a guard, that is to entail a ch and to satisfy the condition on the cut level, the resulting sequence is obtained by adding s ′ ∈ Sh to the initial waiting period. In the semantic parallel operator defined on sequences, we require that the two arguments of the operator agree at each point of time with respect to the contribution of the environment (the σi ’s), and that they have the same length (in all other cases the parallel composition is assumed being undefined).\nIf F .A is a closed process, that is if all the procedure names occurring in A are defined in F , then [[F .A]](e) does not depend on e, and it will be indicated as [[F .A]]. Environments in general allow us to define the semantics also of processes that are not closed. The following result shows the correspondence between the two semantics we have introduced and, therefore, it proves the compositionality of R(F .A). From the above discussion we can derive the following property:\n6 To be more precise, we assume that each time that we consider a new application of the operator\n∃̃ we use a new, different y . As in the case of the operational semantics, this can be ensured by a suitable renaming mechanism.\nProposition 2 (Compositionality) If F .A is closed then R(F .A) = [[F .A]] holds.\nProof We prove by induction on the complexity of the agent A that\n[[F .A]] = {s | s = 〈σ1, σ ′ 1〉〈σ2, σ ′ 2〉 · · · 〈σn , σn〉,\nA1 = A,An = Success and for i ∈ [1, n − 1], either 〈Ai , σi〉 −→ 〈Ai+1, σ ′ i〉 or 〈Ai , σi〉 6−→, Ai+1 = Ai , σ ′ i = σi}.\nThen the proof follows by definition of R(P).\nWhen the P is not of the form F .B ‖ C the thesis follows immediately from the close correspondence between the rules of the transition system and the definition of the denotational semantics.\nAssume now that P is of the form F .B ‖ C . By definition of the denotational\nsemantics, s ∈ [[F .A]] if and only if s = 〈σ1, σ ′ 1〉〈σ2, σ ′ 2〉 · · · 〈σn , σn〉 and there exist s ′ ∈ [[F .B ]] and s ′′ ∈ [[F .C ]],\ns ′ = 〈σ1, σ1 ⊗ γ1〉〈σ2, σ2 ⊗ γ2〉 · · · 〈σn , σn〉 s ′′ = 〈σ1, σ1 ⊗ δ1〉〈σ2, σ2 ⊗ δ2〉 · · · 〈σn , σn〉\nsuch that for each i ∈ [1, n−1], σ′i = σi⊗γi⊗δi . By inductive hypothesis s ′ ∈ [[F .B ]] and s ′′ ∈ [[F .C ]] if and only if for i ∈ [1, n − 1],\neither 〈Bi , σi〉 −→ 〈Bi+1, σi ⊗ γi〉,\nor 〈Bi , σi〉 6−→, Bi+1 = Bi , σi ⊗ γi = σi and\neither 〈Ci , σi〉 −→ 〈Ci+1, σi ⊗ δi〉,\nor 〈Ci , σi〉 6−→, Ci+1 = Ci , σi ⊗ δi = σi .\n(1)\nB1 = B , Bn = Success, C1 = C and Cn = Success. Therefore, by Rule R8 and previous observations, we have that (1) holds if and only if B1 ‖ C1 = B ‖ C , Bn ‖ Cn = Success and for i ∈ [1, n − 1],\neither 〈Bi ‖ Ci , σi〉 −→ 〈Bi+1 ‖ Ci+1, σ ′ i〉 or 〈Bi ‖ Ci , σi〉 6−→, Ai+1 ‖ Bi+1 = Ai ‖ Bi , σ ′ i = σi\nand then the thesis."
    }, {
      "heading" : "7 An Interleaving Approach for non-Time-elapsing Actions",
      "text" : "In this section, we show a different version of the tsccp language: while in tsccp the parallel operator is modeled in terms of maximal parallelism, the same operator can be treated also in terms of interleaving. According to maximal parallelism, at each moment every enabled agent of the system is activated, while in the second paradigm an agent could not be assigned to a “free” processor. Clearly, since we have dynamic process creation, a maximal parallelism approach has the disadvantage that, in general, it implies the existence of an unbound number of processes. On the other hand a naive interleaving semantic could be problematic from the\ntime viewpoint, as in principle the time does not pass for enabled agent which are not scheduled. For the semantics in this section we follow a solution analogous to that one adopted in (de Boer et al. 2004): we assume that the parallel operator is interpreted in terms of interleaving, as usual, however we must assume maximal parallelism for actions depending on time. In other words, time passes for all the parallel processes involved in a computation. To summarize, in this section we adopt maximal parallelism for time elapsing (i.e. for timeout constructs) and an interleaving model for basic computation steps (i.e. (valued) ask and (valued) tell actions).\nTo distinguish this new approach, we named the resulting language as tsccpi, i.e., tsccp with interleaving. Time-outs are modeled in tsccp-i by the construct askpt (c)?φA:B which replaces the nowφ c then A else B construct of tsccp and directly has time t as one of its parameters, differently from the nowφ agent. The askpt agent can be interpreted as follows: one is allowed to wait t time-units for the entailment of the constraint c by the store and the subsequent evaluation of the process A; if this time limit is exceeded, then the process B is evaluated. Analogously for the construct askpt (c)? aA:B .\nDefinition 7 (tsccp-i)\nGiven a soft constraint system 〈S ,D ,V 〉, the corresponding structure C, any semir-\ning value a, soft constraints φ, c ∈ C and any tuple of variables x , the syntax of the tsccp-i language is given by the following grammar:\nP ::= F .A F ::= p(x ) :: A | F · F A ::= success | tell(c) →φ A | tell(c) → a A | E | A ‖ A | ∃xA | p(x ) |\nΣni=1Ei | askpt (c)?φA:A | askpt(c)? aA:A\nE ::= ask(c) →φ A | ask(c) → a A\nwhere, as in Definition 1, P is the class of processes, F is the class of sequences of procedure declarations (or clauses), A is the class of agents. As before, in a tsccp-i process P = F .A, A is the initial agent, to be executed in the context of the set of declarations F .\nAnalogously to tsccp processes, in order to simplify the notation, in the following we will usually write a tsccp-i process P = F .A simply as the corresponding agent A.\nThe operational model of tsccp-i processes can be formally described by a labeled transition system T = (Conf,Label , 7−→), where we assume that each transition step exactly takes one time-unit. Configurations (in) Conf are pairs consisting of a process and a constraint in C representing the common store. L = {τ, ω} is the set of labels. We use labels to distinguish “real” computational steps performed by processes which have the control (label ω) from the transitions which model only the passing of time (label τ). So ω-actions are those performed by processes that modify the store (tell), perform a check on the store (ask, askpt), correspond to exceeding a time-out (askp0), or perform a choice (Σ n i=1Ei). On the other hand, τ -actions are those performed by time-out processes (askpt) in case they have not the control. In Figure 11 we show the semantics of all the tsccp-i actions, but in the following we describe only the actions whose semantics is different from that one presented in Figure 2 (i.e., for tsccp), that is we describe in detail the parallelism and the askpt agent. The semantics of the other actions of tsccp-i is the same as for tsccp, except for the fact that their transition is labeled with ω.\nParallelism Rules Q5 and Q6 in Figure 11 model the parallel composition op-\nerator in terms of interleaving, since only one basic ω-action is allowed for each transition (i.e. for each unit of time). This means that the access to the shared store is granted to one process a time. However, time passes for all the processes appearing in the ‖ context at the external level, as shown by rule Q5, since τ -actions are allowed together with a ω-action. On the other hand, a parallel component is allowed to proceed in isolation if (and only if) the other parallel component cannot perform a τ -action (rule Q6). To summarize, we adopt maximal parallelism for time elapsing (i.e. τ -actions) and an interleaving model for basic computation steps (i.e. ω-actions). We have adopted this approach because it seems more adequate to the nature of time-out operators not to interrupt the elapsing of time, once the evaluation of a time-out has started. Clearly one could start the elapsing of time when the time out process is scheduled, rather than when it appears in the top-level current\nparallel context. This modification could easily be obtained by adding a syntactic construct to differentiate active timeouts from inactive ones, and by accordingly changing the transition system. One could also easily modify the semantics (both operational and denotational) to consider a more liberal assumption which allows multiple ask actions in parallel. Valued-Askpt The rules Q10-Q14 in Figure 11 show that the time-out process\naskpt (c)? aA:B behaves as A if c is entailed by the store and the store is “consistent enough” with respect to the threshold a in the next t time-units: if t > 0 and the condition on the store and the cut level are satisfied, then the agent A is evaluated (rule Q10). If t > 0 and the condition on the cut level is not satisfied, then the agent B is evaluated (rule Q11). Finally if t > 0, the condition on the cut level is satisfied, but the condition on the store is not satisfied, then the control is repeated at the next time instant and the value of the counter t is decreased (axiom Q12); note that in this case we use the label ω, since a check on the store has been performed. As shown by axiom Q13, the counter can be decreased also by performing a τ -action: intuitively, this rule is used to model the situation in which, even though the evaluation of the time-out started already, another (parallel) process has the control. In this case, analogously to the approach in (de Boer et al. 2004) and differently from the approach in (Busi et al. 2000), time continues to elapse (via τ -actions) also for the time-out process (see also the rules Q5 and Q6 of the parallel operator). Axiom Q14 shows that, if the timeout is exceeded, i.e., the counter t has reached the value of 0, then the process askpt (c)? aA:B behaves as B . Askpt The rules Q15-Q19 in Figure 11 are similar to rules Q10-Q14 described\nbefore, with the exception that here a finer (pointwise) threshold φ is compared to the store σ, analogously to what happens with the tell and ask agents.\nIn the following we provide the definition for the observables of the language,\nwhich are clearly based only on ω-actions.\nDefinition 8 (Observables for tsccp-i) Let P = F .A be a tsccp-i process. We define\nOiio(P) = {γ ⇓Fv(A)| 〈A, 1̄〉 ω 7−→ ∗ 〈Success, γ〉},\nwhere Success is any agent that contains only occurrences of the agent success and of the operator ‖.\n8 An Execution Timeline for a tsccp-i Parallel Agent\nIn this section we show a timeline for the execution of three tsccp-i agents in parallel. We consider the three soft constraints shown in Figure 4 and the Weighted semiring 〈R+ ∪ {+∞},min,+,+∞, 0〉 (Bistarelli 2004; Bistarelli et al. 1997). Our parallel agent is defined by:\nA1 :: askp5(c3)? +∞(tell(c1) → +∞ success):(success) A2 :: tell(c1) → +∞ success A3 :: tell(c2) → +∞ success.\nTheir concurrent evaluation in the 0̄ empty store is shown in Figure 12. At t = 0 and t = 1 the agent A1 can make a τ -transition (rule Q13 in Figure 11), waiting for the elapsing of 1 time-unit. This can be done in parallel with a single other ωaction: therefore, the tell(c1) of agent A2, and the tell(c2) of agent A3 cannot run in parallel at the same time, since they are both ω-actions. In the execution shown in Figure 12, A2 is executed before A3 (also the opposite is possible, depending on the scheduling), leading to the store σ = c1 ⊗ c2 = c3. At t = 2, the guard of askp5 in agent A1 is enabled since σ ⊢ c3 and, therefore, rule Q10 in Figure 11 is executed. Finally, at t = 3 the tell(c1) action of agent A1 is executed as the last action, and at t = 4 we have 〈success ‖ success ‖ success, c1 ⊗ c2 ⊗ c1〉.\n9 Denotational Semantics for tsccp-i\nIn this section we define a denotational characterization of the operational semantics for tsccp-i. Differently from the denotational semantics for the maximal parallelism version presented in Section. 6.2, here for computational states we consider triples rather than pairs, as ω-actions have to be distinguished from τ -actions. This difference leads to a different technical development.\nOur denotational model for tsccp-i associates with a process a set of timed reactive sequences of the form 〈σ1, γ1, ξ1〉 · · · 〈σn , γn , ξn〉〈σ, σ, ω〉. Any triple 〈σi , γi , ξi〉 represents a reaction (a computation step) of the given process at time i : intuitively, the process transforms the global store from σi to γi by performing a transition step labeled by ξi or, in other words, σi is the assumption on the external environment, ξi is the label of the performed step while γi is the contribution of the process itself (which entails always the assumption). The last pair denotes a “stuttering step”, in which the agent Success has been reached. In the following we will assume that each timed reactive sequence 〈σ1, γ1, ξ1〉 · · · 〈σn−1, γn−1, ξn−1〉〈σn , σn , ω〉 satisfies the following condition: γi ⊢ σi and σj ⊢ γj−1, for any i ∈ [1, n − 1] and j ∈ [2, n].\nThe basic idea underlying the denotational model then is that, differently from the operational semantics, inactive processes can always make a τ -step, where an inactive process is either suspended (due to the absence of the required constraint in the store) or it is a non-scheduled component of a parallel construct. These\nadditional τ -steps, which represent time-elapsing and are needed to obtain a compositional model in a simple way, are then added to denotations as triples of the form 〈σ, σ, τ〉. For example, the denotation of the process tell(c) →a success contains all the reactive sequences that have, as first element, a triple 〈σ, σ ⊗ c, ω〉 for any possible initial store σ with (σ ⊗ c) ⇓∅ 6< a, as these represent the action of adding the constraint c to the current store. However, such a denotation contains also sequences where the triple 〈σ, σ ⊗ c, ω〉 (still with (σ ⊗ c) ⇓∅ 6< a) is preceded by a finite sequence of triples of the form 〈σ1, σ1, τ〉〈σ2, σ2, τ〉 . . . 〈σn , σn , τ〉. Such a sequence represents time-elapsing while the process is inactive because some other parallel process is scheduled.\nThe set of all reactive sequences for tsccp-i process is denoted by Si , its typical elements by s , s1 . . ., while sets of reactive sequences are denoted by S , S1 . . . and ε indicates the empty reactive sequence. The operator · denotes the operator that concatenates these sequences."
    }, {
      "heading" : "9.1 Compositionality of the Denotational Semantics for tsccp-i Processes",
      "text" : "As in Section 6.2 for the tsccp version, we now introduce a denotational semantics D(F .A)(e) which is compositional by definition and where, for technical reasons, we represent explicitly the environment e which associates a denotation to each procedure identifier. More precisely, assuming that Pvar denotes the set of procedure identifier, Envi = Pvar → P(Si), with typical element e, is the set of environments. Analogously to Section 6.2, given e ∈ Envi , p ∈ Pvar and f ∈ P(Si), we denote by e ′ = e{f /p} the new environment such that e ′(p) = f and e ′(p′) = e(p′) for each procedure identifier p′ 6= p.\nBefore defining formally the denotational semantics, we need to define the op-\nerators ¯tell , ∑̄ , ‖̄, ¯askp and ∃̄x , analogous to those given in Section 6.2 for the maximal parallelism language.\nDefinition 9 (Semantic operators for tsccp-i)\nLet S , Si be sets of reactive sequences, c, ci be constraints. Moreover let ≻i be either of the form ≻ai or ≻φi , defined as in Definition 5. Then we define the operators ¯tell , ∑̄ , ‖̄, ¯askp and ∃̄x as follows: The (valued) tell operator ¯tell a : C ×℘(Si) → ℘(Si) ( ¯tellφ : C ×℘(Si) → ℘(Si)) is the least function (w.r.t. the ordering induced by ⊆) which satisfies the following equation\n¯tell a (c, S ) = {s ∈ Si | s = 〈σ, σ ⊗ c, ω〉 · s ′, σ ⊗ c ⇓∅ 6< a and s ′ ∈ S } ∪\n{s ∈ Si | s = 〈σ, σ, τ〉 · s ′ and s ′ ∈ ¯tell a (c, S ) }.\n¯tellφ(c, S ) = {s ∈ Si | s = 〈σ, σ ⊗ c, ω〉 · s ′, σ ⊗ c 6⊏ φ and s ′ ∈ S } ∪\n{s ∈ Si | s = 〈σ, σ, τ〉 · s ′ and s ′ ∈ ¯tellφ(c, S ) }.\nThe guarded choice The semantic choice operator\n∑̄n i=1 : (C × ℘(Si))× · · · × (C × ℘(Si)) → ℘(Si) is the least function which satisfies the following equation:\n∑̄n i=1 ci ≻i Si = {s ∈ Si | s = 〈σ, σ, ω〉 · s ′,\nσ ≻h ch and s ′ ∈ Sh for an h ∈ [1, n] }\n∪ {s ∈ Si | s = 〈σ, σ, τ〉 · s ′ and s ′ ∈ ∑̄n i=1ci ≻i Si}.\nParallel Composition. Let ‖̄ ∈ Si×Si → Si be the (commutative and associative) partial operator defined by induction on the length of the sequences as follows:\n〈σ, σ, ω〉‖̄〈σ, σ, ω〉 = 〈σ, σ, ω〉 〈σ, σ′, x 〉 · s ‖̄〈σ, σ, τ〉 · s ′ = 〈σ, σ, τ〉 · s ′‖̄〈σ, σ′, x 〉 · s = 〈σ, σ′, x 〉 · (s ‖̄s ′),\nwhere x ∈ {ω, τ}. We define the operator S1‖̄S2 on sets as the image of Si × Si under the above operator. The (valued) askp operator ¯askp(t)a : C × ℘(Si) × ℘(Si) → ℘(Si) ( ¯askp(t)φ : C × ℘(Si)× ℘(Si ) → ℘(Si)), with t > 0, is defined as:\n¯askp(t)a(c, S1, S2) = {s ∈ Si | s = 〈σ, σ, ω〉 · s ′ and\neither σ ≻a c and s ∈ S1 or σ ⇓∅< a and s ∈ S2} ∪\n{s ∈ Si | s = 〈σ, σ, x 〉 · s ′, s ′ ∈ ¯askp(t − 1)a(c, S1, S2)\nand either x = τ or x = ω, σ 6⊢ c and σ ⇓∅ 6< a }.\n¯askp(t)φ(c, S1, S2) = {s ∈ Si | s = 〈σ, σ ′, ω〉 · s ′ and\neither σ ≻φ c and s ∈ S1 or σ ⊏ φ and s ∈ S2} ∪\n{s ∈ Si | s = 〈σ, σ, x 〉 · s ′, s ′ ∈ ¯askp(t − 1)φ(c, S1, S2)\nand either x = τ or x = ω, σ 6⊢ c and σ 6⊏ φ }.\nThe (valued) askp operator ¯askp(0)a : C × ℘(Si ) × ℘(Si) → ℘(Si) ( ¯askp(0)φ : C×℘(Si)×℘(Si) → ℘(Si)) is the least function which satisfies the following equation\n¯askp(0)a(c, S1, S2) = {s ∈ Si | either s = 〈σ, σ, ω〉 · s ′ and s ′ ∈ S2\nor s = 〈σ, σ, τ〉 · s ′ and s ′ ∈ ¯askp(0)a(c, S1, S2) }.\n¯askp(0)φ(c, S1, S2) = {s ∈ Si | either s = 〈σ, σ, ω〉 · s ′ and s ′ ∈ S2\nor s = 〈σ, σ, τ〉 · s ′ and s ′ ∈ ¯askp(0)φ(c, S1, S2) }.\nThe hiding operator The semantic hiding operator can be defined as follows:\n∃̄xS = {s ∈ Si | there exists s ′ ∈ S such that s = s ′[x/y] with y new }\nwhere s ′[x/y] denotes the sequence obtained from s ′ by replacing the variable x for the variable y that we assume to be new.7\nIt is immediate to see that the previous semantic operators are well defined, that is, the least function which satisfies the equations actually exists and can be obtained by a standard fix-point construction. The ¯tell , ∑̄ , ‖̄, ¯askp and ∃̄x operators have the expected definition, including the mentioned addition of τ -steps.\nIn the semantic parallel operator (acting on sequences) we require that at each point of time at most one ω-action is present and the two arguments of the operator agree with respect to the contribution of the environment (the first component of the triple). We also require that the two arguments have the same length (in all other cases the parallel composition is assumed being undefined): this is necessary to reflect the passage of time since the i − th element of any sequence corresponds to the given processes action on the i − th time step. Even though we merge pointwise sequences of the same length, this models an interleaving approach for ωactions, because of the previously mentioned addition of τ -steps to denotations. Concerning the semantic choice operator, a sequence in ∑̄n\ni=1ci ≻i Si consists of\nan initial period of waiting for a store which satisfies one of the guards. During this waiting period, only the environment is active by producing the constraint σ, while the process itself generates the stuttering steps 〈σ, σ, τ〉. When the store is strong enough to satisfy a guard, that is to entail a ch and to satisfy the condition on the cut level, then the resulting sequence is obtained by adding s ′ ∈ Sh to the initial waiting period.\nWe can define the denotational semantics D as follows. Here, Processi denotes\nthe set of tsccp-i processes.\nDefinition 10 (Processes Semantics) We define the semantics D ∈ Processi → P(Si) is the least function with respect to the ordering induced by the set-inclusion, which satisfies the equations in Figure 13\nAlso D is well defined and can be obtained by a fix-point construction. To see this, let us define an interpretation as a mapping I : Processi → ℘(Si). Then let us denote by I the cpo of all the interpretations (with the ordering induced by ⊆). To the equations in Figure 13, we can then associate a monotonic (and continuous) mapping F : I → I defined by the equations of Figure 13, provided that we replace the symbol D for F(I ), we delete the environment e and that we replace equation F9 for the following one: F(I )(F .p(x)) = I (F .ask(1̄) → A).\nThen, one can easily prove that a function satisfies the equations in Figure 13 iff it is a fix-point of the function F . Because this function is continuous (on a cpo), well known results ensure us that its least fix-point exists and it equals Fω, where the powers are defined as follows: F0 = I0 (this is the least interpretation which maps any process to the empty set); Fn = F(Fn−1) and Fω = lub{Fn |n ≥ 0} (where lub is the least upper bound on the cpo I).\n7 As before, we assume that each time that we consider a new applications of the operator ∃̄ we use a new, different y ."
    }, {
      "heading" : "9.2 Correctness of the Denotational Semantics for tsccp-i Processes",
      "text" : "As for the correctness of the denotational semantics presented in Section 6.1, at each step, the assumption on the current store must be equal to the store produced by the previous step. In other words, for any two consecutive steps 〈σi , σ ′ i , xi〉〈σi+1, σ ′ i+1, xi+1〉 we must have σ ′ i = σi+1. Furthermore, triples containing τ -actions do not correspond to observable computational steps, as these involve ω-actions only.\nDefinition 11 (Connected Sequences in tsccp-i) Let s = 〈σ1, σ ′ 1, x1〉〈σ2, σ ′ 2, x2〉 · · · 〈σn , σn , ω〉 be a reactive sequence. We say that s is connected if σ1 = 1̄, σi = σ ′ i−1 and xj = ω for each i , j , 2 ≤ i ≤ n and 1 ≤ j ≤ n − 1.\nAccording to the previous definition, a sequence is connected if all the information assumed on the tuple space is produced by the process itself and only ω-actions are involved. To be defined as connected, a sequence must also have 1̄ as the initial constraint. A connected sequence represents a tsccp-i computation, as it will be proved in the remaining of this section.\nIn order to prove the correctness of the denotational semantics, we use a modified transition system T ′, where inactive (either suspended or not scheduled) processes can perform τ -actions. When considering our notions of observables, we can prove that such a modified transition system is equivalent to the previous one and agrees with the denotational model.\nThe new transition system T ′ is obtained from the one in Figure 11 by deleting rule Q6 and by adding the rules Q0’, Q1’, Q2’, Q3’, Q4’, Q7’, Q8’, Q14’ and Q19’, contained in Figure 14. We denote by ⇒ the relation defined by T ′.\nThe observables induced by the transition system T ′ are formally defined as\nfollows.\nDefinition 12 Let P = F .A be a tsccp-i process. We define\nOi ′ io(P) = {γ ⇓Fv(A)| 〈A, 1̄〉 ω ⇒∗〈Success, γ〉},\nwhere Success is any agent which contains only occurrences of the agent success and of the operator ‖.\nLemma 3 shows that the modified transition system agrees with the original one\nwhen considering our notion of observables.\nWe first need some definitions and technical lemmata. In the following, given two agents A and B , we say that A ≃ B if and only if B is obtained from A by replacing an agent of the form ∃xA1 in A with A1[x/y], where y is new in A. ≈ denotes the reflexive and transitive closure of ≃. The following lemmata hold.\nLemma 1 Let F .A and F .B be tsccp-i processes such that A ≈ B . Then for each store σ and for x ∈ {ω, τ}\n〈F .A, σ〉 x 7−→ 〈F .C , σ′〉 if and only if 〈F .B , σ〉 x 7−→ 〈F .C , σ′〉.\nProof The proof is immediate, by using rule Q9 and by a straightforward inductive argument.\nFrom the above Lemma we derive the following corollary:\nCorollary 1 Let F .A and F .B be tsccp-i processes such that A ≈ B . Then for each store σ, 〈F .A, σ〉 ω 7−→∗〈Success, γ〉 if and only if 〈F .B , σ〉 ω 7−→∗〈Success, γ〉.\nLemma 2 Let P = F .A be a tsccp-i process. Then for each store σ,\n1. 〈F .A, σ〉 τ ⇒ 〈F .B , σ′〉 if and only if σ = σ′ and\n• either 〈F .A, σ〉 τ 7−→ 〈F .C , σ〉 and C ≈ B • or 〈F .A, σ〉 τ 67−→ and B ≈ A.\n2. 〈F .A, σ〉 ω ⇒ 〈F .B , σ′〉 if and only if 〈F .A, σ〉 ω 7−→ 〈F .C , σ′〉 and C ≈ B .\nProof 1. The proof is by induction on the complexity of the agent A.\n• A is of the form success, tell(c) →a A, tell(c) →φ A, ask(c) → a A,\nask(c) →φ A, Σ n i=1Ei , p(x ), askp0(c)? aA:B and askp0(c)?φA:B . The proof is immediate by observing that by the rules in Figure 11, 〈A, σ〉 τ 67−→ and by the rules in Figure 14, 〈A, σ〉 τ ⇒ 〈B , σ′〉 if and only if 〈A, σ〉 = 〈B , σ′〉.\n• A is of the form askpt (c)? aA1:A2 (askpt (c)?φA1:A2), with t > 0.\nThe proof is immediate since both the transition systems use the rule Q13\n(Q18) of Figure 11. • If A is of the form A1 ‖ A2.\nIn this case, by definition of the transition system T ′ and by using rule Q5 of Figure 11, for each store σ,\n〈A1 ‖ A2, σ〉 τ ⇒ 〈B1 ‖ B2, σ ′〉 if and only if 〈A1, σ〉 τ ⇒ 〈B1, σ ′〉 and 〈A2, σ〉 τ ⇒ 〈B2, σ〉\n(the symmetric case is analogous and hence it is omitted). By inductive hypothesis this holds if and only if σ′ = σ and for i = 1, 2 — either 〈Ai , σ〉 τ 7−→ 〈Ci , σ〉 and Ci ≈ Bi — or 〈Ai , σ〉 τ 67−→ and Bi ≈ Ai . If there exists i ∈ [1, 2] such that 〈Ai , σ〉 τ 7−→ 〈Ci , σ〉 then the thesis follows by using either rule Q5 or rule Q6. Otherwise 〈A1 ‖ A2, σ〉 τ 67−→. Then the thesis follows since by the previous\nresults B1 ‖ B2 ≈ A1 ‖ A2. • A is of the form ∃xA1. By rule Q9 of Figure 11 for each store σ,\n〈∃xA1, σ〉 τ ⇒ 〈B , σ′〉 if and only if 〈A1[x/y], σ〉 τ ⇒ 〈B , σ′〉\nBy inductive hypothesis this holds if and only if σ′ = σ — either 〈A1[x/y], σ〉 τ 7−→ 〈C , σ〉 and C ≈ B — or 〈A1[x/y], σ〉 τ 67−→ and B ≈ A1[x/y].\nTherefore, by using rule Q9 of Figure 11 and since ∃xA1 ≈ A1[x/y], we have that — either 〈∃xA1, σ〉 τ 7−→ 〈C , σ〉 and C ≈ B — or 〈∃xA1, σ〉 τ 67−→ and B ≈ ∃xA1 and then the thesis.\n2. The proof is analogous to the previous one and hence it is omitted.\nLemma 3 Let P = F .A be a tsccp-i process. Then Oi ′\nio(P) = O i io(P)·\nProof We prove that there exists a computation 〈A, σ〉 ω ⇒ ∗〈Success, γ〉 if and only if there exists a computation 〈A, σ〉 ω 7−→ ∗ 〈Success, γ〉. Then the thesis follows by definition of Oiio(P) and O i′ io(P)· The proof is by induction on the length of the computation 〈A, σ〉 ω ⇒∗〈Success, γ〉.\nn = 1) In this case A = Success and then the thesis.\nn > 1) In this case\n〈A, σ〉 ω ⇒∗〈Success, γ〉 iff\n(by definition)\n〈A, σ〉 ω ⇒ 〈A1, σ1〉 and 〈A1, σ1〉 ω ⇒∗〈Success, γ〉 iff\n(by inductive hypothesis)\n〈A, σ〉 ω ⇒ 〈A1, σ1〉 and 〈A1, σ1〉 ω 7−→∗〈Success, γ〉 iff\n(by Point 2 of Lemma 2)\n〈A, σ〉 ω 7−→ 〈A2, σ1〉, A2 ≈ A1 and 〈A1, σ1〉 ω 7−→∗〈Success, γ〉 iff\n(by Corollary 1)\n〈A, σ〉 ω 7−→ 〈A2, σ1〉 and 〈A2, σ1〉 ω 7−→∗〈Success, γ〉 iff\n(by definition)\n〈A, σ〉 ω 7−→∗〈Success, γ〉·\nWe can now easily prove that, given our definition of D, the modified transition\nsystem T ′ agrees with the denotational model.\nTheorem 2\nFor any tsccp-i process P = F .A we have\nOi ′\nio(P) = {σn ⇓Fv(A)| there exists a connected sequence s ∈ D(P) such that\ns = 〈σ1, σ2, ω〉〈σ2, σ3, ω〉 · · · 〈σn , σn , ω〉}.\nProof\nWe prove by induction on the complexity of the agent A that\nD(P) = {s | s = 〈σ1, σ ′ 1, x1〉〈σ2, σ ′ 2, x2〉 · · · 〈σn , σn , ω〉, A1 = A,\nfor i ∈ [1, n − 1], 〈Ai , σi〉 xi⇒ 〈Ai+1, σ ′ i〉 and An = Success}.\nThen the proof follows by definition of Oi ′\nio(P).\nWhen the tsccp-i P is not of the form F .B ‖ C the thesis follows immediately from the close correspondence between the rules of the transition system and the definition of the denotational semantics.\nAssume now that P is of the form F .B ‖ C . By definition of the denotational\nsemantics, s ∈ D(P) if and only if s = 〈σ1, σ ′ 1, x1〉〈σ2, σ ′ 2, x2〉 · · · 〈σn , σn , ω〉 and there exist s ′ ∈ D(F .B) and s ′′ ∈ D(F .C ),\ns ′ = 〈σ1, κ ′ 1, x ′ 1〉〈σ2, κ ′ 2, x ′ 2〉 · · · 〈σn , σn , ω〉 and s ′′ = 〈σ1, κ ′′ 1 , x ′′ 1 〉〈σ2, κ ′′ 2 , x ′′ 2 〉 · · · 〈σn , σn , ω〉,\nsuch that for each i ∈ [1, n − 1],\nxi = τ if and only if x ′ i = x ′′ i = τ and in this case σ ′ i = κ ′ i = κ ′′ i = σi , xi = ω if and only if either x ′ i = ω, x ′′ i = τ, κ ′ i = σ ′ i and κ ′′ i = σi\nor x ′i = τ, x ′′ i = ω, κ ′′ i = σ ′ i and κ ′ i = σi ·\n(2)\nBy inductive hypothesis s ′ ∈ D(F .B) and s ′′ ∈ D(F .C ) if and only if\n〈Bi , σi〉 x ′i⇒ 〈Bi+1, κ ′ i〉 for i ∈ [1, n − 1], B1 = B and Bn = Success, 〈Ci , σi〉 x ′′i⇒ 〈Ci+1, κ ′′ i 〉 for i ∈ [1, n − 1], C1 = C and Cn = Success.\n(3)\nTherefore, by Rule R8 and by (2), we have that (3) holds if and only if\n〈Bi ‖ Ci , σi〉 xi⇒ 〈Bi+1 ‖ Ci+1, σi+1〉 for i ∈ [1, n − 1], B1 ‖ C1 = B ‖ C and Bn ‖ Cn = Success\nand then the thesis.\nThus we obtain the following correctness result whose proof is immediate from\nthe previous theorems.\nCorollary 2 (Correctness of tsccp-i) For any tsccp-i process P = F .A we have\nOiio(P) = {σn ⇓Fv(A)| there exists a connected sequence s ∈ D(P) such that\ns = 〈σ1, σ2, ω〉〈σ2, σ3, ω〉 · · · 〈σn , σn , ω〉}."
    }, {
      "heading" : "10 Related Work",
      "text" : "By comparing this work with other timed languages using crisp constraints (instead of soft ones as in this paper) as (Saraswat et al. 1996; Saraswat et al. 1994), there are three main differences we can find out.\nFirst, the computational model of both the languages tcc (Saraswat et al. 1994) and default tcc (Saraswat et al. 1996) is inspired by that one of synchronous languages: each time interval is identified with the time needed for a ccp process to terminate a computation. Clearly, in order to ensure that the next time instant is reached, the (default) ccp program has to be always terminating; thus, it is assumed that it does not contain recursion. On the other hand, we directly introduce a timed interpretation of the usual programming constructs of ccp by considering the primitive ccp constructs ask and tell as the elementary actions whose evaluation takes one time-unit. Therefore, in our model, each time interval is identified with the time needed for the underlying constraint system to accumulate the tells and to answer the queries (asks) issued at each computation step by the processes of the system. For the definition of our tsccp agents we do not need any restriction on recursion to\nensure that the next time instant is reached, since at each moment there are only a finite number of parallel agents, and the next moment in time occurs as soon as the underlying constraint system has responded to the initial actions of all the current agents of the system.\nA second difference relies in the transfer of information across time boundaries. In (Saraswat et al. 1994) and (Saraswat et al. 1996), the programmer has to explicitly transfer the (positive) information from a time instant to the next one, by using special primitives that allow one to control the temporal evolution of the system. In fact, at the end of a time interval all the constraints accumulated and all the processes suspended are discarded, unless they are arguments to a specific primitive. On the contrary, no explicit transfer is needed in tsccp, since the computational model is based on the monotonic evolution of the store which is usual in ccp.\nA third relevant difference is in (Saraswat et al. 1994) and (Saraswat et al. 1996) the authors present deterministic languages while our language allows for nondeterminism. These three differences also hold between (Saraswat et al. 1994) or (Saraswat et al. 1996), and the original crisp version of the language, i.e., tccp (de Boer et al. 2000).\nIn (Olarte et al. 2007), the authors generalize the model in (Saraswat et al. 1994) in order to extend it with temporary parametric ask operations. Intuitively, these operations behave as persistent parametric asks during a time-interval, but may disappear afterwards. The presented extension goes in the direction of better modeling mobile systems with the use of private channels between the agents. However, also the agents in (Olarte et al. 2007) show a deterministic behavior, instead of our not-deterministic choice.\nOther timed extension of concurrent constraint programming have been proposed in (Nielsen and Valencia 2002; Palamidessi and Valencia 2001), however these languages, differently from tsccp, do not take into account quantitative aspects; therefore, this achievement represents a very important expressivity improvement with respect to related works. These have been considered by Di Pierro and Wiklicky, who have extensively studied probabilistic ccp (see for example (Di Pierro and Wiklicky 1998)). This language provides a construct for probabilistic choice which allows one to express randomness in a program, without assuming any additional structure on the underlying constraint system. This approach is therefore deeply different from ours. More recently, stochastic ccp has been introduced in (Bortolussi 2006) to model biological systems. This language is obtained by adding a stochastic duration to the ask and tell primitives, thus it differs from our solutions.\nIn literature we can find other proposals that are related to tuple-based kernellanguages instead of a constraint store, as KLAIM (de Nicola et al. 1998) (A Kernel Language for Agents Interaction and Mobility) or SCEL (De Nicola et al. 2011) (Software Component Ensemble Language) for instance. These languages are designed to study different properties of systems, as mobility and autonomicity of modeled agents. Their basic specification do not encompass time-based primitives, while mobility features are not present in any of the constraint-based languages reported in this section. The purpose of our language is to model systems where a level of preference and time-sensitive primitives (as a timeout) is required: a good\nexample is represented by agents participating to an auction, as the example given in Section 5.1.\nIn general, since semiring-based soft constraints allow one to express several quantitative features, our proposal provides a framework which can be instantiated to obtain a variety of specific extensions of ccp."
    }, {
      "heading" : "11 Conclusion and Future Work",
      "text" : "We have presented the tsccp and tsccp-i in order to join together the expressive capabilities of soft constraints and timing mechanisms in a new programming framework. The agents modeled with these languages are able to deal with time and preference-dependent decisions that are often found during complex interactions. An application scenario can be represented by different entities that need to negotiate generic resources or services, as, for instance, during an auction process. Mechanisms as timeout and interrupt may model the wait for pending conditions or the triggering of some new events. All the tsccp and tsccp-i rules have been formally described by a transition system and, then, also with a denotational characterization of the operational semantics obtained with the use of timed reactive sequences. The resulting semantics has been proved to be compositional and correct.\nAbout future work, a first improvement of the presented languages can be the inclusion of a fail agent in the syntax given in Definition 1 and Definition 7, and a semantics for the transition rules that lead to a failed computation, in case the guard on the transition rule cannot be enforced due to the preference of the store. In fact, the transition systems we have defined consider only successful computations. If this could be a reasonable choice in a don’t know interpretation of the language it will lead to an insufficient analysis of the behavior in a pessimistic interpretation of the indeterminism.\nAt last, we would like to consider other time management strategies (as the one proposed in (Valencia 2003)), and to study how timing and non-monotonic constructs (Bistarelli and Santini 2011) can be integrated together."
    } ],
    "references" : [ {
      "title" : "The ESTEREL synchronous programming language: design, semantics, implementation",
      "author" : [ "G. Berry", "G. Gonthier" ],
      "venue" : "Sci. Comput. Program. 19, 2, 87–152.",
      "citeRegEx" : "Berry and Gonthier,? 1992",
      "shortCiteRegEx" : "Berry and Gonthier",
      "year" : 1992
    }, {
      "title" : "Semirings for Soft Constraint Solving and Programming (LNCS)",
      "author" : [ "S. Bistarelli" ],
      "venue" : "Springer Verlag, London, UK.",
      "citeRegEx" : "Bistarelli,? 2004",
      "shortCiteRegEx" : "Bistarelli",
      "year" : 2004
    }, {
      "title" : "Timed soft concurrent constraint programs",
      "author" : [ "S. Bistarelli", "M. Gabbrielli", "M.C. Meo", "F. Santini" ],
      "venue" : "Coordination Models and Languages, 10th International Conference, COORDINATION. Lecture Notes in Computer Science, vol. 5052. Springer, London, UK, 50–66.",
      "citeRegEx" : "Bistarelli et al\\.,? 2008",
      "shortCiteRegEx" : "Bistarelli et al\\.",
      "year" : 2008
    }, {
      "title" : "Semiring-based constraint satisfaction and optimization",
      "author" : [ "S. Bistarelli", "U. Montanari", "F. Rossi" ],
      "venue" : "J. ACM 44, 2, 201–236.",
      "citeRegEx" : "Bistarelli et al\\.,? 1997",
      "shortCiteRegEx" : "Bistarelli et al\\.",
      "year" : 1997
    }, {
      "title" : "Soft concurrent constraint programming",
      "author" : [ "S. Bistarelli", "U. Montanari", "F. Rossi" ],
      "venue" : "ACM Trans. Comput. Logic 7, 3, 563–589.",
      "citeRegEx" : "Bistarelli et al\\.,? 2006",
      "shortCiteRegEx" : "Bistarelli et al\\.",
      "year" : 2006
    }, {
      "title" : "A nonmonotonic soft concurrent constraint language to model the negotiation process",
      "author" : [ "S. Bistarelli", "F. Santini" ],
      "venue" : "Fundam. Inform. 111, 3, 257–279.",
      "citeRegEx" : "Bistarelli and Santini,? 2011",
      "shortCiteRegEx" : "Bistarelli and Santini",
      "year" : 2011
    }, {
      "title" : "Stochastic concurrent constraint programming",
      "author" : [ "L. Bortolussi" ],
      "venue" : "Electr. Notes Theor. Comput. Sci. 164, 3, 65–80.",
      "citeRegEx" : "Bortolussi,? 2006",
      "shortCiteRegEx" : "Bortolussi",
      "year" : 2006
    }, {
      "title" : "Full abstraction for a shared variable parallel language",
      "author" : [ "S.D. Brookes" ],
      "venue" : "LICS. IEEE Computer Society, Los Alamitos, CA, USA, 98–109.",
      "citeRegEx" : "Brookes,? 1993",
      "shortCiteRegEx" : "Brookes",
      "year" : 1993
    }, {
      "title" : "Process calculi for coordination: From Linda to JavaSpaces",
      "author" : [ "N. Busi", "R. Gorrieri", "G. Zavattaro" ],
      "venue" : "AMAST. Springer-Verlag, London, UK, 198–212.",
      "citeRegEx" : "Busi et al\\.,? 2000",
      "shortCiteRegEx" : "Busi et al\\.",
      "year" : 2000
    }, {
      "title" : "A timed concurrent constraint language",
      "author" : [ "F.S. de Boer", "M. Gabbrielli", "M.C. Meo" ],
      "venue" : "Inf. Comput. 161,",
      "citeRegEx" : "Boer et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Boer et al\\.",
      "year" : 2000
    }, {
      "title" : "A timed Linda language and its denotational semantics",
      "author" : [ "F.S. de Boer", "M. Gabbrielli", "M.C. Meo" ],
      "venue" : "Fundam. Inf",
      "citeRegEx" : "Boer et al\\.,? \\Q2004\\E",
      "shortCiteRegEx" : "Boer et al\\.",
      "year" : 2004
    }, {
      "title" : "A fully abstract model for concurrent constraint programming",
      "author" : [ "F.S. de Boer", "C. Palamidessi" ],
      "venue" : "Proceedings of CAAP ’91",
      "citeRegEx" : "Boer and Palamidessi,? \\Q1991\\E",
      "shortCiteRegEx" : "Boer and Palamidessi",
      "year" : 1991
    }, {
      "title" : "A language-based approach to autonomic computing",
      "author" : [ "R. De Nicola", "G.L. Ferrari", "M. Loreti", "R. Pugliese" ],
      "venue" : "FMCO, B. Beckert, F. Damiani, F. S. de Boer, and M. M. Bonsangue, Eds. Lecture Notes in Computer Science, vol. 7542. Springer, 25–48.",
      "citeRegEx" : "Nicola et al\\.,? 2011",
      "shortCiteRegEx" : "Nicola et al\\.",
      "year" : 2011
    }, {
      "title" : "KLAIM: A Kernel Language for Agents Interaction and Mobility",
      "author" : [ "R. de Nicola", "G.L. Ferrari", "R. Pugliese" ],
      "venue" : "IEEE Transactions on Software Engineering",
      "citeRegEx" : "Nicola et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Nicola et al\\.",
      "year" : 1998
    }, {
      "title" : "Probabilistic concurrent constraint programming: Towards a fully abstract model",
      "author" : [ "Di Pierro", "H.A. andWiklicky" ],
      "venue" : "InMFCS ’98: Proceedings of Mathematical Foundations of Computer Science. Springer-Verlag, London, UK, 446–455.",
      "citeRegEx" : "Pierro and andWiklicky,? 1998",
      "shortCiteRegEx" : "Pierro and andWiklicky",
      "year" : 1998
    }, {
      "title" : "Temporary and permanent buyout prices in online auctions",
      "author" : [ "J. Gallien", "S. Gupta" ],
      "venue" : "Management Science 53, 5, 814–833.",
      "citeRegEx" : "Gallien and Gupta,? 2007",
      "shortCiteRegEx" : "Gallien and Gupta",
      "year" : 2007
    }, {
      "title" : "The synchronous data-flow programming language LUSTRE",
      "author" : [ "N. Halbwachs", "P. Caspi", "P. Raymond", "D. Pilaud" ],
      "venue" : "Proceedings of the IEEE 79, 9, 1305–1320.",
      "citeRegEx" : "Halbwachs et al\\.,? 1991",
      "shortCiteRegEx" : "Halbwachs et al\\.",
      "year" : 1991
    }, {
      "title" : "Statecharts: A visual formalism for complex systems",
      "author" : [ "D. Harel" ],
      "venue" : "Sci. Comput. Program. 8, 3, 231–274.",
      "citeRegEx" : "Harel,? 1987",
      "shortCiteRegEx" : "Harel",
      "year" : 1987
    }, {
      "title" : "A model and proof system for asynchronous networks",
      "author" : [ "B. Jonsson" ],
      "venue" : "PODC ’85: Proceedings ACM symposium on Principles of distributed computing. ACM Press, New York, USA, 49–58.",
      "citeRegEx" : "Jonsson,? 1985",
      "shortCiteRegEx" : "Jonsson",
      "year" : 1985
    }, {
      "title" : "Programming real-time applications with signal",
      "author" : [ "P. le Guernic", "M. le Borgne", "T. Gautier", "C. le Maire" ],
      "venue" : "Proceedings of the IEEE 79,",
      "citeRegEx" : "Guernic et al\\.,? \\Q1991\\E",
      "shortCiteRegEx" : "Guernic et al\\.",
      "year" : 1991
    }, {
      "title" : "Temporal concurrent constraint programming: Applications and behavior",
      "author" : [ "M. Nielsen", "F.D. Valencia" ],
      "venue" : "Formal and Natural Computing - Essays Dedicated to Grzegorz Rozenberg. Springer-Verlag, London, UK, 298–324.",
      "citeRegEx" : "Nielsen and Valencia,? 2002",
      "shortCiteRegEx" : "Nielsen and Valencia",
      "year" : 2002
    }, {
      "title" : "Universal timed concurrent constraint programming",
      "author" : [ "C. Olarte", "C. Palamidessi", "F. Valencia" ],
      "venue" : "Logic Programming, 23rd International Conference, ICLP. LNCS, vol. 4670. Springer, London, UK, 464–465.",
      "citeRegEx" : "Olarte et al\\.,? 2007",
      "shortCiteRegEx" : "Olarte et al\\.",
      "year" : 2007
    }, {
      "title" : "A temporal concurrent constraint programming calculus",
      "author" : [ "C. Palamidessi", "F.D. Valencia" ],
      "venue" : "CP ’01: Proceedings of Principles and Practice of Constraint Programming. Springer-Verlag, London, UK, 302–316.",
      "citeRegEx" : "Palamidessi and Valencia,? 2001",
      "shortCiteRegEx" : "Palamidessi and Valencia",
      "year" : 2001
    }, {
      "title" : "Concurrent constraint programming languages",
      "author" : [ "V. Saraswat" ],
      "venue" : "PhD thesis.",
      "citeRegEx" : "Saraswat,? 1989",
      "shortCiteRegEx" : "Saraswat",
      "year" : 1989
    }, {
      "title" : "Timed default concurrent constraint programming",
      "author" : [ "V. Saraswat", "R. Jagadeesan", "V. Gupta" ],
      "venue" : "J. Symb. Comput. 22, 5-6, 475–520.",
      "citeRegEx" : "Saraswat et al\\.,? 1996",
      "shortCiteRegEx" : "Saraswat et al\\.",
      "year" : 1996
    }, {
      "title" : "Concurrent constraint programming",
      "author" : [ "V. Saraswat", "M. Rinard" ],
      "venue" : "POPL ’90: Proceedings of Principles of programming languages. ACM Press, New York, USA, 232–245.",
      "citeRegEx" : "Saraswat and Rinard,? 1990",
      "shortCiteRegEx" : "Saraswat and Rinard",
      "year" : 1990
    }, {
      "title" : "Foundations of timed concurrent constraint programming",
      "author" : [ "V.A. Saraswat", "R. Jagadeesan", "V. Gupta" ],
      "venue" : "Proceedings, Ninth Annual IEEE Symposium on Logic in Computer Science, LICS. IEEE Computer Society, Los Alamitos, CA, USA, 71–80.",
      "citeRegEx" : "Saraswat et al\\.,? 1994",
      "shortCiteRegEx" : "Saraswat et al\\.",
      "year" : 1994
    }, {
      "title" : "Timed concurrent constraint programming: Decidability results and their application to LTL",
      "author" : [ "F.D. Valencia" ],
      "venue" : "ICLP. LNCS, vol. 2916. Springer, London, UK, 422– 437.",
      "citeRegEx" : "Valencia,? 2003",
      "shortCiteRegEx" : "Valencia",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 23,
      "context" : "The Timed Concurrent Constraint Programming (tccp), a timed extension of the pure formalism of Concurrent Constraint Programming (ccp) (Saraswat 1989), has been introduced in (de Boer et al.",
      "startOffset" : 135,
      "endOffset" : 150
    }, {
      "referenceID" : 24,
      "context" : "The language is based on the hypothesis of bounded asynchrony (Saraswat et al. 1996): computation takes a bounded period of time rather than being instantaneous as in the concurrent synchronous languages ESTEREL (Berry and Gonthier 1992), LUSTRE (Halbwachs et al.",
      "startOffset" : 62,
      "endOffset" : 84
    }, {
      "referenceID" : 0,
      "context" : "1996): computation takes a bounded period of time rather than being instantaneous as in the concurrent synchronous languages ESTEREL (Berry and Gonthier 1992), LUSTRE (Halbwachs et al.",
      "startOffset" : 133,
      "endOffset" : 158
    }, {
      "referenceID" : 16,
      "context" : "1996): computation takes a bounded period of time rather than being instantaneous as in the concurrent synchronous languages ESTEREL (Berry and Gonthier 1992), LUSTRE (Halbwachs et al. 1991), SIGNAL (le Guernic et al.",
      "startOffset" : 167,
      "endOffset" : 190
    }, {
      "referenceID" : 17,
      "context" : "1991) and Statecharts (Harel 1987).",
      "startOffset" : 22,
      "endOffset" : 34
    }, {
      "referenceID" : 1,
      "context" : "Soft constraints (Bistarelli 2004; Bistarelli et al. 1997) extend classical constraints to represent multiple consistency levels, and thus provide a way to express preferences, fuzziness, and uncertainty.",
      "startOffset" : 17,
      "endOffset" : 58
    }, {
      "referenceID" : 3,
      "context" : "Soft constraints (Bistarelli 2004; Bistarelli et al. 1997) extend classical constraints to represent multiple consistency levels, and thus provide a way to express preferences, fuzziness, and uncertainty.",
      "startOffset" : 17,
      "endOffset" : 58
    }, {
      "referenceID" : 4,
      "context" : "The ccp framework has been extended to work with soft constraints (Bistarelli et al. 2006), and the resulting framework is named Soft Concurrent Constraint Programming (sccp).",
      "startOffset" : 66,
      "endOffset" : 90
    }, {
      "referenceID" : 2,
      "context" : "2004), is different from that one of (de Boer et al. 2000; Bistarelli et al. 2008) (where maximal parallelism was assumed for any kind of action), and it is also different from the one considered in (Busi et al.",
      "startOffset" : 37,
      "endOffset" : 82
    }, {
      "referenceID" : 8,
      "context" : "2008) (where maximal parallelism was assumed for any kind of action), and it is also different from the one considered in (Busi et al. 2000), where time does not elapse for timeout constructs.",
      "startOffset" : 122,
      "endOffset" : 140
    }, {
      "referenceID" : 2,
      "context" : "The paper extends the results in (Bistarelli et al. 2008) by providing new semantics that allows maximal parallelism for time elapsing and an interleaving model for basic computation steps (see Section 7).",
      "startOffset" : 33,
      "endOffset" : 57
    }, {
      "referenceID" : 23,
      "context" : "According to the maximal parallelism policy (applied, for example, in the original works as (Saraswat 1989) and (Saraswat et al.",
      "startOffset" : 92,
      "endOffset" : 107
    }, {
      "referenceID" : 26,
      "context" : "According to the maximal parallelism policy (applied, for example, in the original works as (Saraswat 1989) and (Saraswat et al. 1994)), at each moment every enabled agent of the system is activated, while in the interleaving paradigm only one of the enabled agents is executed instead.",
      "startOffset" : 112,
      "endOffset" : 134
    }, {
      "referenceID" : 3,
      "context" : "A soft constraint (Bistarelli et al. 1997; Bistarelli 2004) may be seen as a constraint where each instantiation of its variables has an associated value from a partially ordered set which can be interpreted as a set of preference values.",
      "startOffset" : 18,
      "endOffset" : 59
    }, {
      "referenceID" : 1,
      "context" : "A soft constraint (Bistarelli et al. 1997; Bistarelli 2004) may be seen as a constraint where each instantiation of its variables has an associated value from a partially ordered set which can be interpreted as a set of preference values.",
      "startOffset" : 18,
      "endOffset" : 59
    }, {
      "referenceID" : 3,
      "context" : "This is why this formalization is based on the concept of c-semiring (Bistarelli et al. 1997; Bistarelli 2004), called just semiring in the rest of the paper.",
      "startOffset" : 69,
      "endOffset" : 110
    }, {
      "referenceID" : 1,
      "context" : "This is why this formalization is based on the concept of c-semiring (Bistarelli et al. 1997; Bistarelli 2004), called just semiring in the rest of the paper.",
      "startOffset" : 69,
      "endOffset" : 110
    }, {
      "referenceID" : 3,
      "context" : "Then, it is possible to prove that (see (Bistarelli et al. 1997)): i) ≤S is a partial order; ii) + and × are monotone on ≤S ; iii) 0 is its minimum and 1 its maximum; iv) 〈A,≤S〉 is a complete lattice (a complete lattice is a partially ordered set in which all subsets have both a supremum and an infimum) and, for all a, b ∈ A, a + b = lub(a, b) (where lub is the least upper bound).",
      "startOffset" : 40,
      "endOffset" : 64
    }, {
      "referenceID" : 3,
      "context" : "Given the set C, the combination function ⊗ : C×C → C is defined as (c1⊗c2)η = c1η×c2η (see also (Bistarelli et al. 1997; Bistarelli 2004; Bistarelli et al. 2006)).",
      "startOffset" : 97,
      "endOffset" : 162
    }, {
      "referenceID" : 1,
      "context" : "Given the set C, the combination function ⊗ : C×C → C is defined as (c1⊗c2)η = c1η×c2η (see also (Bistarelli et al. 1997; Bistarelli 2004; Bistarelli et al. 2006)).",
      "startOffset" : 97,
      "endOffset" : 162
    }, {
      "referenceID" : 4,
      "context" : "Given the set C, the combination function ⊗ : C×C → C is defined as (c1⊗c2)η = c1η×c2η (see also (Bistarelli et al. 1997; Bistarelli 2004; Bistarelli et al. 2006)).",
      "startOffset" : 97,
      "endOffset" : 162
    }, {
      "referenceID" : 3,
      "context" : "Given a constraint c ∈ C and a variable v ∈ V , the projection (Bistarelli et al. 1997; Bistarelli 2004; Bistarelli et al. 2006) of c over V − {v}, written c ⇓(V−{v}) is the constraint c s.",
      "startOffset" : 63,
      "endOffset" : 128
    }, {
      "referenceID" : 1,
      "context" : "Given a constraint c ∈ C and a variable v ∈ V , the projection (Bistarelli et al. 1997; Bistarelli 2004; Bistarelli et al. 2006) of c over V − {v}, written c ⇓(V−{v}) is the constraint c s.",
      "startOffset" : 63,
      "endOffset" : 128
    }, {
      "referenceID" : 4,
      "context" : "Given a constraint c ∈ C and a variable v ∈ V , the projection (Bistarelli et al. 1997; Bistarelli 2004; Bistarelli et al. 2006) of c over V − {v}, written c ⇓(V−{v}) is the constraint c s.",
      "startOffset" : 63,
      "endOffset" : 128
    }, {
      "referenceID" : 1,
      "context" : "We define also a function ā (Bistarelli 2004; Bistarelli et al. 2006) as the function that returns the semiring value a for all assignments η, that is, āη = a.",
      "startOffset" : 28,
      "endOffset" : 69
    }, {
      "referenceID" : 4,
      "context" : "We define also a function ā (Bistarelli 2004; Bistarelli et al. 2006) as the function that returns the semiring value a for all assignments η, that is, āη = a.",
      "startOffset" : 28,
      "endOffset" : 69
    }, {
      "referenceID" : 1,
      "context" : "A SCSP (Bistarelli 2004) is defined as P = 〈V ,D ,C , S 〉, where C is the set of constraints defined over variables in V (each with domain D), and whose preference is determined by semiring S .",
      "startOffset" : 7,
      "endOffset" : 24
    }, {
      "referenceID" : 1,
      "context" : "The best level of consistency notion is defined as blevel(P) = Sol(P) ⇓∅, where Sol(P) = ⊗ C (Bistarelli 2004).",
      "startOffset" : 93,
      "endOffset" : 110
    }, {
      "referenceID" : 1,
      "context" : "A problem P is α-consistent if blevel(P) = α (Bistarelli 2004).",
      "startOffset" : 45,
      "endOffset" : 62
    }, {
      "referenceID" : 23,
      "context" : "The basic idea underlying ccp (Saraswat 1989) is that computation progresses via monotonic accumulation of information in a constraint global store.",
      "startOffset" : 30,
      "endOffset" : 45
    }, {
      "referenceID" : 25,
      "context" : "The notion of constraint system has been formalized in (Saraswat and Rinard 1990) following Scott’s treatment of information systems.",
      "startOffset" : 55,
      "endOffset" : 81
    }, {
      "referenceID" : 3,
      "context" : "Soft constraints over a semiring S = 〈A,+,×,0,1〉 and an ordered set of variables V (over a domain D) have been showed to form a constraint system “à la Saraswat”, thus leading to the definition of Soft Concurrent Constraint Programmingg (sccp) (Bistarelli et al. 1997; Bistarelli 2004; Bistarelli et al. 2006).",
      "startOffset" : 244,
      "endOffset" : 309
    }, {
      "referenceID" : 1,
      "context" : "Soft constraints over a semiring S = 〈A,+,×,0,1〉 and an ordered set of variables V (over a domain D) have been showed to form a constraint system “à la Saraswat”, thus leading to the definition of Soft Concurrent Constraint Programmingg (sccp) (Bistarelli et al. 1997; Bistarelli 2004; Bistarelli et al. 2006).",
      "startOffset" : 244,
      "endOffset" : 309
    }, {
      "referenceID" : 4,
      "context" : "Soft constraints over a semiring S = 〈A,+,×,0,1〉 and an ordered set of variables V (over a domain D) have been showed to form a constraint system “à la Saraswat”, thus leading to the definition of Soft Concurrent Constraint Programmingg (sccp) (Bistarelli et al. 1997; Bistarelli 2004; Bistarelli et al. 2006).",
      "startOffset" : 244,
      "endOffset" : 309
    }, {
      "referenceID" : 1,
      "context" : "for each C ∈ ℘(C) and c ∈ C, we have C ⊢ c ⇔ ⊗ C ⊑ c (see also (Bistarelli 2004; Bistarelli et al. 2006)).",
      "startOffset" : 63,
      "endOffset" : 104
    }, {
      "referenceID" : 4,
      "context" : "for each C ∈ ℘(C) and c ∈ C, we have C ⊢ c ⇔ ⊗ C ⊑ c (see also (Bistarelli 2004; Bistarelli et al. 2006)).",
      "startOffset" : 63,
      "endOffset" : 104
    }, {
      "referenceID" : 23,
      "context" : "It is also important to notice that in (Saraswat 1989) it is claimed that a constraint system is a complete algebraic lattice.",
      "startOffset" : 39,
      "endOffset" : 54
    }, {
      "referenceID" : 4,
      "context" : "In the sccp framework, algebraicity is not required (Bistarelli et al. 2006) instead, since the algebraic nature of the structure C strictly depends on the properties of the semiring.",
      "startOffset" : 52,
      "endOffset" : 76
    }, {
      "referenceID" : 1,
      "context" : "For each x ∈ V , the hiding function (Bistarelli 2004; Bistarelli et al. 2006) is the function (∃xc)η = ∑ di∈D cη[x := di ].",
      "startOffset" : 37,
      "endOffset" : 78
    }, {
      "referenceID" : 4,
      "context" : "For each x ∈ V , the hiding function (Bistarelli 2004; Bistarelli et al. 2006) is the function (∃xc)η = ∑ di∈D cη[x := di ].",
      "startOffset" : 37,
      "endOffset" : 78
    }, {
      "referenceID" : 4,
      "context" : "To make the hiding operator computationally tractable, it is required that the number of domain elements in D , having semiring values different from 0, is finite (Bistarelli et al. 2006).",
      "startOffset" : 163,
      "endOffset" : 187
    }, {
      "referenceID" : 4,
      "context" : "In fact, for any constraint c and any variable x ⊆ V , c ⇓V−x= ∃xc (Bistarelli et al. 2006).",
      "startOffset" : 67,
      "endOffset" : 91
    }, {
      "referenceID" : 1,
      "context" : ", dxyη[x := a, y := b] = 1 if a = b, and dxyη[x := a, y := b] = 0 if a 6= b (Bistarelli 2004; Bistarelli et al. 2006).",
      "startOffset" : 76,
      "endOffset" : 117
    }, {
      "referenceID" : 4,
      "context" : ", dxyη[x := a, y := b] = 1 if a = b, and dxyη[x := a, y := b] = 0 if a 6= b (Bistarelli 2004; Bistarelli et al. 2006).",
      "startOffset" : 76,
      "endOffset" : 117
    }, {
      "referenceID" : 4,
      "context" : "Theorem 1 (cylindric constraint system (Bistarelli et al. 2006)) Consider a semiring S = 〈A,+,×,0,1〉, a domain of the variables D , an ordered set of variables V , and the corresponding structure C.",
      "startOffset" : 39,
      "endOffset" : 63
    }, {
      "referenceID" : 24,
      "context" : "Similarly to other existing timed extensions of ccp defined in (Saraswat et al. 1996), tccp is a language for reactive programming designed around the hypothesis of bounded asynchrony (as introduced in (Saraswat et al.",
      "startOffset" : 63,
      "endOffset" : 85
    }, {
      "referenceID" : 24,
      "context" : "1996), tccp is a language for reactive programming designed around the hypothesis of bounded asynchrony (as introduced in (Saraswat et al. 1996): computation takes a bounded period of time rather than being instantaneous).",
      "startOffset" : 122,
      "endOffset" : 144
    }, {
      "referenceID" : 24,
      "context" : "This basic construct allows to derive such timing mechanisms as time-out and preemption (de Boer et al. 2000; Saraswat et al. 1996).",
      "startOffset" : 88,
      "endOffset" : 131
    }, {
      "referenceID" : 1,
      "context" : "The valued-tell rule checks for the a-consistency of the Soft Constraint Satisfaction Problem (Bistarelli 2004) (SCSP) defined by the store σ ⊗ c.",
      "startOffset" : 94,
      "endOffset" : 111
    }, {
      "referenceID" : 1,
      "context" : "For the following examples on the new programming idioms, we consider the Weighted semiring 〈R ∪ {+∞},min,+,+∞, 0〉 (Bistarelli 2004; Bistarelli et al. 1997) and the (weighted) soft constraints in Figure 4.",
      "startOffset" : 115,
      "endOffset" : 156
    }, {
      "referenceID" : 3,
      "context" : "For the following examples on the new programming idioms, we consider the Weighted semiring 〈R ∪ {+∞},min,+,+∞, 0〉 (Bistarelli 2004; Bistarelli et al. 1997) and the (weighted) soft constraints in Figure 4.",
      "startOffset" : 115,
      "endOffset" : 156
    }, {
      "referenceID" : 15,
      "context" : "In the following of the description we consider a buyout auction (Gallien and Gupta 2007), where the auctioneer improves the service and the related consumed resources (or, alternatively, its money price), bid after bid.",
      "startOffset" : 65,
      "endOffset" : 89
    }, {
      "referenceID" : 18,
      "context" : "These sequences are similar to those used in the semantics of dataflow languages (Jonsson 1985), imperative languages (Brookes 1993) and (timed) ccp (de Boer and Palamidessi 1991; de Boer et al.",
      "startOffset" : 81,
      "endOffset" : 95
    }, {
      "referenceID" : 7,
      "context" : "These sequences are similar to those used in the semantics of dataflow languages (Jonsson 1985), imperative languages (Brookes 1993) and (timed) ccp (de Boer and Palamidessi 1991; de Boer et al.",
      "startOffset" : 118,
      "endOffset" : 132
    }, {
      "referenceID" : 8,
      "context" : "2004) and differently from the approach in (Busi et al. 2000), time continues to elapse (via τ -actions) also for the time-out process (see also the rules Q5 and Q6 of the parallel operator).",
      "startOffset" : 43,
      "endOffset" : 61
    }, {
      "referenceID" : 1,
      "context" : "We consider the three soft constraints shown in Figure 4 and the Weighted semiring 〈R ∪ {+∞},min,+,+∞, 0〉 (Bistarelli 2004; Bistarelli et al. 1997).",
      "startOffset" : 106,
      "endOffset" : 147
    }, {
      "referenceID" : 3,
      "context" : "We consider the three soft constraints shown in Figure 4 and the Weighted semiring 〈R ∪ {+∞},min,+,+∞, 0〉 (Bistarelli 2004; Bistarelli et al. 1997).",
      "startOffset" : 106,
      "endOffset" : 147
    }, {
      "referenceID" : 24,
      "context" : "By comparing this work with other timed languages using crisp constraints (instead of soft ones as in this paper) as (Saraswat et al. 1996; Saraswat et al. 1994), there are three main differences we can find out.",
      "startOffset" : 117,
      "endOffset" : 161
    }, {
      "referenceID" : 26,
      "context" : "By comparing this work with other timed languages using crisp constraints (instead of soft ones as in this paper) as (Saraswat et al. 1996; Saraswat et al. 1994), there are three main differences we can find out.",
      "startOffset" : 117,
      "endOffset" : 161
    }, {
      "referenceID" : 26,
      "context" : "First, the computational model of both the languages tcc (Saraswat et al. 1994) and default tcc (Saraswat et al.",
      "startOffset" : 57,
      "endOffset" : 79
    }, {
      "referenceID" : 24,
      "context" : "1994) and default tcc (Saraswat et al. 1996) is inspired by that one of synchronous languages: each time interval is identified with the time needed for a ccp process to terminate a computation.",
      "startOffset" : 22,
      "endOffset" : 44
    }, {
      "referenceID" : 26,
      "context" : "In (Saraswat et al. 1994) and (Saraswat et al.",
      "startOffset" : 3,
      "endOffset" : 25
    }, {
      "referenceID" : 24,
      "context" : "1994) and (Saraswat et al. 1996), the programmer has to explicitly transfer the (positive) information from a time instant to the next one, by using special primitives that allow one to control the temporal evolution of the system.",
      "startOffset" : 10,
      "endOffset" : 32
    }, {
      "referenceID" : 26,
      "context" : "A third relevant difference is in (Saraswat et al. 1994) and (Saraswat et al.",
      "startOffset" : 34,
      "endOffset" : 56
    }, {
      "referenceID" : 24,
      "context" : "1994) and (Saraswat et al. 1996) the authors present deterministic languages while our language allows for nondeterminism.",
      "startOffset" : 10,
      "endOffset" : 32
    }, {
      "referenceID" : 26,
      "context" : "These three differences also hold between (Saraswat et al. 1994) or (Saraswat et al.",
      "startOffset" : 42,
      "endOffset" : 64
    }, {
      "referenceID" : 24,
      "context" : "1994) or (Saraswat et al. 1996), and the original crisp version of the language, i.",
      "startOffset" : 9,
      "endOffset" : 31
    }, {
      "referenceID" : 21,
      "context" : "In (Olarte et al. 2007), the authors generalize the model in (Saraswat et al.",
      "startOffset" : 3,
      "endOffset" : 23
    }, {
      "referenceID" : 26,
      "context" : "2007), the authors generalize the model in (Saraswat et al. 1994) in order to extend it with temporary parametric ask operations.",
      "startOffset" : 43,
      "endOffset" : 65
    }, {
      "referenceID" : 21,
      "context" : "However, also the agents in (Olarte et al. 2007) show a deterministic behavior, instead of our not-deterministic choice.",
      "startOffset" : 28,
      "endOffset" : 48
    }, {
      "referenceID" : 20,
      "context" : "Other timed extension of concurrent constraint programming have been proposed in (Nielsen and Valencia 2002; Palamidessi and Valencia 2001), however these languages, differently from tsccp, do not take into account quantitative aspects; therefore, this achievement represents a very important expressivity improvement with respect to related works.",
      "startOffset" : 81,
      "endOffset" : 139
    }, {
      "referenceID" : 22,
      "context" : "Other timed extension of concurrent constraint programming have been proposed in (Nielsen and Valencia 2002; Palamidessi and Valencia 2001), however these languages, differently from tsccp, do not take into account quantitative aspects; therefore, this achievement represents a very important expressivity improvement with respect to related works.",
      "startOffset" : 81,
      "endOffset" : 139
    }, {
      "referenceID" : 6,
      "context" : "More recently, stochastic ccp has been introduced in (Bortolussi 2006) to model biological systems.",
      "startOffset" : 53,
      "endOffset" : 70
    }, {
      "referenceID" : 27,
      "context" : "At last, we would like to consider other time management strategies (as the one proposed in (Valencia 2003)), and to study how timing and non-monotonic constructs (Bistarelli and Santini 2011) can be integrated together.",
      "startOffset" : 92,
      "endOffset" : 107
    }, {
      "referenceID" : 5,
      "context" : "At last, we would like to consider other time management strategies (as the one proposed in (Valencia 2003)), and to study how timing and non-monotonic constructs (Bistarelli and Santini 2011) can be integrated together.",
      "startOffset" : 163,
      "endOffset" : 192
    } ],
    "year" : 2014,
    "abstractText" : "We propose a timed and soft extension of Concurrent Constraint Programming. The time extension is based on the hypothesis of bounded asynchrony: the computation takes a bounded period of time and is measured by a discrete global clock. Action prefixing is then considered as the syntactic marker which distinguishes a time instant from the next one. Supported by soft constraints instead of crisp ones, tell and ask agents are now equipped with a preference (or consistency) threshold which is used to determine their success or suspension. In the paper we provide a language to describe the agents behavior, together with its operational and denotational semantics, for which we also prove the compositionality and correctness properties. After presenting a semantics using maximal parallelism of actions, we also describe a version for their interleaving on a single processor (with maximal parallelism for time elapsing). Coordinating agents that need to take decisions both on preference values and time events may benefit from this language. To appear in Theory and Practice of Logic Programming (TPLP).",
    "creator" : "LaTeX with hyperref package"
  }
}