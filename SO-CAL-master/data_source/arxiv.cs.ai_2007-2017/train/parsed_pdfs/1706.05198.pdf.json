{
  "name" : "1706.05198.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Structured Best Arm Identification with Fixed Confidence",
    "authors" : [ "Ruitong Huang", "Mohammad M. Ajallooeian", "Csaba Szepesvári", "Martin Müller" ],
    "emails" : [ "ruitong@ualberta.ca", "ajallooe@ualberta.ca", "szepesva@ualberta.ca", "mmueller@ualberta.ca" ],
    "sections" : [ {
      "heading" : "1. Introduction",
      "text" : "Motivated by the problem of finding the optimal move in minimax tree search with noisy leaf evaluations, we introduce best arm identification problems with structured payoffs and micro-observables. In these problems, the learner’s goal is to find the best arm when the payoff of each arm is a fixed and known function of a set of unknown values. In each round, the learner can choose one of the micro-observables to make a noisy measurement (i.e., the learner can obtain a “micro-observation”). We study these problems in the so-called fixed confidence setting.\nA special case of this problem is the standard best arm identification, which has seen a flurry of activity during the last decade, e.g., (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015). Recently, Garivier et al. (2016a) considered the motivating problem mentioned above. However, they only considered the simplest (non-trivial) instance when two players alternate for a single round. One of their main observations is that such\nc©... Ruitong Huang and Mohammad M. Ajallooeian and Csaba Szepesvári and Martin Müller.\nLicense: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided at http://jmlr.org/papers/v./ajallooe17a.html.\nar X\niv :1\n70 6.\n05 19\n8v 2\n[ cs\n.L G\n] 1\n9 Ju\ntwo-move problems can be solved more efficiently than if one considers the problem as an instance of a nested best arm identification problem. They proposed two algorithms, one for the fixed confidence setting, the other for the (asymptotic) vanishing confidence setting and provided upper bounds. An implicit (optimization-based) lower bound was also briefly sketched, together with a plan to derive an algorithm that matches it in the vanishing confidence setting.\nOur main interest in this paper is to see whether the ideas of Garivier et al. (2016a) extend to more general settings, such as when the depth can be non-uniform and is in particular not limited to two, or when the move histories can lead to shared states (that is, in the language of adversarial search we allow “transpositions”). While considering these extensions, we found it cleaner to introduce the abstract setting mentioned below (Section 2). The motivation here is to clearly delineate the crucial properties of the problem that our results use. For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems. Considering again the abstract setting, we propose a new algorithm, which we call LUCB-micro (Section 5), and which can be considered as a natural generalization of Maximin-LUCB of Garivier et al. (2016a) (with some minor differences). Under a regularity assumption on the payoff maps, we prove that the algorithm meets the risk-requirement. We also provide a high-probability, instance-dependent upper bound on algorithm’s sample complexity (i.e., on the number of observations the algorithm takes). As we discuss, while this bound meets the general characteristics of existing bounds, it fails to reproduce the corresponding result of Garivier et al. (2016a). To the best of authors’ knowledge, the only comparable algorithm to study best arm identification in a full-length minimax tree search setting (which was the motivating example of our work) is FindTopWinner by Teraoka et al. (2014). This algorithm is a roundbased elimination based algorithm with additional pruning steps that come from the tree structure. When we specialize our framework to the minimax game scenario (and implement other necessary changes to put our work into their ( , δq-PAC setting), our upper bound is a strict improvement of theirs, e.g., in the number of samples related to the near-optimal micro-observables (leaves of the minimax game tree). Next, we consider the minimax setting (Section 6). First, we show that the regularity assumptions made for the abstract setting are met in this case. We also show how to efficiently compute the choices that LUCB-micro makes using a “min-max” algorithm. Finally, we strengthen our previous result so that it is able to reproduce the mentioned result of Garivier et al. (2016a)."
    }, {
      "heading" : "1.1 Notation",
      "text" : "We use N “ t1, 2, . . . u to denote the set of positive integers, while we let R denote the set of reals. For a positive integer k P N, we let rks “ t1, . . . , ku. For a vector v P Rd, we denote its i-th element by vi; though occasionally we will also use vpiq for the same purpose, i.e., we\nidentify Rd and tf : f : rds Ñ Ru in the obvious way. We let |v| denote the vector defined by |v| “ p|vi|qiPrds. For two vectors u, v P Rd, we define u ď v if and only if ui ď vi for all 1 ď i ď d. Further, we write u ă v when u ‰ v and u ď v. For B Ă rds, we write u|B to denote the |B|-dimensional vector obtained from restricting u to components with index in B: u|B “ puiqiPB. We use 1d to denote the d dimensional vector whose components are all equal to one. For a nonempty set B, we also use 1B to denote the |B|-dimensional all-one vector. We let Bc “ ti P rds : i R Bu to denote the complementer of B (when Bc is used, the base set that the complementer is taken for should be clear from the context). The indicator function will be denoted by I t¨u. We will use a^ b “ minpa, bq and a_ b “ maxpa, bq. For A Ă R, Ā denotes its topological closure, while A˝ denotes its interior. Given a real value a P R, a` “ a_ 0 and a´ “ ´pa^ 0q. For a sequence pm0, . . . ,miq of some values and some other value m, we define joinph,mq “ pm0, . . . ,mi,mq."
    }, {
      "heading" : "2. Problem setup",
      "text" : "Fix two positive integers, L and K. A problem instance of a structured K-armed best arm identification instance with L micro-observations is defined by a tuple pf, P q, where f : RL Ñ RK and P “ pP1, . . . , PLq is an L-tuple of distributions over the reals. We let µi “ ş\nxdPipxq denote the mean of distribution Pi. We shall denote the component functions of f by f1, . . . , fK : fpµq “ pf1pµq, . . . , fKpµqq. The value fipµq is interpreted as the payoff of arm i and we call f the reward map. The goal of the learner is to identify the arm with the highest payoff. It is assumed that the arm with the highest payoff is unique. The learner knows f , while is unaware of P , and, in particular, unaware of µ. To gain information about µ, the learner can query the distributions in discrete rounds indexed by t “ 1, 2, . . . , in a sequential fashion. The learner is also given δ P p0, 1q, a risk parameter (also known as a confidence parameter). The goal of the learner is to identify the arm with the highest payoff using the least number of observations while keeping the probability of making a mistake below the specified risk level.\nA learner is admissible for a given set S of problem instances if (i) for any instance from S, the probability of the learner misidentifying the optimal arm in the instance is below the given fixed risk factor δ; and (ii) the learner stops with probability one on any instance from S. The interaction of a learner and a problem instance is shown on Fig. 1.\nMinimax games As a motivating example, consider the problem of finding the optimal move for the first player in a finite twoplayer minimax game. The game is finite because the game finishes in finitely many steps (by reaching one of the L possible terminating states). The first player has K\nmoves. The value of each move is a function of the values µ P RL of the L possible terminating states.\nFormally, such a minimax game is described by G “ pM,H, p, τq, where M is a nonempty finite set of possible moves, H Ă Yně0Mn is a finite set of (feasible) histories of moves, the function p : H Ñ t´1,`1u determines, for each feasible history, the identity of the player on turn, and τ is a surjection that maps a subset Hmax Ă H of histories, the set of maximal histories in H, to rLs (in particular, note that τ may map multiple maximal histories to the same terminating state). An element h of H is maximal in H if it is not the prefix of any other history h1 P H, or, in other words, if it has no continuation in H. The set H has the property that if h P H then every prefix of h with positive length is also is in H. The first player’s moves are given by the histories in H that have a unit length. To minimize clutter, without the loss of generality (WLOG), we identify this set with rKs.\nThe function f “ pf1, . . . , fKq underlying G gives the payoffs of the first player. To define f we use the auxiliary function V p¨, µq : H Ñ R that evaluates any particular history given the values µ assigned to terminal states. Given V , we define fkpµq “ V ppkq, µq for any k P rKs. It remains to define V : For h P Hmax, V ph, µq “ µτphq. For any other feasible history h P H, V ph, µq “ pphqmaxtpphqV ph1, µq : h1 P Hsuccphqu, where Hsuccphq “ tjoinph,mq : m PMuXH is the set of immediate successors of h inH. Thus, when pphq “ 1, V ph, µq is the maximum of the values associated with the immediate successors of h, while when pphq “ ´1, V ph, µq is the minimum of these values. We define mph, µq as the move m defining the optimal immediate successor of h given µ. Note that all many of the defined functions depend on H, but the dependence is suppressed, as we will keep H fixed. One natural problem that fits our setting is a (small) game when the payoffs at the terminating states of a game are themselves randomized (e.g., at the end of a game some random hidden information such as face down cards can decide the value of the final state). As explained by Garivier et al. (2016a), the setting may also shed light on how to design better Monte-Carlo Tree Search (MCTS) algorithms, which is a relatively novel class of search algorithms that proved to be highly successful in recent years (e.g., Gelly et al., 2012; Silver et al., 2016)."
    }, {
      "heading" : "3. Lower bound: General setting",
      "text" : "In this section we will prove a lower bound for the case of a fixed map f and when the set of instances is the set all normal distributions with unit variance. We denote the corresponding set of instances by Snormf . Our results can be easily extended to the case of other sufficientlyrich family of distributions.\nFor the next result, assume without loss of generality that f1pµq ą f2pµq ě ¨ ¨ ¨ ě fKpµq. Fix a learner (policy) A, which maps histories to actions. For simplicity, we assume that A is deterministic (the extension to randomized algorithms is standard). Let Ω “ prLs ˆ RqN be the set of (infinite) sequences of observable-index and observation pairs so that for any ω “ pi1, y1, i2, y2, . . . q P Ω, t ě 1, Itpωq “ it and Ytpωq “ yt. We equip Ω with the associated Lebesgue σ-algebra F . For an infinite sequence ω “ pi1, y1, i2, y2, . . . q P Ω, we let T pωq P N Y t8u be the round index when the algorithm stops (we let T pωq “ 8 if the algorithm never stops on ω). Thus, T : Ω Ñ N Y t8u. Similarly, define J : Ω Ñ rK ` 1s to be the choice of the algorithm when it stops, where we define Jpωq “ K ` 1 in case T pωq “ 8.\nThe interaction of a problem instance (uniquely determined by µ) and the learner (uniquely determined by the associated policy A) induces a unique distribution Pµ,A over the measurable space pΩ,Fq, where we agree that in rounds with index t “ T ` 1, T ` 2, . . . , we specify that the algorithm chooses arm 1, while the observation distributions are modified so that the observation is deterministically set to zero. We will also use Eµ,A to denote the expectation operator corresponding to Pµ,A.\nTo appease the prudent reader, let us note that our statements will always be concerned with events that are subsets of the event tT ă 8u and as such they are not effected by how we specify the “choices” of the algorithm and the “responses” of the environment for t ą T . Take, as an example, the expected number of steps that A takes in an environment µ, Eµ,ArT s, which we bound below. Since we bound this only in the case when the algorithm A is admissible, which implies that Pµ,ApT ă 8q “ 1, we have Eµ,ArT s “ Eµ,ArT I tT ă 8us. which shows that the behavior of Pµ,A outside of Pµ,A outside of tT ă 8u is immaterial for this statement. The choices we made for t ą T (for the algorithm and the environment) will however be significant in that they simplify a key technical result.\nTo state our result, we need to introduce the set of significant departures, Dµ Ă RL, from µ. This set contains all vectors ∆ such that the best arm under µ `∆ is not arm 1. Formally,\nDµ “ t∆ P RL : f1pµ`∆q ď max ią1 fipµ`∆qu . (1)\nTheorem 1 (Lower bound) Fix a risk parameter δ P p0, 1q. Assume that A is admissible over the instance set Snormf at the risk level δ. Define\nτ˚pµq “ min # L ÿ\ni“1 npiq : inf ∆PDµ\nL ÿ i“1 npiq∆2i ě 2 logp1{p4δqq, np1q, . . . , npLq ě 0\n+\n. (2)\nThen, Eµ,ArT s ě τ˚pµq.\nThe proof can be shown to reproduce the result of Garivier and Kaufmann (2016) (see page 6 of their paper) when the setting is best arm identification. The proof uses standard steps (e.g., Auer et al., 2002; Kaufmann et al., 2016) and one of its main merit is its simplicity. In particular, it relies on two information theoretical results; a high-probability Pinsker inequality (Lemma 2.6 from (Tsybakov, 2008)) and a standard decomposition of divergences. The proof is given in Section B (all proofs omitted from the main body can be found in the appendix).\nRemark 2 (Minimal significant departures (Dminµ )) From the set of significant departures one can remove all vectors d that are componentwise dominating in absolute value some other significant departure ∆ P Dµ without effecting the lower bound. To see this, write the lower bound as mint ř\ni npiq : n P X∆PDµΦp∆qu, where Φp∆q “ tn P r0,8qL : ř i npiq∆2i ě 2 logp1{p4δqqu. Then, if d,∆ P Dµ are such that |∆| ď |d| then Φp∆q Ă Φpdq. Hence, X∆PDµΦp∆q “ X∆PDminµ Φp∆q where D min µ “ td P Dµ : E∆ P Dµ s.t. |∆| ă |d|u."
    }, {
      "heading" : "4. Lower bound for minimax games",
      "text" : "In this section we prove a corollary of the general lower bound of the previous section in the context of minimax games; the question being what role the structure of a game plays in the lower bound. For this section fix a minimax game structure G “ pM,H, p, τq (cf. Section 2). We first need some definitions:\nDefinition 1 (Proof sets) Take a minimax game structure G “ pM,H, p, τq with K first moves and L terminal states. Take j P rKs. A set B Ă rLs is said to be sufficient for proving upper bounds on the value of move j if for any µ P RL and θ P R, µ|B “ θ1B implies fjpµq ď θ. Symmetrically, a set B Ă rLs is said to be sufficient for proving lower bounds on the value of move j if for any µ P RL and θ P R, µ|B “ θ1B implies fjpµq ě θ.\nWe will call the sets satisfying the above definition upper (resp., lower) proof sets, denoted by B`j (resp., B ´ j ). Proof sets are closely related to conspiracy sets (McAllester, 1988), forming the basis of “proof number of search” (Allis, 1994; Kishimoto et al., 2012). In a minimax game tree, a conspiracy set of a node (say, v) is the set of leaves that must change their evaluation value to cause a change in the minimax value of that node v. Proof sets are also related to cuts in α–β search (Russell and Norvig, 2010).\nOne can obtain minimal upper proof sets that belong to B`j in the following way: Let Hj denote the set of histories that start with move j. Consider a non-empty rH Ă Hj that satisfies the following properties: (i) if h P rH and pphq “ ´1 (minimizing turn) then |Hsuccphq X rH| “ 1; (ii) if h P rH and pphq “ 1 (maximizing turn) then Hsuccphq Ă rH. Call the set of rH that can be obtained this way H`j . From the construction of rH we immediately get the following proposition:\nProposition 3 Take any rH P H`j as above. Then, τp rH XHmaxq P B ` j .\nA similar construction and statement applies in the case of B´j , resulting in the set H ´ j . Our next result will imply that the lower bound is achieved by considering departures of a special form, related to proof sets:\nProposition 4 (Minimal significant departures for minimax games) Assume WLOG that f1pµq ą maxją1 fjpµq. Let\nS “ ! ∆ P RL : D1 ă j ď K , θ P rfjpµq, f1pµqs, B P B`1 , B 1 P B´j s.t.\n∆i “ ´pµi ´ θq`, @i P BzB1; ∆i “ pµi ´ θq´, @i P B1zB; ∆i “ θ ´ µi, @i P B1 XB; ∆i “ 0, @i P pB YB1qc ) .\nThen, Dminµ Ă S Ă Dµ.\nNote that the second inclusion shows that replacing Dµ by S in the definition of τ˚pµq would only decrease the value of τ˚pµq, while the first inclusion shows that the value actually does not change. The following lemma, characterizing minimal departures, is essential for our proof of Proposition 4:\nLemma 5 Take any µ P RL, d P Dminµ and assume WLOG that f1pµq ą maxją1 fjpµq. Then, there exist B P B`1 , j P t2, . . . ,Ku and B1 P B ´ j such that\n(i) maxtpµ` dqi : i P Bu “ f1pµ` dq “ fjpµ` dq “ mintpµ` dqi : i P B1u;\n(ii) di ď 0 if i P BzB1; di ě 0 if i P B1zB;\n(iii) @i P B YB1, either pµ` dqi “ f1pµ` dq “ fjpµ` dq or di “ 0.\nProposition 4 implies the following:\nCorollary 6 Let µ be a valuation and assume WLOG that f1pµq ą maxją1 fjpµq. Let Bj “ tpB,B1q : B P B`1 , B1 P B ´ j u. Then,\nτ˚pµq “ min nPr0,8qL\n!\nÿ\ni\nnpiq : min 1ăjďK,θPrfjpµq,f1pµqs,pB,B1qPBj\nÿ\niPBzB1 npiqpµi ´ θq2` `\nÿ\niPB1zB npiqpµi ´ θq2´\n` ÿ\niPBXB1 npiqpθ ´ µiq2 ě 2 logp 14δ q\n)\n.\nHence, for any algorithm A admissible over the instance set Snormf at the risk level δ, Eµ,ArT s is at least as large than the right-hand side of the above display."
    }, {
      "heading" : "5. Upper bound",
      "text" : "In this section we propose an algorithm generalizing the LUCB algorithm of Kalyanakrishnan et al. (2012) and prove a theoretical guarantee for the proposed algorithm’s sample complexity under some (mild) assumptions on the structure of the reward mapping f . Our result is inspired and extends the results of Garivier et al. (2016a) (who also started from the LUCB algorithm) to the general setting proposed in this paper. In Section 6 we give a version of the algorithm presented here that is specialized to minimax games and refine the upper bound of this section, highlighting the advantages of the extra structure of minimax games.\nIn this section we shall assume that the distributions pPiqiPrLs are subgaussian with a common parameter, which we take to be one for simplicity:\nAssumption 1 (1-Subgaussian observations) For any i P rLs, X „ Pip¨q,\nsup λPR\nE “ exppλpX ´ EXq ´ λ2{2q ‰ ď 1 .\nWe will need a result for anytime confidence intervals for martingales with subgaussian increments. For stating this result, let pFtqtPN be a filtration over the probability space pΩ,F ,Pq holding our random variables and introduce Etr¨s “ E r¨|Ft´1s. This result appears as (essentially) Theorem 8 in the paper by Kaufmann et al. (2016) who also cite precursors:\nLemma 7 (Anytime subgaussian concentration) Let pXtqtPN be an pFtqtPN-adapted 1- subgaussian, martingale difference sequence (i.e., for any t P N, Xt is Ft-measurable, EtXt “\n0, and supλ Et “ exppλpXtq ´ λ2{2q ‰ ď 1). For t P N, let Xt “ p1{tq řt s“1Xs, while for t P NY t0u and δ P r0, 1s we let\nβpt, δq “ logp1{δq ` 3 log logp1{δq ` p3{2qplogplogpetqqq` .\nThen, for any δ P r0, 0.1s,1\nP\n˜\nsup tPN\nXt a\n2βpt, δq{t ą 1\n¸\nď δ .\nFor a fixed i P rLs, let Ntpiq “ řt s“1 I tIs “ iu denote the number of observations taken from Pip¨q up to time t. Define the confidence interval rLδt piq, U δt piqs for µi as follows: We let\npµtpiq “ 1\nNtpiq\nt ÿ s“1 I tIs “ iuYs ,\nthe empirical mean of observations from Pip¨q to be the center of the interval (whenNtpiq “ 0, we define pµtpiq “ 0) and\nLδt piq “ max # Lδt´1piq, pµtpiq ´\nd\n2βpNtpiq, δ{p2Lqq Ntpiq\n+\n;\nU δt piq “ min # U δt´1piq, pµtpiq `\nd\n2βpNtpiq, δ{p2Lqq Ntpiq\n+\n,\nwhere βpt, δq is as in Lemma 7 (note that when Ntpiq “ 0, the confidence interval is p´8,`8q). Let T be the index of the round when the algorithm soon to be proposed stops (or T “ 8 if it does not stop). Let ξ “ XtPrT s,iPrLstµi P rLδt piq, U δt piqsu be the “good” event when the proposed respective intervals before the algorithm stops all contain µi for all i P rLs. One can easily verify that, regardless the choice of the algorithm (i.e., the stopping time T ),\nP pξq ě 1´ δ , (3) @t P N, Lδt piq ď pµtpiq ď U δt piq. (4)\nFor S Ă RL define fpSq “ tfpsq : s P Su. With this definition, if we let St “ ŚL i“1rLδt piq, U δt piqs then for any j P rKs, fjpµq P fjpStq holds for any t ě 1 on ξ. Thus, fjpStq is a valid, p1´ δqlevel confidence set for fjpµq. For general f , these sets may have a complicated structure. Hence, we will adapt the following simplifying assumption:\nAssumption 2 (Regular reward maps) The following hold:\n(i) The mapping function f is monotonous with respect to the partial order of vectors: for any u, v P RL, u ď v implies fpuq ď fpvq;\n1. Note that βpt, δq is also defined for t “ 0. The value used is arbitrary: It plays no role in the current result. The reason we define β for t “ 0 is because it simplifies some subsequent definitions.\n(ii) For any u, v P RL, u ď v, j P rKs, the set Dpj, u, vq “ ti P rLs : rfjpuq, fjpvqs Ă rui, vis u is non-empty.\nWe will also let Dtpjq “ Dpj, Lδt , U δt q. Note that the assumption is met when f is the reward map underlying minimax games (see the next section). The second assumption could be replaced by the following weaker assumption without essentially changing our result: with some a ą 0, b P R, for any j, u ď v, rfjpuq, fjpvqs Ă raui ` b, avi ` bs for some i P rLs. The point of this assumption is that by guaranteeing that all intervals on the micro-observables shrink, the interval on the arm-rewards will also shrink at the same rate. We expect that other ways of weakening this assumption are also possible, perhaps at the price of slightly changing the algorithm (e.g., by allowing it to use even more micro-observations per round).\nAlgorithm 1 LUCB-micro for t “ 1, 2, . . . do Choose Bt, Ct as in Equation (5) Choose any pIt, Jtq from DtpBtqˆDtpCtq Observe Yt,1 „ PItp¨q, Yt,2 „ PJtp¨q Update rLδt pItq, U δt pItqs, rLδt pJtq, U δt pJtqs if Stop() then J Ð Bt, T Ð t return pT, Jq\nAt time t, let\nBt “ argmax jPrKs fjpLδt q ,\nCt “ argmax jPrKs,j‰Bt\nfjpU δt q . (5)\n(B stands for candidate “best” arm, C stands for best “contender” arm). Based on the above assumption, we can now propose our algorithm, LUCB-micro (cf. Algorithm 1). Following the idea of LUCB, LUCB-micro chooses Bt and Ct in an effort to separate the highest lower bound from the best competing upper bound.2 To decrease the width of the confidence intervals, both for Bt and Ct, a micro-observable is chosen with the help of Assumption 2(ii). This can be seen as a generalization of the choice made in Maximin-LUCB by Garivier et al. (2016a). Here, we found that the specific way Maximin-LUCB’s choice is made considerably obscured the idea behind this choice, which one can perhaps attribute to that the fact that the two-move setting makes it possible to write the choice in a more-or-less direct fashion.\nIt remains to specify the ‘Stop()’ function used by our algorithm. For this, we propose the standard choice (as in LUCB):\nStop() : fBtpLδt q ě fCtpU δt q. (6)\nAll statements in this section assume that the assumptions stated so far in this section hold.\nThe following proposition is immediate from the definition of the algorithm.\nProposition 8 (Correctness) On the event ξ, LUCB-micro returns J correctly: J “ j˚pµq.\nLet T denote the round index when LUCB-micro stops3 and define c “ f1pµq`f2pµq2 and ∆ “ f1pµq ´ f2pµq, where we assumed that f1pµq ą f2pµq ě maxjě2 fjpµq. The main result\n2. Using a lower bound departs from the choice of LUCB, which would use fjpµ̂tq to define Bt. The reason of this departure is that we found it easier to work with a lower bound. We expect the two versions (original, our choice) to behave similarly. 3. The number of observations, or number of rounds as per Fig. 1, taken by LUCB-micro until it stops is 2T .\nof this section is a high-probability bound on T , which we present next. The following lemma is the key to the proof:\nLemma 9 Let t ă T . Then, on ξ, there exists J P tBt, Ctu such that c P rfJpLδt q, fJpU δt qs and fJpU δt q ´ fJpLδt q ě ∆{2.\nThe proof follows standard steps (e.g., Garivier et al. 2016a). In particular, the above lemma implies that if T ą t then for J P tBt, Ctu, c P rfJpLδt q, fJpU δt qs and fJpU δt q´fJpLδt q ě ∆{2. This in turn implies that for i P tIt, Jtu, Ntpiq cannot be too large.\nTheorem 10 (LUCB-micro upper bound) Let\nHpµq “ ÿ\niPrLs\n\"\n1 pc´ µiq2 ľ 1 p∆{2q2\n*\n, and t˚pµq “ mintt P N : 1` 8Hpµqβpt, δ{p2Lqq ď tu .\nThen, for δ ď 0.1, on the event ξ, the stopping time T of LUCB-micro satisfies T ď t˚pµq.\nNote that βpt, δq9 log log t and thus t˚pµq is well-defined. Furthermore, letting cδ “ logp2L{δq ` 3 log logp2L{δq, for δ sufficiently small and Hpµq sufficiently large, elementary calculations give\nt˚pµq ď 16Hpµqcδ ` 16Hpµq log logp8Hpµqcδq .\nRemark 11 The constant Hpµq acts as a hardness measure of the problem. Theorem 10 can be applied to the best arm identification problem in the multi-armed bandits setting, as it is a special case of our problem setup. Compared to state-of-the-art results available for this setting, our bound is looser in several ways: We lose on the constant factor multiplying Hpµq (Kalyanakrishnan et al., 2012; Jamieson and Nowak, 2014; Jamieson et al., 2014; Kaufmann et al., 2016), we also lose an additive term of Hpµq log logpLq (Chen and Li, 2015). We also lose logpLq terms on the suboptimal arms (Simchowitz et al., 2017). Comparing with the only result available in the two-move minimax tree setting, due to Garivier et al. (2016a), our bound is looser than their Theorem 1. This motivates the refinement of this result to the minimax setting, which is done in the next section, and where we recover the mentioned result of Garivier et al. (2016a). On the positive side, our result is more generally applicable than any of the mentioned results. It remains an interesting sequence of challenges to prove an upper bound for this or some other algorithm which would match the mentioned state-ofthe-art results, when the general setting is specialized."
    }, {
      "heading" : "6. Best move identification in minimax games",
      "text" : "In this section we will show upper bounds on the number of observations LUCB-micro takes in the case of minimax game problems. We still assume that the micro-observations are subgaussian (Assumption 1) and the optimal arm is unique. To apply our result, this leaves us with showing that the payoff function in the minimax game satisfies the regularity assumption (Assumption 2).\nFix a minimax game structure G “ pM,H, p, τq. We first show that Property (i) of Assumption 2 holds. This follows easily from the following lemma, which can be proven by induction based on “distance from the terminating states”.\nLemma 12 For any h P H and u, v P r0, 1sL such that u ď v, V ph, uq ď V ph, vq.\nFrom this result we immediately get the following corollary:\nCorollary 13 For u, v P r0, 1sL such that u ď v, fpuq ď fpvq, hence Assumption 2 (i) holds.\nFor j P rKs, u, v P RL, u ď v, per Property (ii) of Assumption 2, we need to show that the sets Dpj, u, vq are nonempty. For a history h “ pm1,m2, . . . ,m`q P H and 1 ď k ď `, we denote its length-k prefix pm1, . . . ,mkq by hk. We give an algorithmic demonstration, which also shows how to efficiently pick an element of these sets. The resulting algorithm is called MinMax (cf. Algorithm 2). We define MinMax in a recursive fashion: For each nonmaximal history the algorithm extends the history by adding the move which is optimal for u for minimizing moves, while it extends it by adding the optimal move for v for maximizing moves, and then it calls itself with the new history. The algorithm returns when its input is a maximal history. To show that τpMinMaxph, u, vqq P Dpj, u, vq we have the following result:\nLemma 14 Fix u, v P RL, u ď v, and j P rKs. Let h “ MinMaxppjqq and in particular let h “ pm1 “ j,m2, . . . ,m`q. Then, for all 1 ď k ă `,\nrV phk, uq, V phk, vqs Ă rV phk`1, uq, V phk`1, vqs ,\nwhere hk is the length-k prefix of h.\nWe immediately get that i “ τphq is an element of Dpj, u, vq:\nCorollary 15 For j, u, v, h as in the previous result, setting i “ τphq, rfjpvq, fjpvqs Ă rui, viqs, hence i P Dpj, u, vq ‰ H.\nWith this, we have shown that all the assumptions needed by Theorem 10 are satisfied, and in particular, we can use It “ MinMaxpBt, Lδt , U δt q and Jt “ MinMaxpCt, Lδt , U δt q. We call the resulting algorithm LUCBMinMax. Then, Theorem 10 gives:\nCorollary 16 Let ξ, c,∆, Hpµq, t˚ be as in Section 5. If T is the stopping time of LUCBMinMax running on a minimax game search problem then T ď t˚.\nAlgorithm 2 MinMax. Inputs: h P H, u, v P RL. if h P Hmax then return h\nelse if pphq “ ´1 then hÐ joinph,mph, uqq else if pphq “ 1 then hÐ joinph,mph, vqq return MinMaxph, u, vq When applied to a minimax game, as defined in Section 2, the upper bound of Corollary 16 is loose and can be further improved as shown in the result below. To state this result we need some further notation. Given a set of reals S, define the “span” of S as spanpSq “ maxu,vPS u ´ v. For a path h P H that connects some move in rKs and some move in rLs: h “ pm1, . . . ,m`q with some ` ě 0, m1 P rKs and m` P rLs. Finally, for i P rLs such that there is a unique path h P H satisfying τphq “ i, define Vpi, µq “ tV phk, µq : h “ pm1, . . . ,m` “ iq, m1 P rKs, 1 ď k ă `u. Let Vpi, µq be an empty set if there is multiple h P H such that τphq “ i.\nTheorem 17 (LUCBMinMax on MinMax Trees) Let\nHpµq “ ÿ iPrLs mint 1 spanpVpi, µq Y tc, µiuq2 , 4 ∆2 u, t˚pµq “ mintt P N : 1` 8Hpµqβpt, δ{p2Lqq ď tu .\nThen, on ξ, the stopping time T of LUCBMinMax satisfies T ď t˚pµq.\nRemark 18 Note that this result recovers Theorem 1 of Garivier et al. (2016a). To see this note that for every leaf pi, jq (as numbered in their paper), µi,1 P Vppi, jq, µq. Also note that µi,1 ď µi,j, thus |c ´ µi,j | ď maxt|c ´ µi,1|, |µi,j ´ µi,1|u. Therefore, spanptµi,1, µi,j , cuq “ maxt|µi,1 ´ c|, |µi,j ´ µi,1|u."
    }, {
      "heading" : "7. Discussion and Conclusions",
      "text" : "The gap between the lower bound and the upper bound There is a substantial gap between the lower and the upper bound. Besides the gaps that already exist in the multiarmed bandit setting and which have been mentioned before, there exists a substantial gap: In particular, it is not hard to show that in regular minimax game trees with a fixed branching factor of κ and depth d, the upper bound scales with Opκdq while the lower bound scales with Opκd{2q. One potential is to improve the lower bound so as to consider adversarial perturbations of the values assigned to the leaf nodes: That is, after the algorithm is fixed, an adversary can perturb the values of µ to maximize the lower bound. Simchowitz et al. (2017) introduces an interesting technique for proving lower bounds of this form and they demonstrate nontrivial improvements in the multi-armed bandit setting.\nDoes the algorithm need to explore all leaves? The hardness measure Hpµq is rooted in a uniform bound that suggests that all the leaves must potentially be pulled, which may not hold for some particular structure. In particular, the algorithm may be able to benefit from the specific structure of f , saving explorations on some leaves. We present one example when f is a minimax game tree, as in Figure 2. Assume that µ1,i “ µ˚ ąą µ˚˚ “ µj,i for 1 ď i ď K and 2 ď j ď K. A reasonable algorithm would sample each arm once, then discover that the others arms are much less than the sampled leaf under arm 1. Then the algorithm will continue to explore the other leaves of arm 1, and decide arm 1 to be the best arm. This behavior is also in agreement with our lower bound, where the resulting constraints are:\nN1,ipµ˚ ´ µ˚˚q2 ě 2 logp1{4δq; K ÿ\ni“1 Nj,ipµ˚ ´ µ˚˚q2 ě 2 logp1{4δq @j ‰ 1,\nwhich implies N1,i ě 1 and řK i“1Nj,i ě 1 for j ‰ 1 if µ˚´µ˚˚ is large enough. As we can see from this example, pK´1q2 (out ofK2) leaves need no exploration at all. On the other hand, although we don’t have a tight upper bound, our algorithm in practice manages to explore the remaining K´1 leaves under arm 1 for the next K´1 rounds, and then make the right decision.\nIn general, we would expect that a problem with a feed forward neural network structure is easier than that of a tree structure, as the share of the leaves provides more information and thus save the exploration. This is illustrated on Fig. 3, where an optimal arm can be identified solely based on the network structure, thus the algorithm requires 0 sample for all possible µ. Note that our lower bound does not fail, as we have Dµ “ H here.\nAppendices"
    }, {
      "heading" : "A. The Uniqueness Assumption",
      "text" : "Recall that throughout the paper, by definition, we have the following assumption:\nAssumption 3 The instance is such that j˚pµq “ argmaxj fjpµq is unique.\nWe state this assumption explicitly here, so that we can refer to it easily throughout the appendix."
    }, {
      "heading" : "B. Proofs for Section 3",
      "text" : "Here we prove Theorem 1, which is restated for the convenience of the reader:\nTheorem 1 (Lower bound) Fix a risk parameter δ P p0, 1q. Assume that A is admissible over the instance set Snormf at the risk level δ. Define\nτ˚pµq “ min # L ÿ\ni“1 npiq : inf ∆PDµ\nL ÿ i“1 npiq∆2i ě 2 logp1{p4δqq, np1q, . . . , npLq ě 0\n+\n. (2)\nThen, Eµ,ArT s ě τ˚pµq.\nWe start with the two information theoretic results mentioned in the main body of the text. To state these results, let DpP,Qq denote the Kullback–Leibler (KL) divergence of two distributions P and Q. Recall that this is ş\nlogpdPdQqdQ when P is absolutely continuous with respect to Q and is infinite otherwise. For the next result, let Npiq “\nřT t“1 I tIt “ iu denote\nthe number of times an observation on the micro-observable with index i P rLs before time T .\nLemma 19 (Divergence decomposition) For any µ, µ1 P RL it holds that\nDpPµ,A,Pµ1,Aq “ 1\n2\nL ÿ i“1 Eµ,ArNpiqs pµi ´ µ1iq2 . (7)\nNote that 12pµi ´ µ 1 iq2 on the right-hand side is the KL divergence between the normal distributions with means µi and µ1i and both having a unit variance. The result, naturally, holds for other distributions, as well. This is the result that relies strongly on that we forced the same observations and same observation-choices for t ą T . In particular, this is what makes the left-hand side of (7) finite! The proof is standard and hence is omitted.\nLemma 20 (High probability Pinsker, e.g., Lemma 2.6 from (Tsybakov, 2008)) Let P and Q be probability measures on the same measurable space pΩ,Fq and let E P F be an arbitrary event. Then,\nP pEq `QpEcq ě 1 2 expp´DpP,Qqq .\nProof [of Theorem 1] WLOG, we may assume that D˝µ is non-empty. Pick any ∆ P D˝µ and let µ1 “ µ `∆. Let E “ tJ ‰ 1u. Since A is admissible, Pµ,ApEq ď δ. Further, since ∆ P D˝µ, 1 is not an optimal arm in µ1. Hence, again by the admissibility of A, Pµ1,ApEcq ď δ. Therefore, by Lemma 20,\n2δ ě Pµ,ApEq ` Pµ1,ApEcq ě 1\n2 expp´DpPµ,A,Pµ1,Aqq .\nNow, plugging in (7) of Lemma 19 and reordering we get\nlogp1{p4δqq ď DpPµ,A,Pµ1,Aq “ 1\n2\nL ÿ i“1 Eµ,ArNpiqs pµi ´ µ1iq2 .\nThe result follows by continuity, after noting that T “ řL i“1Npiq, that ∆ P D˝µ was arbitrary."
    }, {
      "heading" : "C. Proofs for Section 4",
      "text" : "We start with the following lemma:\nLemma 21 Pick any µ P RL, j P rKs. Then,\n@B P B`j , fjpµq ď maxtµi : i P Bu; @B P B ´ j , fjpµq ě mintµi : i P Bu.\nProof Fix any µ P RL, j P rKs, B P B`j . Let u “ maxtµi : i P Bu. We want to show that fjpµq ď u. Define µ1 ě µ such that µ1i “ µi if i R B, and µ1i “ u otherwise. As noted earlier (cf. Corollary 13), fj is monotonous. Hence, fjpµq ď fjpµ1q ď u, where the last inequality follows because B P B`j . The proof concerning B ´ j is analogous and is left to the reader.\nLemma 5 Take any µ P RL, d P Dminµ and assume WLOG that f1pµq ą maxją1 fjpµq. Then, there exist B P B`1 , j P t2, . . . ,Ku and B1 P B ´ j such that\n(i) maxtpµ` dqi : i P Bu “ f1pµ` dq “ fjpµ` dq “ mintpµ` dqi : i P B1u;\n(ii) di ď 0 if i P BzB1; di ě 0 if i P B1zB;\n(iii) @i P B YB1, either pµ` dqi “ f1pµ` dq “ fjpµ` dq or di “ 0.\nProof Note that since d P Dµ, f1pµ` dq ď fjpµ` dq for some j ‰ 1. Fix such an index j. To construct B and B1, we will pick rH1 P H`1 , rHj P H ´ j and set B “ τp rH1 XHmaxq and B1 “ τp rHj XHmaxq. By the construction of H`1 , to pick rH1 it suffices to specify the unique successor h1 in rH1 of any history h P rH1 with pphq “ ´1. For this, we let h1 P H be the successor for which V ph1, µ`dq “ V ph, µ`dq. Similarly, by the construction of H´j , to pick rHj it suffices to specify the unique successor h1 in rHj of any history h P rHj with pphq “ `1. Again, we let h1 P H be the successor for which V ph1, µ ` dq “ V ph, µ ` dq. Note that by Proposition 3, B P B`1 and B1 P B ´ j .\nLet us now turn to the proof of (i). We start by showing that\nf1pµ` dq “ maxtpµ` dqi : i P Bu . (8)\nTo show this, we first prove that\nV ph, µ` dq ď f1pµ` dq @h P rH1 . (9)\nThe proof uses induction based on the length of histories in rH1. There is only one history of length 1 (base case): h “ p1q. By the definition of f1, V ph, µ`dq “ f1pµ`dq. Now, assume that the statement holds for all histories up to length c ě 1. Take any h P rH1 of length c` 1. Let h1 P rH1 be the unique immediate predecessor of h: h P Hsuccph1q. This is well-defined thanks to the definition of H and the construction of rH1. If pph1q “ ´1 then, by the definition of rH1, V ph, µ`dq “ V ph1, µ`dq. By the induction hypothesis, V ph1, µ` dq ď f1pµ` dq, implying V ph, µ` dq ď f1pµ` dq. On the other hand, if pph1q “ `1 then f1pµ`dq ě V ph1, µ`dq “ maxtV ph̃, µ`dq, h̃ P Hsuccph1qu ě V ph, µ`dq, finishing the induction. Hence, we have proven (9).\nNow, we claim that there exists h˚ P rH1 X Hmax such that V ph˚, µ ` dq “ f1pµ ` dq. This, together with (9) implies (8).\nWe construct h˚ in a sequential process. For this, we will choose a sequence of moves m1, . . . ,mk such that pm1, . . . ,miq P HmaxX rH1 and V ppm1, . . . ,miq, µ` dq “ f1pµ` dq for any 1 ď i ď k. In a nutshell, this sequence is an “optimal sequence of moves” that starts with move 1, which is also known as a principal variation for the game under move 1. In details, the construction is as follows: To start, we choose m1 “ 1. Then V ppm1q, µ`dq “ f1pµ`dq, by the definition of f1. Assume that for some i ě 1, we already chose pm1, . . . ,miq so that V ppm1, . . . ,miq, µ` dq “ f1pµ` dq holds. If h\n.“ pm1, . . . ,miq P Hmax, we let k “ i and we are done. Otherwise, let mi`1 “ mph, µ`dq (this is the “optimal move” at h under valuation µ ` d). Thus, V pjoinph,mi`1q, µ ` dq “ V ph, µ ` dq “ f1pµq. Further, by the construction of rH1, joinph,mi`1q P rH1. Since all histories in H are bounded in length, the process ends after some k moves for some finite k, at which point we are done proving our statement.\nTo recap, so far we have proved (8). An entirely analogous proof (left to the reader) shows that also fjpµ` dq “ mintpµ` dqi : i P B1u.\nWe now prove that f1pµ`dq “ fjpµ`dq, finishing the proof of (i). Assume to the contrary that f1pµ`dq ă fjpµ`dq. Consider the map g : α ÞÑ f1pµ`αdq´fjpµ`αdq on the interval α P r0, 1s. Note that g is continuous, gp0q ą 0 ą gp1q. Hence, by the intermediate value theorem, there exists α P p0, 1q such that gpαq “ 0. Note that f1pµ ` αdq “ fjpµ ` αdq. Hence, αd P Dµ. Since α|d| ă |d|, d P Dminµ cannot hold, a contradiction. Hence, f1pµ`dq “ fjpµ` dq.\nLet us now turn to the proof of (ii). We prove that di ď 0 holds for all i P BzB1. (The statement concerning elements of B1zB follows similarly, the details are left to the reader.) For the proof, assume to the contrary of the desired statement that there exists some i P BzB1 such that di ą 0. Let d1 P RL be such that d1k “ dk for j ‰ i, and d1i “ 0. Thus, d1 ă d. By Corollary 13, f1pµ ` d1q ď f1pµ ` dq ď fjpµ ` dq “ mintpµ ` dqk : k P B1u “ mintpµ` d1qk : k P B1u ď fjpµ` d1q, where the last equality is due to i R B1 (hence, pµ` dq|B1 “ pµ` d1q|B1) while the last inequality follows from Lemma 21. This implies that d1 P Dµ. This together with |d1| ă |d| contradicts d P Dminµ . Thus, (ii) holds.\nIt remains to prove (iii). For this pick i P B. Since f1pµ ` dq “ fjpµ ` dq has already been established, it suffices to show that either pµ ` dqi “ f1pµ ` dq or di “ 0. (The case when i P B1 is symmetric and is left to the reader.) If i P B X B1 then by (i), pµ ` dqi ď maxkPBpµ ` dqk “ f1pµ ` dq “ fjpµ ` dq “ minkPB1pµ ` dqk ď pµ ` dqi, showing that pµ ` dqi “ f1pµ ` dq “ fjpµ ` dq. Hence, assume that i R B X B1. If di “ 0 or pµ ` dqi “ f1pµ ` dq then we are done. Otherwise, by (ii), di ă 0 and by (i), pµ ` dqi ă maxkPBpµ ` dqk “ f1pµ ` dq. Let “ f1pµ ` dq ´ pµ ` dqi. Note that ą 0. Define d1 P RL so that d1k “ dk if k ‰ i and let d1i “ ´pdi ` q´. That is, di is shifted up towards zero by a positive amount so that it never crosses zero. Then, |d1| ă |d|. Note also that µi ` d1i “ µi ` minpdi ` , 0q ď µi ` di ` “ f1pµ ` dq “ maxkPBpµ ` dqk. Hence, maxkPBpµ`d1qk “ maxkPBpµ`dqk “ f1pµ`dq and thus by Lemma 21, f1pµ`d1q ď maxkPBpµ`dq1k “ f1pµ`dq. By (i), f1pµ`dq “ fjpµ`dq “ minkPB1pµ`dqk. By the definition of d1 (thanks to i R B1) and Lemma 21, minkPB1pµ ` dqk “ minkPB1pµ ` d1qk ď fjpµ ` d1q. Putting together the inequalities, we get f1pµ` d1q ď fjpµ` d1q. Hence, d1 P Dµ. However, this and |d1| ă |d| contradict d P Dminµ , finishing the proof of (iii).\nLemma 22 Given any µ P RL and any θ P R, define µ1 as follows:\nµ1i “ # θ, i P I; µi, otherwise,\nwhere I Ă ti : µi ě θu. Then, fjpµ1q ě mint θ, fjpµq u for any j P rKs.\nProof Fix j P rKs. We prove V ph, µ1q ě mintθ, V ph, µqu for h P H by induction based on how close a history h is to being a maximal history. Note that this suffices to prove the statement thanks to fjpµ1q “ V ppjq, µ1q ě mintθ, V ppjq, µqu “ mintθ, fjpµqu.\nDefine function c so that cphq “ 0 if h P Hmax, and cphq “ 1`maxtcph1q : h1 P Hsuccphqu otherwise. Base case: If h P Hmax, then V ph, µ1q “ µ1i P tµi, θu ě mintθ, µiu “ mintθ, V ph, µqu for\nsome i P rLs. Induction step: Assume that for any h P H such that cphq ď c, V ph, µ1q ě mintθ, V ph, µqu. Given h such that cphq “ c` 1, if pphq “ 1,\nV ph, µ1q “ maxtV ph1, µ1q : h1 P Hsuccphqu ě maxtmintθ, V ph1, µqu : h1 P Hsuccphqu (by induction) (a) ě mintθ, V ph1˚, µqu “ mintθ, V ph, µqu,\nwhere in (a), h1˚ is the optimal h1 such that V ph1˚, µq “ V ph, µq. If pphq “ ´1,\nV ph, µ1q “ mintV ph1, µ1q : h1 P Hsuccphqu ě mintmintθ, V ph1, µqu : h1 P Hsuccphqu (b) ě mintθ, mintV ph1, µq : h1 P Hsuccphquu ě mintθ, V ph, µqu.\nHere (b) holds because for any h1 P Hsuccphq, V ph1, µq ě mintV ph1, µq : h1 P Hsuccphqu, thus mintθ , V ph1, µqu ě mintθ, mintV ph1, µq : h1 P Hsuccphquu.\nWith this, we are ready to prove Proposition 4, which we repeat here for the reader’s convenience:\nProposition 4 (Minimal significant departures for minimax games) Assume WLOG that f1pµq ą maxją1 fjpµq. Let\nS “ ! ∆ P RL : D1 ă j ď K , θ P rfjpµq, f1pµqs, B P B`1 , B 1 P B´j s.t.\n∆i “ ´pµi ´ θq`, @i P BzB1; ∆i “ pµi ´ θq´, @i P B1zB; ∆i “ θ ´ µi, @i P B1 XB; ∆i “ 0, @i P pB YB1qc ) .\nThen, Dminµ Ă S Ă Dµ.\nProof First we prove Dminµ Ă S. For this take any d P Dminµ . Since d P Dµ, by Lemma 5, for some j ą 1, f1pµ` dq “ fjpµ` dq. WLOG assume j “ 2. We will prove that:\nDB P B`1 , B 1 P B´2 s.t. @i P pB YB 1qc, di “ 0. (10)\nBy Lemma 5, there exist B P B`1 and B1 P B ´ 2 such that\nmaxtpµ` dqi : i P Bu “ f1pµ` dq “ f2pµ` dq “ mintpµ` dqi : i P B1u;\nTake these sets and pick some i P pB YB1qc. If di “ 0, we are done. Otherwise, let d1k “ dk for all k ‰ i and let d1i “ 0. Then, |d1| ă |d|. By Lemma 21 and Lemma 5 (i),\nf1pµ` d1q ď maxtpµ` d1qj : j P Bu “ maxtpµ` dqj : j P Bu “ f1pµ` dq ď f2pµ` dq “ mintpµ` dqj , j P B1u “ mintpµ` d1qj : j P B1u ď f2pµ` d1q.\nThus d1 P Dµ, which contradicts that d P Dminµ , establishing (10). Also we have f1pµ` dq “ f2pµ` dq.\nLet θ “ f1pµ` dq “ f2pµ` dq. For i P BzB1, by Lemma 5 (ii) and (iii), di “ ´pµi´ θq`. Similarly, di “ pµi ´ θq´ for i P B1zB. Note that for i P B XB1,\npµ` dqi ď maxtpµ` dqi : i P B XB1u ď maxtpµ` dqi : i P Bu “ f1pµ` dq “ θ “ f2pµ` dq “ mintpµ` dqi : i P B1u ď mintpµ` dqi : i P B1 XBu ď pµ` dqi .\nThus, pµ ` dqi “ θ, and therefore di “ θ ´ µi. It remains to prove θ P rf2pµq, f1pµqs. We prove this by contradiction. Assume that θ ă f2pµq. Define d1 as follows:\nd1i “ # ´pµi ´ f2pµqq` , if i P B ; 0 , otherwise.\nWe will prove the following claims:\n(i) |d1| ă |d|;\n(ii) f1pµ` d1q ď f2pµq;\n(iii) f2pµ` d1q ě f2pµq.\nAltogether these contradict d P Dminµ . To show (i), note that for i P Bc or i P B such that µi ď f2pµq, |d1i| “ 0 ď |di|. Assume i P B such that µi ą f2pµq ą θ. Then 0 ą d1i “ f2pµq ´ µi ą θ´ µi “ ´pµi ´ θq` “ di, thus |d1i| ă |di|. Therefore |d1| ă |d|, proving (i).\nFor (ii), note that for i P B, µi` d1i “ µi´ pµi´ f2pµqq` ď f2pµq, thus maxiPB µi` d1i ď f2pµq. By Lemma 21, we also have f1pµ ` d1q ď maxPB µ`d1i, which together with the previous inequality implies (ii).\nLastly, for proving (iii) define I “ ti P B : µi ě f2pµqu. Then µ1 :“ µ ` d1 can be rewritten as\nµ1i “ # f2pµq , if i P I ; µi , otherwise.\nBy Lemma 22, f2pµ` d1q ě f2pµq, showing (iii) . The inequality θ ď f1pµq can also be proved using analogous ideas. Therefore, θ P rf2pµq, f1pµqs. Combining all the previous statements leads to the conclusion Dminµ Ă S. Let us now prove that S Ă Dµ. Take any element ∆ P S. Let j P rKs, B P B`1 and B1 P B´j as in the definition of S. WLOG assume that j “ 2. Let µ1 “ µ `∆. It suffices to show that f1pµ1q ď θ and f2pµ1q ě θ. We show f1pµ1q ď θ, leaving the proof of the other relationship to the reader (the proof is entirely analogous to the one presented). By\nLemma 21, it suffices to show that maxtµ1i : i P Bu ď θ. When i P BzB1, ∆i “ ´pµi ´ θq`. Thus, µ1i “ µi ´ maxpµi ´ θ, 0q “ µi ` minpθ ´ µi, 0q ď µi ` θ ´ µi ď θ. If i P B X B1, µ1i “ µi ` pθ ´ µiq “ θ, thus finishing the proof."
    }, {
      "heading" : "D. Proofs for Section 5",
      "text" : "We start with the correctness result:\nProposition 8 (Correctness) On the event ξ, LUCB-micro returns J correctly: J “ j˚pµq.\nProof Assume to the contrary that J ‰ j˚pµq. WLOG let j˚pµq “ 1. By Assumption 2(i) the definition of ξ and that of J , CT , the stopping rule, fJpµq ě fJpLδT q ě fCT pU δT q ě f1pU δT q ě f1pµq. This contradicts Assumption 3.\nFor proving the sample complexity bound, we consider the following result:\nLemma 9 Let t ă T . Then, on ξ, there exists J P tBt, Ctu such that c P rfJpLδt q, fJpU δt qs and fJpU δt q ´ fJpLδt q ě ∆{2.\nProof We first prove that c P I .“ YjPtBt,CturfjpLδt q, fjpU δt qs. For this, it suffices to show that it does not hold that c P Ic where Ic “ RzI is the complementer of I. Now, c P Ic holds iff at least one of the four conditions hold: (i) fBtpLδt q ą c and fCtpLδt q ą c; (ii) fBtpU δt q ă c and fCtpU δt q ă c; (iii) fBtpU δt q ă c and fCtpLδt q ą c; (iv) fBtpLδt q ą c and fCtpU δt q ă c. Consider the following:\nCase (i) implies that fBtpµq ě fBtpLδt q ą c and similarly fCtpµq ą c. Thus there are two arms with payoff greater than c, which contradicts Assumption 3.\nCase (ii) implies that no arm has payoff above c, which contradicts the definition of c.\nCase (iii) Then fCtpLδt q ą c ą fBtpU δt q ě fBtpLδt q, which contradicts the definition of Bt. Case (iv) If this is true, then by definition the algorithm has stopped, hence t ă T .\nThus, we see that c P Ic cannot hold and hence c P rfJpLδt q, fJpU δt qs for either J “ Bt or J “ Ct, proving the first part. Next, note that for any j P rLs, |c ´ fjpµq| ě ∆2 . Hence, also |c ´ fJpµq| ě ∆2 . Also note that fJpµq P rfJpL δ t q, fJpU δt qs. Thus, fJpU δt q ´ fJpLδt q ě |c´ fJpµq| ě ∆2 .\nWe can now prove Theorem 10:\nTheorem 10 (LUCB-micro upper bound) Let\nHpµq “ ÿ\niPrLs\n\"\n1 pc´ µiq2 ľ 1 p∆{2q2\n*\n, and t˚pµq “ mintt P N : 1` 8Hpµqβpt, δ{p2Lqq ď tu .\nThen, for δ ď 0.1, on the event ξ, the stopping time T of LUCB-micro satisfies T ď t˚pµq.\nProof Let τ be a fixed deterministic integer. Now, on ξ,\nminpT, τq ď 1` τ ÿ\nt“1 I tt ă T u\n(a) ď 1`\nτ ÿ t“1 I ! DJ P tBt, Ctu s.t. c P rfJpLδt q, fJpU δt qs and fJpU δt q ´ fJpLδt q ě ∆{2 )\n(b) ď 1`\nτ ÿ t“1 I ! DI P tIt, Jtu s.t. c P rLδt pIq, U δt pIqs and U δt pIq ´ Lδt pIq ě ∆{2 )\nď 1` τ ÿ\nt“1\nÿ\niPrLs I ti P tIt, Jtuu I\n! c P rLδt piq, U δt piqs and U δt piq ´ Lδt piq ě ∆{2 )\n(c) ď 1`\nτ ÿ\nt“1\nÿ\niPrLs I ti P tIt, Jtuu I\n\" Ntpiq ď 8βpNtpiq, δ{p2Lqq ˆ\n1 pc´ µiq2 ^ 1p∆{2q2\n˙*\n(d) ď 1` ÿ\niPrLs\nτ ÿ t“1 I ti P tIt, Jtuu I \" Ntpiq ď 8βpτ, δ{p2Lqq ˆ\n1 pc´ µiq2 ^ 1p∆{2q2\n˙*\nď 1` ÿ\niPrLs 8βpτ, δ{p2Lqq\nˆ\n1 pc´ µiq2 ^ 1p∆{2q2\n˙\n“ 1` 8Hpµqβpτ, δ{p2Lqq .\nHere, (a) holds by the first part of Lemma 9, (b) holds by Assumption 2(ii), (c) holds by the definition of β, (d) holds because βp¨, δ{p2Lqq is increasing. Picking any τ such that 8Hpµqβpτ, δ{p2Lqq ď τ ´ 1, we have minpT, τq ď τ , showing that T ď minpT, τq ď τ ."
    }, {
      "heading" : "E. Proofs for Section 6",
      "text" : "Lemma 12 For any h P H and u, v P r0, 1sL such that u ď v, V ph, uq ď V ph, vq.\nProof We prove the result by induction based on how close a history h is to being a maximal history. As in an earlier proof, for h P H, we let cphq “ 0 if h P Hmax and otherwise we let cphq “ 1 ` maxtcph1q : h1 P Hsuccphqu, where recall that Hsuccphq denotes the set of immediate successors of h P H in H.\nBase case: If cphq “ 0 (i.e., h P Hmax), then V ph, uq “ uτphq ď vτphq “ V ph, vq. Induction step: Assuming that for all the h1 P H with cphq ď c with some c ě 0 it holds that V ph1, uq ď V ph1, vq. Take h P H such that cphq “ c` 1. WLOG assume that pphq “ 1. We have:\nV ph, uq “ V pjoinph,mph, uqq, uq ď V pjoinph,mph, uqq, vq ď V pjoinph,mph, vqq, vq “ V ph, vq ,\nwhere the first and the last equalities are by definition, the first inequality is by the induction hypothesis, and the second inequality is due to the definition of mph, vq.\nLemma 14 Fix u, v P RL, u ď v, and j P rKs. Let h “ MinMaxppjqq and in particular let h “ pm1 “ j,m2, . . . ,m`q. Then, for all 1 ď k ă `,\nrV phk, uq, V phk, vqs Ă rV phk`1, uq, V phk`1, vqs ,\nwhere hk is the length-k prefix of h.\nProof Fix 0 ď k ă ` and u ď v. WLOG assume that ppkq “ 1. By the definition of V ph, µq and mph, µq,\nV ph, vq “ maxtV ph1, vq : h1 P Hsuccphqu “ V pjoinph,mph, vqq, vq .\nHence, by the definition of MinMax and the above identity, V phk, vq “ V phk`1, vq. Further, V phk, uq “ maxtV ph1, uq : h1 P Hsuccphqu ě V phk`1, uq. Thus,\nV phk, vq ď V phk`1, vq and V phk, uq ě V phk`1, uq ,\nfinishing the proof.\nTheorem 17 (LUCBMinMax on MinMax Trees) Let\nHpµq “ ÿ iPrLs mint 1 spanpVpi, µq Y tc, µiuq2 , 4 ∆2 u, t˚pµq “ mintt P N : 1` 8Hpµqβpt, δ{p2Lqq ď tu .\nThen, on ξ, the stopping time T of LUCBMinMax satisfies T ď t˚pµq.\nProof Recall that It “ τpMinMaxpBt, Lδt , U δt qq and Jt “ τpMinMaxpCt, Lδt , U δt qqu. Assume that ξ holds. We prove that VpIt, µq Ă rLδt pItq, U δt pItqs and VpJt, µq Ă rLδt pJtq, U δt pJtqs hold. The rest of the proof is similar to that of Theorem 10.\nConsider It. The proof for Jt works the same way and is hence omitted. If there is multiple path h P H such that τphq “ It, then VpIt, µq “ H Ă rLδt pItq, U δt pItqs. Otherwise, let h P H be the unique path. Since It is pulled, h “ MinMaxpmq for some m P M . Note that Lemma 14 implies that rV phk, Lδt q, V phk, U δt qs Ă rV phk`1, Lδt q, V phk`1, U δt qs. Thus it is sufficient to prove that for 1 ď k ă `, V phk, µq P rV phk, Lδt q, V phk, U δt qs. However, this follows by Lemma 12 and because on the event ξ, Lδt ď µ ď U δt holds.\nNow let Spiq “ Vpi, µqYtc, µiu. Fix t ă T . By the above result and by Lemma 9, for one of J “ Bt or J “ Ct, if I “ MinMaxpJ, Lδt , U δt q then SpIq Ă rLδt pIq, U δt pIqs, which implies\nthat U δt pIq ´ Lδt pIq ě spanpSpIqq. Therefore,\nminpT, τq ď 1` τ ÿ\nt“1 I tt ă T u\nď 1` τ ÿ\nt“1 I ! DI P tIt, Jtu s.t. U δt pIq ´ Lδt pIq ě spanpSpIqq )\nď 1` τ ÿ\nt“1\nÿ\niPrLs I ti P tIt, Jtuu I\n\"\nNtpiq ď 8βpNtpiq, δ{p2Lqq\nspanpSpiqq2\n*\nď 1` ÿ\niPrLs\nτ ÿ t“1 I ti P tIt, Jtuu I \" Ntpiq ď 8βpτ, δ{p2Lqq spanpSpiqq2 *\nď 1` ÿ\niPrLs\n8βpτ, δ{p2Lqq spanpSpiqq2 “ 1` 8Hpµqβpτ, δ{p2Lqq"
    } ],
    "references" : [ {
      "title" : "Searching for Solutions in Games and Artificial Intelligence",
      "author" : [ "L. Victor Allis" ],
      "venue" : "PhD thesis, Maastricht University,",
      "citeRegEx" : "Allis.,? \\Q1994\\E",
      "shortCiteRegEx" : "Allis.",
      "year" : 1994
    }, {
      "title" : "Best arm identification in multi-armed bandits",
      "author" : [ "Jean-Yves Audibert", "Sébastien Bubeck" ],
      "venue" : "In 23rd Annual Conference on Learning Theory, COLT 2010, pages 13–p,",
      "citeRegEx" : "Audibert and Bubeck.,? \\Q2010\\E",
      "shortCiteRegEx" : "Audibert and Bubeck.",
      "year" : 2010
    }, {
      "title" : "The nonstochastic multiarmed bandit problem",
      "author" : [ "Peter Auer", "Nicolò Cesa-Bianchi", "Yoav Freund", "Robert E. Schapire" ],
      "venue" : "SIAM Journal of Computing,",
      "citeRegEx" : "Auer et al\\.,? \\Q2002\\E",
      "shortCiteRegEx" : "Auer et al\\.",
      "year" : 2002
    }, {
      "title" : "On the optimal sample complexity for best arm identification",
      "author" : [ "Lijie Chen", "Jian Li" ],
      "venue" : "arXiv preprint arXiv:1511.03774,",
      "citeRegEx" : "Chen and Li.,? \\Q2015\\E",
      "shortCiteRegEx" : "Chen and Li.",
      "year" : 2015
    }, {
      "title" : "Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems",
      "author" : [ "Eyal Even-Dar", "Shie Mannor", "Yishay Mansour" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Even.Dar et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Even.Dar et al\\.",
      "year" : 2006
    }, {
      "title" : "Best arm identification: A unified approach to fixed budget and fixed confidence",
      "author" : [ "Victor Gabillon", "Mohammad Ghavamzadeh", "Alessandro Lazaric" ],
      "venue" : "In 26th Annual Conference on Neural Information Processing Systems,",
      "citeRegEx" : "Gabillon et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Gabillon et al\\.",
      "year" : 2016
    }, {
      "title" : "Optimal best arm identification with fixed confidence",
      "author" : [ "Aurélien Garivier", "Emilie Kaufmann" ],
      "venue" : "In COLT,",
      "citeRegEx" : "Garivier and Kaufmann.,? \\Q2016\\E",
      "shortCiteRegEx" : "Garivier and Kaufmann.",
      "year" : 2016
    }, {
      "title" : "Maximin action identification: A new bandit framework for games",
      "author" : [ "Aurélien Garivier", "Emilie Kaufmann", "Wouter M. Koolen" ],
      "venue" : "In 29th Annual Conference on Learning Theory, COLT",
      "citeRegEx" : "Garivier et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Garivier et al\\.",
      "year" : 2016
    }, {
      "title" : "On explore-then-commit strategies",
      "author" : [ "Aurélien Garivier", "Emilie Kaufmann", "Tor Lattimore" ],
      "venue" : "arXiv preprint arXiv:1605.08988,",
      "citeRegEx" : "Garivier et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Garivier et al\\.",
      "year" : 2016
    }, {
      "title" : "The grand challenge of computer Go: Monte Carlo tree search and extensions",
      "author" : [ "Sylvain Gelly", "Levente Kocsis", "Marc Schoenauer", "Michèle Sebag", "David Silver", "Csaba Szepesvári", "Olivier Teytaud" ],
      "venue" : "Communications of ACM,",
      "citeRegEx" : "Gelly et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gelly et al\\.",
      "year" : 2012
    }, {
      "title" : "Best-arm identification algorithms for multi-armed bandits in the fixed confidence setting",
      "author" : [ "Kevin Jamieson", "Robert Nowak" ],
      "venue" : "In Information Sciences and Systems (CISS),",
      "citeRegEx" : "Jamieson and Nowak.,? \\Q2014\\E",
      "shortCiteRegEx" : "Jamieson and Nowak.",
      "year" : 2014
    }, {
      "title" : "lil’UCB: An optimal exploration algorithm for multi-armed bandits",
      "author" : [ "Kevin G. Jamieson", "Matthew Malloy", "Robert D. Nowak", "Sébastien Bubeck" ],
      "venue" : "In 27th Annual Conference on Learning Theory,",
      "citeRegEx" : "Jamieson et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Jamieson et al\\.",
      "year" : 2014
    }, {
      "title" : "PAC subset selection in stochastic multi-armed bandits",
      "author" : [ "Shivaram Kalyanakrishnan", "Ambuj Tewari", "Peter Auer", "Peter Stone" ],
      "venue" : "In Proceedings of the 29th International Conference on Machine Learning,",
      "citeRegEx" : "Kalyanakrishnan et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kalyanakrishnan et al\\.",
      "year" : 2012
    }, {
      "title" : "Almost optimal exploration in multiarmed bandits",
      "author" : [ "Zohar Shay Karnin", "Tomer Koren", "Oren Somekh" ],
      "venue" : "In Proceedings of The 30th International Conference on Machine Learning,",
      "citeRegEx" : "Karnin et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Karnin et al\\.",
      "year" : 2013
    }, {
      "title" : "On the complexity of best-arm identification in multi-armed bandit models",
      "author" : [ "Emilie Kaufmann", "Olivier Cappé", "Aurélien Garivier" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Kaufmann et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Kaufmann et al\\.",
      "year" : 2016
    }, {
      "title" : "Gametree search using proof numbers: The first twenty years",
      "author" : [ "Akihiro Kishimoto", "Mark H.M. Winands", "Martin Müller", "Jahn-Takeshi Saito" ],
      "venue" : "ICGA Journal,",
      "citeRegEx" : "Kishimoto et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kishimoto et al\\.",
      "year" : 2012
    }, {
      "title" : "Conspiracy numbers for min-max search",
      "author" : [ "David Allen McAllester" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "McAllester.,? \\Q1988\\E",
      "shortCiteRegEx" : "McAllester.",
      "year" : 1988
    }, {
      "title" : "Artificial Intelligence: A Modern Approach. Pearson Education, Inc",
      "author" : [ "Stuart J. Russell", "Peter Norvig" ],
      "venue" : "Upper Saddle River, New Jersey,",
      "citeRegEx" : "Russell and Norvig.,? \\Q2010\\E",
      "shortCiteRegEx" : "Russell and Norvig.",
      "year" : 2010
    }, {
      "title" : "The simulator: Understanding adaptive sampling in the moderate-confidence regime",
      "author" : [ "Max Simchowitz", "Kevin G. Jamieson", "Benjamin Recht" ],
      "venue" : null,
      "citeRegEx" : "Simchowitz et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Simchowitz et al\\.",
      "year" : 2017
    }, {
      "title" : "Efficient sampling method for monte carlo tree search problem",
      "author" : [ "Kazuki Teraoka", "Kohei Hatano", "Eiji Takimoto" ],
      "venue" : "IEICE TRANSACTIONS on Information and Systems,",
      "citeRegEx" : "Teraoka et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Teraoka et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).",
      "startOffset" : 2,
      "endOffset" : 168
    }, {
      "referenceID" : 1,
      "context" : ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).",
      "startOffset" : 2,
      "endOffset" : 168
    }, {
      "referenceID" : 12,
      "context" : ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).",
      "startOffset" : 2,
      "endOffset" : 168
    }, {
      "referenceID" : 13,
      "context" : ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).",
      "startOffset" : 2,
      "endOffset" : 168
    }, {
      "referenceID" : 11,
      "context" : ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).",
      "startOffset" : 2,
      "endOffset" : 168
    }, {
      "referenceID" : 3,
      "context" : ", (Even-Dar et al., 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015).",
      "startOffset" : 2,
      "endOffset" : 168
    }, {
      "referenceID" : 1,
      "context" : ", 2006; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Karnin et al., 2013; Jamieson et al., 2014; Chen and Li, 2015). Recently, Garivier et al. (2016a) considered the motivating problem mentioned above.",
      "startOffset" : 8,
      "endOffset" : 186
    }, {
      "referenceID" : 16,
      "context" : "This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988).",
      "startOffset" : 220,
      "endOffset" : 238
    }, {
      "referenceID" : 6,
      "context" : "Our main interest in this paper is to see whether the ideas of Garivier et al. (2016a) extend to more general settings, such as when the depth can be non-uniform and is in particular not limited to two, or when the move histories can lead to shared states (that is, in the language of adversarial search we allow “transpositions”).",
      "startOffset" : 63,
      "endOffset" : 87
    }, {
      "referenceID" : 2,
      "context" : "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al.",
      "startOffset" : 111,
      "endOffset" : 130
    }, {
      "referenceID" : 2,
      "context" : "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time).",
      "startOffset" : 111,
      "endOffset" : 157
    }, {
      "referenceID" : 2,
      "context" : "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems.",
      "startOffset" : 111,
      "endOffset" : 645
    }, {
      "referenceID" : 2,
      "context" : "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems. Considering again the abstract setting, we propose a new algorithm, which we call LUCB-micro (Section 5), and which can be considered as a natural generalization of Maximin-LUCB of Garivier et al. (2016a) (with some minor differences).",
      "startOffset" : 111,
      "endOffset" : 896
    }, {
      "referenceID" : 2,
      "context" : "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems. Considering again the abstract setting, we propose a new algorithm, which we call LUCB-micro (Section 5), and which can be considered as a natural generalization of Maximin-LUCB of Garivier et al. (2016a) (with some minor differences). Under a regularity assumption on the payoff maps, we prove that the algorithm meets the risk-requirement. We also provide a high-probability, instance-dependent upper bound on algorithm’s sample complexity (i.e., on the number of observations the algorithm takes). As we discuss, while this bound meets the general characteristics of existing bounds, it fails to reproduce the corresponding result of Garivier et al. (2016a). To the best of authors’ knowledge, the only comparable algorithm to study best arm identification in a full-length minimax tree search setting (which was the motivating example of our work) is FindTopWinner by Teraoka et al.",
      "startOffset" : 111,
      "endOffset" : 1352
    }, {
      "referenceID" : 2,
      "context" : "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems. Considering again the abstract setting, we propose a new algorithm, which we call LUCB-micro (Section 5), and which can be considered as a natural generalization of Maximin-LUCB of Garivier et al. (2016a) (with some minor differences). Under a regularity assumption on the payoff maps, we prove that the algorithm meets the risk-requirement. We also provide a high-probability, instance-dependent upper bound on algorithm’s sample complexity (i.e., on the number of observations the algorithm takes). As we discuss, while this bound meets the general characteristics of existing bounds, it fails to reproduce the corresponding result of Garivier et al. (2016a). To the best of authors’ knowledge, the only comparable algorithm to study best arm identification in a full-length minimax tree search setting (which was the motivating example of our work) is FindTopWinner by Teraoka et al. (2014). This algorithm is a roundbased elimination based algorithm with additional pruning steps that come from the tree structure.",
      "startOffset" : 111,
      "endOffset" : 1585
    }, {
      "referenceID" : 2,
      "context" : "For the general structured setting, in Section 3 we prove an instance dependent lower bound along the lines of Auer et al. (2002) or Garivier et al. (2016b) (a mild novelty is the way our proof deals with the technical issue that best arm identification algorithms ideally stop and hence their behavior is undefined after the random stopping time). This is then specialized to the minimax game search setting (Section 4), where we show the crucial role of what we call proof sets, which are somewhat reminiscent of the so-called conspiracy sets from adversarial search (McAllester, 1988). Our lower bound matches that of Garivier et al. (2016a) in the case of two-move alternating problems. Considering again the abstract setting, we propose a new algorithm, which we call LUCB-micro (Section 5), and which can be considered as a natural generalization of Maximin-LUCB of Garivier et al. (2016a) (with some minor differences). Under a regularity assumption on the payoff maps, we prove that the algorithm meets the risk-requirement. We also provide a high-probability, instance-dependent upper bound on algorithm’s sample complexity (i.e., on the number of observations the algorithm takes). As we discuss, while this bound meets the general characteristics of existing bounds, it fails to reproduce the corresponding result of Garivier et al. (2016a). To the best of authors’ knowledge, the only comparable algorithm to study best arm identification in a full-length minimax tree search setting (which was the motivating example of our work) is FindTopWinner by Teraoka et al. (2014). This algorithm is a roundbased elimination based algorithm with additional pruning steps that come from the tree structure. When we specialize our framework to the minimax game scenario (and implement other necessary changes to put our work into their ( , δq-PAC setting), our upper bound is a strict improvement of theirs, e.g., in the number of samples related to the near-optimal micro-observables (leaves of the minimax game tree). Next, we consider the minimax setting (Section 6). First, we show that the regularity assumptions made for the abstract setting are met in this case. We also show how to efficiently compute the choices that LUCB-micro makes using a “min-max” algorithm. Finally, we strengthen our previous result so that it is able to reproduce the mentioned result of Garivier et al. (2016a).",
      "startOffset" : 111,
      "endOffset" : 2398
    }, {
      "referenceID" : 7,
      "context" : "As explained by Garivier et al. (2016a), the setting may also shed light on how to design better Monte-Carlo Tree Search (MCTS) algorithms, which is a relatively novel class of search algorithms that proved to be highly successful in recent years (e.",
      "startOffset" : 16,
      "endOffset" : 40
    }, {
      "referenceID" : 14,
      "context" : "The proof uses standard steps (e.g., Auer et al., 2002; Kaufmann et al., 2016) and one of its main merit is its simplicity.",
      "startOffset" : 30,
      "endOffset" : 78
    }, {
      "referenceID" : 5,
      "context" : "The proof can be shown to reproduce the result of Garivier and Kaufmann (2016) (see page 6 of their paper) when the setting is best arm identification.",
      "startOffset" : 50,
      "endOffset" : 79
    }, {
      "referenceID" : 16,
      "context" : "Proof sets are closely related to conspiracy sets (McAllester, 1988), forming the basis of “proof number of search” (Allis, 1994; Kishimoto et al.",
      "startOffset" : 50,
      "endOffset" : 68
    }, {
      "referenceID" : 0,
      "context" : "Proof sets are closely related to conspiracy sets (McAllester, 1988), forming the basis of “proof number of search” (Allis, 1994; Kishimoto et al., 2012).",
      "startOffset" : 116,
      "endOffset" : 153
    }, {
      "referenceID" : 15,
      "context" : "Proof sets are closely related to conspiracy sets (McAllester, 1988), forming the basis of “proof number of search” (Allis, 1994; Kishimoto et al., 2012).",
      "startOffset" : 116,
      "endOffset" : 153
    }, {
      "referenceID" : 17,
      "context" : "Proof sets are also related to cuts in α–β search (Russell and Norvig, 2010).",
      "startOffset" : 50,
      "endOffset" : 76
    }, {
      "referenceID" : 10,
      "context" : "Upper bound In this section we propose an algorithm generalizing the LUCB algorithm of Kalyanakrishnan et al. (2012) and prove a theoretical guarantee for the proposed algorithm’s sample complexity under some (mild) assumptions on the structure of the reward mapping f .",
      "startOffset" : 87,
      "endOffset" : 117
    }, {
      "referenceID" : 7,
      "context" : "Our result is inspired and extends the results of Garivier et al. (2016a) (who also started from the LUCB algorithm) to the general setting proposed in this paper.",
      "startOffset" : 50,
      "endOffset" : 74
    }, {
      "referenceID" : 14,
      "context" : "This result appears as (essentially) Theorem 8 in the paper by Kaufmann et al. (2016) who also cite precursors: Lemma 7 (Anytime subgaussian concentration) Let pXtqtPN be an pFtqtPN-adapted 1subgaussian, martingale difference sequence (i.",
      "startOffset" : 63,
      "endOffset" : 86
    }, {
      "referenceID" : 7,
      "context" : "This can be seen as a generalization of the choice made in Maximin-LUCB by Garivier et al. (2016a). Here, we found that the specific way Maximin-LUCB’s choice is made considerably obscured the idea behind this choice, which one can perhaps attribute to that the fact that the two-move setting makes it possible to write the choice in a more-or-less direct fashion.",
      "startOffset" : 75,
      "endOffset" : 99
    }, {
      "referenceID" : 12,
      "context" : "Compared to state-of-the-art results available for this setting, our bound is looser in several ways: We lose on the constant factor multiplying Hpμq (Kalyanakrishnan et al., 2012; Jamieson and Nowak, 2014; Jamieson et al., 2014; Kaufmann et al., 2016), we also lose an additive term of Hpμq log logpLq (Chen and Li, 2015).",
      "startOffset" : 150,
      "endOffset" : 252
    }, {
      "referenceID" : 10,
      "context" : "Compared to state-of-the-art results available for this setting, our bound is looser in several ways: We lose on the constant factor multiplying Hpμq (Kalyanakrishnan et al., 2012; Jamieson and Nowak, 2014; Jamieson et al., 2014; Kaufmann et al., 2016), we also lose an additive term of Hpμq log logpLq (Chen and Li, 2015).",
      "startOffset" : 150,
      "endOffset" : 252
    }, {
      "referenceID" : 11,
      "context" : "Compared to state-of-the-art results available for this setting, our bound is looser in several ways: We lose on the constant factor multiplying Hpμq (Kalyanakrishnan et al., 2012; Jamieson and Nowak, 2014; Jamieson et al., 2014; Kaufmann et al., 2016), we also lose an additive term of Hpμq log logpLq (Chen and Li, 2015).",
      "startOffset" : 150,
      "endOffset" : 252
    }, {
      "referenceID" : 14,
      "context" : "Compared to state-of-the-art results available for this setting, our bound is looser in several ways: We lose on the constant factor multiplying Hpμq (Kalyanakrishnan et al., 2012; Jamieson and Nowak, 2014; Jamieson et al., 2014; Kaufmann et al., 2016), we also lose an additive term of Hpμq log logpLq (Chen and Li, 2015).",
      "startOffset" : 150,
      "endOffset" : 252
    }, {
      "referenceID" : 3,
      "context" : ", 2016), we also lose an additive term of Hpμq log logpLq (Chen and Li, 2015).",
      "startOffset" : 58,
      "endOffset" : 77
    }, {
      "referenceID" : 18,
      "context" : "We also lose logpLq terms on the suboptimal arms (Simchowitz et al., 2017).",
      "startOffset" : 49,
      "endOffset" : 74
    }, {
      "referenceID" : 3,
      "context" : ", 2016), we also lose an additive term of Hpμq log logpLq (Chen and Li, 2015). We also lose logpLq terms on the suboptimal arms (Simchowitz et al., 2017). Comparing with the only result available in the two-move minimax tree setting, due to Garivier et al. (2016a), our bound is looser than their Theorem 1.",
      "startOffset" : 59,
      "endOffset" : 265
    }, {
      "referenceID" : 3,
      "context" : ", 2016), we also lose an additive term of Hpμq log logpLq (Chen and Li, 2015). We also lose logpLq terms on the suboptimal arms (Simchowitz et al., 2017). Comparing with the only result available in the two-move minimax tree setting, due to Garivier et al. (2016a), our bound is looser than their Theorem 1. This motivates the refinement of this result to the minimax setting, which is done in the next section, and where we recover the mentioned result of Garivier et al. (2016a). On the positive side, our result is more generally applicable than any of the mentioned results.",
      "startOffset" : 59,
      "endOffset" : 481
    }, {
      "referenceID" : 7,
      "context" : "Remark 18 Note that this result recovers Theorem 1 of Garivier et al. (2016a). To see this note that for every leaf pi, jq (as numbered in their paper), μi,1 P Vppi, jq, μq.",
      "startOffset" : 54,
      "endOffset" : 78
    }, {
      "referenceID" : 18,
      "context" : "Simchowitz et al. (2017) introduces an interesting technique for proving lower bounds of this form and they demonstrate nontrivial improvements in the multi-armed bandit setting.",
      "startOffset" : 0,
      "endOffset" : 25
    } ],
    "year" : 2017,
    "abstractText" : "We study the problem of identifying the best action among a set of possible options when the value of each action is given by a mapping from a number of noisy micro-observables in the so-called fixed confidence setting. Our main motivation is the application to the minimax game search, which has been a major topic of interest in artificial intelligence. In this paper we introduce an abstract setting to clearly describe the essential properties of the problem. While previous work only considered a two-move game tree search problem, our abstract setting can be applied to the general minimax games where the depth can be non-uniform and arbitrary, and transpositions are allowed. We introduce a new algorithm (LUCB-micro) for the abstract setting, and give its lower and upper sample complexity results. Our bounds recover some previous results, which were only available in more limited settings, while they also shed further light on how the structure of minimax problems influence sample complexity.",
    "creator" : "LaTeX with hyperref package"
  }
}