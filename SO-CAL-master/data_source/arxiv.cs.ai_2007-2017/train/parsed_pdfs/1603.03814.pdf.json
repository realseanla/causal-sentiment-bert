{
  "name" : "1603.03814.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Solving MaxSAT by Successive Calls to a SAT Solver",
    "authors" : [ "Mohamed El Halaby" ],
    "emails" : [ "halaby@sci.cu.edu.eg" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 3.\n03 81\n4v 1\n[ cs\n.A I]\n1 1\nM ar\n2 01\nContents"
    }, {
      "heading" : "1 Introduction and Preliminaries 4",
      "text" : ""
    }, {
      "heading" : "2 Linear Search Algorithms 5",
      "text" : ""
    }, {
      "heading" : "3 Binary Search-based Algorithms 7",
      "text" : ""
    }, {
      "heading" : "4 Core-guided Algorithms 12",
      "text" : "4.1 Fu and Malik’s algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 4.2 WPM1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 4.3 Improved WPM1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 4.4 WPM2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 4.5 WMSU1-ROR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 4.6 WMSU3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 4.7 WMSU4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25"
    }, {
      "heading" : "5 Core-guided Binary Search Algorithms 26",
      "text" : ""
    }, {
      "heading" : "6 Portfolio MaxSAT Techniques 31",
      "text" : ""
    }, {
      "heading" : "7 Translating Pseudo-Boolean Constraints into CNF 31",
      "text" : "7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 7.2 Encoding method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 7.3 Complexity of the encoding . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n7.3.1 Polynomial cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 7.3.2 Exponential cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n7.4 Other encoding techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34"
    }, {
      "heading" : "8 Experimental Investigation 35",
      "text" : "8.1 Solvers descriptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 8.2 Benchmarks descriptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 8.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n8.3.1 Random category . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 8.3.2 Crafted category . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 8.3.3 Industrial category . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n9 Acknowledgments 42\nList of Algorithms\n1 LinearUNSAT(φ) Linear search UNSAT-based algorithm for solving WPMaxSAT. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2 LinearSAT(φ) Linear search SAT-based algorithm for solving WPMaxSAT. . 6 3 BinS-WPMaxSAT(φ) Binary search based algorithm for solving WPMaxSAT. 8 4 BinLin-WPMaxSAT(φ) Alternating binary and linear searches for solving WPMaxSAT. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 5 BitBased-WPMaxSAT(φ) A bit-based algorithm for solving WPMaxSAT. . . 11 6 Fu&Malik(φ) Fu and Malik’s algorithm for solving PMaxSAT. . . . . . . . . 13 7 WPM1(φ) The WPM1 algorithm for WPMaxSAT. . . . . . . . . . . . . . . . 14 8 ImprovedWPM1(φ) The stratified approach for WPM1 algorithm. . . . . . . 16 9 WPM2(φ) The WPM2 algorithm for WPMaxSAT . . . . . . . . . . . . . . . 18 10 NewBound(AL,B) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 11 WMSU1-ROR(φ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 12 Hard((Ci, wi), R) Determines if a clause is hard or not . . . . . . . . . . . . . 23 13 ROR((Ci, wi), R) Determines if a clause is hard or not or if its ancestors are used at most once . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 14 WMSU3(φ) The WMSU3 algorithm for WPMaxSAT. . . . . . . . . . . . . . 24 15 WMSU4(φ) The WMSU4 algorithm for WPMaxSAT. . . . . . . . . . . . . . 25 16 CoreGuided-BS(φ) Core-guided binary search algorithm for solving WPMaxSAT. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 17 DisjointCoreGuided-BS(φ) Core-guided binary search extended with disjoint\ncores for solving WPMaxSAT. . . . . . . . . . . . . . . . . . . . . . . . . . . 29"
    }, {
      "heading" : "1 Introduction and Preliminaries",
      "text" : "A Boolean variable x can take one of two possible values 0 (false) or 1 (true). A literal l is a variable x or its negation ¬x. A clause is a disjunction of literals, i.e., ∨n i=1 li. A CNF formula is a conjunction of clauses. Formally, a CNF formula φ composed of k clauses, where each clause Ci is composed of mi is defined as F = ∧k i=1 Ci where Ci = ∨mi j=1 li,j .\nIn this paper, a set of clauses {C1, C2, . . . , Ck} is referred to as a Boolean formula. A truth assignment satisfies a Boolean formula if it satisfies every clause.\nGiven a CNF formula φ, the satisfiability problem (SAT) is deciding whether φ has a satisfying truth assignment (i.e., an assignment to the variables of φ that satisfies every clause). The Maximum Satisfiability (MaxSAT) problem asks for a truth assignment that maximizes the number of satisfied clauses in φ.\nMany theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].\nLet φ = {(C1, w2), . . . , (Cs, ws)} ∪ {(Cs+1,∞), . . . , (Cs+h,∞)} be a CNF formula, where w1, . . . , ws are natural numbers. The Weighted Partial MaxSAT problem asks for an assignment that satisfies all Cs+1, . . . , Cs+h (called hard clauses) and maximizes the sum of the weights of the satisfied clauses in C1, . . . , Cs (called soft clauses).\nIn general, exact MaxSAT solvers follow one of two approaches: successively calling a SAT solver (sometimes called the SAT-based approach) and the branch and bound approach. The former converts each MaxSAT problem with different hypothesized maximum weights into multiple SAT problems and uses a SAT solver to solve these SAT problems to determine the actual solution. The SAT-based approach converts the WPMaxSAT problem into a sequence of SAT instances which can be solved using SAT solvers. One way to do this, given an unweighted MaxSAT instance, is to check if there is an assignment that falsifies no clauses. If such an assignment can not be found, we check if there is an assignment that falsifies only one clause. This is repeated and each time we increment the number of clauses that are allowed to be False until the SAT solver returns True, meaning that the minimum number of falsified clauses has been determined. Recent comprehensive surveys on SAT-based algorithms can be found in[43, 8].\nThe second approach utilizes a depth-first branch and bound search in the space of possible assignments. An evaluation function which computes a bound is applied at each search node to determine any pruning opportunity. This paper surveys the satisfiabilitybased approach and provides an experimental investigation and comparison between the performances of both approaches on sets of benchmarks.\nBecause of the numerous calls to a SAT solver this approach makes, any improvement to SAT algorithms immediately benefits MaxSAT SAT-based methods. Experimental results from the MaxSAT Evaluations1 have shown that SAT-based solvers are more competent to handle large MaxSAT instances from industrial applications than branch and bound methods.\n1Web page: http://www.maxsat.udl.cat"
    }, {
      "heading" : "2 Linear Search Algorithms",
      "text" : "A simple way to solve WPMaxSAT is to augment each soft clause Ci with a new variable (called a blocking variable) bi, then a constraint is added (specified in CNF) saying that the sum of the weights of the falsified soft clauses must be less than a given value k. Next, the formula (without the weights) together with the constraint is sent to a SAT solver to check whether or not it is satisfiable. If so, then the cost of the optimal solution is found and the algorithm terminates. Otherwise, k is decreased and the process continues until the SAT solver returns True. The algorithm can start searching for the optimal cost\nfrom a lower bound LB initialized with the maximum possible cost (i.e. LB = ∑|φS | i=1 wi) and decrease it down to the optimal cost, or it can set LB = 0 and increase it up to the optimal cost. Solvers that employ the former approach is called satisfiability-based (not to be confused with the name of the general method) solvers, while the ones that follow the latter are called UNSAT-based solvers. A cost of 0 means all the soft clauses are satisfied and a cost of means all the soft clauses are falsified.\nAlgorithm 1 employs the first method to search for the optimal cost by maintaining (maintaining a lower bound initialized to 0) (line 1).\nAlgorithm 1: LinearUNSAT(φ) Linear search UNSAT-based algorithm for solving WPMaxSAT. Input: A WPMaxSAT instance φ = φS ∪ φH Output: A WPMaxSAT solution to φ\n1 LB ← 0 2 foreach (Ci, wi) ∈ φS do 3 let bi be a new blocking variable 4 φS ← φS \\ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)} 5 while True do\n6 (state, I)← SAT ({C | (C,w) ∈ φ} ∪ CNF ( ∑|φS | i=1 wibi ≤ LB)) 7 if state = True then 8 return I\n9 LB ← UpdateBound({w | (C,w) ∈ φS}, LB)\nNext, the algorithm relaxes each soft clause with a new variable in lines 2-4. The formula φ now contains each soft clause augmented with a new blocking variable. The while loop in lines 5-9 sends the clauses of φ (without the weights) to a SAT solver (line 6). If the SAT solver returns True, then LinearUNSAT terminates returning a solution (lines 7-8). Otherwise, the lower bound is updated and the loop continues until the SAT solver returns True. The function UpdateBound in line 9 updates the lower bound either by simply increasing it or by other means that depend on the distribution of the weights of the input formula. Later in this paper we will see how the subset sum problem can be a possible implementation of UpdateBound. Note that it could be inefficient if UpdateBound changes LB by one in each iteration. Consider a WPMaxSAT formula with five soft clauses having the weights 1, 1, 1, 1 and 100. The cost of the optimal solution can not be anything else other than 0, 1, 2, 3, 4, 100, 101, 102, 103 and 104. Thus, assigning LB any of the values 5, . . . , 99 is unnecessary and will result in a large number of iterations.\nExample 2.1. Let φ = φS ∪ φH , where φS = {(x1, 5), (x2, 5), (x3, 10), (x4, 5), (x5, 10), (x6, 5), (¬x6, 10)} and φH = {¬x1 ∨ ¬x2,∞), (¬x2 ∨ ¬x3,∞), (¬x3 ∨ ¬x4,∞), (¬x4 ∨¬x5,∞), (¬x5 ∨¬x1,∞)}. If we run LinearUNSAT on φ, the soft clauses will be be relaxed {(x1 ∨ b1, 5), (x2 ∨ b2, 5), (x3 ∨ b3, 10), (x4 ∨ b4, 5), (x5 ∨ b5, 10), (x6 ∨ b6, 5), (¬x6 ∨ b7, 10)} and LB is initialized to 0. The sequence of iterations are\n1. The constraint CNF (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 0) is included, state = False, LB = 5.\n2. The constraint CNF (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 5) is included, state = False, LB = 10.\n3. The constraint CNF (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 10) is included, state = False, LB = 15.\n4. The constraint CNF (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 15) is included, state = False, LB = 20.\n5. The constraint CNF (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 20) is included, state = True. The SAT solver returns the assignment I = {x1 = False, x2 = False, x3 = True, x4 = False, x5 = True, x6 = False, b1 = True, b2 = True, b3 = False, b4 = True, b5 = False, b6 = True, b7 = False}, which leads to a WPMaxSAT solution if we ignore the values of the bi, (1 ≤ i ≤ 7) variables with cost 20.\nThe next algorithm is describes the SAT-based technique. Algorithm 2 starts by initializing the upper bound to one plus the the sum of the weights of the soft clauses (line 1).\nAlgorithm 2: LinearSAT(φ) Linear search SAT-based algorithm for solving WPMaxSAT. Input: A WPMaxSAT instance φ = φS ∪ φH Output: A WPMaxSAT solution to φ\n1 UB ← 1 + ∑|φS | i=1 wi 2 foreach (Ci, wi) ∈ φS do 3 let bi be a new blocking variable φS ← φS \\ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)} 4 while True do\n5 (state, I)← SAT ({C | (C,w) ∈ φ} ∪ CNF ( ∑|φS | i=1 wibi ≤ UB − 1)) 6 if state = False then 7 return lastI\n8 lastI ← I 9 UB ← ∑|φS | i=1 wi(1− I(Ci \\ {bi}))\nIn each iteration of algorithm 2 except the last, the formula is satisfiable. The cost of the optimal solution is found immediately after the transition from satisfiable to unsatisfiable instance. LinearSAT begins by initializing the upper bound to one plus the sum of the weights of the soft clauses (line 1). The while loop (lines 4-8) continues until the formula becomes unsatisfiable (line 6), then the algorithm returns a WPMaxSAT solution and terminates (line 7). As long as the formula is satisfiable, the formula is sent to the SAT\nsolver along with the constraint assuring that the sum of the weights of the falsified soft clauses is less than UB − 1 (line 5), and the upper bound is updated to the sum of the weights of the soft clauses falsified by the assignment returned by the SAT solver (line 8).\nNote that updating the upper bound to ∑|φS | i=1 wi(1 − I(Ci \\ {bi})) is more efficient than simply decreasing the upper bound by one, because uses less iterations and thus the problem is solved with less SAT calls.\nExample 2.2. If we run LinearSAT on φ from the previous example, the soft clauses will be be relaxed {(x1∨b1, 5), (x2∨b2, 5), (x3∨b3, 10), (x4∨b4, 5), (x5∨b5, 10), (x6∨b6, 5), (¬x6∨ b7, 10)} and UB is initialized to 1 + (5 + 5 + 5 + 5 + 10 + 10 + 10) = 51. The sequence of iterations are\n1. The constraint CNF (5b1+5b2+10b3+5b4+10b5+5b6+10b7 ≤ 50) is included, state = True, I = {x1 = False, x2 = False, x3 = False, x4 = False, x5 = False, x6 = False, b1 = True, b2 = True, b3 = True, b4 = True, b5 = True, b6 = True, b7 = False}, UB = 5 + 5 + 10 + 5 + 10 + 5 = 40.\n2. The constraint CNF (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 40 − 1) is included, state = True, I = {x1 = False, x2 = False, x3 = False, x4 = False, x5 = True, x6 = False, b1 = True, b2 = True, b3 = True, b4 = True, b5 = False, b6 = True, b7 = False}, UB = 5 + 5 + 10 + 5 + 5 = 30.\n3. The constraint CNF (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 30 − 1) is included, state = True, I = {x1 = False, x2 = False, x3 = True, x4 = False, x5 = True, x6 = False, b1 = True, b2 = True, b3 = False, b4 = True, b5 = False, b6 = True, b7 = False}, UB = 5 + 5 + 5 + 5 = 20.\n4. The constraint CNF (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 20−1) is included, state = False. The assignment from the previous step is indeed a solution to φ if we ignore the values of the bi, (1 ≤ i ≤ 7) variables with cost 20."
    }, {
      "heading" : "3 Binary Search-based Algorithms",
      "text" : "The number of iterations linear search algorithms for WPMaxSAT can take is linear in the sum of the weights of the soft clauses. Thus, in the worst case the a linear search\nWPMaxSAT algorithm can take ∑|φS | i=1 wi calls to the SAT solver. Since we are searching\nfor a value (the optimal cost) among a set of values (from 0 to ∑|φS | i=1 wi), then binary search can be used, which uses less iterations than linear search. Algorithm 3 searches for the cost of the optimal assignment by using binary search.\nAlgorithm 3: BinS-WPMaxSAT(φ) Binary search based algorithm for solving WPMaxSAT. Input: A WPMaxSAT instance φ = φS ∪ φH Output: A WPMaxSAT solution to φ\n1 state← SAT ({Ci | (Ci,∞) ∈ φH}) 2 if state = False then 3 return ∅ 4 LB ← −1 5 UB ← 1 + ∑|φS | i=1 wi 6 foreach (Ci, wi) ∈ φS do 7 let bi be a new blocking variable 8 φS ← φS \\ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)} 9 while LB + 1 < UB do\n10 mid← bLB+UB 2 c 11 (state, I)← SAT ({C | (C,w) ∈ φ} ∪ CNF ( ∑|φS | i=1 wibi ≤ mid)) 12 if state = True then 13 lastI ← I 14 UB ← ∑|φS | i=1 wi(1− I(Ci \\ {bi}))\n15 else 16 LB ← UpdateBound({wi | 1 ≤ i ≤ |φS |},mid)− 1\n17 return lastI\nBinS-WPMaxSAT begins by checking the satisfiability of the hard clauses (line 1) before beginning the search for the solution. If the SAT solver returns False (line 2), BinS-WPMaxSAT returns the empty assignment and terminates (line 3). The algorithm updates both a lower bound LB and an upper bound UB initialized respectively to -1 and one plus the sum of the weights of the soft clauses (lines 4-5). The soft clauses are augmented with blocking variables (lines 6-8). At each iteration of the main loop (lines 9-16), the middle value (mid) is changed to the average of LB and UB and a constraint is added requiring the sum of the weights of the relaxed soft clauses to be less than or equal to the middle value. This clauses describing this constraint are sent to the SAT solver along with the clauses of φ (line 11). If the SAT solver returns True (line 12), then the cost of the optimal solution is less than mid, and UB is updated (line 14). Otherwise, the algorithm looks for the optimal cost above mid, and so LB is updated (line 16). The main loop continues until LB + 1 = UB, and the number of iterations BinS-WPMaxSAT\nexecutes is proportional to log( ∑|φS | i=1 wi) which is a considerably lower complexity than that of linear search methods. In the following example, UpdateBound assigns mid+ 1 to LB.\nExample 3.1. Consider φ in example 2.1 with all the weights of the soft clauses set to 1. At the beginning, LB = −1, UB = 8. The following are the sequence of iterations algorithm 3 executes.\n1. mid = b 8+(−1)2 c = 3, the constraint CNF (b1 + b2 + b3 + b4 + b5 + b6 + b7 ≤ 3) is included, state = False, LB = 3, UB = 8.\n2. mid = b 8+32 c = 5, the constraint CNF (b1 + b2 + b3 + b4 + b5 + b6 + b7 ≤ 5) is\nincluded, state = True, I = {x1 = False, x2 = False, x3 = True, x4 = False, x5 = True, x6 = False, b1 = True, b2 = True, b3 = False, b4 = True, b5 = False, b6 = True, b7 = False}, UB = 4, LB = 3. The assignment I is indeed an optimal one, falsifying four clauses.\nIt is often stated that a binary search algorithm performs better than linear search. Although this is true most of the time, there are instances for which linear search is faster than binary search. Let k be the sum of the soft clauses falsified by the assignment returned by the SAT solver in the first iteration. If k is indeed the optimal solution, linear search methods would discover this fact in the next iteration, while binary search ones would take log k iterations to declare k as the optimal cost. In order to benefit from both search methods, An et al.[3] developed a PMaxSAT algorithm called QMaxSAT (version 0.4) that alternates between linear search and binary search (see algorithm 4).\nAlgorithm 4: BinLin-WPMaxSAT(φ) Alternating binary and linear searches for solving WPMaxSAT.\nInput: A WPMaxSAT instance φ = φS ∪ φH Output: A WPMaxSAT solution to φ\n1 state← SAT ({Ci | (Ci,∞) ∈ φH}) 2 if state = False then 3 return ∅ 4 foreach (Ci, wi) ∈ φS do 5 let bi be a new blocking variable 6 φS ← φS \\ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)} 7 LB ← −1 8 UB ← 1 + ∑|φS | i=1 wi\n9 mode← binary 10 while LB + 1 < UB do 11 if mode = binary then 12 mid← bLB+UB\n2 c\n13 else 14 mid← UB − 1\n15 (state, I)← SAT ({C | (C,w) ∈ φ} ∪ CNF ( ∑|φS | i=1 wibi ≤ mid)) 16 if state = True then 17 lastI ← I 18 UB ← ∑|φS | i=1 wi(1− I(Ci \\ {bi}))\n19 else 20 if mode = binary then 21 LB ← UpdateBound({wi | 1 ≤ i ≤ |φS |},mid)− 1 22 else 23 LB ← mid\n24 if mode = binary then 25 mode← linear 26 else 27 mode← binary\n28 return lastI\nAlgorithm 4 begins by checking that the set of hard clauses is satisfiable (line 1). If not, then the algorithm returns the empty assignment and terminates (line 3). Next, the soft clauses are relaxed (lines 4-6) and the lower and upper bounds are initialized respectively to -1 and one plus the sum of the weights of the soft clauses (lines 7-8). BinLin-WPMaxSAT has two execution modes, binary and linear. The mode of execution is initialized in line 9 to binary search. At each iteration of the main loop (lines 10-27), the SAT solver is called\non the clauses of φ with the constraint ∑|φS | i=1 wibi bounded by the mid point (line 12), if the current mode is binary, or by the upper bound if the mode is linear (line 14). If the formula is satisfiable (line 16), the upper bound is updated. Otherwise, the lower bound is updated to the mid point. At the end of each iteration, the mode of execution is flipped (lines 24-27).\nSince the cost of the optimal solution is an integer, it can be represented as an array of\nbits. Algorithm 5 uses this fact to determine the solution bit by bit. BitBased-WPMaxSAT starts from the most significant bit and at each iteration it moves one bit closer to the least significant bit, at which the optimal cost if found.\nAlgorithm 5: BitBased-WPMaxSAT(φ) A bit-based algorithm for solving WPMaxSAT. Input: A WPMaxSAT instance φ = φS ∪ φH Output: A WPMaxSAT solution to φ\n1 state← SAT ({Ci | (Ci,∞) ∈ φH}) 2 if state = False then 3 return ∅ 4 foreach (Ci, wi) ∈ φS do 5 let bi be a new blocking variable 6 φS ← φS \\ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}\n7 k ← blg( ∑|φS | i=1 wi)c 8 CurrBit← k 9 cost← 2k\n10 while CurrBit ≥ 0 do 11 (state, I)← SAT ({C | (C,w) ∈ φ} ∪ CNF ( ∑|φS | i=1 wibi < cost)) 12 if state = True then 13 lastI ← I 14 let s0, . . . , sk ∈ {0, 1} be constants such that∑|φS |\ni=1 wi(1− I(Ci \\ {bi})) = ∑k j=0 2 jsj // s0, . . . , sk are the binary\nrepresentation of the current cost\n15 CurrBit← max({j | j < CurrBit and sj = 1} ∪ {−1}) 16 if CurrBit ≥ 0 then 17 cost← ∑k j=CurrBit 2 jsj\n18 else 19 CurrBit← CurrBit− 1 20 cost← cost+ 2CurrBit\n21 return lastI\nAt the beginning of the algorithm as in the previous ones, the satisfiability of the hard clauses are checked and the soft clauses are relaxed. The sum of the weights of the soft clauses k is an upper bound on the cost and thus it is computed to determine the number of bits needed to represent the optimal solution (line 7). The index of the current bit being considered is initialized to k (line 7), and the value of the solution being constructed is initialized (line 8). The main loop (lines 10-20) terminates when it reached the least significant bit (when CurrBit = 0). At each iteration, the SAT solver is called on φ with constraint saying that the sum of the weights of the falsified soft clauses must be less than cost (line 11). If the SAT solver returns True (line 12), the sum of the weights of the soft clauses falsified by the current assignment is computed and the set of bits needed to represent that number are determined as well (line 14), the index of the current bit is decreased to the next j < CurrBit such that sj = 1 (line 15). If such an index does not exist, then CurrBit becomes -1 and in the following iteration the algorithm terminates.\nOn the other hand, if the SAT solver returns False, the search continues to the most significant bit by decrementing CurrBit (line 19) and since the optimal cost is greater than the current value of cost, it is decreased by 2CurrBit (line 20).\nExample 3.2. Consider φ from example 2.1 with all the weights of the soft clauses being 1. At the beginning of the algorithm, the soft clauses are relaxed and the formula becomes {(x1∨ b1, 1), (x2∨ b2, 1), (x3∨ b3, 1), (x4∨ b4, 1), (x5∨ b5, 1), (x6∨ b6, 1), (¬x6∨ b7, 1)}∪φH . Also, the variables k, CurrBit and cost are initialized to 2, 2 and 22 respectively. The following are the iterations BitBased-WPMaxSAT executes.\n1. The constraint CNF (b1 + b2 + b3 + b4 + b5 + b6 + b7 < 2 2) is included, state = False,\nCurrBit = 1, cost = 22 + 21 = 6.\n2. The constraint CNF (b1 + b2 + b3 + b4 + b5 + b6 + b7 < 2 2 + 21), state = True,\nI = {x1 = False, x2 = False, x3 = True, x4 = False, x5 = True, x6 = False, b1 = True, b2 = True, b3 = False, b4 = True, b5 = False, b6 = True, b7 = False}, CurrBit = −1."
    }, {
      "heading" : "4 Core-guided Algorithms",
      "text" : "As in the previous method, UNSAT methods use SAT solvers iteratively to solve MaxSAT. Here, the purpose of iterative SAT calls is to identify and relax unsatisfiable formulas (unsatisfiable cores) in a MaxSAT instance. This method was first proposed in 2006 by Fu and Malik in[18] (see algorithm 6). The algorithms described in this section are\n1. Fu and Malik’s algorithm[18]\n2. WPM1[4]\n3. Improved WPM1[5]\n4. WPM2[7]\n5. WMSU1-ROR[21]\n6. WMSU3[37]\n7. WMSU4[38]\nDefinition 4.1 (Unsatisfiable core). An unsatisfiable core of a CNF formula φ is a subset of φ that is unsatisfiable by itself.\nDefinition 4.2 (Minimum unsatisfiable core). A minimum unsatisfiable core contains the smallest number of the original clauses required to still be unsatisfiable.\nDefinition 4.3 (Minimal unsatisfiable core). A minimal unsatisfiable core is an unsatisfiable core such that any proper subset of it is not a core[15].\nModern SAT solvers provide the unsatisfiable core as a by-product of the proof of unsatisfiability. The idea in this paradigm is as follows: Given a WPMaxSAT instance φ = {(C1, w1), . . . , (Cs, ws)} ∪ {(Cs+1,∞), . . . , (Cs+h,∞)}, let φk be a SAT instance that is satisfiable iff φ has an assignment with cost less than or equal to k. To encode φk,\nwe can extend every soft clause Ci with a new (auxiliary) variable bi and add the CNF conversion of the constraint ∑s i=1 wibi ≤ k. So, we have\nφk = {(Ci ∨ bi), . . . , (Cs ∨ bs), Cs+1, . . . , Cs+h} ∪ CNF ( s∑ i=1 wibi ≤ k )\nLet kopt be the cost of the optimal assignment of φ. Thus, φk is satisfiable for all k ≥ kopt, and unsatisfiable for all k < kopt, where k may range from 0 to ∑s i=1 wi. Hence, the search for the optimal assignment corresponds to the location of the transition between satisfiable and unsatisfiable φk. This encoding guarantees that the all the satisfying assignments (if any) to φkopt are the set of optimal assignments to the WPMaxSAT instance φ."
    }, {
      "heading" : "4.1 Fu and Malik’s algorithm",
      "text" : "Fu and Malik implemented two PMaxSAT solvers, ChaffBS (uses binary search to find the optimal cost) and ChaffLS (uses linear search to find the optimal cost) on top of a SAT solver called zChaff[44]. Their PMaxSAT solvers participated in the first and second MaxSAT Evaluations[10]. Their method (algorithm 6 basis for many WPMaxSAT solvers that came later. Notice the input to algorithm 6 is a PMaxSAT instance since all the weights of the soft clauses are the same.\nAlgorithm 6: Fu&Malik(φ) Fu and Malik’s algorithm for solving PMaxSAT.\nInput: φ = {(C1, 1), . . . , (Cs, 1), (Cs+1,∞), . . . , (Cs+h,∞)} Output: The cost of the optimal assignment to φ\n1 if SAT ({Cs+1, . . . , Cs+h}) = (False, ) then 2 return ∞ 3 opt← 0 // The cost of the optimal solution 4 f ← 0 // The number of clauses falsified 5 while True do 6 (state, φC)← SAT ({Ci | (Ci, wi) ∈ φ}) 7 if state = True then 8 return opt\n9 f ← f + 1 10 B ← ∅ 11 foreach Ci ∈ φC such that wi 6=∞ do 12 let bi be a new blocking variable 13 φ← φ \\ {(Ci, 1)} ∪ {(Ci ∨ bi, 1)} 14 B ← B ∪ {i} 15 φ← φ ∪ {(C,∞) | C ∈ ∑ i∈B bi = 1} // Add the cardinality constraint as hard\nclauses\n16 opt← opt+ 1\nFu&Malik (algorithm 6) (also referred to as MSU1) begins by checking if a hard clause is falsified (line 1), and if so it terminates returning the cost∞ (line 2). Next, unsatisfiable cores (φC) are identified by iteratively calling a SAT solver on the soft clauses (line 6).\nIf the working formula is satisfiable (line 7), the algorithm halts returning the cost of the optimal assignment (line 8). If not, then the algorithm starts its second phase by relaxing each soft clause in the unsatisfiable core obtained earlier by adding to it a fresh variable, in addition to saving the index of the relaxed clause in B (lines 11-14). Next, the new working formula constraints are added indicating that exactly one of bi variables should be True (line 15). Finally, the cost is increased by one (line 16) a clause is falsified. This procedure continues until the SAT solver declares the formula satisfiable."
    }, {
      "heading" : "4.2 WPM1",
      "text" : "Ansótegui, Bonet and Levy[4] extended Fu& Malik to WPMaxSAT. The resulting algorithm is called WPM1 and is described in algorithm 7.\nAlgorithm 7: WPM1(φ) The WPM1 algorithm for WPMaxSAT.\nInput: A WPMaxSAT instance φ = {(H1,∞), . . . , (Hh,∞)} ∪ {(S1, w1), . . . , (Ss, ws)} Output: The optimal cost of the WPMaxSAT solution\n1 if SAT ({Hi | 1 ≤ i ≤ h}) = False then 2 return ∞ 3 cost← 0 4 while True do 5 (state, φC)← SAT ({Ci | (Ci, wi) ∈ φ}) 6 if state = True then 7 return cost\n8 BV ← ∅ 9 wmin ← min{wi | Ci ∈ φC and wi 6=∞}\n// Compute the minimum weight of all the soft clauses in φC 10 foreach Ci ∈ φC do 11 if wi 6=∞ then 12 Let bi be a new blocking variable 13 φ← φ \\ {(Ci, wi)} ∪ {(Ci, wi − wmin)} ∪ {(Ci ∨ bi, wmin)} 14 BV ← BV ∪ {bi}\n15 if BV = ∅ then 16 return False // φ is unsatisfiable\n17 else 18 φ← φ ∪ CNF (∑ b∈BV b = 1 ) // Add the cardinality constraint as hard\nclauses\n19 cost← cost+ wmin\nJust as in Fu&Malik, algorithm 7 calls a SAT solver iteratively with the working formula, but without the weights (line 5). After the SAT solver returns an unsatisfiable core, the algorithm terminates if the core contains hard clauses and if it does not, then the algorithm computes the minimum weight of the clauses in the core, wmin (line 9). Next, the working formula is transformed by duplicating the core (line 13) with one copy having the clauses associated with the original weight minus the minimum weight and a second copy having having the clauses augmented with blocking variables with the original weight.\nFinally, the cardinality constraint on the blocking variable is added as hard clauses (line 18) and the cost is increased by the minimum weight (line 19).\nWPM1 uses blocking variables in an efficient way. That is, if an unsatisfiable core, φC = {C1, . . . , Ck}, appears l times, all the copies get the same set of blocking variables. This is possible because the two formulae φ1 = φ \\ φC ∪ {C1 ∨ bi, . . . , Ci ∨ bi | Ci ∈ φC} ∪ CNF (∑k i=1 bi = 1 ) and φ2 = φ \\ φC ∪ {Ci ∨ b1i , . . . , Ci ∨ bli | Ci ∈ φC} ∪\nCNF (∑k\ni=1 b 1 i = 1\n) ∪ · · · ∪ CNF (∑k i=1 b l i = 1 ) are MaxSAT equivalent, meaning that\nthe minimum number of unsatisfiable clause of φ1 and φ2 is the same. However, the algorithm does not avoid using more than one blocking variable per clause. This disadvantage is eliminated by WMSU3 (described later).\nExample 4.1. Consider φ = {(x1, 1), (x2, 2), (x3, 3), (¬x1 ∨ ¬x2,∞), (x1∨¬x3,∞), (x2∨¬x3,∞)}. In the following, bji is the relaxation variable added to clause Ci at the jth iteration. A possible execution sequence of the algorithm is:\n1. state = False, φC = {(¬x3), (¬x1 ∨ ¬x2), (x1 ∨ ¬x3), (x2 ∨ ¬x3)}, wmin = 3, φ = {(x1, 1), (x2, 2), (x3 ∨ b13, 3),, (¬x1 ∨¬x2,∞), (x1 ∨¬x3,∞), (x2 ∨¬x3,∞), (b13 = 1,∞)}.\n2. state = False, φC = {(x1), (x2), (¬x1∨¬x2)}, wmin = 1, φ = {(x1∨b21), (x2, 1), (x2∨ b22), (x3 ∨ b13), (¬x1 ∨ ¬x2,∞),(x1 ∨ ¬x3,∞), (x2 ∨ ¬x3,∞), (b13 = 1,∞), (b21 + b22 = 1,∞).\n3. state = True, A = {x1 = 0, x2 = 1, x3 = 0} is an optimal assignment with∑ Ci is soft\nA satisfies Ci\nwi = 2"
    }, {
      "heading" : "If the SAT solver returns a different unsatisfiable core in the first iteration, a different execution sequence is going to take place.",
      "text" : ""
    }, {
      "heading" : "4.3 Improved WPM1",
      "text" : "In 2012, Ansótegui, Bonet and Levy presented a modification to WPM1 (algorithm 7)[5]. In WPM1, the clauses of the core are duplicated after computing their minimum weight wmin. Each clause Ci in the core, the (Ci, wi − wmin) and (Ci ∨ bi, wmin) are added to the working formula and (Ci, wi) is removed. This process of duplication can be inefficient because a clause with weight w can be converted into w copies with weight 1. The authors provided the following example to illustrate this issue: consider φ = {(x1, 1), (x2, w), (¬x2, ∞)}. If the SAT solver always includes the first clause in the identified core, the working formula after the first iteration will be {(x1 ∨ b11, 1), (x2 ∨ b12, 1), (x2, w− 1), (¬x2,∞), (b11 + b12 = 1,∞)}. If at each iteration i, the SAT solver includes the first clause and with {(x2, w − i + 1), (¬x2,∞)} in the unsatisfiable core, then after i iterations the formula would be {(x1∨b11∨· · ·∨bi1, 1), (x2∨b2∗1, 1), . . . , (x2∨bi2, 1), (x2, w−i), (¬x2,∞), (b11+b12 = 1,∞), . . . , (bi1 + bi2 = 1,∞)}. In this case, WPM1 would need w iterations to solve the problem.\nAlgorithm 8: ImprovedWPM1(φ) The stratified approach for WPM1 algorithm.\nInput: A WPMaxSAT instance φ = {(C1, w1), . . . , (Cm, wm), (Cm+1,∞), . . . , (Cm+m′ , wm+m′)}\nOutput: The cost of the optimal WPMaxSAT solution to φ 1 if SAT ({Ci | wi =∞}) = (False, ) then 2 return ∞ // cost =∞ if the hard clauses can not be satisfied 3 cost← 0 4 wmax ← max{wi | (Ci, wi) ∈ φ and wi < wmax} // Initialize wmax to the largest\nweight smaller than ∞ 5 while True do 6 (state, φC)← SAT ({Ci | (Ci, wi) ∈ φ and wi ≥ wmax}) 7 if state = True and wmax = 0 then 8 return cost\n9 else 10 if state = True then 11 wnax = max{wi | (Ci, wi) ∈ φ and wi < wmax} 12 else 13 BV ← ∅ // Set of blocking variables of the unsatisfiable core 14 wmin ← min{wi | Ci ∈ φC and wi 6=∞} // Minimum weight of soft\nclauses in the unsatisfiable core\n15 foreach Ci ∈ φC do 16 if wi 6=∞ then 17 Let b be a new variable φ← φ \\ {(Ci, wi)} ∪ {(Ci, wi − wmin), (Ci ∨ b, wmin)} 18 BV ← BV ∪ {b}\n19 φ← φ ∪ {(C,∞) | C ∈ CNF ( ∑ b∈BV b = 1)} // The cardinality\nconstraint is added as hard clauses\n20 cost← cost+ wmin\nAlgorithm 8 overcomes this problem by utilizing a stratified approach. The aim is to restrict the clauses sent to the SAT solver to force it to concentrate on those with higher weights, which leads the SAT solver to return unsatisfiable cores with clauses having larger weights. Cores with clauses having larger weight are better because they contribute to increasing the cost faster. Clauses with lower weights are used after the SAT solver returns True. The algorithm starts by initializing wmax to the largest weight smaller than ∞, then in line 6 only the clauses having weight greater than or equal to wmax are sent to the SAT solver. The algorithm terminates if the SAT solver returns True and wmax is zero (lines 7-8), but if wmax is not zero and the formula is satisfiable then wmax is decreased to the largest weight smaller than wmax (lines 10-11). When the SAT solver returns False, the algorithm proceeds as the regular WPM1.\nA potential problem with the stratified approach is that in the worst case the algorithm could use more calls to the SAT solver than the regular WPM1. This is because there is no contribution made to the cost when the SAT solver returns True and at the same time wmax > 0. The authors apply the diversity heuristic which decreases wmax faster when there is a big variety of distinct weights and assigns wmax to the next value of wi when there is a low diversity among the weights."
    }, {
      "heading" : "4.4 WPM2",
      "text" : "In 2007, Marques-Silva and Planes[37] discussed important properties of Fu&Malik that were not mentioned in[18]. If m is the number of clauses in the input formula, they proved that the algorithm performs O(m) iterations and the number of relaxation variables used in the worst case is O(m2). Marques-Silva and Planes also tried to improve the work of Fu and Malik. Fu&Malik use the pairwise encoding[19] for the constraints on the relaxation variables, which use a quadratic number of clauses. This becomes impractical when solving real-world instances. Instead, Marques-Silva and Planes suggested several other encodings all of which are linear in the number of variables in the constraint[57, 53, 17, 19].\nAnother drawback of Fu&Malik is that there can be several blocking variables associated with a given clause. This is due to the fact that a clause C can participate in more than one unsatisfiable core. Each time C is a part of a computed unsatisfiable core, a new blocking variable is added to C. Although the number of blocking variables per clause is possibly large (but still linear), at most one of these variables can be used to prevent the clause from participating in an unsatisfiable core. A simple solution to reduce the search space associated with blocking variables is to require that at most one of the blocking variables belonging to a given clause can be assigned True. For a clause Ci, let bi,j , (1 ≤ j ≤ ti) be the blocking variables associated with Ci. The condition∑ti j=1 bi,j ≤ 1 assures that at most one of the blocking variables of Ci is assigned True. This is useful when executing a large number of iterations, and many clauses are involved in a significant number of unsatisfiable cores. The resulting algorithm that incorporated these improvements is called MSU2.\nAnsótegui, Bonet and Levy also developed an algorithm for WPMaxSAT in 2010, called WPM2[7], where every soft clause Ci is extended with a unique fresh blocking variable bi. Note that a SAT solver will assign bi True if Ci is False. At every iteration, the algorithm modifies two sets of at-most and at-least constraints on the blocking variables, called AL and AM respectively. The algorithm relies of the notion of covers.\nDefinition 4.4 (Cover). Given a set of cores L, its set of covers Covers(L) is defined as the minimal partition of {1, . . . ,m} such that for every A ∈ L and B ∈ Covers(L), if A ∩B 6= ∅, then A ⊆ B.\nAlgorithm 9: WPM2(φ) The WPM2 algorithm for WPMaxSAT\nInput: A WPMaxSAT instance φ = {(C1, w1), . . . , (Cm, wm), (Cm+1,∞), . . . , (Cm+m′ ,∞)}\nOutput: The optimal WPMaxSAT solution to φ 1 if SAT ({Ci ∈ φ | wi =∞}) = (False, ) then 2 return ∞ 3 φe ← {C1 ∨ b1, . . . , Cm ∨ bm, Cm+1, . . . , Cm+m′} 4 Covers← {{1}, . . . , {m}} 5 AL← ∅ 6 AM ← {w1b1 ≤ 0, . . . , wmbm ≤ 0} 7 while True do 8 (state, φC , I)← SAT (φe ∪ CNF (AL ∪AM)) 9 if state = True then\n10 return I\n11 Remove the hard clauses from φC 12 if φC = ∅ then 13 return ∅ // φ has no solution 14 A← ∅ 15 foreach Ci ∨ bi ∈ φC do 16 A← A ∪ {i} 17 RC ← {B ∈ Covers | B ∩A 6= ∅} 18 B ← ⋃ B′∈RC B ′ 19 k ← NewBound(AL,B) 20 Covers← Covers \\RC ∪B 21 AL← AL ∪ { ∑ i∈B wibi ≥ k}\n22 AM ← AM \\ { ∑ i∈B′ wibi ≤ k ′ | B′ ∈ RC} ∪ { ∑ i∈B wibi ≤ k}\nThe constraints in AL give lower bounds on the optimal cost of φ, while the ones in AM ensure that all solutions of the set AM ∪AL are the solutions of AL of minimal cost. This in turn ensures that any solution of φe ∪ CNF (AL ∪ AM) (if there is any) is an optimal assignment of φ.\nThe authors use the following definition of cores and introduced a new notion called covers to show how AM is computed given AL.\nDefinition 4.5 (Core). A core is a set of indices A such that(∑ i∈A wibi ≥ k ) ∈ AL\n. The function Core (∑ i∈A wibi ≥ k )\nreturns the coreA, and Cores(AL) returns {Core(al) | al ∈ AL}.\nDefinition 4.6 (Disjoint cores). Let U = {U1, . . . , Uk} be a set of unsatisfiable cores, each with a set of blocking variables Bi, (1 ≤ i ≤ k). A core Ui ∈ U is disjoint if for all Uj ∈ U we have (Ri ∩Rj = ∅ and i 6= j)\nGiven a set of AL constraints, AM is the set of at-most constraints ∑ i∈A wibi ≤ k\nsuch that A ∈ Cover(Cores(AL)) and k is the solution minimizing ∑ i∈A wibi subject to\nAL and bi ∈ {True, False}. At the beginning, AL = {w1b1 ≥ 0, . . . , wmbm ≥ 0} and the corresponding AM = {w1b1 ≤ 0, . . . , wmbm ≤ 0} which ensures that the solution to AL ∪ AM is b1 = False, . . . , bm = False. At every iteration, when an unsatisfiable core φC is identified by the SAT solver, the set of indices of soft clauses in φC A ⊆ {1, . . . ,m} is computed, which is also called a core. Next, the set of covers RC = {B′ ∈ Covers | B′∩ A 6= ∅} that intersect with A is computed, as well as their union B = ⋃ B′∈RC B\n′. The new set of covers is Covers = Covers \\RC ∪B. The set of at-least constraints AL is enlarged by adding a new constraint ∑ i∈B wibi ≥ NewBound(AL,B), where NewBound(AL,B)\ncorrespond to minimize ∑ i∈A wibi subject to the set of constraints { ∑ wibi≥k}∪AL where\nk = 1 + ∑ {k′ | ∑ i∈A′ wibi ≤ k′ ∈ AM and A′ ⊆ A}. Given AL and B, the computation of NewBound can be difficult since it can be reduced to the subset sum problem in the following way: given {w1, . . . , wn} and k, minimize ∑n j=1 wjxj subject to ∑n j=1 wjxj > k and xj ∈ {0, 1}. This is equivalent to NewBound(AL,B), where the weights are wj , B = {1, . . . , n} and AL = { ∑n j=1 wjxj ≥ k}. In the authors’ implementation, NewBound is computed by algorithm 10.\nAlgorithm 10: NewBound(AL,B) 1 k ← ∑{ k′ | ∑ i∈B′ wibi ≤ k ′ ∈ AM and B′ ⊆ B } 2 repeat 3 k ← SubsetSum({wi | i ∈ B}, k) 4 until SAT ( CNF ( AL ∪ { ∑ i∈B wibi = k}\n)) 5 return k\nThe SubsetSum function (called in line 3) is an optimization version of the decision subset sum problem. It returns the largest integer d ≤ k such that there is a subset of {wi | i ∈ B} that sums to d.\nExample 4.2. Consider φ in example 2.1 with all the weights of the soft clauses set to 1. Before the main loop of algorithm 9, we have φe = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨ b4), (x5∨b5), (x6∨b6), (¬x6∨b7)}∪φH , Covers = {{1}, {2}, {3}, {4}, {5}, {6}, {7}}, AL = ∅, AM = {b1 ≤ 0, b2 ≤ 0, b3 ≤ 0, b4 ≤ 0, b5 ≤ 0, b6 ≤ 0, b7 ≤ 0}. The following are the iterations the algorithm executes. The soft clauses in the core φC are denoted by Soft(φC).\n1. state = False, Soft(φC) = {(x6 ∨ b6), (¬x6 ∨ b7)}, A = {6, 7}, RC = {{6}, {7}}, B = {6, 7}, k = 1, Covers = {{1}, {2}, {3}, {4}, {5}, {6, 7}}, AL = {b6 + b7 ≥ 1}, AM = {b1 ≤ 0, b2 ≤ 0, b3 ≤ 0, b4 ≤ 0, b5 ≤ 0, b6 + b7 ≤ 1}.\n2. state = False, Soft(φC) = {(x1), (x2)}, A = {1, 2}, RC = {{1}, {2}}, B = {1, 2}, k = 1, Covers = {{1, 2}, {3}, {4}, {5}, {6, 7}}, AL = {b6 + b7 ≥ 1, b1 + b2 ≥ 1}, AM = {b3 ≤ 0, b4 ≤ 0, b5 ≤ 0, b6 + b7 ≤ 1, b1 + b2 ≤ 1}.\n3. state = False, Soft(φC) = {(x3), (x4)}, A = {3, 4}, RC = {{3}, {4}}, B = {3, 4}, k = 1, Covers = {{1, 2}, {3, 4}, {5}, {6, 7}}, AL = {b6 +b7 ≥ 1, b1 +b2 ≥ 1, b3 +b4 ≥ 1}, AM = {b1 + b2 ≤ 1, b5 ≤ 0, b6 + b7 ≤ 1, b3 + b4 ≤ 1}.\n4. state = False, Soft(φC) = {(x1), (x2), (x3), (x4), (x5)}, A = {1, 2, 3, 4, 5}, RC = {{1, 2}, {3, 4}, {5}}, B = {1, 2, 3, 4, 5}, k = 3, Covers = {{6, 7}, {1, 2, 3, 4, 5}}, AL = {b6 + b7 ≥ 1, b1 + b2 ≥ 1, b3 + b4 ≥ 1, b1 + b2 + b3 + b4 + b5 ≥ 3}, AM = {b1 + b2 ≤ 1, b1 + b2 + b3 + b4 + b5 ≤ 3}.\n5. state = True, I = {x1 = False, x2 = False, x3 = True, x4 = False, x5 = True, x6 = False, b1 = True, b2 = True, b3 = False, b4 = True, b5 = False, b6 = True, b7 = False}.\nTo sum up, the WPM2 algorithm groups the identified cores in covers, which are a decomposition of the cores into disjoint sets. Constraints are added so that the relaxation variables in each cover relax a particular weight of clauses k, which is changed to the next largest value the weights of the clauses can sum up to. Computing the next k can be expensive since it relies on the subset sum problem, which is NP-hard.\nIn[6], Ansótegui et at. invented three improvements to WPM2. First, they applied the stratification technique[5]. Second, they introduced a new criteria to decide when soft clauses can be hardened. Finally, they showed that by focusing search on solving to optimality subformulae of the original WPMaxSAT instance, they efficiency of WPM2 is increased. This allows to combine the strength of exploiting the information extracted from unsatisfiable cores and other optimization approaches. By solving these smaller optimization problems the authors obtained the most significant boost in their new WPM2 version."
    }, {
      "heading" : "4.5 WMSU1-ROR",
      "text" : "WMSU1-ROR[21] is a modification of WPM1. It attempts to avoid adding blocking variables by applying MaxSAT resolution to the clauses of the unsatisfiable core. Given an unsatisfiable core φC , a resolution refutation (a contradiction obtained by performing resolution) is calculated by a specialized tool. As much of this refutation as possible is copied by applying MaxSAT resolution steps to the working formula. If the transformation derived the empty clause, it means that the core is trivial and the sequence of calls to the SAT solver can continue without adding any relaxation variables for this step. Otherwise, the transformed core is relaxed as in WPM1. The classical resolution rule can not be applied in MaxSAT because it does not preserve the equivalence among weighted formulae. The MaxSAT resolution rule used in WMSU1-ROR is called Max-RES and is described in[26]. The following definition extends the resolution rule from SAT to WMaxSAT.\nDefinition 4.7 (WPMaxSAT resolution). {(x ∨ A, u), (¬x ∨ B,w)} ≡ {(A ∨ B,m), (x ∨ A, u m), (¬x ∨ B,w m), (x ∨ A ∨ ¬B,m), (¬x ∨ ¬A ∨ B,m)}, where A and B are disjunctions and is defined on weights u,w ∈ {0, . . . ,>}, such that u ≥ w, as\nu w = { u− w u 6= > > u = >\nand m = min(u,w). The clauses (x∨A, u) and (¬x∨B,w) are called the clashing clauses, (A∨B,m) is called the resolvent, (x∨A, u m) and (¬x∨B,w m) are called posterior clashing clauses, (x ∨ A ∨ ¬B,m) and (¬x ∨ ¬A ∨ B,m) are the compensation clauses (which are added to recover an equivalent MaxSAT formula).\nFor example, if Max-RES is applied on {(x∨y, 3), (¬x∨y∨z, 4)} with > > 4, we obtain {(y ∨ y ∨ z, 3), (x ∨ y, 3 3), (¬x ∨ y ∨ z, 4 3), (x ∨ y ∨ ¬(y ∨ z), 3), (¬x ∨ ¬y ∨ y ∨ z, 3)}.\nThe first and fourth clauses can be simplified by observing that (A ∨ C ∨ ¬(C ∨B), u) ≡ (A∨C∨¬B, u). The second and fifth clauses can be deleted since the former has weight zero and the latter is a tautology. De Morgan’s laws can not be applied on MaxSAT instance for not preserving the equivalence among instances[26]. The following rule can be applied instead (A ∨ ¬(l ∨C), w) ≡ {(A ∨ ¬C), (A ∨ ¬l ∨C,w)}. A resolution proof is an ordered set R = {Ci = (Ci′ ./ Ci′′), Ci+1 = (Ci′+1 ./ Ci′′+1), . . . , Ci+k = (Ci′+k ./ Ci′′+k)}, where (Ci, wi) = (Ci′ , wi′) ./ (Ci′′ , wi′′) is the the resolution step i of a resolution proof, (Ci, wi) is the resolvent and (Ci′ , wi′) and (Ci′′ , wi′′) are the clashing clauses. The set of compensation clauses will be denoted [(Ci′ , wi′) ./ (Ci′′ , wi′′)].\nThe ROR approach is captured in lines 12-22 in algorithm 11. WMSU1-ROR handles WPMaxSAT formulae the same way as[4]. It maintains a working formula φW and a lower bound LB. The resolution proof RC is obtained in line 12 and MaxSAT resolution is applied (lines 14-21) for each read-once step. In detail, the weights of the clashing clauses (Ci′ , wi′) and (Ci′′ , wi′′) are decreased by the minimum weight of the clauses in the unsatisfiable core φC (lines 15-16). If the clashing clauses are soft, they are deleted from φC (lines 17-18) and if their resolvent is not , it is added to φC (lines 21-22). On the other hand, if the clashing clauses are hard, they are kept in the core because they could be used in a different resolution step. Lastly, the compensation and clashing clauses are added to φW (lines 19-20).\nAlgorithm 11: WMSU1-ROR(φ)\nInput: A WPMaxSAT instance φ = {(C1, w1), . . . , (Cm, wm), (Cm+1,∞), . . . , (Cm+m′ , wm+m′)}\nOutput: The cost of the optimal solution to φ 1 if SAT ({Ci | wi =∞}) = False then 2 return ∞ 3 φW ← φ 4 LB ← 0 5 while True do 6 (state, φC)← SAT (φW ) 7 if state = True then 8 return LB\n9 φW ← φW \\ φC 10 m← min ({w | (C,w) ∈ φC and w < >}) 11 LB ← LB +m\n// Beginning of read-once resolution\n12 RC ← GetProof(φC) 13 foreach (Ci, wi) = (Ci′ , wi′) ./ (Ci′′ , wi′′) ∈ RC do 14 if ROR((Ci, wi), RC) then 15 (Ci′ , wi′)← (Ci′ , wi′ m) 16 (Ci′′ , wi′′)← (Ci′′ , wi′′ m) 17 if wi′ < > and wi′′ < > then 18 φC ← φC \\ {(Ci′ , wi′), (Ci′′ , wi′′)} 19 φW ← φW ∪ {(Ci′ , wi′), (Ci′′ , wi′′)} 20 φW ← φW ∪ {[(Ci′ , wi′) ./ (Ci′′ , wi′′)]} 21 if Ci 6= then 22 φC ← φC ∪ {(Ci,m)}\n// End of read-once resolution\n23 B ← ∅ 24 foreach (Ci, wi) ∈ {(C,w) | (C,w) ∈ φC and w < >} do 25 Let b be a new relaxation variable B ← B ∪ {b} φC ← φC ∪ {(C ∨ b,m)} if w > m then 26 (C,w)← (C,w m) 27 else 28 φC ← φC \\ {(C,w)}\n29 φc ← φC ∪ CNF (∑ b∈B b = 1 ) 30 φW ← φW ∪ φC\nHard((Ci, wi), R) (algorithm 12) returns True if (Ci, wi) is a hard clause and all its ancestors are hard, otherwise it returns False. Input((Ci, wi), R) (called in line 1) returns True if (Ci, wi) is not a resolvent of any step in R (i.e., an original clause), otherwise it returns False. ancestors((Ci, wi), R) (called in line 5) returns the pair of clauses (Ci′ , wi′) and (Ci′′ , wi′′) from which (Ci, wi) was derived as dictated by R.\nAlgorithm 12: Hard((Ci, wi), R) Determines if a clause is hard or not\nInput: A proof R Output: True if (Ci, wi) is hard, or False otherwise\n1 if Input((Ci, wi), R) and wi = > then 2 return True\n3 if Input((Ci, wi), R) and wi 6= > then 4 return False\n5 {(Ci′ , wi′), (Ci′′ , wi′′)} ← ancestors((Ci, wi), R) 6 return Hard((Ci′ , wi′), R) and Hard((Ci′′ , wi′′), R)\nThe function ROR (algorithm 13) returns True if (Ci, wi) is hard or if it and all of its soft ancestors have been used at most once in the resolution proof R. If (Ck, wk) = (Ck′ , wk′) ./ (Ck′′ , wk′′), where (Ck, wk) is the last resolvent in a resolution proof R. The entire proof is read-once if ROR((Ck, wk), R) returns True. In this case (when the last step is ROR), the resolvent of that step is ( ,m). If this situation occurs, the algorithm does not need to augment clauses with relaxation variables or cardinality constraints, which improves upon the original algorithm.\nAlgorithm 13: ROR((Ci, wi), R) Determines if a clause is hard or not or if its ancestors are used at most once Input: A proof R Output: True if (Ci, wi) is hard or if its ancestors are used exactly once, False otherwise\n1 if Hard((Ci, wi), R) then 2 return True\n3 if Input((Ci, wi), R) and Used((Ci, wi), R) = 1 then 4 return True\n5 if Used((Ci, wi), R) > 1 then 6 return False\n7 {(Ci′ , wi′), (Ci′′ , wi′′)} ← ancestors((Ci, wi), R) 8 return ROR((Ci′ , wi′), R) and ROR((Ci′′ , wi′′), R)\nThe problem with this approach (applying Max-RES instead of adding blocking variables and cardinality constraints) is that when soft clauses with weights greater than zero are resolved more than once, MaxSAT resolution does not ensure to produce resolvents with weights greater than zero. For this technique to work, the authors restrict the application of resolution to the case where each clause is used at most once, which is referred to as read-once resolution (ROR). Unfortunately, ROR can not generate resolution proofs for some unsatisfiable clauses[23]."
    }, {
      "heading" : "4.6 WMSU3",
      "text" : "WMSU3 is a WPMaxSAT algorithm that adds a single blocking variable per soft clause, thus limiting the number of variables in the formula sent to the SAT solver in each iteration.\nAlgorithm 14: WMSU3(φ) The WMSU3 algorithm for WPMaxSAT.\nInput: A WPMaxSAT instance φ = φS ∪ φH Output: The cost of the optimal WPMaxSAT solution to φ\n1 if SAT ({C | (C,∞) ∈ φH}) = False then 2 return ∞ 3 B ← ∅ // Set of blocking variables 4 φW ← φ // Working formula initialized to φ 5 LB ← 0 // Lower bound initialized to 0 6 while True do 7 (state, φC)← SAT ({C | (C,w) ∈ φW } ∪ CNF ( ∑ bi∈B wibi ≤ LB)) 8 if state = True then 9 return LB\n10 foreach (Ci, wi) ∈ φC ∩ φS do 11 if w 6=∞ then 12 B ← B ∪ {bi} 13 φW ← φW \\ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}\n14 LB ← UpdateBound({wi | bi ∈ B}, LB)\nAlgorithm 14 begins by initializing the set of blocking variables that will be augmented later to ∅ (line 3), the working formula to φ (line 4) and the lower bound to zero (line 5). MSU3 then loops over unsatisfiable working formulae φW (while loop in lines 6-13) until it finds a satisfiable one in line 8. At each iteration, when an unsatisfiable core is returned by the SAT solver, the algorithm adds one blocking variable to each soft clause that has not been augmented with a blocking variable yet (line 13), unlike WPMaxSAT algorithms discussed previously such as WPM1 (algorithm 7). Indeed, at most one blocking variable is added to each clause because if at iteration i Ci was blocked by bi, then at iteration i+1 the clause Ci ∨ bi will not be in φC ∩ φS . The function UpdateBound in line 14 updates the lower bound LB, either by simply incrementing it or by the subset sum problem as in[7]. The following example illustrates how the algorithm works.\nExample 4.3. Let φ = {(x1, 1), (x2, 3), (x3, 1)} ∪ {(¬x1 ∨ ¬x2,∞), (¬x2 ∨ ¬x3,∞)}.\n1. state = False, φC = {(x1), (x2), (¬x1 ∨ ¬x2)}, φC ∩ φS = {(x1), (x2)}, φW = {(x1 ∨ b1, 1), (x2 ∨ b2, 2), (x3, 1), (¬x1 ∨ ¬x2,∞), (¬x2 ∨ ¬x3,∞)}, LB = 1.\n2. The constraint CNF (b1 + 3b2 ≤ 1) is included and satisfying it implies that b2 must be falsified, and thus CNF (b1 + 3b2 ≤ 1) is replaced by (¬b2). state = False, φC = {(x2∨b2), (x3), (¬x2∨¬x3), (¬b2)}, φC∩φS = {(x3)}, φW = {(x1∨b1, 1), (x2∨ b2, 2), (x3 ∨ b3, 1), (¬x1 ∨ ¬x2,∞), (¬x2 ∨ ¬x3,∞)}, LB = 2. As in the previous iteration, satisfying the constraint b1 + 3b2 + b3 ≤ 2 implies b2 must be falsified.\n3. The constraint CNF (b1+3b2+b3 ≤ 2) is included, state = True and the assignment I = {x1 = False, x2 = True, x3 = False, b1 = True, b2 = False, b3 = True} indeed satisfies φW of the last iteration. By ignoring the values of the blocking variables, I is indeed an optimal assignment for φ. It falsifies the soft clauses (x1, 1) and (x3, 1) and satisfies (x2, 3)."
    }, {
      "heading" : "4.7 WMSU4",
      "text" : "Like WMSU3, WMSU4[38] (algorithm 15) adds at most one blocking variable to each soft clause. Thought, it maintains an upper bound (UB) as well as a lower bound (LB). If the current working formula is satisfiable (line 9), UB is changed to the sum of the weights of the falsified clauses by the solution (I) returned from the SAT solver. On the other hand, if the working formula is unsatisfiable, the SAT solver returns an unsatisfiable core, and the algorithm adds a blocking variable to each clause that has not yet been relaxed in that core. If all the soft clauses in the unsatisfiable core have been relaxed (line 16), then the algorithm updates the lower bound (line 17) and exists the main loop. The following example illustrates how the algorithm works.\nAlgorithm 15: WMSU4(φ) The WMSU4 algorithm for WPMaxSAT.\nInput: A WPMaxSAT instance φ = φS ∪ φH Output: The cost of the optimal WPMaxSAT solution to φ\n1 if SAT ({C | (C,∞) ∈ φH}) = False then 2 return ∞ 3 B ← ∅ // Set of blocking variables 4 φW ← φ // Working formula initialized to φ 5 LB ← −1 // Lower bound initialized to 0 6 UB ← 1 + ∑|φS | i=1 wi // Upper bound initialized to the sum of the weights\nof the soft clauses plus one\n7 while UB > LB + 1 do 8 (state, φC , I)← SAT ({C | (C,w) ∈ φW } ∪ CNF ( ∑ bi∈B wibi ≤ UB − 1))\n9 if state = True then 10 UB ← ∑ bi∈B wi(1− I(Ci \\ bi)) // Update UB to the sum of the\nweights of the falsified clauses without the blocking variables\n11 else 12 foreach (Ci, wi) ∈ φC ∩ φS do 13 if w 6=∞ then 14 B′ ← B′ ∪ {bi} 15 φW ← φW \\ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}\n16 if B′ = ∅ then 17 LB ← UB − 1 18 else 19 B ← B ∪B′ 20 LB ← UpdateBound({wi | bi ∈ B}, LB)\n21 return UB\nExample 4.4. Let φ = φS ∪ φH , where φS = {(x1, 1), (x2, 1), (x3, 1), (x4, 1)} and φH = {(¬x1∨¬x2,∞), (¬x1∨¬x3,∞), (¬x1∨¬x4,∞), (¬x2∨¬x3∨¬x4,∞)}. Before the first iteration of the while loop, we have LB = −1, UB = 1+(1+1+1+1) = 5\nand φW = φ.\n1. state = False, φC∩φS = {(x2), (x3), (x4)}, LB = 0, φW = {(x1, 1), (x2∨b2, 1), (x3∨ b3, 1), (x4 ∨ b4, 1)} ∪ φH .\n2. The constraint CNF (b2 + b3 + b4 ≤ 5 − 1) is included, state = True, I = {x1 = True, x2 = False, x3 = False, x4 = False, b2 = True, b3 = True, b4 = True}, UB = 3.\n3. The constraint CNF (b2 + b3 + b4 ≤ 3 − 1) is included, state = False, φC ∩ φS = {(x1, 1), (x2 ∨ b2, 1), (x3 ∨ b3, 1), (x − 4 ∨ b4, 1)}, LB = 1, φW = {(x1 ∨ b1), (x2 ∨ b2, 1), (x3 ∨ b3, 1), (x− 4 ∨ b4, 1)} ∪ φH .\n4. The constraint CNF (b1 + b2 + b3 + b4 ≤ 2) is included, state = SAT , I = {x1 = False, x2 = False, x3 = True, x4 = True, b1 = True, b2 = True, b3 = False, b4 = False}, UB = 2. The cost of the optimal assignment is indeed 2 (since (x1, 1) and (x2, 1) are falsified) by I."
    }, {
      "heading" : "5 Core-guided Binary Search Algorithms",
      "text" : "Core-guided binary search algorithms are similar to binary search algorithms described in the first section, except that they do not augment all the soft clauses with blocking variables before the beginning of the main loop. Heras, Morgado and Marques-Silva proposed this technique in[22] (see algorithm 16).\nAlgorithm 16: CoreGuided-BS(φ) Core-guided binary search algorithm for solving WPMaxSAT.\nInput: A WPMaxSAT instance φ = φS ∪ φH Output: The cost of the optimal WPMaxSAT solution to φ\n1 state← SAT ({Ci | (Ci,∞) ∈ φH}) 2 if state = False then 3 return ∅ 4 φW ← φ 5 LB ← −1 6 UB ← 1 + ∑|φS | i=1 wi 7 B ← ∅ 8 while LB + 1 < UB do 9 mid← bLB+UB2 c\n10 (state, φC , I)← SAT ({C | (C,w) ∈ φW } ∪ CNF ( ∑ bi∈B wibi ≤ mid)) 11 if state = True then\n12 UB ← ∑|φS | i=1 wi(1− I(Ci \\ {bi})) 13 lastI ← I 14 else 15 if φC ∩ φS = ∅ then 16 LB ← UpdateBound({wi | bi ∈ B},mid)− 1 17 else 18 foreach (Ci, wi) ∈ φC ∩ φS do 19 let bi be a new blocking variable 20 B ← B ∪ {bi} 21 φW ← φW \\ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}\n22 return lastI\nSimilar to other algorithms, CoreGuided-BS begins by checking the satisfiability of the hard clauses (lines 1-3). Then it initializes the lower bound (line 4), the upper bound (line 5) and the set of blocking variables (line 6) respectively to -1, one plus the sum of the weights of the soft clauses and ∅. At each iteration of the main loop (lines 7-21) a SAT solver is called on the working formula with a constraint ensuring that the sum of the weights of the relaxed soft clauses is less than or equal the middle value (line 9). If the formula is satisfiable (line 10), the upper bound is updated to the sum of the falsified soft clauses by the current assignment (line 11). Otherwise, if all the soft clauses have been relaxed (line 14), then the lower bound is updated (line 15), and if not, non-relaxed sot clauses belonging to the core are relaxed (lines 17-19). The main loop continues as long as LB + 1 < UB.\nExample 5.1. Consider φ in example 2.1 with all the weights of the soft clauses set to 1. At the beginning of the algorithm LB = −1, UB = 8, B = ∅ and φH is satisfiable. The following are the iterations the algorithm executes.\n1. mid = b−1+82 c = 3. Since B = ∅, no constraint is included. state = False, φC ∩ φS = {(x6), (¬x6)}, B = {b6, b7}. φ = {(x1, 1), (x2, 1), (x3, 1),\n(x4, 1), (x5, 1), (x6 ∨ b6, 1), (¬x6 ∨ b7, 1)} ∪ φH .\n2. mid = 3, the constraint CNF (b6 + b7 ≤ 3) is included. state = False, φC ∩ φS = {(x1), (x2)}, B = {b1, b2, b6, b7}, φ = {(x1∨b1, 1), (x2∨b2, 1), (x3, 1), (x4, 1), (x5, 1), (x6∨ b6, 1), (¬x6 ∨ b7, 1)} ∪ φH .\n3. mid = 3, the constraint CNF (b1 + b2 + b6 + b7 ≤ 3) is included. state = False, φC ∩φS = {(x3), (x4)}, B = {b1, b2, b3, b4, b6, b7}, φ = {(x1 ∨ b1, 1), (x2 ∨ b2, 1), (x3 ∨ b3, 1), (x4 ∨ b4, 1), (x5, 1), (x6 ∨ b6, 1), (¬x6 ∨ b7, 1)} ∪ φH .\n4. mid = 3, the constraint CNF (b1 + b2 + b3 + b4 + b6 + b7 ≤ 3) is included. state = False, φC ∩φS = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨ b4), (x6 ∨ b6), (¬x6 ∨ b7), (x5)}, B = {b1, b2, b3, b4, b5, b6, b7}, φ = {(x1∨b1, 1), (x2∨b2, 1), (x3∨b3, 1), (x4∨b4, 1), (x5∨ b5, 1), (x6 ∨ b6, 1), (¬x6 ∨ b7, 1)} ∪ φH .\n5. mid = 3, CNF (b1 + b2 + b3 + b4 + b5 + b6 + b7 ≤ 3) is included. state = False, φC ∩ φS = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨ b4), (x5 ∨ b5), (x6 ∨ b6), (¬x6 ∨ b7)}, LB = 3.\n6. mid = 5, the constraint CNF (b1+b2+b3+b4+b6+b7 ≤ 5) is included. state = True, I = {x1 = False, x2 = False, x3 = True, x4 = False, x5 = True, x6 = False, b1 = True, b2 = True, b3 = False, b4 = True, b5 = False, b6 = True, b7 = False}, UB = 4. The values of the xi, (1 ≤ i ≤ 6) variables in I indeed constitute an optimal assignment.\nThe core-guided binary search approach was improved by Heras[22] et al. with disjoint cores (see definition 4.6).\nAlgorithm 17: DisjointCoreGuided-BS(φ) Core-guided binary search extended with disjoint cores for solving WPMaxSAT.\nInput: A WPMaxSAT instance φ = φS ∪ φH Output: A WPMaxSAT solution to φ\n1 if SAT ({C | (C,∞) ∈ φH}) = False then 2 return ∅ 3 φW ← φ 4 C ← ∅ 5 repeat 6 foreach Ci ∈ C do 7 if LBi + 1 = UBi then 8 midi ← UBi 9 else\n10 midi ← bLBi+UBi2 c\n11 (state, φC , I)← SAT ({C | (C,w) ∈ φW } ∪ ⋃ Ci∈C CNF ( ∑ bi∈B wibi ≤ midi)) 12 if state = True then 13 lastI ← I 14 foreach Ci ∈ C do 15 UBi ← ∑ br∈B wr(1− I(Cr \\ {br})))\n16 else 17 subC ← IntersectingCores(φC , C) 18 if φC ∩ φS = ∅ and |subC| = 1 then 19 LB ← mid // subC = {(B,LB,mid, UB)} 20 else 21 foreach (Ci, wi) ∈ φC ∩ φS do 22 let bi be a new blocking variable 23 B ← B ∪ {bi} 24 φW ← φW \\ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)} 25 LB ← 0 26 UB ← 1 + ∑ bi∈B wi 27 foreach (Bi, LBi,midi, UBi) ∈ subC do 28 B ← B ∪Bi 29 LB ← LB + LBi 30 UB ← UB + UBi 31 C ← C \\ subC ∪ {(B,LB, 0, UB)}\n32 until ∀Ci∈CUBi ≤ LBi + 1 33 return lastI\nCore-guided binary search methods with disjoint unsatisfiable cores maintains smaller lower and upper bounds for each disjoint core instead of just one global lower bound and one global upper bound. Thus, the algorithm will add multiple smaller cardinality constraints on the sum of the weights of the soft clauses rather than just one global constraint.\nTo maintain the smaller constraints, the algorithm keep information about the previous cores in a set called C initialized to ∅ (line 4) before the main loop. Whenever\nthe SAT solver returns False (line 12) it also provides a new core and a new entry Ci = (Bi, LBi,midi, UBi) is added in C for Ui, where Bi is the set of blocking variables associated with the soft clauses in Ui, LBi is a lower bound, midi is the current middle value and UBi is an upper bound. The main loop terminates when for each Ci ∈ C, LBi + 1 ≥ UBi (line 33). For each entry in C, its middle value is calculated (lines 6- 10) and a constraint for each entry is added to the working formula before calling the SAT solver on it (line 11). If the working formula is unsatisfiable (line 16), then, using IntersectiongCores, every core that intersects the current core is identified and its corresponding entry is added to subC (line 17). If the core does not contain soft clauses that need to be relaxed and |subC| = 1 (line 18), then LB is assigned the value of the midpoint (line 19). On the other hand, if there exists clauses that has not been relaxed yet then the algorithm relaxes them (lines 21-24) and a new entry for the current core is added to C which accumulates the information of the previous cores in subC (lines 25-31).\nExample 5.2. Consider φ in example 2.1 with all the weights of the soft clauses set to 1. At the beginning of algorithm 17, we have φW = φ and C = ∅. The following are the iterations the algorithm executes.\n1. No constraints to include. state = False, φC ∩ φS = {(x6), (¬x6)}, subC = ∅, B = {b6, b7}, φW = {(x1), (x2), (x3), (x4), (x5), (x6 ∨ b6), (¬x6 ∨ b7)} ∪ φH , LB = 0, UB = 3, C = {({b6, b7}, 0, 0, 3)}.\n2. The constraint CNF (b6+b7 ≤ 1) is included. state = False, φC∩φS = {(x1), (x2)}, subC = ∅, B = {b1, b2}. φW = {(x1 ∨ b1), (x2 ∨ b2), (x3), (x4), (x5), (x6 ∨ b6), (¬x6 ∨ b7)} ∪ φH , LB = 0, UB = 3, C = {({b6, b7}, 0, 0, 3), ({b1, b2}, 0, 0, 3)}.\n3. The constraints {CNF (b6+b7 ≤ 1), CNF (b1+b2 ≤ 1)} are included. state = False, φC ∩ φS = {(x3), (x4)}, subC = ∅, B = {b3, b4}, φW = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4∨b4), (x5), (x6∨b6), (¬x6∨b7)}∪φH , LB = 0, UB = 3, C = {({b6, b7}, 0, 0, 3), ({b1, b2}, 0, 0, 3), ({b3, b4}, 0, 0, 3)}.\n4. The constraints {CNF (b6 + b7 ≤ 1), CNF (b1 + b2 ≤ 1), CNF (b3 + b4 ≤ 1)} are included. state = False, φC ∩ φS = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨ b4), (x5)}, subC = {({b1, b2}, 0, 0, 3), ({b3, b4}, 0, 0, 3)}, B = {b1, b2, b3, b4, b5}, φW = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨ b4), (x5 ∨ b5), (x6∨b6), (¬x6∨b7)}∪φH , LB = 0, UB = 8, C = {({b6, b7}, 0, 0, 3), ({b1, b2, b3, b4, b5}, 0, 0, 8)}.\n5. The constraints CNF (b6 + b7 ≤ 1), CNF (b1 + b2 + b3 + b4 + b5 ≤ 4) are included. state = True, I = {x1 = False, x2 = False, x3 = True, x4 = False, x5 = True, x6 = False, b1 = True, b2 = True, b3 = False, b3 = True, b5 = False, b6 = True, b7 = False}, C = {({b6, b7}, 0, 0, 1), ({b1, b2, b3, b4, b5}, 0, 0, 2)}.\n6. The constraints CNF (b6 + b7 ≤ 1), CNF (b1 + b2 + b3 + b4 + b5 ≤ 1) are included. state = False, φC ∩φS = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨ b4), (x5 ∨ b5)}, subC = {({b1, b2, b3, b4, b5}, 0, 0, 2)}, C = {({b6, b7}, 0, 0, 1), ({b1, b2, b3, b4, b5}, 1, 0, 2)}.\n7. state = True, I = {x1 = False, x2 = False, x3 = True, x4 = False, x5 = True, x6 = False, b1 = True, b2 = True, b3 = False, b4 = True, b5 = False, b6 = True, b7 = False}.\nSAT-based WPMaxSAT solvers rely heavily on the hardness of the SAT formulae returned by the underlying SAT solver used. Obviously, the location of the optimum solution depends on the structure of the instances returned and the number of iterations it takes to switch from True to False (or from False to True)."
    }, {
      "heading" : "6 Portfolio MaxSAT Techniques",
      "text" : "The results of the MaxSAT Evaluations suggest there is no absolute best algorithm for solving MaxSAT. This is because the most efficient solver often depends on the type of instance. In other words, different solution approaches work well on different families of instances[40]. Having an oracle able to predict the most suitable MaxSAT solver for a given instance would result in the most robust solver. The success of SATzilla[59] for SAT was due to a regression function which was trained to predict the performance of every solver in the given set of solvers based on the features of an instance. When faced with a new instance, the solver with the best predicted runtime is run on the given instance. The resulting SAT portfolios excelled in the SAT Competitions in 2007 and in 2009 and pushed the state-of-the-art in SAT solving. When this approach is extended to (WP)MaxSAT, the resulting portfolio can achieve significant performance improvements on a representative set of instances.\nISAC[9] (Instance-Specific Algorithm Configuration) is one of the most successful WPMaxSAT portfolio algorithms. It works by computing a representative feature vector that characterizes the given input instance in order to identify clusters of similar instances. The data is therefore clustered into non-overlapping groups and a single solver is selected for each group based on some performance characteristic. Given a new instance, its features are computed and it is assigned to the nearest cluster. The instance is then solved by the solver assigned to that cluster."
    }, {
      "heading" : "7 Translating Pseudo-Boolean Constraints into CNF",
      "text" : "This section discusses translating pseudo-Boolean (PB) constraints into CNF. The procedure is needed in almost every SAT-based WPMaxSAT algorithm and its efficiency surely affects the overall performance of the solver."
    }, {
      "heading" : "7.1 Introduction",
      "text" : "A PB constraint is a linear constraint over Boolean variables. PB constraints are intensively used in expressing NP-hard problems. While there are dedicated solvers (such as Sat4j) for solving PB constraints, there are good reasons to be interested in transforming the constraints into SAT (CNF formulae), and a number of methods for doing this have been reported[53, 12, 36, 2, 55, 33, 1, 13].\nDefinition 7.1 (PB constraint). A PB constraint is an inequality (equality) on a linear combination of Boolean literals li\nn∑ i=1 aili{<,≥,=,≤, >}K\nwhere a1, . . . , an and K (called the bound) are constant integers and l1, . . . , ln are literals.\nThere are at least two clear benefits of solving PB constraints by encoding them into CNF. First, high-performance SAT solvers are being enhanced continuously, and since they take a standard input format there is always a selection of good solvers to make use of. Second, solving problems involving Boolean combinations of constraints is straightforward. This approach is particularly attractive for problems which are naturally represented by a relatively small number of PB constraints (like the Knapsack problem) together which a large number of purely Boolean constraints."
    }, {
      "heading" : "7.2 Encoding method",
      "text" : "We present the method of Bailleux, Boufkhad and Roussel[13]. In their paper, they consider (without loss of generality) PB constraints of the form ∑n i=1 aili ≤ K, where a1 ≤ a2 ≤ · · · ≤ an. This type of constraint is denoted by the triple 〈An, Ln,K〉, where An = (a1, . . . , an) and Ln = (l1, . . . , ln). For some bound b, the triple 〈Ai, Li, b〉, for 1 ≤ i ≤ n, represents the PB constraint aili + a2l2 + · · · + aili ≤ b. When the tuples An and Ln are fixed, a triple 〈Ai, Li, b〉 representing a PB constraint is defined with no ambiguity by the integer i and the bound b.\nFor each 〈Ai, Li, b〉, a new variable Di,b is introduced. This new variable represents the satisfaction of the constraint 〈Ai, Li, b〉, i.e., Di,b = True if and only if 〈Ai, Li, b〉 is satisfied. The variable Dn,K represents 〈An, Ln,K〉 and the correctness of the encoding is conditioned by the fact that an assignment satisfies 〈An, Ln,K〉 if and only if it satisfies the encoded CNF formula and fixes Dn,K to True.\nThe variables Di,b such that b ≤ 0 or b ≥ ∑i j=1 aj are called terminal variables.\nThe encoding starts with a set of variables containing the original variables PB constraint and the variable Dn,K . The variables li are marked. At each step, an unmarked variable Di,b is considered. If Di,b is not terminal the two variables Di−1,b and Di−1,b−ai are added to the set of variables if they are not already in it and the following four clauses are added\n(¬Di−1,b−ai ∨Di,b), (Di,b ∨Di−1,b), (Di,b ∨ li ∨Di−1,b−ai), (Di−1,b ∨ li ∨Di,b)\nNext, Di,b is marked so it won’t be considered again. In case that Di,b is a terminal variable, then by definition either b ≤ 0 or b ≥ ∑i j=1 aj\nand Di,b is fixed as follows\nDi,b = { False if b < 0. The clause ¬Di,b is added to the formula. True if ∑i j=1 aj ≤ b. The clause Di,b is added to the formula.\nWhen b = False, every variable in the constraint must be set to False. To achieve this, for every 1 ≤ j ≤ i, the clauses (Di,0∨lj) are added together with the clause (l1∨l2∨· · ·∨Di,0). The procedure stops when there are no more unmarked variables.\nExample 7.1. This example illustrates the encoding of the PB constraint 2x1+3x2+4x3 ≤ 6. The formula φ = {(¬D2,2 ∨ D3,6), (¬D3,6 ∨ ¬x3 ∨ D2,2), (¬D2,6 ∨ x3 ∨ D3,6), (D2,6 ∨ ¬D1,−1∨D2,2), (¬D2,2∨D1,2), (¬D2,2∨¬x2∨D1,−1), (¬D1,2∨x2∨D2,2), (D1,2), (¬D1,−1)}. Thus, D3,6 = True only if at least one of x2 or x3 is False.\nThe correctness and the complexity of the encoding are discussed in the same paper[13]."
    }, {
      "heading" : "7.3 Complexity of the encoding",
      "text" : "The complexity of the encoding is measured in terms of the number of variables. The number of clauses produced is related by a constant factor to the number of variables. There are cases where the previous procedure produces a polynomial and others that produce an exponential number of variables."
    }, {
      "heading" : "7.3.1 Polynomial cases",
      "text" : "The encoding seems to generate an exponential number of variables: at each step a nonterminal variable creates two variables that will in turn create two other variables each and so on. However, this is not true for terminal variables and for variables that have already been considered by the procedure. When a terminal variable is met, it is said to be a cut in the procedure and when a variable already in the set of variables is met, it is said to have merged in the procedure. By the cuts and merges, the size of encodings can be polynomial in some cases. There are two restrictions on the PB constraint for it to have a polynomial-size encoding:\n1. The integers ai’s are bounded by a polynomial in n, P (n). In this case, the potential number of Di,b variables for some i is 2\nn−i but because of the merges, this number reduces to a polynomial since the variables Di,b for some i are such that m ≤ b ≤M where m is at least equal to K − ∑i j=0 an−j and M ≤ K, b can take at most M?m\ndifferent values and then it can take at most ∑i j=0 an?j different values, which is bounded by (n − i)P (n). Since there are n different possible values for i, the total number of variables is bounded by a polynomial in n. Figure 1 shows an example of this case.\n2. The weights are ai = αi where α ≥ 2. In this case, for every non terminal variable Di,b considered in the procedure, at least one of the variables Di−1,b or Di−1,b?αi is a terminal variable. This is true because ∑i?1 j=0 α\nj < αi. Either b ≥ αi and then ∑i−1 j=0 α j < b and then Di−1,b is a terminal variable or b < α i and in this case Di−1,b−αi is a terminal variable. Thus, there is a cut each time a variable is considered in the procedure. Figure 2 shows an example for this case."
    }, {
      "heading" : "7.3.2 Exponential cases",
      "text" : "There are possible sequences of ai’s that will give a tree with branches of length Ω(n) and with no possible merge of nodes (which implies a tree of size Ω(2n)). The idea here is simply to combine a constant sequence with a geometric sequence. Let n be the length of the PB constraint Q and let ai = α + b\ni such that α = bn+2. The key point is that the geometric term must be negligible compared to the constant term, that is ∑n i=0 b\ni < α. For simplicity, we will choose b = 2. Note that in this case, ai = 2\nn+2 + 2i which is not bounded by a polynomial in n. Fix K = α× n2 = n× 2 n+1.\nA terminal node is reached when we get a term Di,k such that k ≤ 0 or k ≥ ∑i j=1 aj . Because the constant term is predominant, the first condition cannot be met before i = K α = n 2 . The earliest case where the second condition can be satisfied is when k remains\nequal to K. We have ∑i j=1 aj = ∑i j=1 α + b j = α × i + ∑i j=1 b\nj ≥ α × i. Therefore, the earliest case where the second condition can be met is when α × n2 = α × i which means i = n2 . We can conclude that each branch is at least of length n 2 .\nIn addition, in the encoding, each node of the tree holds the term Di,k which corresponds to ∑i j=1 ajxj ≤ K − ∑ j∈S aj , where S ⊂ [i + 1..n]. One key point is that in the\nbinary representation of K − ∑ j∈S aj , the n least significant bits directly correspond to the indices in S. Therefore, these n least significant bits of the right term are necessarily different from one node to another. For this reason, no node can be merged. Because of this and since branches are of length at least equal to n2 , the size of the tree is at least 2 n 2 and the encoding of this particular constraint is of exponential size."
    }, {
      "heading" : "7.4 Other encoding techniques",
      "text" : "Incremental approaches[42, 39, 47] allow the constraint solver to retain knowledge from previous iterations that may be used in the upcoming iterations. The goal is to retain the inner state of the constraint solver as well as learned clauses that were discovered during the solving process of previous iterations. At each iteration, most MaxSAT algorithms create a new instance of the constraint solver and rebuild the formula losing most if not all the knowledge that could be derived from previous iterations."
    }, {
      "heading" : "8 Experimental Investigation",
      "text" : "We conducted an experimental investigation in order to compare the performance of different WPMaxSAT solvers to branch and bound solvers on a number of benchmarks instances.\nExperimental evaluations of MaxSAT solvers has gained great interest among SAT and MaxSAT researchers. This is due to the fact that solvers are becoming more and more efficient and adequate to handle WPMaxSAT instances coming from real-life applications. Thus, carrying out such an investigation and comparing the efficiency of different solvers is critical to knowing which solving technique is suitable for which category of inputs. In fact, an annual event called the MaxSAT Evaluations is scheduled just for this purpose. The first MaxSAT Evaluation was held in 2006. The objective of the MaxSAT Evaluation is comparing the performance of state of the art (weighted) (partial) MaxSAT solvers on a number of benchmarks and declaring a winner for each benchmark category.\nThe solvers that we investigate participated in the MaxSAT Evaluations of 2013 and 2014. A number of the solvers are available online while some of them were not and we had to contact the authors to get a copy. The benchmarks we used participated in the 2013 MaxSAT Evaluation and are WPMaxSAT instances of three categories: random, crafted and industrial.\nThe solvers were run on a machine with an IntelrCoreTM i5 CPU clocked at 2.4GHz, with 5.7GB of RAM running elementary OS Linux. The timeout is set to 1000 seconds and running the solvers on the benchmarks took roughly three months. We picked elementaryOS because it does not consume too many resources to run and thus giving enough room for the solvers to run. In addition, elementaryOS is compatible with popular Ubuntu distribution which makes it compatible with its repositories and packages."
    }, {
      "heading" : "8.1 Solvers descriptions",
      "text" : "The solvers we experimented with are:\n1. WMiFuMax is an unsatisfiability-based WPMaxSAT solver based on the technique of Fu and Malik[18] and on the algorithm by Manquinho, Marques-Silva, and Planes[32], which is works by identifying unsatisfiable sub-formulae. MiFuMax placed third in the WPMaxSAT industrial category of the 2013 MaxSAT evaluation. The solver (and the source code) is available online under the GNU General Public License. The SAT solver used is called MiniSAT[54]. Author: Mikoláš Janota.\n2. QWMaxSAT is a weighted version of QMaxSAT developed by Koshimura, Zhang, Fujita and Hasegawa[25] and is available freely online. This solver is a satisfiabilitybased solver built on top of version 2.0 of the SAT solver MiniSAT[16]. The authors of QMaxSAT modified only the top-level part of MiniSat to manipulate cardinality constraints, and the other parts remain unchanged. Despite originally being a PMaxSAT solver, the authors developed a version of the solver for WPMaxSAT in 2014. Authors: Miyuki Koshimura, Miyuki Koshimura, Hiroshi Fujita and Ryuzo Hasegawa.\n3. Sat4j[27] is a satisfiability-based WPMaxSAT solver developed by Le Berre and Parrain. The solver works by translating WPMaxSAT instances into pseudo-Boolean optimization ones. The idea is to add a blocking variable per weighted soft clause that represents that such clause has been violated, and to translate the maximization\nproblem on those weighted soft clauses into a minimization problem on a linear function over those variables. Given a WPMaxSAT instance φ = {(C1, w1), . . . , (Cn, wn)}∪ φH , Sat4j translates φ into φ\n′ = {(C1 ∨ b1), . . . , (Cn ∨ bn)} plus an objective function min : ∑n i=1 wibi. Sat4j avoids adding blocking variables to both hard and unit clauses. the Sat4j framework includes the pseudo-Boolean solver Sat4j-PB-Res which is used to solve the encoded WPMaxSAT problem. Authors: Daniel Le Berre and Emmanuel Lonca.\n4. MSUnCore[35] is an unsatisfiability-based WPMaxSAT solver built on top the SAT solver PicoSAT[14]. This solver implements a number of algorithms capable of solving MaxSAT, PMaxSAT and W(P)MaxSAT. MSUnCore uses PicoSAT for iterative identification of unsatisfiable cores with larger weights. Although ideally a minimal core would be preferred, any unsatisfiable core can be considered. Clauses in identified core are then relaxed by adding a relaxation variable to each clause. Cardinality constraints are encoded using several encodings, such as the pairwise and bitwise encodings[49, 48], the ladder encoding[20], sequential counters[53], sorting networks[17], and binary decision diagrams (BDDs)[17]. Authors: António Morgado, Joao Marques-Silva, and Federico Heras.\n5. Maxsatz2013f is a very successful branch and bound solver that placed first in the WPMaxSAT random category of the 2013 MaxSAT evaluation. It is based on an earlier solver called Maxsatz[28], which incorporates the technique developed for the famous SAT solver, Satz[29]. At each node, it transforms the instance into an equivalent one by applying efficient refinements of unit resolution ((A∨B) and (¬B) yield A) which replaces {(x), (y), (¬x∨¬y)} with { , (x∨y)} and {(x), (¬x∨y), (¬x∨ z), (¬y∨¬z)} with { , (¬x∨y∨z), (x∨¬y∨¬z)}. Also, it implements a lower bound method (enhanced with failed literal detection) that increments the lower bound by one for every disjoint inconsistent subset that is detected by unit propagation. The variable selection heuristics takes into account the number of positive and negative occurrences in binary and ternary clauses. Maxsatz2013f is available freely online. Authors: Chu Min Li, Yanli LIU, Felip Manyà, Zhu Zhu and Kun He.\n6. WMaxSatz-2009 and WMaxSatz+[31, 30] are branch and bound solvers that use transformation rules[28] which can be implemented efficiently as a by-product of unit propagation or failed literal detection. This means that the transformation rules can be applied at each node of the search tree. Authors: Josep Argelich, Chu Min Li, Jordi Planes and Felip Manyà.\n7. ISAC+[9] (Instance-Specific Algorithm Configuration) is a portfolio of algorithm which, given a WPMaxSAT instance, selects the solver better suited for that instance. A regression function is trained to predict the performance of every solver in the given set of solvers based on the features of an instance. When faced with a new instance, the solver with the best predicted runtime is run on the given instance. ISAC+ uses a number of branch and bound solvers as well as SAT-based, including QMaxSAT, WMaxSatz-2009 and WMaxSatz+. Authors: Carlos Ansótegui, Joel Gabas, Yuri Malitsky and Meinolf Sellmann.\nSummary Technique Solver name Sub-technique\nSatisfiability-based WMiFuMax SAT-based QWMaxSAT SAT-based Sat4j SAT-based MSUnCore UNSAT-based Branch and bound Maxsatz2013f WMaxSatz-2009 WMaxSatz+ Portfolio ISAC+"
    }, {
      "heading" : "8.2 Benchmarks descriptions",
      "text" : "The benchmarks we used are the WPMaxSAT instances of the 2013 MaxSAT Evaluation and are divided into three categories:\n1. Random: This category consists of WPMax-2-SAT and WPMax-3-SAT instances generated uniformly at random. The WPMax-2-SAT instances are divided into formulae with low (lo), medium (me) and high (hi) numbers of variables and clauses. The WPMax-3-SAT instances contain three literals per clause and have a high number of variables and clauses.\n2. Crafted: These instances are specifically designed to give a hard time to the solver. There is an award for the smallest instance that can not be solved by any solver.\n3. Industrial: Consists of instances that come from various applications of practical interest, such as model checking, planning, encryption, bio-informatics, etc. encoded into MaxSAT. This category is intended to provide a snapshot of the current strength of solvers as engines for SAT-based applications.\nIn the MaxSAT Evaluations, a first, second and third place winners are declared for each of the three categories."
    }, {
      "heading" : "8.3 Results",
      "text" : "In this section, the results we obtained are presented and discussed. For each category, we present the constituting sets of instances and their sizes, the number of instances solved by each solver and the amount of time it took each solver to work on each set of instances."
    }, {
      "heading" : "8.3.1 Random category",
      "text" : "The three sets of instances in the random category are:\nName Abbreviation # of instances wpmax2sat-lo lo 30 wpmax2sat-me me 30 wpmax2sat-hi hi 30 wpmax3sat-hi 3hi 30\nThe branch and bound solvers MaxSatz2013f, WMaxSatz-2009 and WMaxSatz+ performed considerably better than the SAT-based solvers in the random category. In particular, MaxSatz2013f finished the four benchmarks under 16 minutes, while WMiFuMax, MSUnCore and Sat4j timedout on most instances. MaxSatz2013f placed first in the random category in the 2013 MaxSAT Evaluation, see http://www.maxsat.udl.cat/13/results/ index.html#wpms-random-pc. The top non branch and bound solver is ISAC+, which placed third in the random category in 2014 (see http://www.maxsat.udl.cat/14/results/index.html# wpms-random-pc)."
    }, {
      "heading" : "8.3.2 Crafted category",
      "text" : "The seven sets of instances in the crafted category are:\nAs it can be noticed from the results, ISAC+ is the winner of the crafted category. Indeed, the winner of this category in the 2014 MaxSAT Evaluation is ISAC+ (see http://www.maxsat.udl.cat/14/results/index.html#wpms-crafted), and in the 2013 evaluation it placed second (see http://www.maxsat.udl.cat/13/results/index.html#wpms-crafted-pc). Generally, SAT-based and branch and bound solvers perform nearly equally on crafted instances."
    }, {
      "heading" : "8.3.3 Industrial category",
      "text" : "The seven sets of instance in the industrial category are:\nName Abbreviation # of instances wcsp/spot5/dir wcsp-dir 21 wcsp/spot5/log wcsp-log 21 haplotyping-pedigrees HT 100 upgradeability-problem UP 100 preference planning PP 29 packup-wpms PWPMS 99 timetabling TT 26\nIt is clear that SAT-based solvers outperform branch and bound ones on industrial\ninstances. The winner solver of this category in the 2013 MaxSAT evaluation is ISAC+ (see http://www.maxsat.udl.cat/13/results/index.html#wpms-industrial) and the same solver placed second in the 2014 evaluation (see http://www.maxsat.udl.cat/14/results/index.html# wpms-industrial-pc).\nGenerally, we can notice that on industrial instances, SAT-based solvers are performed considerably better than branch and bound solvers which performed poorly. On the other hand, branch and bound solvers outperformed SAT-based ones on random instances."
    }, {
      "heading" : "9 Acknowledgments",
      "text" : "This paper is made possible through the help and support from Dr. Hassan Aly (Department of Mathematics, Cairo University, Egypt) and Dr. Rasha Shaheen (Department of Mathematics, Cairo University, Egypt). I would also like to thank Dr. Carlos Ansótegui (University of Lleida, Spain) for his advice to include a section on translating pseudo Boolean constraints and his encouraging review of this work."
    } ],
    "references" : [ {
      "title" : "Translating pseudo-boolean constraints into cnf",
      "author" : [ "Amir Aavani" ],
      "venue" : "Theory and Applications of Satisfiability Testing-SAT",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2011
    }, {
      "title" : "New encoding for translating pseudo-boolean constraints into sat",
      "author" : [ "Amir Aavani", "David G Mitchell", "Eugenia Ternovska" ],
      "venue" : "In SARA,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2013
    }, {
      "title" : "Qmaxsat version",
      "author" : [ "Xuanye An", "Miyuki Koshimura", "Hiroshi Fujita", "Ryuzo Hasegawa" ],
      "venue" : "Proceedings of the International Workshop on First-Order Theorem Proving,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2011
    }, {
      "title" : "Solving (weighted) partial maxsat through satisfiability testing",
      "author" : [ "Carlos Ansótegui", "Maŕıa Bonet", "Jordi Levy" ],
      "venue" : "Theory and Applications of Satisfiability Testing-SAT",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2009
    }, {
      "title" : "Improving satbased weighted maxsat solvers",
      "author" : [ "Carlos Ansótegui", "Maria Luisa Bonet", "Joel Gabàs", "Jordi Levy" ],
      "venue" : "In Principles and Practice of Constraint Programming,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2012
    }, {
      "title" : "Improving wpm2 for (weighted) partial maxsat",
      "author" : [ "Carlos Ansótegui", "Maria Luisa Bonet", "Joel Gabàs", "Jordi Levy" ],
      "venue" : "In Principles and Practice of Constraint Programming,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2013
    }, {
      "title" : "A new algorithm for weighted partial maxsat",
      "author" : [ "Carlos Ansótegui", "Maria Luisa Bonet", "Jordi Levy" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2010
    }, {
      "title" : "Sat-based maxsat algorithms",
      "author" : [ "Carlos Ansótegui", "Maria Luisa Bonet", "Jordi Levy" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2013
    }, {
      "title" : "Maxsat by improved instance-specific algorithm configuration",
      "author" : [ "Carlos Ansótegui", "Yuri Malitsky", "Meinolf Sellmann" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2014
    }, {
      "title" : "The first and second max-sat evaluations",
      "author" : [ "Josep Argelich", "Chu Min Li", "Felip Manya", "Jordi Planes" ],
      "venue" : "JSAT, 4(2-4):251–278,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2008
    }, {
      "title" : "Curriculum-based course timetabling with sat and maxsat",
      "author" : [ "Roberto Aśın Achá", "Robert Nieuwenhuis" ],
      "venue" : "Annals of Operations Research,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2012
    }, {
      "title" : "Efficient cnf encoding of boolean cardinality constraints",
      "author" : [ "Olivier Bailleux", "Yacine Boufkhad" ],
      "venue" : "In Principles and Practice of Constraint Programming–CP",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2003
    }, {
      "title" : "A translation of pseudoboolean constraints to sat",
      "author" : [ "Olivier Bailleux", "Yacine Boufkhad", "Olivier Roussel" ],
      "venue" : "Journal on Satisfiability, Boolean Modeling and Computation,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2006
    }, {
      "title" : "Postponing optimization to speed up maxsat solving",
      "author" : [ "Jessica Davies", "Fahiem Bacchus" ],
      "venue" : "In Principles and Practice of Constraint Programming,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2013
    }, {
      "title" : "Minisat: A sat solver with conflict-clause",
      "author" : [ "Niklas Een", "Niklas Sörensson" ],
      "venue" : "minimization. Sat,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2005
    }, {
      "title" : "Translating pseudo-boolean constraints into sat",
      "author" : [ "Niklas Eén", "Niklas Sörensson" ],
      "venue" : "JSAT, 2(1-4):1–26,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2006
    }, {
      "title" : "On solving the partial max-sat problem",
      "author" : [ "Zhaohui Fu", "Sharad Malik" ],
      "venue" : "Theory and Applications of Satisfiability Testing-SAT",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2006
    }, {
      "title" : "Arc consistency in sat",
      "author" : [ "Ian P Gent" ],
      "venue" : "In ECAI,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2002
    }, {
      "title" : "A new encoding of alldifferent into sat",
      "author" : [ "Ian P Gent", "Peter Nightingale" ],
      "venue" : "In Proc. 3rd International Workshop on Modelling and Reformulating Constraint Satisfaction Problems,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2004
    }, {
      "title" : "Read-once resolution for unsatisfiabilitybased max-sat algorithms",
      "author" : [ "Federico Heras", "Joao Marques-Silva" ],
      "venue" : "In Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume One,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2011
    }, {
      "title" : "Core-guided binary search algorithms for maximum satisfiability",
      "author" : [ "Federico Heras", "Antonio Morgado", "Joao Marques-Silva" ],
      "venue" : "In Proceedings of the AAAI National Conference (AAAI),",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2011
    }, {
      "title" : "Intractability of read-once resolution",
      "author" : [ "Kazuo Iwama", "Eiji Miyano" ],
      "venue" : "In Structure in Complexity Theory Conference,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1995
    }, {
      "title" : "Packup: Tools for package upgradability solving system description",
      "author" : [ "Mikoláš Janota", "Inês Lynce", "Vasco Manquinho", "Joao Marques-Silva" ],
      "venue" : "Journal on Satisfiability, Boolean Modeling and Computation,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2012
    }, {
      "title" : "Qmaxsat: A partial max-sat solver system description",
      "author" : [ "Miyuki Koshimura", "Tong Zhang", "Hiroshi Fujita", "Ryuzo Hasegawa" ],
      "venue" : "Journal on Satisfiability, Boolean Modeling and Computation,",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2012
    }, {
      "title" : "A logical approach to efficient max-sat solving",
      "author" : [ "Javier Larrosa", "Federico Heras", "Simon de Givry" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2008
    }, {
      "title" : "The sat4j library, release 2.2 system description",
      "author" : [ "Daniel Le Berre", "Anne Parrain" ],
      "venue" : "Journal on Satisfiability, Boolean Modeling and Computation,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2010
    }, {
      "title" : "Exploiting cycle structures in max-sat",
      "author" : [ "Chu Li", "Felip Manyà", "Nouredine Mohamedou", "Jordi Planes" ],
      "venue" : "Theory and Applications of Satisfiability Testing-SAT",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2009
    }, {
      "title" : "Heuristics based on unit propagation for satisfiability problems",
      "author" : [ "Chu Min Li", "Anbulagan Anbulagan" ],
      "venue" : "In Proceedings of the 15th international joint conference on Artifical intelligence-Volume",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1997
    }, {
      "title" : "Resolutionbased lower bounds in maxsat",
      "author" : [ "Chu Min Li", "Felip Manyà", "Nouredine Ould Mohamedou", "Jordi Planes" ],
      "venue" : null,
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2010
    }, {
      "title" : "New inference rules for max-sat",
      "author" : [ "Chu Min Li", "Felip Manyà", "Jordi Planes" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2007
    }, {
      "title" : "Algorithms for weighted boolean optimization",
      "author" : [ "Vasco Manquinho", "Joao Marques-Silva", "Jordi Planes" ],
      "venue" : "Theory and Applications of Satisfiability Testing-SAT",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2009
    }, {
      "title" : "A more compact translation of pseudo-boolean constraints into cnf such that generalized arc consistency is maintained",
      "author" : [ "Norbert Manthey", "Tobias Philipp", "Peter Steinke" ],
      "venue" : "In KI 2014: Advances in Artificial Intelligence,",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2014
    }, {
      "title" : "Timetabling based on sat encoding: a case study",
      "author" : [ "Filip Maric" ],
      "venue" : null,
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 2008
    }, {
      "title" : "The msuncore maxsat solver. SAT 2009 competitive events booklet: preliminary version, page",
      "author" : [ "Joao Marques-Silva" ],
      "venue" : null,
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2009
    }, {
      "title" : "Towards robust cnf encodings of cardinality constraints. Principles and Practice of Constraint Programming–CP",
      "author" : [ "Joao Marques-Silva", "Inês Lynce" ],
      "venue" : null,
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2007
    }, {
      "title" : "On using unsatisfiability for solving maximum satisfiability",
      "author" : [ "Joao Marques-Silva", "Jordi Planes" ],
      "venue" : "arXiv preprint arXiv:0712.1097,",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 2007
    }, {
      "title" : "Algorithms for maximum satisfiability using unsatisfiable cores",
      "author" : [ "Joao Marques-Silva", "Jordi Planes" ],
      "venue" : "In Proceedings of the conference on Design, automation and test in Europe,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2008
    }, {
      "title" : "Incremental cardinality constraints for maxsat",
      "author" : [ "Ruben Martins", "Saurabh Joshi", "Vasco Manquinho", "Inês Lynce" ],
      "venue" : "In Principles and Practice of Constraint Programming,",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 2014
    }, {
      "title" : "A max-sat algorithm portfolio1",
      "author" : [ "Paulo Matos", "Jordi Planes", "Florian Letombe", "Joao Marques-Silva" ],
      "venue" : null,
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2008
    }, {
      "title" : "A pso algorithm to solve a real course+ exam timetabling problem",
      "author" : [ "Elizabeth Montero", "Maŕıa-Cristina Riff", "Leopoldo Altamirano" ],
      "venue" : "In International Conference on Swarm Intelligence,",
      "citeRegEx" : "41",
      "shortCiteRegEx" : "41",
      "year" : 2001
    }, {
      "title" : "Core-guided maxsat with soft cardinality constraints",
      "author" : [ "Antonio Morgado", "Carmine Dodaro", "Joao Marques-Silva" ],
      "venue" : "In Principles and Practice of Constraint Programming,",
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2014
    }, {
      "title" : "Iterative and core-guided maxsat solving: A survey and assessment",
      "author" : [ "Antonio Morgado", "Federico Heras", "Mark Liffiton", "Jordi Planes", "Joao Marques- Silva" ],
      "venue" : null,
      "citeRegEx" : "43",
      "shortCiteRegEx" : "43",
      "year" : 2013
    }, {
      "title" : "Chaff: Engineering an efficient sat solver",
      "author" : [ "Matthew W Moskewicz", "Conor F Madigan", "Ying Zhao", "Lintao Zhang", "Sharad Malik" ],
      "venue" : "In Proceedings of the 38th annual Design Automation Conference,",
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 2001
    }, {
      "title" : "Application of satisfiability algorithms to timetable problems",
      "author" : [ "Fahima NADER", "Mouloud KOUDIL", "Karima BENATCHBA", "Lotfi ADMANE", "Said GHAROUT", "Nacer HAMANI" ],
      "venue" : "Rapport Interne LMCS, INI,",
      "citeRegEx" : "45",
      "shortCiteRegEx" : "45",
      "year" : 2004
    }, {
      "title" : "A comparative study of two boolean formulations of fpga detailed routing",
      "author" : [ "G-J Nam", "Fadi Aloul", "Karem A. Sakallah", "Rob A. Rutenbar" ],
      "venue" : "IEEE Transactions on,",
      "citeRegEx" : "46",
      "shortCiteRegEx" : "46",
      "year" : 2004
    }, {
      "title" : "Maximum satisfiability using core-guided maxsat resolution",
      "author" : [ "Nina Narodytska", "Fahiem Bacchus" ],
      "venue" : "In AAAI,",
      "citeRegEx" : "47",
      "shortCiteRegEx" : "47",
      "year" : 2014
    }, {
      "title" : "Variable dependency in local search: Prevention is better than cure",
      "author" : [ "Steven Prestwich" ],
      "venue" : "In Theory and Applications of Satisfiability Testing–SAT",
      "citeRegEx" : "48",
      "shortCiteRegEx" : "48",
      "year" : 2007
    }, {
      "title" : "Protein structure alignment using maximum cliques and local search",
      "author" : [ "Wayne Pullan" ],
      "venue" : "In AI 2007: Advances in Artificial Intelligence,",
      "citeRegEx" : "50",
      "shortCiteRegEx" : "50",
      "year" : 2007
    }, {
      "title" : "Improved design debugging using maximum satisfiability",
      "author" : [ "Sean Safarpour", "Hratch Mangassarian", "Andreas Veneris", "Mark H Liffiton", "Karem Sakallah" ],
      "venue" : "In Formal Methods in Computer Aided Design, 2007",
      "citeRegEx" : "51",
      "shortCiteRegEx" : "51",
      "year" : 2007
    }, {
      "title" : "A dynamic approach to mpe and weighted max-sat",
      "author" : [ "Tian Sang", "Paul Beame", "Henry Kautz" ],
      "venue" : "In Proceedings of the 20th international joint conference on Artifical intelligence,",
      "citeRegEx" : "52",
      "shortCiteRegEx" : "52",
      "year" : 2007
    }, {
      "title" : "Towards an optimal cnf encoding of boolean cardinality constraints. Principles and Practice of Constraint Programming-CP",
      "author" : [ "Carsten Sinz" ],
      "venue" : null,
      "citeRegEx" : "53",
      "shortCiteRegEx" : "53",
      "year" : 2005
    }, {
      "title" : "Pbliba c++ toolkit for encoding pseudo–boolean constraints into cnf",
      "author" : [ "Peter Steinke", "Norbert Manthey" ],
      "venue" : null,
      "citeRegEx" : "55",
      "shortCiteRegEx" : "55",
      "year" : 2014
    }, {
      "title" : "A “logic-constrained” knapsack formulation and a tabu algorithm for the daily photograph scheduling of an earth observation satellite",
      "author" : [ "Michel Vasquez", "Jin-Kao Hao" ],
      "venue" : "Computational Optimization and Applications,",
      "citeRegEx" : "56",
      "shortCiteRegEx" : "56",
      "year" : 2001
    }, {
      "title" : "A linear-time transformation of linear inequalities into conjunctive normal form",
      "author" : [ "Joost P Warners" ],
      "venue" : "Information Processing Letters,",
      "citeRegEx" : "57",
      "shortCiteRegEx" : "57",
      "year" : 1998
    }, {
      "title" : "sub-sat: A formulation for relaxed boolean satisfiability with applications in routing",
      "author" : [ "Hui Xu", "Rob A Rutenbar", "Karem Sakallah" ],
      "venue" : "Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on,",
      "citeRegEx" : "58",
      "shortCiteRegEx" : "58",
      "year" : 2003
    }, {
      "title" : "Satzilla: portfoliobased algorithm selection for sat",
      "author" : [ "Lin Xu", "Frank Hutter", "Holger H Hoos", "Kevin Leyton-Brown" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "59",
      "shortCiteRegEx" : "59",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 48,
      "context" : "Many theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 52,
      "context" : "Many theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].",
      "startOffset" : 187,
      "endOffset" : 191
    }, {
      "referenceID" : 10,
      "context" : "Many theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].",
      "startOffset" : 212,
      "endOffset" : 228
    }, {
      "referenceID" : 43,
      "context" : "Many theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].",
      "startOffset" : 212,
      "endOffset" : 228
    }, {
      "referenceID" : 39,
      "context" : "Many theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].",
      "startOffset" : 212,
      "endOffset" : 228
    }, {
      "referenceID" : 32,
      "context" : "Many theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].",
      "startOffset" : 212,
      "endOffset" : 228
    }, {
      "referenceID" : 22,
      "context" : "Many theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].",
      "startOffset" : 256,
      "endOffset" : 260
    }, {
      "referenceID" : 54,
      "context" : "Many theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].",
      "startOffset" : 270,
      "endOffset" : 278
    }, {
      "referenceID" : 44,
      "context" : "Many theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].",
      "startOffset" : 270,
      "endOffset" : 278
    }, {
      "referenceID" : 49,
      "context" : "Many theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].",
      "startOffset" : 290,
      "endOffset" : 294
    }, {
      "referenceID" : 47,
      "context" : "Many theoretical and practical problems can be encoded into SAT and MaxSAT such as debugging [51], circuits design and scheduling of how an observation satellite captures photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24], routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].",
      "startOffset" : 345,
      "endOffset" : 349
    }, {
      "referenceID" : 41,
      "context" : "Recent comprehensive surveys on SAT-based algorithms can be found in[43, 8].",
      "startOffset" : 68,
      "endOffset" : 75
    }, {
      "referenceID" : 7,
      "context" : "Recent comprehensive surveys on SAT-based algorithms can be found in[43, 8].",
      "startOffset" : 68,
      "endOffset" : 75
    }, {
      "referenceID" : 2,
      "context" : "[3] developed a PMaxSAT algorithm called QMaxSAT (version 0.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 16,
      "context" : "This method was first proposed in 2006 by Fu and Malik in[18] (see algorithm 6).",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 16,
      "context" : "Fu and Malik’s algorithm[18]",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 3,
      "context" : "WPM1[4]",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 4,
      "context" : "Improved WPM1[5]",
      "startOffset" : 13,
      "endOffset" : 16
    }, {
      "referenceID" : 6,
      "context" : "WPM2[7]",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 19,
      "context" : "WMSU1-ROR[21]",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 35,
      "context" : "WMSU3[37]",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 36,
      "context" : "WMSU4[38]",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 13,
      "context" : "A minimal unsatisfiable core is an unsatisfiable core such that any proper subset of it is not a core[15].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 42,
      "context" : "Fu and Malik implemented two PMaxSAT solvers, ChaffBS (uses binary search to find the optimal cost) and ChaffLS (uses linear search to find the optimal cost) on top of a SAT solver called zChaff[44].",
      "startOffset" : 194,
      "endOffset" : 198
    }, {
      "referenceID" : 9,
      "context" : "Their PMaxSAT solvers participated in the first and second MaxSAT Evaluations[10].",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 3,
      "context" : "Ansótegui, Bonet and Levy[4] extended Fu& Malik to WPMaxSAT.",
      "startOffset" : 25,
      "endOffset" : 28
    }, {
      "referenceID" : 4,
      "context" : "In 2012, Ansótegui, Bonet and Levy presented a modification to WPM1 (algorithm 7)[5].",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 35,
      "context" : "In 2007, Marques-Silva and Planes[37] discussed important properties of Fu&Malik that were not mentioned in[18].",
      "startOffset" : 33,
      "endOffset" : 37
    }, {
      "referenceID" : 16,
      "context" : "In 2007, Marques-Silva and Planes[37] discussed important properties of Fu&Malik that were not mentioned in[18].",
      "startOffset" : 107,
      "endOffset" : 111
    }, {
      "referenceID" : 17,
      "context" : "Fu&Malik use the pairwise encoding[19] for the constraints on the relaxation variables, which use a quadratic number of clauses.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 53,
      "context" : "Instead, Marques-Silva and Planes suggested several other encodings all of which are linear in the number of variables in the constraint[57, 53, 17, 19].",
      "startOffset" : 136,
      "endOffset" : 152
    }, {
      "referenceID" : 50,
      "context" : "Instead, Marques-Silva and Planes suggested several other encodings all of which are linear in the number of variables in the constraint[57, 53, 17, 19].",
      "startOffset" : 136,
      "endOffset" : 152
    }, {
      "referenceID" : 15,
      "context" : "Instead, Marques-Silva and Planes suggested several other encodings all of which are linear in the number of variables in the constraint[57, 53, 17, 19].",
      "startOffset" : 136,
      "endOffset" : 152
    }, {
      "referenceID" : 17,
      "context" : "Instead, Marques-Silva and Planes suggested several other encodings all of which are linear in the number of variables in the constraint[57, 53, 17, 19].",
      "startOffset" : 136,
      "endOffset" : 152
    }, {
      "referenceID" : 6,
      "context" : "Ansótegui, Bonet and Levy also developed an algorithm for WPMaxSAT in 2010, called WPM2[7], where every soft clause Ci is extended with a unique fresh blocking variable bi.",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 5,
      "context" : "In[6], Ansótegui et at.",
      "startOffset" : 2,
      "endOffset" : 5
    }, {
      "referenceID" : 4,
      "context" : "First, they applied the stratification technique[5].",
      "startOffset" : 48,
      "endOffset" : 51
    }, {
      "referenceID" : 19,
      "context" : "WMSU1-ROR[21] is a modification of WPM1.",
      "startOffset" : 9,
      "endOffset" : 13
    }, {
      "referenceID" : 24,
      "context" : "The MaxSAT resolution rule used in WMSU1-ROR is called Max-RES and is described in[26].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 24,
      "context" : "De Morgan’s laws can not be applied on MaxSAT instance for not preserving the equivalence among instances[26].",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 3,
      "context" : "WMSU1-ROR handles WPMaxSAT formulae the same way as[4].",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 21,
      "context" : "Unfortunately, ROR can not generate resolution proofs for some unsatisfiable clauses[23].",
      "startOffset" : 84,
      "endOffset" : 88
    }, {
      "referenceID" : 6,
      "context" : "The function UpdateBound in line 14 updates the lower bound LB, either by simply incrementing it or by the subset sum problem as in[7].",
      "startOffset" : 131,
      "endOffset" : 134
    }, {
      "referenceID" : 36,
      "context" : "Like WMSU3, WMSU4[38] (algorithm 15) adds at most one blocking variable to each soft clause.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 20,
      "context" : "Heras, Morgado and Marques-Silva proposed this technique in[22] (see algorithm 16).",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 20,
      "context" : "The core-guided binary search approach was improved by Heras[22] et al.",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 38,
      "context" : "In other words, different solution approaches work well on different families of instances[40].",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 55,
      "context" : "The success of SATzilla[59] for SAT was due to a regression function which was trained to predict the performance of every solver in the given set of solvers based on the features of an instance.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 8,
      "context" : "ISAC[9] (Instance-Specific Algorithm Configuration) is one of the most successful WPMaxSAT portfolio algorithms.",
      "startOffset" : 4,
      "endOffset" : 7
    }, {
      "referenceID" : 50,
      "context" : "While there are dedicated solvers (such as Sat4j) for solving PB constraints, there are good reasons to be interested in transforming the constraints into SAT (CNF formulae), and a number of methods for doing this have been reported[53, 12, 36, 2, 55, 33, 1, 13].",
      "startOffset" : 232,
      "endOffset" : 262
    }, {
      "referenceID" : 11,
      "context" : "While there are dedicated solvers (such as Sat4j) for solving PB constraints, there are good reasons to be interested in transforming the constraints into SAT (CNF formulae), and a number of methods for doing this have been reported[53, 12, 36, 2, 55, 33, 1, 13].",
      "startOffset" : 232,
      "endOffset" : 262
    }, {
      "referenceID" : 34,
      "context" : "While there are dedicated solvers (such as Sat4j) for solving PB constraints, there are good reasons to be interested in transforming the constraints into SAT (CNF formulae), and a number of methods for doing this have been reported[53, 12, 36, 2, 55, 33, 1, 13].",
      "startOffset" : 232,
      "endOffset" : 262
    }, {
      "referenceID" : 1,
      "context" : "While there are dedicated solvers (such as Sat4j) for solving PB constraints, there are good reasons to be interested in transforming the constraints into SAT (CNF formulae), and a number of methods for doing this have been reported[53, 12, 36, 2, 55, 33, 1, 13].",
      "startOffset" : 232,
      "endOffset" : 262
    }, {
      "referenceID" : 51,
      "context" : "While there are dedicated solvers (such as Sat4j) for solving PB constraints, there are good reasons to be interested in transforming the constraints into SAT (CNF formulae), and a number of methods for doing this have been reported[53, 12, 36, 2, 55, 33, 1, 13].",
      "startOffset" : 232,
      "endOffset" : 262
    }, {
      "referenceID" : 31,
      "context" : "While there are dedicated solvers (such as Sat4j) for solving PB constraints, there are good reasons to be interested in transforming the constraints into SAT (CNF formulae), and a number of methods for doing this have been reported[53, 12, 36, 2, 55, 33, 1, 13].",
      "startOffset" : 232,
      "endOffset" : 262
    }, {
      "referenceID" : 0,
      "context" : "While there are dedicated solvers (such as Sat4j) for solving PB constraints, there are good reasons to be interested in transforming the constraints into SAT (CNF formulae), and a number of methods for doing this have been reported[53, 12, 36, 2, 55, 33, 1, 13].",
      "startOffset" : 232,
      "endOffset" : 262
    }, {
      "referenceID" : 12,
      "context" : "While there are dedicated solvers (such as Sat4j) for solving PB constraints, there are good reasons to be interested in transforming the constraints into SAT (CNF formulae), and a number of methods for doing this have been reported[53, 12, 36, 2, 55, 33, 1, 13].",
      "startOffset" : 232,
      "endOffset" : 262
    }, {
      "referenceID" : 12,
      "context" : "We present the method of Bailleux, Boufkhad and Roussel[13].",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 12,
      "context" : "The correctness and the complexity of the encoding are discussed in the same paper[13].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 40,
      "context" : "Incremental approaches[42, 39, 47] allow the constraint solver to retain knowledge from previous iterations that may be used in the upcoming iterations.",
      "startOffset" : 22,
      "endOffset" : 34
    }, {
      "referenceID" : 37,
      "context" : "Incremental approaches[42, 39, 47] allow the constraint solver to retain knowledge from previous iterations that may be used in the upcoming iterations.",
      "startOffset" : 22,
      "endOffset" : 34
    }, {
      "referenceID" : 45,
      "context" : "Incremental approaches[42, 39, 47] allow the constraint solver to retain knowledge from previous iterations that may be used in the upcoming iterations.",
      "startOffset" : 22,
      "endOffset" : 34
    }, {
      "referenceID" : 16,
      "context" : "WMiFuMax is an unsatisfiability-based WPMaxSAT solver based on the technique of Fu and Malik[18] and on the algorithm by Manquinho, Marques-Silva, and Planes[32], which is works by identifying unsatisfiable sub-formulae.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 30,
      "context" : "WMiFuMax is an unsatisfiability-based WPMaxSAT solver based on the technique of Fu and Malik[18] and on the algorithm by Manquinho, Marques-Silva, and Planes[32], which is works by identifying unsatisfiable sub-formulae.",
      "startOffset" : 157,
      "endOffset" : 161
    }, {
      "referenceID" : 23,
      "context" : "QWMaxSAT is a weighted version of QMaxSAT developed by Koshimura, Zhang, Fujita and Hasegawa[25] and is available freely online.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 14,
      "context" : "0 of the SAT solver MiniSAT[16].",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 25,
      "context" : "Sat4j[27] is a satisfiability-based WPMaxSAT solver developed by Le Berre and Parrain.",
      "startOffset" : 5,
      "endOffset" : 9
    }, {
      "referenceID" : 33,
      "context" : "MSUnCore[35] is an unsatisfiability-based WPMaxSAT solver built on top the SAT solver PicoSAT[14].",
      "startOffset" : 8,
      "endOffset" : 12
    }, {
      "referenceID" : 46,
      "context" : "Cardinality constraints are encoded using several encodings, such as the pairwise and bitwise encodings[49, 48], the ladder encoding[20], sequential counters[53], sorting networks[17], and binary decision diagrams (BDDs)[17].",
      "startOffset" : 103,
      "endOffset" : 111
    }, {
      "referenceID" : 18,
      "context" : "Cardinality constraints are encoded using several encodings, such as the pairwise and bitwise encodings[49, 48], the ladder encoding[20], sequential counters[53], sorting networks[17], and binary decision diagrams (BDDs)[17].",
      "startOffset" : 132,
      "endOffset" : 136
    }, {
      "referenceID" : 50,
      "context" : "Cardinality constraints are encoded using several encodings, such as the pairwise and bitwise encodings[49, 48], the ladder encoding[20], sequential counters[53], sorting networks[17], and binary decision diagrams (BDDs)[17].",
      "startOffset" : 157,
      "endOffset" : 161
    }, {
      "referenceID" : 15,
      "context" : "Cardinality constraints are encoded using several encodings, such as the pairwise and bitwise encodings[49, 48], the ladder encoding[20], sequential counters[53], sorting networks[17], and binary decision diagrams (BDDs)[17].",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 15,
      "context" : "Cardinality constraints are encoded using several encodings, such as the pairwise and bitwise encodings[49, 48], the ladder encoding[20], sequential counters[53], sorting networks[17], and binary decision diagrams (BDDs)[17].",
      "startOffset" : 220,
      "endOffset" : 224
    }, {
      "referenceID" : 26,
      "context" : "It is based on an earlier solver called Maxsatz[28], which incorporates the technique developed for the famous SAT solver, Satz[29].",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 27,
      "context" : "It is based on an earlier solver called Maxsatz[28], which incorporates the technique developed for the famous SAT solver, Satz[29].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 29,
      "context" : "WMaxSatz-2009 and WMaxSatz+[31, 30] are branch and bound solvers that use transformation rules[28] which can be implemented efficiently as a by-product of unit propagation or failed literal detection.",
      "startOffset" : 27,
      "endOffset" : 35
    }, {
      "referenceID" : 28,
      "context" : "WMaxSatz-2009 and WMaxSatz+[31, 30] are branch and bound solvers that use transformation rules[28] which can be implemented efficiently as a by-product of unit propagation or failed literal detection.",
      "startOffset" : 27,
      "endOffset" : 35
    }, {
      "referenceID" : 26,
      "context" : "WMaxSatz-2009 and WMaxSatz+[31, 30] are branch and bound solvers that use transformation rules[28] which can be implemented efficiently as a by-product of unit propagation or failed literal detection.",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 8,
      "context" : "ISAC+[9] (Instance-Specific Algorithm Configuration) is a portfolio of algorithm which, given a WPMaxSAT instance, selects the solver better suited for that instance.",
      "startOffset" : 5,
      "endOffset" : 8
    } ],
    "year" : 2016,
    "abstractText" : "The Maximum Satisfiability (MaxSAT) problem is the problem of finding a truth assignment that maximizes the number of satisfied clauses of a given Boolean formula in Conjunctive Normal Form (CNF). Many exact solvers for MaxSAT have been developed during recent years, and many of them were presented in the well-known SAT conference. Algorithms for MaxSAT generally fall into two categories: (1) branch and bound algorithms and (2) algorithms that use successive calls to a SAT solver (SATbased), which this paper in on. In practical problems, SAT-based algorithms have been shown to be more efficient. This paper provides an experimental investigation to compare the performance of recent SAT-based and branch and bound algorithms on the benchmarks of the MaxSAT Evaluations. 1 ar X iv :1 60 3. 03 81 4v 1 [ cs .A I] 1 1 M ar 2 01 6",
    "creator" : "LaTeX with hyperref package"
  }
}