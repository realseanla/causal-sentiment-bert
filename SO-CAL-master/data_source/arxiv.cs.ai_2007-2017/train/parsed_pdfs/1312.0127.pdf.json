{
  "name" : "1312.0127.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Characterizing and Extending Answer Set Semantics using Possibility Theory",
    "authors" : [ "KIM BAUTERS", "STEVEN SCHOCKAERT", "MARTINE DE COCK", "DIRK VERMEIR" ],
    "emails" : [ "kim.bauters@gmail.com)", "s.schockaert@cs.cardiff.ac.uk)", "martine.decock@ugent.be)", "dirk.vermeir@vub.ac.be)" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\nAnswer Set Programming (ASP) is a popular framework for modeling combinatorial problems. However, ASP cannot easily be used for reasoning about uncertain information. Possibilistic ASP (PASP) is an extension of ASP that combines possibilistic logic and ASP."
    }, {
      "heading" : "In PASP a weight is associated with each rule, where this weight is interpreted as the certainty with which the conclusion can be established when the body is known to hold.",
      "text" : "As such, it allows us to model and reason about uncertain information in an intuitive way. In this paper we present new semantics for PASP, in which rules are interpreted as constraints on possibility distributions. Special models of these constraints are then identified as possibilistic answer sets. In addition, since ASP is a special case of PASP in which all the rules are entirely certain, we obtain a new characterization of ASP in terms of constraints on possibility distributions. This allows us to uncover a new form of disjunction, called weak disjunction, that has not been previously considered in the literature. In addition to introducing and motivating the semantics of weak disjunction, we also pinpoint its computational complexity. In particular, while the complexity of most reasoning tasks coincides with standard disjunctive ASP, we find that brave reasoning for programs with weak disjunctions is easier.\nKEYWORDS: logic programming, answer set programming, possibility theory"
    }, {
      "heading" : "1 Introduction",
      "text" : "Answer set programming (ASP) is a form of logic programming with a fully declarative semantics, centered around the notion of a stable model. Syntactically, an ASP program is a set of rules of the form (head← body) where head is true whenever body is true. Possibilistic ASP (PASP) extends upon ASP by associating a weight with every rule, which is interpreted as the necessity with which we can derive the head of the rule when the body is known to hold. Semantics for PASP have been introduced in (Nicolas et al. 2006) for possibilistic normal programs and later extended to possibilistic disjunctive programs in (Nieves et al. 2013). Under these semantics, a possibilistic rule with certainty λ allows us to derive head with certainty min(λ,N(body)) where N(body) denotes the necessity of the body, i.e. the certainty of head is restricted by the least certain piece of information in the derivation chain. Specifically, to deal with PASP rules without negation-as-failure, the semantics from (Nicolas et al. 2006) treat such rules as implications in possibilistic logic (Dubois et al. 1994). When faced with negation-as-failure, the semantics from (Nicolas et al. 2006) rely on the reduct operation from classical ASP. Essentially, this means that the weights associated with the rules are initially ignored, the classical reduct is determined and the weights are then reassociated with the corresponding rules in the reduct. Given this particular treatment of negation-as-failure, the underlying intuition of ‘not l’ is “‘l’ cannot be derived with a strictly positive certainty”. Indeed, as soon as ‘l’ can be derived with a certainty λ > 0, ‘l’ is treated as true when determining the reduct. However, this particular understanding of negationas-failure is not always the most intuitive one.\nConsider the following example. You want to go to the airport, but you notice that your passport will expire in less than three months. Some countries require that the passport is at least valid for an additional three months on the date of entry. As such, you have some certainty that your passport might be invalid (invalid ). When you are not entirely certain that your passport is invalid, you should still go to the airport (airport) and check-in nonetheless. Indeed, since you are not absolutely certain that you will not be allowed to board, you might still get lucky. We have the possibilistic program:\n0.1: invalid ←\n1: airport ← not invalid\nwhere 0.1 and 1 are the weights associated with the rules (invalid ←) and airport ← invalid , respectively. Clearly, what we would like to be able to conclude with a high certainty is that you need to go to the airport to check-in. However, as the semantics from (Nicolas et al. 2006) adhere to a different intuition of negation-as-failure, the conclusion is that you need to go to the airport with a necessity of 0. Or, in other words, you should not go to the airport at all.\nAs a first contribution in this paper, we present new semantics for PASP by interpreting possibilistic rules as constraints on possibility distributions. These semantics do not correspond with the semantics from (Nicolas et al. 2006) when considering programs with negation-as-failure. Specifically, the semantics presented in\nthis paper can be used in settings in which the possibilistic answer sets according to (Nicolas et al. 2006) do not correspond with the intuitively acceptable results. For the example mentioned above, the conclusion under the new semantics is that you need to go to the airport with a necessity of 0.9.\nIn addition, the new semantics allow us to uncover a new characterization of ASP in terms of possibility theory. Over the years, many equivalent approaches have been proposed to define the notion of an answer set. One of the most popular characterizations is in terms of the Gelfond-Lifschitz reduct (Gelfond and Lifzchitz 1988) in which an answer set is guessed and verified to be stable. This characterization is used in the semantics for PASP as presented in (Nicolas et al. 2006). Alternatively, the answer set semantics of normal programs can be defined in terms of autoepistemic logic (Marek and Truszczyński 1991), a well-known non-monotonic modal logic. An important advantage of the latter approach is that autoepistemic logic enjoys more syntactic freedom, which opens the door to more expressive forms of logic programming. However, as has been shown early on in (Lifschitz and Schwarz 1993), the characterization in terms of autoepistemic logic does not allow us to treat classical negation or disjunctive rules in a natural way, which weakens its position as a candidate for generalizing ASP from normal programs to e.g. disjunctive programs. Equilibrium logic (Pearce 1997) offers yet another way for characterizing and extending ASP, but does not feature modalities which limits its potential for epistemic reasoning as it does not allow us to reason over the established knowledge of an agent. The new characterization of ASP, as presented in this paper, is a characterization in terms of necessary and contingent truths, where possibility theory is used to express our certainty in logical propositions. Such a characterization is unearthed by looking at ASP as a special case of PASP in which the rules are certain and no uncertainty is allowed in the answer sets. It highlights the intuition of ASP that the head of a rule is certain when the information encoded in its body is certain. Furthermore, this characterization stays close to the intuition of the Gelfond-Lifschitz reduct, while sharing the explicit reference to modalities with autoepistemic logic.\nAs a second contribution, we show in this paper how this new characterization of ASP in terms of possibility theory can be used to uncover a new form of disjunction in both ASP and PASP. As indicated, we have that the new semantics offer us an explicit reference to modalities, i.e. operators with which we can qualify a statement. Epistemic logic is an example of a modal logic in which we use the modal operatorK to reason about knowledge, where K is intuitively understood as “we know that”. A statement such as a∨ b∨ c can then be treated in two distinct ways. On the one hand, we can interpret this statement as Ka ∨ Kb ∨ Kc, which makes it explicit that we know that one of the disjuncts is true. This treatment corresponds with the understanding of disjunction in disjunctive ASP and will be referred to as strong disjunction. Alternatively, we can interpret a ∨ b ∨ c as K(a ∨ b ∨ c) which only states that we know that the disjunction is true, i.e. we do not know which of the disjuncts is true. We will refer to this form of disjunction as weak disjunction. This is the new form of disjunction that we will discuss in this paper, as it allows us\nto reason in settings where a choice cannot or should not be made. Still, such a framework allows for non-trivial forms of reasoning.\nConsider the following example. A SCADA (supervisory control and data acquisition) system is used to monitor the brewing of beer in an industrialised setting. To control the fermentation, the system regularly verifies an air-lock for the presence of bubbles. An absence of bubbles may be due to a number of possible causes. On the one hand there may be a production problem such as a low yeast count or low temperature. Adding yeast when the temperature is low results in a beer with a strong yeast flavour, which should be avoided. Raising the temperature when there is too little yeast present will kill off the remaining yeast and will ruin the entire batch. On the other hand, there may be technical problems. There may be a malfunction in the SCADA system, which can be verified by running a diagnostic. The operator runs a diagnostic (diagnostic), which reports back that there is no malfunction (¬malfunction). Or, alternatively, the air-lock may not be sealed correctly (noseal). The operator furthermore checks the temperature because he suspects that the temperature is the problem (verifytemp), but the defective temperature sensor returns no temperature when checked (notemp). These three technical problems require physical maintenance and the operator should send someone out to fix them. Technical problems do not affect the brewing. As such, the brewing process should not be interrupted for such problems as this will ruin the current batch. If there is a production problem, however, the brewing process needs to be interrupted as soon as possible (in addition, evidently, to interrupting the brewing process when the brewing is done). This prevents the current batch from being ruined due to over-brewing but also allows the interaction with the contents of the kettle. In particular, when the problem is diagnosed to be low yeast the solution is to add a new batch of yeast and restart the process. Similarly, low temperature can be solved by raising the kettle temperature and restarting the fermentation process. Obviously, the goal is to avoid ruining the current batch. An employer radios in that the seal is okay. We have the following program:\nlowyeast ∨ lowtemp ∨ noseal ∨malfunction ← not bubbles\ndiagnostic ←\n¬malfunction ← diagnostic\nverifytemp ←\nnotemp ← verifytemp\nmaintenance ← noseal ∨malfunction ∨ notemp\nbrew ← not (lowyeast ∨ lowtemp ∨ done)\naddyeast ← lowyeast\nraisetemp ← lowtemp\nruin ← raisetemp, not lowtemp\nruin ← addyeast , not lowyeast\nruin ← not brew , not (lowtemp ∨ lowyeast)\n← ruin\n¬noseal ←\nThe program above does not use the standard ASP syntax since we allow for disjunction in the body. Furthermore, the disjunction used in the head and the body is weak disjunction. The only information that we can therefore deduce from e.g. the first rule is (lowyeast ∨ lowtemp ∨ noseal ∨malfunction). At first, this new form of disjunction may indeed appear weaker that strong disjunction since it does not induce a choice. Still, even without inducing a choice, conclusions obtained from other rules may allow us to refine our knowledge. In particular, note that from lowyeast ∨ lowtemp ∨ noseal ∨ malfunction together with ¬malfunction and ¬noseal we can entail lowyeast ∨ lowtemp. Similarly, conclusions can also have prerequisites that are disjunctions. For example, we can no longer deduce brew since lowyeast ∨ lowtemp entails lowyeast ∨ lowtemp ∨ done. From maintenance ← noseal ∨ malfunction ∨ notemp and notemp we can deduce that we should call maintenance. However, we do not yet have enough information to diagnose whether yeast should be added or whether the temperature should be raised. The unique answer set of this program, according to the semantics of weak disjunction which we present in Section 4, is given by\n{lowyeast ∨ lowtemp,maintenance,\ndiagnostic,¬malfunction , verifytemp, notemp,¬noseal}\nThe expressiveness of weak disjunction becomes clear when we study its complexity. In particular, we show that while most complexity results coincide with the strong disjunctive semantics, the complexity of brave reasoning (deciding whether a literal ‘l’ is entailed by a consistent answer set of program P ) in absence of negationas-failure is lower for weak disjunction. Still, the expressiveness is higher than for normal programs. The complexity results are summarized in Table 1 in Section 5.\nThe remainder of this paper is organized as follows. In Section 2 we provide the reader with some important notions from answer set programming and possibilistic logic. In Section 3 we introduce new semantics for PASP which can furthermore be used to characterize normal ASP programs using possibility theory. In Section 4 we characterize disjunctive ASP in terms of constraints on possibility distributions and we discuss the complexity results of the new semantics for PASP in detail in Section 5. Related work is discussed in Section 6 and we formulate our conclusions in Section 7.\nThis paper aggregates and extends parts of our work from (Bauters et al. 2011) and substantially extends a previous conference paper (Bauters et al. 2010), which did not consider classical negation nor computational complexity. In addition, rather than limiting ourselves to atoms in this paper, we extend our work to cover the case of literals, which offer interesting and unexpected results in the face of weak disjunction. Complexity results are added for all reasoning tasks and full proofs are provided in appendix."
    }, {
      "heading" : "2 Background",
      "text" : "We start by reviewing the definitions from both answer set programming and possibilistic logic that will be used in the remainder of the paper. We then review the semantics of PASP from (Nicolas et al. 2006), a framework that combines possibilistic logic and ASP. Finally, we recall some notions from complexity theory."
    }, {
      "heading" : "2.1 Answer Set Programming",
      "text" : "To define ASP programs, we start from a finite set of atoms A. A literal is defined as an atom a or its classical negation ¬a. For L a set of literals, we use ¬L to denote the set {¬l | l ∈ L} where, by definition, ¬¬a = a. A set of literals L is consistent if L∩ ¬L = ∅. We write the set of all literals as L = (A∪¬A). A naf-literal is either a literal ‘l’ or a literal ‘l’ preceded by not, which we call the negation-as-failure operator. Intuitively, ‘not l’ is true when we cannot prove ‘l’. An expression of the form\nl0; ...; lk ← lk+1, ..., lm, not lm+1, ..., not ln\nwith li a literal for every 0 ≤ i ≤ n, is called a disjunctive rule. We call l0; ...; lk the head of the rule (interpreted as a disjunction) and lk+1, ..., lm, not lm+1, ..., not ln the body of the rule (interpreted as a conjunction). For a rule r we use head(r) and body(r) to denote the set of literals in the head, resp. the body. Specifically, we use body+(r) to denote the set of literals in the body that are not preceded by the negation-as-failure operator ‘not’ and body−(r) for those literals that are preceded by ‘not’. Whenever a disjunctive rule does not contain negation-as-failure, i.e. when n = m, we say that it is a positive disjunctive rule. A rule with an empty body, i.e. a rule of the form (l0; ...; lk ←), is called a fact and is used as a shorthand for (l0; ...; lk ← ⊤) with ⊤ a special language construct that denotes tautology. A rule with an empty head, i.e. a rule of the form (← lk+1, ..., lm, not lm+1, ..., not ln), is called a constraint rule and is used as a shorthand for the rule of the form (⊥ ← lk+1, ..., lm, not lm+1, ..., not ln) with ⊥ a special language construct that denotes contradiction.\nA (positive) disjunctive program P is a set of (positive) disjunctive rules. A normal rule is a disjunctive rule with at most one literal in the head. A simple rule is a normal rule with no negation-as-failure. A definite rule is a simple rule with no classical negation, i.e. in which all literals are atoms. A normal ( resp. simple, definite) program P is a set of normal (resp. simple, definite) rules.\nThe Herbrand base BP of a disjunctive program P is the set of atoms appearing in P . We define the set of literals that are relevant for a disjunctive program P as LitP = (BP ∪ ¬BP ). An interpretation I of a disjunctive program P is any set of literals I ⊆ LitP . A consistent interpretation I is an interpretation I that does not contain both a and ¬a for some a ∈ I.\nA consistent interpretation I is said to be amodel of a positive disjunctive rule r if head(r)∩I 6= ∅ or body(r) 6⊆ I, i.e. the body is false or the head is true. In particular, a consistent interpretation I is a model of a constraint rule r if body(r) 6⊆ I. If for an interpretation I and a constraint rule r we have that body(r) ⊆ I, then we say\nthat the interpretation I violates the constraint rule r. Notice that for a fact rule we require that head(r) ∩ I 6= ∅, i.e. at least one of the literals in the head must be true. Indeed, otherwise I would not be a model of r. An interpretation I of a positive disjunctive program P is a model of P either if I is consistent and for every rule r ∈ P we have that I is a model of r, or if I = LitP . It follows from this definition that LitP is always a model of P , and that all other models of P (if any) are consistent interpretations, which we will further on also refer to as consistent models. We say that I is an answer set of the positive disjunctive program P when I is a minimal model of P w.r.t. set inclusion.\nThe semantics of an ASP program with negation-as-failure is based on the idea of a stable model (Gelfond and Lifzchitz 1988). The reduct P I of a disjunctive program P w.r.t. the interpretation I is defined as:\nP I ={l0; . . . ; lk ← lk+1, ..., lm | ({lm+1, ..., ln} ∩ I = ∅)\n∧ (l0; ...; lk ← lk+1, ..., lm, not lm+1, ..., not ln) ∈ P}.\nAn interpretation I is said to be an answer set of the disjunctive program P when I is an answer set of the positive disjunctive program P I (hence the notion of stable model). Note that we can also write the disjunctive program P as P = P ′∪C where C is the set of constraint rules in P . An interpretation I then is an answer set of the disjunctive program P when I is an answer set of P ′ and I is a model of C, i.e. I does not violate any constraints in C. Whenever P has consistent answer sets, i.e. answer sets that are consistent interpretations, we say that P is a consistent program. When P has the answer set LitP , then this is the unique (Baral 2003) inconsistent answer set and we say that P is an inconsistent program.\nAnswer sets of simple programs can also be defined in a more procedural way. By using the immediate consequence operator TP , which is defined for a simple program P without constraint rules and w.r.t. an interpretation I as:\nTP (I) = {l0 | (l0 ← l1, ..., lm) ∈ P ∧ {l1, ..., lm} ⊆ I} .\nWe use P ⋆ to denote the fixpoint which is obtained by repeatedly applying TP starting from the empty interpretation ∅, i.e. it is the least fixpoint of TP w.r.t. set inclusion. When the interpretation P ⋆ is consistent, P ⋆ is the (unique and consistent) answer set of the simple program P without constraint rules. When we allow constraint rules, an interpretation is a (consistent) answer set of P = P ′ ∪C iff I is a (consistent) answer set of P and I is a model of C. For both simple and normal programs, with or without constraint rules, we have that LitP is the (unique and inconsistent) answer set of P if P has no consistent answer set(s)."
    }, {
      "heading" : "2.2 Possibilistic Logic",
      "text" : "An interpretation in possibilistic logic corresponds with the notion of an interpretation in propositional logic. We represent such an interpretation as a set of atoms ω, where ω |= a if a ∈ ω and ω |= ¬a otherwise with |= the satisfaction relation from classical logic. The set of all interpretations is defined as Ω = 2A, with A a finite set of atoms. At the semantic level, possibilistic logic (Dubois et al. 1994) is defined in\nterms of a possibility distribution π on the universe of interpretations. A possibility distribution, which is an Ω → [0, 1] mapping, encodes for each interpretation (or world) ω to what extent it is plausible that ω is the actual world. By convention, π(ω) = 0 means that ω is impossible and π(ω) = 1 means that no available information prevents ω from being the actual world. A possibility distribution π is said to be normalized if ∃ω ∈ Ω ·π(ω) = 1, i.e. at least one interpretation is entirely plausible. We say that a possibility distribution π is vacuous when ∀ω ∈ Ω · π(ω) = 0. Note that possibility degrees are mainly interpreted qualitatively: when π(ω) > π(ω′), ω is considered more plausible than ω′. For two possibility distributions π1 and π2 with the same domain Ω we write π1 ≥ π2 when ∀ω ∈ Ω · π1(ω) ≥ π2(ω) and we write π1 > π2 when π1 ≥ π2 and π1 6= π2.\nA possibility distribution π induces two uncertainty measures that allow us to\nrank propositions. The possibility measure Π is defined by (Dubois et al. 1994):\nΠ(p) = max {π(ω) | ω |= p}\nand evaluates the extent to which a proposition p is consistent with the beliefs expressed by π. The dual necessity measure N is defined by:\nN(p) = 1−Π(¬p)\nand evaluates the extent to which a proposition p is entailed by the available beliefs (Dubois et al. 1994). Note that we always have N(⊤) = 1 for any possibility distribution, while Π(⊤) = 1 (and, related, N(⊥) = 0) only holds when the possibility distribution is normalized (i.e. only normalized possibility distributions can express consistent beliefs) (Dubois et al. 1994). To identify the possibility/necessity measure associated with a specific possibility distribution πX, we will use a subscript notation, i.e. ΠX and NX are the corresponding possibility and necessity measure, respectively. We omit the subscript when the possibility distribution is clear from the context.\nAn important property of necessity measures is the min-decomposability property w.r.t. conjunction: N(p ∧ q) = min(N(p), N(q)) for all propositions p and q. However, for disjunction only the inequality N(p ∨ q) ≥ max(N(p), N(q)) holds. As possibility measures are the dual measures of necessity measures, they have the property of max-decomposability w.r.t. disjunction, whereas for the conjunction only the inequality Π(p ∧ q) ≤ min (Π(p),Π(q)) holds.\nAt the syntactic level, a possibilistic knowledge base consists of pairs (p, c) where p is a propositional formula and c ∈ ]0, 1] expresses the certainty that p is the case. Formulas of the form (p, 0) are not explicitly represented in the knowledge base since they encode trivial information. A formula (p, c) is interpreted as the constraint N(p) ≥ c, i.e. a possibilistic knowledge base Σ corresponds to a set of constraints on possibility distributions. Typically, there can be many possibility distributions that satisfy these constraints. In practice, we are usually only interested in the least specific possibility distribution, which is the possibility distribution that makes minimal commitments, i.e. the greatest possibility distribution w.r.t. the ordering > defined above. Such a least specific possibility distribution always exists and is unique (Dubois et al. 1994).\nIn Section 4 we will also consider constraints that deviate from the form of constraints we just discussed. As a result, there can be multiple minimally specific possibility distributions rather than a unique least specific possibility distribution. To increase the uniformity throughout the paper we immediately start using the concept of a minimally specific possibility distribution, which is a maximal possibility distribution w.r.t. the ordering >, even though the distinction between the least specific possibility distribution and minimally specific possibility distributions only becomes relevant once we discuss the characterization of disjunctive programs."
    }, {
      "heading" : "2.3 Possibilistic Answer Set Programming",
      "text" : "Possibilistic ASP (PASP) (Nicolas et al. 2006) combines ASP and possibility theory by associating a weight with each rule, where the weight denotes the necessity with which the head of the rule can be concluded given that the body is known to hold. If it is uncertain whether the body holds, the necessity with which the head can be derived is the minimum of the weight associated with the rule and the degree to which the body is necessarily true.\nSyntactically, a possibilistic disjunctive (resp. normal, simple, definite) program is a set of pairs p = (r, λ) with r a disjunctive (resp. normal, simple, definite) rule and λ ∈ ]0, 1] a certainty associated with r. Possibilistic rules with λ = 0 are generally omitted as only trivial information can be derived from them. We will also write a possibilistic rule p = (r, λ) with r a disjunctive rule of the form (l0; ...; lk ← lk+1, ..., lm, not lm+1, ..., not ln) as:\nλ : l0; ...; lk ← lk+1, ..., lm, not lm+1, ..., not ln.\nFor a possibilistic rule p = (r, λ) we use p∗ to denote r, i.e. the classical rule obtained by ignoring the certainty. Similarly, for a possibilistic program P we use P ∗ to denote the set of rules {p∗ | p ∈ P}. The set of all weights found in a possibilistic program P is denoted by cert(P ) = {λ | p = (r, λ) ∈ P}. We will also use the extended set of weights cert+(P ), defined as cert+(P ) = {λ | λ ∈ cert(P )} ∪ {1− λ | λ ∈ cert(P )} ∪ {\n0, 12 , 1 } .\nSemantically, PASP is based on a generalization of the concept of an interpretation. In classical ASP, an interpretation can be seen as a mapping I : LitP → {0, 1}, i.e. a literal l ∈ LitP is either true or false. This notion is generalized in PASP to a valuation, which is a function V : LitP → [0, 1]. The underlying intuition of V (l) = λ is that the literal ‘l’ is true with certainty ‘λ’, which we will also write in set notation as lλ ∈ V . As such, a valuation corresponds with the set of constraints { N(l) ≥ λ | lλ ∈ V } . Note that, like interpretations in ASP, these valuations are of an epistemic nature, i.e. they reflect what we know about the truth of atoms. For notational convenience, we often also use the set notation V = { lλ, . . . } . In accordance with this set notation, we write V = ∅ to denote the valuation in which each literal is mapped to 0. For λ ∈ [0, 1] a certainty and V a valuation, we use V λ to denote the classical projection {l | l ∈ LitP , V (l) ≥ λ}. We also use V λ = {l | l ∈ LitP , V (l) > λ}, i.e. those literals that can be derived to be true with certainty strictly greater than ‘λ’. A valuation is said to be consistent when V 0 is\nconsistent. In such a case, there always exists a normalized possibility distribution πV such that NV (l) = V (l).\nWe now present a straightforward extension of the semantics for PASP introduced in (Nicolas et al. 2006). Let the λ-cut Pλ of a possibilistic program P , with λ ∈ [0, 1], be defined as:\nPλ = {r | (r, λ ′) ∈ P and λ′ ≥ λ} ,\ni.e. the rules in P with an associated certainty higher than or equal to ‘λ’.\nDefinition 1 Let P be a possibilistic simple program and V a valuation. The immediate consequence operator TP is defined as:\nTP (V )(l0) = max { λ ∈ [0, 1] | V λ |= l1, ..., lm and (l0 ← l1, ..., lm) ∈ Pλ } .\nThe intuition of Definition 1 is that we can derive the head only with the certainty of the weakest piece of information, i.e. the necessity of the conclusion is restricted either by the certainty of the rule itself or the lowest certainty of the literals used in the body of the rule. Note that the immediate consequence operator defined in Definition 1 is equivalent to the one proposed in (Nicolas et al. 2006), although we formulate it somewhat differently. Also, the work from (Nicolas et al. 2006) only considered definite programs, even though adding classical negation does not impose any problems.\nAs before, we use P ⋆ to denote the fixpoint obtained by repeatedly applying TP starting from the minimal valuation V = ∅, i.e. the least fixpoint of TP w.r.t. set inclusion. A valuation V is said to be the answer set of a possibilistic simple program if V = P ⋆ and V is consistent. Answer sets of possibilistic normal programs are defined using a reduct. Let L be a set of literals. The reduct PL of a possibilistic normal program is defined as (Nicolas et al. 2006):\nPL = {(head(r) ← body+(r), λ) | (r, λ) ∈ P and body−(r) ∩ L = ∅} .\nA consistent valuation V is said to be a possibilistic answer set of the possibilistic normal program P iff ( P (V 0) )⋆ = V , i.e. if V is the answer set of the reduct P (V 0).\nExample 1 Consider the possibilistic normal program P from the introduction:\n0.1: invalid ←\n1: airport ← not invalid\nIt is easy to verify that { invalid0 .1 } is a possibilistic answer set of P . Indeed, P {invalid} is the set of rules:\n0.1: invalid ←\nfrom which it trivially follows that (P {invalid}) ⋆ = { invalid 0 .1 } . The conclusion is thus that we do not need to go to the airport, which differs from our intuition of the problem. We will revisit this example in Example 4 in Section 3.2.\nThe semantics we presented allow for classical negation, even though this was not considered in (Nicolas et al. 2006). However, adding classical negation does not impose any problems and could, as an alternative, easily be simulated in ASP (Baral 2003)."
    }, {
      "heading" : "2.4 Complexity Theory",
      "text" : "Finally, we recall some notions from complexity theory. The complexity classes ΣP2 and ΠP2 are defined as follows (Papadimitriou 1994):\nΣP0 = Π P 0 = P ΣP1 = NP Σ P 2 = NP NP ΠP1 = coNP Π P 2 = coΣ P 2\nwhere NPNP is the class of problems that can be solved in polynomial time on a non-deterministic machine with an NP oracle, i.e. assuming a procedure that can solve NP problems in constant time. We also consider the complexity class BH2 (Cai et al. 1988), which is the class of all languages L such that L = L1 ∩ L2, where L1 is in NP and L2 is in coNP. For a general complexity class C, a problem is C-hard if any problem in C can be polynomially reduced to this problem. A problem is said to be C-complete if the problem is in C and the problem is C-hard. Deciding the validity of a Quantified Boolean Formula (QBF) φ = ∃X1∀X2 · p(X1, X2) with p(X1, X2) in disjunctive normal form (DNF) is the canonical Σ P 2 -complete problem. The decision problems we consider in this paper are brave reasoning (deciding whether a literal ‘l’ (clause ‘e’) is entailed by a consistent answer set of program P ), cautious reasoning (deciding whether a literal ‘l’ (clause ‘e’) is entailed by every consistent answer set of a program P ) and answer set existence (deciding whether a program P has a consistent answer set). Brave reasoning as well as answer set existence for simple, normal and disjunctive programs is P-complete, NP-complete and ΣP2 -complete, respectively (Baral 2003). Cautious reasoning for simple, normal and disjunctive programs is P-complete, coNP-complete and ΠP2 - complete (Baral 2003)."
    }, {
      "heading" : "3 Characterizing (P)ASP",
      "text" : "ASP lends itself well to being characterized in terms of modalities. For instance, ASP can be characterized in autoepistemic logic by interpreting ‘not a’ as the epistemic formula ¬La (“a is not believed”) (Gelfond 1987). In this paper, as an alternative, we show how ASP can be characterized within possibility theory. To arrive at this characterization, we first note that ASP is essentially a special case of PASP in which every rule is certain. As such, we will show how PASP can be characterized within possibility theory. This characterization does not coincide with the semantics proposed in (Nicolas et al. 2006) for PASP, as the semantics from (Nicolas et al. 2006) rely on the classical Gelfond-Lifschitz reduct. Rather, the semantics that we propose for PASP adhere to a different intuition of negation-\nas-failure. A characterization of ASP is then obtained from these new semantics by considering the special case in which all rules are entirely certain.\nThis characterization of ASP, while still in terms of modalities, stays close in spirit to the Gelfond-Lifschitz reduct. In contrast to the characterization in terms of autoepistemic logic it does not require a special translation of literals to deal with classical negation and disjunction. The core idea of our characterization is to encode the meaning of each rule as a constraint on possibility distributions. Particular minimally specific possibility distributions that satisfy all the constraints imposed by the rules of a program will then correspond to the answer sets of that program. In this section, we first limit our scope to possibilistic simple programs (Section 3.1). Afterwards we will broaden the scope and also consider possibilistic normal programs (Section 3.2). The most general case, in which we also consider possibilistic disjunctive programs, will be discussed in Section 4."
    }, {
      "heading" : "3.1 Characterizing Possibilistic Simple Programs",
      "text" : "When considering a fact, i.e. a rule of the form r = (l0 ← ⊤), we know by definition that this rule encodes that the literal in the head is necessarily true, i.e. N(l0) = 1. If we attach a weight to a fact, then this expresses the knowledge that we are not entirely certain of the conclusion in the head, i.e. for a possibilistic rule p = (r, λ) we have that N(l0) ≥ N(⊤). Note that the constraint uses ≥, as there may be other rules in the program that allow us to deduce l0 with a greater certainty.\nIn a similar fashion we can characterize a rule of the form (l0 ← l1, ..., lm) as the constraint N(l0) ≥ N(l1 ∧ ... ∧ lm) which is equivalent to the constraint N(l0) ≥ min(N(l1), ..., N(lm)) due to the min-decomposability property of the necessity measure. Indeed, the intuition of such a rule is that the head is only necessarily true when every part of the body is true. When associating a weight with a rule, we obtain the constraint N(l0) ≥ min(N(l1), ..., N(lm), λ) for a possibilistic rule p = (r, λ) with r = (l0 ← l1, ..., lm). Similarly, to characterize a constraint rule, i.e. a rule of the form r = (⊥ ← l1, ..., lm), we use the constraint N(⊥) ≥ min(N(l1), ..., N(lm)), or, in the possibilistic case with p = (r, λ), the constraint N(⊥) ≥ min(N(l1), ..., N(lm), λ).\nDefinition 2 Let P be a possibilistic simple program and π : Ω → [0, 1] a possibility distribution. For every p ∈ P , the constraint γ(p) imposed by p = (r, λ) with λ ∈ ]0, 1], r = (l0 ← l1, ..., lm) and m ≥ 0 is given by\nN(l0) ≥ min(N(l1), ..., N(lm), λ). (1)\nCP = {γ(p) | p ∈ P} is the set of constraints imposed by program P . If π satisfies the constraints in CP , π is said to be a possibilistic model of CP , written π |= CP . A possibilistic model of CP will also be called a possibilistic model of P . We write SP for the set of all minimally specific possibilistic models of P .\nDefinition 3\nLet P be a possibilistic simple program. Let π be a minimally specific model of P , i.e. π ∈ SP . Then V = { lN (l) | l ∈ LitP } is called a possibilistic answer set of P .\nExample 2 Consider the possibilistic simple program P with the rules:\n0.8 :a← 0.6 :¬b← a\n0.7 : c← a,¬b 0.9 : d← d.\nThe set CP consists of the constraints:\nN(a) ≥ 0.8 N(¬b) ≥ min(N(a), 0.6)\nN(c) ≥ min(N(a), N(¬b), 0.7) N(d) ≥ min(N(d), 0.9).\nIt is easy to see that the last constraint is trivial and can be omitted and that the other constraints can be simplified to Π(¬a) ≤ 0.2, Π(b) ≤ 0.4 and Π(¬c) ≤ 0.4. The least specific possibility distribution that satisfies these constraints is given by:\nπ({a, b, c, d}) = 0.4 π({a, c, d}) = 1 π({b, c, d}) = 0.2 π({c, d}) = 0.2\nπ({a, b, c}) = 0.4 π({a, c}) = 1 π({b, c}) = 0.2 π({c}) = 0.2\nπ({a, b, d}) = 0.4 π({a, d}) = 0.4 π({b, d}) = 0.2 π({d}) = 0.2\nπ({a, b}) = 0.4 π({a}) = 0.4 π({b}) = 0.2 π({}) = 0.2.\nBy definition, since the possibility distribution π satisfies the given constraints, is a possibilistic model. Furthermore, it is easy to see that π is the unique minimally specific possibilistic model (due to least specificity). We can verify that N(¬a) = N(b) = N(¬c) = N(¬d) = 0 since we have that π({a, c, d}) = 1 and that N(d) = 0 since π({a, c}) = 1. Furthermore it is easy to verify that N(a) = 0.8, N(¬b) = 0.6 and N(c) = 0.6. Hence we find that V = { a0 .8 ,¬b0 .6 , c0 .6 } is a possibilistic answer set of P .\nIn particular, when we consider all the rules to be entirely certain, i.e. λ = 1, the results are compatible with the semantics of classical ASP.\nExample 3 Consider the program P = {(b← a), (¬a ←)}. The set of constraints CP is given by N(b) ≥ N(a) and N(¬a) ≥ N(⊤). The first constraint can be rewritten as 1−Π(¬b) ≥ 1−Π(¬a), i.e. as Π(¬a) ≥ Π(¬b). The last constraint can be rewritten as 1−Π(a) ≥ 1, i.e. as Π(a) = max {π(ω) | ω |= a} = 0. Given these two constraints, we find that SP contains exactly one element, which is defined by\nπ({a, b}) = 0 π({a}) = 0\nπ({b}) = 1 π({}) = 1.\nNotice how the first constraint turned out to be of no relevance for this particular example. Indeed, due to the principle of minimal specificity and since there is nothing that prevents Π(¬a) = 1, we find that N(a) = 1 − Π(¬a) = 0. Therefore the first constraint simplifies to N(b) ≥ 0. Once more, due to the principle of minimal specificity we thus find that N(b) = 0 as there is no information that prevents\nΠ(¬b) = 1. To find out whether a, b, ¬a and ¬b are necessarily true w.r.t. the least specific possibility distribution π ∈ SP arising from the program, we verify whether N(a) = 1, N(b) = 1, N(¬a) = 1 and N(¬b) = 1, respectively, with N the necessity measure induced by the unique least specific possibility distribution π ∈ SP . As desired, we find that N(¬a) = 1−Π(a) = 1 whereas N(a) = N(b) = N(¬b) = 0. The unique possibilistic answer set is therefore { ¬a1 } . As we will see, it then follows from Proposition 1 that the unique classical answer set of P is {¬a}.\nIn Propositions 1 and 2, below, we prove that this is indeed a correct characterization of simple programs. First, we present a technical lemma.\nLemma 1 Let L be a set of literals, M ⊆ L a consistent set of literals and let the possibility distribution π be defined as π(ω) = 1 if ω |= M and π(ω) = 0 otherwise. Then M = {l | N(l) = 1, l ∈ L}.\nThe proof is given in the online appendix of the paper, pp. 1–2.\nProposition 1 Let P be a simple program. If π ∈ SP then either the unique consistent answer set of P is given by M = {l | N(l) = 1, l ∈ LitP } or π is the vacuous distribution, in which case P does not have any consistent answer sets.\nThe proof is given in the online appendix of the paper, pp. 2–4.\nProposition 2 Let P be a simple program. If M is an answer set of P then the possibility distribution π defined by π(ω) = 1 iff ω |=M and π(ω) = 0 otherwise belongs to SP .\nThe proof is given in the online appendix of the paper, pp. 4."
    }, {
      "heading" : "3.2 Characterizing Possibilistic Normal Programs",
      "text" : "To deal with negation-as-failure, we rely on a reduct-style approach in which a valuation is guessed and it is verified whether this guess is indeed stable. The approach taken in (Gelfond and Lifzchitz 1988) to deal with negation-as-failure is to guess an interpretation and verify whether this guess is stable. We propose to treat a rule of the form r = (l0 ← l1, ..., lm, not lm+1, ..., not ln) as the constraint\nN(l0) ≥ min (N(l1), ..., N(lm), 1− V (lm+1), ..., 1− V (ln))\nwhere V is the guess for the valuation and where we assume min({}) = 1. Or, when we consider a possibilistic rule p = (r, λ), we treat it as the constraint\nN(l0) ≥ min (N(l1), ..., N(lm), 1− V (lm+1), ..., 1− V (ln), λ) .\nWe like to make it clear to the reader that the characterization of normal programs in terms of constraints on possibility distributions in its basic form is little more than a reformulation of the Gelfond-Lifschitz approach. The key difference is that this characterization can be used to guess the certainty with which we can\nderive particular literals from the available rules, rather than guessing what may or may not be derived from it. Nevertheless, this difference plays a crucial role when dealing with uncertain rules. In particular, this characterization of PASP does not coincide with the semantics of (Nicolas et al. 2006) and adheres to a different intuition for negation-as-failure.\nDefinition 4 Let P be a possibilistic normal program and let V be a valuation. For every p ∈ P , the constraint γ V (p) induced by p = (r, λ) with λ ∈ ]0, 1], r = (l0 ← l1, ..., lm, not lm+1, ..., not ln) and V is given by\nN(l0) ≥ min (N(l1), ..., N(lm), 1− V (lm+1), ..., 1− V (ln), λ) . (2)\nC(P,V ) = {γV (p) | p ∈ P} is the set of constraints imposed by program P and valuation V , and S(P,V ) is the set of all minimally specific possibilistic models of C(P,V ).\nDefinition 5 Let P be a possibilistic normal program and let V be a valuation. Let π ∈ S(P,V ) be such that\n∀l ∈ LitP ·N(l) = V (l)\nthen V = { lN (l) | l ∈ LitP } is called a possibilistic answer set of P .\nExample 4 Consider the possibilistic normal program P from Example 1. The constraints CP induced by P are:\nN(invalid) ≥ 0.1\nN(airport) ≥ min(1− V (invalid ), 1)\nFrom the first constraint it readily follows that we need to choose V (invalid) = 0.1 to comply with the principle of minimal specificity. The other constraint can then readily be simplified to:\nN(airport) ≥ 0.9\nHence it follows that V = { invalid0 .1 , airport0 .9 } is the unique possibilistic answer set of P .\nIt is easy to see that the proposed semantics remain closer to the intuition of the possibilistic normal program discussed in the introduction. Indeed, we conclude with a high certainty that we need to go to the airport.\nStill, it is interesting to further investigate the particular relationship between the semantics for PASP as proposed in (Nicolas et al. 2006) and the semantics presented in this section. Let the possibilistic rule r be of the form:\nλ : l0; ...; lk ← lk+1, ..., lm, not lm+1, ..., not ln.\nWhen we determine the reduct w.r.t. a valuation V of the possibilistic program\ncontaining r, then the certainty of the rule in the reduct that corresponds with r can be verified to be:\nmin(FN (V (lm+1)), ..., FN (V (ln)), λ)\nwith FN a fuzzy negator, i.e. where FN is a decreasing function with FN (0) = 1 and FN (1) = 0. In particular, for the semantics of (Nicolas et al. 2006) we have that FN is the Gödel negator FG, defined as FG(0) = 1 and FG(c) = 0 with 0 < c ≤ 1. In the semantics for PASP presented in this section, FN is the Lukasiewicz negator F L(c) = 1− c with 0 ≤ c ≤ 1. Thus, for a rule such as:\n0.9: b ← not a\nand a valuation V = { a0 .2 } we obtain under the approach from (Nicolas et al. 2006) the reduct (0: b ← ), whereas under our approach we obtain the constraint N(b) ≥ min(0.9, 1 − 0.2), which can be encoded by the rule (0.8: b ← ). Essentially, the difference between both semantics can thus be reduced to a difference in the choice of negator. However, even though the semantics share similarities, there is a notable difference in the underlying intuition of both approaches. Specifically, in the semantics presented in this paper, we have that ‘not l’ is understood as “the degree to which ‘¬l’ is possible”, or, equivalently, “the degree to which it is not the case that we can derive ‘l’ with certainty”. This contrasts with the intuition of ‘not l’ in (Nicolas et al. 2006) as a Boolean condition and understood as “we cannot derive ‘l’ with a strictly positive certainty”.\nInterestingly, we find that the complexity of the main reasoning tasks for possibilistic normal programs remains at the same level of the polynomial hierarchy as the corresponding normal ASP programs.\nWhile we will see in Section 5 that the complexity of possibilistic normal programs remains unchanged compared to classical normal programs, it is important to note that under the semantics proposed in this section there is no longer a 1-on-1 mapping between the classical answer sets of a normal program and the possibilistic answer sets. Indeed, if we consider a possibilistic normal program constructed from a classical normal program where we attach certainty λ = 1 to each rule, then we can sometimes obtain additional intermediary answer sets. Consider the next example:\nExample 5\nConsider the normal program with the single rule a ← not a. This program has no classical answer sets. Now consider the possibilistic normal program P with the rule"
    }, {
      "heading" : "1: a ← not a.",
      "text" : "The set of constraints C(P,V ) is given by\nN(a) ≥ min(1 − V (a), 1).\nThis constraint can be rewritten as\nN(a) ≥ min(1− V (a), 1)\n≡ N(a) ≥ 1− V (a)\n≡ 1−Π(¬a) ≥ 1− V (a)\n≡ Π(¬a) ≤ V (a).\nWe thus find that the set S(P,V ) is a singleton with π ∈ S(P,V ) defined by π({a}) = 1 and π({}) = V (a). We can now establish for which choices of V (a) it holds that V (a) = N(a):\nV (a) = N(a)\nΠ(¬a) = 1−Π(¬a)\n2 · Π(¬a) = 1\nand thus, since Π(¬a) ≤ V (a), we have π({}) = 0.5. The unique possibilistic answer set of P is therefore { a0 .5 } . In the same way, one may verify that the program"
    }, {
      "heading" : "1: a ← not b 1: b ← not a",
      "text" : "has an infinite number of possibilistic answer sets, i.e. { ac, b1−c } for every c ∈ [0, 1]. For practical purposes, however, this behavior has a limited impact as we only need to consider a finite number of certainty levels to perform brave/cautious reasoning. Indeed, we only need to consider the certainties used in the program, their complement to account for negation-as-failure and 12 to account for the intermediary value as in Example 5. Thus, for the main reasoning tasks it suffices to limit our attention to the certainties from the set cert+(P ).\nWe now show that when we consider rules with an absolute certainty, i.e. classical normal programs, we obtain a correct characterization of classical ASP, provided that we restrict ourselves to absolutely certain conclusions, i.e. valuations V for which it holds that ∀l · V (l) ∈ {0, 1}.\nExample 6\nConsider the program P with the rules\na← b← b c← a, not b.\nThe set of constraints C(P,V ) is then given by\nN(a) ≥ 1 N(b) ≥ N(b) N(c) ≥ min (N(a), 1 − V (b)) .\nWe can rewrite the first constraint as 1−Π(¬a) ≥ 1 and thus Π(¬a) = 0. The second\nconstraint is trivially satisfied and, since it does not entail any new information, can be dropped. The last constraint can be rewritten as Π(¬c) ≤ 1−min(1−Π(¬a), 1− V (b)), which imposes an upper bound on the value that Π(¬c) can assume. Since we already know that Π(¬a) = 0 we can further simplify this inequality to Π(¬c) ≤ 1−min(1−0, 1−V (b)) = 1−(1−V (b)) = V (b). In conclusion, the program imposes the constraints\nΠ(¬a) = 0 Π(¬c) ≤ V (b).\nThe set S(P,V ) then contains exactly one element, which is defined by\nπ({a, b, c}) = 1 π({b, c}) = 0\nπ({a, b}) = V (b) π({b}) = 0\nπ({a, c}) = 1 π({c}) = 0\nπ({a}) = V (b) π({}) = 0.\nNote that this possibility distribution is independent of the choice for V (a) and V (c) since there are no occurrences of ‘not a’ and ‘not c’ in P . It remains then to determine for which choices of V (b) it holds that V (b) = N(b), i.e. for which the guess V (b) is stable. We have:\nV (b) = N(b) = 1−Π(¬b) = 1−max {π(ω) | ω |= ¬b} = 0\nand thus we find that π({a, b}) = π({a}) = 0. We have N(a) = 1 − Π(¬a) = 1, N(c) = 1 − Π(¬c) = 1 and N(b) = 1 − Π(¬b) = 0. As we will see in the next propositions, the unique answer set of P is therefore {a, c}.\nProposition 3 Let P be a normal program and V a valuation. Let π ∈ S(P,V ) be such that\n∀l ∈ LitP · V (l) = N(l) ; and (3)\n∀l ∈ LitP ·N(l) ∈ {0, 1} (4)\nthen M = {l | N(l) = 1, l ∈ LitP} is an answer set of the normal program P .\nProof This proposition is a special case of Proposition 5 presented below.\nNote that the requirement stated in (4) cannot be omitted. Let us consider Example 5, in which we considered the normal program P = {a← not a}. This normal program P has no classical answer sets. The constraint that corresponds with the rule (a ← not a) is N(a) ≥ 1 − V (a). For a choice of V = { a0.5 } , however, we would find that V (a) = N(a) and thus that V is an answer set of P if we were to omit this requirement.\nProposition 4 Let P be a normal program. If M is an answer set of P , there is a valuation V , defined by V (l) = 1 if l ∈M and V (l) = 0 otherwise, and a possibility distribution π ∈ S(P,V ) such that for every l ∈ LitP we have V (l) = N(l) (i.e. N(l) = 1 if l ∈M and N(l) = 0 otherwise).\nProof This proposition is a special case of Proposition 6 presented below.\nWe like to point out to the reader that we could try to encode the information in a rule in such a way that we interpret ‘not a’ as Π(¬a), which closely corresponds to the intuition of negation-as-failure. Indeed, when it is completely possible to assume that ‘¬a’ is true, then surely ‘not a’ is true. Under this encoding, however, we run into a significant problem. Consider the rules (b ← not c) and (c ← not b). These rules would then correspond with the constraints N(b) ≥ Π(¬c) and N(c) ≥ Π(¬b), respectively. Notice though that both constraints can be rewritten as the constraint 1 − Π(¬b) ≥ Π(¬c). This would imply that both rules are semantically equivalent in ASP, which is clearly not the case. Hence we cannot directly encode ‘not a’ as Π(¬a) and guessing a valuation is indeed necessary since without the guess V we would not be able to obtain a unique set of constraints. As we have shown this only affects literals preceded by negation-as-failure and we can continue to interpret a literal ‘b’ as N(b)."
    }, {
      "heading" : "4 Possibilistic Semantics of Disjunctive ASP Programs",
      "text" : "We now turn our attention to how we can characterize disjunctive rules. We found in Section 3 that we can characterize a rule of the form r = (head ← body) as the constraint N(head) ≥ N(body), or, similarly, that we can characterize a possibilistic rule p = (r, λ) as the constraint N(head) ≥ min(N(body), λ). Such a characterization works particularly well due the min-decomposability w.r.t. conjunction. Indeed, since the body of e.g. a simple rule r = (l0 ← l1, ..., lm) is a conjunction of literals we can write body = l1 ∧ ... ∧ lm. Then N(body) can be rewritten as min(N(l1), ..., N(lm)), which allows for a straightforward simplification. In a similar fashion, for a positive disjunctive rule r = (l0; ...; lk ← lk+1, ..., lm) we can readily write N(body) as min(N(lk+1), ..., N(lm)). We would furthermore like to simplify N(head) with head = l0 ∨ ... ∨ lk. However, we do not have that N(head) = max(N(l0), ..., N(lk)). Indeed, in general we only have that N(head) ≥ max(N(l0), ..., N(lk)). This means that we can either choose to interpret the head as max(N(l0), ..., N(lk)) or N(l0 ∨ ... ∨ lk). In particular, a possibilistic disjunctive rule p = (r, λ) with\nr = (l0; ...; lk ← lk+1, ..., lm, not lm+1, ..., not ln)\ncan either be interpreted as the constraint\nmax(N(l0), ..., N(lk)) ≥ min(N(lk+1), ..., N(lm), 1− V (lm+1), ..., 1− V (ln), λ)\n(5)\nwhich we will call the strong interpretation of disjunction, or as the constraint\nN(l0 ∨ ... ∨ lk) ≥ min(N(lk+1), ..., N(lm), 1− V (lm+1), ..., 1− V (ln), λ) (6)\nwhich we will call the weak interpretation of disjunction. In the remainder of this paper, we syntactically differentiate between both approaches by using the nota-\ntion l0; ...; lk and l0 ∨ ... ∨ lk to denote the strong and the weak interpretation of disjunction, respectively.\nThe choice of how to treat disjunction is an important one that crucially impacts the nature of the resulting answer sets. For example, the non-deterministic nature of strong disjunction provides a useful way to generate different (candidate) solutions, whereas weak disjunction is oftentimes better suited when we are interested in modelling the epistemic state of an agent since it amounts to accepting the disjunction as being true rather than making a choice of which disjunct to accept. In this section we consider both characterizations; the characterization of disjunction as (5) is discussed in Section 4.1 and in Section 4.2 we discuss the characterization as (6). In particular we will show that the first characterization of disjunction corresponds to the semantics of disjunction found in ASP whereas the Boolean counterpart of the second characterization has, to the best of our knowledge, not yet been studied in the literature."
    }, {
      "heading" : "4.1 Strong Possibilistic Semantics of Disjunctive Rules",
      "text" : "We first consider the characterization of disjunction in which we treat a disjunction of the form ‘l0; ...; lk’ as max(N(l0), . . . , N(lk)). As it turns out, under these strong possibilistic semantics the disjunction behaves as in classical ASP.\nDefinition 6 Let P be a possibilistic disjunctive program and let V be a valuation. For every possibilistic disjunctive rule p = (r, λ) with λ ∈ ]0, 1] and r = (l0; ...; lk ← lk+1, ..., lm, not lm+1, ..., not ln) the constraint γ s V (p) induced by p and V is given by\nmax(N(l0), ..., N(lk)) ≥ min(N(lk+1), ..., N(lm), 1−V (lm+1), ..., 1−V (ln), λ) (7)\nCs(P,V ) = { γs V (p) | p ∈ P } is the set of constraints imposed by program P and V , and Ss(P,V ) is the set of all minimally specific possibilistic models of C s (P,V ). 1\nWhenever P is a positive disjunctive program, i.e. whenever P is a disjunctive program without negation-as-failure, (7) is independent of V and we simplify the notation to γs, CsP and S s P .\nNotice that, unlike in possibilistic logic where a unique least specific possibility distribution exists because of the specific form of the considered constraints, the constraint of the form (7) can give rise to multiple minimally specific possibility distributions of which some will correspond with answer sets. Indeed, the program P = {a; b←} induces the constraint max(N(a), N(b)) ≥ 1, which has two minimally specific possibility distributions, yet no least specific possibility distribution. Indeed, we have the minimally specific possibility distributions π1, π2 defined by\nπ1({a, b}) = 1 π1({b}) = 0 π2({a, b}) = 1 π2({b}) = 1\nπ1({a}) = 1 π1({}) = 0 π2({a}) = 0 π2({}) = 0\n1 We use the superscript ‘s’ to highlight that we employ the semantics of strong disjunction.\nDefinition 7 Let P be a possibilistic disjunctive program and let V be a valuation. Let π ∈ Ss(P,V ) be such that\n∀l ∈ LitP ·N(l) = V (l)\nthen V = { lN (l) | l ∈ LitP } is called a possibilistic answer set of P .\nWe now further illustrate the semantics and the underlying intuition by consid-\nering a possibilistic disjunctive program in detail.\nExample 7\nConsider the possibilistic (positive) disjunctive program P with the following rules:\n0.8: a; b ←\n0.6: c ← a\n0.4: c ← b.\nThe constraints CsP induced by this program are:\nmax(N(a), N(b)) ≥ 0.8\nN(c) ≥ min(N(a), 0.6)\nN(c) ≥ min(N(b), 0.4).\nFrom the first constraint it follows that we either need to choose V (a) = 0.8 or V (b) = 0.8, in accordance with the principal of minimal specificity. Hence, we either obtain V (c) = 0.6 or V (c) = 0.4. As such we find that the two unique possibilistic answer sets of P are { a0 .8 , c0 .6 } and { b0 .8 , c0 .4 } .\nAs before, if we restrict ourselves to rules that are entirely certain we obtain a characterization of disjunctive programs in classical ASP.\nExample 8\nConsider the program P with the rules\na; b← a← b\nThe set of constraints CsP is given by\nmax(N(a), N(b)) ≥ N(⊤) = 1 N(a) ≥ N(b).\nIntuitively, the first constraint induces a choice. To satisfy this constraint, we need to take either N(a) = 1 or N(b) = 1. Depending on our choice, we can consider two possibility distributions. The possibility distribution π1 is the least specific possibility distribution that satisfies the constraints N(a) = 1 and N(a) ≥ N(b), whereas π2 is the least specific possibility distribution satisfying the constraints N(b) = 1 and N(a) ≥ N(b):\nπ1({a, b}) = 1 π1({b}) = 0\nπ1({a}) = 1 π1({}) = 0\nand\nπ2({a, b}) = 1 π2({b}) = 0\nπ2({a}) = 0 π2({}) = 0.\nIt is clear that the possibility distribution π2 cannot be minimally specific w.r.t. the constraints max(N(a), N(b)) = 1 and N(a) ≥ N(b) since π1({a}) > π2({a}) and π1(ω) ≥ π2(ω) for all other interpretations ω. We thus have that S s P only contains a single element, namely π1. With N the necessity measure induced by π1 we obtain N(a) = 1 and N(b) = 0. As will follow from Proposition 5 and 6 the unique answer set of P is therefore {a}. Let us now add the rule (b← not b) to P . Notice that in classical ASP this extended program has no answer sets. The set of constraints Cs(P,V ) is given by:\nCsP ∪ {N(b) ≥ 1− V (b)} .\nThis new constraint, intuitively, tells us that ‘b’ must necessarily be true, since we force it to be true whenever it is not true. Note, however, that the act of making ‘b’ true effectively removes the motivation for making it true in the first place. As expected, we cannot find any minimally specific possibilistic model that agrees with the constraints imposed by P and V such that ∀l ∈ LitP · N(l) ∈ {0, 1}. The problem has to do with our choice of V (b). If we take V (b) = 1 then the constraint imposed by the first rule still forces us to choose either N(a) = 1 or N(b) = N(a) = 1 due to the interplay with the constraint imposed by the second rule. However, Ss(P,V ) contains only one minimally specific possibility distribution, namely the one with N(a) = 1. Hence N(b) = 0 6= V (b). If we take V (b) = 0 then the last rule forces N(b) = 1. Hence V (b) = 0 6= 1 = N(b).\nNow that we have clarified the intuition, we can formalize the connection between the strong possibilistic semantics and classical disjunctive ASP.\nProposition 5 Let P be a disjunctive program, V a valuation and let π ∈ Ss(P,V ) be such that\n∀l ∈ LitP · V (l) = N(l) ; and (8)\n∀l ∈ LitP ·N(l) ∈ {0, 1} (9)\nthen M = {l | N(l) = 1, l ∈ LitP} is an answer set of the disjunctive program P .\nThe proof is given in the online appendix of the paper, pp. 4–5.\nProposition 6\nLet P be a disjunctive program. If M is an answer set of P , there is a valuation V , defined as V (l) = 1 if l ∈M and V (l) = 0 otherwise, and a possibility distribution π, defined as π(ω) = 1 if ω |= M and π(ω) = 0 otherwise, such that π ∈ Ss(P,V ) and for every l ∈ LitP we have V (l) = N(l).\nThe proof is given in the online appendix of the paper, pp. 5–6."
    }, {
      "heading" : "4.2 Weak Possibilistic Semantics of Disjunctive Rules",
      "text" : "Under the strong possibilistic semantics of disjunction we consider all the disjuncts of a satisfied rule separately. Under this non-deterministic view the rule (a; b ←) means that ‘a’ is believed to be true or ‘b’ is believed to be true. When looking at answer sets as epistemic states it becomes apparent that there is also another choice in how we can treat disjunction in the head. Indeed, we can look at the disjunction as a whole to hold, without making any explicit choices as to which of the disjuncts holds. When trying to reason about one’s knowledge there are indeed situations in which we do not want, or simply cannot make, a choice as to which of the disjuncts is true. This implies that we need to look at an answer set as a set of clauses, rather than a set of literals.\nAn elaborate example using weak disjunction and uncertainty has been given in\nSection 1. In this subsection we consider the semantics of such programs. For starters, we will extend the PASP semantics with the notion of clauses, rather than literals, and define an applicable immediate consequence operator for programs composed of clauses. We then prove some important properties, such as the monotonicity of the immediate consequence operator. For the classical case (i.e. when omitting weights), we furthermore characterize the complexity of clausal programs, both with and without negation-as-failure in Section 5. In particular, we show how the complexity is critically determined by whether we restrict ourselves to atoms and highlight, as shown by the higher complexity of some of the reasoning tasks, that weak disjunction is a non-trivial extension of ASP.\nWe start by formally defining possibilistic clausal programs, i.e. possibilistic programs with a syntax that allows for disjunction in the body. We then define the weak possibilistic semantics of such clausal programs in terms of constraints on possibility distributions. We also introduce an equivalent characterization based on an immediate consequence operator and a reduct, which is more in line with the usual treatment of ASP programs. When all the rules are entirely certain we obtain the classical counterpart, which we name clausal programs."
    }, {
      "heading" : "4.2.1 Semantical Characterization",
      "text" : "We rely on the notion of a clause, i.e. a finite disjunction of literals. Consistency and entailment for sets of clauses are defined as in propositional logic. As such, we can derive from the information ‘a ∨ b ∨ c’ and ‘¬b’ that ‘a ∨ c’ is true.\nDefinition 8 A clausal rule is an expression of the form (e0 ← e1, ..., em, not em+1, ..., not en) with ei a clause for every 0 ≤ i ≤ n. A positive clausal rule is an expression of the form (e0 ← e1, ..., em) , i.e. a clausal rule without negation-as-failure. A (positive) clausal program is a finite set of (positive) clausal rules.\nFor a clausal rule, which is of the form r = (e0 ← e1, ..., em, not em+1, ..., not en), we say that e0 is the head and that e1, ..., em, not em+1, ..., not en is the body of the clausal rule. We use the notation head(r) and body(r) to denote the clause in\nthe head, resp. the set of clauses in the body. The Herbrand base BP of a clausal program P is still defined as the set of atoms appearing in P . As such, possibility distributions are defined in the usual way as π : 2BP → [0, 1] mappings.\nUntil now, we were able to define the possibility distributions that satisfied the constraints imposed by the rules in a program in terms of a valuation V , i.e. a V : LitP → [0, 1] mapping. This need no longer be the case. Specifically, note that we will now impose constraints of the form N(l0 ∨ ... ∨ lk) ≥ λ. Assume that we have a possibility distribution π defined as\nπ({a, b, c}) = 0 π({a, b}) = 0 π({a, c}) = 1 π({a}) = 1\nπ({b, c}) = 0 π({b}) = 0 π({c}) = 1 π({}) = 0.\nThis possibility distribution is the least specific possibility distribution that satisfies the constraints N(a∨b∨c) = 1 and N(¬b) = 1. However, it can be verified that this possibility distribution cannot be defined in terms of a mapping V : LitP → [0, 1].\nInstead, we define the set of clauses appearing in the head of the rules of a clausal program P as ClauseP = {head(r) | r ∈ P}. Given a clausal program, it is clear that the only information that can be derived from the program are those clauses that are in the head of a rule. To compactly describe a possibility distribution imposed by clausal programs we will thus, for the remainder of this section and for Section 5, take a valuation V to be a ClauseP → [0, 1] mapping. As before, a valuation V corresponds with the set of constraints { N(e) ≥ λ | eλ ∈ V } . The set notation for valuations and the notations V λ and V λ are extended as usual. Entailment for valuations is defined as in possibilistic logic, i.e. if we consider the least specific possibility distribution πV satisfying the constraints { NV (e) ≥ λ | eλ ∈ V } then V |= pλ with ‘p’ a proposition iff NV (p) ≥ λ. In particular, recall from possibilistic logic the inference rules (GMP) or graded modus ponens, i.e. we can infer from N(α) ≥ λ and N(α → β) ≥ λ′ that N(β) ≥ min(λ, λ′). In addition recall the inference rule (S), i.e. we can infer from N(α) ≥ λ that N(α) ≥ λ′ with λ ≥ λ′.\nDefinition 9 A possibilistic (positive) clausal program is a set of possibilistic (positive) clausal rules, which are pairs p = (r, λ) with r a (positive) clausal rule and λ ∈ ]0, 1] a certainty associated with r.\nWe define P ∗ and the λ-cut Pλ as usual.\nWe are now almost able to define the semantics of weak disjunction. In the previous sections we guessed a valuation and used this valuation to deal with negationas-failure. However, for clausal programs, a new problem arises. Note that the least specific possibility distribution that satisfies the constraints N(a ∨ b ∨ c) = 1 and N(¬b) = 1 is also the least specific possibility distribution that satisfies the constraints N(a ∨ c) and N(¬b). As such, if ClauseP = {(a ∨ b ∨ c), (¬b), (a ∨ c)}, there would not be a unique valuation that can be used to define this least specific possibility distribution. Indeed, a valuation uniquely defines a possibility distribution, but not vice versa. To avoid such ambiguity, we will instead immediately guess a possibility distribution πV and use this possibility distribution to deal with negation-as-failure in a clausal program.\nDefinition 10 Let P be a possibilistic clausal program and let πV be a possibility distribution. For every p ∈ P , the constraint γwπV (p) induced by p = (r, λ) with λ ∈ ]0, 1], r = (e0 ← e1, ..., em, not em+1, ..., not en) and πV under the weak possibilistic semantics is given by\nN(e0) ≥ min(N(e1), ..., N(em), 1−NV (em+1), ..., 1−NV (en), λ). (10)\nCw(P,πV ) = { γwπV (p) | p ∈ P } is the set of constraints imposed by program P and πV , and Sw(P,πV ) is the set of all minimally specific possibilistic models of C w (P,πV ) .\nWhenever P is a possibilistic (positive) clausal program, i.e. whenever P is a\npossibilistic clausal program without negation-as-failure, (10) is independent of πV and we simplify the notation to γw, CwP and S w P .\nDefinition 11 Let P be a possibilistic clausal program. Let πV be a possibility distribution such that πV ∈ Sw(P,πV ). We then say that πV is a possibilistic answer set of P .\nAs already indicated we can also use a valuation V to concisely describe πV . When we say that V is a possibilistic answer set of the clausal program P we are, more precisely, stating that the possibility distribution induced by V is a possibilistic answer set of the clausal program P .\nLemma 2 Let P be a possibilistic positive clausal program. Then Sw(P,πV ) is a singleton, i.e. π ∈ Sw(P,πV ) is a least specific possibility distribution.\nProof This readily follows from the form of the constraints imposed by the rules p ∈ P and since a possibilistic positive clausal program is free of negation-as-failure.\nExample 9 Consider the possibilistic clausal program P with the rules:\n1 : a ∨ c ∨ d←\n0.4 :¬d←\n0.8 : e← not (a ∨ b ∨ c).\nWe have that Cw(P,πV ) is the set of constraints:\nN(a ∨ c ∨ d) ≥ 1\nN(¬d) ≥ 0.4\nN(e) ≥ min(1−NV (a ∨ b ∨ c), 0.8).\nWe can rewrite the first constraint as N(¬d → a ∨ c) ≥ 1. Given the second constraint N(¬d) ≥ 0.4 we can apply the inference rule (GMP) to conclude that N(a∨ c) ≥ 0.4. From propositional logic we know that (a∨ c) → (a∨ b∨ c), i.e. we also have N(a ∨ b ∨ c) ≥ 0.4.\nFor πV to be an answer set of P we know from Definition 11 that we must have that π ∈ Sw(P,πV ) with π = πV . In other words, we must have that NV (a ∨ b ∨ c) = N(a ∨ b ∨ c) ≥ 0.4. Due to the principle of least specificity, which implies that N(a ∨ b ∨ c) = 0.4, the last constraints can be simplified toN(e) ≥ min(1− 0.4, 0.8) or N(e) ≥ 0.6. As such, the least specific possibility distribution defined by the constraints N(e) ≥ 0.6, N(a ∨ c ∨ d) ≥ 1 and N(¬d) ≥ 0.4 is a possibilistic answer set of P .\nNotice that we implicitly defined the possibilistic answer set of the previous example as a valuation, i.e. in terms of clauses that appear in the head. Alternatively we could thus write that V = { e0 .6 , a ∨ b ∨ d1 ,¬b0 .4 } defines the possibilistic answer set of P . This idea will be further developed in Section 4.2.2 to avoid the need to explicitly define a possibility distribution (which would require an exponential amount of space) and instead rely on an encoding of a possibility distribution by a (polynomial) set of weighted clauses.\nFor the crisp case, we only want clauses that are either entirely certain or completely uncertain, i.e. true or false. To this end, we add the constraint (11), which is similar to (4) from Proposition 3.\nDefinition 12 Let P be a clausal program and πV ∈ Sw(P,πV ) a possibility distribution such that\n∀ω ∈ Ω · πV (ω) ∈ {0, 1} (11)\nthen πV is called an answer set of P ."
    }, {
      "heading" : "4.2.2 Syntactic Characterization",
      "text" : "We now introduce a syntactic counterpart of the semantics for weak disjunction by defining an immediate consequence and reduct operator. As such, it is more in line with the classical Gelfond-Lifschitz approach. In addition, the syntactic approach only needs polynomial size (as we will only consider clauses appearing in the head of the clausal rules). Indeed, what we will do is formalise the idea of using a valuation to determine the possibilistic answer sets of a clausal program, rather than relying on an exponential possibility distribution.\nDefinition 13\nLet P be a possibilistic positive clausal program. We define the immediate consequence operator TwP as:\nTwP (V )(e0) = max { λ ∈ [0, 1] | (e0 ← e1, ..., em) ∈ Pλ and ∀i ∈ {1, ...,m} · V λ |= ei } .\nWe use P ⋆w to denote the fixpoint which is obtained by repeatedly applying T w P starting from the minimal clausal valuation V = ∅, i.e. the least fixpoint of TwP w.r.t. set inclusion. When P is a positive clausal program we take λ ∈ {0, 1}.\nExample 10 Consider the clausal program P with the clausal rules\n1 : a ∨ b ∨ c←\n0.4 :¬b←\n0.8 : e← (a ∨ c ∨ d).\nWe can easily verify that, starting from V = ∅, we obtain\nTwP (V )(a ∨ b ∨ c) = 1 and\nTwP (V )(¬b) = 0.4.\nIn the next iteration we furthermore find that\nTwP (T w P (V ))(e) = 0.4\nsince (0.8: e ← (a ∨ c ∨ d)) ∈ P0.4 and since (TwP (V )) 0.4 |= a ∨ c ∨ d. In addition, this is the least fixpoint, i.e. we have P ⋆w = { (a ∨ b ∨ c)1 ,¬b0 .4 , e0 .4 } .\nNotice that this definition of the immediate consequence operator is a generalization of the immediate consequence operator for possibilistic simple programs (see Definition 1). Indeed, for a possibilistic positive clausal program where all clauses contain only a single literal, i.e. a possibilistic simple program, we have that P ⋆ = P ⋆w. In addition, when all clauses contain only a single literal, we can simplify the immediate consequence operator and simply write ei ∈ V λ instead of V λ |= ei. We now show that the fixpoint obtained from the immediate consequence operator TwP is indeed the answer set of P .\nProposition 7 Let P be a possibilistic positive clausal program without possibilistic constraint rules. Then P ⋆w is a possibilistic answer set of P .\nThe proof is given in the online appendix of the paper, pp. 6–7.\nThus far, we only considered possibilistic positive clausal programs. If we allow for negation-as-failure, we will also need to generalize the notion of a reduct. As usual, in the classical case we want that an expression of the form ‘not e’ is true when ‘e’ cannot be entailed. Furthermore, since we are working in the possibilistic case, we want to take the degrees into account when determining the reduct.\nDefinition 14 Given a possibilistic clausal program P and a valuation V , the reduct PV of P w.r.t. V is defined as:\nPV = { ((e0 ← e1, ..., em),min(λrule , λbody)) | min(λrule , λbody) > 0\n∧ λbody = max { λ | ∀i ∈ {m+ 1, ..., n} · V 1−λ 6|= ei, λ ∈ [0, 1] }\n∧ ((e0 ← e1, ..., em, not em+1, ..., not en), λrule) ∈ P}\nThis definition corresponds with the Gelfond-Lifschitz reduct when we consider crisp clausal programs where each clause consists of exactly one literal. Indeed, if\nwe consider clauses with exactly one literal, we could simplify ∀i ∈ {m+ 1, ..., n} · V 1−λ 6|= ei to {em+1, ..., en} ∩ V 1−λ = ∅. This new reduct generalises the GelfondLifschitz reduct in two ways. Firstly, we now have clauses, i.e. we now need to verify whether the negative body is not entailed by our guess. Secondly, we need to take the weights attached to the rules, which we interpret as certainties, into account. In particular, the certainty of the reduct of a rule is limited by the certainty of the negative body of the rule and the certainty of the rule itself. In the crisp case these certainty degrees would become trivial.\nProposition 8\nA valuation E is a possibilistic answer set of the possibilistic clausal program P without possibilistic constraint rules iff E is a possibilistic answer set of PE .\nThe proof is given in the online appendix of the paper, pp. 7. Before we discuss the complexity results, we look at an example to further uncover the intuition of clausal programs.\nExample 11\nConsider the possibilistic clausal program P with the following rules:\n0.7 :a ∨ b ∨ c← 0.2 :¬b← 1 : d← not (a ∨ c ∨ f) 1 : e← not c.\nThe reduct PV with V = { (a ∨ b ∨ c)0 .7 , (¬b)0 .2 , d0 .8 , e1 } is then:\n0.7 :a ∨ b ∨ c← 0.2 :¬b← 0.8 : d← 1 : e←\nsince V 1−0.8 |= a ∨ c but V 1−0.8 6|= a ∨ c and V 1−1 6|= c. We then have that (PV ) ⋆\nw = { (a ∨ b ∨ c)0 .7 , (¬b)0 .2 , d0 .8 , e1 } , hence V is indeed an answer set of P ."
    }, {
      "heading" : "5 Complexity Results",
      "text" : "Before we discuss the complexity results of the weak possibilistic semantics for disjunctive rules (Section 4.2), we first look at the complexity results of both possibilistic normal programs (Section 3.2) and the strong possibilistic semantics for disjunctive rules (Section 4.1). As such, for Proposition 9, 10, 11 and 12 we once again consider a valuation V for a possibilistic normal/disjunctive program P as a V : LitP → [0, 1] mapping. We find that for possibilistic normal programs the addition of weights does not affect the complexity compared to classical normal programs.\nProposition 9 (possibilistic normal program; brave reasoning)\nLet P be a possibilistic normal program. The problem of deciding whether there exists a possibilistic answer set V of P such that V (l) ≥ λ is NP-complete.\nThe proof is given in the online appendix of the paper, pp. 8.\nProposition 10 (possibilistic normal program; cautious reasoning) Let P be a possibilistic normal program. The problem of deciding whether for all possibilistic answer sets V of P we have that V (l) ≥ λ is coNP-complete.\nThe proof is given in the online appendix of the paper, pp. 9.\nSimilarly, we find for possibilistic disjunctive programs under the strong disjunctive semantics that the addition of weights does not affect the complexity compared to classical disjunctive programs.\nProposition 11 (possibilistic disjunctive program; brave reasoning) Let P be a possibilistic disjunctive program. The problem of deciding whether there is a possibilistic answer set V such that V (l) ≥ λ is a ΣP2 -complete problem.\nThe proof is given in the online appendix of the paper, pp. 9-10.\nProposition 12 (possibilistic disjunctive program; cautious reasoning) Let P be a possibilistic disjunctive program. The problem of deciding whether for all possibilistic answer sets V we have that V (l) ≥ λ is a ΠP2 -complete problem.\nThe proof is given in the online appendix of the paper, pp. 10-11.\nWe now look at the complexity of the weak possibilistic semantics for disjunctive rules for a variety of decision problems and under a variety of restrictions. In particular, throughout this section we look at the complexity of weak disjunction in the crips case that allows us to compare these results against the complexity of the related decision problems in classical ASP and other epistemic extensions of ASP, e.g. (Truszczyński 2011; Vlaeminck et al. 2012). As we will see, for certain classes of clausal programs, decision problems exist where weak disjunction is computationally less complex than disjunctive programs while remaining more complex than normal programs.\nAn overview of the complexity results available in the literature for disjunctive programs as well as the new results for weak disjunction (in the crisp case) which we discuss in the remainder of this section can be found in Table 1.\nProposition 13 (weak disjunction, positive clausal program; brave reasoning) Let P be a positive clausal program. The problem of deciding whether a clause ‘e’ is entailed by a consistent answer set E of P is BH2-hard.\nThe proof is given in the online appendix of the paper, pp. 11-12.\nProposition 14 (weak disjunction, positive clausal program; brave reasoning) Let P be a positive clausal program. The problem of deciding whether a clause ‘e’ is entailed by a consistent answer set M of P is in BH2.\nThe proof is given in the online appendix of the paper, pp. 12-13.\nCorollary 1 Let P be a positive clausal program. The problem of deciding whether a clause ‘e’ is entailed by a consistent answer set E of P is BH2-complete.\nCorollary 2 (weak disjunction, positive clausal program; answer set existence)\nDetermining whether a positive clausal program P has a consistent answer set is an NP-complete problem.\nThe proof is given in the online appendix of the paper, pp. 14.\nCorollary 3 (weak disjunction, positive clausal program; cautious reasoning)\nCautious reasoning, i.e. determining whether a clause ‘e’ is entailed by every answer set M of a positive clausal program P is coNP-complete.\nThe proof is given in the online appendix of the paper, pp. 14.\nSurprisingly, the expressivity of positive clausal programs under the weak interpretation of disjunction is directly tied to the ability to use classical negation in clauses. If we limit ourselves to positive clausal programs without classical negation we find that the expressiveness is restricted to P.\nIn order to see this, let us take a closer look at the immediate consequence operator for clausal programs as defined in Definition 13. When there are no occurrences of classical negation we can simplify this immediate consequence operator to\nTwP (E) = {e0 | e0 ← e1, ..., em ∈ P ∧ ∀i ∈ {1, ...,m} · ∃e ∈ E · e ⊆ ei}\nwhere e ⊆ ei is defined as the subset relation where we interpret e and ei as sets of literals, i.e. e = (l1 ∨ ... ∨ ln) is interpreted as {l1, ..., ln}.\nProposition 15 Let P be a positive clausal program without classical negation. We can find the unique answer set of P in polynomial time.\nThe proof is given in the online appendix of the paper, pp. 14. We now examine the complexity of general clausal programs. We will do this by showing that the problem of determining the satisfiability of a QBF of the form φ = ∃X1∀X2 · p(X1, X2) with p(X1, X2) in DNF can be reduced to the problem of determining whether a clause ‘e’ is entailed by a consistent answer set M of the clausal program P . We start with the definition of our reduction.\nDefinition 15 Let φ = ∃X1∀X2 · p(X1, X2) be a QBF with p(X1, X2) = θ1 ∨ ... ∨ θn a formula in disjunctive normal form with Xi sets of variables. We define the clausal program Pφ corresponding to φ as\nPφ = {x← not ¬x | x ∈ X1} ∪ {¬x← not x | x ∈ X1} (12)\n∪ {¬θt ∨ sat← | 1 ≤ t ≤ n} (13)\n∪ {← not sat} (14)\nwith ¬θt the clausal representation of the negation of the formula θt, e.g. when θt = x1 ∧ ¬x2 ∧ ... ∧ ¬xk then ¬θt = ¬x1 ∨ x2 ∨ ... ∨ xk.\nExample 12 Given the QBF φ = ∃p1, p2∀q1, q2 · (p1 ∧ q1) ∨ (p2 ∧ q2) ∨ (¬q1 ∧ ¬q2) the clausal program Pφ is\np1 ← not ¬p1\n¬p1 ← not p1\np2 ← not ¬p2\n¬p2 ← not p2\n¬p1 ∨ ¬q1 ∨ sat ←\n¬p2 ∨ ¬q2 ∨ sat ←\nq1 ∨ q2 ∨ sat ←\n← not sat .\nNotice how M = {p1, p2,¬p1 ∨ ¬q1 ∨ sat ,¬p2 ∨ ¬q2 ∨ sat , q1 ∨ q2 ∨ sat} is an answer set of Pφ and that M |= sat . Accordingly we find that the QBF is satisfied.\nIf we take the QBF φ′ = ∃p1, p2∀q1, q2 · (p1 ∧ q1) ∨ (p2 ∧ q2) then the clausal program Pφ′ corresponding to φ ′ is the program Pφ in which the penultimate rule has been removed. Notice how Pφ′ has no answer sets, because we are not able to entail ‘sat ’ from any of the answer sets of Pφ′ . Indeed, the QBF φ ′ is not satisfiable.\nProposition 16 (weak disjunction; brave reasoning) Let P be a clausal program. The problem of deciding whether a clause ‘e’ is entailed by a consistent answer set M of P is ΣP2 -hard.\nThe proof is given in the online appendix of the paper, pp. 14-15.\nProposition 17 (weak disjunction; brave reasoning) Let P be a clausal program. The problem of deciding whether a clause ‘e’ is entailed by a consistent answer set M of P is in ΣP2 .\nThe proof is given in the online appendix of the paper, pp. 15.\nCorollary 4 Let P be a clausal program. The problem of deciding whether a clause ‘e’ is entailed by a consistent answer set E of P is ΣP2 -complete.\nCorollary 5 (weak disjunction; answer set existence) Determining whether a clausal program P has a consistent answer set is an ΣP2 - complete problem.\nThe proof is given in the online appendix of the paper, pp. 15.\nCorollary 6 (weak disjunction; cautious reasoning) Cautious reasoning, i.e. determining whether a clause ‘e’ is entailed by every answer set M of a clausal program P , is ΠP2 -complete.\nProof This problem is complementary to brave reasoning, i.e. we verify that there does not exist an answer set M ′ of P such that ‘¬e’ is entailed by M ′."
    }, {
      "heading" : "6 Related Work",
      "text" : "The work presented in this paper touches on various topics that have been the subject of previous research. In this section we structure our discussion of related existing work along 3 main lines. Previous work on the semantics of disjunctive programs is discussed in Section 6.1. In Section 6.2 we look at how ASP and possibility theory have been used in the literature for epistemic reasoning. Finally, in Section 6.3, we look at prior work on characterizing rules with possibility theory and fuzzy logic."
    }, {
      "heading" : "6.1 Semantics of Disjunctive Programs",
      "text" : "Many characterizations of stable models have been proposed in the literature. We refer the reader to (Lifschitz 2010) for a concise overview of thirteen such definitions. One of the earliest characterizations of stable models was in terms of autoepistemic logic (Moore 1985). Formulas in autoepistemic logic are constructed using atoms and propositional connectives, as well as the modal operator L, which intuitively stands for “it is believed”. The characterization of stable models proposed in (Gelfond and Lifschitz 1991) based on autoepistemic logic is to look at ‘not a’ as the expression ‘¬La’, a choice which clearly stands out for its simplicity and intuitively. For example, to explain the semantics of the rule a0 ← a1, ..., am, not am+1, ..., not an one would consider the formula a1∧...∧am∧¬Lam+1∧ ... ∧ ¬Lan → a0. Yet this characterization does have some problems. Indeed, it\nwas soon afterwards realized that this correspondence does not hold for programs with classical negation or disjunction in the head. A more involved characterization based on autoepistemic logic that does work for classical negation and disjunction has been proposed in (Lifschitz and Schwarz 1993). The idea is to look at literals ‘l’ that are not preceded by negation as failure as the formula (l∧Ll), while one still looks at a literal of the form ‘not l’ as the formula ¬Ll. In our approach, an expression of the form ‘not l’ is essentially identified with Π(¬l), which clearly resembles the first characterization in terms of autoepistemic logic. By staying closer to the Gelfond-Lifschitz reduct, our approach is more elegant in that we do not require a special translation of literals in order to be able to deal with classical negation and disjunction.\nSeveral authors have already proposed alternatives and extensions to the semantics of disjunctive programs. Ordered disjunction (Brewka 2002) falls in the latter category and allows to use the head of the rule to formulate alternative solutions in their preferred order. For example, a rule such as l1 × ... × lk ← represents the knowledge that l1 is preferred over l2 which is preferred over l3 . . . , but that at the very least we want lk to be true. As such it allows for an easy way to express context dependent preferences. The semantics of ordered disjunction allow certain non-minimal models to be answer sets, hence, unlike the work in this paper, it does not adhere to the standard semantics of disjunctive rules in ASP.\nAnnotated disjunctions are another example of a framework that changes the semantics of disjunctive programs (Vennekens et al. 2004). It is based on the idea that every disjunct in the head of a rule is annotated with a probability. Interestingly, both ordered and annotated disjunction rely on split programs, as found in the possible model semantics (Sakama and Inoue 1994). These semantics provide an alternative to the minimal model semantics. The idea is to split a disjunctive program into a number of normal programs, one for each possible choice of disjuncts in the head, of which the minimal Herbrand models are then the possible models of the disjunctive programs. Intuitively this means that a possible model represents a set of atoms for which a possible justification is present in the program. In line with our conclusions for weak disjunction, using the possible model semantics also leads to a lower computational complexity.\nNot all existing extensions of disjunction allow non-minimal models. For example, in (Buccafurri et al. 2002) an extension of disjunctive logic programs is presented which adds the idea of inheritance. Conflicts between rules are then resolved in favor of more specific rules. Such an approach allows for an intuitive way to deal with default reasoning and exceptions. In particular, the semantics allow for rules to be marked as being defeasible and allows to specify an order or inheritance tree among (sets of) rules. Interestingly, the complexity of the resulting system is not affected and coincides with the complexity of ordinary disjunctive programs."
    }, {
      "heading" : "6.2 Epistemic Reasoning with ASP and Possibility Theory",
      "text" : "In (Gelfond 1991) it was argued that classical ASP, while later proven to have strong epistemic foundations (Loyer and Straccia 2006), is not well-suited for epistemic\nreasoning. Specifically, ASP lacks mechanisms for introspection and can thus not be used to e.g. reason based on cautiously deducible information. At the same time, however, it was shown that extensions of ASP could be devised that do allow for a natural form of epistemic reasoning. The language ASPK proposed in (Gelfond 1991) allows for modal atoms, e.g. Ka, where K is a modal operator that can intuitively be read as “it is known that [a is true]”. These new modal atoms can in turn be used in the body of rules. The semantics of ASPK were originally based on a three-valued interpretation (to allow for the additional truth value ‘uncertain’), but later, in (Truszczyński 2011), it was shown that this is not essential and that a more classical two-valued possible world structure can also be considered. In addition, further extensions are discussed that allow for epistemic reasoning over arbitrary theories, where it is shown that ASPK can be encoded within these extensions. The complexity is studied for these extensions and is shown to be brought up one level w.r.t. ASP, e.g. to ΣP3 for disjunctive epistemic programs.\nAlternatively, existing extensions of ASP can be used to implement some epistemic reasoning tasks, such as reasoning based on brave/cautious conclusions. This idea is proposed in (Faber and Woltran 2009) to overcome the need for an intermediary step to compute the desired consequences of the ASP program P1, before being fed into P2. Rather, they propose a translation to manifold answer set programs, which exploit the concept of weak constraints (Buccafurri et al. 2000) to allow for such programs to access all desired consequences of P1 within a single answer set. As such, for problems that can be cast into this particular form, only a single ASP program needs to be evaluated and the intermediary step is made obsolete.\nAs we mentioned in Section 6.1, the semantics of ASP can also be expressed in terms of autoepistemic logic (Marek and Truszczyński 1991). These semantics have the benefit of making the modal operator explicit, allowing for an extensions of ASP that incorporates such explicit modalities to better express exactly which form of knowledge is required. However, since autoepistemic logic treats negation-as-failure as a modality, it is quite hard to extend to the uncertain case. Furthermore, as already discussed, it as shown in (Lifschitz and Schwarz 1993) that this characterization does not allow us to treat classical negation or disjunctive rules in a natural way, which weakens its position as a candidate for generalizing ASP from normal programs to e.g. disjunctive programs.\nPossibility theory, which can e.g. be used for belief revision, has a strong epistemic\nnotion and shares a lot of commonalities with epistemic entrenchments (Dubois and Prade 1991). Furthermore, in (Dubois et al. 2012) a generalization of possibilistic logic is studied, which corresponds to a weighted version of a fragment of the modal logic KD. In this logic, epistemic states are represented as possibility distributions, and logical formulas are used to express constraints on possible epistemic states. In this paper, we similarly interpret rules in ASP as constraints on possibility distributions, which furthermore allows us to unearth the semantics of weak disjunction."
    }, {
      "heading" : "6.3 Characterization of Rules using Possibility Theory and Fuzzy Logic",
      "text" : "A large amount of research has focused on how possibility distributions can be used to assign a meaning to rules. For example, possibility theory has been used to model default rules (Benferhat et al. 1992; Benferhat et al. 1997). Specifically, a default rule “if a then b” is interpreted as Π(a∧b) > Π(a∧¬b), which captures the intuition that when a is known to hold, b is more plausible than ¬b, if all that is known is that a holds. In this approach entailment is defined by looking at the least specific possibility distributions which is similar in spirit to our approach for characterizing ASP rules (although the notion of least specific possibility distribution is defined, in this context, w.r.t. the plausibility ordering on interpretations induced by the possibility degrees).\nThe work on possibilistic logic (Dubois et al. 1994) forms the basis of possibilistic logic programming (Dubois et al. 1991). The idea of possibilistic logic programming is to start from a necessity-valued knowledge base, which is a finite set of pairs (φ α), called necessity-valued formulas, with φ a closed first-order formula and α ∈ [0, 1]. Semantically, a necessity-valued formula expresses a constraint of the form N(φ) ≥ α on the set of possibility distributions. A possibilistic logic program is then a set of necessity-valued implications. As rules are essentially modelled using material implication, however, the stable model semantics cannot straightforwardly be characterized using possibilistic logic programming. For example, the knowledge base {(a→ b 1), (¬b 1)}, which represents the program {b← a,¬b←}, induces that N(¬a) = 1. Indeed, the semantics of this knowledge base indicate that Π(a ∧ ¬b) = 0 and Π(b) = 0, i.e. we find that Π(a) = 0. In other words: a direct encoding using possibilistic logic programming allows for contraposition, which is not in accordance with the stable model semantics.\nRules in logic can also be interpreted as statements of conditional probability (Jaynes 2003). In the possibilistic setting this notion has been adapted to the notion of conditional necessity measures. Rules can be then also be modelled in terms of conditional necessity measures (Benferhat et al. 1997; Dubois and Prade 1997; Benferhat et al. 2002). The conditional possibility measure Π (ψ | φ) is defined as the greatest solution to the equation Π(φ∧ψ) = min(Π (ψ | φ) ,Π(φ)) in accordance with the principle of least specificity. It can be derived mathematically that this gives us Π (ψ | φ) = 1 if Π(ψ ∧ φ) = Π(φ) and Π (ψ | φ) = Π(ψ ∧ φ) otherwise whenever Π(φ) > 0. When Π(φ) = 0, then by convention Π (ψ | φ) = 1 for every ψ 6= ⊥ and Π (⊥ | φ) = 0, otherwise. The conditional necessity measure is defined as N (ψ | φ) = 1−Π(¬ψ | φ). However, there does not seem to be a straightforward way to capture the stable model semantics using conditional necessity measures, especially when classical negation is allowed. Indeed, if we represent the semantics of the program {b← a,¬b←} as the constraints N (b | a) ≥ 1 and N (¬a | ⊤) ≥ 1. Using the definition of the conditional necessity measure, the first constraint is equivalent to 1−Π(¬b | a) ≥ 1, i.e. Π (¬b | a) = 0. The second constraint simplifies to Π(a) = 0, which, using the convention stated above gives rise to Π (¬b | a) = 1, clearly a contradictory result to the earlier conclusion that Π (¬b | a) = 0.\nThe work in (Nicolas et al. 2006) was one of the first papers to explore the idea\nof combining possibility theory with ASP. Rather than defining the semantics of ASP in terms of constraints on possibility distributions as we did in this paper, the goal was to allow one to reason with possibilities in ASP programs. In this way one can associate certainties with the information encoded in an ASP program. The approach from (Nicolas et al. 2006) upholds the 1-on-1 relationship between the classical answer sets of a normal program and the possibilistic answer sets, which brings with it some advantages. One of those advantages is that it allows us to deal with possibilistic nested programs (Nieves and Lindgren 2012). The work from Nicolas et al. was later extended to also cover the case of disjunctive ASP in (Nieves et al. 2013). The latter approach allows us to e.g. capture qualitative information by considering partially ordered sets, which would not be straightforward to accomplish in our work. However, the approaches from (Nicolas et al. 2006) and (Nieves et al. 2013) work by taking a possibilistic ASP program and reducing it – by ignoring the certainty values – to a possibilistic ASP program without negation-as-failure. As such, both approaches loose the certainty encoded through negation-as-failure, since the certainty values are not taken into account.\nPossibility theory has also been used to define various semantics of fuzzy if-then rules (Zadeh 1992). Rather than working with literals, fuzzy if-then rules consider fuzzy predicates which each have their own universe of discourse. To draw conclusions from a set of fuzzy if-then rules, mechanisms are needed that can produce an (intuitively acceptable) conclusion from a set of such rules.\nFinally, a formal connection also exists between the approach from Section 3 and the work on residuated logic programs (Damásio and Pereira 2001) under the Gödel semantics. Both approaches are different in spirit, however, in the same way that possibilistic logic (which deals with uncertainty or priority) is different from Gödel logic (which deals with graded truth). The formal connection is due to the fact that necessity measures are min-decomposable and disappears as soon as classical negation or disjunction is considered."
    }, {
      "heading" : "7 Conclusions",
      "text" : "In this paper we defined semantics for Possibilistic ASP (PASP), a framework that combines possibility theory and ASP to allow for reasoning under (qualitative) uncertainty. These semantics are based on the interpretation of possibilistic rules as constraints on possibility distributions. We showed how our semantics for PASP differ from existing semantics for PASP. Specifically, they adhere to a different intuition for negation-as-failure. As such, they can be used to arrive at acceptable results for problems where the possibilistic answer sets according to the existing semantics for PASP do not necessarily agree with our intuition of the problem. In addition, we showed how our semantics for PASP allowed for a new characterization of ASP. When looking at ASP as a special case of PASP, we naturally recover the intuition of a rule that the head is certain whenever we are certain that the body holds. The resulting characterization stays close to the intuition of the stable model semantics, yet also shares the explicit reference to modalities with autoepistemic logic. We showed that this characterization not only naturally characterizes normal\nprograms, i.e. programs with negation-a-failure, but can also naturally characterize disjunctive programs and programs with classical negation.\nDue to our explicit reference to modalities in the semantics, we are furthermore able to characterize an alternative semantics for disjunction in the head of a rule that has a more epistemic flavour than the standard treatment of disjunction in ASP, i.e. given a rule of the form (a ∨ b ←) we do not obtain two answer sets, but rather we have ‘a ∨ b’ as-is in the answer set. While such a characterization might seem weak, we showed that the interplay with literals significantly affects the expressiveness. Indeed, we found that the problem of brave reasoning/cautious reasoning under these weak semantics for disjunction for a program without negationas-failure, but with classical negation, is BH2-complete and coNP-complete, respectively. This highlights that weak disjunction is not merely syntactic sugar, i.e. it cannot simply be simulated in normal ASP without causing an exponential blow-up. For strong disjunction, on the other hand, we have obtained that brave and cautious reasoning without negation-as-failure are ΣP2 -complete and coNP-complete, respectively. As such, the weak semantics for disjunction detailed in this paper allow us to work with disjunction in a less complex way that still remains non-trivial. If, however, we restrict ourselves to atoms, then brave reasoning under the weak semantics for disjunction is P-complete."
    } ],
    "references" : [ {
      "title" : "A simple modal logic for reasoning about revealed beliefs",
      "author" : [ "M. Banerjee", "D. Dubois" ],
      "venue" : "Proceedings of the 10th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU’09). 805–816.",
      "citeRegEx" : "Banerjee and Dubois,? 2009",
      "shortCiteRegEx" : "Banerjee and Dubois",
      "year" : 2009
    }, {
      "title" : "Knowledge, Representation, Reasoning and Declarative Problem Solving",
      "author" : [ "C. Baral" ],
      "venue" : "Cambridge University Press.",
      "citeRegEx" : "Baral,? 2003",
      "shortCiteRegEx" : "Baral",
      "year" : 2003
    }, {
      "title" : "Possibilistic answer set programming revisited",
      "author" : [ "K. Bauters", "S. Schockaert", "M. De Cock", "D. Vermeir" ],
      "venue" : "Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence (UAI).",
      "citeRegEx" : "Bauters et al\\.,? 2010",
      "shortCiteRegEx" : "Bauters et al\\.",
      "year" : 2010
    }, {
      "title" : "Weak and strong disjunction in possibilistic ASP",
      "author" : [ "K. Bauters", "S. Schockaert", "M. De Cock", "D. Vermeir" ],
      "venue" : "Proceedings of the 11th International Conference on Scalable Uncertainty Management (SUM).",
      "citeRegEx" : "Bauters et al\\.,? 2011",
      "shortCiteRegEx" : "Bauters et al\\.",
      "year" : 2011
    }, {
      "title" : "On the transformation between possibilistic logic bases and possibilistic causal networks",
      "author" : [ "S. Benferhat", "D. Dubois", "L. Garcia", "H. Prade" ],
      "venue" : "International Journal of Approximate Reasoning 29, 2, 135–173.",
      "citeRegEx" : "Benferhat et al\\.,? 2002",
      "shortCiteRegEx" : "Benferhat et al\\.",
      "year" : 2002
    }, {
      "title" : "Representing default rules in possibilistic logic",
      "author" : [ "S. Benferhat", "D. Dubois", "H. Prade" ],
      "venue" : "Proceedings of the 3rd International Conference on Principles of Knowledge Representation and Reasoning (KR). 673–684.",
      "citeRegEx" : "Benferhat et al\\.,? 1992",
      "shortCiteRegEx" : "Benferhat et al\\.",
      "year" : 1992
    }, {
      "title" : "Nonmonotonic reasoning, conditional objects and possibility theory",
      "author" : [ "S. Benferhat", "D. Dubois", "H. Prade" ],
      "venue" : "Artificial Intelligence 92, 1–2, 259–276.",
      "citeRegEx" : "Benferhat et al\\.,? 1997",
      "shortCiteRegEx" : "Benferhat et al\\.",
      "year" : 1997
    }, {
      "title" : "Logic programming with ordered disjunction",
      "author" : [ "G. Brewka" ],
      "venue" : "Proceedings of the 18th National Conference on Artificial Intelligence (AAAI). 100–105.",
      "citeRegEx" : "Brewka,? 2002",
      "shortCiteRegEx" : "Brewka",
      "year" : 2002
    }, {
      "title" : "Disjunctive logic programs with inheritance",
      "author" : [ "F. Buccafurri", "W. Faber", "N. Leone" ],
      "venue" : "Theory and Practice of Logic Programming 2, 3, 293–321.",
      "citeRegEx" : "Buccafurri et al\\.,? 2002",
      "shortCiteRegEx" : "Buccafurri et al\\.",
      "year" : 2002
    }, {
      "title" : "Enhancing disjunctive datalog by constraints",
      "author" : [ "F. Buccafurri", "N. Leone", "P. Rullo" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering 12, 5, 845–860.",
      "citeRegEx" : "Buccafurri et al\\.,? 2000",
      "shortCiteRegEx" : "Buccafurri et al\\.",
      "year" : 2000
    }, {
      "title" : "The boolean hierarchy I: Structural properties",
      "author" : [ "Cai", "J.-Y", "T. Gundermann", "J. Hartmanis", "L. Hemachandra", "V. Sewelson", "K. Wagner", "G. Wechsung" ],
      "venue" : "SIAM Journal on Computing",
      "citeRegEx" : "Cai et al\\.,? \\Q1988\\E",
      "shortCiteRegEx" : "Cai et al\\.",
      "year" : 1988
    }, {
      "title" : "Monotonic and residuated logic programs",
      "author" : [ "C.V. Damásio", "L.M. Pereira" ],
      "venue" : "ECSQARU ’01: Proceedings of the 6th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty. 748–759.",
      "citeRegEx" : "Damásio and Pereira,? 2001",
      "shortCiteRegEx" : "Damásio and Pereira",
      "year" : 2001
    }, {
      "title" : "Towards possibilistic logic programming",
      "author" : [ "D. Dubois", "J. Lang", "H. Prade" ],
      "venue" : "Proceedings of the 8th International Conference on Logic Programming (ICLP). 581– 595.",
      "citeRegEx" : "Dubois et al\\.,? 1991",
      "shortCiteRegEx" : "Dubois et al\\.",
      "year" : 1991
    }, {
      "title" : "Possibilistic logic",
      "author" : [ "D. Dubois", "J. Lang", "H. Prade" ],
      "venue" : "Handbook of Logic for Artificial Intelligence and Logic Programming 3, 1, 439–513.",
      "citeRegEx" : "Dubois et al\\.,? 1994",
      "shortCiteRegEx" : "Dubois et al\\.",
      "year" : 1994
    }, {
      "title" : "Epistemic entrenchment and possibilistic logic",
      "author" : [ "D. Dubois", "H. Prade" ],
      "venue" : "Artificial Intelligence 50, 2, 223–239.",
      "citeRegEx" : "Dubois and Prade,? 1991",
      "shortCiteRegEx" : "Dubois and Prade",
      "year" : 1991
    }, {
      "title" : "A synthetic view of belief revision with uncertain inputs in the framework of possibility theory",
      "author" : [ "D. Dubois", "H. Prade" ],
      "venue" : "International Journal of Approximate Reasoning 17, 2-3, 295–324.",
      "citeRegEx" : "Dubois and Prade,? 1997",
      "shortCiteRegEx" : "Dubois and Prade",
      "year" : 1997
    }, {
      "title" : "Stable models in generalized possibilistic logic",
      "author" : [ "D. Dubois", "H. Prade", "S. Schockaert" ],
      "venue" : "Proceedings of the 13th International Conference on Principles of Knowledge Representation and Reasoning (KR’12), 519–529.",
      "citeRegEx" : "Dubois et al\\.,? 2012",
      "shortCiteRegEx" : "Dubois et al\\.",
      "year" : 2012
    }, {
      "title" : "Complexity results for disjunctive logic programming and application to nonmonotonic logics",
      "author" : [ "T. Eiter", "G. Gottlob" ],
      "venue" : "Proceedings of the 1993 International Logic Programming Symposium (ILPS). 266–278.",
      "citeRegEx" : "Eiter and Gottlob,? 1993",
      "shortCiteRegEx" : "Eiter and Gottlob",
      "year" : 1993
    }, {
      "title" : "Manifold answer-set programs for meta-reasoning",
      "author" : [ "W. Faber", "S. Woltran" ],
      "venue" : "LPNMR. Lecture Notes in Computer Science, vol. 5753. Springer, 115–128.",
      "citeRegEx" : "Faber and Woltran,? 2009",
      "shortCiteRegEx" : "Faber and Woltran",
      "year" : 2009
    }, {
      "title" : "On stratified autoepistemic theories",
      "author" : [ "M. Gelfond" ],
      "venue" : "Proceedings of the 6th National Conference on Artificial Intelligence (AAAI). 207–211.",
      "citeRegEx" : "Gelfond,? 1987",
      "shortCiteRegEx" : "Gelfond",
      "year" : 1987
    }, {
      "title" : "Strong introspection",
      "author" : [ "M. Gelfond" ],
      "venue" : "Proceedings of the 9th National conference on Artificial intelligence (AAAI’91). 386–391.",
      "citeRegEx" : "Gelfond,? 1991",
      "shortCiteRegEx" : "Gelfond",
      "year" : 1991
    }, {
      "title" : "Classical negation in logic programs and disjunctive databases",
      "author" : [ "M. Gelfond", "V. Lifschitz" ],
      "venue" : "New Generation Computing 9, 365–385.",
      "citeRegEx" : "Gelfond and Lifschitz,? 1991",
      "shortCiteRegEx" : "Gelfond and Lifschitz",
      "year" : 1991
    }, {
      "title" : "The stable model semantics for logic programming",
      "author" : [ "M. Gelfond", "V. Lifzchitz" ],
      "venue" : "Proceedings of the 5th International Conference on Logic Programming (ICLP). 1081–1086.",
      "citeRegEx" : "Gelfond and Lifzchitz,? 1988",
      "shortCiteRegEx" : "Gelfond and Lifzchitz",
      "year" : 1988
    }, {
      "title" : "Logic in Computer Science: Modelling and Reasoning about Systems",
      "author" : [ "M. Huth", "M. Ryan" ],
      "venue" : "Cambridge University Press.",
      "citeRegEx" : "Huth and Ryan,? 2004",
      "shortCiteRegEx" : "Huth and Ryan",
      "year" : 2004
    }, {
      "title" : "Probability Theory: The Logic of Science",
      "author" : [ "E. Jaynes" ],
      "venue" : "Cambridge University Press.",
      "citeRegEx" : "Jaynes,? 2003",
      "shortCiteRegEx" : "Jaynes",
      "year" : 2003
    }, {
      "title" : "Thirteen definitions of a stable model",
      "author" : [ "V. Lifschitz" ],
      "venue" : "Fields of Logic and Computation. Lecture Notes in Computer Science, vol. 6300. 488–503.",
      "citeRegEx" : "Lifschitz,? 2010",
      "shortCiteRegEx" : "Lifschitz",
      "year" : 2010
    }, {
      "title" : "Extended logic programs as autoepistemic theories",
      "author" : [ "V. Lifschitz", "G. Schwarz" ],
      "venue" : "In Proceedings of the 2nd International Workshop on Logic Programming and Nonmonotonic Reasoning. 101–114.",
      "citeRegEx" : "Lifschitz and Schwarz,? 1993",
      "shortCiteRegEx" : "Lifschitz and Schwarz",
      "year" : 1993
    }, {
      "title" : "Epistemic foundation of stable model semantics",
      "author" : [ "Y. Loyer", "U. Straccia" ],
      "venue" : "Theory and Practice of Logic Programming 6, 4, 355–393.",
      "citeRegEx" : "Loyer and Straccia,? 2006",
      "shortCiteRegEx" : "Loyer and Straccia",
      "year" : 2006
    }, {
      "title" : "Autoepistemic logic",
      "author" : [ "W. Marek", "M. Truszczyński" ],
      "venue" : "Journal of the ACM 38, 587–618.",
      "citeRegEx" : "Marek and Truszczyński,? 1991",
      "shortCiteRegEx" : "Marek and Truszczyński",
      "year" : 1991
    }, {
      "title" : "Semantical considerations on nonmonotonic logic",
      "author" : [ "R. Moore" ],
      "venue" : "Artificial Intelligence 29, 1, 75–94.",
      "citeRegEx" : "Moore,? 1985",
      "shortCiteRegEx" : "Moore",
      "year" : 1985
    }, {
      "title" : "On the complexity of fragments of modal logics",
      "author" : [ "L.A. Nguyen" ],
      "venue" : "Proceedings of the 5th International Conference on Advances in Modal logic (AiML’05). 249–268.",
      "citeRegEx" : "Nguyen,? 2005",
      "shortCiteRegEx" : "Nguyen",
      "year" : 2005
    }, {
      "title" : "Possibilistic uncertainty handling for answer set programming",
      "author" : [ "P. Nicolas", "L. Garcia", "I. Stéphan", "C. Lefèvre" ],
      "venue" : "Annals of Mathematics and Artificial Intelligence 47, 1–2, 139–181.",
      "citeRegEx" : "Nicolas et al\\.,? 2006",
      "shortCiteRegEx" : "Nicolas et al\\.",
      "year" : 2006
    }, {
      "title" : "Possibilistic nested logic programs",
      "author" : [ "J.C. Nieves", "H. Lindgren" ],
      "venue" : "Technical Communications of the 28th International Conference on Logic Programming (ICLP’12). 267–276.",
      "citeRegEx" : "Nieves and Lindgren,? 2012",
      "shortCiteRegEx" : "Nieves and Lindgren",
      "year" : 2012
    }, {
      "title" : "Semantics for possibilistic disjunctive programs",
      "author" : [ "J.C. Nieves", "M. Osorio", "U. Cortés" ],
      "venue" : "Theory and Practice of Logic Programming 13, 1, 33–70.",
      "citeRegEx" : "Nieves et al\\.,? 2013",
      "shortCiteRegEx" : "Nieves et al\\.",
      "year" : 2013
    }, {
      "title" : "Computational complexity",
      "author" : [ "C. Papadimitriou" ],
      "venue" : "Addison-Wesley.",
      "citeRegEx" : "Papadimitriou,? 1994",
      "shortCiteRegEx" : "Papadimitriou",
      "year" : 1994
    }, {
      "title" : "A new logical characterization of stable models and answer sets",
      "author" : [ "D. Pearce" ],
      "venue" : "Proceedings of the 2nd International Workshop on Non-Monotonic Extensions of Logic Programming (NMELP). Lecture Notes in Artificial Intelligence, vol. 1216. 57–70.",
      "citeRegEx" : "Pearce,? 1997",
      "shortCiteRegEx" : "Pearce",
      "year" : 1997
    }, {
      "title" : "An alternative approach to the semantics of disjunctive logic programs and deductive databases",
      "author" : [ "C. Sakama", "K. Inoue" ],
      "venue" : "Journal of Automated Reasoning 13, 1, 145– 172.",
      "citeRegEx" : "Sakama and Inoue,? 1994",
      "shortCiteRegEx" : "Sakama and Inoue",
      "year" : 1994
    }, {
      "title" : "Revisiting epistemic specifications",
      "author" : [ "M. Truszczyński" ],
      "venue" : "Logic Programming, Knowledge Representation, and Nonmonotonic Reasoning. Lecture Notes in Computer Science, vol. 6565. Springer Berlin Heidelberg, 315–333.",
      "citeRegEx" : "Truszczyński,? 2011",
      "shortCiteRegEx" : "Truszczyński",
      "year" : 2011
    }, {
      "title" : "Logic programs with annotated disjunctions",
      "author" : [ "J. Vennekens", "S. Verbaeten", "M. Bruynooghe" ],
      "venue" : "Proceedings of the 20th International Conference on Logic Programming (ICLP). Lecture Notes in Computer Science, vol. 3132. 431–445.",
      "citeRegEx" : "Vennekens et al\\.,? 2004",
      "shortCiteRegEx" : "Vennekens et al\\.",
      "year" : 2004
    }, {
      "title" : "Ordered epistemic logic: Semantics, complexity and applications",
      "author" : [ "H. Vlaeminck", "J. Vennekens", "M. Bruynooghe", "M. Denecker" ],
      "venue" : "Principles of Knowledge Representation and Reasoning: Proceedings of the 13th International Conference (KR’12).",
      "citeRegEx" : "Vlaeminck et al\\.,? 2012",
      "shortCiteRegEx" : "Vlaeminck et al\\.",
      "year" : 2012
    }, {
      "title" : "Fuzzy logic and the calculus of fuzzy if-then rules",
      "author" : [ "L. Zadeh" ],
      "venue" : "Proceedings of the 22nd IEEE International Symposium on Multiple-Valued Logic (ISMVL). 480–480.",
      "citeRegEx" : "Zadeh,? 1992",
      "shortCiteRegEx" : "Zadeh",
      "year" : 1992
    } ],
    "referenceMentions" : [ {
      "referenceID" : 31,
      "context" : "Semantics for PASP have been introduced in (Nicolas et al. 2006) for possibilistic normal programs and later extended to possibilistic disjunctive programs in (Nieves et al.",
      "startOffset" : 43,
      "endOffset" : 64
    }, {
      "referenceID" : 33,
      "context" : "2006) for possibilistic normal programs and later extended to possibilistic disjunctive programs in (Nieves et al. 2013).",
      "startOffset" : 100,
      "endOffset" : 120
    }, {
      "referenceID" : 31,
      "context" : "Specifically, to deal with PASP rules without negation-as-failure, the semantics from (Nicolas et al. 2006) treat such rules as implications in possibilistic logic (Dubois et al.",
      "startOffset" : 86,
      "endOffset" : 107
    }, {
      "referenceID" : 13,
      "context" : "2006) treat such rules as implications in possibilistic logic (Dubois et al. 1994).",
      "startOffset" : 62,
      "endOffset" : 82
    }, {
      "referenceID" : 31,
      "context" : "When faced with negation-as-failure, the semantics from (Nicolas et al. 2006) rely on the reduct operation from classical ASP.",
      "startOffset" : 56,
      "endOffset" : 77
    }, {
      "referenceID" : 31,
      "context" : "However, as the semantics from (Nicolas et al. 2006) adhere to a different intuition of negation-as-failure, the conclusion is that you need to go to the airport with a necessity of 0.",
      "startOffset" : 31,
      "endOffset" : 52
    }, {
      "referenceID" : 31,
      "context" : "These semantics do not correspond with the semantics from (Nicolas et al. 2006) when considering programs with negation-as-failure.",
      "startOffset" : 58,
      "endOffset" : 79
    }, {
      "referenceID" : 31,
      "context" : "this paper can be used in settings in which the possibilistic answer sets according to (Nicolas et al. 2006) do not correspond with the intuitively acceptable results.",
      "startOffset" : 87,
      "endOffset" : 108
    }, {
      "referenceID" : 22,
      "context" : "One of the most popular characterizations is in terms of the Gelfond-Lifschitz reduct (Gelfond and Lifzchitz 1988) in which an answer set is guessed and verified to be stable.",
      "startOffset" : 86,
      "endOffset" : 114
    }, {
      "referenceID" : 31,
      "context" : "This characterization is used in the semantics for PASP as presented in (Nicolas et al. 2006).",
      "startOffset" : 72,
      "endOffset" : 93
    }, {
      "referenceID" : 28,
      "context" : "Alternatively, the answer set semantics of normal programs can be defined in terms of autoepistemic logic (Marek and Truszczyński 1991), a well-known non-monotonic modal logic.",
      "startOffset" : 106,
      "endOffset" : 135
    }, {
      "referenceID" : 26,
      "context" : "However, as has been shown early on in (Lifschitz and Schwarz 1993), the characterization in terms of autoepistemic logic does not allow us to treat classical negation or disjunctive rules in a natural way, which weakens its position as a candidate for generalizing ASP from normal programs to e.",
      "startOffset" : 39,
      "endOffset" : 67
    }, {
      "referenceID" : 35,
      "context" : "Equilibrium logic (Pearce 1997) offers yet another way for characterizing and extending ASP, but does not feature modalities which limits its potential for epistemic reasoning as it does not allow us to reason over the established knowledge of an agent.",
      "startOffset" : 18,
      "endOffset" : 31
    }, {
      "referenceID" : 3,
      "context" : "This paper aggregates and extends parts of our work from (Bauters et al. 2011) and substantially extends a previous conference paper (Bauters et al.",
      "startOffset" : 57,
      "endOffset" : 78
    }, {
      "referenceID" : 2,
      "context" : "2011) and substantially extends a previous conference paper (Bauters et al. 2010), which did not consider classical negation nor computational complexity.",
      "startOffset" : 60,
      "endOffset" : 81
    }, {
      "referenceID" : 31,
      "context" : "We then review the semantics of PASP from (Nicolas et al. 2006), a framework that combines possibilistic logic and ASP.",
      "startOffset" : 42,
      "endOffset" : 63
    }, {
      "referenceID" : 22,
      "context" : "The semantics of an ASP program with negation-as-failure is based on the idea of a stable model (Gelfond and Lifzchitz 1988).",
      "startOffset" : 96,
      "endOffset" : 124
    }, {
      "referenceID" : 1,
      "context" : "When P has the answer set LitP , then this is the unique (Baral 2003) inconsistent answer set and we say that P is an inconsistent program.",
      "startOffset" : 57,
      "endOffset" : 69
    }, {
      "referenceID" : 13,
      "context" : "At the semantic level, possibilistic logic (Dubois et al. 1994) is defined in",
      "startOffset" : 43,
      "endOffset" : 63
    }, {
      "referenceID" : 13,
      "context" : "The possibility measure Π is defined by (Dubois et al. 1994):",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 13,
      "context" : "and evaluates the extent to which a proposition p is entailed by the available beliefs (Dubois et al. 1994).",
      "startOffset" : 87,
      "endOffset" : 107
    }, {
      "referenceID" : 13,
      "context" : "only normalized possibility distributions can express consistent beliefs) (Dubois et al. 1994).",
      "startOffset" : 74,
      "endOffset" : 94
    }, {
      "referenceID" : 13,
      "context" : "Such a least specific possibility distribution always exists and is unique (Dubois et al. 1994).",
      "startOffset" : 75,
      "endOffset" : 95
    }, {
      "referenceID" : 31,
      "context" : "Possibilistic ASP (PASP) (Nicolas et al. 2006) combines ASP and possibility theory by associating a weight with each rule, where the weight denotes the necessity with which the head of the rule can be concluded given that the body is known to hold.",
      "startOffset" : 25,
      "endOffset" : 46
    }, {
      "referenceID" : 31,
      "context" : "We now present a straightforward extension of the semantics for PASP introduced in (Nicolas et al. 2006).",
      "startOffset" : 83,
      "endOffset" : 104
    }, {
      "referenceID" : 31,
      "context" : "Note that the immediate consequence operator defined in Definition 1 is equivalent to the one proposed in (Nicolas et al. 2006), although we formulate it somewhat differently.",
      "startOffset" : 106,
      "endOffset" : 127
    }, {
      "referenceID" : 31,
      "context" : "Also, the work from (Nicolas et al. 2006) only considered definite programs, even though adding classical negation does not impose any problems.",
      "startOffset" : 20,
      "endOffset" : 41
    }, {
      "referenceID" : 31,
      "context" : "The reduct P of a possibilistic normal program is defined as (Nicolas et al. 2006):",
      "startOffset" : 61,
      "endOffset" : 82
    }, {
      "referenceID" : 31,
      "context" : "The semantics we presented allow for classical negation, even though this was not considered in (Nicolas et al. 2006).",
      "startOffset" : 96,
      "endOffset" : 117
    }, {
      "referenceID" : 1,
      "context" : "However, adding classical negation does not impose any problems and could, as an alternative, easily be simulated in ASP (Baral 2003).",
      "startOffset" : 121,
      "endOffset" : 133
    }, {
      "referenceID" : 34,
      "context" : "The complexity classes ΣP2 and ΠP2 are defined as follows (Papadimitriou 1994): ΣP0 = Π P 0 = P ΣP1 = NP Σ P 2 = NP NP",
      "startOffset" : 58,
      "endOffset" : 78
    }, {
      "referenceID" : 10,
      "context" : "We also consider the complexity class BH2 (Cai et al. 1988), which is the class of all languages L such that L = L1 ∩ L2, where L1 is in NP and L2 is in coNP.",
      "startOffset" : 42,
      "endOffset" : 59
    }, {
      "referenceID" : 1,
      "context" : "Brave reasoning as well as answer set existence for simple, normal and disjunctive programs is P-complete, NP-complete and ΣP2 -complete, respectively (Baral 2003).",
      "startOffset" : 151,
      "endOffset" : 163
    }, {
      "referenceID" : 1,
      "context" : "Cautious reasoning for simple, normal and disjunctive programs is P-complete, coNP-complete and ΠP2 complete (Baral 2003).",
      "startOffset" : 109,
      "endOffset" : 121
    }, {
      "referenceID" : 19,
      "context" : "For instance, ASP can be characterized in autoepistemic logic by interpreting ‘not a’ as the epistemic formula ¬La (“a is not believed”) (Gelfond 1987).",
      "startOffset" : 137,
      "endOffset" : 151
    }, {
      "referenceID" : 31,
      "context" : "This characterization does not coincide with the semantics proposed in (Nicolas et al. 2006) for PASP, as the semantics from (Nicolas et al.",
      "startOffset" : 71,
      "endOffset" : 92
    }, {
      "referenceID" : 31,
      "context" : "2006) for PASP, as the semantics from (Nicolas et al. 2006) rely on the classical Gelfond-Lifschitz reduct.",
      "startOffset" : 38,
      "endOffset" : 59
    }, {
      "referenceID" : 22,
      "context" : "The approach taken in (Gelfond and Lifzchitz 1988) to deal with negation-as-failure is to guess an interpretation and verify whether this guess is stable.",
      "startOffset" : 22,
      "endOffset" : 50
    }, {
      "referenceID" : 31,
      "context" : "In particular, this characterization of PASP does not coincide with the semantics of (Nicolas et al. 2006) and adheres to a different intuition for negation-as-failure.",
      "startOffset" : 85,
      "endOffset" : 106
    }, {
      "referenceID" : 31,
      "context" : "Still, it is interesting to further investigate the particular relationship between the semantics for PASP as proposed in (Nicolas et al. 2006) and the semantics presented in this section.",
      "startOffset" : 122,
      "endOffset" : 143
    }, {
      "referenceID" : 31,
      "context" : "In particular, for the semantics of (Nicolas et al. 2006) we have that FN is the Gödel negator FG, defined as FG(0) = 1 and FG(c) = 0 with 0 < c ≤ 1.",
      "startOffset" : 36,
      "endOffset" : 57
    }, {
      "referenceID" : 31,
      "context" : "we obtain under the approach from (Nicolas et al. 2006) the reduct (0: b ← ), whereas under our approach we obtain the constraint N(b) ≥ min(0.",
      "startOffset" : 34,
      "endOffset" : 55
    }, {
      "referenceID" : 31,
      "context" : "This contrasts with the intuition of ‘not l’ in (Nicolas et al. 2006) as a Boolean condition and understood as “we cannot derive ‘l’ with a strictly positive certainty”.",
      "startOffset" : 48,
      "endOffset" : 69
    }, {
      "referenceID" : 37,
      "context" : "(Truszczyński 2011; Vlaeminck et al. 2012).",
      "startOffset" : 0,
      "endOffset" : 42
    }, {
      "referenceID" : 39,
      "context" : "(Truszczyński 2011; Vlaeminck et al. 2012).",
      "startOffset" : 0,
      "endOffset" : 42
    }, {
      "referenceID" : 17,
      "context" : "(1) (Eiter and Gottlob 1993) (6) Proposition 15 (2) (Baral 2003) (7) Proposition 16 and 17 (3) Proposition 13 and 14 (8) Corollary 5 (4) Corollary 2 (9) Corollary 6 (5) Corollary 3",
      "startOffset" : 4,
      "endOffset" : 28
    }, {
      "referenceID" : 1,
      "context" : "(1) (Eiter and Gottlob 1993) (6) Proposition 15 (2) (Baral 2003) (7) Proposition 16 and 17 (3) Proposition 13 and 14 (8) Corollary 5 (4) Corollary 2 (9) Corollary 6 (5) Corollary 3",
      "startOffset" : 52,
      "endOffset" : 64
    }, {
      "referenceID" : 25,
      "context" : "We refer the reader to (Lifschitz 2010) for a concise overview of thirteen such definitions.",
      "startOffset" : 23,
      "endOffset" : 39
    }, {
      "referenceID" : 29,
      "context" : "One of the earliest characterizations of stable models was in terms of autoepistemic logic (Moore 1985).",
      "startOffset" : 91,
      "endOffset" : 103
    }, {
      "referenceID" : 21,
      "context" : "The characterization of stable models proposed in (Gelfond and Lifschitz 1991) based on autoepistemic logic is to look at ‘not a’ as the expression ‘¬La’, a choice which clearly stands out for its simplicity and intuitively.",
      "startOffset" : 50,
      "endOffset" : 78
    }, {
      "referenceID" : 26,
      "context" : "A more involved characterization based on autoepistemic logic that does work for classical negation and disjunction has been proposed in (Lifschitz and Schwarz 1993).",
      "startOffset" : 137,
      "endOffset" : 165
    }, {
      "referenceID" : 7,
      "context" : "Ordered disjunction (Brewka 2002) falls in the latter category and allows to use the head of the rule to formulate alternative solutions in their preferred order.",
      "startOffset" : 20,
      "endOffset" : 33
    }, {
      "referenceID" : 38,
      "context" : "Annotated disjunctions are another example of a framework that changes the semantics of disjunctive programs (Vennekens et al. 2004).",
      "startOffset" : 109,
      "endOffset" : 132
    }, {
      "referenceID" : 36,
      "context" : "Interestingly, both ordered and annotated disjunction rely on split programs, as found in the possible model semantics (Sakama and Inoue 1994).",
      "startOffset" : 119,
      "endOffset" : 142
    }, {
      "referenceID" : 8,
      "context" : "For example, in (Buccafurri et al. 2002) an extension of disjunctive logic programs is presented which adds the idea of inheritance.",
      "startOffset" : 16,
      "endOffset" : 40
    }, {
      "referenceID" : 20,
      "context" : "In (Gelfond 1991) it was argued that classical ASP, while later proven to have strong epistemic foundations (Loyer and Straccia 2006), is not well-suited for epistemic",
      "startOffset" : 3,
      "endOffset" : 17
    }, {
      "referenceID" : 27,
      "context" : "In (Gelfond 1991) it was argued that classical ASP, while later proven to have strong epistemic foundations (Loyer and Straccia 2006), is not well-suited for epistemic",
      "startOffset" : 108,
      "endOffset" : 133
    }, {
      "referenceID" : 20,
      "context" : "The language ASP proposed in (Gelfond 1991) allows for modal atoms, e.",
      "startOffset" : 29,
      "endOffset" : 43
    }, {
      "referenceID" : 37,
      "context" : "The semantics of ASP were originally based on a three-valued interpretation (to allow for the additional truth value ‘uncertain’), but later, in (Truszczyński 2011), it was shown that this is not essential and that a more classical two-valued possible world structure can also be considered.",
      "startOffset" : 145,
      "endOffset" : 164
    }, {
      "referenceID" : 18,
      "context" : "This idea is proposed in (Faber and Woltran 2009) to overcome the need for an intermediary step to compute the desired consequences of the ASP program P1, before being fed into P2.",
      "startOffset" : 25,
      "endOffset" : 49
    }, {
      "referenceID" : 9,
      "context" : "Rather, they propose a translation to manifold answer set programs, which exploit the concept of weak constraints (Buccafurri et al. 2000) to allow for such programs to access all desired consequences of P1 within a single answer set.",
      "startOffset" : 114,
      "endOffset" : 138
    }, {
      "referenceID" : 28,
      "context" : "1, the semantics of ASP can also be expressed in terms of autoepistemic logic (Marek and Truszczyński 1991).",
      "startOffset" : 78,
      "endOffset" : 107
    }, {
      "referenceID" : 26,
      "context" : "Furthermore, as already discussed, it as shown in (Lifschitz and Schwarz 1993) that this characterization does not allow us to treat classical negation or disjunctive rules in a natural way, which weakens its position as a candidate for generalizing ASP from normal programs to e.",
      "startOffset" : 50,
      "endOffset" : 78
    }, {
      "referenceID" : 14,
      "context" : "be used for belief revision, has a strong epistemic notion and shares a lot of commonalities with epistemic entrenchments (Dubois and Prade 1991).",
      "startOffset" : 122,
      "endOffset" : 145
    }, {
      "referenceID" : 16,
      "context" : "Furthermore, in (Dubois et al. 2012) a generalization of possibilistic logic is studied, which corresponds to a weighted version of a fragment of the modal logic KD.",
      "startOffset" : 16,
      "endOffset" : 36
    }, {
      "referenceID" : 5,
      "context" : "For example, possibility theory has been used to model default rules (Benferhat et al. 1992; Benferhat et al. 1997).",
      "startOffset" : 69,
      "endOffset" : 115
    }, {
      "referenceID" : 6,
      "context" : "For example, possibility theory has been used to model default rules (Benferhat et al. 1992; Benferhat et al. 1997).",
      "startOffset" : 69,
      "endOffset" : 115
    }, {
      "referenceID" : 13,
      "context" : "The work on possibilistic logic (Dubois et al. 1994) forms the basis of possibilistic logic programming (Dubois et al.",
      "startOffset" : 32,
      "endOffset" : 52
    }, {
      "referenceID" : 12,
      "context" : "1994) forms the basis of possibilistic logic programming (Dubois et al. 1991).",
      "startOffset" : 57,
      "endOffset" : 77
    }, {
      "referenceID" : 24,
      "context" : "Rules in logic can also be interpreted as statements of conditional probability (Jaynes 2003).",
      "startOffset" : 80,
      "endOffset" : 93
    }, {
      "referenceID" : 6,
      "context" : "Rules can be then also be modelled in terms of conditional necessity measures (Benferhat et al. 1997; Dubois and Prade 1997; Benferhat et al. 2002).",
      "startOffset" : 78,
      "endOffset" : 147
    }, {
      "referenceID" : 15,
      "context" : "Rules can be then also be modelled in terms of conditional necessity measures (Benferhat et al. 1997; Dubois and Prade 1997; Benferhat et al. 2002).",
      "startOffset" : 78,
      "endOffset" : 147
    }, {
      "referenceID" : 4,
      "context" : "Rules can be then also be modelled in terms of conditional necessity measures (Benferhat et al. 1997; Dubois and Prade 1997; Benferhat et al. 2002).",
      "startOffset" : 78,
      "endOffset" : 147
    }, {
      "referenceID" : 31,
      "context" : "The work in (Nicolas et al. 2006) was one of the first papers to explore the idea",
      "startOffset" : 12,
      "endOffset" : 33
    }, {
      "referenceID" : 31,
      "context" : "The approach from (Nicolas et al. 2006) upholds the 1-on-1 relationship between the classical answer sets of a normal program and the possibilistic answer sets, which brings with it some advantages.",
      "startOffset" : 18,
      "endOffset" : 39
    }, {
      "referenceID" : 32,
      "context" : "One of those advantages is that it allows us to deal with possibilistic nested programs (Nieves and Lindgren 2012).",
      "startOffset" : 88,
      "endOffset" : 114
    }, {
      "referenceID" : 33,
      "context" : "was later extended to also cover the case of disjunctive ASP in (Nieves et al. 2013).",
      "startOffset" : 64,
      "endOffset" : 84
    }, {
      "referenceID" : 31,
      "context" : "However, the approaches from (Nicolas et al. 2006) and (Nieves et al.",
      "startOffset" : 29,
      "endOffset" : 50
    }, {
      "referenceID" : 33,
      "context" : "2006) and (Nieves et al. 2013) work by taking a possibilistic ASP program and reducing it – by ignoring the certainty values – to a possibilistic ASP program without negation-as-failure.",
      "startOffset" : 10,
      "endOffset" : 30
    }, {
      "referenceID" : 40,
      "context" : "Possibility theory has also been used to define various semantics of fuzzy if-then rules (Zadeh 1992).",
      "startOffset" : 89,
      "endOffset" : 101
    }, {
      "referenceID" : 11,
      "context" : "Finally, a formal connection also exists between the approach from Section 3 and the work on residuated logic programs (Damásio and Pereira 2001) under the Gödel semantics.",
      "startOffset" : 119,
      "endOffset" : 145
    } ],
    "year" : 2013,
    "abstractText" : "Answer Set Programming (ASP) is a popular framework for modeling combinatorial problems. However, ASP cannot easily be used for reasoning about uncertain information. Possibilistic ASP (PASP) is an extension of ASP that combines possibilistic logic and ASP. In PASP a weight is associated with each rule, where this weight is interpreted as the certainty with which the conclusion can be established when the body is known to hold. As such, it allows us to model and reason about uncertain information in an intuitive way. In this paper we present new semantics for PASP, in which rules are interpreted as constraints on possibility distributions. Special models of these constraints are then identified as possibilistic answer sets. In addition, since ASP is a special case of PASP in which all the rules are entirely certain, we obtain a new characterization of ASP in terms of constraints on possibility distributions. This allows us to uncover a new form of disjunction, called weak disjunction, that has not been previously considered in the literature. In addition to introducing and motivating the semantics of weak disjunction, we also pinpoint its computational complexity. In particular, while the complexity of most reasoning tasks coincides with standard disjunctive ASP, we find that brave reasoning for programs with weak disjunctions is easier.",
    "creator" : "LaTeX with hyperref package"
  }
}