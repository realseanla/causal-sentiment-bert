{
  "name" : "1305.4130.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Belief Propagation for Linear Programming",
    "authors" : [ "Andrew E. Gelfand", "Jinwoo Shin", "Michael Chertkov" ],
    "emails" : [ "agelfand@ics.uci.edu", "jshin@us.ibm.com", "chertkov@lanl.gov" ],
    "sections" : [ {
      "heading" : null,
      "text" : "I. INTRODUCTION\nGraphical Models (GMs) provide a useful representation for reasoning in a range of scientific fields [1], [2], [3], [4]. Such models use a graph structure to encode a joint probability distribution, where vertices correspond to random variables and edges (or lack thereof) specify conditional independencies.\nAn important inference task in many applications involving GMs is finding the most likely assignment to the variables in a GM - the Maximum-A-Posteriori (MAP) configuration. Belief Propagation (BP) is a much celebrated algorithm for approximately solving the MAP inference problem. BP is an iterative, message passing algorithm that is exact on tree structured GMs, but has empirically been shown to give good results even on GMs with loops. Its main appeal is that it is naturally suited for a distributed implementation.\nIt was recently shown that BP is exact for a certain class of GMs with loops. This inspiring result was shown for GMs in which well known optimization problems - namely, the matching problem [5], [6] and min-cost network flow problem [7] - were posed as MAP inference tasks. In the weighted matching case, the original combinatorial optimization problem can can be expressed as a binary Integer Linear Program (ILP). In certain cases (e.g. in bi-partite graphs), solving the LP relaxation to the matching ILP yields an integral solution.\nThe MAP inference task can also be formulated as an ILP in GMs with discrete variables. The LP relaxation to the MAP ILP, which we refer to herein as BPLP, arises by relaxing the integrality constraint on the discrete variables. When the weighted matching problem is formulated as a MAP\ninference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].\nThis line of work established a solid theoretical link between message passing algorithms and optimization theory. It provides a practical certificate of exactness/integrality for MAP inference when using BP and has also suggested strategies for improving upon BP’s results, by adding constraints that reduce the BPLP integrality gap [14], [15], [16].\nMotivated by this prior work, our manuscript characterizes the class of binary ILPs for which LP=BPLP, i.e. where the LP relaxation of an ILP is equivalent to BPLP, the LP relaxation of the MAP formulation of the problem. While standard BP is an approximation algorithm that is not guaranteed to converge to a correct answer for the LP, we provide an annealing version of BP that converges to the correct answer as long as LP=BPLP. Establishing this relationship allows us to use BP (or its variants) to efficiently approximate MAP inference in the special class of binary ILPs. We extend the work in [5], [6] by empirically demonstrating that annealing BP can be used to solve LP-relaxations to the weighted matching problems requiring Edmonds’ blossom inequalities. In particular, we use annealing BP to solve a sequence of successively tightened LP relaxations. If coupled with the method for finding a tight LP relaxation of ‘polynomial’ size in [17], annealing BP could be used in a novel, distributed approximation algorithm for the weighted matching problem.\nThe material in the manuscript is organized as follows. Section II introduces GMs, BP and the class of LPs of interest. Section III provides our main result. Sections IV and V describe our annealed BP algorithm and demonstrate its utility as an LP-solver."
    }, {
      "heading" : "II. PRELIMINARIES",
      "text" : ""
    }, {
      "heading" : "A. Graphical Model",
      "text" : "Let Z = [Zi] be a collection of n random variables, each of which takes values in a finite alphabet Zi = zi ∈ Ω. Let the joint probability distribution of Z ∈ Ωn factor into a product of real-valued, positive functions {ψα : α ∈ F} each defined\nar X\niv :1\n30 5.\n41 30\nv1 [\ncs .A\nI] 1\n7 M\nay 2\n01 3\nover a subset of the variables: Pr[Z = z] ∝ ∏ α∈F ψα(zα),\nwhere zα = [zi : i ∈ α] are the arguments of factor α. z is called a valid assignment if Pr[Z = z] > 0. The MAP assignment z∗ is defined as:\nz∗ = arg max z∈Ωn Pr[Z = z]. (1)\nA Graphical Model (GM) represents the above factorization using a bi-partite graph, known as a Factor Graph [18], where each factor α ∈ F is connected to the variables in its argument. (See Figure 1 for an example).\nB. Integer Linear Programming as MAP\nConsider the following ILP (Integer Linear Program):\nILP : max c · x s.t. Ax ≤ d, xi ∈ {0, 1} (2)\nwhere i = 1, · · · , n, j = 1, · · · , k, c = [ci], d = [dj ] are integer (column) vectors and A = [Aji] is an integer matrix.\nThe ILP in (2) can be formulated as a MAP inference task by constructing a suitable binary GM. Let X = [Xi] ∈ {0, 1}n be a set of binary random variables associated with each variable in (2) and consider the probability distribution:\nPr[X = x] ∝ ∏ i ecixi ∏ j ψj(xj ), (3)\nψj(xSj ) = { 1, if (Ax)j ≤ dj 0, otherwise , (4)\nwhere every row of matrix A is associated with a factor ψj defined over a subset of the variables xSj , where Sj = {i : Aji 6= 0}. It is clear that Pr[X = x] ∝ ∏ i e cixi for any ‘feasible’ assignment satisfying the linear constraints in (2) and Pr[X = x] = 0 otherwise. An illustration of this transformation is shown in Figure 1.\nThe LP relaxation of (2) replaces the integrality constraints with inequalities:\nLP : max c · x s.t. Ax ≤ d, 0 ≤ xi ≤ 1. (5)\nThe LP relaxation of the ILP optimizes over a larger polytope. We will use the notation A ≤ B to indicate that\nevery feasible point of polytope A is a feasible point of polytope B and A ≥ B to indicate the converse. Note that while ILP ≤ LP is true, ILP ≥ LP is not true in general."
    }, {
      "heading" : "C. Bethe Free Energy and BPLP",
      "text" : "Belief Propagation (BP) is an algorithm for approximately computing marginals that works by sending messages along the edges of the factor graph. We describe the algorithm for the GM in (3). Messages from factor node j to variable node i are denoted mji and messages in the opposite direction are denoted mij . The messages are updated as follows: for each xi ∈ {0, 1},\nmji(xi) ← ∑ xSj \\xi ψj(xSj ) 1/T ∏ k∈Sj\\i mkj(xk)\nmij(xi) ← exp (ci T xi ) ∏ k∈Ei\\j mki(xi)\nwhere we have introduced a parameter T > 0 (called temperature) and Ei = {j : Aji 6= 0}.\nEach factor or variable node in the factor graph is associated with a belief bj(xSj ) and bi(xi), respectively. The beliefs are calculated from the messages as:\nbj(xSj ) ∝ ψj(xSj )1/T ∏ k∈Sj mkj(xk)\nbi(xi) ∝ exp (ci T xi ) ∏ k∈Ei mki(xi),\nwhere ∑ xi bi(xi) = 1 and ∑ xSj bj(xSj ) = 1.\nBP for the GM in (3) can be interpreted as a variational optimization procedure in which the messages and beliefs minimize the Bethe Free Energy (BFE) functional [1]\nF(b) = − ∑ i cibi(xi = 1)− TS(b), (6)\n−S(b) = ∑ j ∑ xSj bj(xSj ) log(bj(xSj ))\n+ ∑ i (1− qi) ∑ xi bi(xi) log(bi(xi)), (7)\nwhere qi = ∑ j:Aji6=0\n1, subject to the following normalization and local consistency constraints:∑\nxSj :xi\nbj ( xSj ) = bi(xi), ∀i ∈ Sj (8)\nbj(xSj ) ≥ 0, ∑ xSj bj(xSj ) = 1, (9)\nbj(xSj ) = 0, if ∑ i∈Sj Ajixi > dj , ∀j. (10)\nNote that we use bi(xi = 1) to mean bi(1).\nIt is known [1] that if BP converges, it finds a minimum (possibly local) of the BFE. Finding the global minimum of the\nBFE is desirable (as an approximation). This task is reduced at T = 0 to the following LP:\nBPLP : min− ∑ i cibi(xi = 1), s.t. (8), (9), (10). (11)\nD. Illustrative Example: ILP and LP for Matching\nWe illustrate the ILP formulation and transformation to a GM described in Section II-B on the weighted matching problem. Given an (undirected) graph G = (V,E) with nonnegative edge weights {we : e ∈ E}, we seek to find the matching of largest weight, where a matching is a subset of edges such that each vertex is incident to at most one edge. The problem is described by the following ILP:\nm-ILP: max ∑ e∈E wexe (12)\ns.t. ∑ e∈δ(i) xe ≤ 1, ∀i ∈ V ; xe ∈ {0, 1}.\nwhere δ(i) = {e = (i, j) ∈ E} is the set of edges adjacent to vertex i.\nThe straightforward LP relaxation of m-ILP is formed by replacing xe ∈ {0, 1} by xe ∈ [0, 1]. However, this LP is not tight in general - i.e. m-LP ≥ m-ILP. The LP can be made tight, as famously shown by Edmonds [19], by adding a set of blossom inequalities:\nm-bl-LP : max ∑ e∈E wexe (13)\ns.t. ∑ e∈δ(i) xe ≤ 1, ∀i ∈ V∑\ne∈E(S) xe ≤ |S|−1\n2 , ∀S ∈ S xe ∈ [0, 1].\nwhere E(S) = {(i, j) ∈ E : i, j ∈ S} is the set of edges with both ends in S and S ⊂ 2V is the set of all odd-sized sets of vertices in G. The blossom inequalities imply that an odd cycle of length 2l + 1 can have l edges in a matching.\nThe weighted matching problem can be formulated as a MAP inference problem by associating a random variable with each edge X = [Xe] ∈ {0, 1}|E| and constructing the following distribution:\nPr[X = x] ∝ ∏ e∈E ewexe ∏ i∈V ψi(xi) ∏ S∈S ψS(xS), (14)\nψi(xi) =\n{ 1, if ∑ e∈δ(i) xe ≤ 1\n0, otherwise (15)\nψS(xS) =\n{ 1, if ∑ e∈E(S) xe ≤ |S|−1 2\n0, otherwise . (16)\nwhere ψi are functions defined over variables xi = {xe : e ∈ δ(i)} and ψS are functions defined over xS = {xe : e ∈ E(s)}. It is easy to see that (14) is equivalent to\nPr[X = x] ∝ { exp (w(x)) if x induces a matching in G 0 otherwise , (17) where w(x) := ∑ e∈E wexe."
    }, {
      "heading" : "III. EQUIVALENCE BETWEEN LP AND BPLP",
      "text" : "Now we state the main result of the paper.\nTheorem III.1. For any (fixed) j, consider the polytope Pj : ∑ i∈Sj Ajixi ≤ dj , 0 ≤ xi ≤ 1 ∀i ∈ Sj . (18)\nThen, the following properties hold:\n• If Pj has only 0-1 integral vertices (i.e., extreme points) for all j, then LP ≤ BPLP. • LP ≥ BPLP (without any conditions).\nTheorem III.1 implies the following corollary.\nCorollary III.2. If Aji ∈ {−1, 0, 1} for all i, j, then LP = BPLP.\nProof: Corollary III.2 is proved using Theorem III.1 and the fact that each vertex of a polytope can be expressed as the unique solution to a system of ‘face’ linear equalities (see e.g. [20].\nNote that the condition of Corollary III.2 holds for mbl-LP. One also observes (arguing by contradiction) that the condition in Theorem III.1 for LP ≤ BPLP is necessary. For example, suppose the number of rows of matrix A is one, S1 = {1, . . . , n} and the polytope P1 has a fractional vertex x = [xi]. Then there exists c = [ci] such that x is the unique solution of LP (5). However, [bi(1)] = [xi] cannot satisfy (8), (9) and (10) for any factor bj(·) because x is a fractional vertex of P1. Hence, LP > BPLP."
    }, {
      "heading" : "A. Proof for LP ≤ BPLP",
      "text" : "Here we prove that if x = [xi] satisfies the constraints of LP (5), then there exists normalized beliefs {bj} such that [bi(1)] = [xi], [bi(0)] = [1 − xi] and {bi, bj} satisfies constraints of BPLP. From the condition of Theorem III.1, the polytope Pj has only 0-1 integral vertices. Then, according to the Carathéodory’s theorem [21], any point [xi] in the polytope can be expressed as a convex combination of 0-1 vertices, where coefficients in the convex combination provide values of {bj}, and the variables bi(0) and bi(1) in the description of the BPLP polytope, correspond to the variables 1− xi and xi in the LP polytope, respectively. This completes the proof of LP ≤ BPLP."
    }, {
      "heading" : "B. Proof for LP ≥ BPLP",
      "text" : "Here we prove that if {bi, bj} satisfies the constraints of BPLP, then [xi = bi(1)] satisfies the constraints of LP as well. As mentioned above, bi(0) is redundant as bi(0) = 1− bi(1) within the BPLP polytope. From this, one derives∑\ni∈Sj Ajixi = ∑ i∈Sj Aji ∑\nxSj :xi=1\nbj ( xSj )\n= ∑ i∈Sj Aji ∑ xSj xibj ( xSj ) = ∑ xSj ∑ i∈Sj Ajixi  bj (xSj)\n≤ ∑ xSj djbj ( xSj )\n= dj ∑ xSj bj ( xSj ) = dj ,\nwhere (10) was used at the inequality stage. This completes the proof of LP ≥ BPLP."
    }, {
      "heading" : "IV. ANNEALING BP FOR SOLVING LPS",
      "text" : "In this section, we propose the following annealing version of BP as an LP solver:\nmt+1ji (xi)← m t ji(xi) 1−αt ∑ xSj \\xi ψj(xSj ) αt Tt ∏ k∈Sj\\i mtkj(xk) αt\nmt+1ij (xi)← m t ij(xi) 1−αt exp ( αtci Tt xi ) ∏ k∈Ei\\j mtki(xi) αt\nbt+1j (xSj ) ∝ ψj(xSj ) 1/Tt ∏ k∈Sj mtkj(xk)\nbt+1i (xi) ∝ exp ( ci Tt xi ) ∏ k∈Ei mtki(xi),\nwhere αt ∈ (0, 1], Tt > 0, mtij ,mtji and btj , bti are a ‘damping’ parameter, a temperature parameter, messages and beliefs at the t-th iteration, respectively. We have the following conjecture.\nConjecture IV.1. If LP = BPLP and m0ij = m0ji = 1 for all i, j, then there exists a scheme with annealing schedule T0 ≥ T1 ≥ . . . with limt→∞ Tt = 0 and damping schedule α0, α1, . . . such that [bti(1)] converges to the solution of LP.\nWe now explain the rationale for the above conjecture. First, recall the following facts:\n• If BP converges, it finds a (possibly local) minimum of the BFE function. • The BFE minimization is equal to BPLP at T = 0.\nThe main difficulties in establishing the conjecture are (a) BP may not converge, and (b) BP may converge to a local (not global) minimum of the BFE functional. To overcome both issues, one can use a convex modification of the BFE function [22], and the known convergent variant to BP (providing sufficient damping), called CCCP, to find its minimum [23]. We believe that an appropriate annealing scheme can fix the convergence issue and that the natural initialization m0ij = m 0 ji = 1 can prevent annealing BP from converging to an undesirable local minimum of the BFE functional. Support for natural message initialization comes from [5], [6], [7], [24], where for certain GMs the natural initial messages are needed to prevent BP from converging to an undesirable fixed point. We empirically verify this conjecture for matching GMs in the following section.\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nTemperature\nb( x e\n= 1\n)\nBeliefs versus Temperature for Fractional Matching\n(0,2) (0,4) (1,3) (1,4) (2,3) (2,4) (3,4)\nEdges\n1 2 4 5\n2\n1 5\n0\n1\n2 3\n4\nFig. 2. Convergence of edge beliefs found by annealing BP to a fractional LP solution with total weight w(x) = 8.\n0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nTemperature\nb( x e\n= 1\n)\nBeliefs versus Temperature for Integral Matching − 1 Blossom\n(0,2) (0,4) (1,3) (1,4) (2,3) (2,4) (3,4)\nEdges\n1 2 4 5\n2\n1 5\n0\n1\n2 3\n4\nFig. 3. Convergence of edge beliefs found by annealing BP to the integral LP solution with total weight w(x) = 7."
    }, {
      "heading" : "V. EXPERIMENTS WITH MATCHINGS",
      "text" : "In this section, we demonstrate that annealing BP with sufficient damping can be used to reliably solve sequential LP relaxations to the weighted matching problem introduced in section II-D. We note that our approach here differs from prior work on solving the weighted matching problem using BP because we consider the sum-product form of BP. The work in [5], [6] demonstrated that max-product BP will converge to the MAP solution (and therefore find the maximum weight matching) if the relaxation to the matching ILP without blossoms is tight. However, when this LP is not tight, maxproduct will fail to converge. The connection between BPLP and LP made in the previous section, tells us that the MAP solution will correspond to the solution to the LP involving blossoms (i.e. m-bl-LP). We demonstrate that annealed sumproduct BP can be used to solve m-bl-LP.\nFigures 2 and 3 plot the edge beliefs be(xe = 1) found by sum-product BP on a particular weighted matching problem instance with 5 vertices and 7 edges. The edge weights for this instance are depicted in the inlay of each figure. In both figures, T is annealed linearly from 1 to 0.01 over 100 steps\nand BP is run for 20 iterations at each temperature with αt = 12 for all t. The results in Figure 2 are for a GM corresponding to a non-tight relaxation of m-ILP. Notice as the temperature is annealed that the beliefs converge to a fractional solution with total weight w(x) = 8. In this plot, we see that vertices {1, 3, 4} constitute an odd set of vertices violating a blossom inequality. Adding an inequality for this blossom makes mbl-LP tight. The GM used in Figure 3 includes an additional factor enforcing the blossom inequality. The beliefs in the tight GM converge to an integral (and exact) solution with total weight w(x) = 7.\nFigure 4 demonstrates how annealing sum-product BP can be used to solve a much larger weighted matching problem, with 20 vertices and 80 edges. We use the same annealing and damping scheme as in the previous experiments. The leftmost figure plots edge beliefs as a function of temperature for the LP relaxation without blossoms. This relaxation is not tight, so several edge beliefs converge to b(xe = 1) = 12 . In the center plot we have added a single blossom constraint that also yields a fractional solution. However, the blossom tightens the LP relaxation, reducing the total weight from w(x) = 87.5 to w(x) = 86.5. The right-most plot depicts a tight LP relaxation (i.e. m-bl-LP = m-ILP). Notice that as temperature is annealed, all edge beliefs converge to either 0 or 1. In the exact matching w(x) = 86."
    } ],
    "references" : [ {
      "title" : "Constructing free-energy approximations and generalized belief propagation algorithms,",
      "author" : [ "J. Yedidia", "W. Freeman", "Y. Weiss" ],
      "venue" : "Info. Theory, IEEE Trans. on,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2005
    }, {
      "title" : "Modern Coding Theory",
      "author" : [ "T.J. Richardson", "R.L. Urbanke" ],
      "venue" : "Cambridge University Press",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Information",
      "author" : [ "M. Mezard", "A. Montanari" ],
      "venue" : "physics, and computation, ser. Oxford Graduate Texts. Oxford: Oxford Univ. Press",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Graphical models",
      "author" : [ "M.J. Wainwright", "M.I. Jordan" ],
      "venue" : "exponential families, and variational inference,” Foundations and Trends in Machine Learning, vol. 1, no. 1, pp. 1–305",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Max-product for maximum weight matching: Convergence, correctness, and lp duality,",
      "author" : [ "M. Bayati", "D. Shah", "M. Sharma" ],
      "venue" : "Info. Theory, IEEE Trans. on,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2008
    }, {
      "title" : "Belief propagation and lp relaxation for weighted matching in general graphs,",
      "author" : [ "S. Sanghavi", "D. Malioutov", "A. Willsky" ],
      "venue" : "Info. Theory, IEEE Trans. on,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2011
    }, {
      "title" : "and Y",
      "author" : [ "D. Gamarnik", "D. Shah" ],
      "venue" : "Wei, “Belief propagation for min-cost network flow: convergence & correctness,” in SODA",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Exactness of belief propagation for some graphical models with loops,",
      "author" : [ "M. Chertkov" ],
      "venue" : "Journal of Statistical Mechanics: Theory and Experiment,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "Using linear programming to decode binary linear codes,",
      "author" : [ "J. Feldman", "M. Wainwright", "D. Karger" ],
      "venue" : "Info. Theory, IEEE Trans. on,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2005
    }, {
      "title" : "Towards low-complexity linearprogramming decoding,",
      "author" : [ "P.O. Vontobel", "R. Koetter" ],
      "venue" : "6th International ITG-Conference on Source and Channel Coding,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    }, {
      "title" : "An efficient pseudocodeword search algorithm for linear programming decoding of LDPC codes,",
      "author" : [ "M. Chertkov", "M. Stepanov" ],
      "venue" : "Info. Theory, IEEE Trans. on,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2008
    }, {
      "title" : "and M",
      "author" : [ "A. Dimakis", "A. Gohari" ],
      "venue" : "Wainwright, “Guessing facets: Polytope structure and improved lp decoder,” Info. Theory, IEEE Trans. on, vol. 55, no. 8, pp. 3479 –3487",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Convex relaxation methods for graphical models: Lagrangian and maximum entropy approaches,",
      "author" : [ "J. Johnson" ],
      "venue" : "Ph.D. dissertation, MIT, Department of Electrical Engineering and Computer Science,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Approximate inference in graphical models using lp relaxations,",
      "author" : [ "D. Sontag" ],
      "venue" : "Ph.D. dissertation, MIT, Department of Electrical Engineering and Computer Science,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2010
    }, {
      "title" : "and M",
      "author" : [ "S. Kudekar", "J.K. Johnson" ],
      "venue" : "Chertkov, “Improved linear programming decoding using frustrated cycles,” CoRR, vol. abs/1105.4665",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "and S",
      "author" : [ "K. Chandrasekaran", "L.A. Végh" ],
      "venue" : "Vempala, “The cutting plane method is polynomial for perfect matchings,” CoRR, vol. abs/1207.5813",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Factor graphs and the sum-product algorithm,",
      "author" : [ "F. Kschischang", "B. Frey", "H.-A. Loeliger" ],
      "venue" : "Info. Theory, IEEE Trans. on,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2001
    }, {
      "title" : "Paths",
      "author" : [ "J. Edmonds" ],
      "venue" : "trees, and flowers,” Canadian Journal of mathematics, vol. 17, no. 3, pp. 449–467",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 1965
    }, {
      "title" : "Combinatorial Optimization : Polyhedra and Efficiency (Algorithms and Combinatorics)",
      "author" : [ "A. Schrijver" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2004
    }, {
      "title" : "Map estimation",
      "author" : [ "Y. Weiss", "C. Yanover", "T. Meltzer" ],
      "venue" : "linear programming, and belief propagation with convex free energies,” in UAI",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Cccp algorithms to minimize the bethe and kikuchi free energies: Convergent alternatives to belief propagation,",
      "author" : [ "A.L. Yuille" ],
      "venue" : "Neural Computation,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2002
    }, {
      "title" : "and A",
      "author" : [ "S. Sanghavi", "D. Shah" ],
      "venue" : "Willsky, “Message-passing for max-weight independent set,” in NIPS",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Graphical Models (GMs) provide a useful representation for reasoning in a range of scientific fields [1], [2], [3], [4].",
      "startOffset" : 101,
      "endOffset" : 104
    }, {
      "referenceID" : 1,
      "context" : "Graphical Models (GMs) provide a useful representation for reasoning in a range of scientific fields [1], [2], [3], [4].",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 2,
      "context" : "Graphical Models (GMs) provide a useful representation for reasoning in a range of scientific fields [1], [2], [3], [4].",
      "startOffset" : 111,
      "endOffset" : 114
    }, {
      "referenceID" : 3,
      "context" : "Graphical Models (GMs) provide a useful representation for reasoning in a range of scientific fields [1], [2], [3], [4].",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 4,
      "context" : "This inspiring result was shown for GMs in which well known optimization problems - namely, the matching problem [5], [6] and min-cost network flow problem [7] - were posed as MAP inference tasks.",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 5,
      "context" : "This inspiring result was shown for GMs in which well known optimization problems - namely, the matching problem [5], [6] and min-cost network flow problem [7] - were posed as MAP inference tasks.",
      "startOffset" : 118,
      "endOffset" : 121
    }, {
      "referenceID" : 6,
      "context" : "This inspiring result was shown for GMs in which well known optimization problems - namely, the matching problem [5], [6] and min-cost network flow problem [7] - were posed as MAP inference tasks.",
      "startOffset" : 156,
      "endOffset" : 159
    }, {
      "referenceID" : 4,
      "context" : "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].",
      "startOffset" : 165,
      "endOffset" : 168
    }, {
      "referenceID" : 5,
      "context" : "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].",
      "startOffset" : 170,
      "endOffset" : 173
    }, {
      "referenceID" : 7,
      "context" : "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].",
      "startOffset" : 175,
      "endOffset" : 178
    }, {
      "referenceID" : 8,
      "context" : "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].",
      "startOffset" : 301,
      "endOffset" : 304
    }, {
      "referenceID" : 9,
      "context" : "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].",
      "startOffset" : 306,
      "endOffset" : 310
    }, {
      "referenceID" : 10,
      "context" : "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].",
      "startOffset" : 312,
      "endOffset" : 316
    }, {
      "referenceID" : 11,
      "context" : "When the weighted matching problem is formulated as a MAP inference task, BPLP is equivalent to the relaxed matching ILP - explaining the success of BP in these GMs [5], [6], [8]! The connection between LP relaxations and BPLP (also called LPdecoding) has also been discussed in the coding literature [9], [10], [11], [12], [13].",
      "startOffset" : 324,
      "endOffset" : 328
    }, {
      "referenceID" : 12,
      "context" : "It provides a practical certificate of exactness/integrality for MAP inference when using BP and has also suggested strategies for improving upon BP’s results, by adding constraints that reduce the BPLP integrality gap [14], [15], [16].",
      "startOffset" : 219,
      "endOffset" : 223
    }, {
      "referenceID" : 13,
      "context" : "It provides a practical certificate of exactness/integrality for MAP inference when using BP and has also suggested strategies for improving upon BP’s results, by adding constraints that reduce the BPLP integrality gap [14], [15], [16].",
      "startOffset" : 225,
      "endOffset" : 229
    }, {
      "referenceID" : 14,
      "context" : "It provides a practical certificate of exactness/integrality for MAP inference when using BP and has also suggested strategies for improving upon BP’s results, by adding constraints that reduce the BPLP integrality gap [14], [15], [16].",
      "startOffset" : 231,
      "endOffset" : 235
    }, {
      "referenceID" : 4,
      "context" : "We extend the work in [5], [6] by empirically demonstrating that annealing BP can be used to solve LP-relaxations to the weighted matching problems requiring Edmonds’ blossom inequalities.",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 5,
      "context" : "We extend the work in [5], [6] by empirically demonstrating that annealing BP can be used to solve LP-relaxations to the weighted matching problems requiring Edmonds’ blossom inequalities.",
      "startOffset" : 27,
      "endOffset" : 30
    }, {
      "referenceID" : 15,
      "context" : "If coupled with the method for finding a tight LP relaxation of ‘polynomial’ size in [17], annealing BP could be used in a novel, distributed approximation algorithm for the weighted matching problem.",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 16,
      "context" : "A Graphical Model (GM) represents the above factorization using a bi-partite graph, known as a Factor Graph [18], where each factor α ∈ F is connected to the variables in its argument.",
      "startOffset" : 108,
      "endOffset" : 112
    }, {
      "referenceID" : 0,
      "context" : "BP for the GM in (3) can be interpreted as a variational optimization procedure in which the messages and beliefs minimize the Bethe Free Energy (BFE) functional [1]",
      "startOffset" : 162,
      "endOffset" : 165
    }, {
      "referenceID" : 0,
      "context" : "It is known [1] that if BP converges, it finds a minimum (possibly local) of the BFE.",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 0,
      "context" : "The straightforward LP relaxation of m-ILP is formed by replacing xe ∈ {0, 1} by xe ∈ [0, 1].",
      "startOffset" : 86,
      "endOffset" : 92
    }, {
      "referenceID" : 17,
      "context" : "The LP can be made tight, as famously shown by Edmonds [19], by adding a set of blossom inequalities: m-bl-LP : max ∑ e∈E wexe (13) s.",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 0,
      "context" : "∑ e∈δ(i) xe ≤ 1, ∀i ∈ V ∑ e∈E(S) xe ≤ |S|−1 2 , ∀S ∈ S xe ∈ [0, 1].",
      "startOffset" : 60,
      "endOffset" : 66
    }, {
      "referenceID" : 18,
      "context" : "[20].",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "To overcome both issues, one can use a convex modification of the BFE function [22], and the known convergent variant to BP (providing sufficient damping), called CCCP, to find its minimum [23].",
      "startOffset" : 79,
      "endOffset" : 83
    }, {
      "referenceID" : 20,
      "context" : "To overcome both issues, one can use a convex modification of the BFE function [22], and the known convergent variant to BP (providing sufficient damping), called CCCP, to find its minimum [23].",
      "startOffset" : 189,
      "endOffset" : 193
    }, {
      "referenceID" : 4,
      "context" : "Support for natural message initialization comes from [5], [6], [7], [24], where for certain GMs the natural initial messages are needed to prevent BP from converging to an undesirable fixed point.",
      "startOffset" : 54,
      "endOffset" : 57
    }, {
      "referenceID" : 5,
      "context" : "Support for natural message initialization comes from [5], [6], [7], [24], where for certain GMs the natural initial messages are needed to prevent BP from converging to an undesirable fixed point.",
      "startOffset" : 59,
      "endOffset" : 62
    }, {
      "referenceID" : 6,
      "context" : "Support for natural message initialization comes from [5], [6], [7], [24], where for certain GMs the natural initial messages are needed to prevent BP from converging to an undesirable fixed point.",
      "startOffset" : 64,
      "endOffset" : 67
    }, {
      "referenceID" : 21,
      "context" : "Support for natural message initialization comes from [5], [6], [7], [24], where for certain GMs the natural initial messages are needed to prevent BP from converging to an undesirable fixed point.",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 4,
      "context" : "The work in [5], [6] demonstrated that max-product BP will converge to the MAP solution (and therefore find the maximum weight matching) if the relaxation to the matching ILP without blossoms is tight.",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 5,
      "context" : "The work in [5], [6] demonstrated that max-product BP will converge to the MAP solution (and therefore find the maximum weight matching) if the relaxation to the matching ILP without blossoms is tight.",
      "startOffset" : 17,
      "endOffset" : 20
    } ],
    "year" : 2013,
    "abstractText" : "Belief Propagation (BP) is a popular, distributed heuristic for performing MAP computations in Graphical Models. BP can be interpreted, from a variational perspective, as minimizing the Bethe Free Energy (BFE). BP can also be used to solve a special class of Linear Programming (LP) problems. For this class of problems, MAP inference can be stated as an integer LP with an LP relaxation that coincides with minimization of the BFE at “zero temperature”. We generalize these prior results and establish a tight characterization of the LP problems that can be formulated as an equivalent LP relaxation of MAP inference. Moreover, we suggest an efficient, iterative annealing BP algorithm for solving this broader class of LP problems. We demonstrate the algorithm’s performance on a set of weighted matching problems by using it as a cutting plane method to solve a sequence of LPs tightened by adding “blossom” inequalities.",
    "creator" : "LaTeX with hyperref package"
  }
}