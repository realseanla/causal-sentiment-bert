{
  "name" : "1301.2313.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Bayesian Error-Bars for Belief Net Inference",
    "authors" : [ "Tim Van Allen", "Russell Greiner", "Peter Hooper" ],
    "emails" : [ "timv@digimine.com", "greiner@cs.ualberta.ca", "hooper@stat.ualberta.ca" ],
    "sections" : null,
    "references" : [ {
      "title" : "A note on uniform asymptotic nor­ mality of Dirichlet distribution",
      "author" : [ "Y. Akimoto" ],
      "venue" : "Mathematica Japonica, 44:25-30",
      "citeRegEx" : "Aki96",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Context-specific independence in Bayesian networks",
      "author" : [ "C. Boutilier", "N. Friedman", "M. Goldszmidt", "D. Koller" ],
      "venue" : "UAI-96",
      "citeRegEx" : "BFGK96",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Dis­ crete Multivariate Analysis- Theory and Practice",
      "author" : [ "Y. Bishop", "S. Fienberg", "P. Holland" ],
      "venue" : "MIT Press",
      "citeRegEx" : "BFH95",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "and Ke",
      "author" : [ "J. Binder", "D. Koller", "S. Russell" ],
      "venue" : "Kanazawa. Adaptive probabilistic networks with hidden variables. Machine Learning, 29:213-244",
      "citeRegEx" : "BKRK97",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "The ALARM monitoring system: A case study with two probabilistic inference techniques for be­ lief networks",
      "author" : [ "I. Beinlich", "H. Suermondt", "R. Chavez", "G. Cooper" ],
      "venue" : "Proc. Second European Conf Artificial Intelligence in Medicine, August",
      "citeRegEx" : "BSCC89",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "A Bayesian method for the induction of probabilistic networks from data",
      "author" : [ "G. Cooper", "E. Herskovits" ],
      "venue" : "MU, 9:309-347",
      "citeRegEx" : "CH92",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "An implementation of a method for com­ puting the uncertainty in inferred probabilities in belief networks",
      "author" : [ "P. Che", "R. Neapolitan", "J. Kenevan", "M. Evens" ],
      "venue" : "UA/-93, pages 292-300",
      "citeRegEx" : "CNKE93",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "The computational complexity of probabilistic inference using Bayesian belief networks",
      "author" : [ "G. Cooper" ],
      "venue" : "Artificial Intelligence, 42(2-3):393--405",
      "citeRegEx" : "Coo90",
      "shortCiteRegEx" : null,
      "year" : 1990
    }, {
      "title" : "A differential approach to inference in bayesian networks",
      "author" : [ "A Darwiche" ],
      "venue" : "UA/'00",
      "citeRegEx" : "DarOO",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Bucket elimination: A unifying framework for probabilistic inference",
      "author" : [ "R. Dechter" ],
      "venue" : "Learning and Inference in Graphical Models",
      "citeRegEx" : "Dec98",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "and D",
      "author" : [ "R. Greiner", "A Grove" ],
      "venue" : "Schuurmans. Learning Bayesian nets that perform welL In UAI-97",
      "citeRegEx" : "GGS97",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Algorithms for Bayesian belief-network precomputation",
      "author" : [ "E. Herskovits", "C. Cooper" ],
      "venue" : "Methods of Information in Medicine, pages 362-370",
      "citeRegEx" : "HC91",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "A tutorial on learning with Bayesian networks",
      "author" : [ "D. Heckerman" ],
      "venue" : "Learning in Graphical Models",
      "citeRegEx" : "Hec98",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "P ropagating imprecise probabilities in bayesian networks",
      "author" : [ "G. Kleiter" ],
      "venue" : "Artificial Intelligence, 88",
      "citeRegEx" : "Kle96",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Sensitivity analysis for probability as­ sessments in Bayesian networks",
      "author" : [ "K. Laskey" ],
      "venue" : "IEEE Transactions on Man, Cybernetics and Systems, 25(6):901-909",
      "citeRegEx" : "Las95",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "A comparison of Lauritzen-Spiegelhalter",
      "author" : [ "V. Lepar", "P.P. Shenoy" ],
      "venue" : "Hugin, and Shenoy-Shafer ar­ chitectures for computing marginals of probability dis­ tributions. In UA/98",
      "citeRegEx" : "LS99",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Minimal assumption distribution propagation in belief networks",
      "author" : [ "R. Musick" ],
      "venue" : "UA/93",
      "citeRegEx" : "Mus93",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
      "author" : [ "J. Pearl" ],
      "venue" : "Morgan Kaufmann",
      "citeRegEx" : "P ea88",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "Bayesian error-bars for belief net inference",
      "author" : [ "T. Van Allen", "R. Greiner", "P. Hooper" ],
      "venue" : "Technical report, University of Alberta",
      "citeRegEx" : "V GH01",
      "shortCiteRegEx" : null,
      "year" : 2001
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "Be­ lief nets are typically built by first finding an ap­ propriate structure (either by interviewing an expert, or by selecting a good model from training data), then using a training sample to fill in the parame­ ters [Hec98].",
      "startOffset" : 220,
      "endOffset" : 227
    }, {
      "referenceID" : 2,
      "context" : "Under the posterior distribution (the conditional distribution given the training data), the E>vlf are independent Vir( O:v,zl/• x E Xv) random vectors, with O:v,xlf = a;,xlf + mv,xlf [BFH95].",
      "startOffset" : 184,
      "endOffset" : 191
    }, {
      "referenceID" : 2,
      "context" : "J/ = l::xEXv O:v,xJf• the posterior means and (co)variances for CPtable entries are [BFH95]:",
      "startOffset" : 84,
      "endOffset" : 91
    }, {
      "referenceID" : 12,
      "context" : "lv,xlf = O:v,-J/ (1) Cov{0v,zJ/• 0v,yJ/} = ll v,xjt(c5xy- llv,yJf) (2) O:v,-J/ + 1 1Readers unfamiliar with these assumptions, or with Dirichlet distributions, are referred to [Hec98].",
      "startOffset" : 176,
      "endOffset" : 183
    }, {
      "referenceID" : 0,
      "context" : "The ran­ dom vectors Elvlf are asymptotically normal, in the limit as min, av,xl! --t oo [Aki96].",
      "startOffset" : 89,
      "endOffset" : 96
    }, {
      "referenceID" : 5,
      "context" : "T his value can be calcu­ lated using the identity [CH92]:",
      "startOffset" : 51,
      "endOffset" : 57
    }, {
      "referenceID" : 2,
      "context" : "Our proof uses the Delta method [BFH95].",
      "startOffset" : 32,
      "endOffset" : 39
    }, {
      "referenceID" : 16,
      "context" : "It is then straightforward to derive the distribution of the query probability using properties of the Dirichlet distribution; see [Mus93].",
      "startOffset" : 131,
      "endOffset" : 138
    }, {
      "referenceID" : 7,
      "context" : "LQ = q(p,) is known to be NP-hard [Coo90]; when all variables Xv are binary, the most effective ex­ act algorithms require time O(n2w), where n = lVI is the number of nodes and w is the induced tree width of the graph [Dec98, LS99].",
      "startOffset" : 34,
      "endOffset" : 41
    }, {
      "referenceID" : 8,
      "context" : "q�,xlf in time O(n2w); see [DarOO].",
      "startOffset" : 27,
      "endOffset" : 34
    }, {
      "referenceID" : 9,
      "context" : "The main challenge, computing all of the derivatives q� xlf' is accomplished by \"back propagat­ ing\" intermediate' results obtained by the Bucket Elimina­ tion [Dec98] algorithm.",
      "startOffset" : 160,
      "endOffset" : 167
    }, {
      "referenceID" : 4,
      "context" : "The Alarm network [BSCC89] is a benchmark network based on a medical diagnosis domain, commonly used in belief network studies.",
      "startOffset" : 18,
      "endOffset" : 26
    }, {
      "referenceID" : 11,
      "context" : "(Here, we used [HC91] to determine which vari-",
      "startOffset" : 15,
      "endOffset" : 21
    }, {
      "referenceID" : 13,
      "context" : "T he strongest ef­ fect, observed in Table 4, was that increasing the number of variables assigned in a query tended to increase the er­ ror I� - 81; see also [Kle96].",
      "startOffset" : 159,
      "endOffset" : 166
    }, {
      "referenceID" : 2,
      "context" : "This is done using the \"Delta method\" [BFH95]: first determine the variance of each CPtable row, then propagate this variance using a sensi­ tivity analysis (i.",
      "startOffset" : 38,
      "endOffset" : 45
    }, {
      "referenceID" : 13,
      "context" : "Kleiter [Kle96] performs a similar computation; parts of his analysis are more general, in that he considers incomplete data.",
      "startOffset" : 8,
      "endOffset" : 15
    }, {
      "referenceID" : 5,
      "context" : "For exam­ ple, Cooper and Herskovits [CH92] use it to compute the expected response to a query; by contrast, we also approx­ imate the posterior variance in that response.",
      "startOffset" : 37,
      "endOffset" : 43
    }, {
      "referenceID" : 12,
      "context" : "Similarly, while many BN-learning algorithms compute the posterior distribution over CPtables [Hec98], most of these systems seek a single set of CPtable entries that maximize the like­ lihood, which again is different from our task; e.",
      "startOffset" : 94,
      "endOffset" : 101
    }, {
      "referenceID" : 10,
      "context" : ", their task is not relative to a specific query (but see [GGS97]).",
      "startOffset" : 58,
      "endOffset" : 65
    }, {
      "referenceID" : 8,
      "context" : "The [DarOO] system is an excep­ tion, as it can simultaneously produce all of the derivatives.",
      "startOffset" : 4,
      "endOffset" : 11
    }, {
      "referenceID" : 8,
      "context" : "Excluding the [DarOO] result, none of the other projects provides an efficient way to compute that information.",
      "startOffset" : 14,
      "endOffset" : 21
    }, {
      "referenceID" : 6,
      "context" : ", [CNKE93]) deal only with singly connected networks (trees).",
      "startOffset" : 2,
      "endOffset" : 10
    }, {
      "referenceID" : 1,
      "context" : "represented as, say, decision tree functions [BFGK96], etc.",
      "startOffset" : 45,
      "endOffset" : 53
    } ],
    "year" : 2011,
    "abstractText" : "A Bayesian Belief Network (BN) is a model of a joint distribution over a finite set of variables, with a DAG structure to represent the immedi­ ate dependencies between the variables, and a set of parameters (aka CPTables) to represent the local conditional probabilities of a node, given each assignment to its parents. In many situa­ tions, the parameters are themselves treated as random variablesreflecting the uncertainty re­ maining after drawing on knowledge of domain experts and/or observing data generated by the network. A distribution over the CPtable param­ eters induces a distribution for the response the BN will return to any \"What is Pr{ H I E} ?\" query. This paper investigates the distribution of this response, shows that it is asymptotically normal, and derives expressions for its mean and asymptotic variance. We show that this compu­ tation has the same complexity as simply com­ puting the (mean value of the) response -i.e., O(n exp(w)), where n is the number of vari­ ables and w is the effective tree width. We also provide empirical evidence showing that the error-bars computed from our estimates are fairly accurate in practice, over a wide range of belief net structures and queries.",
    "creator" : "pdftk 1.41 - www.pdftk.com"
  }
}