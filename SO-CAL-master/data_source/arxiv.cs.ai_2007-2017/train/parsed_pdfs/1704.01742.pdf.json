{
  "name" : "1704.01742.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "klopotek@ipipan.waw.pl" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 4.\n01 74\n2v 1\n[ cs\n.A I]\n6 A\npr 2"
    }, {
      "heading" : "1 Introduction",
      "text" : "Dempster Rule of Independent Evidence Combination has been criticized for its failure to conform to probabilistic interpretation ascribed to belief and plausibility function. Among those verifying DST (Dempster-Shafer-Theory, [2,12]) critically were Kyburg [7], Fagin [3], Halpern [6], Pearl [9], Provan [10], Cano [1], just to mention a few.\nAs a way out of those difficulties, we proposed in a recent book co-authored by S.T.Wierzchon [18] three proposals for an empirical model of DST:\n– ”the marginally correct approximation”. – ”the qualitative model” – ”the quantitative model”\nThe marginally correct approximation assumes that the belief function shall constitute lower bounds for frequencies, though only for the marginals, and not for the joint distribution. Then, the reasoning process is expressed in terms of the so-called Cano et al. conditionals - a special class of conditional belief functions that are positive. This approach implies modification of the reasoning mechanism, because the correctness is maintained only by reasoning forward. Depending on the reasoning direction we need different ”Markov trees” for the reasoning engine.\nNote that lower/upper bound interpretations have a long tradition for DST [2,7] and have been heavily criticized [6]. The one that we presented in our\n1 This is a preliminary version of the paper: M.A. Kopotek: Transferable Plausibility Model - A Probabilistic Interpretation of Mathematical Theory of Evidence O.Hryniewicz, J. Kacprzyk, J.Koronacki, S.Wierzcho: Issues in Intelligent Systems Paradigms Akademicka Oficyna Wydawnicza EXIT, Warszawa 2005 ISBN 83-87674-90-7, pp.107–118\nbook differs from the known ones significantly as we insist on different reasoning schemes (hypertrees) depending on which are our target variables, whose values are to be inferred. This assures overcoming of the basic difficulties with lower/upper bound interpretations.\nOur qualitative approach is based on the earlier rough set interpretations of DST, but makes a small and still significant distinction. All computations are carried out in a strictly ”relational” way, that is, indistinguishable objects in a database are merged (no object identities). The behavior under reasoning fits strictly the DST reasoning model. Factors of well established hypergraph representation (due to Shafer and Shenoy [14]) can be expressed by relational tables. Conditional independence is well defined. However, there is no interpretation for conditional belief functions in this model.\nRough set interpretations [15] were primarily developed for interpreting the belief function in terms of decision tables. However, the Dempster-rule of evidence combination was valid there only for the ”extended decision tables”, not easily derived from the original ones. In our interpretation, both the original tables and the resultant tables dealt with when simulating Dempster-rule are conventional decision tables and the process of combining of decision tables is a natural one (relational join operator).\nOur rough set based interpretation may be directly applied in the domain of multiple decision tables: independence of decision variables or Shenoy’s conditional independence in the sense of DST may serve as an indication of possibility of decomposition of the decision table into smaller but equivalent tables.\nFurthermore, it may be applied in the area of Cooperative Query Answering [11]. The problem there is that a query posed to a local relational database system may contain an unknown attribute. But, possibly, other co-operating database systems know it and may explain it to the queried system in terms of known attributes, shared by the various systems. The uncertainties studied in the decision tables arise here in a natural way and our interpretation may be used to measure these uncertainties in terms of DST (as a diversity of support). Furthermore, if several co-operating systems respond, then the queried system may calculate the overall uncertainty measure using DST combination of measures of individual responses.\nThe quantitative model assumed that the objects possess multivalued properties which are then lost in some physical properties and these physical processes are described by DST belief functions (see e.g. [8])..\nThe quantitative model assumes that during the reasoning process one attaches labels to objects hiding some of their properties. There is a full agreement with the reasoning mechanism of DST. Conditional independence and conditional belief functions are well defined. We have also elaborated processes that can give rise to well-controlled graphoidally structured belief functions. Thus, sample generation for DST is possible. We elaborated also learning procedures for discovery of graphoidal structures from data.\nThe quantitative model seems to be the best fitting model for belief functions created so far.\nThis frequency model differs from what was previously considered [16,17] in that it assumes that reasoning in DST is connected with updating of variables for individual cases. This is different from e.g. reasoning in probability where reasoning means only selection of cases. In this way, failures of previous approaches could be overcome.\nMany authors [13,16] question the need for an empirical model for DST and point rather to theoretical properties of DST considered within an axiomatic framework seeking parallels with the probability theory. Though it is true that the probability theory may be applied within the framework of Kolmogorov axioms and quite useful results are derived in this way, one shall still point out that the applicability of probability theory is significantly connected with frequencies. Both frequencies considered as ”naive probabilities”, ore ones being probabilities ”in the limit”. Statistics is clearly an important part of the probabilistic world.\nAll three interpretations share a common drawback they are not sensu stricto probabilistic. In the current paper we make an attempt of a purely probabilistic vision of plausibility function."
    }, {
      "heading" : "2 Basics of the Dempster-Shafer Theory",
      "text" : "We understand DST measures in a standard way (see [12]). Let Ξ be a finite set of elements called elementary events. Any subset of Ξ is a composite event, or hypothesis. Ξ be called also the frame of discernment.\nDefinition 1. [12] Let Ω be a finite set of elements called elementary events. The set Ω is called frame of discernment. Any subset of Ω be a composite event. A basic probability assignment (bpa) function is any function m:2Ω → [0, 1] such that ∑\nA∈2Ω\nm(A) = ONE m(∅) = 0, ∀A∈2Ω 0 ≤ ∑\nA⊆B\nm(B)\nWe say that a bpa is vacuous iff m(Ω) = ONE and m(A) = 0 for every A 6= Ω.\nIf ONE is equal 1, then we say that the belief function is normalized, otherwise not (but ONE must be positive).\nDefinition 2. [12] Let a belief function be defined as Bel:2Ω → [0, 1] so that Bel(A) = ∑ B⊆A m(B). Let a plausibility function be Pl:2 Ω → [0, 1] with ∀A∈2Ω Pl(A) = ONE − Bel(Ω − A), a commonality function be Q:2Ω − {∅} → [0, 1] with ∀A∈2Ω−{∅} Q(A) = ∑ A⊆B m(B).\nDefinition 3. [12] The Rule of Combination of two Independent Belief Functions BelE1 , BelE2 Over the Same Frame of Discernment (the so-called DempsterRule), denoted\nBelE1,E2 = BelE1 ⊕BelE2\nis defined as follows: :\nmE1,E2(A) = c · ∑\nB,C;A=B∩C\nmE1(B) ·mE2(C)\n(c - constant normalizing the sum of m to 1).\nUnder multivariate settings Ξ is a set of vectors in n-dimensional space spanned by the set of variables X={ X1, X2, . . .Xn}. If A ⊆ Ξ, then by projection A↓Y of the set A onto a subspace spanned by the set of variables Y ⊆ X we understand the set B of vectors from A projected onto Y. Then marginalization operator of DST is defined as follows: m↓Y(B) = ∑ A;B=A↓X m(A).\nDefinition 4. (See [?]) Let B be a subset of Ξ, called evidence, mB be a basic probability assignment such that mB(B) = 1 and mB(A) = 0 for any A different from B. Then the conditional belief function Bel(.||B) representing the belief function Bel conditioned on evidence B is defined as: Bel(.||B) = Bel ⊕BelB."
    }, {
      "heading" : "3 New Rule of Evidence Combination",
      "text" : "Let us suggest now a totally new approach to understanding belief functions.\nWe assume the following interpretation of the plausibility function: Plξ(A) is the maximum probability that an element from the set of events A occurs, given the evidence ξ, where we assume the apriorical probability of all elementary events is equal. Let ξ1 and ξ2 be two independent bodies of evidence, which are represented numerically by plausibility functions Plξ1 and Plξ2 over some frame of discourse Ω. We would like to obtain such an evidence updating rule ⊕Pl that Pl3 = Plξ1 ⊕Pl Plξ2 would have the semantics that under that interpretation Pl3(A) is the maximum probability that an element from the set of events A occurs, given the evidence Pl1, Pl2 under the least conflicting evidence.\nLet us study in detail this assumption. First of all we have to tell what we mean by independent evidence. Let ω be an elementary event from the frame of discernment Ω. The body of evidence ξ1 is independent of the body ξ2 if, for each ω ∈ Ω, the probability of occurrence of evidence ξ1 is independent of the occurrence of evidence ξ2. So we say that Pr(ξ1 ∧ ξ2|ω) = Pr(ξ1|ω) · Pr(ξ2|ω).\nHow shall we understand the evidence, however. For any A ⊆ Ω) should hold Plξ(A) ≥ Pr(A|ξ). Consequently, by the way, Plξ(A) + Plξ(Ω/A) ≥ 1.\nNow observe that Pr(ω1 ∨ ω2|ξ) = Pr(ω1|ξ) + Pr(ω2|ξ). As a consequence, we have always that Plξ({ω1}) + Plξ({ω2}) ≥ Plξ({ω1, ω2}).\nLet us now turn to combining independent evidence.\nPr(ω|ξ1 ∧ ξ2) = Pr(ξ1 ∧ ξ2|ω) · Pr(ω)\nPr(ξ1 ∧ ξ2) Pr(ξ1|ω) · Pr(ξ2|ω) ·\nPr(ω)\nPr(ξ1 ∧ ξ2)\nPr(ω|ξ1) · Pr(ω|ξ2) · Pr(ξ1) · Pr(ξ2)\nPr(ξ1 ∧ ξ2) · Pr(ω)\nSo we can conclude that Plξ1∧ξ2(ω) = Plξ1(ω)·Plξ2(ω)·c where c is a normalizing factor (which needs to be chosen carefully).\nBut what about Pr(ω1 ∨ ω2|ξ1 ∧ ξ2) ? We know that Pr(ω1 ∨ ω2|ξ1 ∧ ξ2) = Pr(ω1|ξ1 ∧ ξ2) + Pr(ω2|ξ1 ∧ ξ2) hence\nPr(ω1 ∨ ω2|ξ1 ∧ ξ2)\nPr(ω1|ξ1)·Pr(ω1|ξ2)· Pr(ξ1) · Pr(ξ2)\nPr(ξ1 ∧ ξ2) · Pr(ω1) +Pr(ω2|ξ1)·Pr(ω2|ξ2)·\nPr(ξ1) · Pr(ξ2)\nPr(ξ1 ∧ ξ2) · Pr(ω2)\nAs Pr(ω) is the same for all the ωs, we get\nPr(ω1 ∨ ω2|ξ1 ∧ ξ2)\n(Pr(ω1|ξ1) · Pr(ω1|ξ2) + Pr(ω2|ξ1) · Pr(ω2|ξ2)) · Pr(ξ1) · Pr(ξ2)\nPr(ξ1 ∧ ξ2) · Pr(ω)\nWe can easily check that this translates to:\nPlξ1∧ξ2({ω1, ω2}) =\nmax(Plξ1(ω1) ·Plξ2(ω1)+(Plξ1({ω1, ω2}−Plξ1(ω1)) ·(Plξ2({ω1, ω2}−Plξ2(ω1))\n, P lξ1(ω1) · (Plξ2({ω1, ω2} − Plξ2(ω2)) + (Plξ1({ω1, ω2} − Plξ1(ω1)) · Plξ2(ω2)\n, P lξ1(ω2) · (Plξ2({ω1, ω2} − Plξ2(ω1)) + (Plξ1({ω1, ω2} − Plξ1(ω2)) · Plξ2(ω1)\n, P lξ1(ω2) ·Plξ2(ω2)+ (Plξ1({ω1, ω2}−Plξ1(ω2)) · (Plξ2({ω1, ω2}−Plξ2(ω2))) · c\nwhere c is the normalizing factor mentioned earlier. These formulas easily generalize for subsets of Ω with higher cardinality. The normalizing factor should be chosen in such a way that Plξ1∧ξ2(Ω) = 1. The generalization of ⊕Pl for frames of discourse with cardinality higher than 3 runs along the following lines. To combine Pl1 with Pl2 we calculate:\n– for each subset X of Ω Plresult(X) = PL ↓∗X 1 ⊗V Pl2↓ ∗X;\nThe operator ↓ ∗X does only a change of the domain of the Pl function keeping the values of Pl for each subset of X and presuming that the discourse frame consists only of X . In this way we get unnormalized Pls here, which are not normalized during this operation.\nThe operator ⊗V , returning a numerical value, attempts identify such combinations of mass assignments ma and mb to singleton sets that will not violate the constraints imposed by plausibility functions Pl1 and Pl2 resp. and such that the sum ∑ X;Xasingleton ma(X) ·mb(X) is maximal.\nThis is done by the operation of so-called pushing down the plausibilities to singleton sets. Independently for Pl1 and Pl2 candidate ma and mb are obtaining via ”pushing-down” recursively a singleton ω of Ω. A candidate ma is obtained if all singletons are pushed down. Different candidates are obtained by different sequences of pushing down. It is easy to imagine that the process is time-consuming and its complexity grows exponentially with the number of elements of a set. Nonetheless for small domains the operation is feasible.\nThe idea of the push-down operator ↓ + is as follows: Let Pl be a plausibility function. If A does not contain ω, Pl↓+ω(A) = min(Pl(A), P l(A ∪ {ω}) − Pl({ω})), and otherwise Pl↓+ω(A) = Pl(A).\nUnder these conditions it is obvious that we do not seek actually the maximum product over the whole domain, but rather in some ”corner points”. We will give a formal proof elsewhere that this check is in fact sufficient to establish the maximum. Here we only want to draw attention to the analogy with linear programming, where we seek the maximum subject to linear constraints. Whenever we fix ”pushdown” of one of the plausibility distributions, we in fact have a linear optimization case with the other. If found, we can do the same with the other.\nThe ⊕Pl operator is characterized by commutativity and associativity. The commutativity is easily seen because all the operations are in fact symmetrical with respect to left and right hand of the operators. The associativity is more difficult to grasp, and a formal proof will be subject of another publication. Nonetheless we can give here brief common-sense guidelines how it can be established. We can essentially concentrate on the associative properties of the maximum operator. Starting with the expression of combination of all the three plausibility functions, we can show that we can equivalently denote the same optimization task when drawing behind braces the first or the third operand.\nIn the next section we show some properties of the new operator compared with Dempster rule of combination for some illustrative examples."
    }, {
      "heading" : "4 Examples",
      "text" : "Let us consider the bodies of evidence in the tables 1, 2, 3.\ncompare tables 4 and 6\nWith this and other experiments we see clearly the tendency of Dempster rule to move mass downwards to singleton sets, whereas the new rule is much more cautious here and in fact does not introduce the feeling of certainty where it is not justified."
    }, {
      "heading" : "5 Conclusions",
      "text" : "We have introduced in this paper a new DST operator for combining independent evidence providing a clear probabilistic definition of the plausibility function, which is preserved under this rule of combination.\nWe have also provided several toy examples to give an impression what results are returned by the new operator.\nThough the strict theoretical proof of properties like cummutativeness, associativeness is still to be provided, the computations for test examples show that the properties really hold. It is also obvious from the examples that the new rule differs from the Dempster rule of evidence combination. An interested reader is invited to visit the Web page http://www.ipipan.waw.pl/˜klopotek/DSTnew/DSTdemo.html to try out himself."
    } ],
    "references" : [ {
      "title" : "An axiomatic framework for propagating uncertainty in directed acyclic networks",
      "author" : [ "J. Cano", "M. Delgado", "S. Moral" ],
      "venue" : "Int. J. of Approximate Reasoning",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1993
    }, {
      "title" : "Halpern: Uncertainty, belief, and probability",
      "author" : [ "J.Y.R. Fagin" ],
      "venue" : "Comput. Intell",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1991
    }, {
      "title" : "Two views of belief: belief as generalized probability and belief as evidence.Artificial Intelligence",
      "author" : [ "J.Y. Halpern", "R. Fagin" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1992
    }, {
      "title" : "Query processing in distributed information systems, Fundamenta Informaticae Journal, Special Issue on Logics for Artificial Intelligence, IOS Press, Vol",
      "author" : [ "Z.W. Ras" ],
      "venue" : "XV, No",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1991
    }, {
      "title" : "Ph.Smets, R.Kennes: The tranferable belief model",
      "author" : [ "Smets", "Kenne" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1994
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Among those verifying DST (Dempster-Shafer-Theory, [2,12]) critically were Kyburg [7], Fagin [3], Halpern [6], Pearl [9], Provan [10], Cano [1], just to mention a few.",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 0,
      "context" : "Among those verifying DST (Dempster-Shafer-Theory, [2,12]) critically were Kyburg [7], Fagin [3], Halpern [6], Pearl [9], Provan [10], Cano [1], just to mention a few.",
      "startOffset" : 140,
      "endOffset" : 143
    }, {
      "referenceID" : 2,
      "context" : "Note that lower/upper bound interpretations have a long tradition for DST [2,7] and have been heavily criticized [6].",
      "startOffset" : 113,
      "endOffset" : 116
    }, {
      "referenceID" : 3,
      "context" : "Furthermore, it may be applied in the area of Cooperative Query Answering [11].",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 4,
      "context" : "This frequency model differs from what was previously considered [16,17] in that it assumes that reasoning in DST is connected with updating of variables for individual cases.",
      "startOffset" : 65,
      "endOffset" : 72
    }, {
      "referenceID" : 0,
      "context" : "A basic probability assignment (bpa) function is any function m:2 → [0, 1] such that ∑",
      "startOffset" : 68,
      "endOffset" : 74
    }, {
      "referenceID" : 0,
      "context" : "[12] Let a belief function be defined as Bel:2 → [0, 1] so that Bel(A) = ∑ B⊆A m(B).",
      "startOffset" : 49,
      "endOffset" : 55
    }, {
      "referenceID" : 0,
      "context" : "Let a plausibility function be Pl:2 Ω → [0, 1] with ∀A∈2Ω Pl(A) = ONE − Bel(Ω − A), a commonality function be Q:2 − {∅} → [0, 1] with ∀A∈2Ω−{∅} Q(A) = ∑ A⊆B m(B).",
      "startOffset" : 40,
      "endOffset" : 46
    }, {
      "referenceID" : 0,
      "context" : "Let a plausibility function be Pl:2 Ω → [0, 1] with ∀A∈2Ω Pl(A) = ONE − Bel(Ω − A), a commonality function be Q:2 − {∅} → [0, 1] with ∀A∈2Ω−{∅} Q(A) = ∑ A⊆B m(B).",
      "startOffset" : 122,
      "endOffset" : 128
    } ],
    "year" : 2017,
    "abstractText" : "This paper suggests a new interpretation of the DempsterShafer theory in terms of probabilistic interpretation of plausibility. A new rule of combination of independent evidence is shown and its preservation of interpretation is demonstrated. 1",
    "creator" : "LaTeX with hyperref package"
  }
}