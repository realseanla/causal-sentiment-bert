{
  "name" : "1611.10215.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Unit Commitment using Nearest Neighbor as a Short-Term Proxy",
    "authors" : [ "Gal Dalal", "Elad Gilboa", "Shie Mannor", "Louis Wehenkel" ],
    "emails" : [ "gald@tx.technion.ac.il,", "egilboa@tx.technion.ac.il,", "shie@ee.technion.ac.il", "L.Wehenkel@ulg.ac.be" ],
    "sections" : [ {
      "heading" : null,
      "text" : "I. INTRODUCTION\nUnit commitment (UC) is solved daily by system operators (SO) world-wide as part of the market clearing process, to ensure safe operation. Typically, the resulting mathematical problem is either a deterministic or stochastic Mixed IntegerLinear Program (MILP). It is solved accurately for the following day, taking into account all available information on generation and demand, along with exogenous factors such as renewable generation forecast.\nAs intermittent generation capacity is increasing regularly in recent years, more stochasticity is involved in power system operation, affecting the way planning is done not only in the day-ahead time horizon, but in all different time horizons [1]–[3]. The complex dependence between the different timehorizons and the high uncertainty in long time-horizons makes long-term planning challenging. As demonstrated in [4], solving an extensive amount of UC problems to mimic short-term decision-making does not scale well to realistic grids, with thousands of nodes, generators and loads. This is specifically burdensome in planning for horizons of months to years, such as scheduling outages for asset maintenance. This midto long-term planning problem necessitates consideration of shorter time-scale operation. Outage scheduling, for instance, needs to be coordinated with short-term operation, namely the SO’s intervention in the day-ahead market clearing. For brevity, from this point on, we jointly refer both to mid- and long-term time horizons as long-term.\nPlanning under uncertainty is often done using stochastic optimization. This involves generation of scenarios, which in the case of long-term planning span over months or even dozens of years. In this context, scenario evolution is dependent on the sought plan and contains daily and hourly states of the system and exogenous conditions such as wind generation and consumption. To illustrate this, consider a maintenance planner assessing several alternatives for next year’s proposed\noutage schedule. To evaluate each of the schedules, he needs to examine the network’s ability to comply to a security constrained UC during the proposed outages in the schedules. He will therefore reproduce different possible network conditions during each of the year’s months, in terms of likely nodal wind generation and demand during that month. For each of the reproduced conditions, a UC problem will be solved given the specific future topology of the grid under the outages planned for this month. The planner will conduct this using simulation, iterating many times for each of the year’s months, per each of the optional outage schedules. The more accurate he wishes the result to be, the more samples of wind and demand values should be drawn from the assumed probabilistic distribution, fed to corresponding security constrained UC programs being solved. Each such UC solution can be used to evaluate the outage schedule in one or more possible ways: counting how many of the UC programs resulted in a feasible solution; averaging the resulting UC cost; averaging load lost if load shedding is allowed; used as reference for calculating costs in finer-grained hourly simulation, such as re-dispatch and recommitment of generators.\nMotivated by the above use-case, in this work we consider the need to solve numerous UC problem instances, for which the solution accuracy is not of the first priority."
    }, {
      "heading" : "A. Contribution",
      "text" : "In large networks, approximated proxy methods are necessary for assessment of cost and reliability, while performing long-term planning. We thus introduce the following concept – learning a proxy for approximating short-term decision making outcomes, relieving the dependence of long-term outcome assessment on accurate short-term decision making simulations; ergo, allowing for a tractable assessment methodology. We use a well-known machine learning algorithm – nearest neighbor classification [5]. We therefore call it UCNN.\nThe methodology relies on a simple concept – creating a large and diverse data-set that contains samples of the environment and grid conditions along with their respective UC solution. Consequently, during assessment of an outage schedule, instead of solving the multiple UC problem instances required to simulate decisions taken, simply choose among the already pre-computed UC solutions. The UC solution chosen to be used is the one with the closest conditions to the\nar X\niv :1\n61 1.\n10 21\n5v 1\n[ cs\n.L G\n] 3\n0 N\nov 2\n01 6\nenvironment and grid conditions of the current UC problem needed to be solved.\nThe essence of this method’s advantage lies in the fact that planning and assessment for long horizons in stochastic environments requires obtaining multiple samples (UC solutions), and the assumption that similar UC solutions will result in similar outputs (cost, reliability, etc.). Therefore, instead of repeating the expensive process of obtaining these samples (solving MILPs) for environment and grid conditions that often are repetitive within a single scenario and across different scenarios, utilize samples created ex-ante as representatives of sets of similar repetitive conditions. The initial creation of the data-set is a slow process which can either be done offline or online, i.e., by continuously adding new solutions to the datasets as they come available. After obtaining the training set, UCNN reduces computation time in several orders of magnitude, with relatively little compromise in quality, as presented in Section III. Without this significant reduction in computation time, long-term assessment processes, which account for short-term decisions based on multiple UC instances, would not be possible due to computational intractability."
    }, {
      "heading" : "B. Related work",
      "text" : "The literature contains several works that use machine learning for predicting outcomes of decision processes in power networks by pre-solving for multiple input conditions; such methods are referred to as supervised learning algorithms. We limit our analysis to the problem of generation (re)scheduling and reserve activation. In [6], frequency and active power time series are used for determining whether generator reserve activation is satisfactory or not. In this application, manual labeling of the data is required by experts, and there are only four possible classes. Reliability is maximized in [7] by learning a function that assesses the implications of rescheduling. The sought output is a policy, that dynamically maps system states to rescheduling actions. Reference [8] uses supervised learning for finding recourse strategies in generation management, by generating a training set via Monte-Carlo simulation of load and generation disturbances and then learning a near-optimal recourse strategy to handle similar disturbances observed in real-time. Recourse strategy learning is also investigated in [9], where boosting is used to create binary classifiers for boolean variables of the mixed integer programs resulting from daily generation re-planning problems."
    }, {
      "heading" : "II. UNIT COMMITMENT NEAREST NEIGHBOR CLASSIFICATION",
      "text" : "We begin by defining the accurate UC solution; notations are adopted from [4]. In our context, the optimal UC decision u∗p(ys, um) is the solution of the following optimization problem:\nu∗p(ys, um) = argmin up∈Up(um) Cp(ys, um, up), (1)\nwhere um is a long-term planning action that dictates the topology of the network, e.g., an outage schedule that determines which assets are offline; Up(um) is the set of feasible\nUC schedules with respect to um; Cp is the overall UC cost, consisting of generation, start-up, wind curtailment, and load shedding costs; ys is the day-ahead forecast of hourly nodal renewable generation and demand. We further use the following notation\nC∗p (ys, um) = Cp(ys, um, u ∗ p(ys, um)), (2)\nto denote the optimal value of the cost-function. For this UC problem we use the DC approximation, with the available generator capacities, minimum up/down times, ramp-rates, line flow constraints and N-1 security constraints when N-1 is used. It also includes wind curtailment and load shedding as (last resort) decisions. This results in a MILP that can be solved using commercial solvers [10]. It is a single-stage formulation that comes to estimate the marketclearing process. In the real world, two-stage unit commitment problems are often being solved (usually in Europe), in a continental scale at a first stage, and in a zonal level at a later stage. Notice this day-ahead market problem does not account for the possible developments in the real-time balancing market. It is solved once per each forecast value ys. This formulation is often referred to as inefficient market [11]. Next, we introduce the proposed supervised learning approach to solve this problem."
    }, {
      "heading" : "A. Supervised learning algorithm",
      "text" : "Generally, in the context of machine learning, supervised learning is the problem of predicting some output value (or label l) as a function of inputs (x), based on a learning set {(xj , lj)}nj=1 composed of a number n of input-output pairs. In this work, x = (ys, um) will be the inputs to a UC optimization problem, and l = (u∗p(ys, um), C ∗ p (ys, um)) will be its solution. We now show how to utilize a well-known and popular classification algorithm – nearest neighbor (NN) [12] – to construct a proxy that dismisses the need of obtaining accurate MILP solution to (1). Instead, it obtains approximate solutions (û∗p(ys, um), Ĉ ∗ p (ys, um)), solving a much less complex problem – finding the closest neighbor to the environment and grid conditions (ys, um) – with computation time that is several orders of magnitude lower. The family of NN algorithms was shown to work well on a large variety of problems [12]. We choose it, since it is in principle able to make consistent predictions over very complex output spaces (in our case a set of pairs (u∗p, C ∗ p )) provided that n is large enough."
    }, {
      "heading" : "B. Step one - training set generation",
      "text" : "For the application of supervised learning we first need to build a large data-set of pre-solved unit commitment problems, a process which we refer to as training set generation. It involves generating first a set {xj = (yjs, ujm)}nj=1, of inputs drawn from the marginal distribution expected to be used during the long-term planning process, and solving each of them accurately; i.e., obtain its output label lj = (u∗p(y j s, u j m), C ∗ p (y j s, u j m)) by solving (1) and using (2)."
    }, {
      "heading" : "C. Step two - definition of features and distance measure",
      "text" : "After the training set has been created, prediction is performed for each new sample x = (ys, um) to determine its corresponding label l̂(x) = (û∗p(x), Ĉ ∗ p (x)). In the NN method this is based on the choice of a distance measure defined over a chosen feature space defined by a mapping from the original inputs x to a vector φ(x). Given the dayahead forecast and maintenance plan x = (ys, um), the daily conditions which are the input for the UC problem are 24- hour per-bus demand and wind generation forecasts Dd.a(x) ∈ R24×nl ,Wd.a(x) ∈ R24×nw , where nl, nw are the numbers of loads and wind generators, and daily network topology topd.a(x) ∈ {0, 1}nl , where nl is the number of transmission lines. Element i in topd.a is 0 if line i is offline, and 1 otherwise. We thus denote by φ(ys, um) (or simply φ(x)) a column-stack (single-column vector representation) of a UC daily condition tuple: φ(x) = [Dcsd.a(x);W cs d.a(x); topd.a(x)], where superscript ·cs stands for column-stack. Based on this representation, we measure the distance d(x, x′) between two UC daily conditions x, x′ by the ξweighted L2-norm of their element-wise feature differences:\n||φ(x)− φ(x′)||ξ =\n  length(φ(x))∑\ni=1\nξ2i (φi(x)−φi(x ′))2\n  1 2\n. (3)\nThe weights ξ are used for expressing the importance of different entries in choosing the nearest neighbor. In our simulations the ξis multiplying the entries of topd.a are chosen to be 100, whereas the rest are set to 1. This choice came from our belief of higher importance of network’s topology than forecast values of demand and wind generation. In addition, ξ is used for scaling different units, e.g., for the binary values obtained for differences in topd.a, compared to the values in [MW] obtained for differences in Dcsd.a, W cs d.a. Further research in the field of feature selection and metric learning [13] is anticipated by the authors for optimizing the method."
    }, {
      "heading" : "D. Step three - prediction of outputs for a new sample",
      "text" : "The prediction of the output for a new sample x = (ys, um) is done by first finding the index of the learning sample closest to it in the feature space, namely by computing NN(x) = argminj∈{1,...,n} ||φ(x) − φ(xj)||ξ, and then by setting (û∗p(x), Ĉ ∗ p (x)) = (u ∗ p(x NN(x)), C∗p (x NN(x))) = lNN(x)."
    }, {
      "heading" : "III. EXPERIMENTS",
      "text" : "We begin by explaining the indicators used in our evaluation methodology to test the merits of UCNN and then present our experimental results."
    }, {
      "heading" : "A. Evaluation methodology",
      "text" : "From a machine-learning perspective, the problem introduced is not a standard classification problem, where an algorithm is assessed by its probability to classify samples correctly. In our case, labeling a sample means choosing the optimal UC schedule for it and at the same time predicting the corresponding cost. There is however no obvious technique\nfor comparing two UC schedules; they are represented in binary matrices that can be very different in standard metrics, such as Manhattan distance, and yet practically identical in terms of operation, depending on the network test-case and choice of generator representation. Non-standard evaluation methodology is therefore required in our setting.\nTo assess our UCNN algorithm, we therefore evaluate the quality of its output by solely using the cost criterion; for brevity we abuse notations and denote by C∗p (x) the “exact” optimal cost from (2) for a daily network state x. To evaluate UCNN’s approximation quality of the optimal cost C∗p (x), we use two accuracy measures: average relative error and correlation. The relative error of an approximate UC solution û∗p(x) compared to its accurate counterpart u ∗ p(x) is thus defined to be |Ĉ∗p (x)−C∗p (x)|\nC∗p (x) ; the average relative error is\ncalculated over an independent test set Xtest. On the other hand, the correlation is simply the linear correlation of Ĉ∗p (x) and C∗p (x) estimated over Xtest."
    }, {
      "heading" : "B. Experimental results",
      "text" : "We run our experiments on a Sun cluster with several Intel(R) Xeon(R) servers @2.53GHz, containing 100 cores, each with 2GB of memory. All code is written in Matlab [14]. We use YALMIP [15] to model the UC formulation and solve it using CPLEX [10].\nIn our simulation we consider the IEEE RTS-96 test-case. We adopt updated generator parameters from Kirschen et. al [16], namely their capacities, min-output, ramp up/down limits, min up/down times, price curve and start-up costs. Capacities and daily wind generation profiles are based on real historical records from the US as published in [17]. Peak loads and daily demand profile are based on real data, taken from [17]. Value of lost load is set to V OLL = 1000[ $MWh ], taken from [18] and wind-curtailment price is set to CWC = 100[ $MWh ], taken from [19]. In addition, we slightly modify the test-case so as to create several ’bottleneck’ areas to provide conditions for a variant set of UC plan costs with relatively short simulation time. These modifications include 1) removal of transmission line between bus 1 and 2, and 2) shift of loads from buses 1 and 2 to buses 3 and 4, respectively; visualization is found in Fig. 1.\nTraining and test sets of labeled (solved) UC schedules are of sizes |Xtrain| = 14K , |Xtest| = 1K. The three components of each sample x, i.e., daily load Dd.a(x), daily wind power Wd.a(x), and daily network topology topd.a(x) are drawn independently and then concatenated into a single vector. Both demand and wind processes are sampled from a multivariate normal distribution with standard deviation that is a fixed fraction of the mean (this fraction is 0.02 for demand and 0.15 for wind). Moreover, a monthly trend in demand and wind is governing the mean profiles [20]; each sample’s month is drawn uniformly.\nFor the sake of sampling daily network topology topd.a(x), we construct a set of possible outage combinations, given a list of candidate planned outages considered by the SO. This\nlist consists of 7 transmission line outages and 2 transmission interconnection outages in each of the three zones of IEEERTS96; for further elaboration refer to Fig. 1. The set of outage combinations consists of all possible 27+2 transmission outages, replicated per each zone. Each outage combination sample, i.e. topology topd.a(x), is drawn uniformly from the set of outage combinations. As for available generators and costs parameters, the whole study assumes those remain fixed. Supplementary material with further comprehensive technical details can be found in [21].\nFor each sample x ∈ Xtest, a UC solution is predicted by UCNN, and the corresponding approximate cost Ĉ∗(x) is compared to its accurate counterpart, C∗(x), using the average relative error and correlation measures. Scatter of accurate UC costs vs. UCNN costs is presented in Fig. 2. The form of small clusters is obtained since several daily mean demand-wind forecast profiles are used (season dependent). During summer demand is low and generation cost is relatively low. The months of this season correspond to the three small clusters of low UC costs. As a result, these improve linear correlation compared to when costs are high; the relative error measure is more robust to this effect. The resulting accuracy reports to be high: average relative error measures 3.6%, while linear correlation coefficient is 0.96.\nAn imperative question to be asked is how big should the training set be. Given some fixed level of accuracy to be achieved, there is an obvious dependence of the required size of Xtrain on the number of degrees of freedom in a single sample x, and their variance. The degrees of freedom in x are in load buses, wind generators, and number of candidate outages. The variance is based on common values from the\nliterature, as brought in the opening of this section. Therefore the larger the considered power system model and the more outages investigated, the larger the training set should be. We leave the detailed analysis discovering a mathematical relation between the two as an open question. Nevertheless, we now present an empirical examination of the level of approximation accuracy as a function of the training set size. Fig. 3 contains three plots: average relative error, correlation, and density as a function of |Xtrain|. The third metric, density, is defined to be the average distance (as defined in (3)) of x ∈ Xtest from its nearest neighbor in Xtrain. The results demonstrate errors that might be considered tolerable at already small sizes, where a training set of size 14K is sufficient for obtaining relative error and correlation of 3.7% and 0.96, using the examined setting. As the training set grows, the smaller the average distance is from nearest neighbors, allowing for a better approximation.\nNext, we test for the overall runtime improvement when\nusing UCNN. We compare the average run-time of solving an accurate UC program1 and obtaining a single UC solution when using UCNN. While accurate UC spans over 81 seconds on average, NNUC run-time is 0.31 seconds, spent on searching for a nearest neighbor of a sample. This is an enormous, two orders of magnitude, reduction in runtime."
    }, {
      "heading" : "C. Additional investigation and further experiments",
      "text" : "Our investigation of UCNN was extended in several directions, which for compactness we enclose in short. First, we experimented on a second test-case, IEEE-RTS79, that was modified in spirit that is similar to the modifications described in Sec. III. The results exhibit practically identical behavior for both networks in all simulations. In order to achieve the same low-error results as reported in Figures 2 and 3, a training set size that is roughly 2.5 larger was required for IEEE-RTS96 compared to IEEE-RTS79. This supports our claim that larger networks require more pre-computation. Second, we compared our method to N-1 secure UC; primarily the difference is in run-time. Adding N-1 constraints results in accurate solution times that are in order of magnitude larger than the non N1 case. We therefore achieve runtime improvement of three orders of magnitude by using UCNN, rendering the method even stronger for that case. Third, in addition to using cost as the sole classification evaluation method, we consider a notion of reliability in terms of resiliency to N-1 events, and witness strong correlation and low relative error in the view of that metric as well."
    }, {
      "heading" : "IV. CONCLUSION",
      "text" : "In this work we argue that at times, the accuracy vs. runtime trade-off is not be resolved by solely focusing on the former. We harness the power of machine learning and present the notion of a proxy – a mechanism that approximates shortterm decision making outcomes in a hierarchical setting, thus facilitating tractable assessment methodology.\nThe potential overall gain in CPU time is the fundamental advantage of this method, when used in the context of longterm assessment/control applications. This gain is essentially constituted by the ratio between the overall number of UC programs being solved in the process of long-term assessment, and the size of UCNN’s training set. As shown in [4], the required number of UC solutions can be in order of magnitude larger or more than the training set sizes used in the Section III, resulting in immense CPU time speed-up. Also, when implemented using efficient data-structures such as KD-Trees, computational complexity for searching a NN is sub-linear, eliminating the need of going over all data. The merits of our method hold even when very small training set sizes are used, generating only 8% relative error for example, for a training set of 1000 samples in the case of IEEE-RTS96.\nFurther research ought to focus on the metric-learning problem, discovering metrics induced by the classification problem at hand. The belief is that such an approach could not only\n1Overall runtime includes MILP modeling time, roughly taking 30-40% of the calculation time.\nimprove prediction accuracy, but also bear insights regarding the importance of different components of power networks in terms of cost and reliability. An additional direction is to use UCNN as a warm-start strategy to the optimization problem, where the approximate solution is fed to the solver as an initial guess. This enhancement can speed-up accurate UC solutions and can be of interest when approximations are not satisfactory."
    }, {
      "heading" : "I. EXACT UNIT COMMITMENT FORMULATION",
      "text" : "In the case of DC power flow, voltage magnitudes and reactive powers are eliminated from the problem and real power flows are modeled as linear functions of the voltage angles. This results in a mixed integer-linear program (MILP) that can be solved efficiently using commercial solvers [1]. The accurate unit-commitment problem formulation is the following:\nu∗p = arg min up∈Up(um,ys) Cp(um, up) = arg min α,Θ,Pg,t,WC,LS\nTd.a∑\nt=1\n  ngd∑\ni=1\n( αitf i P (P i g,t) + α i t(1− αit−1)SUi(tioff) )\n+\nngw∑\niw=1\nWCiwt · CWC + nb∑\nib=1\nLSibt · V OLL\n  (1a)\nsubject to (1b)\nglP,t(Θ l, α, Pg) = B l busΘ l t + P l BUS,shift +Dd.a,t (1c)\n+Gsh − LSt − (Wd.a,t −WCt)− Cg(αt. ∗ Pg) = 0 hlf,t(Θ l t) = B l fΘ l t + P l f,shift − F lmax ≤ 0 (1d) hlt,t(Θ l t) = B l fΘ l t − P lf,shift − F lmax ≤ 0 (1e) θrefi ≤ θli,t ≤ θrefi , i ∈ Iref (1f) αitp i,min g ≤ pig,t ≤ αitpi,maxg , i = 1, . . . , ngd (1g) 0 ≤WCiwt ≤W iwd.a,t, iw = 1, . . . , ngw (1h) 0 ≤ LSibt ≤ Dibd.a,t, ib = 1, . . . , nb (1i) tioff ≥ tidown, i = 1, . . . , ngd (1j) tion ≥ tiup, i = 1, . . . , ngd (1k) l = 0, 1, . . . , nlt (1l) t = 1, . . . , Td.a (1m)\nwhere\n• l is the index of a line that is offline. l = 0 means that all lines are connected and online. (lines that are under maintenance are not counted in nlt to begin with). • α ∈ {0, 1}ngd×Td.a is the commitment (on/off) status of all dispatchable generators, at all time-steps.\n• Θ ∈ [−π, π]nb×(nl+1)×Td.a are the different voltage angle vectors for the different network layouts, for all time steps. • Pg ∈ Rn g d×Td.a + ,WC ∈ R ngw×Td.a + , LS ∈ Rn b×Td.a + are\nthe dispatchable generation, wind curtailment and load shedding decision vectors, with fP , CWC , V OLL as their corresponding prices. • tidown, t i up are the minimal up and down times for generator\ni, after it had been off/on for tioff/t i on.\n• SUi(tioff) is the start-up cost of dispatchable generator i after it had been off for tioff time-steps. • glP,t(Θ l, α, Pg) is the overall power balance equation for\nline l being offline. • Bbus, PBUS,shift are the nodal real power injection linear\nrelation terms. • Bf , Pf,shift are the linear relation terms of the branch\nflows at the from ends of each branch (which are the minus of the to ends, due to the lossless assumption). • Gsh is the vector of real power consumed by shunt elements. • Cg is the generator-to-bus connection matrix, (αt. ∗ Pg) is the dot-product of the two vectors. • Fmax are the line flow limits. • Iref is the set of indices of reference buses, with θrefi being\nthe reference voltage angle. • pi,ming , p i,max g are the minimal and maximal power outputs\nof generator i.\nMore information on the DC approximation can be found in [2]. Constraints in Eqs. (1c)-(1e) ensure load balance and network topology constraints. Constraints in Eqs. (1f)-(1i) restrict the decision variables to stay within boundary, namely voltage angle limits, generator minimal and maximal power output range, wind curtailment and load shedding limits. Constraints in Eqs. (1j)-(1k) bind the different time steps to follow generator minimal up and down time thermal limits. Notice that the UC is an optimization program, where the decision is based on the informational state ys which the decision maker is exposed to when facing a day-ahead planning problem. The informational state ys contains the wind power and load forecasts Wd.a, Dd.a, which appear in the UC\nar X\niv :1\n61 1.\n10 21\n5v 1\n[ cs\n.L G\n] 3\n0 N\nov 2\n01 6\nproblem formulation. The short-term action-space Up(um) in Eq. (??), from which the decision variables (as appearing in their detailed form in the full inner optimization problem) are chosen, is the set of possible short-term operational plans. Long-term decision um dictates which assets are not taking part of the current plan due to maintenance."
    }, {
      "heading" : "II. TEST-CASE MODIFICATIONS",
      "text" : "The IEEE RTS-79 and IEEE RTS-96 test-cases used in this work were slightly modified. The network modifications and outages considered were chosen so as to create several ’bottleneck’ areas in the networks and by that provide conditions for a variant set of UC plan costs and reliability levels with relatively short simulation time.\nFig. 1 visualizes the network modifications and choice of considered outages for the IEEE-RTS79 network. The same modifications and outages were replicated for each of the three identical zones of the IEEE-RTS96 network, and are not explicitly listed for the sake of brevity. Additionally, outages in three transmission interconnections between the three zones of IEEE-RTS96 were considered as well.\nIEEE-RTS79 network modifications involve:\n1) Removal of transmission line between bus 1 and 2. 2) Shift of loads from buses 1 and 2 to buses 3 and 4,\nrespectively.\nThe considered outages are in transmission lines with ID 2,3,4,5,11,25,26."
    }, {
      "heading" : "III. DAILY CONDITIONS DISTRIBUTIONS",
      "text" : "Generation of the training and test sets involves a sampling procedure of UC inputs x out of some distribution PX(x). We independently sample daily wind power Wd.a, daily load Dd.a, and daily network topology topd.a. Provided are details on the models used for these probabilistic processes, along with the data they are based on.\n1) Wind power distribution: Wind generation capacities are taken from [3], along with their daily mean profile. The wind process mean µw(t) is therefore obtained by the formula\nµw(t) = µw(tD) · pw,annual(tM )\n, where µw(tD) ∈ Rn g w\n+ is the daily wind mean profile at timeof-day tD, and pw,annual(tM ) ∈ [0, 1] is the annual wind profile relative to its peak at month tM of the year. Hourly wind generation process Wt is a multivariate, normally distributed random variable\nWt ∼ N ( µw(t), diag((pw,σ · µw(t))2) )\nwhere pw,σ ∈ [0, 1] is a constant (= 0.15) that multiplies the mean µw(t), to obtain a standard deviation that is a fixed fraction of the mean. diag(x) is a square diagonal matrix, with the elements of x as its diagonal, so different wind generators are assumed uncorrelated. Wt is truncated to stay in the range between 0 and the generator’s capacity.\n2) Load distribution: Hourly load Dt is assumed to follow the same normal distribution as the wind, with the same formula containing peak loads and daily profiles for each bus µd(tD) ∈ Rn b\n+ with values taken from [3]. Fraction of mean for standard deviation is set to be pd,σ = 0.02.\n3) Outage distribution: Appendix II lists the choice of transmission lines where outages are considered. Sampling of daily topology topd.a is done uniformly out of the combinatorial outage set."
    } ],
    "references" : [ {
      "title" : "Matpower: Steady-state operations, planning, and analysis tools for power systems research and education",
      "author" : [ "R.D. Zimmerman", "C.E. Murillo-Sánchez", "R.J. Thomas" ],
      "venue" : "Power Systems, IEEE Transactions on, vol. 26, no. 1, pp. 12–19, 2011.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Renewable energy analysis lab",
      "author" : [ "E.E.D. University of Washington" ],
      "venue" : "http://www.ee.washington.edu/research/real/library.html.",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 0
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "[1]–[3].",
      "startOffset" : 4,
      "endOffset" : 7
    } ],
    "year" : 2016,
    "abstractText" : "We devise the Unit Commitment Nearest Neighbor (UCNN) algorithm to be used as a proxy for quickly approximating outcomes of short-term decisions, to make tractable hierarchical long-term assessment and planning for large power systems. Experimental results on an updated version of IEEE-RTS96 show high accuracy measured on operational cost, achieved in runtimes that are lower in several orders of magnitude than the traditional approach.",
    "creator" : "LaTeX with hyperref package"
  }
}