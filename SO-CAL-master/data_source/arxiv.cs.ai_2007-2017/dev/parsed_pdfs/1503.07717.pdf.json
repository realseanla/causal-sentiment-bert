{
  "name" : "1503.07717.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Claire Lefèvre", "Christopher Béatrix", "Igor Stéphan", "Laurent Garcia" ],
    "emails" : [ "claire@info.univ-angers.fr", "beatrix@info.univ-angers.fr", "stephan@info.univ-angers.fr", "garcia@info.univ-angers.fr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "In this article, the project ASPeRiX is presented as a first order forward chaining approach for Answer Set Computing. This project was amongst the first to introduce an approach of answer set computing that escapes the preliminary phase of rule instantiation by integrating it in the search process. The methodology applies a forward chaining of first order rules that are grounded on the fly by means of previously produced atoms. Theoretical foundations of the approach are presented, the main algorithms of the ASP solver ASPeRiX are detailed and some experiments and comparisons with existing systems are provided.\nKEYWORDS : Answer Set Programming, solver implementation, grounding on the fly, first order, forward chaining."
    }, {
      "heading" : "1 Introduction",
      "text" : "Answer Set Programming (ASP) is a very convenient paradigm to represent knowledge in Artificial Intelligence (AI) and to encode combinatorial problems (Baral 2003; Niemelä 1999). It has its roots in nonmonotonic reasoning and logic programming and has led to a lot of works since the seminal paper (Gelfond and Lifschitz 1988). Beyond its ability to formalize various problems from AI or to encode combinatorial problems, ASP provides also an interesting way to practically solve such problems since some efficient solvers are available. In few words, if someone wants\n∗ This work was supported by ANR (National Research Agency), project ASPIQ under the reference ANR-12-BS02-0003.\nar X\niv :1\n50 3.\n07 71\n7v 1\n[ cs\n.L O\n] 2\nto use ASP to solve a problem, he has to write a logic program in term of rules in a purely declarative manner in such a way that the answer sets (initially called stable models in (Gelfond and Lifschitz 1988)) of the program represent the solutions of his original problem.\nIllustration of ASP formalism Let us take two typical examples for which ASP is suitable: the first example is devoted to knowledge representation in Artificial Intelligence and the second one is a combinatorial problem.\nKR problem This first example deals with default reasoning on incomplete information. It consists in describing knowledge about birds. bird(titi).\nostrich(lola). bird(X)← ostrich(X). f ly(X)← bird(X), not ostrich(X). non fly(X)← ostrich(X).\nThe meaning of the two first rules is that we have two objects: titi which is a bird and lola which is an ostrich. The meaning of the other rules is that an ostrich is a bird, a bird which is not an ostrich flies and an ostrich does not fly. Here, we are interested in deducing some properties about titi and lola. Intuitively, we want that titi flies, lola is a bird and lola does not fly. Concerning the information that lola does not fly, let us notice that it is obtained by applying the last rule since lola is an ostrich and, then, the next to last rule cannot be applied in presence of ostrich lola due to the part not of this rule, called default negation. Here, there is only one answer set which contains all the deduced pieces of information: {bird(titi), f ly(titi), ostrich(lola), bird(lola), non fly(lola)}.\nCSP problem The second example deals with the representation of a combinatorial problem: possibles worlds are represented by nonmonotonic “guess” rules and choice between these worlds is expressed by constraints. The problem is then to find (at least) one solution corresponding to a world verifying the constraints. This example is about graph 2-coloring. vertex(1).\nvertex(2). edge(1, 2). red(X)← vertex(X), not blue(X). blue(X)← vertex(X), not red(X). ← red(X), red(Y ), edge(X,Y ). ← blue(X), blue(Y ), edge(X,Y ).\nThis represents a graph with two vertices and an edge between them (three first rules). The two following rules are guess rules. The fourth (resp. fifth) rule means that a vertex which is not colored in blue (resp. red) has to be colored in red (resp. blue). The two last rules are constraints. They mean that two adjacent vertices can not have the same color. Here, we want to find how the two vertices should be colored (knowing that two colors are available). Intuitively, we have two solutions:\none with vertex 1 colored in blue and vertex 2 colored in red and the other one with vertex 1 colored in red and vertex 2 colored in blue. This corresponds to the two answer sets of the program: {vertex(1), vertex(2), edge(1, 2), blue(1), red(2)} and {vertex(1), vertex(2), edge(1, 2), red(1), blue(2)}. However, let us note that, in this kind of problem, we are often interested in finding one solution rather than finding all the possible solutions (and the determination of only one answer set is enough).\nAs regards the form of the rules, we can notice that a program usually contains different kind of rules. The simplest ones are facts as (bird(titi).) or (vertex(1).) representing data of the particular problem. Some ones are about background knowledge as (bird(X)← ostrich(X).). Some others can be nonmonotonic as (fly(X)← bird(X), not ostrich(X).) for reasoning with incomplete knowledge. In other cases, especially for combinatorial problems, nonmonotonic rules can be used to encode alternative potential solutions of a problem as (red(X)← vertex(X), not blue(X).) and (blue(X)← vertex(X), not red(X).) expressing the two exclusive possibilities to color a vertex in a graph. Last, special headless rules are used to represent constraints of the problem to solve as (← red(X), red(Y ), edge(X,Y ).), here, in order to not color with red two vertices linked by an edge.\nWith the examples above we can point out that knowledge representation in ASP is done by means of first order rules. But, from a theoretical point of view, answer set definition is given for propositional programs and the answer sets of a first order program are those of its ground instantiation with respect to its Herbrand universe (i.e. without variables). The first order program has to be seen as an intensional version of the grounded propositional corresponding program.\nASP systems Concerning the ASP sytems, their main goal is how to compute answer sets in an efficient way. Let us recall some of their main features. Until today, almost all systems available to compute the answer sets of a program follow the architecture described in Fig. 1.\nAn ASP system begins its work by an instantiation phase in order to obtain a propositional program (and, as said above, the answer sets of the first order program will be those of its ground instantiation). After this first grounding phase realized by a grounder the solver starts the real phase of answer set computation by dealing\nwith a finite, but sometimes huge, propositional program. The main goal of each grounding system is to generate all propositional rules that can be relevant for a solver and only these ones, while preserving answer sets of the original program. Current intelligent grounders simplify rules as much as possible. Simplifications can lead to compute the unique answer set of some programs (for instance, programs that does not contain default negation) but it is no longer possible once the problem is combinatorial. Anyway, the grounding phase is firstly and fully processed before calling the solver.\nFor the grounder box we can cite Lparse (Syrjänen 1998) and Gringo (Gebser et al. 2011), and for the solver box Smodels (Simons et al. 2002) and Clasp (Gebser et al. 2012). A particular family of solvers are Assat (Lin and Zhao 2004), Cmodels (Giunchiglia et al. 2006) and Pbmodels (Liu and Truszczynski 2005), since they transform the answer set computation problem into a (pseudo) boolean model computation problem and use a (pseudo) SAT solver as an internal black box. In the system DLV (Leone et al. 2006), symbolized in Fig. 1 by the dash-line rectangle, the grounder ((Calimeri et al. 2008) describes a parallel version) is incorporated as an internal function. In the same way, WASP (Alviano et al. 2013) uses the DLV grounder (Faber et al. 2012).\nGrounding The main drawback of the preliminary grounding phase is that it may lead to a lot of useless work as illustrated in the following examples.\nThe first examples illustrate the fact that the separation between the instantiation phase and the computation phase can prevent the (efficient) use of information relevant to the computation.\nExample 1. Let P1a be the following ASP program:\nP1a =  a← not b., b← not a., ← a., p(0).,\np(X + 1)← a, p(X).  Grounding of P1a is infinite (if an upper bound for integers is not fixed) while it has a unique (and finite) answer set {b, p(0)}. Let P1b be the following ASP program:\nP1b =  p(1)., p(2)., . . . , p(N)., a← not b., aa(X,Y )← pa(X), pa(Y ), not bb(X,Y )., b← not a., bb(X,Y )← pb(X), pb(Y ), not cc(X,Y )., pa(X)← a, p(X)., cc(X,Y )← aa(X,Y ), X < Y., pb(X)← b, p(X)., ← a.  From the program P1b, current grounders generate roughly 2.5×N2 rules.\nIn both programs, because of the constraint (← a.) that eliminates from the possible solutions every atom set containing a, it is easy to see that rules (p(X+1)←\na, p(X).) for P1a and (pa(X)← a, p(X).) for P1b are useless since they can never contribute to generate an answer set of the corresponding program. In P1a these useless rules are infinite (p(X + 1) ← a, p(X).) while they are “only” large in P1b: N rules with positive body containing a, like (pa(1)← a, p(1).), and then, the N2 rules with pa(X) in their positive body are useless too. In defense of the actual grounders, their inability to eliminate these particular rules is not surprising since the reason justifying this elimination is the consequence of a reasoning taking into account the semantics of ASP. Thus, if we want to limit as much as possible the number of rules and atoms to deal with, we have not to separate grounding and answer set computing.\nExample P1a is a typical situation for planning problems where step i+1 must be generated only if the goal is not reached at step i. Such situations are not tractable by grounders. That is the reason why the number of steps needed to reach the goal (or at least the maximum number of allowed steps) is given as input of planning problems (in ASP competition for example). Yet it is rather counterintuitive having to know the step number to solve the problem before solving.\nThe next example illustrates that the grounding phase generates too much infor-\nmation regarding the computation of one answer set.\nExample 2. Let P2 be the program, as given in (Niemelä 1999), encoding a 3- coloring problem on a N vertices graph organized as a bicycle wheel (see below). v stands for vertex, e for edge, c for color, col for colored by, ncol for not colored by.\nP2 =  v(1)., . . . , v(N)., c(red)., c(blue)., c(green)., e(1, 2)., . . . , e(1, N)., e(2, 3)., e(3, 4)., . . . , e(N, 2)., col(V,C)← v(V ), c(C), not ncol(V,C)., ncol(V,C)← col(V,D), c(C), C 6= D., ← e(V,U), col(V,C), col(U,C).  . From P2, current grounders generate about 18N rules. If N is even then P2 has\nno answer set and if N is odd then it has 6 answer sets.\nSuppose that P2 has an answer set in which there is col(1, red). Obviously, all the N − 1 constraints like (← e(1, U), col(1, red), col(U, red).) for all U ∈ {2, . . . , N} are necessary because they have to be checked. But, all the other constraints like (← e(1, U), col(1, blue), col(U, blue).), and (← e(1, U), col(1, green), col(U, green).) for all U ∈ {2, . . . , N} can be considered as useless since vertex 1 is not colored by blue or green. However, all these 2N − 2 constraints have been generated. So, the time consumed by this task is clearly a lost time and the memory space used by these data could have been saved. Thus, if we are searching for a single answer set, a lot of work would be done for nothing since the grounded program contains the enumeration of all solutions when only one is searched.\nThe last exemple shows that when the number of solutions is very important ASP solvers have more difficulty to find one solution due to the grounding phase generating a lot of information concerning all the solutions.\nExample 3. Let P3 be the program, inspired from one given in (Niemelä 1999), encoding the Hamiltonian cycle problem in a N vertices complete oriented graph. v\nstands for vertex, a for arc, hc for in Hamiltonian cycle, nhc for not in Hamiltonian cycle, s for start and r for reached.\nP3 =  s(1)., v(1)., . . . , v(N)., a(X,Y )← v(X), v(Y )., hc(X,Y )← s(X), a(X,Y ), not nhc(X,Y )., hc(X,Y )← r(X), a(X,Y ), not nhc(X,Y )., nhc(X,Y )← hc(X,Z), a(X,Y ), Y 6= Z., nhc(X,Y )← hc(Z, Y ), a(X,Y ), X 6= Z., r(Y )← hc(X,Y )., ← v(X), not r(X).  This program has (N − 1)! answer sets. Whatever the number of desired solutions, current grounders generate about 2N2 rules with hc predicate as head and about 2N3 rules with nhc predicate as head. Thus, even if we restrict our attention to the computation of one answer set, all the ASP solvers preceded by a grounding phase consume a huge amount of time when the graph has a few hundred vertices.\nThis previous example illustrates another strange phenomenon. Sometimes, solving a trivial problem, as finding one Hamiltonian cycle in a complete graph, is impossible for ASP systems. This is very counterintuitive since, in whole generality, in combinatorial problem solving the more solutions the problem has, the easier it is to find one of them. Again, the bottleneck for ASP systems seems to come from the huge number of rules and atoms that are generated in first, delaying and making the resolution more difficult than it should be.\nBeyond these particular examples, the point to stress is that grounders generate in extension all the search space (for all potential solutions) that they give then to the solver. But, this is clearly not the approach of usual search algorithms. A classical coloring algorithm does not firstly enumerate, in extension, all possible colorations for every vertex in the graph. A finite domain solver makes choices by instantiating some variables, propagates the consequences of these choices, checks the constraints and by backtracking explores its search space. Following this strategy it instantiates and desinstantiates variables describing the problem to solve all along its search process. But, it does not build, a priori and explicitly, all the possible tuples of variables and constraints representing the problem to solve. That is why we think that if we want to use ASP to solve very large problems we have to realize the grounding process during the search process and not before it.\nIs is important to notice that few works advocate the grounding of the program during the search of an answer set and not by a preprocessing. Some aim at solving the grounding bottleneck by combining ASP to constraint programming: (Baselice et al. 2005) proposes to reduce the memory requirements for a very specific class of programs, i.e. multi-sorted logic programs with cardinality constraints, (Balduccini 2009) proposes an algorithm to make cooperate an ASP solver and a Constraint Logic Programming solver in such a way that ASP is viewed as a specification language for constraint satisfaction problems and (Ostrowski and Schaub 2012) describes the Clingcon system which is a tight cooperation between the ASP solver Clasp and the Constraint Programming solver GeCode. The theory solvers (mainly arithmetic solvers) forbid instances that are in conflict with the constraints reduc-\ning by this way the size of the grounding image. Some others works use a forward chaining of rules that are instantiated as and when required: GASP (Dal Palù et al. 2009) and ASPeRiX (Lefèvre and Nicolas 2009a; Lefèvre and Nicolas 2009b)) developed at the same time, and more recently OMiGA (Dao-Tran et al. 2012). They are all based on the notion of computation given in (Liu et al. 2010). GASP is implemented in Prolog and Constraint Logic Programming over finite domains. Each rule instantiation and propagation is realized by building and solving a CSP. OMiGA is implemented in Java and uses an underlying Rete network for instantiation and propagation. ASPeRiX, which is the one presented in this article, is implemented in C++. Instantiation and propagation are inspired by previous work realized on the DLV grounder which is based on the semi-naive evaluation technique of (Ullman 1989).\nLast, concerning a direct handling of first order programs, let us note that there exists some works (Gottlob et al. 1996; Eiter et al. 1997; Ferraris et al. 2007; Lin and Zhou 2007; Truszczynski 2012) dealing with first order nonmonotonic logic programs. These works establish some relations between stable model semantics and constraints systems or second order logic or circumscription but they are not really concerned by the explicit computation of answer sets.\nThe present paper is an extended version of (Lefèvre and Nicolas 2009a; Lefèvre and Nicolas 2009b). It details our approach of answer set computation that escapes the preliminary grounding phase by integrating it in the search process and includes:\n• theoretical foundations of the approach, “mbt ASPeRiX computation”, with complete proofs; these computations are based on those of (Liu et al. 2010)\nand include use of constraints and must-be-true propagation in order to guide the search;\n• a detailed description of the main algorithms; • experimentations of the resulting system, ASPeRiX, and comparisons with\nother similar systems and other “classical” ASP systems. Our methodology is particularly well suited for:\n— solving easy problems with a large grounding, — finding only one answer set for a program whose search space is large and\nproportional to the desired number of solutions,\n— solving problems for which pre-grounding is impossible because domains\nare infinite or open, or because some pieces of knowledge come from outside (distributed systems for example).\nThe paper is organized as follows. In Section 2 we recall the theoretical backgrounds about ASP necessary to the understanding of our work. In Section 3 we present our first order rule oriented approach of answer set computation and its implementation in the solver ASPeRiX. In Section 4 experimental results are presented. We conclude in Section 5 by citing some new perspectives for ASP as a result of our innovative approach. Proofs of theorems are reported in Appendix B."
    }, {
      "heading" : "2 Theoretical Background",
      "text" : "In this section, we give the main backgrounds of ASP framework useful to the understanding of this article.\nSet V denotes the infinite countable set of variables, set FS denotes the set of function symbols, set CS denotes the set of constant symbols and set PS denotes the set of predicate symbols. It is assumed that the sets V, CS, FS and PS are disjoint and that the set CS is not empty. Function ar denotes the arity function from FS to N∗ and from PS to N which associates to each function or predicate symbol its arity. Set T denotes the set of terms defined by induction as follows:\n• if v ∈ V then v ∈ T, • if c ∈ CS then c ∈ T, • if f ∈ FS with ar(f) = n > 0 and t1, . . . , tn ∈ T then f(t1, . . . , tn) ∈ T.\nA ground term is a term built over only the two last items of the previous definition. The Herbrand universe is the set of all ground terms. Set A denotes the set of atoms defined as follows:\n• if a ∈ PS with ar(a) = 0 then a ∈ A, • if p ∈ PS with ar(p) = n > 0 and t1, . . . , tn ∈ T then p(t1, . . . , tn) ∈ A.\nA ground atom is an atom built over only ground terms. The Herbrand base denoted A is the set of all ground atoms. A normal logic program (or simply program) is a set of rules like\nc← a1, . . . , an, not b1, . . . , not bm. n ≥ 0,m ≥ 0 (1)\nwhere c, a1, . . . , an, b1, . . . , bm are atoms.\nThe intuitive meaning of such a rule is: ”if all the ai’s are true and it may be assumed that all the bj ’s are false then one can conclude that c is true”. Symbol not denotes the default negation. A rule with no default negation is a definite rule otherwise its is a nonmonotonic rule. A program with only definite rules is a definite logic program. A program is a propositional program if all the predicate symbols are of arity 0.\nFor each program P , we consider that the set CS (resp. FS and PS) consists of all constant (resp. function and predicate) symbols appearing in P . These sets determine the set of ground terms and the set of ground atoms of the program. A substitution for a rule r ∈ P is a mapping from the set of variables from r to the set of ground terms of P . A ground rule r′ is a ground instance of a rule r if there is a substitution θ for r such that r′ = θ(r), the rule obtained by substituting every variable in r by the corresponding ground term in θ. The program P (with variables) has to be seen as an intensional version of the program ground(P ) defined as follows: given a rule r, ground(r) is the set of all ground instances of r and\nthen, ground(P ) = ⋃ r∈P ground(r). Program ground(P ) may be considered as a propositional program. Let us note that the use of function symbols leads to an infinite Herbrand universe, this point will be discussed in Section 3.5.\nExample 4. The program\nP4 =  n(1)., n(2).,\na(X)← n(X), not b(X)., b(X)← n(X), not a(X).  is a shorthand for the program\nground(P4) =  n(1)., n(2)., a(1)← n(1), not b(1)., b(1)← n(1), not a(1)., a(2)← n(2), not b(2)., b(2)← n(2), not a(2).  For a rule r (or by extension for a rule set), we define:\n• head(r) = c its head, • body+(r) = {a1, . . . , an} its positive body and • body−(r) = {b1, . . . , bm} its negative body.\nThe immediate consequence operator for a definite logic program P is TP : 2 A → 2A such that TP (X) = {head(r) | r ∈ P, body+(r) ⊆ X}. The least Herbrand model of P , denoted Cn(P ), is the smallest set of atoms closed under P , i.e., the smallest set X such that TP (X) ⊆ X. It can be computed as the least fix-point of the consequence operator TP .\nThe reduct PX of a normal logic program P w.r.t. an atom set X ⊆ A is the definite logic program defined by:\nPX = {head(r)← body+(r). | r ∈ P, body−(r) ∩X = ∅}\nand it is the core of the definition of an answer set.\nDefinition 1. (Gelfond and Lifschitz 1988) Let P be a normal logic program and X an atom set. X is an answer set of P if and only if X = Cn(PX).\nFor instance, the propositional program {a← not b., b← not a.} has two answer sets {a} and {b}.\nExample 5. Taking again the program P4, ground(P4) has four answer sets:\n{a(1), a(2), n(1), n(2)}, {a(1), b(2), n(1), n(2)}, {a(2), b(1), n(1), n(2)}, {b(1), b(2), n(1), n(2)}\nthat are thus the answer sets of P4.\nThere is another definition of an anwer set for a normal logic program based on the notion of generating rules which are the rules participating to the construction of the answer set. These rules are important in our approach because they are exactly the rules fired in the ASPeRiX computation presented in the next section.\nDefinition 2. (Konczak et al. 2006) Let P be a normal logic program and X be an atom set. GRP (X), the set of generating rules of P , is defined as GRP (X) = {r ∈ P | body+(r) ⊆ X and body−(r) ∩X = ∅}.\nTheorem 1. (Konczak et al. 2006) Let P be a normal logic program and X be an atom set. Then, X is an answer set of P if and only if X = head(GRP (X)).\nSpecial headless rules, called constraints, are admitted and considered equivalent to rules like (bug ← . . . , not bug.) where bug is a new symbol appearing nowhere else. For instance, the program {a ← not b., b ← not a.,← a.} has one, and only one, answer set {b} because constraint (← a.) prevents a to be in an answer set.\nWhen dealing with default negation, we call a literal an atom, a, or the negation of an atom, not a. A literal a is said to be positive, and not a is said to be negative. The corresponding atom a of a literal l is denoted by at(l). For a literal l where at(l) = a, let us denote pred(l) the function such that pred(not a) = pred(a) = p with p the predicate symbol of the atom a.\nFor purposes of knowledge representation, one may have to use conjointly strong negation (like ¬a) and default negation (like not a) inside a same program. This is possible in ASP by means of an extended logic program (Gelfond and Lifschitz 1991) in which rules are built with classical literals (i.e. an atom a or its strong negation ¬a) instead of atoms only. Semantics of extended logic programs distinguishes inconsistent answer sets from absence of answer set. But, if we are not interested in inconsistent answer sets, the semantics associated to an extended logic program is reducible to answer set semantics for a normal logic program using constraints by taking into account the following conventions:\n• every classical literal ¬x is encoded by the atom nx, • for every atom x, the constraint (← x, nx.) is added.\nBy this way, only consistent answer sets are kept. In this article, we do not focus on strong negation and literal will never stand for classical literal.\nLet us note that one can also use some particular atoms for (in)equalities and simple arithmetic calculus on (positive and negative) integers. Arithmetic operations are treated as a functional arithmetic and comparison relations are treated as built-in predicates.\nFinally, a program P is said to be stratified iff there is a mapping strat from PS to N such that, for each ground rule like (1), the two following conditions hold:\n• strat(pred(c)) ≥ str(pred(ai)) for all i ∈ [1..n] • strat(pred(c)) > str(pred(bj)) for all j ∈ [1..m]\n3 A First Order Forward Chaining Approach for Answer Set\nComputing\n3.1 ASPeRiX Computation\nIn this section, a characterization of answer sets for first-order normal logic programs, based on a concept of ASPeRiX computation, is presented. This concept is itself based on an abstract notion of computation for ground programs proposed in (Liu et al. 2010). This computation fundamentally uses a forward chaining of rules. It builds incrementally the answer set of the program and does not require the whole set of ground atoms from the beginning of the process. So, it is well suited to deal directly with first order rules by instantiating them during the computation.\nThe only syntactic restriction required by this methodology is that every rule of a\nprogram must be safe. That is, all variables occurring in the head and all variables occurring in the negative body of a rule occur also in its positive body. Note that this condition is already required by all standard evaluation procedures. Moreover, every constraint (i.e. headless rule) is considered given with the particular head ⊥ and is also safe. For the moment we do not consider function symbols but their use will be discussed in Section 3.5.\nAn ASPeRiX computation is defined as a process on a computation state based\non a partial interpretation which is defined as follows.\nDefinition 3. A partial interpretation for a program P is a pair 〈IN,OUT 〉 of disjoint atom sets included in the Herbrand base of P .\nIntuitively, all atoms in IN belong to a search answer set and all atoms in OUT\ndo not.\nThe notion of partial interpretation defines different status for rules.\nDefinition 4. Let r be a ground rule and I = 〈IN,OUT 〉 be a partial interpretation.\n• r is supported w.r.t. I when body+(r) ⊆ IN , • r is blocked w.r.t. I when body−(r) ∩ IN 6= ∅, • r is unblocked w.r.t. I when body−(r) ⊆ OUT , • r is applicable w.r.t. I when r is supported and not blocked.1\nAn ASPeRiX computation is a forward chaining process that instantiates and fires one unique rule at each iteration according to two kinds of inference: a monotonic step of propagation and a nonmonotonic step of choice. To fire a rule means to add the head of the rule in the set IN .\nDefinition 5. Let P be a set of first order rules, I be a partial interpretation and R be a set of ground rules.\n• ∆pro(P, I,R) is the set of all supported definite rules and supported unblocked nonmonotonic rules from ground(P ) \\R. • ∆cho(P, I,R) is the set of all applicable nonmonotonic rules from ground(P )\\ R.\nIt is important to notice that the two sets defined above, like the set ground(P ), do not need to be explicitly computed. It is in accordance with the principal aim of this work that is to avoid their extensive construction. When necessary, a firstorder rule of P can be selected and grounded with propositional atoms occurring in IN and OUT in order to define a new (not already occurring in R) fully ground rule member of ∆pro or ∆cho. Because of the safety constraint on rules this full grounding is always possible. These mechanisms are specified in more details in Subsection 3.3. The sets ∆pro and ∆cho are used in the following definition of an ASPeRiX computation. Specific case of constraints (rules with ⊥ as head) is treated by adding ⊥ into OUT set. By this way, if a constraint is fired (violated), ⊥ should be added into IN and thus, 〈IN,OUT 〉 would not be a partial interpretation.\n1 The negation of blocked, not blocked, is different from unblocked.\nDefinition 6. Let P be a first order normal logic program. An ASPeRiX computation for P is a sequence 〈Ri, Ii〉∞i=0 of ground rule sets Ri and partial interpretations Ii = 〈INi, OUTi〉 that satisfies the following conditions:\n• R0 = ∅ and I0 = 〈∅, {⊥}〉,\n(Propagation) Ri = Ri−1 ∪ {ri} with ri ∈ ∆pro(P, Ii−1, Ri−1) and Ii = 〈INi−1 ∪ {head(ri)}, OUTi−1〉\nor (Rule choice) ∆pro(P, Ii−1, Ri−1) = ∅, Ri = Ri−1 ∪ {ri} with ri ∈ ∆cho(P, Ii−1, Ri−1) and Ii = 〈INi−1 ∪ {head(ri)}, OUTi−1 ∪ body−(ri)〉 or (Stability) Ri = Ri−1 and Ii = Ii−1,\n• (Convergence) ∃i ≥ 0, ∆cho(P, Ii, Ri) = ∅.\nThe computation is said to converge to the set IN∞ = ⋃∞ i=0 INi.\nExample 6. Let P6 be the following program:\n n(1). n(X + 1)← n(X), (X + 1) <= 2. a(X)← n(X), not b(X), not b(X + 1). b(X)← n(X), not a(X). c(X)← n(X), not b(X + 1).  The following sequence is an ASPeRiX computation for P6:\nI0 = 〈∅, {⊥}〉\nr1 = n(1). ∈ ∆pro(P6, I0, ∅) I1 = 〈{n(1)}, {⊥}〉\nr2 = n(2)← n(1). ∈ ∆pro(P6, I1, {r1}) I2 = 〈{n(1), n(2)}, {⊥}〉\n∆pro(P6, I2, {r1, r2}) = ∅ r3 = a(1)← n(1), not b(1), not b(2). ∈ ∆cho(P6, I2, {r1, r2}) I3 = 〈{n(1), n(2), a(1)}, {⊥, b(1), b(2)}〉\nr4 = c(1)← n(1), not b(2). ∈ ∆pro(P6, I3, {r1, r2, r3}) I4 = 〈{n(1), n(2), a(1), c(1)}, {⊥, b(1), b(2)}〉\n∆pro(P6, I4, {r1, r2, r3, r4}) = ∅ r5 = a(2)← n(2), not b(2), not b(3). ∈ ∆cho(P6, I4, {r1, r2, r3, r4}) I5 = 〈{n(1), n(2), a(1), c(1), a(2)}, {⊥, b(1), b(2), b(3)}〉\nr6 = c(2)← n(2), not b(3). ∈ ∆pro(P6, I5, {r1, r2, r3, r4, r5}) I6 = 〈{n(1), n(2), a(1), c(1), a(2), c(2)}, {⊥, b(1), b(2), b(3)}〉\n∆pro(P6, I6, {r1, r2, r3, r4, r5, r6}) = ∅ ∆cho(P6, I6, {r1, r2, r3, r4, r5, r6}) = ∅\nI7 = I6\nThe previous ASPeRiX computation converges to the set\n{n(1), n(2), a(1), c(1), a(2), c(2)} which is an answer set for P6.\nThe following theorem establishes a connection between the results of any ASPeRiX\ncomputation and the answer sets of a normal logic program.\nTheorem 2. Let P be a normal logic program and X be an atom set. Then, X is an answer set of P if and only if there is an ASPeRiX computation 〈Ri, Ii〉∞i=0, Ii = 〈INi, OUTi〉, for P such that IN∞ = X.\nLet us note that in order to respect the revision principle of an ASPeRiX computation each sequence of partial interpretations must be generated by using the propagation inference based on rules from ∆pro as long as possible before using the choice based on ∆cho in order to fire a nonmonotonic rule. Then, because of the non determinism of the selection of rules from ∆cho, the natural implementation of this approach leads to a usual search tree where, at each node, one has to decide whether or not to fire a rule chosen in ∆cho. Persistence of applicability of the nonmonotonic rule chosen to be fired is ensured by adding to OUT all ground atoms from its negative body. On the other branch, where the rule is not fired, the translation of its negative body into a new constraint ensures that it becomes impossible to find later an answer set in which this rule is not blocked.\nPropagation can be improved by using “must-be-true”2 atoms: atoms which have to be in the answer set to avoid a contradiction or, in other words, atoms already determined to be in IN but which are not yet be proved to be in.\nExample 7. Let (⊥ ← not b.) be a constraint whose body contains only one literal not b with b 6∈ IN ∪OUT . In order to have an answer set, b must be in IN so that the constraint is not applicable but b is not yet proved (it is not the head of a fired rule). Thus, one can only conclude that b must be true.\nMust-be-true atoms can be used during the propagation step in order to reduce\nthe search space.\nExample 8. Let (c ← a, b.) be a rule with a ∈ IN and b 6∈ IN but b has been determined to be a must-be-true atom. The rule may be fired during the propagation step but one can only conclude that the rule head c must be true (because b is not yet proved).\nMust-be-true atoms can also be used to reduce the size of ∆cho, the set of nom-\nmonotonic rules that can be chosen to be fired.\n2 The term “must be true” is first used in (Faber et al. 1999).\nExample 9. Let (c← a, not d.) be a rule with a ∈ IN and d 6∈ IN but d has been determined to be a must-be-true atom. The rule may already be considered to be blocked, even if d is not yet proved, and thus may be excluded from ∆cho.\nNote that must-be-true atoms are first used to improve propagation and choice but have to be proved later, otherwise the computation can not lead to an answer set.\nNotions of partial interpretation, rule status and ASPeRiX computation can be\nmodified in order to consider these new elements.\nDefinition 7. Let P be a logic program. A mbt partial interpretation for P is a triplet 〈IN,MBT,OUT 〉 of disjoint atom sets included in the Herbrand base of P .\nDefinition 8. Let r be a ground rule and I = 〈IN,MBT,OUT 〉 be a mbt partial interpretation.\n• r is supported w.r.t. I when body+(r) ⊆ IN , • r is weakly supported w.r.t. I when body+(r) ⊆ (IN ∪MBT ) • r is blocked w.r.t. I when body−(r) ∩ (IN ∪MBT ) 6= ∅, • r is unblocked w.r.t. I when body−(r) ⊆ OUT , • r is applicable w.r.t. I when r is supported and not blocked.\nPropagation is extended by Mbt-propagation: if some rule is weakly supported and unblocked w.r.t. mbt partial interpretation 〈IN,MBT,OUT 〉 (but is not supported, i.e., does not belong to ∆pro), then the head of the rule can be added in MBT set. And ∆cho, the set of rules that can be chosen, is restricted to the rules that are not blocked w.r.t. mbt partial interpretation.\nDefinition 9. Let P be a set of first order rules, I = 〈IN,MBT,OUT 〉 be a mbt partial interpretation and R be a set of ground rules.\n• ∆pro(P, I,R) = {r ∈ ground(P ) \\R | body+(r) ⊆ IN and body−(r) ⊆ OUT} • ∆pro mbt(P, I,R) = {r ∈ ground(P )\\R | body+(r) ⊆ IN ∪MBT, body+(r) 6⊆ IN and body−(r) ⊆ OUT} • ∆cho mbt(P, I,R) = {r ∈ ground(P ) \\ R | body+(r) ⊆ IN, and body−(r) ∩\n(IN ∪MBT ) = ∅}\nA mbt ASPeRiX computation is an ASPeRiX computation with this additional kind of propagation and with the possibility to block a rule from ∆cho mbt instead of firing it (“Rule exclusion”). To block a rule is to add a constraint with the negative literals of the rule body. If there is only one literal in the negative body, this constraint can be expressed by adding an atom in MBT set (see Example 7). These possibilities restrict rule choice in ∆cho mbt and thus forbid some computations: if a rule r is blocked, computation can only converge to an answer set whose generating rules do not contain r. Note that Convergence principle impose that, at the end of a computation, no constraint is applicable and each atom from MBT set has been proved (i.e., was moved from MBT to IN set).\nDefinition 10. Let P be a first order normal logic program. A mbt ASPeRiX computation for P is a sequence 〈Ki, Ri, Ii〉∞i=0 of ground rule sets Ki and Ri and mbt partial interpretations Ii = 〈INi,MBTi, OUTi〉 that satisfies the following conditions:\n• K0 = ∅, R0 = ∅ and I0 = 〈∅, ∅, {⊥}〉, • (Revision) ∀i ≥ 1,\n(Propagation) Ki = Ki−1, Ri = Ri−1 ∪ {ri} with ri ∈ ∆pro(P, Ii−1, Ri−1) and Ii = 〈INi−1 ∪ {head(ri)},MBTi−1 \\ {head(ri)}, OUTi−1〉\nor (Mbt-propagation) Ki = Ki−1, Ri = Ri−1,\nand Ii = 〈INi−1,MBTi−1 ∪ {head(ri)}, OUTi−1〉 with ri ∈ ∆pro mbt(P, Ii−1, Ri−1)\nor (Rule choice) ∆pro(P ∪Ki−1, Ii−1, Ri−1) = ∅, ∆pro mbt(P ∪Ki−1, Ii−1, Ri−1) = ∅, Ki = Ki−1,\nRi = Ri−1 ∪ {ri} with ri ∈ ∆cho mbt(P, Ii−1, Ri−1) and Ii = 〈INi−1 ∪{head(ri)},MBTi−1 \\ {head(ri)}, OUTi−1 ∪ body−(ri)〉\nor (Rule exclusion) ∆pro(P ∪Ki−1, Ii−1, Ri−1) = ∅, ∆pro mbt(P ∪Ki−1, Ii−1, Ri−1) = ∅,\nKi = Ki−1, Ri = Ri−1 and Ii = 〈INi−1,MBTi−1 ∪ body−(ri), OUTi−1〉 with ri ∈ ∆cho mbt(P, Ii−1, Ri−1) and |body−(ri)| = 1\nor Ki = Ki−1 ∪ {⊥ ← ∪b∈body−(ri)not b.}, Ri = Ri−1 and Ii = Ii−1 with ri ∈ ∆cho mbt(P, Ii−1, Ri−1) and |body−(ri)| > 1\nor (Stability) Ki = Ki−1, Ri = Ri−1 and Ii = Ii−1,\n• (Convergence) ∃i ≥ 0, ∆cho mbt(P ∪Ki, Ii, Ri) = ∅ and MBTi = ∅.\nMbt ASPeRiX computations characterize answer sets of a normal logic program.\nCompleteness and correctness are established by the following theorem.\nTheorem 3. Let P be a normal logic program and X be an atom set. Then, X is an answer set of P if and only if there is a mbt ASPeRiX computation 〈Ki, Ri, Ii〉∞i=0, Ii = 〈INi,MBTi, OUTi〉, for P such that IN∞ = X.\nNote that computations model only successfull branches of a search tree. On the other hand, must-be-true atoms and rules blocking enable to prune failed branches of the tree and to reduce non determinism of the search by restricting the possible choices for the oracle (because some rules are explicitly excluded, and others are blocked by must-be-true atoms). So, these new elements do not improve the number of steps of a computation but they improve the number of steps needed to find a computation when there is no oracle to guide the search and, then, they make easier the search of answer sets.\n3.2 ASPeRiX Main Algorithm\nNow, we are interested in the practical computation of an answer set. The ASPeRiX algorithm, following the principle of mbt ASPeRiX computation seen in section 3.1, is based on the construction of three disjoint atom sets IN , MBT and OUT during the search for an answer set. It alternates two steps. On the one hand, a propagation step which instantiates all supported and unblocked rules which may be built from IN , MBT and OUT and fires them, i.e. adds their head in IN (or MBT ). On the other hand, a choice step which forces or prohibits a nonmonotonic instantiated applicable rule to be fired during the next propagation step.\nIn order to treat the information more efficiently, the rules of a program P are ordered following the strongly connected components (SCC) of the dependency graph of P : the nodes of the dependency graph of a program P are its predicate symbols and the arcs are defined by {(p, q)|∃r ∈ P, p = pred(head(r)), q ∈ pred(body+(r) ∪ body−(r))}. The strongly connected components {C1, ..., Cn} are ordered in such a way that if i < j then no node (i.e. predicate symbol) of Ci depends of a node of Cj . A rule is said to belong to a SCC C if the predicate symbol of its head is in the component C. Note that constraints are not really concerned by ordering of rules but, for standardizing notations, constraints are considered to belong to a unique component whose number is greater than that of the last SCC, i.e., if Cn is the last SCC then constraints are considered to belong to Cn+1.\nExample 10. (Example 6 continued)\nThe strongly connected components (SCC) of the graph of the program P6 are\nC1 = {n}, C2 = {a, b} and C3 = {c} (Figure 2).\nThe ASPeRiX algorithm solves one by one the SCC {C1, ..., Cn} of a program P by starting by C1. When no propagation nor choice can no longer be done on the current SCC, the predicate symbols of the SCC are said to be solved and the SCC too. It means that nothing can be deduced anymore for those predicate symbols. The atoms which are instances of the predicate symbols of the current SCC and which are not in IN are implicitly added to OUT . Note that they are not explicitly added to OUT because ground instances of a predicate are not known (not computed): they could be infinite and, even if finite, to compute and store them is useless.\nRules of the program are instantiated on the fly during the propagation phase and the choice step. Hence the propositional program ground(P ) which contains all the instantiated rules of the program is never really computed. The propagation step\nand the choice step are realized in the ASPeRiX algorithm thanks to the functions γpro and γcho (which are selection functions in ∆pro ∪∆pro mbt and ∆cho mbt sets used in the mbt ASPeRiX computation of Subsection 3.1). The γpro function searches for a weakly supported unblocked rule amongst the current and next non-solved SCC. So propagation operates on several components: each rule is fired as soon as possible to quickly detect a possible conflict. Rules instantiated by γpro are stored in a set Subst = {subst(ri), ..., subst(rn)} during the answer set search to mark the substitution of rules that have already been used. For each first-order rule ri, subst(ri) denotes the set of all substitutions θ such that θ(ri) has already been fired.\nAnd subst rule(ri) = ⋃ θ∈subst(ri){θ(ri)} is the set of instantiated rules obtained thanks to substitutions subst(ri). The notation is extended to a set R of first-\norder rules: subst rule(R) = ⋃ ri∈R subst rule(ri). The γcho function chooses an applicable rule in the current SCC when nothing can no longer be propagated. So choice, unlike propagation, operates only on the current component. This strategy, consisting of solving the SCC one after another, makes it possible to solve efficiently stratified programs (or some stratified parts of programs).\nFunctions γpro and γcho are specified in more details in Subsection 3.3 and are\ndefined informally as follows:\n• γpro(P, S, S′, T, SCC, Subst): nondeterministic function which selects a rule (or a constraint) r belonging to a SCC greater or equal to the current SCC in\nthe dependency graph of a program P such that body+(r) ⊆ S∪S′, body−(r) ⊆ T and r ∈ ground(P )\\subst rule(P ) or returns NULL if no such a rule exists. • γcho(P, S, S′, T, SCC, Subst): nondeterministic function which selects a rule r belonging to the current SCC in the dependency graph of a program P such\nthat body+(r) ⊆ S, body−(r)∩(S∪S′) = ∅ and r ∈ ground(P )\\subst rule(P ) or returns NULL if no such a rule exists.\nThe function solve of Algorithm 1 specifies the algorithm of the search of one answer set for a program P . The set PK is the set of constraints (rules with the symbol ⊥ at their heads) of P and PR the other rules. By default, ⊥ is into the set OUT . Then, if a constraint is fired, a contradiction is immediately detected since ⊥ is added into the set IN and the sets IN and OUT are no longer disjoint. The algorithm of the function solve computes one answer set (or none if the program is incoherent) thanks to the variable stop which stops the search once an answer set has been found. This algorithm may be easily extended to compute an arbitrary number of answer sets. Let us note that, for sake of simplicity, the function solve will return either a set (when there is an answer set) or the constant no answer set if there is no answer set.\nThe main parts of the function solve are now described. Initially, IN = ∅, MBT = ∅, OUT = {⊥}, SCC is the index of the first SCC and Subst = ∅.\nThe propagation phase successively fires each weakly supported and unblocked instantiated rule r0. At each step, the call γpro(PR∪PK , IN,MBT,OUT, SCC, Subst) selects and instantiates a unique unblocked rule r0 such that body\n+(r0) ⊆ IN ∪ MBT (line 4). If such a rule exists, its head atom head(r0) must belong to the answer set. This head atom is added into the set IN (line 9) if the positive body\nAlgorithm 1: solve\n1 Function solve(PR, PK , IN, MBT, OUT, SCC, Subst); 2 // search of one answer set for a program P = PR ∪ PK 3 repeat //Propagation phase 4 r0 ← γpro(PR ∪ PK , IN,MBT,OUT, SCC, Subst); 5 if r0 6= NULL then 6 if (body+(r0) ∩MBT ) 6= ∅ then 7 MBT ←MBT ∪ {head(r0)}; 8 else\n9 IN ← IN ∪ {head(r0)}; 10 if (head(r0) ∈MBT ) then 11 MBT ←MBT\\{head(r0)};\n12 until r0 = NULL; 13 if ((IN ∪MBT ) ∩OUT 6= ∅) then //Contradiction detected 14 return no answer set;\n15 else 16 r0 ← γcho(PR, IN,MBT,OUT, SCC, Subst); 17 if r0 6= NULL then //Choice point 18 stop← solve(PR, PK , IN,MBT,OUT ∪ body−(r0), SCC, Subst); 19 if stop = no answer set then 20 atoms← {a|a ∈ body−(r0), pred(a) ∈ pred(SCC)}; 21 if (|atoms| = 1) then 22 MBT ←MBT ∪ atoms; 23 else 24 PK ← PK ∪ {⊥ ← ∪ai∈atoms not ai}; 25 stop← solve(PR, PK , IN,MBT,OUT, SCC, Subst); 26 return stop ;\n27 else// The SCC is solved 28 if pred(MBT ) ∩ pred(SCC) = ∅ then 29 if ¬last(SCC) then 30 return solve(PR, PK , IN,MBT,OUT, SCC + 1, Subst); 31 else 32 if γcheck(PK , IN,MBT,OUT, SCC) then // a constraint is\nviolated\n33 return no answer set;\n34 else// An answer set has been found 35 return IN ;\n36 else// a MBT atom can not be proved 37 return no answer set;\nof the rule is included in the set IN or added into the set MBT (line 7) otherwise since at least one atom a of the positive body of the rule has not yet proved its membership to the set IN (a ∈MBT but a /∈ IN). Moreover, a head atom which is added into IN must be deleted from MBT since a proof of its membership to the answer set has been found (line 10). When there is no more unblocked rule r0 such that body+(r0) ⊆ IN ∪MBT , (IN ∪MBT ) ∩ OUT = ∅ is checked in order to detect a contradiction (line 13). If no contradiction is detected, the algorithm begins the choice step.\nThe choice point forces or forbids a nonmonotonic applicable rule to be fired. The call γcho(PR, IN, MBT, OUT, SCC, Subst) selects and instantiates a unique applicable rule of PR whose head belongs to the current SCC (line 16). If such a rule exists, r0 is forced to be unblocked and then will be fired during the next propagation phase: its negative body is added to the OUT set and function solve is recursively called with its new parameters (line 18). If a recursive call to the function solve detects a contradiction, the algorithm backtracks on the last choice point on the rule r0 which has been forced to be fired and blocks it (lines 19-25): if a is the only atom of the negative body of r0 then a is added to the set MBT (line 22) else a constraint including all the atoms of the negative body of r0 is added to the program (line 24). More precisely, the only atoms of the negative body that are considered are those with a predicate symbol belonging to the current SCC because atoms from a lower SCC are already solved, i.e. they are in IN or OUT . When there is no more choice point, the current SCC is solved (line 27) but it must be checked that no atom of the MBT set has a predicate symbol in the current SCC (line 28). If such an atom exists, MBT and OUT sets are not disjoint. Indeed, if a SCC is solved, atoms which are instances of predicate symbols of the SCC and which are not in IN are implicitly added to OUT . Then if a MBT atom is an instance of a predicate symbol of the current SCC, a failure is observed and the backtrack process continues (line 36). If the last SCC is solved, the set IN represents an answer set of P if no constraint is applicable. This test is realized thanks to the nondeterministic function γcheck (line 32) which is specified in more details in Subsection 3.3 and is defined informally as follows:\nγcheck(P, S, S ′, T, SCC): function which checks if there is any constraint c such\nthat body+(c) ⊆ S, body−(c) ∩ S = ∅ and c ∈ ground(P ).\nExample 11. The execution of the ASPeRiX algorithm for program P6 of Example 6 is represented by a tree in Figure 3. At the beginning IN = ∅, MBT = ∅, OUT = {⊥} and the current SCC is the component C1 = {n}. After the first propagation, n(1) and n(2) are in IN thanks to the two rules (n(1).) and (n(2)← n(1), (1+1) <= 2.). No choice point exists and the first SCC is solved since the MBT set is empty. The component C2 = {a, b} becomes the current SCC. The first choice is realized on the current SCC (choice point CP1): the rule (a(1) ← n(1), not b(1), not b(2).) becomes unblocked by adding b(1) and b(2) into the set OUT (left branch after choice point CP1). A new propagation phase shows that a(1) and c(1) are in IN since (a(1) ← n(1), not b(1), not b(2).) and (c(1) ← n(1), not b(2).) can be fired. Then, a new choice is realized (choice point CP2) and\nthe rule (a(2)← n(2), not b(2), not b(3).) is forced to be unblocked (left branch after choice point CP2). The atom b(3) is added into the set OUT . A new propagation phase shows that a(2) and c(2) are in IN since (a(2) ← n(2), not b(2), not b(3).) and (c(2)← n(2), not b(3).) can be fired. The second SCC is solved since no other rule is applicable and the MBT set is still empty. In the same way, no propagation nor choice point is possible in the SCC C3 = {c}. Since no constraint is applicable, a first answer set is obtained: {a(1), a(2), c(1), c(2), n(1), n(2)}.\nIf another answer set is wished, the algorithm backtracks to the last choice point\nFig. 3. The tree-shaped execution of the answer sets of program P6.\non (a(2)← n(2), not b(2), not b(3).) of the component C2 and blocks the rule (right branch after choice point CP2) by adding a constraint (⊥ ← not b(2), not b(3).) into PK . A new choice is realized (choice point CP3) and the rule (b(2)← n(2), not a(2).) is forced to be unblocked (left branch after choice point CP3) by adding a(2) into the OUT set. During the propagation step, b(2) is added into the IN set since (b(2) ← n(2), not a(2).) is fired. The atom b(2) is then simultaneously in the sets IN and OUT which leads to a contradiction.\nThe algorithm backtracks to the choice point (b(2) ← n(2), not a(2).) of the component C2 (choice point CP3) and the rule is blocked by adding the atom a(2) into the MBT set (right branch after choice point CP3). Since there is no more possible choice and the MBT set contains an atom whose predicate symbol is in the current SCC, this atom cannot be proved and this leads to a failure. The algorithm backtracks to the first choice point on (a(1) ← n(1), not b(1), not b(2).) of the component C2 (choice point CP1) and blocks the rule and searches for a new possible answer set (right branch after choice point CP1). The process keeps going until the whole tree is computed when all the answer sets are required. Let us note that when dealing with the computation of one answer set like explained in the algorithm, only the first branch is considered."
    }, {
      "heading" : "3.3 Functions γ",
      "text" : "Functions γ have a crucial role in two important steps of the search of an answer set. The function γpro is called during the propagation step in order to choose the rules to fire and then to add their heads into IN (or MBT ). The function γcho is called during the choice step in order to force or to forbid a rule to be fired during the next propagation step. The function γcheck is called during the verification step in order to verify that no constraint is applicable. Since the principle of the solver ASPeRiX is to instantiate the rules on the fly during the search of an answer set, functions γ need to call a function instantiateRule which searches for a substitution for the atoms of a rule. This function is detailed in its own Subsection 3.4.\nFunction γpro. The function γpro searches for a rule to fire w.r.t. IN , MBT and OUT sets. This function computes a complete instantiation of a rule such that the positive body is in IN ∪MBT and the negative body is in OUT . The rule to instantiate is chosen amongst a set of rules R consisting of rules that could lead to new, unprocessed instances. These rules are those whose body contains some predicate symbol of what we call an atom to propagate. Atoms to propagate are atoms recently added into IN , MBT and OUT sets, and not yet used for propagation phase. Thereby, when an atom a is added into IN or MBT (resp. OUT ) set, the rules containing pred(a) in their positive body (resp. negative body) will be in the R set for the next call to γpro in order to propagate this atom, i.e. to use its presence in IN or MBT (resp. OUT ) for building new instances of rules to be fired. During the first call of the function solve, atoms to propagate are the facts of the program, and the set R contains all the rules which have some predicate symbols of the facts in their positive body. During a call after a choice\npoint, atoms to propagate are those added into OUT during this choice point, and the set R contains all the rules which have some predicate symbols of these atoms in their negative body. During a call after the access to the next SCC, the predicate symbols of the current SCC are solved and then all instances of these predicate symbols that are not in IN are implicitly added into OUT . Atoms to propagate are all these instances determined to be false, and then the set R contains all the rules which have in their negative body some of these solved predicate symbols.\nThe Algorithm 2 of the function γpro chooses a first-order rule r amongst the set R (the first one, line 5) and tries to find a weakly supported unblocked instantiation of the rule. It calls the function instantiateRule which returns this next instantiation if any (line 6). If there is no more weakly supported unblocked instantiated rule which may be extracted from r (line 7), γpro deletes from R the rule r and treats the next rule. This process is repeated until a weakly supported unblocked rule is found or there is no more rule in R. When a rule allows a substitution (line 10), the latter is stored in Subst in order to find some others at the next call to γpro.\nAlgorithm 2: γpro\n1 Function γpro(P, IN,MBT,OUT, SCC, Subst); 2 R← Set of rules (including constraints) containing predicate symbols to propagate; 3 if R 6= ∅ then 4 repeat 5 r ← first(R); /* Searching for an instantiation of the rule r with body+(r) ⊆ IN ∪MBT and body−(r) ⊆ OUT */ 6 θ ← instantiateRule(r, γpro, IN,MBT,OUT, subst(r)); 7 if θ = NULL then 8 R← R\\{r};"
    }, {
      "heading" : "9 until θ 6= NULL or R = ∅;",
      "text" : "10 if θ 6= NULL then\n/* An unblocked weakly supported instantiated rule is found\n*/\n11 subst(r)← subst(r) ∪ {θ}; 12 return θ(r);\n13 else 14 return NULL;\n15 else 16 return NULL;\nExample 12. Example 11 is taken again. An answer set is searched after the choice point on the rule (a(1) ← n(1), not b(1), not b(2).) (choice point CP1): the atoms b(1) and b(2) are added into the set OUT in order to force the rule to be fired\n(left branch after choice point CP1). During the propagation step, many calls to the function γpro are executed. During the first call the set R consists of all the rules containing in their negative body the predicate symbol b of the atoms b(1) and b(2) that must be propagated. This set R then contains the rules (a(X) ← n(X), not b(X), not b(X + 1).) and (c(X) ← n(X), not b(X + 1).) Arbitrarily, the rule (a(X)← n(X), not b(X), not b(X+1).) of the set R is chosen and a supported unblocked instantiation (a(1) ← n(1), not b(1), not b(2).) is found. The function γpro returns the instantiation of the rule and the solve function adds a(1) into IN . During the next call to γpro, the set R must contain, in addition to the previous rules, any rule containing in its positive body the predicate symbol a of the atom to be propagated a(1) (since a(1) has been added into IN). Since no rule respects this condition, the set R still contains only the two previously added rules. The function γpro searches for a new weakly supported unblocked instantiation of the rule (a(X) ← n(X), not b(X), not b(X + 1).). No such instantiation is found and the rule is deleted from the set R. The function γpro searches for a new weakly supported unblocked instantiation of the rule (c(X) ← n(X), not b(X + 1).). The instantiation (c(1) ← n(1), not b(2).) is then returned to the solve function which adds c(1) into IN . Then during the next call to the function γpro, the set R must be updated with the rules containing in their positive body the predicate symbol c of the atom to propagate c(1). As previously, no rule respects this condition and the set R still contains the only rule (c(X)← n(X), not b(X + 1).). A new weakly supported unblocked instantiation is sought but this rule leads to a failure. The rule (c(X) ← n(X), not b(X + 1).) is then deleted from the set R which becomes empty. Then the function γpro returns the value NULL and the propagation step of the function solve stops.\nFunction γcho. The function γcho is executed when no rule can be fired anymore and there is some SCC to be solved. This function searches an applicable instantiated rule belonging to the current SCC. The Algorithm 3 of function γcho is similar to the algorithm of the function γpro. The function γcho searches for an applicable instantiated rule amongst a set R of rules which have in their negative body at least one predicate symbol from the current SCC (otherwise, if all predicate symbols from negative body belong to previous SCC, they are already solved and then the rule can be considered as a monotonic one and is only used for propagation). The function γcho chooses a rule in this set R before calling the function instantiateRule searching for the next applicable instantiation for the considered rule. In a similar way as the function γpro, the process is repeated until an applicable instantiated rule is found for a rule of R or there is no more rule in R.\nExample 13. Example 12 is taken again. After the first SCC has been solved, a first choice is realized on the current SCC, C2 = {a, b}, by the function γcho. The rules of this component which contains in their negative body at least one predicate symbol a or b of C2 are added into the set R of the rules that may be chosen. Then, the rules (a(X) ← n(X), not b(X), not b(X + 1).) and (b(X) ← n(X), not a(X).) are in R. Arbitrarily, the function γcho searches for an applicable instantiation of the first rule\nAlgorithm 3: γcho\n1 Function γcho(P, IN,MBT,OUT, SCC, Subst); 2 R← Set of rule belonging to the current SCC such that the negative body contains at least a predicate symbol not solved; 3 if R 6= ∅ then 4 repeat 5 r ← first(R); /* Searching for an instantiation of the rule r with body+(r) ⊆ IN and body−(r) ∩ (IN ∪MBT ) = ∅ */ 6 θ ← instantiateRule(r, γcho, IN,MBT,OUT, subst(r)); 7 if θ = NULL then 8 R← R\\{r};"
    }, {
      "heading" : "9 until θ 6= NULL or R = ∅;",
      "text" : "10 if θ 6= NULL then\n/* An applicable instantiated rule is found */\n11 subst(r)← subst(r) ∪ {θ}; 12 return θ(r);\n13 else 14 return NULL;\n15 else 16 return NULL;\nof this set and a choice point on (a(1)← n(1), not b(1), not b(2).) is returned to the calling function solve (choice point CP1). After the propagation step, γcho searches for a new applicable instantiation of the rule (a(X)← n(X), not b(X), not b(X+1).) and a choice point on (a(2) ← n(2), not b(2), not b(3).) is returned to the calling function solve (choice point CP2). After a new propagation step, γcho searches in vain a new applicable instantiation of the rule (a(X)← n(X), not b(X), not b(X + 1).) This last rule is then deleted from the set R and γcho searches for an applicable instantiation of the rule (b(X)← n(X), not a(X).) which leads to a failure. The set R is now empty and the function γcho returns NULL to the calling function solve to mean that no other choice may be realized on the current SCC.\nFunction γcheck. The function γcheck is executed when no more choice point is possible for the last SCC. This function verifies that no constraint containing at least one predicate symbol of the last SCC is applicable in order to determine if the set IN is an answer set. The Algorithm 4 of the function γcheck is similar to the algorithm of the function γcho. The function γcheck searches for an applicable instantiated constraint amongst a set C of constraints whose negative body contains at least a not-solved predicate symbol of the last SCC. The function γcheck chooses a constraint in the set C and calls the function instantiateRule which searches for an applicable instantiated constraint. If no instantiated constraint is applicable,\nthe algorithm returns false and the set IN is an answer set of the program. If a constraint is applicable, the algorithm returns true which means there is a failure on the branch (the search of answer sets keeps going on other branches if any).\nAlgorithm 4: Function γcheck\n1 Function γcheck(P, IN,MBT,OUT, SCC); 2 C ← Set of constraints such that the negative body contains at least a predicate symbol not solved; 3 if C 6= ∅ then 4 repeat 5 c← first(C); /* Searching for an instantiation of the constraint c such that body+(c) ⊆ IN and body−(c) ∩ IN = ∅ */ 6 θ ← instantiateRule(c, γcheck, IN,MBT,OUT, ∅); 7 if θ = NULL then 8 C ← C\\{c};"
    }, {
      "heading" : "9 until θ 6= NULL or C = ∅;",
      "text" : "10 if θ 6= NULL then\n/* An applicable instantiated constraint is found */\n11 return true;\n12 else 13 return false;\n14 else 15 return false;"
    }, {
      "heading" : "3.4 Rule Instantiation",
      "text" : "In this section is described the process of instantiation of a rule. This process is a lazy one only called when needed. Since we only consider safe rules, the instantiation of a rule is in fact the instantiation of its positive body. In a forward chaining approach, the only rule instantiations of interest are those that lead to a not blocked supported rule or an unblocked weakly supported rule. Hence, the rule instantiation is mainly directed by the instantiated atoms already present in the sets IN and MBT .\nThe algorithm used in the ASPeRiX solver and described below is inspired by the previous work realized on the DLV grounder (Faber et al. 2012; Perri et al. 2007) which is based on the semi-naive evaluation technique of (Ullman 1989). The goal is to find a substitution for all the literals of the body of a rule r thanks to the atoms already in IN , MBT or OUT . To do this, a partial substitution θ is built as possible values are found for the variables of the literals of the body of the rule r. It is assumed that the literals l1, l2, . . . , ln of the body of the rule r are ordered following a list [l1, l2, . . . , ln]: firstLiteral(r) (resp. lastLiteral(r)) corresponds to l1 (resp.\nln) and previousLiteral(r) (resp. nextLiteral(r)) corresponds to the literal which precedes (resp. follows) the literal under consideration in the list. The substitution calculus for a literal l of a rule r is realized thanks to the functions firstMatch and nextMatch. These functions look for a substitution which has not already been computed, i.e. not leading to a substitution for r present in the set subst(r) of all substitutions θ such that θ(r) has already been fired. If the literal l is positive, a substitution such that the substituted atom is in the set IN (or IN ∪MBT ) is searched. If the literal is negative, (a) a substitution such that the substituted corresponding atom is in the set OUT is searched if the goal is an unblocked rule or (b) the non membership of the substituted atom to the set IN ∪MBT is checked if the goal is a not blocked rule3.\nIn the functions firstMatch and nextMatch which follow, the parameter γ shows\nif an unblocked weakly supported or not blocked supported rule is looked for.\n• firstMatch(l, θ, γ, IN,MBT,OUT, subst) is a function which searches for the first possible substitution for a literal l w.r.t. the sets IN , MBT and\nOUT , selection criterion γ (unblocked weakly supported or applicable rule) and the current partial substitution θ. firstMatch returns true and updates the partial substitution θ in case of success. Otherwise, the function returns false. • nextMatch(l, θ, γ, IN,MBT,OUT, subst) is a function which searches for the next possible substitution for literal l given the already realized substitutions.\nFor a rule r, a free variable of a literal l is an occurrence of a variableX such that it is its first occurrence in the body of r when starting traversing the literal l. In other words, no other literal which precedes l in the body of r contains an occurrence of the variable X. During the instantiation of a rule, a possible substitution is sought for all the free variables of every traversed literal and the substitutions of the previously calculated variables are kept. If a literal has no free variable, the validity of the substitution w.r.t. the selection criterion γ is checked (i.e. the substituted corresponding atom θ(at(l)) is in IN or IN ∪MBT if l ∈ body+(r) and θ(at(l)) is in OUT or θ(at(l)) is not in IN if l ∈ body−(r)).\nExample 14. Let (a(X,Y, Z)← b(X,Y ), c(X,Y ), d(X,Z).) be a rule. The ordered list of the body of the rule is [l1 = b(X,Y ), l2 = c(X,Y ), l3 = d(X,Z)] with:\n• freeV ariables(l1) = {X,Y } • freeV ariables(l2) = ∅ • freeV ariables(l3) = {Z}.\nFunction instantiateRule of Algorithm 5 specifies the instantiation principles of a rule for constant sets IN , MBT and OUT . This function is initialized with the partial substitution θ which is the last found substitution (thanks to the function lastSubstitution) for the rule r if any (line 2). If it is the first attempt for the instantiation of this rule, θ is empty (line 3) and the function searches a first substitution\n3 In this case, the body of the rule is ordered in such a way that negative literals appear after the positive literals containing their variables.\nAlgorithm 5: instantiateRule\n1 Function instantiateRule(r, γ, IN, MBT, OUT, subst); 2 θ ← lastSubstitution(r); 3 if θ = ∅ then\n/* Searching for the first possible substitution of first\nliteral */\n4 l← firstLiteral(r); 5 matchFound← firstMatch(l, θ, γ, IN,MBT,OUT, subst);"
    }, {
      "heading" : "6 else",
      "text" : "/* Searching for the next possible substitution of last\nliteral */\n7 l← lastLiteral(r); 8 θ ← θ\\freeV ariableSubstitutions(l); 9 matchFound← nextMatch(l, θ, γ, IN,MBT,OUT, subst);\n10 while true do 11 if matchFound then 12 if l 6= lastLiteral(r) then 13 l← nextLiteral(r); 14 matchfound← firstMatch(l, θ, γ, IN,MBT,OUT, subst) 15 else\n/* A complete substitution is found */\n16 return θ;\n17 else\n/* No substitution for literal l. Bactrack to previous\nliteral (if any) to find its next possible substitution */\n18 if l 6= firstLiteral(r) then 19 l← previousLiteral(r); 20 θ ← θ\\freeV ariableSubstitutions(l); 21 matchFound← nextMatch(l, θ, γ, IN,MBT,OUT, subst); 22 else 23 return NULL;\nfor the first literal of the body of the rule r using the function firstMatch. Otherwise, a substitution for r has already been computed (line 6), the function searches a new possible substitution for the rule. For this, the function searches the next possible instance of the last literal of the rule r by deleting from θ the substitutions of the free variables of this literal (thanks to the function freeV ariableSubstitutions) and by calling the function nextMatch. During the execution of the main loop, the function first checks if a substitution has been found for the current literal a (line 11). If it is the case, it searches a first substitution for the next literal of the rule body respecting the partial substitution θ. When all the atoms have been considered,\na complete substitution is found (line 15). The function returns this substitution. When the instantiation of a literal fails (i.e. there is no possible substitution for it), the function backtracks on the previous literal (line 18) and updates θ by deleting the substitutions of the free variables of this literal. Hence the function calls the function nextMatch which searches the next possible instantiation for this literal. The instantiation of a rule r fails when no more substitution is possible for the first literal (line 23).\nActually, the instantiation algorithm of a rule is slightly more complicated than the Algorithm 5 since the atoms dynamically added into IN , MBT and OUT sets during the answer set computation, called atoms to propagate, have to be taken into account: if possible, each substitution has to be computed once and only once. Hence ASPeRiX uses a queue called propagate IN (resp. propagate MBT and propagate OUT ) which contains the atoms to be added into the set IN (resp. MBT and OUT ). When all the instances of a rule r, for given sets IN0, MBT0 and OUT0, have been generated, an atom to propagate ap whose predicate symbol p appears in the body of the rule r is extracted. Now I1 = 〈IN1,MBT1OUT1〉 denotes the mbt partial interpretation obtained by adding ap into I0 = 〈IN0,MBT0, OUT0〉. The body of the rule is ordered in such a way that the first literals are those whose predicate symbol is the one of the atom to propagate ap (they are the literals that might unify with ap). Then these literals whose predicate symbol is p are successively marked and placed at the beginning of the rule. The marked literal might only take the value of the atom to propagate ap whereas the following (non marked) literals might take any values in I1. Then, if the instantiation of the first literal fails, it is unmarked, the next literal of predicate p becomes the first literal of the rule body and is marked in turn, and the instantiation of the rule is started again. The unmarked literals might then take any values in I0 (which excludes the values of ap already used) while the marked literal can only take the value of the atom to propagate, and the non marked literals always take their values in I1. If the instantiation of the first literal fails and there is no other literal to be marked, the instantiation of the rule fails.\nExample 15. Let r0 be a rule and IN0, propagate IN and IN1 be sets of atoms defined as follow:\nr0 = a(X + Y )← a(X), b(X,Y ), a(Y ). IN0 = {b(1, 1), b(1, 2)} propagate IN = {a(1)} IN1 = {b(1, 1), b(1, 2), a(1)}\nThe atom a(1) has to be propagated by instantiating the rule r0. Table 1 shows the different steps of the instantiation. The literals to be marked (whose predicate symbol is a) of the body of the rule are a(X) and a(Y ). These literals are placed at the beginning of the body of r0 like this: [l1 = a(X), l2 = a(Y ), l3 = b(X,Y )]. In Table 1, for clarity, the sequence of literals of the rule body is not changed when the marked literal changes. But the marked literal (shown in bold) is processed first, which is the same. The first attempt for an instantiation begins and for the first time with atom to propagate a(1). The literal l1 = a(X) is then marked and takes\nas unique value that of the atom to propagate a(1) ((1.1) Table 1). Hence, value 1 is substituted to the variable X in θ. Then, the following literal in the body of the rule, l2 = a(Y ), becomes the current literal and takes as value the first amongst those into IN1 which is also a(1). Hence, value 1 is substituted to the variable Y in θ ((1.2) Table 1). Then the last literal, l3 = b(X,Y ), is reached. This literal has no free variable and the membership into IN1 is simply checked for b(1, 1) which is obtained from b(X,Y ) by substituting X and Y by the values in θ ((1.3) Table 1). There is no more literal to consider then a complete substitution has been found. The atom of the head a(X + Y ) takes the values of the substitution θ. Hence, the forward chaining algorithm can add a(2) into the propagate IN queue.\nNow, during a new instantiation attempt of the rule for the atom to propagate a(1), the function restarts with the last substitution of the rule θ = {X/1, Y/1} in order to find a new substitution for the literal l3 = b(X,Y ). The second attempt for an instantiation begins with atom to propagate a(1) for the second time. Since b(X,Y ) has no free variable, there can be no other substitution than the current one ((2.1) Table 1). The process then backtracks to the literal l2 = a(Y ) which has no other substitution in IN1 (a(2) has been inferred after a(1) and is not into the current set IN1) ((2.2) Table 1). Since literal l1 = a(X) can only take the value a(1), it also fails ((2.3) Table 1). Since the last literal has failed, the literal l2 = a(Y ) is now marked instead of a(X), and is instantiated with the atom to propagate a(1). Hence, value 1 is substituted to the variable Y in θ ((2.4) Table 1). Literal l1 = a(X) is unmarked and can only take the values of the atoms of IN0, thus no substitution is possible. Hence the algorithm fails on the first literal ((2.5) Table 1). Since there is no more literal to be marked, the rule instantiation ends by a failure for the atom to propagate a(1). The sets becomes as follow:\nIN0 = {b(1, 1), b(1, 2), a(1)} propagate IN = {a(2)} IN1 = {b(1, 1), b(1, 2), a(1), a(2)}\nThe next atom a(2) is extracted from the queue to propagate. The third attempt for an instantiation of r0 begins with atom to propagate a(2) for the first time. Table 2 shows the different steps of the instantiation. The literals a(X) and a(Y )\nare again to be marked. The rule instantiation is restarted with the literal l1 = a(X) which is the marked literal. The variable X is substituted by the value 2 since the only allowed value is that of the atom to propagate a(2) ((1.1) Table 2). The current literal is now l2 = a(Y ) where Y is substituted by the value 1 since a(1) is into IN1 ((1.2) Table 2). The literal b(X,Y ) has no free variable and since the atom b(2, 1) which respects the substitution θ = {X/2, Y/1} is not in IN1, the literal b(X,Y ) has no possible substitution ((1.3) Table 2). Then a new instantiation for l2 = a(Y ) is sought: its next possible value is 2 (since a(2) is in IN1) ((1.4) Table 2). Again, since the atom b(2, 2) which respects the substitution θ = {X/2, Y/2} is not in IN1, the literal b(X,Y ) has no possible substitution ((1.5) Table 2). The process backtracks to the literal l2 = a(Y ) which has no possible value ((1.6) Table 2). Hence, the process backtracks to the literal l1 = a(X) which has no possible value since the only possible value was that of the atom to propagate a(2) ((1.7) Table 2). Since the first literal has failed, the process restarts by marking the second literal a(Y ) (and unmarking the first a(X)). The marked literal l2 = a(Y ) is processed first, it substitutes Y by the value 2 of the atom to propagate a(2) ((1.8) Table 2). The unmarked literal l1 = a(X) may only take its values into IN0. The variable X is then substituted by the value 1 ((1.9) Table 2). The literal l3 = b(X,Y ) has no free variable and since b(1, 2) which respects the substitution θ = {X/1, Y/2} is in IN1 a complete substitution is found ((1.10) Table 2). The atom a(X + Y ) of the head takes then the value of the substitution θ. Hence, the forward chaining algorithm can add a(3) into IN1 and into propagate IN .\nThen, during a new instantiation attempt of the rule r0, the atom to propagate is still a(2). The process restarts from the last substitution θ = {X/1, Y/2} and search for a new substitution for the literal l3 = b(X,Y ). A fourth attempt for an instantiation begins with atom to propagate a(2) for the second time. Since b(X,Y ) has no free variable, there can be no other substitution than the current one ((2.1) Table 2). The process then backtracks to the literal l1 = a(X) that has no other\nsubstitution since the only possible values are those from IN0 (then neither the atom to propagate a(2) nor a(3) appeared after a(2) are possible) ((2.2) Table 2). The literal l2 = a(Y ) also fails since the marked literal only accepts the value of the atom to propagate a(2) ((2.3) Table 2). Since there is no more literal to be marked, the instantiation of the failing rule ends for this atom to propagate. The process continues with the atom a(3) which also leads to a failure.\n3.5 ASPeRiX language\nThe core language of ASPeRiX is that of normal logic programs (Gelfond and Lifschitz 1988) with function symbols and true (or strong) negation without inconsistent answer set. ASPeRiX also provides dedicated treatment of lists with built-in predicates, as in DLV-complex (Calimeri et al. 2008), an extension of DLV with lists and sets. On the other side, ASPeRiX does not provide aggregate atoms and optimization statements (Buccafurri et al. 2000) which are accepted by the main current systems.\nOne of the important issues in ASP is the treatment of function symbols. Uninterpreted function symbols are important because they enable representation of recursive structures such as lists and trees. But reasoning becomes undecidable if no restriction is enforced. A lot of work has been made for identifying program classes for which reasoning is decidable (Alviano et al. 2011; Alviano et al. 2010; Calimeri et al. 2011; Lierler and Lifschitz 2009; Baselice and Bonatti 2010; Greco et al. 2013).\nThe inherent difficulty with functions in general (and arithmetic in particular) in the framework of ASP is that it makes the Herbrand universe infinite in whole generality. ASP grounders Lparse (Syrjänen 1998) and versions up to 3.0 of Gringo (Gebser et al. 2007) accept programs respecting some syntactic domain restrictions and are able to deal with some restricted versions of functions.\nDLV grounder (Faber et al. 2012) and Gringo (since version 3.0) (Gebser et al. 2011) only require programs to be safe and can deal with all programs having a finite instantiation. DLV guarantees finite instantiation for finitely ground programs but membership in this class is not decidable. It integrates a Finite Checker module which can check if a program belongs to a sub-class of finitely ground programs (argument-restricted programs). For programs that are not member of this subclass, answer sets can be computed without preliminary check but ending is not guaranteed.\nASPeRiX can deal with these programs and with some other programs whose instantiation is infinite but whose answer sets are finite. For example, the program P1a from Section 1 is not finitely ground: intelligent instantiation of the program must be finite to be finitely ground. The key points of intelligent instantiation are that rules are instantiated with atoms appearing in head of rules of the program, and simplifications are performed relatively to facts and rule heads of preceding components of the dependency graph. In example P1a, choice between a and b makes both possible for the grounder, and constraint has no effect on intelligent instantiation of the program. Thus, the grounding of rules from P1a will be the same with or with-\nout the constraint (← a.): infinite in both cases. ASPeRiX halts on P1a and is thus able to halt on non finitely ground programs but it is not able to verify in advance if answer sets are finite or not, and thus if computation will end or not. Nevertheless, ending can be guaranteed by means of command-line options specifying the maximum allowed nesting level for functional terms and the biggest admissible integer (DLV grounder provides similar possibilities). These restrictions ensure that our computations always converge to an answer set if it exists. Formalizing the class of programs for which ASPeRiX halts will be the subject of a forthcoming work."
    }, {
      "heading" : "4 Experimental results",
      "text" : "Following Algorithm 1 of Section 3.2, the solver called ASPeRiX has been implemented in C++ and is available at http://www.info.univ-angers.fr/pub/ claire/asperix.\nThere are two other ASP systems, GASP (Dal Palù et al. 2009) and OMiGA (DaoTran et al. 2012), that realize the grounding of the program during the search of an answer set.\nGASP is an implementation in Prolog and Constraint Logic Programming over finite domains of the notion of computation (see Section 3.1). The main ideas are the same as those of ASPeRiX. Notable differences are the following. Well founded consequences of the program are computed first. Then propagation is close to ours. GASP does not deal with must-be-true atoms but two special cases of propagation, not treated by ASPeRiX, are implemented: (a) if the head of a rule is known to be in OUT set and the body of the rule is satisfied except for one positive literal, then this literal must be false (added to OUT) and (b) if, for some undefined atom a, there is no applicable rule whose head is a, then a can be added to OUT. For each rule, instantiation and propagation are realized by building and solving a CSP that determines atoms derivable from the rule. Representation of interpretations uses Finite Domain Sets, such a data structure is efficient to represent compactly intervals but it need to code tuples (instances of predicates) by integers (very big integers if domain is large and arity of predicate too). This representation impose the set of ground terms of the program to be finite and thus function symbols are excluded. On the other hand, GASP supports some cardinality constraints. To our knowledge, GASP remained at the prototype stage and is no longer developed.\nOMiGA is implemented in Java. Functional symbols (of non-zero arity) are not supported. Principles of propagation and choice are the same as those of ASPeRiX but implementation uses Rete algorithm for improving the speed of propagation. First order rules are represented by a Rete network. Each node represents a literal (or a set of literals) from the body of a rule or the atom of the head of a rule. It stores all instances of the node that are true w.r.t. current partial interpretation. Thereby all partial instantiations of rules are stored in the network. This lead to an efficient propagation regarding computation time, but memory space is sacrified. Dependency graph and solved predicates seems to be treated in a similar manner to that of ASPeRiX. Current version (Weinzierl 2013) uses must-be-true propagation and tries to introduce methods for conflict-driven learning of non-ground rules:\nwhen a constraint is violated, a new constraint is built by unfolding of rules whose firing contributes to the conflict. This learned constraint is then transformed into special rules so as to be used for propagation.\nIn the following we give some results of evaluation of ASPeRiX 0.2.5 highlighting its adequacy to some particular problems. It is compared with Clingo (composed by Gringo 3.0.5 and Clasp 1.3.10) (Gebser et al. 2011; Gebser et al. 2012), DLV Dec 16 2012 (Leone et al. 2006), GASP (june 2009) (Dal Palù et al. 2009) and OMiGA Dec 3 2012 (Dao-Tran et al. 2012). Version without learning is used for OMiGA because learning lowers its performances. All the systems have been run on an Intel Core i7-3520M PC with 4 cores at 2.90GHz and about 4GB RAM, running Linux Ubuntu 12.04 64 bits. For each instance of a problem, the memory usage is limited to 3.000MB and computation time to 600 seconds. RunLim1.7 is used for these limitations tasks. Tables of results use OoM (resp. OoT ) to indicate Out of Memory (resp. Out of Time). Results for GASP are only given for the first two examples, because it does not accept other tested programs.\nSchur problem The Schur number problem is to partition N numbers into M sets such that all of the sets satisfy: if x and y are assigned to the same set, then x+ y is not in the set. The following program (Dal Palù et al. 2009) is for M = 3 sets and N = 4 numbers.\nPSchur−4 =  number(1)., number(2)., number(3)., number(4)., part(1)., part(2)., part(3)., inpart(X, 1)← not inpart(X, 2), not inpart(X, 3), number(X)., inpart(X, 2)← not inpart(X, 1), not inpart(X, 3), number(X)., inpart(X, 3)← not inpart(X, 1), not inpart(X, 2), number(X)., ← number(X), number(Y ), part(P ), inpart(X,P ), inpart(Y, P ), inpart(Z,P ),\nT = Y + 1, X < T, Z = X + Y.  The results are shown in Table 3 for M = 3. AS reports the number of answer\nsets which are all computed. For all N ≥ 14, Schur-N has no answer set. The program is a typical “guess and check” program. The seach space is expressed by the three rules with inpart as head predicate, and constraint eliminates “bad choices”. The grounding of the program is rather small but the search space is large. The problem is very easy for Clingo and DLV but very hard for ASPeRiX and GASP. Systems using grounding on the fly have to repeat instantiation of the same rules in each branch of the search tree. Moreover, constraints are not efficiently managed by systems like ASPeRiX: it does not use constraints for propagation but only checks if a constraint is violated. Compared to ASPeRiX, OMiGA performs well for computation time, certainly because Rete network improve speed of instantiation (partial instantiations are stored in the network) and the network remains relatively small in such an example. This example illustrates a large class of programs that ASPeRiX mismanage: programs with many choices and little propagation by forward chaining.\nConversely, the following examples illustrate problems for which grounding on\nthe fly is well adapted.\nBirds problem Problem birds is a stratified program encoding a taxonomy about flying and non flying birds. b stands for bird, f for flying, nf for nonflying, p for penguin, sp for superpenguin, and o for ostrich.\nPbirds =  p(X)← sp(X)., b(X)← p(X)., b(X)← o(X)., f(X)← b(X), not p(X), not o(X)., f(X)← sp(X)., nf(X)← p(X), not sp(X)., nf(X)← o(X). \nWe add to this program the atoms encoding N birds with 10% of ostriches, 20%\nof penguins whose half of them are super penguins.\nThe unique answer set of such a program can be computed polynomially. ASPeRiX uses only propagation step, without choice point, and grounders completely evaluate the program so that the solver has nothing to do. Experimental results for birds are comparable for ASPeRiX, Clingo, GASP and DLV. ASPeRiX has the best results for CPU time, and DLV for memory usage (Figure 4 and 5). For such a problem, the number of instantiated rules must be nearly the same for all systems. On the other side, OMiGA system uses a very large amount of memory space, certainly due to the Rete network which is designed to sacrifice memory for increased speed. Unfortunately, memory gains expected by the first order approach are lost.\nCutedge problem cutedge program is proposed in (Dao-Tran et al. 2012): given a random graph with 100 vertices and N edges, each answer set is obtained by deleting an edge and compute some transitive closure on the remaining edges.\nPcutedge =  delete(X,Y )← edge(X,Y ), not keep(X,Y )., keep(X,Y )← edge(X,Y ), delete(X1, Y 1), X1! = X., keep(X,Y )← edge(X,Y ), delete(X1, Y 1), Y 1! = Y., reachable(X,Y )← keep(X,Y )., reachable(X, 98)← reachable(X,Z), reachable(Z, 98).  Computing each answer set is only based on propagation, and the number of answer sets equals the number of edges. The number of rules needed to compute all answer sets is proportional to N2 while the rule number needed to compute\none is proportional to N . But systems with pregrounding phase must generate all ground instances of rules even if only one answer set is required. The results are shown in Table 4. ASPeRiX has the best results for this program both for CPU time and memory usage. OMiGA and Clingo use much more memory and are much slower than ASPeRiX. As expected, memory usage of Clingo is independent of the number of answer sets required and is close to the square of that used by ASPeRiX. For its part, DLV quickly exceeds the time limit imposed.\nHamiltonian cycle problem The program P3 (see Example 3), Hamiltonian cycle in a complete graph, is another easy problem with a lot of answer sets. Each answer set is easy to compute but the whole instantiation is huge. Experiments for the computation of one answer set in a graph with N vertices are represented in Figures 6 and 7. ASPeRiX performs well on this example whereas OMiGA has time and memory problems similar to that of Clingo and DLV. One more time, a simple problem becomes intractable by systems with pregrounding phase because they drown it in a lot of useless information so that memory used quickly becomes prohibitive.\nHanoi problem Hanoi example illustrates a planning problem where the maximum number of allowed steps is given as input. NbD is the number of disks in the problem and NbM is the maximum number of moves that are allowed to move all disks from the first rod to the third. The least value of NbM is the minimum required to achieve the goal, then its value is gradually increased to evaluate its impact. The complete program is given in Appendix A and experimental results\nare shown in Table 5. ASPeRiX performances are (almost) independent of the given number of moves: search, and therefore grounding, are stopped when a solution is found. Conversely, grounders are quickly overwhelmed as they are obliged to fully instantiate the program with all hypothetical (and unnecessary in this case) calculation steps4. This example cannot be computed by OMiGA due to restrictions on the input language it accepts (function symbols are not supported).\nThree coloring problem The program P2 (see Example 2), 3-coloring problem on a graph organized as a bicycle wheel, poses no problem for Clingo and DLV (cf. Table 6). But ASPeRiX and OMiGA have bad results on this example because they are mismanaging constraints. Once a vertex is colored, say red, constraint (← e(V,U), col(V,C), col(U,C).) prohibits coloring adjacent vertices of the same color. In propositional systems, unit propagation (or equivalent) works well and allows to infer that adjacent vertices are not colored red. But first-order approach does not allow, in general case, to use unit propagation and thus, constraints are mainly used for verification and not for propagation. A lot of work remains on these points. First-order constraints could instead allow more powerful propagation. Suppose for example a constraint (← p(X,Y ), p(Y,Z).) and p(1, 2) is added in IN set then, for all Z, p(2, Z) can be excluded at once from current solution, even if Z values are potentially infinite. But these opportunities are not exploited yet.\nTo sum up, ASPeRiX is efficient to deal with stratified programs or simple prob-\n4 iClingo (Gebser et al. 2008) was created to address this specific problem. Some directives are added to the program in order to incrementally instantiate some predicates of the program. But\nlems whose instantiation is infinite or huge but much of which is useless to compute one specific answer set. On the other hand, the system is not competitive for more combinatorial problems, with a large search space and few solutions, because propositional methods for propagation, heuristics, learning lemmas did not apply to the first order case."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we have presented the ASPeRiX approach to answer set computation. Our methodology deals with first order rules following a forward chaining with grounding process realized on the fly and has been implemented in the ASP solver ASPeRiX. This paper is the first comprehensive document in which a survey of the important techniques relevant to our approach is presented.\nStarting from a short description of state-of-the-art ASP working principle, we have presented by many examples the main motivation of our approach: escaping the bottleneck of the preliminary phase of grounding in which many state-of-the-art systems fall. After a presentation of the theoretical foundations of ASP, we have described by an ASPeRiX computation our first order forward chaining approach for answer set computing and have established the soundness and completeness of this calculus w.r.t. the semantics of ASP (Proofs are reported in Appendix B). We have then described in details the main algorithms of ASPeRiX and particularly those\nit does not escape the grounding/solving separation, it only introduces some tools to control the process.\nwhich realize the selection of the first order rules to be instantiated and applied according to the current answer set in construction.\nOur methodology allows very good performances for definite and stratified programs. It outperforms systems with a pregrounding phase for programs with large grounding but much of it is unnecessary to solve the problem. On the other side, performances quickly degrade for combinatorial problems with large search spaces, especially if forward chaining propagation can not be exploited.\nWe have shown that our approach escapes the bottleneck of the preliminary phase of grounding that is the only difficulty for some classes of programs. A direct consequence of our new approach is that the use of symbolic functions in general and arithmetic calculus in particular inside ASP is greatly facilitated.\nThe forward chaining with the grounding process realized on the fly as an operational semantics emphasizes the programming aspect of ASP in which the answer set is not only the result of a black box but the result of a process that may be followed. This is interesting when dealing with knowledge coming from the web and expressed in description logic since the structure of information uses rules that are chained ones with the others (whereas this is not always the case for a program encoding a combinatorial problem). Moreover, when dealing with knowledge expressed in description logic, one important issue is the ability to query the knowledge base. The grounding process realized on the fly will then allow to focus only\non the rules useful to find an answer to the query. For this category of programs, we think that our approach may be of great interest.\nFurthermore, computing the answer sets of a program is a fundamental goal but not an exclusive one. Debugging a program, controlling its behavior, introducing in it some features coming from other programming languages may be of great interest for ASP. We think that our methodology of answer set computing, guided by the rules of the program, is the good starting point towards these new goals.\nThe ASPeRiX project is still in progress. Improvements at the algorithmic level are underway by the development and implementation of backjumping and clause learning techniques. On the other hand, we plan to fully respect the core language ASP (Calimeri et al. 2014) by introducing, among others, minimization / maximization and aggregates and extend it by introducing existentially quantified variables in multi-head rules to encode fragments of Description Logics which are logical formalisms for ontologies and the Semantic Web.\nTribute\nIn memory of the late Pascal Nicolas who was at the origin of this work. He sadly passed away in 2010 but his enthusiasm, his passion for research and his great humanity are still with us."
    }, {
      "heading" : "Appendix A Hanoi example",
      "text" : "The following ASP program is the Hanoi example with 4 discs.\n%------ Initial settings number of moves(10000). largest disc(4).\n%------ Initial state initial state(towers(l(4,l(3,l(2,l(1,nil)))),nil,nil)).\n% ------ Goal state goal(towers(nil, nil, l(4,l(3,l(2,l(1,nil)))))).\n% ------ all discs involved ------ disc(1..4).\n% ------ legal stacks ------ legalStack(nil). legalStack(l(T,nil)) :- disc(T). legalStack(l(T,l(T1,S))) :- legalStack(l(T1,S)), disc(T), T > T1.\n% ------ possible moves ------ possible state(0,towers(S1,S2,S3))\n:- initial state(towers(S1,S2,S3)), legalStack(S1), legalStack(S2), legalStack(S3).\npossible state(I,towers(S1,S2,S3))\n:- possible move(I,T,towers(S1,S2,S3)).\n% From stack one to stack two. possible move(J,towers(l(X,S1),S2,S3),towers(S1,l(X,S2),S3))\n:- possible state(I,towers(l(X,S1),S2,S3)), number of moves(N), I<=N, legalStack(l(X,S2)), J=I+1, not ok(I).\n% From stack one to stack three. possible move(J,towers(l(X,S1),S2,S3),towers(S1,S2,l(X,S3)))\n:- possible state(I,towers(l(X,S1),S2,S3)), number of moves(N), I<=N, legalStack(l(X,S3)), J=I+1, not ok(I).\n% From stack two to stack one. possible move(J,towers(S1,l(X,S2),S3),towers(l(X,S1),S2,S3))\n:- possible state(I,towers(S1,l(X,S2),S3)),\nnumber of moves(N), I<=N, legalStack(l(X,S1)), J=I+1, not ok(I).\n% From stack two to stack three. possible move(J,towers(S1,l(X,S2),S3),towers(S1,S2,l(X,S3)))\n:- possible state(I,towers(S1,l(X,S2),S3)), number of moves(N), I<=N, legalStack(l(X,S3)), J=I+1, not ok(I).\n% From stack three to stack one. possible move(J,towers(S1,S2,l(X,S3)),towers(l(X,S1),S2,S3))\n:- possible state(I,towers(S1,S2,l(X,S3))), number of moves(N), I<=N, legalStack(l(X,S1)), J=I+1, not ok(I).\n% From stack three to stack two. possible move(J,towers(S1,S2,l(X,S3)),towers(S1,l(X,S2),S3))\n:- possible state(I,towers(S1,S2,l(X,S3))), number of moves(N), I<=N, legalStack(l(X,S2)), J=I+1, not ok(I).\n%------ actual moves ------ % a solution exists if and only if there is a \"possible move\" % leading to the goal. % in this case, starting from the goal, we proceed backward % to the initial state to single out the full set of moves.\n% Choose from the possible moves. move(I,towers(S1,S2,S3))\n:- goal(towers(S1,S2,S3)), possible state(I,towers(S1,S2,S3)).\nok(I) :- move(I,towers(S1,S2,S3)), goal(towers(S1,S2,S3)). win :- ok(I). :- not win.\nmove(J,towers(S1,S2,S3))\n:- move(I,towers(A1,A2,A3)), possible move(I,towers(S1,S2,S3),towers(A1,A2,A3)), J=I-1, not nomove(J,towers(S1,S2,S3)).\nnomove(J,towers(S1,S2,S3))\n:- move(I,towers(A1,A2,A3)), possible move(I,towers(S1,S2,S3),towers(A1,A2,A3)), J=I-1, not move(J,towers(S1,S2,S3)).\n%------ precisely one move at each step ------ moveStepI(I) :- move(I,T).\n:- legalMoveNumber(I), ok(J), I<J, not moveStepI(I).\n:- legalMoveNumber(I), move(I,T1), move(I,T2), T1!=T2.\nlegalMoveNumber(0).\nlegalMoveNumber(K)\n:- legalMoveNumber(I), number of moves(J), I < J, K=I+1.\n#hide. #show move/2."
    }, {
      "heading" : "Appendix B Proofs",
      "text" : "B.1 Proof of Theorem 2\nWe first give some material needed in the proof. Auxiliary Lemma 1 is used in the proof of Lemma 2. Lemmas 2 and 3 establish completeness and correctness.\nLemma 1 shows that the generating rules of a program can be ordered so as to correspond to the order of application of rules in an ASPeRiX computation. Condition (1) says that a rule used at step i is supported at this step. Condition (2) says that if a rule is a member of ∆pro at step i but is used at a later stage j, then all rules used at steps between i and j are members of ∆pro at step i. In other words, condition (2) says that propagation is entirely completed before making a choice.\nLemma 1. Let P be a normal logic program and X be an answer set of P . Then, there exists an enumeration 〈ri〉i∈[1..n] of GRP (X), the set of generating rules of X, such that for all i ∈ [1..n] the following two conditions are satisfied:\n(1) body+(ri) ⊆ head({rk | k < i}) (2) for all j > i, if body+(rj) ⊆ head({rk | k < i}) and body−(rj) ⊆ body−({rk |\nk < i}) then body−(ri) ⊆ body−({rk | k < i}).\nProof. (of Lemma 1) Let P be a normal logic program and X be an answer set of P . By a theorem from (Konczak et al. 2006), there exists an enumeration 〈ri〉i∈[1..n] of GRP (X) such that ∀i ∈ [1..n], body+(ri) ⊆ head({rk | k < i}), i.e. such that condition (1) is satisfied. This enumeration can be recursively modified in the following way in order to verify condition (2). For each i ∈ [1..n], if ri satisfies (2) then ri remains at rank i, else there exists rj with j > i that falsifies condition (2). In this last case, it suffices to swap the two rules in the enumeration to satisfy condition (2) at rank i.\nNotation. If P is a normal logic program and 〈Ri, 〈INi, OUTi〉〉∞i=0 is a sequence of ground rule sets Ri and partial interpretations 〈INi, OUTi〉, then ∆ipro denotes ∆pro(P, 〈INi, OUTi〉, Ri) and ∆icho denotes ∆cho(P, 〈INi, OUTi〉, Ri).\nLemma 2. Let P be a normal logic program and X be an answer set of P . Then there exists an ASPeRiX computation that converges to X.\nProof. (of Lemma 2) Let P be a normal logic program and X be an answer set of P . Then, there exists an enumeration 〈ri〉i∈[1..n] of GRP (X) that satisfies conditions (1) and (2) from Lemma 1.\nLet 〈Ri, 〈INi, OUTi〉〉∞i=0 be the sequence defined as follows.\n• R0 = ∅, IN0 = ∅ and OUT0 = {⊥} • ∀i, 1 ≤ i ≤ n, Ri = Ri−1 ∪ {ri}, INi = INi−1 ∪ {head(ri)} and OUTi = OUTi−1 ∪ body−(ri) • ∀i > n, Ri = Ri−1, INi = INi−1 and OUTi = OUTi−1\nFor all i ∈ [1..n], we have:\n(*1) X = head(GRP (X)) (by Theorem 1) (*2) INi = ⋃i j=1{head(rj)} and IN∞ = ⋃∞ i=0 INi = X (by (*1))\n(*3) OUTi = ⋃i j=1 body\n−(rj) and therefore OUTi ∩ X = ∅ (by Definition 2 of GRP (X))\n(*4) ∆pro(P, 〈INi, OUTi〉, Ri) ⊆ GRP (X)\nProperty (*4) can be proved as follows. By definition 5, ∆ipro = {r ∈ ground(P ) \\ Ri | body+(r) ⊆ INi and body−(r) ⊆ OUTi}. And by (*2) and (*3), INi ⊆ X and OUTi ∩X = ∅. Thus ∆ipro ⊆ GRP (X).\nWe are now able to prove that the sequence 〈Ri, 〈INi, OUTi〉〉∞i=0 is an ASPeRiX computation.\nLet us first note that ∀i, 〈INi, OUTi〉 is a partial interpretation since INi ∩ OUTi = ∅ (by (*2) and (*3)).\nNow we prove that Revision principle holds for each i ≥ 1. Let i such that 1 ≤ i ≤ n, then ri is such that body+(ri) ⊆ head({rk | k < i}) = INi−1. Two cases are possible. First, if body−(ri) ⊆ body−({rk | k < i}) = OUTi−1, then ri ∈ ∆i−1pro and Revision principle holds at rank i. Second, if body−(ri) 6⊆ body−({rk | k < i}) then, by definition of enumeration 〈ri〉i∈[1..n], there is no rule rj with j > i such that body+(rj) ⊆ INi−1 and body−(rj) ⊆ OUTi−1. So ∆i−1pro ∩ GRP (X) = ∅. And as ∆i−1pro ⊆ GRP (X) (by (*4)), ∆i−1pro = ∅. Moreover, ri is a generating rule, thus body−(ri)∩X = ∅ and body−(ri)∩INi−1 = ∅ (since INi−1 ⊆ X). Thereby ri ∈ ∆i−1cho and Revision principle holds. If i > n, Revision principle trivially holds (Stability).\nAt step n, we have INn = ⋃n j=1{head(rj)} = X and Rn = ⋃n j=1{rj} = GRP (X). ∆n+1cho = {r ∈ ground(P ) \\ Rn | body+(r) ⊆ X and body−(r) ∩ X = ∅}. Thus ∆n+1cho = ∅. Convergence principle holds and IN∞ = INn = X. Lemma 3. Let P be a normal logic program and 〈Ri, 〈INi, OUTi〉〉∞i=0 be an ASPeRiX computation for P . Then, IN∞ is an answer set of P .\nProof. (of Lemma 3) Let 〈Ri, 〈INi, OUTi〉〉∞i=0 be an ASPeRiX computation for P . We first prove that ∀i > 0, ∀j ≥ i − 1, Ri ⊆ GRP (INj). For each rule ri, body+(ri) ⊆ INi−1 and IN set increases monotonically, thus body+(ri) ⊆ INj ,∀j ≥ i− 1. If ri ∈ ∆i−1pro , then body−(ri) ⊆ OUTi−1 and OUTi−1 ∩ INi−1 = ∅. Since IN and OUT sets grow monotonically with an empty intersection, body−(ri) ∩ INj = ∅,∀j ≥ i − 1. If ri ∈ ∆i−1cho , then body−(ri) ∩ INi−1 = ∅. And, since OUTi =\nOUTi−1 ∪ body−(ri), we have ∀j ≥ i, body−(ri) ⊆ OUTj , and thus, with the same reasonning as above (ri ∈ ∆i−1pro ), body−(ri) ∩ INj = ∅,∀j ≥ i− 1. Ri = ⋃i k=1{rk} and, since ∀j ≥ k − 1, rk ∈ GRP (INj), rk ∈ GRP (INi). Thus Ri ⊆ GRP (INi). By Convergence principle we have ∃i, ∆icho = {r ∈ ground(P ) \\Ri | body+(r) ⊆ INi and body −(r)∩INi = ∅} = ∅, then GRP (INi) ⊆ Ri. Since ∀i, Ri ⊆ GRP (INi), GRP (INi) = Ri. And INi = head(Ri) (by definition of an ASPeRiX computation), thus INi = head(GRP (INi)) and INi is an answer set of P (by Theorem 1).\nProof. (of Theorem 2) Lemmas 2 and 3 prove each one direction of the equivalence.\nB.2 Proof of Theorem 3\nLemmas 4 and 5 establish completeness and correctness.\nLemma 4. Let P be a normal logic program and X be an answer set for P . Then there exists a mbt ASPeRiX computation for P that converges to X.\nProof. (of Lemma 4) Let P be a normal logic program and X an answer set for P . By Theorem 2, there exists an ASPeRiX computation 〈Ri, 〈INi, OUTi〉〉∞i=0 with IN∞ = X. Let C = 〈Ki, Ri, 〈INi,MBTi, OUTi〉〉∞i=0 with Ki = MBTi = ∅, ∀i ≥ 0. C is clearly a mbt ASPeRiX computation for P where “Rule exclusion” is never used and thus “Mbt-propagation” is not used either.\nLemma 5. Let P be a normal logic program and 〈Ki, Ri, 〈INi,MBTi, OUTi〉〉∞i=0 be a mbt ASPeRiX computation for P . Then IN∞ is an answer set of P . Proof. (of Lemma 5) Let 〈Ki, Ri, 〈INi,MBTi, OUTi〉〉∞i=0 a mbt ASPeRiX computation for P . Then C = 〈Ri, 〈INi, OUTi〉〉∞i=0 is an ASPeRiX computation for P : it satisfies Revision principles of an ASPeRiX computation and it trivially satisfies Convergence too. By Theorem 2, C converges to an answer set IN∞.\nProof. (of Theorem 3) Lemmas 4 and 5 prove each one direction of the equivalence."
    } ],
    "references" : [ {
      "title" : "Function Symbols in ASP: Overview and Perspectives",
      "author" : [ "M. Alviano", "F. Calimeri", "W. Faber", "G. Ianni", "N. Leone" ],
      "venue" : "Nonmonotonic Reasoning, Essays Celebrating its 30th Anniversary, G. Brewka, V. Marek, and M. Truszczynski, Eds. Studies in Logic, vol. 31. College Publications, 1–24.",
      "citeRegEx" : "Alviano et al\\.,? 2011",
      "shortCiteRegEx" : "Alviano et al\\.",
      "year" : 2011
    }, {
      "title" : "WASP: A native ASP solver based on constraint learning",
      "author" : [ "M. Alviano", "C. Dodaro", "W. Faber", "N. Leone", "F. Ricca" ],
      "venue" : "Proceedings of the 12th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR’13), P. Cabalar and T. C. Son, Eds. LNCS, vol. 8148. Springer, 55–67.",
      "citeRegEx" : "Alviano et al\\.,? 2013",
      "shortCiteRegEx" : "Alviano et al\\.",
      "year" : 2013
    }, {
      "title" : "Disjunctive asp with functions: Decidable queries and effective computation",
      "author" : [ "M. Alviano", "W. Faber", "N. Leone" ],
      "venue" : "Theory and Practice of Logic Programming 10, 4-6, 497–512.",
      "citeRegEx" : "Alviano et al\\.,? 2010",
      "shortCiteRegEx" : "Alviano et al\\.",
      "year" : 2010
    }, {
      "title" : "Representing constraint satisfaction problems in answer set programming",
      "author" : [ "M. Balduccini" ],
      "venue" : "Proceedings of the Workshop on Answer Set Programming and Other Computing Paradigms (ASPOCP’09). 16–30.",
      "citeRegEx" : "Balduccini,? 2009",
      "shortCiteRegEx" : "Balduccini",
      "year" : 2009
    }, {
      "title" : "Knowledge Representation, Reasoning and Declarative Problem Solving",
      "author" : [ "C. Baral" ],
      "venue" : "Cambridge University Press.",
      "citeRegEx" : "Baral,? 2003",
      "shortCiteRegEx" : "Baral",
      "year" : 2003
    }, {
      "title" : "Towards an integration of answer set and constraint solving",
      "author" : [ "S. Baselice", "P. Bonatti", "M. Gelfond" ],
      "venue" : "Proceedings of the 21st International Conference on Logic Programming (ICLP’05). LNCS, vol. 3668. Springer, 52–66.",
      "citeRegEx" : "Baselice et al\\.,? 2005",
      "shortCiteRegEx" : "Baselice et al\\.",
      "year" : 2005
    }, {
      "title" : "A decidable subclass of finitary programs",
      "author" : [ "S. Baselice", "P.A. Bonatti" ],
      "venue" : "Theory and Practice of Logic Programming 10, 4-6, 481–496.",
      "citeRegEx" : "Baselice and Bonatti,? 2010",
      "shortCiteRegEx" : "Baselice and Bonatti",
      "year" : 2010
    }, {
      "title" : "Enhancing disjunctive datalog by constraints",
      "author" : [ "F. Buccafurri", "N. Leone", "P. Rullo" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering 12, 5, 845–860.",
      "citeRegEx" : "Buccafurri et al\\.,? 2000",
      "shortCiteRegEx" : "Buccafurri et al\\.",
      "year" : 2000
    }, {
      "title" : "Computable functions in",
      "author" : [ "F. Calimeri", "S. Cozza", "G. Ianni", "N. Leone" ],
      "venue" : null,
      "citeRegEx" : "Calimeri et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Calimeri et al\\.",
      "year" : 2008
    }, {
      "title" : "Finitely recursive programs: Decidability and bottom-up computation",
      "author" : [ "F. Calimeri", "S. Cozza", "G. Ianni", "N. Leone" ],
      "venue" : "AI Communications 24, 4 (Dec.), 311–334.",
      "citeRegEx" : "Calimeri et al\\.,? 2011",
      "shortCiteRegEx" : "Calimeri et al\\.",
      "year" : 2011
    }, {
      "title" : "The third open answer set programming competition",
      "author" : [ "F. Calimeri", "G. Ianni", "F. Ricca" ],
      "venue" : "Theory and Practice of Logic Programming 14, 1, 117–135.",
      "citeRegEx" : "Calimeri et al\\.,? 2014",
      "shortCiteRegEx" : "Calimeri et al\\.",
      "year" : 2014
    }, {
      "title" : "Experimenting with parallelism for the instantiation of ASP programs",
      "author" : [ "F. Calimeri", "S. Perri", "F. Ricca" ],
      "venue" : "Journal of Algorithms 63, 1-3, 34–54.",
      "citeRegEx" : "Calimeri et al\\.,? 2008",
      "shortCiteRegEx" : "Calimeri et al\\.",
      "year" : 2008
    }, {
      "title" : "Gasp: Answer set programming with lazy grounding",
      "author" : [ "A. Dal Palù", "A. Dovier", "E. Pontelli", "G. Rossi" ],
      "venue" : "Fundamenta Informaticae 96, 3 (Aug.), 297–322.",
      "citeRegEx" : "Palù et al\\.,? 2009",
      "shortCiteRegEx" : "Palù et al\\.",
      "year" : 2009
    }, {
      "title" : "OMiGA: An open minded grounding on-the-fly answer set solver",
      "author" : [ "M. Dao-Tran", "T. Eiter", "M. Fink", "G. Weidinger", "A. Weinzierl" ],
      "venue" : "Proceedings of the 13th European Conference on Logics in Artificial Intelligence (JELIA’12). LNAI, vol. 7519. Springer, 480–483.",
      "citeRegEx" : "Dao.Tran et al\\.,? 2012",
      "shortCiteRegEx" : "Dao.Tran et al\\.",
      "year" : 2012
    }, {
      "title" : "Computing non-ground representations of stable models",
      "author" : [ "T. Eiter", "J.J. Lu", "V.S. Subrahmanian" ],
      "venue" : "Proceedings of the 4th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR’97), J. Dix, U. Furbach, and A. Nerode, Eds. LNCS, vol. 1265. Springer, 198–217.",
      "citeRegEx" : "Eiter et al\\.,? 1997",
      "shortCiteRegEx" : "Eiter et al\\.",
      "year" : 1997
    }, {
      "title" : "The intelligent grounder of DLV",
      "author" : [ "W. Faber", "N. Leone", "S. Perri" ],
      "venue" : "Correct Reasoning - Essays on Logic-Based AI in Honour of Vladimir Lifschitz, E. Erdem, J. Lee, Y. Lierler, and D. Pearce, Eds. LNCS, vol. 7265. Springer, 247–264.",
      "citeRegEx" : "Faber et al\\.,? 2012",
      "shortCiteRegEx" : "Faber et al\\.",
      "year" : 2012
    }, {
      "title" : "Pushing goal derivation in dlp computations",
      "author" : [ "W. Faber", "N. Leone", "G. Pfeifer" ],
      "venue" : "Proceedings of the 5th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR’99), M. Gelfond, N. Leone, and G. Pfeifer, Eds. LNCS, vol. 1730. Springer, 177–191.",
      "citeRegEx" : "Faber et al\\.,? 1999",
      "shortCiteRegEx" : "Faber et al\\.",
      "year" : 1999
    }, {
      "title" : "A new perspective on stable models",
      "author" : [ "P. Ferraris", "J. Lee", "V. Lifschitz" ],
      "venue" : "Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI’07). 372–379.",
      "citeRegEx" : "Ferraris et al\\.,? 2007",
      "shortCiteRegEx" : "Ferraris et al\\.",
      "year" : 2007
    }, {
      "title" : "Engineering an incremental ASP solver",
      "author" : [ "M. Gebser", "R. Kaminski", "B. Kaufmann", "M. Ostrowski", "T. Schaub", "S. Thiele" ],
      "venue" : "Proceedings of the 24th International Conference on Logic Programming (ICLP’08), M. Garcia de la Banda and E. Pontelli, Eds. LNCS, vol. 5366. Springer, 190–205.",
      "citeRegEx" : "Gebser et al\\.,? 2008",
      "shortCiteRegEx" : "Gebser et al\\.",
      "year" : 2008
    }, {
      "title" : "Advances in gringo Series 3",
      "author" : [ "M. Gebser", "R. Kaminski", "A. König", "T. Schaub" ],
      "venue" : "Proceedings of 11th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR’11), J. P. Delgrande and W. Faber, Eds. LNCS, vol. 6645. Springer, 345–351.",
      "citeRegEx" : "Gebser et al\\.,? 2011",
      "shortCiteRegEx" : "Gebser et al\\.",
      "year" : 2011
    }, {
      "title" : "Conflict-driven answer set solving: From theory to practice",
      "author" : [ "M. Gebser", "B. Kaufmann", "T. Schaub" ],
      "venue" : "Artificial Intelligence 187, 52–89.",
      "citeRegEx" : "Gebser et al\\.,? 2012",
      "shortCiteRegEx" : "Gebser et al\\.",
      "year" : 2012
    }, {
      "title" : "GrinGo : A New Grounder for Answer Set Programming",
      "author" : [ "M. Gebser", "T. Schaub", "S. Thiele" ],
      "venue" : "Proceedings of the 9th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR’07). LNCS, vol. 4483. Springer, 266–271.",
      "citeRegEx" : "Gebser et al\\.,? 2007",
      "shortCiteRegEx" : "Gebser et al\\.",
      "year" : 2007
    }, {
      "title" : "The stable model semantics for logic programming",
      "author" : [ "M. Gelfond", "V. Lifschitz" ],
      "venue" : "Proceedings of the Fifth International Conference and Symposium on Logic Programming (ICLP’88), R. A. Kowalski and K. Bowen, Eds. The MIT Press, Cambridge, Massachusetts, 1070–1080.",
      "citeRegEx" : "Gelfond and Lifschitz,? 1988",
      "shortCiteRegEx" : "Gelfond and Lifschitz",
      "year" : 1988
    }, {
      "title" : "Classical negation in logic programs and disjunctive databases",
      "author" : [ "M. Gelfond", "V. Lifschitz" ],
      "venue" : "New Generation Computing 9, 3/4, 365–386.",
      "citeRegEx" : "Gelfond and Lifschitz,? 1991",
      "shortCiteRegEx" : "Gelfond and Lifschitz",
      "year" : 1991
    }, {
      "title" : "Answer set programming based on propositional satisfiability",
      "author" : [ "E. Giunchiglia", "Y. Lierler", "M. Maratea" ],
      "venue" : "Journal of Automated Reasoning 36, 4, 345–377.",
      "citeRegEx" : "Giunchiglia et al\\.,? 2006",
      "shortCiteRegEx" : "Giunchiglia et al\\.",
      "year" : 2006
    }, {
      "title" : "A non-ground realization of the stable and well-founded semantics",
      "author" : [ "G. Gottlob", "S. Marcus", "A. Nerode", "G. Salzer", "V.S. Subrahmanian" ],
      "venue" : "Theoretical Computer Science 166, 1-2, 221–262.",
      "citeRegEx" : "Gottlob et al\\.,? 1996",
      "shortCiteRegEx" : "Gottlob et al\\.",
      "year" : 1996
    }, {
      "title" : "Logic programming with function symbols: Checking termination of bottom-up evaluation through program adornments",
      "author" : [ "S. Greco", "C. Molinaro", "I. Trubitsyna" ],
      "venue" : "Theory and Practice of Logic Programming 13, 4-5, 737–752.",
      "citeRegEx" : "Greco et al\\.,? 2013",
      "shortCiteRegEx" : "Greco et al\\.",
      "year" : 2013
    }, {
      "title" : "Graphs and colorings for answer set programming",
      "author" : [ "K. Konczak", "T. Linke", "T. Schaub" ],
      "venue" : "Theory and Practice of Logic Programming 6, 61–106.",
      "citeRegEx" : "Konczak et al\\.,? 2006",
      "shortCiteRegEx" : "Konczak et al\\.",
      "year" : 2006
    }, {
      "title" : "A first order forward chaining approach for answer set computing",
      "author" : [ "C. Lefèvre", "P. Nicolas" ],
      "venue" : "Proceedings of the 12th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR’09). LNCS, vol. 5753. Springer, 196–208.",
      "citeRegEx" : "Lefèvre and Nicolas,? 2009a",
      "shortCiteRegEx" : "Lefèvre and Nicolas",
      "year" : 2009
    }, {
      "title" : "The first version of a new ASP solver : ASPeRiX",
      "author" : [ "C. Lefèvre", "P. Nicolas" ],
      "venue" : "Proceedings of the 12th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR’09). LNCS, vol. 5753. Springer, 522–527.",
      "citeRegEx" : "Lefèvre and Nicolas,? 2009b",
      "shortCiteRegEx" : "Lefèvre and Nicolas",
      "year" : 2009
    }, {
      "title" : "The DLV system for knowledge representation and reasoning",
      "author" : [ "N. Leone", "G. Pfeifer", "W. Faber", "T. Eiter", "G. Gottlob", "S. Perri", "F. Scarcello" ],
      "venue" : "ACM Transactions on Computational Logic 7, 3, 499–562.",
      "citeRegEx" : "Leone et al\\.,? 2006",
      "shortCiteRegEx" : "Leone et al\\.",
      "year" : 2006
    }, {
      "title" : "One more decidable class of finitely ground programs",
      "author" : [ "Y. Lierler", "V. Lifschitz" ],
      "venue" : "Proceedings of the 25th International Conference on Logic Programming (ICLP’09). LNCS, vol. 5649. Springer, 489–493.",
      "citeRegEx" : "Lierler and Lifschitz,? 2009",
      "shortCiteRegEx" : "Lierler and Lifschitz",
      "year" : 2009
    }, {
      "title" : "ASSAT: computing answer sets of a logic program by SAT solvers",
      "author" : [ "F. Lin", "Y. Zhao" ],
      "venue" : "Artificial Intelligence 157, 1-2, 115–137.",
      "citeRegEx" : "Lin and Zhao,? 2004",
      "shortCiteRegEx" : "Lin and Zhao",
      "year" : 2004
    }, {
      "title" : "From answer set logic programming to circumscription via logic of GK",
      "author" : [ "F. Lin", "Y. Zhou" ],
      "venue" : "Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI’07). 441–446.",
      "citeRegEx" : "Lin and Zhou,? 2007",
      "shortCiteRegEx" : "Lin and Zhou",
      "year" : 2007
    }, {
      "title" : "Logic programs with abstract constraint atoms: The role of computations",
      "author" : [ "L. Liu", "E. Pontelli", "T.C. Son", "M. Truszczynski" ],
      "venue" : "Artificial Intelligence 174, 3-4, 295–315.",
      "citeRegEx" : "Liu et al\\.,? 2010",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2010
    }, {
      "title" : "Pbmodels - software to compute stable models by pseudoboolean solvers",
      "author" : [ "L. Liu", "M. Truszczynski" ],
      "venue" : "Proceedings of the 8th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR’05), C. Baral, G. Greco, N. Leone, and G. Terracina, Eds. LNCS, vol. 3662. Springer, 410–415.",
      "citeRegEx" : "Liu and Truszczynski,? 2005",
      "shortCiteRegEx" : "Liu and Truszczynski",
      "year" : 2005
    }, {
      "title" : "Logic programs with stable model semantics as a constraint programming paradigm",
      "author" : [ "I. Niemelä" ],
      "venue" : "Annals of Mathematics and Artificial Intelligence 25, 3-4, 241–273.",
      "citeRegEx" : "Niemelä,? 1999",
      "shortCiteRegEx" : "Niemelä",
      "year" : 1999
    }, {
      "title" : "ASP modulo CSP: the clingcon system",
      "author" : [ "M. Ostrowski", "T. Schaub" ],
      "venue" : "Theory and Practice of Logic Programming 12, 4-5, 485–503.",
      "citeRegEx" : "Ostrowski and Schaub,? 2012",
      "shortCiteRegEx" : "Ostrowski and Schaub",
      "year" : 2012
    }, {
      "title" : "Enhancing dlv instantiator by backjumping techniques",
      "author" : [ "S. Perri", "F. Scarcello", "G. Catalano", "N. Leone" ],
      "venue" : "Annals of Mathematics and Artificial Intelligence 51, 2-4, 195–228.",
      "citeRegEx" : "Perri et al\\.,? 2007",
      "shortCiteRegEx" : "Perri et al\\.",
      "year" : 2007
    }, {
      "title" : "Extending and implementing the stable model semantics",
      "author" : [ "P. Simons", "I. Niemelä", "T. Soininen" ],
      "venue" : "Artificial Intelligence 138, 1-2, 181–234.",
      "citeRegEx" : "Simons et al\\.,? 2002",
      "shortCiteRegEx" : "Simons et al\\.",
      "year" : 2002
    }, {
      "title" : "Implementation of local grounding for logic programs for stable model semantics",
      "author" : [ "T. Syrjänen" ],
      "venue" : "Tech. rep., Helsinki University of Technology.",
      "citeRegEx" : "Syrjänen,? 1998",
      "shortCiteRegEx" : "Syrjänen",
      "year" : 1998
    }, {
      "title" : "Connecting first-order ASP and the logic FO(ID) through reducts",
      "author" : [ "M. Truszczynski" ],
      "venue" : "Correct Reasoning - Essays on Logic-Based AI in Honour of Vladimir Lifschitz. LNCS, vol. 7265. Springer, 543–559.",
      "citeRegEx" : "Truszczynski,? 2012",
      "shortCiteRegEx" : "Truszczynski",
      "year" : 2012
    }, {
      "title" : "Principles of Database and Knowledge-Base Systems, Volume II",
      "author" : [ "J.D. Ullman" ],
      "venue" : "Computer Science Press.",
      "citeRegEx" : "Ullman,? 1989",
      "shortCiteRegEx" : "Ullman",
      "year" : 1989
    }, {
      "title" : "Learning non-ground rules for answer-set solving. In 2nd Workshop on Grounding and Transformations for Theories With Variables (GTTV’13). Appendix A Hanoi example The following ASP program is the Hanoi example with 4 discs",
      "author" : [ "A. Weinzierl" ],
      "venue" : null,
      "citeRegEx" : "Weinzierl,? \\Q2013\\E",
      "shortCiteRegEx" : "Weinzierl",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "Answer Set Programming (ASP) is a very convenient paradigm to represent knowledge in Artificial Intelligence (AI) and to encode combinatorial problems (Baral 2003; Niemelä 1999).",
      "startOffset" : 151,
      "endOffset" : 177
    }, {
      "referenceID" : 36,
      "context" : "Answer Set Programming (ASP) is a very convenient paradigm to represent knowledge in Artificial Intelligence (AI) and to encode combinatorial problems (Baral 2003; Niemelä 1999).",
      "startOffset" : 151,
      "endOffset" : 177
    }, {
      "referenceID" : 22,
      "context" : "It has its roots in nonmonotonic reasoning and logic programming and has led to a lot of works since the seminal paper (Gelfond and Lifschitz 1988).",
      "startOffset" : 119,
      "endOffset" : 147
    }, {
      "referenceID" : 22,
      "context" : "to use ASP to solve a problem, he has to write a logic program in term of rules in a purely declarative manner in such a way that the answer sets (initially called stable models in (Gelfond and Lifschitz 1988)) of the program represent the solutions of his original problem.",
      "startOffset" : 181,
      "endOffset" : 209
    }, {
      "referenceID" : 40,
      "context" : "For the grounder box we can cite Lparse (Syrjänen 1998) and Gringo (Gebser et al.",
      "startOffset" : 40,
      "endOffset" : 55
    }, {
      "referenceID" : 19,
      "context" : "For the grounder box we can cite Lparse (Syrjänen 1998) and Gringo (Gebser et al. 2011), and for the solver box Smodels (Simons et al.",
      "startOffset" : 67,
      "endOffset" : 87
    }, {
      "referenceID" : 39,
      "context" : "2011), and for the solver box Smodels (Simons et al. 2002) and Clasp (Gebser et al.",
      "startOffset" : 38,
      "endOffset" : 58
    }, {
      "referenceID" : 20,
      "context" : "2002) and Clasp (Gebser et al. 2012).",
      "startOffset" : 16,
      "endOffset" : 36
    }, {
      "referenceID" : 32,
      "context" : "A particular family of solvers are Assat (Lin and Zhao 2004), Cmodels (Giunchiglia et al.",
      "startOffset" : 41,
      "endOffset" : 60
    }, {
      "referenceID" : 24,
      "context" : "A particular family of solvers are Assat (Lin and Zhao 2004), Cmodels (Giunchiglia et al. 2006) and Pbmodels (Liu and Truszczynski 2005), since they transform the answer set computation problem into a (pseudo) boolean model computation problem and use a (pseudo) SAT solver as an internal black box.",
      "startOffset" : 70,
      "endOffset" : 95
    }, {
      "referenceID" : 35,
      "context" : "2006) and Pbmodels (Liu and Truszczynski 2005), since they transform the answer set computation problem into a (pseudo) boolean model computation problem and use a (pseudo) SAT solver as an internal black box.",
      "startOffset" : 19,
      "endOffset" : 46
    }, {
      "referenceID" : 30,
      "context" : "In the system DLV (Leone et al. 2006), symbolized in Fig.",
      "startOffset" : 18,
      "endOffset" : 37
    }, {
      "referenceID" : 8,
      "context" : "1 by the dash-line rectangle, the grounder ((Calimeri et al. 2008) describes a parallel version) is incorporated as an internal function.",
      "startOffset" : 44,
      "endOffset" : 66
    }, {
      "referenceID" : 1,
      "context" : "In the same way, WASP (Alviano et al. 2013) uses the DLV grounder (Faber et al.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 15,
      "context" : "2013) uses the DLV grounder (Faber et al. 2012).",
      "startOffset" : 28,
      "endOffset" : 47
    }, {
      "referenceID" : 36,
      "context" : "Let P2 be the program, as given in (Niemelä 1999), encoding a 3coloring problem on a N vertices graph organized as a bicycle wheel (see below).",
      "startOffset" : 35,
      "endOffset" : 49
    }, {
      "referenceID" : 36,
      "context" : "Let P3 be the program, inspired from one given in (Niemelä 1999), encoding the Hamiltonian cycle problem in a N vertices complete oriented graph.",
      "startOffset" : 50,
      "endOffset" : 64
    }, {
      "referenceID" : 5,
      "context" : "Some aim at solving the grounding bottleneck by combining ASP to constraint programming: (Baselice et al. 2005) proposes to reduce the memory requirements for a very specific class of programs, i.",
      "startOffset" : 89,
      "endOffset" : 111
    }, {
      "referenceID" : 3,
      "context" : "multi-sorted logic programs with cardinality constraints, (Balduccini 2009) proposes an algorithm to make cooperate an ASP solver and a Constraint Logic Programming solver in such a way that ASP is viewed as a specification language for constraint satisfaction problems and (Ostrowski and Schaub 2012) describes the Clingcon system which is a tight cooperation between the ASP solver Clasp and the Constraint Programming solver GeCode.",
      "startOffset" : 58,
      "endOffset" : 75
    }, {
      "referenceID" : 37,
      "context" : "multi-sorted logic programs with cardinality constraints, (Balduccini 2009) proposes an algorithm to make cooperate an ASP solver and a Constraint Logic Programming solver in such a way that ASP is viewed as a specification language for constraint satisfaction problems and (Ostrowski and Schaub 2012) describes the Clingcon system which is a tight cooperation between the ASP solver Clasp and the Constraint Programming solver GeCode.",
      "startOffset" : 274,
      "endOffset" : 301
    }, {
      "referenceID" : 28,
      "context" : "2009) and ASPeRiX (Lefèvre and Nicolas 2009a; Lefèvre and Nicolas 2009b)) developed at the same time, and more recently OMiGA (Dao-Tran et al.",
      "startOffset" : 18,
      "endOffset" : 72
    }, {
      "referenceID" : 29,
      "context" : "2009) and ASPeRiX (Lefèvre and Nicolas 2009a; Lefèvre and Nicolas 2009b)) developed at the same time, and more recently OMiGA (Dao-Tran et al.",
      "startOffset" : 18,
      "endOffset" : 72
    }, {
      "referenceID" : 13,
      "context" : "2009) and ASPeRiX (Lefèvre and Nicolas 2009a; Lefèvre and Nicolas 2009b)) developed at the same time, and more recently OMiGA (Dao-Tran et al. 2012).",
      "startOffset" : 126,
      "endOffset" : 148
    }, {
      "referenceID" : 34,
      "context" : "They are all based on the notion of computation given in (Liu et al. 2010).",
      "startOffset" : 57,
      "endOffset" : 74
    }, {
      "referenceID" : 42,
      "context" : "Instantiation and propagation are inspired by previous work realized on the DLV grounder which is based on the semi-naive evaluation technique of (Ullman 1989).",
      "startOffset" : 146,
      "endOffset" : 159
    }, {
      "referenceID" : 25,
      "context" : "Last, concerning a direct handling of first order programs, let us note that there exists some works (Gottlob et al. 1996; Eiter et al. 1997; Ferraris et al. 2007; Lin and Zhou 2007; Truszczynski 2012) dealing with first order nonmonotonic logic programs.",
      "startOffset" : 101,
      "endOffset" : 201
    }, {
      "referenceID" : 14,
      "context" : "Last, concerning a direct handling of first order programs, let us note that there exists some works (Gottlob et al. 1996; Eiter et al. 1997; Ferraris et al. 2007; Lin and Zhou 2007; Truszczynski 2012) dealing with first order nonmonotonic logic programs.",
      "startOffset" : 101,
      "endOffset" : 201
    }, {
      "referenceID" : 17,
      "context" : "Last, concerning a direct handling of first order programs, let us note that there exists some works (Gottlob et al. 1996; Eiter et al. 1997; Ferraris et al. 2007; Lin and Zhou 2007; Truszczynski 2012) dealing with first order nonmonotonic logic programs.",
      "startOffset" : 101,
      "endOffset" : 201
    }, {
      "referenceID" : 33,
      "context" : "Last, concerning a direct handling of first order programs, let us note that there exists some works (Gottlob et al. 1996; Eiter et al. 1997; Ferraris et al. 2007; Lin and Zhou 2007; Truszczynski 2012) dealing with first order nonmonotonic logic programs.",
      "startOffset" : 101,
      "endOffset" : 201
    }, {
      "referenceID" : 41,
      "context" : "Last, concerning a direct handling of first order programs, let us note that there exists some works (Gottlob et al. 1996; Eiter et al. 1997; Ferraris et al. 2007; Lin and Zhou 2007; Truszczynski 2012) dealing with first order nonmonotonic logic programs.",
      "startOffset" : 101,
      "endOffset" : 201
    }, {
      "referenceID" : 28,
      "context" : "The present paper is an extended version of (Lefèvre and Nicolas 2009a; Lefèvre and Nicolas 2009b).",
      "startOffset" : 44,
      "endOffset" : 98
    }, {
      "referenceID" : 29,
      "context" : "The present paper is an extended version of (Lefèvre and Nicolas 2009a; Lefèvre and Nicolas 2009b).",
      "startOffset" : 44,
      "endOffset" : 98
    }, {
      "referenceID" : 34,
      "context" : "• theoretical foundations of the approach, “mbt ASPeRiX computation”, with complete proofs; these computations are based on those of (Liu et al. 2010) and include use of constraints and must-be-true propagation in order to guide the search;",
      "startOffset" : 133,
      "endOffset" : 150
    }, {
      "referenceID" : 22,
      "context" : "(Gelfond and Lifschitz 1988) Let P be a normal logic program and X an atom set.",
      "startOffset" : 0,
      "endOffset" : 28
    }, {
      "referenceID" : 27,
      "context" : "(Konczak et al. 2006) Let P be a normal logic program and X be an atom set.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 27,
      "context" : "(Konczak et al. 2006) Let P be a normal logic program and X be an atom set.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 23,
      "context" : "This is possible in ASP by means of an extended logic program (Gelfond and Lifschitz 1991) in which rules are built with classical literals (i.",
      "startOffset" : 62,
      "endOffset" : 90
    }, {
      "referenceID" : 34,
      "context" : "This concept is itself based on an abstract notion of computation for ground programs proposed in (Liu et al. 2010).",
      "startOffset" : 98,
      "endOffset" : 115
    }, {
      "referenceID" : 16,
      "context" : "2 The term “must be true” is first used in (Faber et al. 1999).",
      "startOffset" : 43,
      "endOffset" : 62
    }, {
      "referenceID" : 15,
      "context" : "The algorithm used in the ASPeRiX solver and described below is inspired by the previous work realized on the DLV grounder (Faber et al. 2012; Perri et al. 2007) which is based on the semi-naive evaluation technique of (Ullman 1989).",
      "startOffset" : 123,
      "endOffset" : 161
    }, {
      "referenceID" : 38,
      "context" : "The algorithm used in the ASPeRiX solver and described below is inspired by the previous work realized on the DLV grounder (Faber et al. 2012; Perri et al. 2007) which is based on the semi-naive evaluation technique of (Ullman 1989).",
      "startOffset" : 123,
      "endOffset" : 161
    }, {
      "referenceID" : 42,
      "context" : "2007) which is based on the semi-naive evaluation technique of (Ullman 1989).",
      "startOffset" : 63,
      "endOffset" : 76
    }, {
      "referenceID" : 22,
      "context" : "The core language of ASPeRiX is that of normal logic programs (Gelfond and Lifschitz 1988) with function symbols and true (or strong) negation without inconsistent answer set.",
      "startOffset" : 62,
      "endOffset" : 90
    }, {
      "referenceID" : 8,
      "context" : "ASPeRiX also provides dedicated treatment of lists with built-in predicates, as in DLV-complex (Calimeri et al. 2008), an extension of DLV with lists and sets.",
      "startOffset" : 95,
      "endOffset" : 117
    }, {
      "referenceID" : 7,
      "context" : "On the other side, ASPeRiX does not provide aggregate atoms and optimization statements (Buccafurri et al. 2000) which are accepted by the main current systems.",
      "startOffset" : 88,
      "endOffset" : 112
    }, {
      "referenceID" : 0,
      "context" : "A lot of work has been made for identifying program classes for which reasoning is decidable (Alviano et al. 2011; Alviano et al. 2010; Calimeri et al. 2011; Lierler and Lifschitz 2009; Baselice and Bonatti 2010; Greco et al. 2013).",
      "startOffset" : 93,
      "endOffset" : 231
    }, {
      "referenceID" : 2,
      "context" : "A lot of work has been made for identifying program classes for which reasoning is decidable (Alviano et al. 2011; Alviano et al. 2010; Calimeri et al. 2011; Lierler and Lifschitz 2009; Baselice and Bonatti 2010; Greco et al. 2013).",
      "startOffset" : 93,
      "endOffset" : 231
    }, {
      "referenceID" : 9,
      "context" : "A lot of work has been made for identifying program classes for which reasoning is decidable (Alviano et al. 2011; Alviano et al. 2010; Calimeri et al. 2011; Lierler and Lifschitz 2009; Baselice and Bonatti 2010; Greco et al. 2013).",
      "startOffset" : 93,
      "endOffset" : 231
    }, {
      "referenceID" : 31,
      "context" : "A lot of work has been made for identifying program classes for which reasoning is decidable (Alviano et al. 2011; Alviano et al. 2010; Calimeri et al. 2011; Lierler and Lifschitz 2009; Baselice and Bonatti 2010; Greco et al. 2013).",
      "startOffset" : 93,
      "endOffset" : 231
    }, {
      "referenceID" : 6,
      "context" : "A lot of work has been made for identifying program classes for which reasoning is decidable (Alviano et al. 2011; Alviano et al. 2010; Calimeri et al. 2011; Lierler and Lifschitz 2009; Baselice and Bonatti 2010; Greco et al. 2013).",
      "startOffset" : 93,
      "endOffset" : 231
    }, {
      "referenceID" : 26,
      "context" : "A lot of work has been made for identifying program classes for which reasoning is decidable (Alviano et al. 2011; Alviano et al. 2010; Calimeri et al. 2011; Lierler and Lifschitz 2009; Baselice and Bonatti 2010; Greco et al. 2013).",
      "startOffset" : 93,
      "endOffset" : 231
    }, {
      "referenceID" : 40,
      "context" : "ASP grounders Lparse (Syrjänen 1998) and versions up to 3.",
      "startOffset" : 21,
      "endOffset" : 36
    }, {
      "referenceID" : 21,
      "context" : "0 of Gringo (Gebser et al. 2007) accept programs respecting some syntactic domain restrictions and are able to deal with some restricted versions of functions.",
      "startOffset" : 12,
      "endOffset" : 32
    }, {
      "referenceID" : 15,
      "context" : "DLV grounder (Faber et al. 2012) and Gringo (since version 3.",
      "startOffset" : 13,
      "endOffset" : 32
    }, {
      "referenceID" : 19,
      "context" : "0) (Gebser et al. 2011) only require programs to be safe and can deal with all programs having a finite instantiation.",
      "startOffset" : 3,
      "endOffset" : 23
    }, {
      "referenceID" : 43,
      "context" : "Current version (Weinzierl 2013) uses must-be-true propagation and tries to introduce methods for conflict-driven learning of non-ground rules:",
      "startOffset" : 16,
      "endOffset" : 32
    }, {
      "referenceID" : 19,
      "context" : "10) (Gebser et al. 2011; Gebser et al. 2012), DLV Dec 16 2012 (Leone et al.",
      "startOffset" : 4,
      "endOffset" : 44
    }, {
      "referenceID" : 20,
      "context" : "10) (Gebser et al. 2011; Gebser et al. 2012), DLV Dec 16 2012 (Leone et al.",
      "startOffset" : 4,
      "endOffset" : 44
    }, {
      "referenceID" : 30,
      "context" : "2012), DLV Dec 16 2012 (Leone et al. 2006), GASP (june 2009) (Dal Palù et al.",
      "startOffset" : 23,
      "endOffset" : 42
    }, {
      "referenceID" : 13,
      "context" : "2009) and OMiGA Dec 3 2012 (Dao-Tran et al. 2012).",
      "startOffset" : 27,
      "endOffset" : 49
    }, {
      "referenceID" : 13,
      "context" : "Cutedge problem cutedge program is proposed in (Dao-Tran et al. 2012): given a random graph with 100 vertices and N edges, each answer set is obtained by deleting an edge and compute some transitive closure on the remaining edges.",
      "startOffset" : 47,
      "endOffset" : 69
    }, {
      "referenceID" : 18,
      "context" : "4 iClingo (Gebser et al. 2008) was created to address this specific problem.",
      "startOffset" : 10,
      "endOffset" : 30
    }, {
      "referenceID" : 10,
      "context" : "On the other hand, we plan to fully respect the core language ASP (Calimeri et al. 2014) by introducing, among others, minimization / maximization and aggregates and extend it by introducing existentially quantified variables in multi-head rules to encode fragments of Description Logics which are logical formalisms for ontologies and the Semantic Web.",
      "startOffset" : 66,
      "endOffset" : 88
    } ],
    "year" : 2017,
    "abstractText" : "The natural way to use Answer Set Programming (ASP) to represent knowledge in Artificial Intelligence or to solve a combinatorial problem is to elaborate a first order logic program with default negation. In a preliminary step this program with variables is translated in an equivalent propositional one by a first tool: the grounder. Then, the propositional program is given to a second tool: the solver. This last one computes (if they exist) one or many answer sets (stable models) of the program, each answer set encoding one solution of the initial problem. Until today, almost all ASP systems apply this two steps computation. In this article, the project ASPeRiX is presented as a first order forward chaining approach for Answer Set Computing. This project was amongst the first to introduce an approach of answer set computing that escapes the preliminary phase of rule instantiation by integrating it in the search process. The methodology applies a forward chaining of first order rules that are grounded on the fly by means of previously produced atoms. Theoretical foundations of the approach are presented, the main algorithms of the ASP solver ASPeRiX are detailed and some experiments and comparisons with existing systems are provided.",
    "creator" : "LaTeX with hyperref package"
  }
}