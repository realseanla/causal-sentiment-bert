{
  "name" : "1601.03095.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Submodular Optimization under Noise",
    "authors" : [ "Avinatan Hassidim", "Yaron Singer" ],
    "emails" : [ "avinatan@cs.biu.ac.il", "yaron@seas.harvard.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "• For a cardinality constraint k ≥ 2, there is an approximation algorithm whose approximation ratio is arbitrarily close to 1− 1/e;\n• For k = 1 there is an algorithm whose approximation ratio is arbitrarily close to 1/2. No randomized algorithm can obtain an approximation ratio better than 1/2 + o(1);\n• If the noise is adversarial, no non-trivial approximation guarantee can be obtained.\n∗Supported by ISF 1241/12; †Supported by NSF grant CCF-1301976, CAREER CCF-1452961, Google Faculty Research Award, Facebook Faculty\nAward.\nar X\niv :1\n60 1.\n03 09\n5v 3\n[ cs\n.D S]\n4 N\nov 2\nContents"
    }, {
      "heading" : "1 Introduction 1",
      "text" : "1.1 Main result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.3 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.4 Paper organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5"
    }, {
      "heading" : "2 Optimization for Large k 6",
      "text" : "2.1 The Smooth Greedy Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.1 The algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.2 Smoothing guarantees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.1.3 Approximation guarantee . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2 Slick Greedy: Optimal Approximation for Sufficiently Large k . . . . . . . . . . . . . 9\n2.2.1 The algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2.2 Generalizing guarantees of smooth greedy . . . . . . . . . . . . . . . . . . . . 10\n2.2.3 The smooth comparison procedure . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2.2.4 Approximation guarantee of SLICK GREEDY . . . . . . . . . . . . . . . . . . . 11"
    }, {
      "heading" : "3 Optimization for Small k 12",
      "text" : "3.1 Combinatorial averaging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.2 The Sampled Mean Greedy Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n3.3 Smoothing Guarantees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n3.4 Approximation Guarantee in Expectation . . . . . . . . . . . . . . . . . . . . . . . . . 14\n3.5 From Expectation to High Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . 15"
    }, {
      "heading" : "4 Optimization for Very Small k 16",
      "text" : "4.1 Smoothing Guarantees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n4.2 An Approximation Algorithm for Very Small k . . . . . . . . . . . . . . . . . . . . . . 16\n4.3 Information Theoretic Lower Bounds for Constant k . . . . . . . . . . . . . . . . . . . 16\n5 Extensions 17\n5.1 Additive Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n5.2 Marginal Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n5.3 Correlated Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n5.4 Information Degradation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n5.5 Approximate Submodularity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21"
    }, {
      "heading" : "6 Impossibility for Adversarial Noise 23",
      "text" : ""
    }, {
      "heading" : "7 More related work 26",
      "text" : ""
    }, {
      "heading" : "8 Acknowledgements 28",
      "text" : "Appendices 36"
    }, {
      "heading" : "A Combinatorial Smoothing 37",
      "text" : ""
    }, {
      "heading" : "B Optimization for Large k 45",
      "text" : ""
    }, {
      "heading" : "C Optimization for Small k 60",
      "text" : ""
    }, {
      "heading" : "D Optimization for Very Small k 72",
      "text" : ""
    }, {
      "heading" : "E Noise Distributions 77",
      "text" : "F Additional Examples 79"
    }, {
      "heading" : "1 Introduction",
      "text" : "In this paper we study the effects of error and noise on submodular optimization. A function f : 2N → R defined on a ground set N of size n is submodular if for any S, T ⊆ N :\nf(S ∪ T ) ≤ f(S) + f(T )− f(S ∩ T )\nEquivalently, submodularity can be defined in terms of a natural diminishing returns property. For any A,B ⊆ N let fA(B) = f(A ∪B)− f(A), then f is submodular if ∀S ⊆ T ⊆ N, a ∈ N \\ T :\nfS(a) ≥ fT (a).\nIn general, submodular functions may require a representation that is exponential in the size of the ground set and the assumption is that we are given access to a value oracle which given a set S returns f(S). It is well known that submodular functions admit desirable approximation guarantees and are heavily used in applications such as market design, data mining, and machine learning (see related work). For the classic problem of maximizing a monotone (i.e. S ⊆ T =⇒ f(S) ≤ f(T )) submodular function under a cardinality constraint, the greedy algorithm which iteratively adds the element with largest marginal contribution into the solution obtains a 1− 1/e approximation [82] which is optimal unless using exponentially-many queries [81] or P=NP [35].\nSince submodular functions can be exponentially representative, it may be reasonable to assume that there are cases where one faces some error in their evaluation. In market design where submodular functions often model agents’ valuations for goods, it seems reasonable to assume that agents do not precisely know their valuations. Even with compact representation, evaluation of a submodular function may be prone to error. In learning and sketching submodular functions, the algorithms produce an approximate version of the function [48, 8, 7, 4, 42, 43, 30, 31, 41, 44, 6].\nCan we retain desirable approximation guarantees in the presence of error?\nFor f : 2N → R and > 0 we say that f̃ : 2N → R is -erroneous if for every set S ⊆ N , it respects:\n(1− )f(S) ≤ f̃(S) ≤ (1 + )f(S)\nFor the canonical problem of maxS:|S|≤k f(S), one can trivially approximate the solution within a factor of 1− 1+ using ( n k ) queries with an -erroneous oracle by simply evaluating all possible subsets and returning the best solution (according to the erroneous oracle). Is there a polynomial-time algorithm that can obtain desirable approximation guarantees for maximizing a monotone submodular function under a cardinality constraint given access to -erroneous oracles? In Appendix F we sketch an example showing that the celebrated greedy algorithm fails to obtain an approximation strictly better than O(1/k) for any constant > 0 when given access to an -erroneous oracle f̃ instead of f . It turns out that this is not intrinsic to greedy. No algorithm is robust to small errors.\nTheorem (6.1). No randomized algorithm can obtain an approximation strictly better than O(n−1/2+δ) to maximizing monotone submodular functions under a cardinality constraint using enδ/n queries to an -erroneous oracle, for any fixed , δ < 1/2, with high probability.\n1\nSince desirable guarantees are generally impossible with erroneous oracles, we seek natural relaxations of the problem. The first could be to consider stricter classes of functions. It is trivial to show for example, that additive functions (i.e. f(S) = ∑ a∈S f(a)) allow us to obtain a 1− 1+ approximation when given access to -erroneous oracles. Unfortunately, it seems like there are not many interesting classes of submodular functions that enjoy these properties. In fact, our impossibility result applies to very simple affine functions, and even coverage functions like the example in Appendix F. An alternative relaxation is to consider error models that are not necessarily adversarial.\nNoisy oracles. We can equivalently say that f̃ : 2N → R is -erroneous if for every S ⊆ N we have that f̃(S) = ξSf(S) for some ξS ∈ [1 − , 1 + ]. The lower bound stated above applies to the case in which the error multipliers ξS are adversarially chosen. A natural question is whether some relaxation of the adversarial error model can lead to possibility results.\nDefinition. For a function f : 2N → R we say that f̃ : 2N → R is a noisy oracle if there exists some distribution D s.t. f̃(S) = ξSf(S) where ξS is independently drawn from D for every S ⊆ N .\nNote that the noisy oracle defined above is consistent: for any S ⊆ N the noisy oracle returns the same answer regardless of how many times it is queried. When the noisy oracle is inconsistent, mild conditions on the noise distribution allow the noise to essentially vanish after logarithmically-many queries, reducing the problem to standard submodular maximization (see e.g. [59, 91]). Consistency implies that the noise is arbitrarily correlated for a given set in different time steps, but i.i.d between different sets. In fact, we will later generalize the model to the case in which ξS and ξT are i.i.d only when S and T are sufficiently far, and arbitrarily correlated otherwise (see Section 1.3). At this point, we are interested in identifying a natural non worst-case model of corrupted or approximately submodular functions that is amendable to optimization.\nWe will be interested in a class of distributions that avoids trivialities like D ⊆ {0} and is yet general enough to contain natural distributions. In this paper we define a class which we call generalized exponential tail distributions that contains Gaussian, Exponential, and distributions with bounded support which are independent of n (o.w. optimization is impossible, see Appendix E). Note that optimization in this setting always requires that n is sufficiently large. For example, if for every S the noise is s.t. ξS = 2100 with probability 1/2100 and 0 otherwise, but n = 50, it is likely that the noisy oracle will always return 0, in which case we cannot do better than selecting an element at random. Throughout the paper we assume that n is sufficiently large.\nDefinition. A noise distribution D has a generalized exponential tail if there exists some x0 such that for x > x0 the probability density function ρ(x) = e−g(x), where g(x) = ∑ i aix\nαi . We do not assume that all the αi’s are integers, but only that α0 ≥ α1 ≥ . . ., and that α0 ≥ 1. If D has bounded support we only require that either it has an atom at its supremum, or that ρ is continuous and non zero at the supremum.\nFor simplicity, one can always consider the special case where D ⊆ [1 − , 1 + ], which implies that two sets whose true values are close will remain close in the noisy evaluation. Even when the noise distribution is uniform in [1− , 1 + ] it is easy to show that the greedy algorithm fails (see Appendix F). The question is whether provable guarantees are achievable in this model.\n2"
    }, {
      "heading" : "1.1 Main result",
      "text" : "Our main result is that for the problem of optimizing a monotone submodular function under a cardinality constraint, near-optimal approximations are achievable under noise.\nTheorem. For any monotone submodular function there is a polynomial-time algorithm which optimizes the function under a cardinality constraint k > 2 and obtains an approximation ratio that is w.h.p arbitrarily close to 1− 1/e using access to a generalized exponential tail noisy oracle of the function.\nThis proof is a summary of three results, each for a different regime of k. For any > 0 we show:\n• 1 − 1/e − guarantee for large k: we say that k is large when k ∈ Ω(log log n/ 2). For k that is sufficiently larger than log logn/ 2 we give a deterministic algorithm which obtains a (1− 1/e− ) approximation guarantee w.h.p over the noise distribution;\n• 1 − 1/e − guarantee for small k: we say that k is small when k ∈ O(log log n) ∩ Ω(1/ ). In this regime the problem is surprisingly harder. We give a different deterministic algorithm which achieves the coveted (1− 1/e− ) guarantee, w.h.p. over the noise distribution;\n• Guarantees for very small k: We say that k is very small when it is an arbitrarily small constant. For this case we give a randomized algorithm whose approximation ratio is 1−1/k− w.h.p. over the randomization of the algorithm and the noise distribution. Note that this gives 1− 1/e− for any k > 2, and 1/2− for k = 2. We also give a k/(k+ 1) approximation which holds in expectation over the randomization of the algorithm. This achieves 1 − 1/e for k = 2 and 1/2 for k = 1. For k = 1 no randomized algorithm can obtain an approximation ratio better than 1/2 +O(1/ √ n) and (2k − 1)/2k +O(1/ √ n) for general k.\nAt their core, the algorithms are variants of the classic greedy algorithm. In the presence of noise, greedy fails since it cannot identify the set whose value is maximal in each iteration. To handle noise, we apply a natural approach we call smoothing. In general, by selecting a family of sets H we can define a surrogate function F (S) = ∑ H′∈H f(S ∪ H ′) and its noisy analogue\nF̃ (S) = ∑\nH′∈H f̃(S ∪ H ′) which we can evaluate. Intuitively, when H is sufficiently large and chosen appropriately, submodularity and monotonicity can be used to argue that F̃ (S) ≈ F (S). Thus, smoothing essentially makes the noise disappear and instead leaves us to deal with the implications of optimizing with the surrogate F rather than f . In that sense, a large part of the challenge is in using optimization over the surrogate F to approximate the optimum over f , i.e.:\n• Large k. In this regime, we first define SMOOTH-GREEDY which takes an arbitrary set H of size log log n and runs the greedy algorithm with the surrogate F̃ = ∑ H′⊆H f̃(T ∪ H ′) on\nN \\H . In the analysis we show that its output together with H is arbitrarily close to 1− 1/e of the optimal solution evaluated on fH (not f ). The SLICK-GREEDY algorithm runs multiple instantiations of a slightly modified version of SMOOTH-GREEDY with different smoothing sets, and obtains a guarantee arbitrarily close to 1− 1/e of the true optimum;\n• Small k. In this regime, we use a modified version of greedy which adds a bundle of O(1/ ) elements in each iteration. For each such bundleB we define a surrogate F̃ with a smoothing\n3\nneighborhood of elements which are at distance 2 on the {0, 1}n hypercube from B. In each iteration SM-GREEDY identifies the bundleAwhich maximizes F̃ , but doesn’t take it. Taking a random bundle Â from the smoothing neighborhood of A gives the 1− 1/e guarantee but in expectation. To obtain the result w.h.p. SM-GREEDY takes the bundle Â which maximizes f̃(B), over all bundlesB in the smoothing neighborhood ofA. The analysis is then quite technical and strongly leverages the properties of the noise distribution and that k ∈ O(log log n). It is for this reason it is crucial that SLICK-GREEDY applies to k ∈ Ω(log logn);\n• Very small k. In this case we consider bundles of size k and smoothing with singletons."
    }, {
      "heading" : "1.2 Extensions",
      "text" : "One of the appealing aspects of the noise model and the algorithms, is that they can easily be extended to a rich variety of related models. In Section 5 we discuss application to additive noise, marginal noise, correlated noise, information degradation, and approximate submodularity, ."
    }, {
      "heading" : "1.3 Applications",
      "text" : "• Optimization under noise. When considering optimization under noise, queries can be independent or correlated in time and in space. For f : 2N → R the noisy oracle is defined as f̃(S) = ξS(t)f(S) where ξS(t) ∼ D, for every step the oracle is queried t ∈ N and S ⊆ N .\nDefinition. Noise is i.i.d in time if ξS(t) and ξS(t′) are independent for any t 6= t′ ∈ N and S ⊆ N . Similarly, we can say that noise is i.i.d in in space if ξS(t) and ξT (t′) for any S 6= T and t, t′ ∈ N. The noise distribution is correlated in time (space) if it is not independent in time (space).\nThe case in which the oracle is inconsistent is one where the noise is i.i.d in time and in space. From an algorithmic perspective this problem is largely solved, as discussed above. From Theorem 6.1 we know that there is no poly-time approximation algorithm for the case in which the errors are arbitrarily correlated in time and in space, even when the support of the noise distribution is arbitrarily small. The model we describe assumes the noise is arbitrarily correlated in time, but i.i.d in space. In Section 5 we show how one can relax this assumption. In particular, we show how to generalize the algorithms to obtain approximation ratios arbitrarily close to 1 − 1/e in a noise model where ξS(t) and ξT (t′) are arbitrarily correlated in time and in space for any t, t′ ∈ N and S, T for which |S4T | ∈ O( √ k) when k ∈ Ω(log logn) and |S4T | ∈ O(1) when k ∈ O(log log n). To the best of our knowledge, this is the first step towards studying submodular optimization under any correlation.\n• Maximizing approximately submodular functions. There are cases where one may wish to optimize an approximately submodular function. Theorem 6.1 implies that being arbitrarily close to a submodular function is not sufficient. In statistics and learning theory, to model the fact that data is generated by a function that is approximately in a class of well behaved functions, the function generating the data f̃ is typically assumed to be a noisy version of a function f from a well-behaved class of functions [53, 97, 88]:\nf̃(x) = f(x) + ξx,\n4\nwhere ξx is an i.i.d sample drawn from some distribution D. In regression problems for instance, one assumes that the data is generated by f̃(x) = wᵀx + ξx. This model captures the idea that some phenomena may not exactly behave in a linear manner, but can be approximated by such a model. Making a good prediction then involves optimizing the noisy model. This therefore seems like a natural model to study approximate submodularity, especially in light of Theorem 6.1. Notice that in this case we would be interested in the optimization problem: maxS:|S|≤k f̃(S). In Section 5 we describe a black-box reduction which allows one to use the algorithms described here to get optimal guarantees.\n• Active learning. In active learning one assumes a membership oracle that can be queried to obtain labeled data [3]. In noise-robust learning, the task is to get good approximations to the noise-free target f when the examples are corrupted by some noise. In this model the assumption is that noise is consistent and i.i.d, exactly as in our model. That is, we observe f̃(x) + ξx where x is drawn i.i.d from D and multiple queries return the same answer (see e.g. [49, 55, 89, 56, 13, 40]). Our results apply to additive noise, and thus apply to active learning with noisy membership queries of submodular functions. One example application of active learning where the function is submodular is experimental design [70, 69, 54].\n• Learning and sketching. In learning and sketching the goal is to generate a surrogate function which approximates the submodular function well (see e.g. [48, 8, 7, 4, 42, 43, 30, 31, 41, 44, 6]). Theorem 6.1 implies that a surrogate which approximates a submodular function arbitrarily well may be inapproximable. Our main result shows that if when sets are sufficiently far the surrogate approximates the function via independent noise, then one can use the surrogate for optimization. This can therefore be used as a stricter benchmark for learning and sketching which allows optimizing a function learned or sketched from data."
    }, {
      "heading" : "1.4 Paper organization",
      "text" : "The main technical contribution of the paper is the algorithms for the three different regimes of k. The exposition of the algorithms is contained in sections 2, 3, and 4, which can be read independently from each other. For each algorithm, we suppress proofs and additional lemmas to the corresponding section in the appendix. All the algorithms employ smoothing arguments which can be found in Appendix A. The smoothing arguments are used as a black-box in the proofs of each algorithm, and are not required for reading the main exposition. In Section 5 we discuss extensions of the algorithms to related models. In Section 6 we prove the result for adversarial noise. Discussion about additional related work is in Section 7.\n5"
    }, {
      "heading" : "2 Optimization for Large k",
      "text" : "In this section we describe the SLICK-GREEDY algorithm whose approximation guarantee is arbitrarily close to 1 − 1/e for sufficiently large k. The algorithm is deterministic and for any desired degree of accuracy > 0 can be applied when the cardinality constraint k is in Ω(log log n/ 2), or more specifically when k ≥ 3168 log log n/ 2. We first describe and analyze the SMOOTH-GREEDY algorithm. This algorithm is then used as a subroutine by the SLICK-GREEDY algorithm."
    }, {
      "heading" : "2.1 The Smooth Greedy Algorithm",
      "text" : "We begin by describing the smoothing technique used by SMOOTH-GREEDY. We select an arbitrary set H and for a given element a, the smoothing neighborhood is simply H = {H ′ ⊆ H : H ′ ∪ a}. Throughout the rest of this section we assume that H is an arbitrary set of size `, where ` depends on k. In the case where k ≥ 2400 log nwe will use ` = 25 log n, and when k < 2400 log nwe will use ` = 33 log log n 1. The precise choice for ` will become clear later in this section. Intuitively, ` is on the one hand small enough so that we can afford to sacrifice ` elements for smoothing the noise, and on the other hand ` is large enough so that taking all its subsets gives us a large smoothing neighborhood which enables applying concentration bounds.\nDefinition. For a set S ⊆ N and some fixed set H ⊆ N of size `, we use H(1), . . . ,H(t) to denote all the subsets of H and k′ = k − `. The smooth value, noisy smooth value and smooth marginal contribution are, respectively:\n(1) F (S ∪ a) := E [ f(S ∪ (H(i) ∪ a) ] =\n1\nt t∑ i=1 f ( S ∪ (H(i) ∪ a) ) ;\n(2) F̃ (S ∪ a) := E [ f̃(S ∪ (H(i) ∪ a) ] =\n1\nt t∑ i=1 f̃ ( S ∪ (H(i) ∪ a) ) ;\n(3) FS(a) := E [ fS((H (i) ∪ a)) ] = 1\nt t∑ i=1 fS ( H(i) ∪ a ) ."
    }, {
      "heading" : "2.1.1 The algorithm",
      "text" : "The smooth greedy algorithm is a variant of the standard greedy algorithm which replaces the procedure of adding argmaxa∈N f(S ∪ a) with its smooth analogue. The algorithm receives a set of elements H of size `, initializes S = ∅ and at every stage adds to S the element a /∈ H for which the smooth noisy value F̃ (S ∪ a) is largest. A formal description is added below.\nOverview of the analysis. At a high level, the idea behind the analysis is to compare the performance of the solution returned by the algorithm against an optimal solution which ignores the\n1W.l.o.g. we assume that k < n − 25 logn as for sufficiently large n this then implies that k ≥ (1 − )n and by submodularity optimizing with k′ = n− 25 logn suffices to get the 1− 1/e− guarantee for any fixed > 0.\n6\nAlgorithm 1 SMOOTH-GREEDY Input: budget k, set H\n1: S ← ∅ 2: while |S| < k − |H| do 3: S ← S ∪ arg maxa/∈H F̃ (S ∪ a) 4: end while 5: return S\nvalue of H and any of its partial substitutes. More specifically, let OPT denote the value of the optimal solution with k elements evaluated on f and OPTH denote the value of the optimal solution with k′ = k − ` elements evaluated on fH , where fH(T ) = f(T ∪H) − f(H). Essentially, we will show that at every step SMOOTH-GREEDY selects an element whose marginal contribution is larger than that of an element from the optimal solution evaluated on fH (we illustrate this idea in Figure 1). Together with an inductive argument this suffices for a constant factor approximation.\nRelevant iterations. One of the artifacts of noise is that our comparisons are not precise. Specifically, when we select an element that maximizes F̃ (S ∪ a), our smoothing guarantee will be that this element respects FS(a) ≥ (1− δ) maxb/∈H FS(b) for δ > 0 that depends on and k. This can be guaranteed only for an iteration where two conditions are met: (i) there is at least a single element not yet selected (and not in H) whose marginal contribution is at least /k fraction of OPTH , and (ii) OPTH is sufficiently large in comparison to OPT. We call such iterations -relevant.\nDefinition. For a given iteration of SMOOTH-GREEDY let S be the set of elements selected in previous iterations. The iteration is -relevant if (i) maxb/∈H fH∪S(b) ≥ ·OPTHk and (ii) OPTH ≥ OPT e .\nWe will analyze SMOOTH-GREEDY in the case where the iterations are -relevant as it allows applying the smoothing arguments. In the analysis we will then ignore iterations that are not -relevant at the expense of a negligible loss in the approximation guarantee. The main steps are:\n1. In Lemma 2.1 we show that in each -relevant iteration the (non-noisy) smooth marginal contribution of the element selected in that iteration by the algorithm is w.h.p. an arbitrarily good approximation to maxb/∈H FS(b). To do so we need claims B.1, B.2 and B.3;\n2. Next, in Claim 2.3 we show that the element a whose smooth marginal contribution FS(a) is maximal has true marginal contribution fS(a) that is roughly a k′th fraction of the marginal contribution of the optimal solution over fH ;\n3. Finally, in Lemma 2.4 we apply a standard inductive argument to show that the fact that the algorithm selects an element with large smooth value in each step results in an approximation arbitrarily close to 1− 1/e to OPTH (not OPT). In Corollary B.4 we show that the bound against OPTH can already be used to give a constant factor approximation to OPT. To get arbitrarily close to 1− 1/e, SLICK-GREEDY executes multiple instantiations of a generalization of SMOOTH-GREEDY as later described in Section 2.2.\n7"
    }, {
      "heading" : "2.1.2 Smoothing guarantees",
      "text" : "The first step is to prove Lemma 2.1. This lemma shows that at every step as SMOOTH-GREEDY adds the element that maximizes the noisy value argmaxa/∈H F̃ (S ∪ a), that element nearly maximizes the (non-noisy) smooth marginal contribution FS , with high probability.\nLemma 2.1. For any fixed > 0, consider an -relevant iteration of SMOOTH-GREEDY where S is the set of elements selected in previous iterations and a ∈ arg maxb/∈H F̃ (S ∪ b). Then for δ = 2/4k and sufficiently large n we have that w.p. ≥ 1− 1/n4:\nFS(a) ≥ (1− δ) max b/∈H FS(b).\nTo prove the above lemma we use claims B.1, B.2, and B.3. The statements and proofs can be found in Appendix B and are best understood after reading the smoothing section in Appendix A."
    }, {
      "heading" : "2.1.3 Approximation guarantee",
      "text" : "Lemma 2.1 lets us forget about noise, at least for the remainder of the analysis of SMOOTH-GREEDY. We can now focus on the consequences of selecting an element a which (up to factor 1− δ) maximizes FS rather than the true marginal contribution fS .\nClaim 2.2. For any > 0, let δ ≤ 2/4k. Suppose that the iteration is -relevant and let b? ∈ argmaxb/∈H fH∪S(b). If FS(a) ≥ (1− δ)FS(b?), then:\nfS(a) ≥ (1− )fH∪S(b?).\nThe principle is similar to Claim B.1. In this version we have a weaker condition since FS(a) is not greater than FS(b?) but rather (1 − δ)FS(b?), but the claim is less general as it only needs to hold for b?. We therefore use a slightly different approach to prove this claim (see Appendix B).\n8\nClaim 2.3. For any fixed > 0, consider an -relevant iteration of SMOOTH-GREEDY with S as the elements selected in previous iterations. Let a ∈ argmaxb/∈H F̃ (S ∪ b). Then, w.p. ≥ 1− 1/n4:\nfS(a) ≥ ( 1− )[ 1\nk′\n( OPTH − f(S) )] .\nThe proof is in Appendix B. We can now state the main lemma of this subsection.\nLemma 2.4. Let S be the set returned by SMOOTH-GREEDY and H its smoothing set. Then, for any fixed > 0 when k ≥ 3`/ with probability of at least 1− 1/n3 we have that:\nf(S ∪H) ≥ (1− 1/e− /3)OPTH .\nTo prove the lemma we show that if OPTH < OPT/e then H alone provides the approximation guarantee. Otherwise we can apply Claim 2.3 using a standard inductive argument to show that S ∪H provides the approximation. The subtle yet crucial aspect of the proof is that the inductive argument is applied to analyze the quality of the solution against the optimal solution for fH and not against the optimal solution on f . The proof is in Appendix B.\nAs we will soon see, Lemma 2.4 plays a key role in the analysis of the SLICK-GREEDY algorithm. It is worth noting that this lemma can also be used to show that SMOOTH-GREEDY alone provides a constant (≈ 0.387) albeit suboptimal approximation guarantee (Corollary B.4)."
    }, {
      "heading" : "2.2 Slick Greedy: Optimal Approximation for Sufficiently Large k",
      "text" : "The reason SMOOTH-GREEDY cannot obtain an approximation arbitrarily close to 1 − 1/e is due to the fact that a substantial portion of the optimal solution’s value may be attributed to H . This would be resolved if we had a way to guarantee that the contribution of H is small. The idea behind SLICK-GREEDY is to obtain this type of guarantee. Intuitively, by running a large albeit constant number of instances of SMOOTH-GREEDY with different smoothing sets, selecting the “best” solution will ensure the contribution of the smoothing set is relatively minor."
    }, {
      "heading" : "2.2.1 The algorithm",
      "text" : "We can now describe the SLICK-GREEDY algorithm which is the main result of this section. Given a constant > 0 we set δ = /6 and generate arbitrary sets H1, . . . ,H1/δ, each of size ` s.t. Hi ∩ Hj = ∅ for every i, j ∈ [1/δ]. We then run a modified version of SMOOTH-GREEDY 1/δ times: in each iteration j we initialize SMOOTH-GREEDY with Rj = ∪i 6=jHi 2 and use Hj to generate the smoothing neighborhood. We denote this as SMOOTH-GREEDY(k,Rj , Hj). We then compare the solution Tj = Sj∪Hj to the best Ti = Si∪Hi we’ve seen so far using a procedure we call SMOOTHCOMPARE described below. The SMOOTH-COMPARE procedure compares Ti and Tj by using a set Hij s.t. Hij ∩ (Tj ∪Ti) = ∅ and |Hij | = `. If Ti wins, the procedure returns Ti and otherwise returns Tj . The SLICK-GREEDY then returns the set Ti that survived the SMOOTH-COMPARE tournament.\n2By initializing the SMOOTH-GREEDY with Rj we mean that the first iteration begins with S = Rj rather than S = ∅ and following the initialization the algorithm greedily adds k − |Rj | − |Hj | elements.\n9\nAlgorithm 2 SLICK-GREEDY Input: budget k\n1: Select `/δ elements in N and partition them into disjoint sets of equal size H1 . . . , H1/δ 2: Ti ← ∅ 3: for j ∈ [1/δ] do 4: Rj ← ∪i 6=jHi 5: Tj ← SMOOTH-GREEDY(k,Rj , Hj) ∪Hj 6: Hij ← arbitrary set of ` elements disjoint from Ti ∪ Tj 7: Ti ← SMOOTH-COMPARE({Ti, Tj}, Hij) 8: end for 9: return Ti\nOverview of the analysis. Consider the smoothing sets H1, . . . ,H1/δ. Let Hl be the smoothing set whose marginal contribution to the others is minimal, i.e. Hl ∈ argmini∈[1/δ] fRi(Hi). Notice that from submodularity we are guaranteed that fRl(Hl) ≤ δf(Rl ∪Hl). In this case, the fact that the marginal contribution of Hl to the rest of the smoothing sets Rl is small, together with the fact that the solution is initialized with Rl, enables the tight analysis. The two main steps are:\n1. In Lemma 2.5 we show that w.h.p. Tl provides an approximation arbitrarily close to (1−1/e). Intuitively, this happens since the marginal contribution of Hl to the rest of the smoothing sets Rl = ∪iHi \\ Hl is small, and since the solution to SMOOTH-GREEDY is initialized with Rl, losing the value of Hl is negligible. The proof relies on Claim B.5 and Lemma B.7 that generalize the guarantees of SMOOTH-GREEDY to the case it is initialized (see Appendix);\n2. We then describe and analyze the SMOOTH-COMPARE procedure. In the absence of noise, one can simply select the set whose value is largest. To overcome noise, we run a tournament to extract the solution whose value is approximately largest, or at least arbitrarily close to (1− 1/e)OPT. Specifically, we prove that w.h.p. the set Ti that wins the SMOOTH-COMPARE tournament (i.e. the set Ti returned by SLICK-GREEDY) satisfies f(Ti) ≥ (1− /3) min{f(Tl), (1− 1/e− 2 /3)OPT}. Since f(Tl) is arbitrarily close to (1− 1/e)OPT, this concludes the proof."
    }, {
      "heading" : "2.2.2 Generalizing guarantees of smooth greedy",
      "text" : "Lemma 2.5. Let Sl be the set returned by SMOOTH-GREEDY that is initialized withRl andHl its smoothing set. Then, for any fixed > 0 when k ≥ 36`/ 2 w.p. at least 1− 1/n3 we have that:\nf(Sl ∪Hl) ≥ (1− 1/e− 2 /3)OPT."
    }, {
      "heading" : "2.2.3 The smooth comparison procedure",
      "text" : "We can now describe the SMOOTH-COMPARE procedure we use in the algorithm. For a given set Hij ⊆ N of size ` and two sets Ti, Tj ⊆ N \\ Hij , we compare f̃(Ti ∪ H ′ij) with f̃(Tj ∪ H ′ij) for all H ′ij ⊂ Hij . We select Ti if in the majority of the comparisons with H ′ij ⊂ Hij (breaking ties lexicographically) we have that f̃(Ti ∪H ′ij) ≥ f̃(Tj ∪H ′ij), and otherwise we select Tj .\n10\nAlgorithm 3 SMOOTH-COMPARE Input: Ti, Tj , Hij ⊆ N \\ (Ti ∪ Tj),\n1: Compare f̃(Ti ∪H ′ij) with f̃(Tj ∪H ′ij) for all H ′ij ⊂ Hij 2: if Ti won the majority of comparisons return Ti otherwise return Tj\nLemma 2.6. Assume k ≥ 96`/ 2. Let Ti be the set that won the SMOOTH-COMPARE tournament. Then, with probability at least 1− 1/n2:\nf(Ti) ≥ (\n1− 3\n) min {( 1− 1\ne − 2 3\n) OPT, max\nj∈[1/δ] f(Tj)\n}\nThe proof of this lemma has two parts.\n1. First we show in Claim B.8 that if a set Ti has moderately larger value than another set Tj (more specifically, if the gap is 1 − δ/3) then as long as f(Tj) is not arbitrarily close to (1−1/e)OPT then f(Ti∪H ′ij) is larger than f(Tj∪H ′ij), for anyH ′ij ⊆ Hij . At a high level, this is because elements inH ′ij are candidates for SMOOTH-GREEDY and the fact that they are not selected indicates that their marginal contribution to Tj = Sj ∪Hj is low. Thus, elements in H ′ij cannot add much value, and since |Hij | k adding subsets of Hij does not distort the comparison by much. If f(Tj) is arbitrarily close to (1− 1/e)OPT, we may have that Tj beats Ti, but this would still ultimately result in an approximation arbitrarily close to 1− 1/e;\n2. The next step (Claim B.9) then shows that if for every H ′ij we have f(Ti ∪H ′ij) ≥ f(Tj ∪H ′ij) then with high probability Ti wins the comparison against Tj in SMOOTH-COMPARE.\nUsing these two parts we then conclude since we are running the SMOOTH-COMPARE tournament between 1/δ sets, the winner is an (1 − δ/3)1/δ ≥ (1 − /3) approximation to the competing set with the highest value or a set whose approximation is arbitrarily close to 1− 1/e. The claims and proofs can be found in Appendix B."
    }, {
      "heading" : "2.2.4 Approximation guarantee of SLICK GREEDY",
      "text" : "Finally, putting everything together, we can prove the main result of this section (see Appendix ??).\nTheorem 2.1. Let f : 2N → R be a monotone submodular function. For any fixed > 0, when k ≥ 3168 log log n/ 2, then given access to a noisy oracle whose noise distribution has a generalized exponential tail, the SLICK-GREEDY algorithm returns a set which is a (1−1/e− ) approximation to maxS:|S|≤k f(S), with probability at least 1− 1/n.\n11"
    }, {
      "heading" : "3 Optimization for Small k",
      "text" : "When k is small we cannot use the smoothing technique from the previous section, since it requires including the smoothing set of size Θ(log log n) in the solution. In this section we describe the sampled mean method which can be applied to k ∈ Ω(1/ ) ∩O(log log n) and results in a 1− 1/e− approximation. This result is obtained by applying a greedy algorithm on a surrogate function F : 2N → R+ which is what we call the sampled mean of f . The use of the surrogate function makes it relatively easy to obtain the 1 − 1/e − approximation, albeit in expectation. The main technical challenge is the transition from a guarantee that holds in expectation to one that holds with high probability. This difficulty is what limits this method to be applicable only when k ranges between Ω(1/ ) and O(log log n), and heavily exploits the generalized exponential tail property."
    }, {
      "heading" : "3.1 Combinatorial averaging",
      "text" : "The sampled-mean method is based on averaging sets to find elements whose marginal contribution is high, which can then be greedily added to the solution. The intuition for this method comes from continuous optimization. Consider optimizing a function f : Rn → R given access to a noisy value oracle f̃ : Rn → R which for each point x ∈ Rn returns f̃(x) = ξxf(x) where ξx ∼ D. A natural approach would be to sample t points x1, . . . ,xt from an -ball B around x, for some small > 0, and estimate the value of x using the sampled mean:\nF̃ (x) := E [ f̃(x) ] = 1\nt ∑ xi∼B f̃(xi)\nUnder some smoothness assumptions on f , for sufficiently large t and small , concentration bounds kick in, and one can apply an optimization algorithm on F̃ to optimize f . The method in this section translates this idea to a combinatorial domain. To do so effectively, rather than considering singletons a ∈ N we obtain multidimensionality by considering bundles of size c ∈ O(1/ ).\nDefinition. Let f : 2N → R. For a set S ⊆ N and bundle A ⊆ N of fixed size c, we define Aij := (A \\ {ai}) ∪ {aj} for ai ∈ A and aj /∈ S ∪ A, and t = c(n − c − |S|). The mean value, noisy mean value, and mean marginal contribution of A given S are, respectively:\n(1) F (S ∪A) := E [f(S ∪Aij)] = 1\nt ∑ i∈A ∑ j /∈S∪A f(S ∪Aij);\n(2) F̃ (S ∪A) := E [ f̃(S ∪Aij) ] =\n1\nt ∑ i∈A ∑ j /∈S∪A f̃(S ∪Aij);\n(3) FS(A) := E [fS(Aij)] = 1\nt ∑ i∈A ∑ j /∈S∪A fS(Aij).\nThe above definition mimics the continuous case by considering a bundle of elements A of fixed size c (we will use c ≈ 1/ ) as a point, and the points in the -ball are modeled by all the sets Aij obtained by replacing an element from A with an element from N \\ (S ∪A). We illustrate this idea in Figure 2. Although the combinatorial analogue is not as well-behaved as the continuous case, the sampled mean approach defined here extracts some of its desirable properties.\n12"
    }, {
      "heading" : "3.2 The Sampled Mean Greedy Algorithm",
      "text" : "The SM-GREEDY begins with the empty set S and at every iteration considers all bundles of size c ∈ O(1/ ) to add to S. At every iteration, the algorithm first identifies the bundle A which maximizes the noisy mean value. After identifying A, it then considers all possible bundles Aij and takes the one whose noisy mean value is largest. We describe the algorithm formally below.\nAlgorithm 4 SM-GREEDY Input: budget k, precision > 0, c ∈ O(1 )\n1: S ← ∅ 2: while |S| < c · ⌊ k c ⌋ do 3: A← argmaxB:|B|=c F̃ (S ∪B) 4: S ← S ∪ arg maxi∈A,j /∈S∪A f̃(S ∪Aij) 5: end while 6: return S\nAt a high level, the major steps in the analysis can be described as follows.\n1. We begin with smoothing guarantees. In Lemma 3.2 we apply Lemma 3.1 as well as other arguments to show that w.h.p. in each iterationA ∈ argmaxB:|B|=c F̃ (S∪B) well approximates the bundle with maximal (non-noisy) mean marginal contribution argmaxB:|B|=c FS(B);\n2. Lemma 3.3 argues that if the marginal contribution fS(Â) of the set Âwe select at every iteration is close to the mean marginal contribution FS(A) we obtain an approximation arbitrarily close to 1− 1/e. This suffices for an approximation guarantee that holds in expectation;\n3. The last step is Lemma 3.4 which is the technical crux of this section. We show that taking Â ∈ argmaxi,j f̃(S∪Aij) in line 4 of the algorithm gives us, with sufficiently high probability that the marginal contribution fS(Â) is arbitrarily close to the mean marginal contribution FS(A). We can therefore invoke Lemma 3.3 and recover the optimal approximation guarantee."
    }, {
      "heading" : "3.3 Smoothing Guarantees",
      "text" : "We first show that the largest marginal contribution is well approximated by its mean contribution.\nLemma 3.1. For any > 0 and any set S ⊂ N , let A? ∈ arg maxA:|A|=1/ fS(A). Then:\n(1− ) fS(A?) ≤ FS(A?) ≤ fS(A?).\nThe proof is in Appendix C and exploits a natural property of submodular functions: the removal of a random element from a large set does not significantly affect its value, in expectation.\nSignificant iterations. Similar to the previous section, we define an assumption on the iterations of the algorithm which allows us to employ the smoothing technique in this section.\n13\nDefinition. LetB ∈ argmaxB:|B|=c fS(B). An iteration of SM-GREEDY is -significant if for the given set S selected before the iteration we have that fS(B) ≥ ·c·OPTk .\nThe following lemma implies that at every step we add a bundle whose smooth marginal contribution is comparable with the largest smooth marginal contribution obtainable.\nLemma 3.2. LetA ∈ argmaxB:|B|=c F̃ (S∪B) where c ≥ 16 , and assume that the iteration is 4 -significant. Then, with probability at least 1− e−Ω(n1/10) we have that:\nFS(A) ≥ (1− ) max B:|B|=c FS(B).\nThe proof relies on arguments from the smoothing framework (Appendix A). In this case, the application of smoothing is a bit subtle as we do not apply smoothing on the noisy version of F directly. The proof uses Lemma 3.1 above as well as Claim C.2 which bounds the variation in values of sets A?ij , when A ? ∈ argmaxB:|B|=c fS(B). Details and proofs are in Appendix C."
    }, {
      "heading" : "3.4 Approximation Guarantee in Expectation",
      "text" : "Lemma 3.3. Let δ > 0 and assume k > 16/δ2, c = 16/δ. Suppose that in every δ/4-significant iteration of SM-GREEDY when S are the elements selected in previous iterations, A ∈ argmaxB:|B|=c F̃ (S ∪ B), the bundle added Â respects fS(Â) ≥ (1− δ)FS(A). Let S̄ be the solution after bk/cc iterations. Then, w.p. ≥ 1− 1/n2:\nf(S̄) = (1− 1/e− 5δ)OPT.\nThis lemma implicitly proves an approximation guarantee that holds in expectation. This is simply because we know that if we choose Â = A \\ {ai} ∪ {aj} uniformly at random over all choices of i ∈ [c], aj /∈ S ∪ A we get E[fS(Â)] = FS(A) > (1 − δ)FS(A) in every iteration, and thus by Lemma 3.3 we would be arbitrarily close to 1− 1/e, in expectation over all our choices.\n14"
    }, {
      "heading" : "3.5 From Expectation to High Probability",
      "text" : "From Lemma 3.2 we know that A ∈ argmaxB:|B|=c F̃ (S ∪ B) has mean marginal contribution arbitrarily close to maxB:|B|=c FS(B), but for Lemma 3.3 to hold we need the true marginal contribution fS(Â) to be arbitrarily close to maxB:|B|=c FS(B). Simply adding A can easily lead to an arbitrarily bad approximation (see Appendix F ). In order to prove that SM-GREEDY provides the desired approximation guarantee, we need to show that when Â ∈ argmaxi∈[c],j /∈S∪A f̃(S ∪ Aij) then with sufficiently high probability fS(Â) is arbitrarily close toFS(A) as required by Lemma 3.3.\nHigh-level overview to show high probability guarantee. Let A? ∈ argmaxB:|B|=c fS(B) and A ∈ argmaxB:|B|=c F̃ (S ∪ B). We will define two kinds of sets in {Aij}i∈[c],j /∈S∪A, called good and bad. A good set is a set G for which fS(G) ≥ (1 − 2 )fS(A?) and a bad set is a set B for which fS(B) ≤ (1− 3 )fS(A?). Our goal is to prove argmax{f̃(S ∪Aij) : ai ∈ A, aj /∈ S ∪A} is w.h.p. not bad. Doing so implies that in every iteration w.h.p. we add a bundle whose true marginal value is at least (1− 3 ) of fS(A?) which is an upper bound on maxB:|B|=c FS(B) (and thus also on FS(A)). Lemma 3.4. For any > 0, suppose we run SM-GREEDY where in each iteration we add a bundle of size c = 16/ . For any /8-significant iteration where the set previously selected is S : |S| ∈ O(log log n), let A ∈ argmax F̃ (S ∪A) and Â = argmax(i,j)∈A×N\\S∪A f̃(S ∪Aij). Then, w.p. ≥ 1− 3/ log n we have:\nfS(Â) ≥ (1− 3 )FS(A).\nAt a high level, the proof follows the following steps:\n1. In Claim C.4 we show that for A ∈ argmaxB:|B|=c F̃ (S ∪ B), at least half of the sets in {Aij}i∈A,j /∈S∪A are good, and at most half are bad;\n2. Next, we define two thresholds: θg and θb. Intuitively, θg is a lower bound on the maximum of noise multipliers from the good sets, and θb is an upper bound on the maximum of noise multipliers from bad sets. We then show in Lemma C.8 that θg ≥ (1 − γ) θb, for any γ = Ω(1/ log logn). This lemma is quite technical, and it is where we fully leverage the property of the generalized exponential tail distribution and the fact that k ∈ O(log log n);\n3. From θg ≥ (1 − γ) θb and Claim C.4 we can prove that w.h.p. there is at least one good set whose noisy value is sufficiently larger than the noisy value of a bad set. The fact that a bad set loses to a good set implies that the value of the set we end up selecting must at least be as high as that of a bad set, i.e. fS(Â) ≥ (1− 3 )fS(A?). Notice that by definition fS(A?) is an upper bound on FS(B) for any bundle B of size c which therefore completes the proof.\nLemma 3.4 above essentially tells us that at every iteration we select the bundle whose marginal contribution is almost maximal. Together with previous arguments from this section, this proves our main theorem for the case in which k ∈ Ω(1/ 2) ∩O(log log n). For k ∈ Ω(1 ) ∩O( 1 2\n) we run a single iteration of SM-GREEDY with c = k (o.w. the approximation is ≈ 1/2, when k = 2c− 1). Theorem 3.5. For any monotone submodular function f : 2N → R and > 0, when k ∈ Ω(1/ ) ∩O(log log n), there is a (1 − 1/e − ) approximation for maxS:|S|≤k f(S), with probability 1− 4/ log n given access to a noisy oracle whose distribution has a generalized exponential tail.\n15"
    }, {
      "heading" : "4 Optimization for Very Small k",
      "text" : "The smoothing guarantee from the previous section actually necessitates selecting bundles of size c ∈ Θ(1/ ) and does not apply to very small values of k ∈ O(1/ )3. For small constants we propose a different algorithm that uses a different smoothing technique. The algorithm is simple and applies the same principles as the ones from the previous section. We show that this simple algorithm obtains an approximation ratio arbitrarily close to 1 − 1/e w.h.p. when k > 2 and in expectation when k = 2. For k = 1 we get arbitrarily close to 1/2, which is tight. We show lower bounds for small values of k and in particular when k = 1 show that no algorithm can obtain an expected approximation ratio better than 1/2 + o(1). All proofs and details are in Appendix D."
    }, {
      "heading" : "4.1 Smoothing Guarantees",
      "text" : "The smoothing here is straightforward. For every set A consider the smoothing neighborhood H(A) = {A ∪ x : x /∈ A}, F (A) = EX∈H(A)[f(X)] and F̃ (A) = EX∈H(A)[f̃(X)].\nLemma 4.1. Let A ∈ argmaxB:|B|=k F̃ (B). Then, for any fixed > 0 w.p. 1− e−Ω( 2(n−k)):\nF (A) ≥ (1− ) max B:|B|=k F (B)."
    }, {
      "heading" : "4.2 An Approximation Algorithm for Very Small k",
      "text" : "Approximation guarantee in expectation. The algorithm will simply select the set Â to be a random set of k elements from a random set ofH(A) whereA ∈ argmaxB:|B|=k F̃ (B). For any constant k and any fixed > 0 this is a (k/(k + 1)− ) approximation in expectation (see Theorem D.1).\nHigh probability. To obtain a result that holds w.h.p. we will consider a modest variant of the algorithm above. The algorithm enumerates all possible subsets of size k−1, and identifies the set A ∈ argmaxB:|B|=k−1 F̃ (B). The algorithm then returns Â ∈ argmaxX∈H(A) f̃(X).\nTheorem 4.2. For any submodular function f : 2N → R and any fixed > 0 and constant k, there is a (1− 1/k − )-approximation algorithm for maxS:|S|≤k f(S) which only uses a generalized exponential tail noisy oracle, and succeeds with probability at least 1− 6/ log n."
    }, {
      "heading" : "4.3 Information Theoretic Lower Bounds for Constant k",
      "text" : "Surprisingly, even for k = 1 no algorithm can obtain an approximation better than 1/2, which proves a separation between large and small k. In Claim D.2 we show no randomized algorithm with a noisy oracle can obtain an approximation better than 1/2 +O(1/ √ n) for maxa∈N f(a), and in Claim D.3 approximation better than (2k − 1)/2k +O(1/ √ n) for the optimal set of size k.\n3The dependency on originates in Claim C.2 where we bound on the variation of c−1 setsA-i, and thus smoothing depends on c ≥ 4/ .\n16"
    }, {
      "heading" : "5 Extensions",
      "text" : "In this section we consider extensions of the optimization under noise model. In particular, we show that the algorithms can be applied to several related problems: additive noise, marginal noise, correlated noise, degradation of information, and approximate submodularity."
    }, {
      "heading" : "5.1 Additive Noise",
      "text" : "Throughout this paper we assumed the noise is multiplicative, i.e. we defined the noisy oracle to return f̃(S) = ξS ·f(S). An alternative model is one where the noise is additive, i.e. f̃(S) = f(S)+ξS , where ξS ∼ D. The impossibility results for adversarial noise apply to the additive case as well.\nFrom a modeling perspective, the fact that the noise may be independent of the value of the set queried may be an advantage or a disadvantage, depending on the setting. From a technical perspective, the problem remains non-trivial. Fortunately, all the algorithms described above apply to the additive noise model, modulo the smoothing arguments which become straightforward. That is, we still need to apply smoothing on the surrogate functions, but it is easy to show arguments likeA ∈ argmaxB F̃ (S∪B) implies w.h.p. FS(A) ≥ (1−δ) maxb FS(B). In the additive noise model:\nF̃ (S ∪A) = ∑\nX∈H(A)\nf̃(S ∪X) = ∑\nX∈H(A)\n(f(S ∪X) + ξS∪X) = ∑\nX∈H(A)\nf(S ∪X) + ∑\nX∈H(X)\nξS∪X\nThus, by applying a concentration bound we can show that a setAwhose smooth value is maximal implies that its non-noisy smooth marginal contribution FS(A) is approximately maximal as well."
    }, {
      "heading" : "5.2 Marginal Noise",
      "text" : "An alternative noise model is one where the noise acts on the marginals of the distribution. In this model, a query to the oracle is a pair of sets S, T ⊆ N and the oracle returns ξS,T · fS(T ) in the multiplicative marginal noise model and fS(T ) + ξS,T in the additive marginal noise model.\nAdversarial additive marginal noise is generally impossible. If the error is adversarial, and the noise is additive, the lower bound of 6.1 follows for any magnitude of the noise. Letting denote the maximal magnitude of the noise, we consider a function in which no element ever gives a contribution higher than , and then getting marginal information does not help.\nAdversarial multiplicative marginal noise is approximable. If the marginal error is adversarial but multiplicative within factor α, it is well known one can obtain a 1− 1/eα approximation.\nMarginal i.i.d noise is approximable. If one is allowed to query the oracle on any two sets S, T and get ξS,T ·fS(T ) (or fS(T )+ξS,T ) where ξS,T is drawn i.i.d for any pair S, T , then one can simply apply all the algorithms and analysis as is, by always considering f∅(S ∪T ). If one is only allowed\n17\nto query S, T where |T | = 1, the algorithms still work, but we need to be careful with the analysis, since we need to show that we are calling the oracle on different sets. It is easy to show that if the noise is weak and multiplicative (e.g. ξ ∈ [1− , 1+ ]) we can obtain a (1−1/e− ) approximation."
    }, {
      "heading" : "5.3 Correlated Noise",
      "text" : "As discussed in the Introduction, Theorem 6.1 implies that no algorithm can optimize a monotone submodular function under a cardinality constraint given access to a noisy oracle whose noise multipliers are arbitrarily correlated across sets, even when the support of the distribution is arbitrarily small. In light of this, one may wish to consider special cases of correlated distributions. We first show that even very simple correlations can result in inapproxiability. We then show an interesting class of distributions we call d-correlated, for which optimal guarantees are obtainable.\nImpossibility result for correlated distributions. Having taken the first step showing algorithms for the i.i.d. in space model, a natural question is whether this assumption is necessary.\nTheorem 5.1. Even for unit demand functions there are simple space-correlated distributions for which no algorithm can achieve an approximation strictly better than 1/n.\nProof. Consider a unit demand function f(S) = maxa∈S f(a) which operates on a ground set with n elements. There are n − 1 regular elements and one special element a?. The value of f on any regular element is 1, but f(a?) = M for some arbitrarily large M . The noise distribution is such that it returns 1 on sets which do not contain a?, and 1/M on sets that contain a?. The best one can do in this case is to choose a random element without querying the oracle at all.\nGuarantees for d-correlated distributions. Our algorithms can be extended to a model in which querying similar sets may return results that are arbitrarily correlated, as long as querying sets which are sufficiently far from each other gives independent answers.\nDefinition. We say that the noise distribution is d-correlated if for any two sets S and T , such that |S \\ T |+ |T \\ S| > d we have that the noise is applied independently to S and to T .\nNotice that if a distribution is d-correlated, any two points on the hypercube at distance at most d can be arbitrarily correlated. For this model we show that when k ∈ Ω(log logn) then we can obtain an approximation arbitrarily close to 1 − 1/e for O( √ k)-correlated distributions. Alternatively, in this regime we can get this approximation guarantee for any distribution that is arbitrarily correlated when querying two sets S, T whose symmetric difference is larger than √ max{|T |, |S|}. When k ∈ Ω(log logn) we can get arbitrarily close to 1− 1/e for O(1)-correlated noise.\nModification of algorithms for large k for √ k-correlated noise. For large k, if we have that k d2, then the approximation guarantee we get is still arbitrarily close to 1 − 1/e even when D is d-correlated. To do this, we modify the smoothing neighborhood and the definition of smooth\n18\nvalues as follows. Recall that in SMOOTH-GREEDY, we select an arbitrary set of elements H of size ` for smoothing, and compute the noisy smooth value of S ∪ a by averaging all subsets of H :\nF̃ (S ∪ a) = 1 2` ∑ H′⊂H f̃ ( S ∪ ( a ∪H ′ )) .\nIn the d-correlated case, for each 1 ≤ i ≤ d and 1 ≤ j ≤ ` we choose a bundle h(i)j of d elements, such that every two bundles are disjoint. Denote H(i) = {h(i)1, . . . h(i)`, and H = di,jh(i)j the set of all elements we used. The noisy smooth value with smoothing set H(i) is now:\nF̃ (i)(S ∪ a) = 1 2` ∑ H′⊂H(i) f̃(S ∪ a ∪H ′)\nwhere we abuse notation and use S ∪ a ∪H ′ instead of S ∪ {a} ∪h(i)j∈H′ h(i)j .\nWe will run SMOOTH-GREEDY with the smoothing sets H(1), . . . ,H(d), where in each iteration i mod d we use H(i) as the smoothing set. Exactly as in the original algorithm, we generate S by iteratively adding k−|H| elements from N \\H that maximize the smooth value in every iteration, and we then return S ∪H . As before, SLICK- GREEDY employs SMOOTH-GREEDY.\nTo prove correctness of the algorithm we need to show that the evaluations of the surrogate functions are independent. We will first show by induction on |S| that between iterations, the oracle calls are independent.\nClaim 5.2. Any oracle call at iteration i is independent of any previous oracle call at iteration r < i.\nProof. Let S(i) be the set of elements we have already committed to in stage i. Consider an evaluation of f̃(S(i) ∪ a ∪ H ′) for some non empty H ′ ⊂ H(i mod d) at iteration i, and an oracle evaluation f̃(S(r)∪b∪H ′′) made at some iteration r < swith some non emptyH ′′ ⊂ H(r mod d) and b /∈ S(r) ∪ H . If r ≤ i − d, then the symmetric difference between S(i) ∪ a and S(r) ∪ b is at least of size d. Since a, b /∈ H , and S(i) ∩ H = ∅, this means that the symmetric difference of S(i) ∪ a ∪H ′ and S(r) ∪ b ∪H ′′ is at least of size d, for any H ′′ ⊂ H(r mod d), and thus the calls are independent. If r > s− d, then i mod d 6= r mod d, and hence S(i)∪ a∪H ′ and S(r)∪ b∪H ′′ are independent because of the symmetric difference between H ′ and H ′′.\nClaim 5.3. When evaluating F̃ (i)(S ∪ a), all noise multipliers are independent.\nProof. When evaluating F̃ (i)(S ∪ a) we call the noisy oracle on sets of the form S ∪ a ∪ H ′. Since each H ′ corresponds to a different subset of H(i), and H(i) is a collection of ` bundles of size d, the symmetric difference between every two sets H ′, H ′′ ⊆ H(i), is at least d.\nAs in the original SMOOTH-GREEDY procedure, we can show that at every iteration, when S is the set of elements we selected in previous iterations, an element a added to S implies that w.h.p. F (S ∪ a) is arbitrarily close to maxb/∈H F (S ∪ b) (see Claim 5.3). Let a1, a2, . . . an−|S|−|H| denote the elements which are being considered. For each element ai, we have that if F (S ∪ ai) is non\n19\nnegligible then w.h.p F̃ (S ∪ ai) approximates F (S ∪ ai), and if F (S ∪ ai) is negligible then so is F̃ (S ∪ ai). While for ai, aj these events may well be correlated, since the probability of failure is inverse polynomially small and there are only n−|S|−|H| events, we can take a union bound and say that with high probability for every i if F (S ∪ ai) is negligible so is F̃ (S ∪ ai), and if F (S ∪ ai) is non negligible then it is well approximated by F̃ (S ∪ ai).\nThus, we know that at every iteration iwhen S is the set of elements selected in previous iterations, we have selected the element a that is arbitrarily close to maxb/∈H F (i)(S ∪ b). From the arguments in the paper we know that this implies that for an arbitrarily small γ > 0 we have:\nfS(a) ≥ (1− γ)fS∪H(i)(b) ≥ (1− γ)fS∪H(b)\nwhere the right inequality is due to submodularity and the fact that H(i) ⊆ H . The guarantees of SMOOTH-GREEDY therefore apply in this case as well. What remains to show is that SLICKGREEDY is unaffected by this modification. This is easy to verify as SLICK-GREEDY takes 1/δ disjoint sets H1, . . . ,H1/δ, and the arguments discussed apply for every such set. Since we apply SMOOTH-COMPARE 1/δ times with sets of size ` it is easy to implement as well.\nModification of algorithms for small k for O(1)-correlated noise. A similar idea works also for the small k case, assuming d is constant. In this case, we add c d/ elements at each phase of the algorithm. We modify the definition of F̃ in the following way. First we take a an arbitrary partition P1, . . . P(n−|S|)/d on the elements not in S, in which each Pi is of size d, and a partition Q1 . . . Q(|S|+|A|)/d of the elements in S ∪A. We estimate the value of a set A given S using:\nF̃ (S ∪A) = d 2 (|S|+ |A|)(|N | − |S| − |A|) ∑ Qi ∈ A ∑ Pj f̃(((S ∪A) \\Qi) ∪ Pj)\nand modify the rest of the algorithm accordingly.\nCorrectness relies on three steps:\n1. First, when we are in iteration i of the algorithm (after we already added (i − 1)c elements to S), all the sets we apply the oracle on are of size c · i, and hence they are independent of any set of size c(i− 1) or less which were used in previous phases;\n2. Second, when we evaluate F̃ (S ∪A) for a specific set A, we only use sets which are independent in the comparison. Here we rely on changing d elements in A each time, and replacing them by another set of d elements;\n3. Finally, we treat each setA separately, and show that if its marginal contribution is negligible then w.h.p its mean smooth value is not too large, and if its marginal contribution is not negligible, then w.h.p. F̃ (S ∪A) approximates F (S ∪A) well. Taking a union bound over all the bad events we get that the set A chosen has large (non-noisy) smooth mean value."
    }, {
      "heading" : "5.4 Information Degradation",
      "text" : "We have written the paper as if the algorithm gains no additional information for querying a point twice. The generalization to a case where the algorithm gets more information each time but there\n20\nis a degradation of information is simple: whenever the algorithms we presented here want to query a point just query it multiple times, and feed the expected value of the point given all the information one has to the algorithm. Hence it makes sense to focus on the extreme case where only the first query is helpful, as common in the literature of noisy optimization (e.g. [12])"
    }, {
      "heading" : "5.5 Approximate Submodularity",
      "text" : "In this paper our goal is to obtain near optimal guarantees as defined on the original function that was distorted through noise. That is, we assume that there is an underlying submodular function which we aim to optimize, and we only get to observe noisy samples of it. An alternative direction would be to consider the problem of optimizing functions that are approximately submodular:\nmax S:|S|≤k f̃(S)\nThe notion of approximate submodularity has been studied in machine learning [67, 23, 22, 33]. More generally, given the desirable guarantees of submodular functions, it is interesting to understand the limits of efficient optimization with respect to the function classes we aim to optimize.\nImpossibility for -adversarial approximation. If we assume that the function is an adversarial (1 ± ) approximation of a submodular function, our lower bound from Section 6 for erroneous oracles implies that no polynomial time algorithm can obtain a non-trivial approximation.\nTrivial reduction for noise in [1− , 1+ ]. WhenD ⊆ [1− , 1+ ], and the noise is i.i.d across sets, the algorithms in the paper obtain a solution arbitrarily close to ( 1− 1+ ) ( 1− 1e ) of maxS:|S|≤k f̃(S).\nImpossibility for unbounded noise. If we assume that a noisy process of a distribution with unbounded support altered a submodular function, then there are trivial impossibility results. Suppose that the initial submodular function is the constant function that gives 1 to every set. If we apply (e.g.) Gaussian noise to it, then the optimal algorithm is just to try random sets and hope for the best, and no polynomial time algorithm can achieve a constant factor approximation.\nOptimal approximation via black-box reduction. First, note that there is an algorithm which runs in time nk and finds the optimal subset of size k: query f̃ on all subsets of size at most k, and choose the maximal one. Notice that this is in contrast to the setting we study throughout the paper in which there is a lower bound of (2k − 1)/2k + O(1/ √ n). The interesting regime is k = ω(1), where there is a black-box reduction from the problem of maximizing a submodular function given an approximately submodular function, to the problem of maximizing an approximately submodular function. Since we can solve the original problem within a factor arbitrarily close to 1 − 1/e we get an optimal approximation guarantee in this case as well. Let maxD(t) = E[maxξ1,...ξt∼D{ξ1, . . . , ξt}] be the expected maximum value of t i.i.d samples of D.\n21\nLemma 5.4. An algorithm which uses t ≤ ( n k ) queries to f̃ cannot achieve approximation ratio better than:\nmaxD(t) maxD( ( n k ) ) .\nProof. Suppose that f(S) = 1 for every set S. The best that the algorithm can do is query t sets with at most k elements, and output the maximal one. The approximation ratio of this is exactly\nmaxD(t) maxD( ( n k ) )\nIf the algorithm queries sets with more than k elements, the approximation would deteriorate.\nLemma 5.5. Suppose there exists an algorithm which given k ∈ ω(1) returns a solution S s.t. f(S) ≥ γmaxT :|T |≤k f(T ) using q queries to a noisy oracle. Then, for any t ∈ poly(n) there is an algorithm that uses q + t to a noisy oracle and returns a solution S′ s.t.:\nf̃(S′) ≥ ( γ − o(1) )( maxD(t) maxD( ( n k ) ) ) max T :|T |≤k f̃(T ).\nProof. Let r be such that ( n−k r ) ≥ t. Since t is polynomial in n, we have that r is constant. Run the algorithm to obtain a set G of size k − r. From submodularity and the fact that r is constant:\nf(G) ≥ γ max S:|S|≤k−r f(S) ≥ (1− r/k)γ max S:|S|≤k f(S) ≥ (1− o(1))γ max S:|S|≤k f(S)\nFor every set of r elements {x1, . . . , xr} where xi 6∈ G, the algorithm queries f̃ on G ∪ {x1, . . . xr}, and chooses the set with maximum value. It is easy to see that the expected value of this set would be at least maxD(t)(1− r/k)γmaxS:|S|≤k f(S), which gives the ratio.\n22"
    }, {
      "heading" : "6 Impossibility for Adversarial Noise",
      "text" : "In this section we show that there are very simple submodular functions for which no randomized algorithm with access to an -erroneous oracle can obtain a reasonable approximation guarantee with a subexponential number of queries to the oracle. Intuitively, the main idea behind this result is to show that a noisy oracle can make it difficult to distinguish between two functions whose values can be very far from one another. The functions we use are similar to those used to prove information theoretic lower bounds for submodular optimization and learning [79, 84, 36, 8, 95].\nTheorem 6.1. No randomized algorithm can obtain an approximation strictly better than O(n−1/2+δ) to maximizing monotone submodular functions under a cardinality constraint using enδ/n queries to an -erroneous oracle, for any fixed , δ < 1/2.\nProof. We will consider the problem of maxS:|S|≤k f(S) where k = n1/2+δ. Let X ⊆ N be a random set constructed by including every element from N with probability n−1/2+δ. We will use this set to construct two functions that are close in expectation but whose maxima have a large gap, and show that access to a noisy oracle implies distinguishing between these two functions. The functions are:\n• f1(S) = min { |S ∩X| · n1/2 + n1/2+δ , |S| · n 1+δ }\n• f2(S) = min { |S| · nδ + n1/2+δ , |S| · n 1+δ }\nNotice that both functions are normalized monotone submodular: when S = ∅ both functions evaluate to 0, and otherwise are affine. By the Chernoff bound we know that |X| ≥ n1/2+δ/2 with probability 1 − e−Ω(n1/2+δ). Conditioned on this event we have that maxS:|S|≤k f1(S) = f1(X) ∈ O(n1+δ) whereas f2 is symmetric and maxS:|S|≤k f2(S) ∈ O(n1/2+2δ). Thus, an inability to distinguish between these two functions implies there is no approximation algorithm with approximation better than O(n−1/2+δ). We define the erroneous oracle as follows. If the function is f2, its oracle returns the exact same value as f2 for any given set. Otherwise, the function is f1 and its erroneous oracle is defined as:\nf̃(S) = { f2(S), if (1− )f1(S) ≤ f2(S) ≤ (1 + )f1(S) f1(S) otherwise\nNotice that this oracle is -erroneous, by definition.\nSuppose now that the set X is unknown to the algorithm, and the objective is maxS:|S|≤k f1(S). We will first show that no deterministic algorithm that uses a single query to the erroneous oracle f̃ can distinguish between f1 and f2, with exponentially high probability (equivalently, we will show that a single query to the algorithm cannot find a set S for which f1(S) < (1 − )f2(S) or f1(S) > (1 + )f2(S) with exponentially high probability). For a single query algorithm, we can imagine that the set X is chosen after the algorithm chooses which query to invoke, and compute the success probability over the choice of X . In this case, all the elements are symmetric, and the function value is only determined by the size of the set that the single-query algorithm queries.\n23\nIn case the query is a set S of cardinality smaller or equal to n1/2, by the Chernoff bound we have that |S ∩X| ≤ (1 + β)nδ for any β < 1 with probability at least 1− e−Ω(β2nδ). Thus:\nn1/2+δ\n≤ f1(S) ≤ ( 1 + β + 1 ) n1/2+δ\nn1/2+δ\n≤ f2(S) ≤\n( 1 + 1 ) n1/2+δ\nIt is easy to verify that for β < /(1− ): (1− )f1(S) ≤ f2(S) ≤ (1 + )f1(S). Thus, for any query of size less or equal to n1/2 the likelihood of the oracle returning f1 is 1− e−Ω(n δ).\nIn case the oracle queries a set of size greater than n1/2 then again by the Chernoff bound, for any β < 1 we have that with probability at least 1− e−Ω(β2n1/2):(\n1− β ) |S| n1/2−δ ≤ |S ∩X| ≤ ( 1 + β ) |S| n1/2−δ\nFor β ≤ /(1− ), this implies that:\n(1− )f1(S) ≤ f2(S) ≤ (1 + )f1(S)\nTherefore, for any fixed ∈ (0, 1), the algorithm cannot distinguish between f1 and f2 with probability 1 − e−Ω(nδ) by querying the erroneous oracle with a set larger than n1/2. To conclude, by a union bound we get that with probability 1−e−Ω(nδ) no algorithm can distinguish between f1 and f2 using a single query to the erroneous oracle, and the ratio between their maxima is O(n1/2−δ).\nTo complete the proof, suppose we had an algorithm running in time en δ /n which can approximate the value of a submodular function, given access to an -erroneous oracle with approximation ratio strictly better than O(n−1/2+δ) which succeeds with probability 2/3. This would let us solve the following decision problem: Given access to an -erroneous oracle for either f1 or f2, determine which function is being queried. To solve the decision problem, given access to an erroneous oracle of unknown function, we would use the hypothetical approximation algorithm to estimate the value of the maximal set of size n1/2+δ. If this value is strictly more than n1/2+2δ, the function is f1 (since f1(X) = O(n 1+δ)), and otherwise it is f2.\nThe reduction allows us to show that distinguishing between the functions in time en δ /n and success probability 2/3 is impossible. For purpose of contradiction, suppose that there is a (randomized) algorithm for the decision problem, and let p denote the probability that it outputs f2 if it sees an oracle which is fully consistent with f2. To succeed with probability 2/3, it must be the case that whenever the algorithm gets f1 as an input, it finds a set S for which the noisy oracle returns f1(S) with probability at least 2/3−p/2 ≥ 1/6. Whenever it finds such a set, the algorithm is done, since it can compute f2(S) without calling the oracle, and hence it knows that f1 was chosen in the decision problem.\nIn this case, we know that the algorithm makes up to en δ /n queries, until it sees a set for which it gets f1(S). But this means that there is an algorithm with success probability at least O(n/6en δ ) that makes a single query. This algorithm guesses some index i < en δ /n, and simulates the original algorithm for i− 1 steps (by feeding it with f2 without using the oracle), and then using the oracle\n24\nin step i. If the algorithm guesses i to be the first index in which the exponential time algorithm sees f1(S), then the single query algorithm would succeed. Hence, since we showed that no single query (randomized) algorithm can find a set S such that f1(S) < (1− )f2(S) or f1(S) > (1+ )f2(S) with just one query this concludes the proof.\nThe following remarks are worth mentioning:\n• The functions we used in the lower bound are very simple examples of coverage functions;\n• If one does not require the function to be normalized, then the lower bound holds for affine functions, i.e. f(S) = ∑ a∈S f(a) + C, where C independent of S;\n• The lower bound is tight: for any -erroneous oracle there is a 1− 1+ ·max{n −1/2, 1/k} approxi-\nmation by simply partitioning the ground sets to arbitrary sets of size min{ √ n, k}, and select the set whose value according to the erroneous oracle is maximal;\n• The lower bound applies to additive noise by simply applying an additive version of the Chernoff bound.\nSomewhat surprisingly, the above theorem suggests that a good approximation to a submodular function does not suffice to obtain reasonable approximation guarantees. In particular, guarantees from learning or sketching where the goal is to approximate a submodular function up to constant factors may not necessarily be meaningful for optimization. It is important to note that for some classes of submodular functions such as additive functions (f(S) = ∑ a∈S f(a)), we can obtain algorithms that are robust to adversarial noise. A very interesting open question is to characterize the class of submodular functions that are robust to adversarial noise.\n25"
    }, {
      "heading" : "7 More related work",
      "text" : "Submodular optimization. Maximizing monotone submodular functions under cardinality and matroid constraints is heavily studied. The seminal works of [80, 46] show that the greedy algorithm gives a factor of 1−1/e for maximizing a submodular function under a cardinality constraint and a factor 1/2 approximation for matroid constraints. For max-cover which is a special case of maximizing a submodular function under a cardinality constraint, Feige shows that no poly-time algorithm can obtain an approximation better than 1-1/e unless P=NP [35]. Vondrak presented the continuous greedy algorithm which gives a 1− 1/e ratio for maximizing a monotone submodular function under matroid constraints [94]. This is optimal, also in the value oracle model [79, 61, 81]. It is interesting to note that with a demand oracle the approximation ratio is strictly better than 1 − 1/e [39]. When the function is not monotone, constant factor approximation algorithms are known to be obtainable as well [37, 73, 14, 15]. In general, in the past decade there has been a development in the theory of submodular optimization, through concave relaxations [1, 19], the multilinear relaxation [18, 94, 20], and general rounding technique frameworks [96]. In this paper, the techniques we develop arise from first principles: we only rely on basic properties of submodular functions, concentration bounds, and the algorithms are variants of the standard greedy algorithm.\nSubmodular optimization in game theory. Submodular functions have been studied in game theory almost fifty years ago [90]. In mechanism design submodular functions are used to model agents’ valuations [74] and have been extensively studied in the context of combinatorial auctions (e.g. [27, 28, 26, 79, 16, 25, 83, 32, 29]). Maximizing submodular functions under cardinality constraints have been studied in the context of combinatorial public projects [84, 87, 17, 78] where the focus is on showing the computational hardness associated with not knowing agents valuations and having to resort to incentive compatible algorithms. Our adversarial lower bound implies that if agents err in their valuations, optimization may be hard, regardless of incentive constraints.\nSubmodular optimization in machine learning. In the past decade submodular optimization has become a central tool in machine learning and data mining (see surveys [65, 66, 11]). Problems include identifying influencers in social networks [59, 86] sensor placement [75, 50], learning in data streams [92, 52, 71, 5], information summarization [76, 77], adaptive learning [51], vision [58, 57, 63], and general inference methods [64, 57, 24]. In many cases the submodular function is learned from data, and our work aims to address the case in which there is potential for noise in the model.\nLearning submodular functions. One of the main motivations we had for studying optimization under noise is to understand whether submodular functions that are learned from data can be optimized well. The standard framework in the literature for learning set functions is Probably Mostly Approximately Correct (PMAC) learnability due to Balcan and Harvey [9]. This framework nicely generalizes Valiant’s notion of Probably Approximately Correct (PAC) learnability [93]. Informally, PMAC-learnability guarantees that after observing polynomially-many samples of sets and\n26\ntheir function values, one can construct a surrogate function that is with constant probability over the distributions generating the samples, likely to be an approximation of the submodular function generating the data. Since the seminal paper of Balcan and Harvey there has been a great deal of work on learnability of submodular functions [41, 7, 4, 43, 45, 6]. As discussed in the paper, our lower bounds imply that one cannot optimize the surrogate function PMAC learned from data. If the approximation is via i.i.d noise on sets sufficiently far, this may be possible.\nApproximate submodularity. The concept of approximate submodularity has been studied in machine learning for dictionary selection and feature selection in linear regression [67, 23, 22, 33]. Generally speaking, this line of work considers approximate submodularity by defining a notion of the submodularity ratio of a function, defined in terms of how close it is to have a diminishing returns property. This ratio depends on the instance, which in the worst-case may result in a function that poorly approximates a submodular function. In practice however, these works show that in a broad range of applications the functions of interest are sufficiently close to submodular. Recently, the notion of approximate modularity (i.e. additivity) has been studied in [21] which give an optimal algorithm for approximating an approximately modular function via a modular function. These notions of approximate modularity and approximate submodularity are the model in which we have noise on the marginals. As discussed in Section 5, if the error on the marginals is adversarial, there are regimes in which non-trivial guarantees are impossible. If one assumes the marginal approximations are i.i.d our positive results apply.\nCombinatorial optimization under noise. Combinatorial optimization with noisy inputs can be largely studied through consistent (independent noisy answers when querying the oracle twice) and inconsistent oracles. For inconsistent oracles, it usually suffices to repeat every query O(log n) times, and eliminate the noise. To the best of our knowledge, submodular optimization has been studied under noise only in instances where the oracle is inconsistent or equivalently small enough so that it does not affect the optimization [59, 68]. One line of work studies methods for reducing the number of samples required for optimization (see e.g. [38, 10]), primarily for sorting and finding elements. On the other hand, if two identical queries to the oracle always yield the same result, the noise can not be averaged out so easily, and one needs to settle for approximate solutions, which has been studied in the context of tournaments and rankings [60, 12, 2].\nConvex optimization under noise. Maximizing functions under noise is also an important topic in convex optimization. The analogue of our model here is one where there is a zeroth-order noisy oracle to a convex function. As discussed in the paper, the question of polynomial-time algorithms for noisy convex optimization is straightforward and the work in this area largely aims at improving the convergence rate [34, 47, 62, 72, 85].\n27"
    }, {
      "heading" : "8 Acknowledgements",
      "text" : "A.H. was supported by ISF 1241/12; Y.S. was supported by NSF grant CCF-1301976, CAREER CCF-1452961, a Google Faculty Research Award, and a Facebook Faculty Gift. We thank Vitaly Feldman who pointed out the application to active learning. We are deeply indebted to Lior Seeman, who has carefully read previous versions of the manuscript and made multiple invaluable suggestions.\n28"
    }, {
      "heading" : "A Combinatorial Smoothing",
      "text" : "In this section we illustrate a general framework we call combinatorial smoothing that we will use in the subsequent sections. Intuitively, combinatorial smoothing mitigates the effects of noise and enables finding elements whose marginal contribution is large.\nSome intuition. Recall from our earlier discussion that implementing the greedy algorithm requires identifying arg max f(S ∪ a) for a given set S of elements selected by the algorithm in previous iterations. Thus, if for some a, b ∈ N we can compare S ∪a and S ∪ b and decide whether f(S∪a) > f(S∪ b) or vice versa, we can implement the greedy algorithm. Put differently, viewing a set as a point on the hypercube, given two points in {0, 1}n we need to be able to tell which one has the larger true value, using a noisy oracle. In a world of continuous optimization, a reasonable approach to estimate the true value of a point in [0, 1]n with access to a noisy oracle is to take a small neighborhood around the point, sample values of points in its neighborhood, and average their values. Taking polynomially-many samples allows concentration bounds to kick in, and using a small enough diameter can often guarantee that the averaged value is a reasonable estimate of the point’s true value. Surprisingly, the spirit of this idea can used in submodular optimization.\nSmoothing neighborhood. For a given subset A ⊆ N a smoothing function is a method which assigns a family of sets H(A) called the smoothing neighborhood. The smoothing function will be used to create a smoothing neighborhood for a small setA. This setAwhose marginal contribution we aim to evaluate, is essentially a candidate for a greedy algorithm. In the application in Section 2 the set A is simply be a single element, whereas in Section 3 the set A is of size O(1/ ).\nDefinition A.1. For a given function f : 2N → R, A,S ⊆ N , and smoothing neighborhoodH(A):\n• FS(A) := EX∈H(A) [fS(X)] (called the smooth marginal contribution of A),\n• F (S ∪A) := EX∈H(A) [f(S ∪X)] (called the smooth value of S ∪A) • F̃ (S ∪A) := EX∈H(A) [ f̃(S ∪X) ] (called the noisy smooth value of S ∪A).\nThe idea behind combinatorial smoothing is to select a smoothing neighborhood which includes sets whose value is in some sense close to the value of the set A whose marginal contribution we wish to evaluate. Intuitively, when the sets are indeed close, by averaging the values of the sets in H(A) we can mitigate the effects of noise and produce meaningful statistics (see Figure 3).\nSmoothing arguments\nIn our model, the algorithm may only access F̃ (S ∪ A). Ideally, given a set S and a smoothing neighborhoodH(A) we would have liked to apply concentration bounds and show that the noisy smooth value is arbitrarily close to the non-noisy smooth value, i.e. F (S ∪A) ≈ F̃ (S ∪A) or:∑\ni∈H(A)\nf(S ∪Xi) ≈ ∑\ni∈H(A)\nξif(S ∪Xi)\n37\nIf the values in {f(S ∪ Xi)}|H(A)|i=1 were arbitrarily close, we could simply apply a concentration bound by taking the value of any one of the sets, say S ∪Xj , and for vj = f(S ∪Xj), since all the values are close, we would be guaranteed that:∑\ni∈H(A)\nξif(S ∪Xi) ≈ ∑\ni∈H(A)\nξif(S ∪Xj) = vj · ∑\ni∈H(A)\nξi\nIn continuous optimization this is usually the case when averaging over an arbitrarily small ball around the point of interest, and concentration bounds apply. In our case, due to the combinatorial nature of the problem, the values of the sets in the smoothing neighborhood may take on very different values. For this reason we cannot simply apply concentration bounds. The purpose of this section is to provide machinery that overcomes this difficulty. The main ideas can be summarized as follows:\n1. In general, there may be cases in which we cannot perform smoothing well and cannot get\n38\nthe noisy smooth values to be similar to the true smooth values. We therefore define a more modest, yet sufficient goal. Since our algorithms essentially try to replace the step of adding the element a ∈ argmaxb f(S ∪ b) in the greedy algorithm with a′ ∈ argmaxb F (S ∪ b), it suffices to guarantee that for the set A which maximizes the noisy smooth values, that set also well approximates the (non-noisy) smooth values. More precisely our goal is to show that if for an arbitrarily small δ > 0 we have that A ∈ argmaxB F̃ (S ∪ B) then F (S ∪A) ≥ (1− δ) maxB F (S ∪B);\n2. To show thatA ∈ argmax F̃ (S∪A) implies F (S∪A) ≥ (1−δ) maxB F (S∪B) for an arbitrarily small δ > 0, we prove two bounds. Lemma A.4 lower bounds the noisy smooth contribution of a set in terms of its (true) smooth contribution. Lemma A.5 upper bounds the smooth noisy contribution of any element against its smooth contribution. The key difference between these lemmas is that Lemma A.4 lower bounds the value in terms the variation of the smoothing neighborhood. The variation of the neighborhood is the ratio between the set with largest value and that with lowest value in the neighborhood. Intuitively, for elements with large values the variation of the neighborhood is bounded, and thus we can show that the noisy smooth value of these elements is nearly as high as their true smooth values.\n3. Together, these lemmas are used in subsequent sections to show that an element with the largest noisy smooth marginal contribution is an arbitrarily good approximation to the element with the largest (non-noisy) smooth marginal contribution. This is achieved by showing that the lower bound on the smooth value of an element with large (non-noisy) smooth marginal contribution beats the upper bound on the smooth (non-noisy) value of an element with slightly smaller smooth contribution.\nThe first lemma gives us tail bounds on the upper and lower bounds of the value of the noise multiplier in any of the calls made by a polynomial-time algorithm. We later use these tail bounds in concentration bounds we use in the smoothing procedures.\nLemma A.2. Let ωmax = max{ξ1, . . . , ξm} and ωmin = min{ξ1, . . . , ξm}, where ξi ∼ D and D is a noise distribution with a generalized exponential tail. For any δ > 0 and sufficiently large m, we have that:\n• Pr[ωmax < mδ] > 1− e−Ω(m δ/ lnm)\n• Pr[ωmin > m−δ] > 1− e−Ω(m δ/ lnm)\nProof. As m tends to infinity, this lemma trivial for any noise distribution which is bounded, or has finite support. If the noise distribution is unbounded, we know that its tail is subexponential. Thus, at any given sample the probability of seeing the value mδ is at most e−O(m\nδ) where the constant in the big O notation depends on the magnitude of the tail. Iterating this a polynomial number of times gives the bound. The proof of the lower bound is equivalent.\nThe definition below of the variation of the neighborhood quantifies the ratio between the largest possible value and the smallest possible value achieved by a set in the neighborhood.\n39\nDefinition A.3. For given sets A,S ⊆ N , the variation of the neighborhood denoted vS(H(A)) is:\nvS(H(A)) = maxT∈H(A) fS(T )\nminT∈H(A) fS(T ) .\nThe following lemma gives a lower bound on the noisy smooth value in terms of the (non-noisy) smooth value and the variation. Intuitively, when an element has large value its variation is bounded, and the lemma implies that its noisy smooth value is close to its smooth value. Essentially, when the variation is bounded F̃ (S) ≈ (1 − λ)(1 − )F (S) for λ and that vanish as n grows large.\nLemma A.4. Let f : 2N → R, A,S ⊂ N , ω = maxAi∈H(A) ξAi , and µ be the mean of the noise distribution. For = min { 1, 2vS(H) · |H(A)|−1/4 } for any λ < 1 w.p 1− e−Ω( λ2t1/4 ω ) we have:\nF̃ (S ∪A) > (1− λ)µ · (f(S) + (1− ) · FS(A)) .\nProof. Let A1, . . . , At be the sets in H(A) and let α1, . . . , αt denote the corresponding marginal contributions and ξ1 . . . , ξt denote their noise multipliers. In these terms the noisy smooth value is:\nF̃ (S ∪A) = 1 t t∑ i=1 ξi(f(S) + αi) = 1 t t∑ i=1 ξif(S) + 1 t t∑ i=1 ξiαi. (1)\nLet ω be the upper bound on the value of the noise multiplier. Applying the Chernoff bound, we get that for any λ < 1 with probability at least 1− e−Ω(λ2t/ω):\n1\nt t∑ i=1 ξif(S) ≥ (1− λ)µf(S).\nTo complete the proof we need to argue about concentration of the second term in (1). To do so, in our analysis we will consider a fine discretization of {αi}i∈[t] and apply concentration bounds on each discretized value. Define αmax = maxi∈[t] αi and αmin = mini∈[t] αi. We can divide the set of values {αi}i∈[t] to t1/4 bins BIN1, . . . , BINt1/4 , where a value αi is placed in the bin BINq if\n(q − 1) · αmaxt−1/4 ≤ αi ≤ q · αmaxt−1/4\nSay a bin is dense if it contains at least t1/4 values and sparse otherwise. Consider some dense bin BINq and let αmin(q) = mini∈BINq αi and αmax(q) = maxi∈BINq αi. Since every bin is of width αmax · t−1/4 we know that:\nαmin(q) ≥ αmax(q) − αmax · t−1/4 Applying concentration bounds as above, we get that ∑\ni∈BINq ξi ≥ (1−λ)µ·|BINq|with probability\n40\nat least 1− e−Ω(λ2t1/4/ω) for any λ < 1. Thus, with this probability:∑ i∈BINq ξiαi ≥ ∑ i∈BINq ξiαmin(q)\n≥ (1− λ)µ · |BINq| · αmin(q) ≥ (1− λ)µ · |BINq| · ( max { 0, αmax(q) − αmax · t−1/4 }) > (1− λ)µ · |BINq| · ( max { 0, 1− αmax\nαmax(q) · t−1/4\n}) αmax(q)\n≥ (1− λ)µ · |BINq| · ( max { 0, 1− αmax\nαmin · t−1/4\n}) αmax(q)\n= (1− λ)µ · |BINq| · ( max { 0, 1− vS (H(A)) · t−1/4 }) αmax(q)\nTaking a union bound over all (at most t1/4) dense bins, we get that with probability 1 − e−Ω(λ\n2t1/4/ω):∑ i∈dense ξiαi ≥ (1− λ)µ · ( 1−max { 0, vS (H(A)) · t−1/4 }) ∑ BINq∈dense |BINq| · αmax(q)\n≥ (1− λ)µ · ( max { 0, 1− vS (H(A)) · t−1/4 }) ∑\ni∈dense αi. (2)\nLet α = 1t ∑t i=1 αi. Since we have less than t 1/4 elements in a sparse bin, and in total t1/4 bins, the number of elements in sparse bins is at most t1/2. We can use this to effectively lower bound the values in sparse bins in terms of α:\n∑ i∈dense αi = t∑ i=1 αi − ∑ i∈sparse αi\n≥ max { 0,\nt∑ i=1 αi − t1/2αmax } ≥ max { 0, tα− t1/2αmax\n} > max { 0, t · ( 1− αmax\nαmin · t−1/2\n) α } = max { 0, t · ( 1− vS(H) · t−1/2 ) α }\n(3)\n41\nPutting (2) and (3) we get that for any λ < 1, with probability 1− e−Ω(λ2t1/4/ω):\nF̃S(A) = 1\nt t∑ i=1 ξi · αi\n≥ 1 t ∑ i∈dense ξi · αi\n≥ (1− λ)µ · (max { 0, 1− vS (H(A)) · t−1/4 }\n) · 1 t ∑ i∈dense αi\n≥ (1− λ)µ · (max { 0, 1− vS (H(A)) · t−1/4 } )(max { 0, 1− vS (H(A)) · t−1/2 } )α\n> (1− λ)µ · (max { 0, 1− 2vS (H(A)) · t−1/4 } )α\n= (1− λ)µ · (max { 0, 1− 2vS (H(A)) · t−1/4 } )FS(A)\nTaking a union bound we get that for any positive λ < 1 with probability 1− e−Ω(λ2t1/4/ω):\nF̃ (S ∪A) = 1 t t∑ i=1 ξif(S) + 1 t t∑ i=1 ξiαi\n> (1− λ)µ · ( f(S) + (max { 0, 1− 2vS(H(A)) · t−1/4) · FS(A) }) = (1− λ)µ · ( f(S) + (1−min { 1, 2vS(H(A)) · t−1/4) · FS(A) }) .\nThe next lemma gives us an upper bound on the noisy smooth value. The bound shows that for sufficiently large t (the size of the smoothing neighborhood, which always depends on n), for small λ > 0 we have that F̃ (S) ≈ (1 + λ)F (S) + 3t−1/4 · αmax. In our applications of smoothing αmax ≤ OPT, and t is large. Since we use this upper bound to compare against elements whose value is at least some bounded factor of OPT, the dependency of the additive term on αmax will be insignificant.\nLemma A.5. Let f : 2N → R, A,S ⊆ N , ω = maxAi∈H(A) ξAi , αmax = maxAi∈H(A) fS(Ai) and µ be the mean of the noise distribution. For = 3t−1/4αmax we have that for any λ < 1 with probability 1− e−Ω(λ2t1/4/ω):\nF̃ (S ∪A) < (1 + λ)µ · (f(S) + FS(A) + ) .\nProof. As in the proof of Lemma A.4 let A1, . . . , At denote the sets inH(A), and for each set Ai we will again use αi to denote the marginal value fS(Ai) and ξi to denote the noise multiplier ξS∪{Ai}.\nF̃ (S ∪A) = 1 t t∑ i=1 ξif(S) + 1 t t∑ i=1 ξiαi. (4)\nAs before, we will focus on showing concentration on the second term. Define αmax = maxi αi and αmin = mini αi. To apply concentration bounds on the second term, we again partition the values of {αi}i∈[t] to bins of width αmax · t−1/4 and call a bin dense if it has at least t1/4 values and sparse\n42\notherwise. Using this terminology:\nt∑ i=1 ξiαi = ∑ i∈dense ξiαi + ∑ i∈sparse ξiαi.\nLet BIN` be the dense bin whose elements have the largest values. Consider the t1/4/2 largest values in BIN` and call the set of indices associated with these values L. We have:\nt∑ i=1 ξiαi = ∑ i∈dense\\L ξiαi + ∑ i∈L∪sparse ξiαi\nThe set L∪ sparse is of size at least t1/4/2 and at most t1/4/2 + t1/2. This is because L is of size exactly t1/4/2 and there are at most t1/2 values in bins that are sparse since there are t1/4 bins and a bin that has at least t1/4 is already considered dense. Thus, when ω is an upper bound on the value of the noise multiplier, from Chernoff, for any λ < 1 with probability 1− e−Ω(λ2t1/4/ω):∑\ni∈L∪sparse ξiαi ≤ ∑ i∈L∪sparse ξiαmax\n< (1 + λ)µ · |L ∪ sparse| · αmax\n≤ (1 + λ)µ ·\n( t1/4\n2 + t1/2\n) αmax\n< (1 + λ)µ · 2t1/2αmax\nWe will now use the same logic as in the proof of Lemma A.4 to apply concentration bounds on the values in the dense bins. For a dense bin BINq, let αmax(q) and αmin(q) be the maximal and minimal values in the bin, respectively. As in Lemma A.4, for any λ < 1 with probability 1− e−Ω(λ2t1/4/ω):∑\ni∈BINq ξiαi ≤ ∑ i∈BINq ξi · αmax(q)\n≤ (1 + λ)µ · αmax(q) · |BINq| ≤ (1 + λ)µ · ( αmin(q) + αmax · t−1/4 ) · |BINq|\n< (1 + λ)µ · ( |BINq| · αmin(q) + |BINq|αmax · t−1/4 ) Applying a union bound we get with probability 1− e−Ω(λ2t1/4/ω):∑\ni∈dense\\L\nξiαi < ∑ q (1 + λ)µ · ( |BINq| · αmin(q) + |BINq|αmax · t−1/4 ) < (1 + λ)µ · t ( α+ t−1/4αmax )\n43\nTogether we have:\n1\nt t∑ i=1 ξiαi = 1 t  ∑ i∈dense\\L ξiαi + ∑ i∈L∪sparse ξiαi  < (1 + λ)µ · ( α+ t−1/4αmax + 2t −1/2αmax\n) < (1 + λ)µ · ( α+ 3t−1/4αmax\n) < (1 + λ)µ · ( FS(A) + 3t −1/4αmax )\nBy a union bound we get that with probability 1− e−Ω(λ2t1/4/ω):\nF̃ (S ∪A) = 1 t t∑ i=1 ξif(S) + 1 t t∑ i=1 ξiαi ≤ (1 + λ)µ · ( f(S) + FS(A) + 3t −1/4αmax ) .\n44"
    }, {
      "heading" : "B Optimization for Large k",
      "text" : "The Smooth Greedy Algorithm\nSmoothing guarantees\nLemma (2.1). For any fixed > 0, consider an -relevant iteration of SMOOTH-GREEDY where S is the set of elements selected in previous iterations and a ∈ arg maxb/∈H F̃ (S ∪ b). Then for δ = 2/4k and sufficiently large n we have that w.p. ≥ 1− 1/n4:\nFS(a) ≥ (1− δ) max b/∈H FS(b).\nTo prove the above lemma we will need claims B.1, B.2 and B.3. After proving B.3 the proof will follow by verifying that the number of sets in the smoothing set is sufficient to obtain the desired approximation (1− δ).\nClaim B.1. If FS(a) ≥ FS(b) then fS(a) ≥ fS∪H(b).\nProof. Assume for purpose of contradiction that fS(a) < fS∪H(b). Since f is a submodular function, fS(T ) = f(S ∪ T )− f(S) is also submodular (hence also subadditive). Therefore ∀H ′ ⊆ H :\nfS(H ′ ∪ a) ≤ fS(H ′) + fS(a) subadditivity of fS\n< fS(H ′) + fS∪H(b) by assumption ≤ fS(H ′) + fS∪H′(b) submodularity of fS = fS(H ′ ∪ b).\nNotice however, that this contradicts our assumption:\nFS(a) = 1\nt ∑ H′⊆H fS(H ′ ∪ a) < 1 t ∑ H′⊆H fS(H ′ ∪ b) = FS(b).\nThe following claim bounds the variation (see Definition A.3) of the smoothing neighborhood of the element we selected. This is a necessary property for later applying the smoothing arguments.\nClaim B.2. Let > 0. For an -relevant iteration of SMOOTH-GREEDY, let S be the set of elements selected in previous iterations. If a? ∈ arg maxa/∈H FS(a) then vS (H(a?)) < 3k/ .\nProof. Let b? ∈ argmaxb/∈H fH∪S(b). By the maximality of a? we have that FS(a?) ≥ FS(b?), and thus by Claim B.1 we get fS(a?) ≥ fH∪S(b?). Since the iteration is -relevant we have that fH∪S(b ?) ≥ · OPTH/k, and from monotonicity of f we get:\nmin H′⊆H\nfS(H ′ ∪ a?) ≥ fS(a?) ≥ fH∪S(b?) ≥ · OPTH k\nand since every set inH(a?) is of size at most k we know that maxH′⊆H fS(H ′∪a?) ≤ OPT. Together with the fact that OPT ≤ e · OPTH we get:\nvS (H(a?)) = maxH′⊆H fS(H ′ ∪ a?) minH′⊆H fS(H ′ ∪ a?) ≤ OPT OPTH · k < 3k .\n45\nWe can now show that in -relevant iterations the value of the element which maximizes the noisy smooth value is comparable to that of the (non-noisy) smooth value, with high probability. Recall that we use t to denote the size of the smoothing neighborhood.\nClaim B.3. Given > 0 assume t ≥ (\n110k·logn δ\n)8 . For an -relevant iteration of SMOOTH-GREEDY, let\nS be the elements selected in previous iterations and a ∈ arg maxb/∈H F̃ (S ∪ b). Then, w.p. ≥ 1− 1/n4:\nFS(a) ≥ (1− δ) max b/∈H FS(b).\nProof. Let a? be the element which maximizes smooth marginal contribution:\na? ∈ argmaxb/∈H FS(a)\nWe will show that for any element b whose smooth marginal contribution is a factor of (1 − δ) smaller than the smooth marginal contribution of a?, then w.h.p. its noisy value of is smaller than that of a?. That is, for any b /∈ H for which FS(b) < (1− δ)FS(a?) we get that F̃ (S ∪ b) < F̃ (S ∪ a?) with probability at least Ω(1− 1/n5). The result will then follow by taking a union bound over all comparisons. We will show that a? likely beats b by lower bounding F̃ (S∪a?) and upper bounding F̃ (S ∪ b) using the smoothing arguments from the previous section. We use ω to denote the value of the largest noise multiplier realized throughout the iterations of the algorithm. We later argue that we can upper bound ω ≤ 6 log n as the noise distribution has an exponentially decaying tail.\n• Lower bound on F̃ (S ∪ a?): First, from Claim B.2 we know that vS(H(a?)) ≤ 3k/ . Together with Lemma A.4 we get that ∀λ < 1 with probability 1− e−Ω(λ2t1/4/ω):\nF̃ (S ∪ a?) > (1− λ)µ · ( f(S) + ( 1− 6k · t−1/4 ) · FS(a?) ) (5)\n• Upper bound on F̃ (S ∪ b): Letting βmax = maxX∈H(b) f(X), from Lemma A.5, we get that ∀λ < 1 with probability 1− e−Ω(λ2t1/4/ω):\nF̃ (S ∪ b) < (1 + λ)µ · ( f(S) + FS(b) + 3t −1/4βmax ) (6)\nWe’ll express this inequality in terms of f(S) and FS(a?) as well. First, since all sets in H(b) are of size at most k we also know that βmax ≤ OPT. Thus:\n3t−1/4βmax ≤ 3t−1/4 · OPT (7)\nWe will now bound OPT in terms of FS(a?). Since every set inH(a?) includes a?, from monotonicity we get that FS(a?) ≥ fS(a?). Let b? ∈ argmaxb/∈H fH∪S(b). Due to the maximality of a? we have that FS(a?) ≥ FS(b?) and by Claim B.1 we know that fS(a?) ≥ fS∪H(b?). Since the iteration is -relevant we get:\nFS(a ?) ≥ fS(a?) ≥ fS∪H(b?) ≥\nfS∪H(OH) k ≥ · OPTH k > · OPT 3k (8)\n46\nPutting (8) together with (7) we get:\n3t−1/4βmax ≤ k · 9t−1/4 · FS(a?)\nPlugging into (6) and using the assumption that FS(b) < (1− δ)FS(a?) we get: F̃ (S ∪ b) < (1 + λ)µ · ( f(S) + FS(b) + ( 9t−1/4 · k ) FS(a ?) ) (9)\n< (1 + λ)µ · ( f(S) + ( 9t−1/4 · k + (1− δ) ) FS(a ?) ) (10)\nPutting (5) together with (10) we get that ∀λ < 1 with probability at least 1− 2e−Ω(λ2t1/4/ω):\nF̃ (S ∪ a?)− F̃ (S ∪ b) > µ · ( FS(a ?) [ (1− λ) ( 1− 6k t−1/4 ) − (1 + λ) ( 9k t−1/4 + (1− δ) )] − 2λf(S) ) ≥ µ · ( FS(a ?) [ (1− λ) ( 1− 6k t−1/4 ) − (1 + λ) ( 9k t−1/4 + (1− δ) )] − 2λOPT\n) > µ · ( FS(a ?) [ (1− λ) ( 1− 6k t−1/4 ) − (1 + λ) ( 9k t−1/4 + (1− δ) )] − 2λ3k FS(a ?)\n) = µ · ( FS(a ?) [ (1− λ) ( 1− 6k t−1/4 ) − (1 + λ) ( 9k t−1/4 + (1− δ) ) − 2λ3k\n]) = µ · ( FS(a ?) [ δ − 15k · t−1/4 − λ ( (2− δ) + 3k · t−1/4 + 6k\n)]) > µ · ( FS(a ?) [ δ − k ( 15t−1/4 + 10λ )])\nThe second inequality above is an application of (8) and the fact that f(S) ≤ OPT since |S| ≤ k. The third is from (8).\nFor the result to hold we need the above difference to be strictly positive, and hold with probability Ω(1− 1/n5). Thus, sufficient conditions would be:\n1. k · 15t −1/4 ≤ δ2 , and\n2. 10λ ≤ δ2 , and\n3. 1− 2 exp(−λ2t1/4ω ) ∈ Ω(1− 1/n 5).\nThe first condition holds when t ≥ (30k/ δ)4; the second condition holds when λ = δ/20k. For ω = 6 log n and λ = δ/20k, the third condition is satisfied when:\n( δ)2t1/4\n202k2ω =\n( δ)2t1/4\n202k26 log n ≥ 5 log n\nrearranging:\nt ≥ 120004 ( k log n\nδ )8 47\nThus, since t in the lemma statement respects:\nt ≥ ( 110k log n\nδ\n)8 > 120004 ( k log n\nδ )8 we have that the first, second, and third conditions are met conditioned on ω ≤ 6 log n. That is, we have that the difference is positive with probability 1− 2 exp(−λ2t1/4ω ) ≥ 1− 2/n\n5, conditioned on ω ≤ 6 log n. From lemma A.2 we know that the probability of ω > 6 log n is smaller than 1/n5 for sufficiently large n. Therefore, by taking a union bound on the probability of the event in which the difference is negative and the probability that ω > 6 log n, both occurring with probability smaller than 2/n5 we have that the probability of the difference being positive is at least 1−4/n5 ∈ Ω(1− 1/n5), as required.\nProof of Lemma 2.1. By Claim B.3, when δ = 2/4k for any fixed > 0 we need to verify that for sufficiently large n:\nt >\n( 110k log n\nδ\n)8 = (440k2 log n)8\n3\nIn the case where k ≥ log n we use ` = 25 log n and thus t = 2` = n25 and the above inequality holds. When k < log n we use ` = 33 log log n and thus t = log33 n and the above inequality holds in this case as well. We therefore have the result with probability at least 1− 1/n4.4\nApproximation guarantee\nClaim (2.2). For any > 0, let δ ≤ 2/4k. Suppose that the iteration is -relevant and let b? ∈ argmaxb/∈H fH∪S(b). If FS(a) ≥ (1− δ)FS(b?), then:\nfS(a) ≥ (1− )fH∪S(b?).\nProof. First, we upper bound FS(a):\nFS(a) = 1\nt ∑ H′⊆H fS(H ′ ∪ a) by definition of FS\n= 1\nt ∑ H′⊆H ( fS(H ′) + fS∪H′(a) )\n≤ 1 t ∑ H′⊆H ( fS(H ′) + fS(a) )\nby submodularity of f\n= fS(a) + 1\nt ∑ H′⊆H fS(H ′) t = 2|H|\n4Note that we could have used smaller values of ` to achieve the desired bound. The reason we exaggerate the values of ` is to be consistent with the analysis of SLICK-GREEDY which necessitates these slightly larger values of `.\n48\nNext, we lower bound (1− δ)FS(b?):\n(1− δ)FS(b?) = (1− δ) 1\nt ∑ H′⊆H fS(H ′ ∪ b?) by definition of FS\n= (1− δ)1 t ∑ H′⊆H ( fS(H ′) + fS∪H′(b ?) ) ≥ (1− δ)1 t ∑ H′⊆H ( fS(H ′) + fS∪H(b ?) )\nby submodularity of f\n= (1− δ)fH∪S(b?)− δ 1\nt ∑ H′⊆H fS(H ′) + 1 t ∑ H′⊆H fS(H ′) t = 2|H|\nSince FS(a) ≥ (1− δ)FS(b?) this implies that:\nfS(a) ≥ (1− δ)fH∪S(b?)− δ 1\nt ∑ H′⊆H fS(H ′)\n≥ (1− δ)fH∪S(b?)− δ 1\nt ∑ H′⊆H fS(H) monotonicity of f\n≥ (1− δ)fH∪S(b?)− δfS(H) t = |H ′| ≥ (1− δ)fH∪S(b?)− δOPT |H| ≤ k ≥ (1− δ)fH∪S(b?)− eδOPTH OPTH ≥ OPT/e\n≥ (1− δ)fH∪S(b?)− eδ · k · fH∪S(b?) -relevant iteration\n= ( 1− δ ( 1 + e · k )) fH∪S(b ?)\n≥ ( 1− δ ( 4k )) fH∪S(b ?)\n= (1− )fH∪S(b?). δ ≤ 2/4k\nClaim (2.3). For any fixed > 0, consider an -relevant iteration of SMOOTH-GREEDY with S as the elements selected in previous iterations. Let a ∈ arg maxb/∈S∪H F̃ (S ∪ b). Then, w.p. ≥ 1− 1/n4:\nfS(a) ≥ ( 1− )[ 1\nk′\n( OPTH − f(S) )] .\nProof. Let O ∈ argmaxT :|T |≤k′fH(T ), o ? ∈ argmaxo∈OfH∪S(o) and b ? ∈ argmaxb/∈H fH∪S(b). From Lemma 2.1 we know that with probability 1− 1/n4 we have FS(a) ≥ (1− δ)FS(b?) for δ = 2/4k, and together with Claim 2.2 we get:\nfS(a) ≥ (1− )fH∪S(b?) ≥ (1− )fH∪S(o?)\nFrom subadditivity fH∪S(o?) ≥ fH∪S(O)/k′ and thus:\nfS(a) ≥ (1− )fH∪S(o?) ≥ (\n1− k′\n) fH∪S(O) ≥ ( 1− k′ )( fH(O)− f(S) ) .\n49\nLemma (2.4). Let S be the set returned by SMOOTH-GREEDY and H its smoothing set. Then, for any fixed > 0 when k ≥ 3`/ with probability of at least 1− 1/n3 we have that:\nf(S ∪H) ≥ (1− 1/e− /3)OPTH .\nProof. In case OPTH < OPT/e then H alone provides a 1− 1/e− /3 approximation. To see this, let O ∈ argmaxT :|T |≤k f(T ) and O′ ∈ argmaxT :|T |≤k′ f(T ), and OH ∈ argmaxT :|T |≤k′ fH(T ). We get:\n(1− /3)f(O) ≤ f(O′) k′ = k − ` and k ≥ 3`/ ≤ f(H ∪O′) monotonicity = f(H) + fH(O ′)\n≤ f(H) + fH(OH) optimality of OH < f(H) + f(O)/e eOPTH < OPT\nThus:\nf(H) ≥ (\n1− 1 e − 3\n) OPT ≥ ( 1− 1\ne − 3\n) OPTH\nIn case OPTH ≥ OPT/e we set γ = min{1/e, /6}. We will use the following notation. At every iteration i ∈ [k′] of the while loop in the algorithm, we will use ai to denote the element that was added in that step, and Si := {a1, . . . , ai}.\nFirst, notice that if there exists an iteration i that is not γ-relevant, our bound trivially holds:\nfH∪Si(OH) ≤ k′ · max o∈OH fH∪Si(o) ≤ k′ · max b/∈Si∪H fH∪Si(b) ≤ k′ · γOPTH k < γOPTH\nSince fH∪Si(OH) = f(H ∪ Si ∪ OH) − f(H ∪ Si), the above inequality implies that f(H ∪ Si) > f(H ∪ Si ∪OH)− γOPTH . But this implies:\nf(S ∪H) ≥ f(Si ∪H) > f(OH ∪ Si ∪H)− γOPTH ≥ f(OH)− γOPTH ≥ fH(OH)− γOPTH = (1− γ)OPTH ≥ (1− 1/e)OPTH\nIt remains to prove the approximation guarantee in the case that every iteration is γ-relevant. To do so, we can apply a standard inductive argument on Claim 2.3 to show that S alone provides a 1− 1/e− /3 approximation. Claim 2.3 states that for γ-relevant iterations, at every stage i ∈ [k′]:\nf(Si+1)− f(Si) ≥ (1− γ) [ 1\nk′ (fH(OH)− f(Si))\n] . (11)\nWe will show that at every stage i ∈ [k′]:\nf(Si) ≥ (1− γ) ( 1− ( 1− 1\nk′\n)i) fH(OH).\n50\nThe proof is by induction on i. For i = 1 we have that Si = {a1} and invoking Claim 2.3 with S = ∅we get that f(ai) ≥ (1− γ) 1k′ fH(OH). Therefore:\nf(S1) = f(a1) ≥ (1− γ) 1\nk′ fH(OH) = (1− γ)\n( 1− ( 1− 1\nk′\n)) fH(OH).\nWe can now assume the claim holds for i = l < k′ and show that it holds for i = l + 1: f(Sl+1) ≥ (1− γ) ( 1\nk′ (fH(OH)− f(Sl))\n) + f(Sl) By (11)\n> (1− γ) (( 1\nk′ fH(OH)\n) + ( 1− 1\nk′\n) f(Sl) ) δ > 0\n≥ (1− γ) ( 1\nk′ fH(OH)\n) + (1− γ) ( 1− 1\nk′\n)( 1− ( 1− 1\nk′\n)l) fH(OH) inductive hypothesis\n= (1− γ) ( 1− ( 1− 1\nk′\n)l+1) fH(OH)\nNote that for any l > 1 we have that (1− 1/l)l ≤ 1/e, and thus:\nf(S) = f(Sk′)\n≥ (1− 1/e− γ)fH(OH) by the induction > (1− 1/e− /3)OPTH . γ = /6\nCorollary B.4. Let S be the set returned by SMOOTH-GREEDY and H be its smoothing set. For any fixed > 0 and k > 3`/ , we have that with probability at least 1− 1/n3:\nf(S ∪H) > (\ne− 1 2e− 1−\n− 2 ) OPT.\nProof. Let OH ∈ argmaxT :|T |≤k′fH(T ). From Lemma 2.4, with probability at least 1− 1/n 3:\nf(S ∪H) > (\n1− 1 e − 3\n) f(OH) (12)\nLet O′ ∈ argmaxT :|T |≤k−|H| f(T ). From submodularity and the fact that k ≥ 3`/ > |H|/ we get that (1− )OPT ≤ f(O′). Putting everything together:\n(1− )OPT ≤ f(O′) submodularity of f ≤ f(OH ∪H) monotonicity of f ≤ f(OH) + f(H) subadditivity of f\n≤ (\ne\ne− 1−\n) f(S ∪H) + f(H) by (12)\n≤ (\n2e− 1− e− 1−\n) f(S ∪H). monotonicity of f\nTherefore f(S ∪H) > (\ne−1 2e−1− − 2\n) OPT as required.\n51\nSlick Greedy: Optimal Approximation for Sufficiently Large k\nAs described in the main body of the paper, in SLICK-GREEDY we apply a slightly more general version of SMOOTH-GREEDY where in each iteration i ∈ [1/δ] the algorithm SMOOTH-GREEDY is initialized with the set of elements Ri = ∪j 6=iHj and uses the smoothing set Hi. SMOOTH-GREEDY from the previous section is a special case in which Ri = ∅. As one might imagine, the guarantees from the previous section carry over, using the appropriate definitions.\nGeneralizing guarantees of smooth greedy\nTo make the transition to the case in which SMOOTH-GREEDY is being initialized with Ri of size `/δ − ` and selects k′′ = k − |Ri| − |Hi| = k − `/δ elements, we extend our definitions as follows. For a given set Ri used for initialization, it’ll be convenient to consider the function gi(T ) = fRi(T ), and its smooth value Gi(a) = 1 t ∑t i=1 g (S ∪ (Hi ∪ a)). When the smoothing set is clear from context we will generally use R,H, g,G instead of Ri, Hi, gi, Gi. The value of the optimal solution here is OPT[G] = maxT :|T |≤k′′ g(T ) where k′′ = k − |R| − |H|. We can then also define OPT[G]H = maxT :|T |≤k′′ gH(T ). For a given set S of elements selected by SMOOTH-GREEDY and b? ∈ argmaxb/∈H gS∪H(b), an -relevant iteration is one in which gH∪S(b?) ≥ OPT[G]H/k and OPT[G]H ≥ OPT[G]/e.\nLower bounding the marginal contribution in each iteration. We first show that when SMOOTH-GREEDY is initialized with a set R and run with smoothing set H , then in every γrelevant iteration the element a selected respects gS(a) ≥ (1− γ)gH∪H(b?). This claim is necessary for proving Lemma B.7 which shows the approximation guarantee of SMOOTH-GREEDY in each iteration of SLICK-GREEDY as well as for proving guarantees of SMOOTH-COMPARE in Lemma 2.6.\nClaim B.5. For a given set R ⊂ N , let g(T ) = fR(T ). For any fixed γ > 0 consider a γ-relevant iteration of SMOOTH-GREEDY initialized with some set R using smoothing set H s.t. H ∩R = ∅, and let S be the set of elements selected before the iteration. If a ∈ argmaxb/∈H F̃ (R ∪ S ∪ b) then w.p.≥ 1− 1/n4:\ngS(a) ≥ (1− γ)gH∪S(b?)\nProof. Let G denote the smooth value function of g, i.e. G(S ∪ a) = 1t ∑\nH′⊂H g(S ∪ H ′ ∪ a). The proof in a chaining of four simple arguments. Let λ = γ2/4k and α = γλ/3k. We show:\n1. F̃ (R ∪ S ∪ a) ≥ F̃ (R ∪ S ∪ b?) =⇒ FR∪S(a) ≥ (1− α) FR∪S(b?) 2. FR∪S(a) ≥ (1− α) FR∪S(b?) =⇒ G(S ∪ a) ≥ (1− α) G(S ∪ b?) 3. G(S ∪ a) ≥ (1− α) G(S ∪ b?) =⇒ GS(a) ≥ (1− λ) GS(b?) 4. GS(a) ≥ (1− λ) GS(b?) =⇒ gS(a) ≥ (1− γ) gH∪S(b?)\nThe above arguments can be justified as follows:\n52\n1. To see F̃ (R∪T ∪a) ≥ F̃ (R∪T ∪b?) implies FR∪T (a) ≥ (1−α)FR∪T (b?), we invoke Claim B.3 on S = R ∪ T . To do so, since α ≤ γ3/24k2 for sufficiently large n we need to verify:\nt >\n( 110k log n\nγα\n)8 = ( 2640k3 log n\nγ3 )8 In the case where k ≥ 2400 log n we use ` = 25 log n and thus t = 2` = n25 and the above inequality holds. When k < 2400 log n we use ` = 33 log logn and thus t = log33 n and the above inequality holds in this case as well. We therefore have the result w.p. ≥ 1− 1/n4.\n2. Assuming that FR∪S(a) ≥ (1− α)FR∪S(b?) we will show that G(S ∪ a) ≥ (1− α)G(S ∪ b?):\nFR∪S(a) ≥(1− α)FR∪S(b?)\n=⇒ 1 t ∑ H′⊂H fR∪S(H ′ ∪ a) ≥(1− α)1 t ∑ H′⊂H fR∪S(H ′ ∪ b?) =⇒ 1 t ∑ H′⊂H ( f(R ∪ S ∪H ′ ∪ a)− f(R ∪ S) ) ≥(1− α)1 t ∑ H′⊂H ( f(R ∪ S ∪H ′ ∪ b?)− f(R ∪ S)\n) =⇒ 1\nt ∑ H′⊂H ( f(R ∪ S ∪H ′ ∪ a)− f(R) ) ≥(1− α)1 t ∑ H′⊂H ( f(R ∪ S ∪H ′ ∪ b?)− f(R) ) =⇒ 1\nt ∑ H′⊂H fR(S ∪H ′ ∪ a) ≥(1− α) 1 t ∑ H′⊂H fR(S ∪H ′ ∪ b?)\n=⇒ 1 t ∑ H′⊂H g(S ∪H ′ ∪ a) ≥(1− α)1 t ∑ H′⊂H g(S ∪H ′ ∪ b?) =⇒ G(S ∪ a) ≥(1− α)G(S ∪ b?)\n3. G(S ∪ a) ≥ (1− α)G(S ∪ b?) =⇒ GS(a) ≥ (1− λ)GS(b?): We first argue GS(b?) > γOPT[G]e·k′′ :\nGS(b ?) =\n1\nt ∑ H′⊂H ( g(S ∪ b? ∪H ′)− g(S) ) ≥ 1 t ∑ H′⊂H ( g(S ∪ b? ∪H ′)− g(S ∪H ′) ) monotonicity of g ≥ 1 t ∑ H′⊂H (g(S ∪ b? ∪H)− g(S ∪H)) submodularity of g = g(S ∪ b? ∪H)− g(S ∪H) = gS∪H(b ?) ≥ γ k′′ OPT[G]H γ-relevant iteration > γ\ne · k′′ OPT[G] OPT[G]H > OPT[G]/e\n53\nNow, in a similar fashion to Claim 2.2:\nGS(a) = G(S ∪ a)−G(S) ≥ (1− α) (G(S ∪ b?)−G(S))− αG(S) ≥ (1− α) (G(S ∪ b?)−G(S))− αOPT[G]\n≥ (1− α) (G(S ∪ b?)−G(S))− αe · k ′′\nγ ·GS(b?) GS(b?) >\nγOPT[G]\ne · k′′\n= (1− α) (GS(b?))− α e · k′′\nγ ·GS(b?)\n= ( 1− α ( 1 + e · k′′\nγ\n)) GS(b ?)\n= (1− λ)GS(b?) α = λ/3k and k ≥ k′′ + 1\n4. GS(a) ≥ (1− λ)GS(b?) =⇒ gS(a) ≥ (1− γ)gH∪S(b?): by direct application of Claim 2.2\nDefinition B.6. Given two disjoint sets H and R, let OPTH,R = f(H ∪R ∪OH,R)− fR(H) where:\nOH,R ∈ argmaxT :|T |≤k−|H∪R| f(H ∪R ∪ T ).\nNotice that when R = ∅ we have that OH,R = OH ∈ argmaxT :|T |≤k−|H| fH(T ) as defined in the previous subsection. In that sense, the value of OH,R is that of the optimal solution evaluated on fH when initialized with R. In the same way Lemma 2.4 shows SMOOTH-GREEDY obtains a 1− 1/e− /3 approximation to OPTH , the following lemma shows that when SMOOTH-GREEDY is initialized with R it obtains the same guarantee against OPTH,R. Details are in Appendix ??.\nLemma B.7. Let S be the set returned by SMOOTH-GREEDY that is initialized with a set R ⊆ N and has H as its smoothing set of size `, which is disjoint from R and S. Then, for any fixed > 0 when k ≥ 3|H ∪R|/ with probability of at least 1− 1/n3 we have that:\nf(R ∪ S ∪H) ≥ (1− 1/e− /3)OPTH,R.\nProof. Notice that the proof of Lemma 2.4 applies for the application of SMOOTH-GREEDY on any submodular function v where in every γ-relevant iteration vS(a) ≥ (1 − γ)vS∪H(b?) with probability 1 − 1/n4, for γ ∈ min{1/e, /6}, and S being the elements added in the previous iteration. From Claim B.5 we have that for any γ-relevant iteration gS(a) ≥ (1− γ)gS∪H(b?) w.p. ≥ 1− 1/n4. We can therefore apply the exact same proof on g and get:\ng(S ∪H) ≥ (1− 1/e− /3)OPT[G]H (13)\nLet OH ∈ argmaxT :|T |≤k−|R∪H| g(T ) and let OH,R ∈ argmaxT :|T |≤k−|H∪R| f(H ∪ R ∪ T ). Observe that by definition of g(X) = fR(X) we have that:\nf(H ∪R ∪OH,R) = f(H ∪R ∪OH)\n54\nand thus from (13) we get:\nf(R ∪ S ∪H)− f(R) = fR(S ∪H) = g(S ∪H) ≥ (1− 1/e− /3)gH(OH) ≥ (1− 1/e− /3) (g(OH ∪H)− g(H)) = (1− 1/e− /3) (fR(OH ∪H)− fR(H)) ≥ (1− 1/e− /3) (f(R ∪OH ∪H)− f(R)− fR(H)) ≥ (1− 1/e− /3) (f(R ∪OH,R ∪H)− fR(H))− (1− 1/e− /3)f(R)\nand we therefore have that f(R ∪ S ∪H) ≥ (1− 1/e− /3) (f(R ∪OH,R ∪H)− fR(H)).\nWe will instantiate the Lemma with R = Rl and H = Hl as discussed above: for any i ∈ [1/δ] we will define Ri = ∪j 6=iHj and use the index l to denote the smoothing set in {Hi} 1/δ i=1 which has the least marginal contribution to the rest, i.e. Hl = argmini∈[1/δ] fRi(Hi). We first show that the iteration of SLICK-GREEDY on l finds a solution arbitrarily close to 1− 1/e for sufficiently large k.\nLemma (2.5). Let Sl be the set returned by SMOOTH-GREEDY that is initialized with Rl and Hl its smoothing set. Then, for any fixed > 0 when k ≥ 36`/ 2 with probability of at least 1− 1/n3 we have:\nf(Sl ∪Hl) ≥ (1− 1/e− 2 /3)OPT\nProof. To ease notation, letR = Rl,H = Hl, andO = Ol whereOl is the solution which maximizes f(H ∪ R ∪ T ) over all subsets T of size at most k − |H ∪ R|. Let β = |H ∪ R|/k. Notice that by submodularity we have that:\nf(H ∪R ∪O) ≥ (\n1− |H ∪R| k\n) OPT = (1− β)OPT (14)\nNotice also that by the minimality ofH = Hl and submodularity we have that fR(H) ≤ δf(H∪R). Recall also that δ = /6 and notice that whenever k ≥ `/δ2 = 36`/ 2 we have that β < δ and hence β + δ < /3. Therefore, by application of Lemma B.7 we get that with probability 1− 1/n3:\nf(S ∪R ∪H) ≥ (\n1− 1 e − 3\n) OPTH,R by Lemma B.7\n= ( 1− 1\ne − 3\n) (f(H ∪R ∪O)− fR(H)) by definition\n≥ (\n1− 1 e − 3\n) (f(H ∪R ∪O)− δ · f(H ∪R)) fR(H) ≤ δf(H ∪R)\n≥ (\n1− 1 e − 3\n) ((1− δ)f(H ∪R ∪O)) monotonicity of f\n≥ (\n1− 1 e − 3 − δ ) (f(H ∪R ∪O))\n≥ (\n1− 1 e − 3 − δ ) (1− β)OPT by (14)\n≥ (\n1− 1 e − 2 3\n) OPT. β + δ < /3\n55\nThe smooth comparison procedure\nLemma (2.6). Assume k ≥ 96`/ 2. Let Ti be the set that won the SMOOTH-COMPARE tournament. Then, with probability at least 1− 1/n2:\nf(Ti) ≥ (\n1− 3\n) min {( 1− 1\ne − 2 3\n) OPT, max\nj∈[1/δ] f(Tj)\n}\nThe proof of the lemma uses the following two claims.\nClaim B.8. Let Ti = Si ∪Hi and Tj = Sj ∪Hj be two sets that are compared by SMOOTH-COMPARE, and suppose that (i)f(Ti) ≥ (1 + 2β)f(Tj) where β = |Hij |/k′′ and k′′ = k − `/δ, and (ii) f(Tj) < (1− 1/e− 2 /3)OPT for any ≥ 3(1− k′′/k)/2. Then, for any set H ′ij ⊆ Hij w.p. ≥ 1− 1/n3:\nf(Ti ∪H ′ij) ≥ f(Tj ∪H ′ij).\nProof. Recall that Hij ∩ ( Ti ∪ Tj ) = ∅. We will argue that assuming f(Tj) < (1− 1/e)OPT, the fact that every element in H ′ij was a candidate for selection by SMOOTH-GREEDY and wasn’t selected, implies that w.h.p. either (i) f(Tj) is arbitrarily close to 1 − 1/e (in which case we wouldn’t mind that if it wins the comparison) or (ii) the marginal contribution of H ′ij to Tj is bounded from above by 2βf(Tj) which suffices since then we get:\nf(Tj ∪H ′ij) = f(Tj) + fTj (H ′ij) ≤ (1 + 2β)f(Tj) < f(Ti) ≤ f(Ti ∪H ′ij)\nTo prove this, consider the instantiation of SMOOTH-GREEDY initialized with Rj with smoothing set Hj , and let S be the set selected after its k′′ = k− |Rj | − |Hj | iterations. Recall that Sj = Rj ∪ S and that Tj = Sj ∪Hj . To ease notation let R = Rj and H = Hj .\nWe will first prove the statement in the case that the iteration is γ-relevant for γ = 1/4. For every iteration r ∈ [k′′] let S(r) be the set of elements selected in the previous iterations and a(r) be the element added to the solution at that stage by SMOOTH-GREEDY. From Claim B.5 we know that since a(r) ∈ argmaxb F̃ (R ∪ S(r) ∪ b) and the size of the smoothing neighborhood t is sufficiently large then w.p. ≥ 1− 1/n4:\ngS(r)(a(r)) ≥ (1− γ) max b/∈H gH∪S(r)(b)\n56\nWe therefore have that:\ng(S) = k′′∑ r=1 gS(r)(ar)\n≥ k′′∑ r=1 (1− γ) max b/∈H gS(r)∪H(b)\n≥ k′′∑ r=1 (1− γ) max b/∈H gS∪H(b) = k′′(1− γ) max b/∈H gS∪H(b) ≥ k′′(1− γ) max h∈H′ij gS∪H(h) ≥ k ′′(1− γ) |H ′ij | gS∪H(H ′ ij) ≥ (1− γ)k ′′\n` gS∪H(H\n′ ij)\nSince g(T ) = fR(T ) and γ = 1/4 this implies:\nf(R ∪ S)− f(R) > k ′′\n2`\n( f(R ∪H ∪H ′ij)− f(R ∪ S) ) Since Tj = Rj ∪ S ∪Hj = R ∪ S ∪H we get:\nfTj (H ′ ij) <\n2` k′′ f(Tj) = 2βf(Tj).\nIf the iteration is not γ-relevant, assume first that e · OPT[G]H ≥ OPT[G]. In this case, let OH = argmaxT :|T |≤k′′ gH(T ). Notice that the fact that iteration is not relevant in this case says that there is an iteration r for which maxb/∈H gH∪S(r)(b) < γOPT[G]H/k and from submodularity of g since S(r) ⊆ S we get maxb/∈H gH∪S(b) < γOPT[G]H/k. Thus:\ngH∪S(OH) ≤ k′′ · gH∪S(b?)\n≤ k′′ · γOPT[G]H k\n< γOPT[G]H\nwhich implies:\ng(H ∪ S) > g(OH ∪H ∪ S)− γOPT[G]H ≥ gH(OH)− γOPT[G]H = (1− γ)OPT[G]H\n57\nUsing this bound we get:\ngH∪S(H ′ ij) ≤ |H ′ij | max\nh∈H′ij gH∪S(h)\n≤ |H ′ij |max b/∈H gH∪S(b) ≤ |H ′ij | γ\nk OPT[G]H\n< γ`\nk(1− γ) g(H ∪ S)\nAgain, as before for δ = 1/4 we get that in this case:\nfTj (H ′ ij) <\n2` k′′ f(Tj) = 2βf(Tj)\nLastly, it remains to show that if if the iteration is not γ-relevant because e · OPT[G]H < OPT[G], we get a contradiction to our assumption that f(Tj) < (1 − 1/e − 2 /3)OPT. To see this, let O ∈ argmaxT :|T |≤k′′ g(T ), and notice that:\ng(H ∪OH)− g(H) < g(O)\ne\nhence:\nf(R ∪H)− f(R) = g(H)\n> g(H ∪OH)− g(O)\ne ≥ (\n1− 1 e\n) g(O)\n≥ (\n1− 1 e\n) (f(R ∪O))− f(R)\nWe therefore get that f(Tj) ≥ f(R ∪ H) > (1 − 1/e)f(O). Notice that since |O| = k′′ and k′′/k ≥ (1− 2 /3), submodularity implies f(Tj) ≥ (1− 1/e− 2 /3)OPT, a contradiction.\nClaim B.9. For k ≥ 96`/ 2 suppose that f(Ti) ≥ (1 + δ/3)f(Tj) and that f(Tj) ≤ (1− 1/e− 2 /3)OPT. Then, Ti wins in the smooth comparison procedure w.p. ≥ 1− 2/n3.\nProof. Let β = |Hij |/k′′ where k′′ = k − (|Hij | + |Ri|). Since we assume that k ≥ 96` and δ = /6 this implies that 2β < 2/45. We therefore have:\nf(Ti) >\n( 1 + δ\n3\n) f(Tj) = ( 1 + 2\n18\n) f(Tj) > ( 1 + 2\n45\n)2 f(Tj) > (1 + 2β) 2 f(Tj)\nFrom Claim B.8 this implies that for any H ′ij ⊆ Hij we have that with probability at least 1− 1/n3:\nf(Tj ∪H ′ij) ≤ (1 + 2β)f(Tj ∪H ′ij)\n58\nWe will condition on this event as well as the event that the maximal value obtained throughout the iterations of the algorithm is νmax and minimal value is νmin, and that νmax/νmin ≤ nτ for some constant τ > 0.\nPr [ f̃(Ti ∪H ′ij) ≥ f̃(Tj ∪H ′ij) ∣∣∣f(Ti) ≥ (1 + δ 3 ) f(Tj) ] = Pr [ ξif(Ti ∪H ′ij) ≥ ξjf(Tj ∪H ′ij) ∣∣∣f(Ti) ≥ (1 + δ 3 ) f(Tj)\n] > Pr [ (1 + 2β) · ξi\nξj ≥ 1 ] ≥ 1\n2 +\n1\n2 log1+2β( νmax νmin )\nThe last inequality follows from a discretization argument: Consider the m ∈ O(log n) intervals, where the i’th interval is [νmin(1 + 2β)i, νmin(1 + 2β)i+1], and i ranges from 0 to log1+2β( νmax νmin\n). Due to symmetry of ξi and ξj , the likelihood of ξi falling in the same or higher interval than ξj is:∑m\ni=1 i\nm2 =\n1 2 + 1 2m = 1 2 +\n1\n2 log1+2β( νmax νmin\n) =\n1 2 +\n1\n2τ log1+2β n\nApplying a Chernoff bound, for any constants , δ > 0, s.t. δ/8 > 1 + 2β, and νmax/νmin ≤ nτ for some constant τ > 0, we get that Ti is chosen with probability at least 1− exp(−Ω(n/ log(n))), conditioned on νmax/νmin < nτ which by Lemma A.2 occurs with probability 1− exp(−Ω(nα)) for some constant α > 0. For sufficiently large n, Ti therefore wins w.p. at least 1− 2/n3.\nProof of Lemma 2.6. Since ∀i, j ∈ [1/δ] SMOOTH-COMPARE({Ti, Tj}, Hij) returns Ti as long as f(Ti) ≥ (1 − δ/3)f(Tj) and f(Tj) < (1 − 1/e − 2 /3)OPT, and SMOOTH-COMPARE is called 1/δ times we get:\nf(Ti) ≥ (\n1− δ 3\n) 1/δ × min {( 1− 1\ne − 2 3\n) OPT, max\nj∈[1/δ] f(Tj) } ≥ ( 1−\n3\n) × min {( 1− 1\ne − 2 3\n) OPT, max\nj∈[1/δ] f(Tj)\n} .\n59"
    }, {
      "heading" : "C Optimization for Small k",
      "text" : "Smoothing Guarantees\nLemma C.1 (3.1). For any > 0 and any set S ⊂ N , let A? ∈ arg maxA:|A|=1/ fS(A). Then:\n(1− ) fS(A?) ≤ FS(A?) ≤ fS(A?).\nProof. By the maximality of A? we have that f(A?) ≥ f(A?ij) for any i, j since A?ij is generated by replacing ai ∈ A? with aj /∈ A? ∪S. Therefore, the average of all Aijs is upper bounded by fS(A?).\nFor the lower bound, let c = 1/ and consider some arbitrary ordering on a1, . . . , ac ∈ A?. Define A-i = A \\ {ai}. From the diminishing returns property we get that for any i ∈ [c]:\nfS∪A?-i(ai) = f(S ∪A ? -i ∪ ai) − f(S ∪A?-i)\n≤ f(S ∪ {a1 . . . , ai}) − f(S ∪ {a1, . . . , ai−1})\nThus: c∑ i=1 fS∪A?-i(ai) ≤ c∑ i=1 (f(S ∪ {a1 . . . , ai})− f(S ∪ {a1, . . . , ai−1})) = fS(A?) (15) By summing over all A?-i we get the desired bound:\nFS(A ?) =\n1\nc(n− c− |S|) n−c−|S|∑ j=1 c∑ i=1 fS(A ? ij)\n≥ 1 c c∑ i=1 fS(A ? -i) monotonicity, since A ? -i ⊂ A?ij\n= 1\nc c∑ i=1 ( fS(A ? -i ∪ ai)− fS∪A?-i(ai) ) = 1\nc c∑ i=1 fS(A ?)− 1 c c∑ i=1 fS∪A?-i(ai)\n≥ fS(A?)− 1\nc fS(A\n?) by (15)\n= ( 1− 1\nc\n) fS(A ?)\n= (1− ) fS(A?).\nThe smoothing lemma. The rest of this subsection is devoted to proving the following important lemma. Intuitively, this lemma implies that at every iteration of SM-GREEDY we identify the bundle which nearly maximizes the mean marginal contribution.\nLemma (3.2). Let A ∈ argmaxB:|B|=c F̃ (S ∪ B) where c ≥ 16 , and assume that the iteration is 4 - significant. Then, with probability at least 1− e−Ω(n1/10) we have that:\nFS(A) ≥ (1− ) max B:|B|=c FS(B).\n60\nSmoothing neighborhoods. The proof uses the smoothing arguments developed in Section A. Recall that for a given set of elements A ⊆ N a smoothing function is a method which assigns A a family of sets H(A) called the smoothing neighborhood. For a given function f : 2N → R, A,S ⊆ N , and smoothing neighborhoodH(A) we define:\n(1) FS(A) := EX∈H(A) [ fS(X) ]; (2) F(S ∪A) := EX∈H(A) [ f(S ∪X) ];\n(3) F̃(S ∪A) := EX∈H(A) [ f̃(S ∪X) ].\nNote that F(A) 6= F (A). In particular, as discussed above, we do not apply smoothing on the noisy version of F directly, but rather on the noisy version of the function F which is applied on A-i := A \\ {ai}, for all i ∈ [c]:\nF̃(S ∪A-i) := 1 n− c− |S| ∑\nj /∈S∪A\nf̃(S ∪A-i ∪ {aj})\nNotice that the smoothing arguments then apply to F since:\nF̃ (S ∪A) = 1 c c∑ i=1 F̃(S ∪A-i)\nIn our case, for every A-i, its smoothing neighborhood is:\nH(A-i) = {A-i ∪ {aj} : j /∈ S ∪A}\nThroughout the rest of this section we will use t to denote the number of sets in a smoothing neighborhood ofH(A-i). Note that for every i ∈ [c] the size of a smoothing neighborhood is:\nt = |H(A-i)| = |N ∪ (S \\A)| = n− c− |S| ∈ O(n).\nSmoothing in the sampled mean method. In order to apply Lemma A.4 in a meaningful way we need to bound the variation of the neighborhoods H(A?-i). To do so, we use the next claim which essentially bounds the variation of the smoothing neighborhoodsH(A?-i), of almost all A?-i.\nClaim C.2. Let A? ∈ argmaxB:|B|=c fS(B), c ≥ 4/ . Then:\n1\nc c∑ i=1 max { 0, 1− 2vS(H(A?-i)) · t−1/4 } FS(A ? -i) ≥ (1− ) fS(A?).\nProof. To bound the average variation of the sets {A?-i}ci=1 we argue that at most one set A?-i will be s.t. fS(A?-i) < fS(A ?)/2. To see this, assume for purpose of contradiction there are A?-i and A ? -j for which fS(A?-i) ≤ fS(A?-j) < fS(A?)/2, then since A? = A?-i ∪A?-j we get a contradiction:\nfS(A ?) = fS(A ? -i ∪A?−j) ≤ fS(A?-i) + fS(A?−j) < 2 ·\nfS(A ?)\n2 = fS(A\n?).\n61\nWe therefore have at least c−1 sets s.t. eachA?-i respects fS(A?-i) ≥ fS(A?)/2. Call these sets bounded. For any such bounded set A?-i, since A ? -i ⊂ A?ij for any j /∈ S ∪A?, monotonicity implies:\nmin A?ij∈H(A?-i)\nfS(A ? ij) ≥\nfS(A ?)\n2\nFor a given set A?-i note that for every j, every set Aij ∈ H(A?i ) respects fS(A?ij) ≤ fS(A?) due to the maximality of A?. Thus for any bounded set A?-i:\nvS(H(A?-i)) = maxA?ij∈H(A?i ) fS(A\n? ij)\nminA?ij∈H(A?i ) fS(A ? ij) ≤ fS(A\n?)\nfS(A?)/2 = 2\nLet l be the index of the set A?-i with the lowest value fS(A ? -i). Our discussion above implies that this is the only set whose variation may not be bounded from above by 2. Assume n sufficiently large s.t. t ≥ 212/ 4. We therefore get:\n1\nc c∑ i=1 ( max{0, 1− 2vS(H(A?-i))t− 1 4 } ) FS(A ? -i) ≥ 1 c ∑ i 6=l ( max{0, 1− 2vS(H(A?-i))t− 1 4 } ) FS(A ? -i)\n(16)\n≥ 1 c ∑ i 6=l ( 1− 4t− 1 4 ) FS(A ? -i) (17)\n≥ 1 c ∑ i 6=l ( 1− 4t− 1 4 ) fS(A ? -i) (18)\n≥ ( 1− 4t− 1 4 ) 1 c ( c∑ i=1 fS(A ? -i)− fS(A?−l) ) (19)\n≥ ( 1− 4t− 1 4 ) 1 c ( (c− 1)fS(A?)− fS(A?−l) ) (20)\n≥ ( 1− 4t− 1 4 ) 1 c ((c− 1)fS(A?)− fS(A?)) (21)\n≥ ( 1− 4t− 1 4 )(c− 2 c ) fS(A ?) (22)\n≥ ( c− 2 c − 4t− 1 4 ) fS(A ?) (23)\n≥ (1− ) fS(A?) (24)\nThe inequality (17) is justified by the bound we established on bounded sets; (18) is due to monotonicity of fS , since FS(A?-i) is an average of the marginal contribution over all possible A ? ij , which is a superset of A?-i; (20) is due to an argument in the proof of Lemma 3.1; (21) is due to the optimality of A?; (24) is due to the assumption on the parameters in the statement of the claim.\nProof of Lemma 3.2. Let A? = arg maxA:|A|=c fS(A) and let B : |B| = c be such that FS(B) < (1− )FS(A?). We will apply the smoothing arguments and show that with high probability\nF̃ (S ∪A?) > F̃ (S ∪B).\n62\nBy taking a union bound over all possible O(nc) sets B we will then conclude that the set whose smooth noisy contribution is largest must have smooth contribution at least factor of (1− ) from that of A?, with high probability.\nWe will denote 1 = and 2 = /4. Notice that the conditions of Claim C.2 are met with 2 and that the iteration is 2-significant, which from submodularity implies fS(A?) ≥ 2 · f(S)/k.\nFor a set B-i ⊂ B, using Lemma A.5, for t = n− c− |S|, when ω denotes the highest realized value of a noise multiplier, we know that for λ ∈ [0, 1) with probability 1− exp ( −Ω(λ2t1/4/ω) ) :\nF̃ (S ∪B) = 1 c ∑ i F̃(S ∪B-i)\n< 1\nc ∑ i (1 + λ)µ · ( f(S) + FS(B-i) + 3t −1/4 max Bij∈{H(B-i)} fS(Bij) )\n≤ (1 + λ)µ · ( f(S) + 3t−1/4 max\nBij∈{∪i∈[c]H(B-i)} fS(Bij) +\n1\nc c∑ i=1 FS(B-i)\n)\n≤ (1 + λ)µ · ( f(S) + 3t−1/4fS(A ?) + 1\nc c∑ i=1 FS(B-i) ) ≤ (1 + λ)µ · ( f(S) + 3t−1/4fS(A ?) + F (S ∪B) )\n≤ (1 + λ)µ · ( f(S) + 3t−1/4fS(A ?) + (1− 1)F (S ∪A?) )\n≤ (1 + λ)µ · ( f(S) + 3t−1/4fS(A ?) + (1− 1)fS(A?) )\n= (1 + λ)µ · ( f(S) + fS(A ?) ( 3t−1/4 + (1− 1) ))\nWe now need to argue that F̃ (S ∪ A?) is sufficiently large to beat F̃ (S ∪ B). Assuming n is sufficiently large s.t. t ≥ 220/ 4, from lemmas A.4 and C.2 we know that for λ ∈ [0, 1) w.p. 1− e−Ω(λ2t1/4/ω):\nF̃ (S ∪A?) = 1 c c∑ i=1 F̃(S ∪A?)\n> (1− λ)µ · ( f(S) + 1\nc c∑ i=1 ( 1− 2v(H(A?i )) · t−1/4 ) · FS(A?) ) > (1− λ)µ · (f(S) + (1− 2)fS(A?))\n63\nWe therefore get that:\nF̃ (S ∪A?)− F̃ (S ∪B) ≥ µ ( (1− λ) · (f(S) + (1− 2)fS(A?))− (1 + λ) · ( f(S) + fS(A ?) ( 3t−1/4 + (1− 1) )))\n≥ µ ( (1− λ)(1− 2)fS(A?)− 2λf(S)− (1 + λ) ( 3t−1/4 + (1− 1) ) fS(A ?) )\n≥ µ ( (1− λ)(1− 2)fS(A?)− 2λk\n2 fS(A\n?)− (1 + λ) ( 3t−1/4 + (1− 1) ) fS(A ?) ) ≥ µ · fS(A?) ( (1− λ)(1− 2)− 2λk\n2 − (1 + λ)\n( 3t−1/4 + (1− 1) )) ≥ µ · fS(A?) ( (1− λ)(1− 2)− 2λk\n2 − (1 + λ) ( 4 + (1− 1)) ) ≥ µ · fS(A?) ( 1− λ− 2 − 2λk\n2 − 2 − λ 2 − 1− λ+ 1 ) > µ · fS(A?) ( 1 − 3 2 − λ ( 2k\n2\n))\nFor any λ ≤ 2/2k the difference above is strictly positive. Conditioning on ω being bounded from above by t1/5 which happens with probability 1− e−Ω(t1/5/ log t), since k ∈ O(log log n) we that the result holds with probability at least 1− e−Ω(t1/10).\nApproximation Guarantee in Expectation\nLemma (3.3). Let δ > 0 and assume k > 16/δ2, c = 16/δ. Suppose that in every δ/4-significant iteration of SM-GREEDY when S are the elements selected in previous iterations, A ∈ argmaxB:|B|=c F̃ (S ∪ B), the bundle added Â respects fS(Â) ≥ (1− δ)FS(A). Let S̄ be the solution after bk/cc iterations. Then, w.p. ≥ 1− 1/n2:\nf(S̄) = (1− 1/e− 5δ)OPT.\nProof. We will analyze the solution only on iterations that are δ/4 relevant since this is when we can apply the smoothing arguments. Since k > 16/δ2 and since each iteration is δ/4-significant, by Lemma 3.2 we know that in each iteration A ∈ argmaxB:|B|=c F̃ (S ∪B) respects with overwhelming probability:\nFS(A) ≥ (1− δ) max B:|B|=c FS(B)\nWe will condition on the success of this event in every one of the bk/cc iterations. By a union bound the result will hold w.p. at least 1− 1/n2. We assume that n is sufficiently large s.t. t ≥ 220/δ4.\nTo account for the fact that we are only analyzing δ/4-significant iterations, we can compare against (1 − δ/4) of the optimal value: let k̂ be the last δ/4-significant iteration and Ô ⊆ O be the subset of size k̂ of the optimal solution whose value is largest. By submodularity:\nf(Ô) ≥ (1− δ/4)OPT (25)\n64\nSecond, we argue that optimizing over sets of size c rather than singletons is inconsequential when k > c/ . To be convinced, notice that when the algorithm selects c elements in every iteration the total number of elements selected will be k′ > k − c. Let O′ ∈ arg maxT :|T |≤k′ f(T ). As in previous arguments, from submodularity we have that: (1− c/k)f(Ô) ≤ f(O′). Since k > c/ we have that:\nf(O′) > (1− δ)f(Ô) > (1− 2δ)OPT (26)\nWe will henceforth analyze the algorithm against O′. In a similar manner to the analysis of the greedy algorithm which selects singletons at every stage i ∈ [k], we can analyze the greedy algorithm which selects sets of size c at every stage i ∈ [k′/c]. To ease notation assume bk′/cc = k′/c.\nFor a given stage of the algorithm, assume the set S has been previously selected and that a set Â is being added into the solution. Let B? = arg maxB⊆O′:|B|=c fS(B) and A? = arg maxB:|B|=c fS(B).\nfS(Â) ≥ (1− δ) max B:|B|=c FS(B) assumption in the statement\n> (1− 2δ)FS(A?) Lemma 3.2 applied with = δ > (1− 3δ)fS(A?) Lemma 3.1 and c ≥ 1/δ > (1− 3δ)fS(B?) maximality of A? > (1− 3δ) c k′ · fS(O′) subadditivity.\n= (1− 3δ) c k′ · ( f(O′ ∪ S)− f(S) ) ≥ (1− 3δ) c\nk′ · ( f(O′)− f(S) ) A standard inductive argument stating that at every iteration i ∈ bk/cc we have that the value of the current solution is at least ( 1− (1− 1/bk/cc)i ) OPT implies that f(S̄) ≥ (1− 1/e− 3δ) f(O′). Since we lose 2δ from (26) this concludes our proof.\nFrom Expectation to High Probability\nDefinition C.3. For a given set S, let A? ∈ argmaxB:|B|=c fS(B), A ∈ argmaxB:|B|=c F̃ (S ∪ B), and A = {Aij}i∈A,j /∈A. For a fixed > 0:\n• Aij ∈ A is -good if fS(Aij) ≥ (1− 2 )fS(A?); let good(A) denote all -good Aij ∈ A;\n• Aij ∈ A is -bad if fS(Aij) ≤ (1− 3 )fS(A?); let bad(A) denote all -bad Aij ∈ A.\nClaim C.4. For a set S ⊆ N let A ∈ argmaxB:|B|=c F̃ (S ∪B) and assume the iteration is /8-significant and that c ≥ /2. Then with probability at least 1− 1/n10:\n• |good(A) | ≥ c(n−c−|S|)2 ;\n• |bad(A) | ≤ c(n−c−|S|)2 .\n65\nProof. Since the sets Aij are distinct both good(A) and bad(A) contain no repetitions and we can argue about their size. To lower bound the size of good(A), let A? ∈ argmaxA:|A|=c fS(A). When the iteration is /8-significant, from Lemma 3.2 we know that with exponentially high probability:\nFS(A) ≥ (1− /2)FS(A?)\nWhen c ≥ 2/ , from Lemma, we know that:\nFS(A ?) ≥ (1− /2)fS(A?)\nDenoting m = c(n− c− |S|), we get with exponentially high probability:\nFS(A) = 1\nm m∑ j=1 c∑ i=1 fS(Aij) ≥ (1− )fS(A?) (27)\nIn addition, due to the maximality of A? we have that fS(Aij) ≤ fS(A?) for every i, j. Therefore:\nm∑ j=1 c∑ i=1 fS(Aij) ≤ |good(A) | · fS(A?) + (m− |good(A) |) · (1− 2 )fS(A?) (28)\nPutting (27) and (28) together we get that for sufficiently large n, with probability at least 1−1/n10:\nm(1− )fS(A?) ≤ (|good(A) |+ (m− |good(A) |)(1− 2 )) fS(A?)\nRearranging and using m = c(n − c − |S|) we get that |good(A) | ≥ c(n − c − |S|)/2. Since there are a total of c(n− c− |S|) it follows that |bad(A) | ≤ c(n− c− |S|) as required.\nDefinition C.5. Let ρ(x) denote the probability density function of the noise distribution. For a set S : |S| ∈ O(log n), c > 0, γ > 0, we define θg and θb as:\n• ∫∞ θb ρ(x)dx = 2c(n−c−|S|) logn ;\n• ∫∞ θg ρ(x)dx = 2 lognc(n−c−|S|) .\nThe following claim immediately follows from the definition, yet it is still useful to specify explicitly. The claim considers c(n − c − |S|)/2 samples since this is an upper and lower bound on |good(A) | and |bad(A) |. Therefore the claim gives us the likelihood that the largest noise multiplier of bad(A) does not exceed θb and that at least one set from good(A) exceeds θg.\nClaim C.6. For a fixed set S and A ∈ argmaxB:|B|=c F̃ (S ∪B), let m = c(n− c− |S|) and consider m/2 independent samples from the noise distribution. Then:\n• Pr [ max{ξ1, . . . ξm/2} ≤ θb ] > ( 1− 2logn ) ;\n• Pr [ max{ξ1 . . . ξm/2} ≥ θg ] > 1− 2/n.\n66\nProof. For a single sample ξ from D, we have that:\nPr[ξ ≤ θb] = 1− 2\nm log n\nIf we take m/2 independent samples ξ1, . . . ξm/2, the probability they are all bounded by θb is:\nPr [ max{ξ1, . . . ξ|bad(A) |} ≤ θb ] ≥ (\n1− 2 m log n\n)m 2\n> ( 1− 2\nlog n ) In the case of θg, the probability that a single sample ξ taken from D is at most θg is equal to:\nPr [ξ ≤ θg] = 1− 2 log n\nm\nIf we take independent samples ξ1, . . . ξm/2, the probability they are all bounded by θg is:\nPr [ max{ξ1, . . . ξc(n−c−|S|)} ≤ θg ] = ( 1− 2 log n\nm\n)m 2\n< 2\n2logn =\n2\nn\nAnd accordingly the probability that at least one of these samples is greater than θg is:\nPr [ max{ξ1 . . . ξm/2} ≥ θg ] > 1− 2/n.\nShowing θg is arbitrarily close to θb. Lemma C.8 below relates θg and θb assuming that D has a generalized exponential tail. This lemma makes the result applicable for Exponential and Gaussian distributions, and it fully leverages the fact that k ∈ O(log log n). The lemma is quite technical, and we therefore first prove the much simpler case where the distribution is bounded.\nLemma C.7. Assume D has a generalized exponential tail and that D is bounded, then for all γ ∈ Ω(1/ log log n) we have that θg ≥ (1− γ) θb.\nProof. Let χ be an upper bound on D. If there is an atom at χ with some probability γ > 0, then we are done, as θg = θb = χ. Otherwise, since D has a generalized exponential tail we know that ρ(χ) = γ for some γ > 0, and that ρ is continuous at χ. But then there is some δ > 0 such that for any χ− δ ≤ x ≤ χ we have that ρ(x) ≥ γ/2. Choosing n to be large enough that (1− )γ > γ − δ, we have that\n∫ γ (1− )γ ρ(x) ≥ γ/2\nChoosing n large enough such that\n2 log n\nc(n− c− |S|) < γ/2\nGives that θg ≥ (1− )χ. As θb ≤ χ we are done.\n67\nLemma C.8. If D has a generalized exponential tail then (1− γ) θb ≤ θg, ∀ γ ∈ Ω(1/ log logn).\nProof. The proof follows three stages:\n1. We use properties of D to argue upper and lower bounds for ρ(x);\n2. We show an upper bound M on θb;\n3. We show that integrating a lower bound of ρ(X) from (1 − γ)M to∞, yields a probability mass at least lognγ c(n−c−|S|) . Now suppose for contradiction that θg < (1 − γ) θb, we would get that ∫∞ θg ρ(x) is strictly greater than lognγ c(n−c−|S|) , which contradicts the definition of θg.\nWe now elaborate each on stage. Recall that by definition of D for x ≥ x0, we have that ρ(x) = e−g(x), where g(x) = ∑ i aiαi and that we do not assume that all the αi’s are integers, but only that α0 ≥ α1 ≥ . . ., and that α0 ≥ 1. We do not assume anything on the other αi values.\nFor the first stage we will show that for every g(x), there exists n0 such that for any n > n0 and x ≥ (\nlogn 2a0\n)1/α0 we have that for β = γ /100 < 1/100:\n(1 + β)a0x α0−1e−(1+β)a0x α0 ≤ ρ(x) ≤ (1− β)a0xα0−1e−(1−β)a0x α0\nWe explain both directions of the inequality. To see a0xα0−1(1 + β)e−(1+β)a0x α0 ≤ ρ(x) we first show: e−(1+β/2)a0x α0 ≤ ρ(x)\nThis holds since for sufficiently large n, we have that:\nx ≥ (log n) 1/α0 2a0 ≥ ( 2 ∑ i=1 |ai| βa0 )α0−α1 So the term β2x α0 dominates the rest of the terms. We now show that:\ne−(1+β/2)a0x α0 ≥ a0xα0−1(1 + β)e−(1+β)a0x α0\nThis is equivalent to: eβa0/2x α0 ≥ a0xα0−1(1 + β)\nWhich hold for x = log log3 n and large enough n.\nThe other side of the inequality is proved in a similar way. We want to show that:\nρ(x) ≤ (1− β)a0xα0−1e−(1−β)a0x α0\nClearly for x > log log3 n we have that (1− β)a0xα0−1 > 1. Hence we just need to show that:\nρ(x) ≤ e−(1−β)a0xα0\nBut this holds for sufficiently large n s.t.:\nx ≥ (log n) 1/α0 2a0 ≥ (∑ i=1 |ai| βa0 )α0−α1 68\nWe now proceed to the second stage, and compute an upper bound on θb. Note that if∫ ∞ θb ρ(x) = ∫ ∞ M g(x)\nand for every x ≥ M we have ρ(x) ≤ g(x) then it must be that M ≥ θb. Applying this to our setting, we bound ρ(x) ≤ (1− β)a0xα0−1e−(1−β)a0x α0 to get:\n1\nc(n− c− |S|) log n = ∫ ∞ M (1− β)a0xα0−1e−(1−β)a0x α0\n= −e−(1−β)a0xα0 |∞M = e−(1−β)a0M α0\nTaking the logarithm of both sides, we get:\n−(1− β)a0Mα0 = log 1\nc(n− c− |S|) log n = − log(c(n− c− |S|) log n)\nMultiplying by −1, dividing by (1− β)a0 and taking the 1/α0 root we get:\nM =\n( log(c(n− c− |S|) log n)\n(1− β)a0 )α0 Note that (1− γ)M > ( logn 2a0 )1/α0 and hence our bounds on ρ(x) hold for this regime.\nWe move to the third stage, and bound ∫∞ (1−γ)M ρ(x) from below. If we show that: ∫∞ (1−γ)M ρ(x) is greater than lognγ c(n−c−|S|) , this implies that θg ≥ (1 − γ)M , as θg is defined as the value such that when we integrate ρ(x) from θg to∞we get exactly lognγ c(n−c−|S|) . We show:∫ ∞\n(1−γ)M ρ(x) ≥ (1 + β)a0α0xα0−1e−(1+β)a0x α0\n= −e−(1+β)a0xα0 |∞(1−γ)M = e−(1+β)a0((1−γ)M) α0\n= e−(1+β)a0M α0 (1−γ)α0\n≥ e−(1+β)a0Mα0 (1−γ)\nHowever a0Mα0 = ( log(c(n−c−|S|) logn) (1−β) ) . Since β < 0.1 we have that 1+β1−β < 1 + 3β. Substituting both expressions we get:\ne−(1+β)a0M α0 (1−γ) ≥ e−(1+3β)(1−γ) log(c(n−c−|S|) logn)\n=\n( 1\nc(n− c− |S|) log n )(1−γ)(1+3β) ≥ ( 1\nc(n− c− |S|) log n\n)(1−γ /2)\n69\nWhere we used that β = γ /100 and hence (1 − γ)(1 + 3β) < 1 − γ /2. We now need to compare this to √ logn\nγ c(n−c−|S|) . To do this, note that:( 1\nc(n− c− |S|) log n )(1−γ /2) ≥ 1 c(n− c− |S|)1−γ /2 log n\n≥ 2 √ logn\nc(n− c− |S|) log n\n≥ log n γ c(n− c− |S|)\nWhere n is large enough that γ2 log(n − c − |S|) > √\nlog n. This completes the proof, since θg ≥ (1− γ)M ≥ (1− γ) θb as required.\nLemma (3.4). For any > 0, suppose we run SM-GREEDY where in each iteration we add a bundle of elements of size c = 16/ . For any /8-significant iteration where the set previously selected is S : |S| ∈ O(log log n), let A ∈ argmax F̃ (S ∪A) and Â = argmax(i,j)∈A×N\\S∪A f̃(S ∪Aij). Then, with probability at least 1− 3/ log n we have that:\nfS(Â) ≥ (1− 3 )FS(A).\nProof. We will use the above claims to argue that with probability at least 1 − 4/ log n the noisy mean value of any set in bad(A) is smaller than the largest noisy mean value of a set in good(A). Since a bad set is defined as a set B for which fS(B) ≤ (1 − 3 )fS(A?) this implies that the set returned by the algorithm has value at least (1 − 3 )fS(A?). Since for any set A : |A| = c we have that fS(A?) is an upper bound on FS(A) will complete the proof.\nWe will condition on the event that |good(A) | ≥ c(n− c− |S|)/2 which happens with probability at least 1 − 1/n10 from Claim C.4. Under this assumption, from Claim C.6 we know that with probability at least 1−2/n at least one of the noise multipliers of sets in good(A) has value at least θg, and from Lemma C.8 we know that θg ≥ (1− γ) θb for any γ ∈ Θ(1/ log logn). Thus:\nmax Aij∈good(A) f̃(S ∪Aij) = max Aij∈good(A) ξAij × [ f(S) + fS(Aij) ]\n≥ θg × [ f(S) + (1− 2 )fS(A?) ] ≥ (1− γ) θb × [ f(S) + (1− 2 )fS(A?) ]\nLet B ∈ argmaxC∈bad(A) f̃(S ∪C). From Claim C.6 we know that w.p. at least 1− 2/ log n all noise multipliers of sets in bad(A) are at most θb. Thus:\nf̃(S ∪B) = max Aij∈bad(A) f̃(S ∪Aij) = max Aij∈bad(A) ξAijf(S ∪Aij) ≤ θb ·[f(S) + (1− 3 )fS(A?)]\nLet d be some constant such that |S| ≤ d log log n. Note that the iteration is -significant, and therefore due to the maximality of A? and since f(S) ≤ OPT and the optimal solution has at most d · log logn elements we have that:\nfS(A ?) ≥\nd log logn f(S).\n70\nSince Lemma C.8 applies to any γ ∈ Θ(1/ log logn), we know that for any constant d there is a large enough value of n such that γ < 2/3d log log n. Putting it all together and conditioning on all events we have with probability at least 1− 3/ log n:\nf̃(S ∪ Â)− f̃(S ∪B) ≥ ( (1− γ) θb ·[f(S) + (1− 2 )fS(A?)] ) − ( θb ·[f(S) + (1− 3 )fS(A?)] ) ≥ θb ( fS(A ?) − γ × [ (1− 2 )fS(A?) + f(S) ] )\n≥ θb ( fS(A ?) − γ × [ (1− 2 )fS(A?) + d log logn fS(A ?) ] )\n= θb fS(A ?) ( − γ × [ (1− 2 ) + d log logn ] ) > θb fS(A ?) ( − 2\n3d log log n ×\n[ (1− 2 ) + d log log n ] ) > θb fS(A ?) (\n− 2 3 ) > 0\nSince the difference is strictly positive this implies that with probability at least 1 − 3/ log n a bad set will not be selected by the algorithm which concludes our proof.\nApproximation Guarantee of SM-Greedy\nTheorem C.9. For any monotone submodular function f : 2N → R and > 0, when k ∈ Ω(1/ ) ∩O(log log n), there is a (1 − 1/e − ) approximation for maxS:|S|≤k f(S), with probability 1− 4/ log n given access to a noisy oracle whose distribution has a generalized exponential tail.\nProof. First, for the case in which k ∈ Ω(1/ 2), we can apply SM-GREEDY as described in the main body of the paper. Let δ = /5 and set c = 16/δ. At any given δ/8-significant iteration of SM-GREEDY from Lemma 3.4 we know that with probability at least 1 − 3/ log n we have that f(Â) ≥ (1−δ)FS(A), whereA ∈ argmaxB:|B|=c F̃ (B). We can then apply Lemma 3.3 which implies that with probability at least 1− 4logn we have a 1− 1/e− 5δ = (1− 1/e− ) approximation.\nIn the case k ∈ Ω(1/ ) ∩ O(1/ 2) note that taking bundles of size c ∈ O(1/ ) in each iteration may result in a 1/2 approximation. In this case, we therefore enumerate over all possible sets of size c = k and output Â = argmax f̃(Aij) whereA = argmaxB:|B|=k F̃ (B). By Lemma 3.4 we know that w.p. 1− 3 log n:\nf(Â) ≥ (1− 48/c)F (A) = (1− 48/k)F (A) ≥ (1− /2)F (A) (29)\nBy the smoothing lemma (Lemma 3.2) we know that for any fixed and sufficiently large n with overwhelming probability F (A) ≥ (1 − /2)F (A?) for A? ∈ argmaxB:|B|=k f(B). By the sampled mean method (Lemma 3.1) we know that F (A?) ≥ (1− 1/k)f(A?), thus:\nF (A) ≥ (1− 1/k − /2)f(A?) (30)\nPutting (29) and (30) together and taking a union bound we get our result.\n71"
    }, {
      "heading" : "D Optimization for Very Small k",
      "text" : "Smoothing Guarantees\nLemma (4.1). Let A ∈ argmaxB:|B|=k F̃ (B). Then, for any fixed > 0 w.p. 1− e−Ω( 2(n−k)):\nF (A) ≥ (1− ) max B:|B|=k F (B)\nProof. The proof follows the same reasoning as those from previous sections. Let A? = argmaxB:|B|=k F (B). We will show that w.h.p. no set B for which F (B) < (1 − )F (A?) beats A. The size of the smoothing set is t = n− k, and ω is an upper bound on the noise multiplier.\nNote that the optimality ofA? and submodularity imply that f(A?∪x) ≤ 2f(A?), for all x ∈ N \\A?. Hence from monotonicity the variation is bounded by 2:\nv(A?) = maxx∈N\\A f(A ? ∪ x) minx∈N\\A f(A? ∪ x) ≤ 2f(A ?) f(A?) = 2\nWe can therefore apply Lemma A.5 and get that with probability at least 1− eΩ(λ2t1/4/ω):\nF̃ (A?) ≥ (1− λ)µ ( 1− 4t−1/4F (A?) )\nTo upper bound F̃ (B) for a set B s.t. F (B) < (1− )F (A?), note that the value of largest set in the smoothing neighborhood is maxx∈N\\B f(B ∪ x) ≤ 2f(A?). Hence, from Lemma A.4 we get that with probability at least 1− eΩ(λ2t1/4/ω):\nF (B) ≤ (1 + λ)µ ( F (B) + 6t−1/4F (A?) ) Therefore when n is sufficiently large s.t. t−1/4 ≤ /100 and λ < 1 we get that:\nF (A?)− F (B) ≥ (1− λ)µ(1− 4t−1/4)F (A?)− (1 + λ)µ ( F (B) + 6t−1/4F (A?) ) ≥ µ ( (1− λ)(1− 4\n100 )F (A?)− (1 + λ)(1− )F (A?)− (1 + λ) 6 100 F (A?) ) ≥ µ ( (1− λ)(1− 4\n100 )F (A?)− (1 + λ)(1− )F (A?)− (1 + λ) 6 100 F (A?) ) > µ · F (A?) ( − 2λ− /5)\nUsing λ < /10 the above inequality is strictly positive. Conditioning on the event of ω being sufficiently small completes the proof."
    }, {
      "heading" : "An Approximation Algorithm for Very Small k",
      "text" : "Approximation guarantee in expectation. We first present the algorithm whose approximation guarantee is arbitrarily close to k/(k + 1), in expectation.\n72\nAlgorithm 5 EXP-SMALL-GREEDY Input: budget k\n1: A← arg maxB :|B|=k F̃ (B) 2: x← select random element from N \\A 3: Â← random set of size k from A ∪ x 4: return Â\nTheorem D.1. For any submodular function f : 2N → R, the algorithm EXP-SMALL-GREEDY obtains returns a (k/(k + 1)− ) approximation for maxS:|S|≤k f(S), in expectation, for any fixed > 0.\nProof. From Lemma 3.1 we know that f(Â) ≥ (k/(k + 1))F (A). Let A? = argmaxB:|B|=k f(B). From monotonicity we know that f(A?) ≤ F (A?). Applying Lemma 4.1 we get that for the set F (A) ≥ (1− )F (A?). Hence:\nf(Â) ≥ ( k\nk + 1\n) F (A) ≥ (1− ) ( k\nk + 1\n) F (A?) ≥ (1− ) ( k\nk + 1\n) f(A?) > (( k\nk + 1\n) − ) OPT.\nHigh probability. To obtain a result w.h.p. we modify the algorithm above. The algorithm enumerates all possible subsets of size k − 1, and then select the set A ∈ argmaxB:|B|=k−1 F̃ (B). The algorithm then selects Â ∈ argmaxX∈H(A) f̃(X). A formal description is added below.\nAlgorithm 6 WHP-SMALL-GREEDY Input: budget k\n1: A← arg maxB :|B|=k−1 F̃ (B) 2: Â← argmaxx∈N\\A f̃(A ∪ x) 3: return Â\nThe analysis of the algorithm is similar to the high probability proof from Section 3.\nTheorem (4.2). For any submodular function f : 2N → R and any fixed > 0 and constant k, there is a (1− 1/k − )-approximation algorithm for maxS:|S|≤k f(S) which only uses a generalized exponential tail noisy oracle, and succeeds with probability at least 1− 6/ log n.\nProof. Let A ∈ argmaxB:|B|=k−1 F̃ (B), and let A? ∈ argmaxB:|B|=k−1 f(B). Since A? is the optimal solution over k−1 elements, from submodularity we know that f(A?) ≥ (1−1/k)OPT. What now remains to show is that Â ∈ argmaxx∈N\\A f̃(A ∪ x) is a (1 − ) approximation to F (A). To do so recall the definitions of good and bad sets from the previous section. Let δ = /3. Suppose that a set X is in δ-good(A) if f(X) ≥ (1− 2δ)f(A?) and in δ-bad(A) if f(X) ≤ (1− 3δ)f(A?). We will show that the set selected has value at least as high as that of a bad set, i.e. (1 − 3δ)f(A?) which will complete the proof.\nWe first show that with probability at least 1 − 6/ log n the noise multiplier of some good set is at least θg and of a bad set is at most θb. To do so we will first argue about the size of δ-good(A)\n73\nand δ-bad(A). From Lemma 4.1 and the maximality of A we know that with exponentially high probability F (A) ≥ (1− δ)F (A?). Therefore for m = n− k:\nF (A) = 1\nm ∑ x/∈A f(A ∪ x) ≥ (1− δ) 1 m ∑ x/∈A? f(A? ∪ x) ≥ (1− δ)f(A?)\nDue to the maximality of A? and submodularity we know that f(A ∪ x) ≤ 2f(A?) for all x /∈ A:∑ x/∈A f(A ∪ x) ≤ |δ-good(A)|2f(A?) + (m− |δ-good(A)|)(1− 2δ)f(A?)\nPutting the these bounds on F (A) together and rearranging we get that:\n|δ-good(A)| ≥ δ ·m 1 + 2 ≥ δm 3\nTherefore, for sufficiently large n the likelihood of at least one set achieving value at least θg is:\nPr[max{ξ1, . . . , ξδ·m/3} ≥ θg] ≥ 1− (\n1− 2 log n m\n) δm 3\n≥ 1− 2 nδ/3 ≥ 1− 1 log n\nTo bound δ-bad(A) we will simply note that it is trivial that δ-bad(A) < m. Thus, the likelihood that all noise multipliers of bad sets are bounded from above by θb is:\nPr [max{ξ1, . . . ξm} ≤ θb] ≥ (\n1− 2 m log n\n)m > ( 1− 4\nlog n ) Thus, by a union bound and conditioning on the event in Lemma 4.1 we get that θb is an upper bound on the value of the noise multiplier of bad sets and θg is with lower bound on the value of the noise multiplier of a good stem all with probability at least 1 − 6/ log n. From Lemma C.8 we know that for any γ ∈ Θ(1/ log log n) we have that θg ≥ (1− γ) θb. Thus:\nmax X∈δ-good(A) f̃(X) = max X∈δ-good(A)\nξXf(X) ≥ θg ·(1− 2δ)f(A?) ≥ (1− γ)Mb · (1− 2δ)f(A?)\nLetB ∈ argmaxC∈δ-bad f̃(S∪C). From Claim C.6 we know that with probability at least 1−2/ log n all noise multipliers of sets in bad(A) are at most θb. Thus:\nf̃(S ∪B) = max X∈δ-bad f̃(X) = max X∈bad(A) ξXf(X) ≤Mb · (1− 3δ)f(X)\nPutting it all together we have with probability at least 1− 6/ log n:\nf̃(Â)− f̃(B) ≥Mbf(A?) · ((1− γ)(1− 2δ)− (1− 3δ)) > θb f(A?) (δ − γ)\nSince Lemma C.8 applies to any γ ∈ Θ(1/ log log n), and δ is fixed it applies to γ < δ and the difference is positive. Since δ = /6 this completes our proof.\n74\nInformation Theoretic Lower Bounds for Constant k\nSurprisingly, even for k = 1 no algorithm can obtain an approximation better than 1/2, which proves a separation between large and small k.5 The following is a tight bound for k = 1.\nClaim D.2. There exists a submodular function and noise distribution for which w.h.p. no randomized algorithm with a noisy oracle can obtain an approximation better than 1/2 +O(1/ √ n) for maxa∈N f(a).\nProof. We will construct two functions that are identical except that one function attributes a value of 2 for a special element x? and 1 for all other elements, whereas the other is assigns a value of 1 for each element. In addition, these functions will be bounded from above by 2 so that the only queries that gives any information are those of singletons. More formally, consider the functions f1(S) = min{|S|, 2} and f2(S) = min{g(S), 2}where g : 2N → R is defined for some x? ∈ N as:\ng(S) =\n{ 2, if S = x?\n|S|, otherwise\nThe noise distribution will return 2 with probability 1/ √ n and 1 otherwise.\nWe claim that no algorithm can distinguish between the two functions with success probability greater than 1/2 + O(1/ √ n). For all sets with two or more elements, both functions return 2, and so no information is gained when querying such sets. Hence, the only information the algorithm has to work with is the number of 1, 2, and 4 values observed on singletons. If it sees the value 4 on such a set, it concludes that the underlying function is f2. This happens with probability 1/ √ n.\nConditioned on the event that the value 4 is not realized, the only input that the algorithm has is the number of 1s and 2s it sees. The optimal policy is to choose a threshold, such if a number of 2s observed is or above this threshold, the algorithm returns f2 and otherwise it reruns f1. In this case, the optimal threshold is √ n+ 1. The probability that f2 has at most √ n twos is 1/2− 1/ √ n, and so is the probability that f1 has at least √ n+ 1 twos, and hence the advantage over a random guess is O(1/ √ n) again. An algorithm which approximates the maximal set on f2 with ratio better than 1/2 +ω(1/ √ n) can be used to distinguish the two functions with advantage ω(1/ √ n). Having ruled this out, the best approximation one can get is 1/2 +O(1/ √ n) as required.\nWe generalize the construction to general k. The lower for general k behaves like 2k/(2k − 1), where our upper bound is (k − 1)/k.\nClaim D.3. There exists a submodular function and noise distribution for which w.h.p. no randomized algorithm with a noisy oracle can obtain an approximation better than (2k − 1)/2k + O(1/ √ n) for the optimal set of size k.\n5We note that if the algorithm is not allowed to query the oracle on sets of size greater than k, Claim D.2 can be extended to show aO(n) inapproximability, so choosing a random element is almost the best possible course of action.\n75\nProof. Consider the function:\nf1(S) =  2|S|, if |S| < k 2k − 1, if |S| = k 2k, if |S| > k\nand the function f2, which is dependent on the identity of some random set of size k, denoted S? :\nf2(S;S ?) =  2|S|, if |S| < k 2k − 1, if |S| = k, S 6= S? 2k, if S = S?\n2k, if |S| > k\nNote that both functions are submodular.\nThe noise distribution will return 2k/(2k − 1) with probability n−1/2 and 1 otherwise. Again we claim that no algorithm can distinguish between the functions with probability greater than 1/2. Indeed, since f1, f2 are identical on sets of size different than k, and their value only depends on the set size, querying these sets doesn’t help the algorithm (the oracle calls on these sets can be simulated). As for sets of size k, the algorithm will see a mix of 2k−1, 2k, and at most one value of 4k2/(k−1). If the algorithm sees the value 4k2/(k−1) then it was given access to f2. However, the algorithm will see this value only with probability 1/ √ n. Conditioning on not seeing this value, the best policy the algorithm can adopt is to guess f2 if the number of 2k values is at least 1 + (nk)√ n\n, and guess f1 otherwise. The probability of success with this test is 1/2 + O(1/ √ n) (regardless of whether the underlying function is f1 or f − 2). Any algorithm which would approximate the best set of size k to an expected ratio better than (2k − 1)/2k + ω(1/ √ n) could be used to distinguish between the function with an advantage greater than 1/ √ n, and this puts a bound of (2k − 1)/2k +O(1/ √ n) on the expected approximation ratio.\n76"
    }, {
      "heading" : "E Noise Distributions",
      "text" : "As discussed in the Introduction, our goal was to allow noise distribution in the model to potentially be Gaussian, Exponential, uniform and generally bounded. It was important for us that algorithm to be oblivious to the specific noise distribution, and rely on its properties only in the analysis. For achieve this we introduced the class of generalized exponential tail distributions. We recall the definition from the Introduction.\nDefinition. A noise distribution D has a generalized exponential tail if there exists some x0 such that for x > x0 the probability density function ρ(x) = e−g(x), where g(x) = ∑ i aix\nαi . We do not assume that all the αi’s are integers, but only that α0 ≥ α1 ≥ . . ., and that α0 ≥ 1. If D has bounded support we only require that either it has an atom at its supremum, or that ρ is continuous and non zero at the supremum.\nNote that the definition includes Gaussian and Exponential distributions. For i > 0 it is possible that αi < 1 which implies that a generalized exponential tail also includes cases where the probability density function denoted ρ respects ρ(x) = ρ(x0)e−g\n′(x−x0) (we can simply add ρ(x0) to g using αi = 0 for some i, and move from g′(x− x0) to an equivalent g(x) via a coordinate change).\nThe most important property of the noise distribution is that all of its moments are constant, independent of n. In fact,D describes how the noise affects a single evaluation, and does not depend on the number of elements. This means (for example) that if we could get h(n) independent samples from D, we would be arbitrarily close to the mean, as long as h(n) is monotone in n.\nImpossibility for distributions that depend on n. We note that if the adversary would have been allowed to choose the noise distribution as a function of n, then no approximation would be possible, even if the noise distribution had mean 1. For example, a noise distribution which returns 0 with probability 1 − 1/22n and 22n with probability 1/22n has an expected value of 1, is not always 0, but does not enable any approximation.\nImpossibility for two distributions. One can consider having multiple noise distributions which act on different sets. A noise distribution can be assigned to a set either in adversarial manner, or at random. If sets are assigned to noise distributions in an adversarial manner, it is possible to construct the bad example of the correlated case from Section 5 with just two noise distributions. If sets are assigned to a noise distribution in an i.i.d manner, this reduces to the i.i.d case when there is a single distribution.\nThe relation between n and the distribution As we have explained above, if the distribution depends on n, then approximation is not possible. In particular, this means that if the universe is too small, optimization is not possible. For example, suppose that D returns 0 with probability 1 − 2−100, and otherwise returns 2100. Then D is bounded away from zero, has expectancy 1, but approximation is not possible if n = 50. Hence we need to assume some minimal value n0 that depends on the distribution, and assert an approximation ratio of 1− 1/e− only for n > n0. We note that n0 is constant, and hence if n ≤ n0 we can run the “optimal” algorithm of evaluating the noisy oracle over all subsets of n, but the approximation ratio might still be arbitrarily bad.\n77\nWe note that the problem is not “just” an atom at zero. Suppose that f is additive, and bounded between 1 and 100. if D is uniform over the set 2100i for 1 ≤ i ≤ 2100 and n = 50 then approximation is not possible; if f̃(A) turns out to be larger than f̃(B) this says very little about f(A), f(B) - it’s more likely happen due to the noise.\n78"
    }, {
      "heading" : "F Additional Examples",
      "text" : "In this section we show some examples of how greedy and its variants fail under error and noise.\nGreedy fails with error. In the maximum-coverage problem we are given a family of sets that cover a universe of items, and the goal is to select a fixed number of sets whose union is maximal. This classic problem is an example of maximizing a monotone submodular function under a cardinality constraint. For a concrete example showing how greedy fails with error, consider the instance illustrated in Figure 4. In this instance there is one family of sets A depicted on the left where all sets cover the same two items, and another family of disjoint sets B that each cover a single unique item. Consider an oracle which evaluates sets as follows. For any combination of sets the oracle evaluates the cardinality of the union of the subsets exactly, except for a few special cases: For S = A ∪ b ∀A ⊆ A, b ∈ B the oracle returns f̃(S) = 2, and for S ⊆ A the oracle returns f̃(S) = 2 + δ for some arbitrarily small δ > 0. With access to this oracle, the greedy algorithm will only select sets in A which may be as bad as linear in the size of the input. In this example we tricked the greedy algorithm with a 1/3-erroneous oracle, but same consequences apply to an -erroneous oracle for any > 0 by planting (1− )/ items in A.\nGreedy fails with random noise. In practice, the greedy algorithm is often used although we know the data may be noisy. Hence, a different direction for research could be to analyze the effect of noise on the existing greedy algorithm. Unfortunately, it turns out that the greedy algorithm fails even on very simple examples.\nTheorem F.1. Given a noise distribution that is either uniformly distributed in [1− , 1 + ] for any > 0, a Gaussian, or an Exponential, the greedy algorithm cannot obtain a constant factor approximation ratio even in the case of maximizing additive functions under a cardinality constraint.\nProof sketch. Consider an additive function, which has two types of elements: k = √ n good elements, each worth n1/4, and n − k bad elements, each worth 1. Suppose that the noise is uniform in [1 − , 1 + ]. Then after taking k2/3 good elements greedy is much more likely to take bad elements, which leads to an approximation ratio of O(1/n1/6). Similar examples hold for Gaussian and Exponential noise.\nGreedy fails when taking maximal sampled mean bundle. In Section 3 we discuss a greedy algorithm which iteratively takes bundles of O(1/ ) elements that maximize F̃ (S ∪ B), where F̃ (S ∪A) = ∑ i∈A,j /∈S∪A f̃(S ∪Aij). To see this can be arbitrarily bad, even when F̃ ≈ F , consider an instance with n − 2 elements N ′ s.t. for any S ⊆ N ′ the function evaluates to f(S) = M for some arbitrarily large value M > 0, and an additional subset of elements A = {a1, a2} s.t. f(A) = f(a1) = f(a2) = , for some arbitrarily small > 0. Now assume that for any S ⊆ N ′ and i ∈ [2] we have f(S∪ai) = M+ . The sampled mean ofA is maximal, its value is arbitrarily small.\n79\n80"
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "We consider the problem of maximizing a monotone submodular function under noise.<lb>There has been a great deal of work on optimization of submodular functions under various<lb>constraints, resulting in algorithms that provide desirable approximation guarantees. In many<lb>applications, however, we do not have access to the submodular function we aim to optimize,<lb>but rather to some erroneous or noisy version of it. This raises the question of whether prov-<lb>able guarantees are obtainable in presence of error and noise. We provide initial answers, by<lb>focusing on the question of maximizing a monotone submodular function under a cardinality<lb>constraint when given access to a noisy oracle of the function. We show that:<lb>• For a cardinality constraint k ≥ 2, there is an approximation algorithm whose approxi-<lb>mation ratio is arbitrarily close to 1− 1/e;<lb>• For k = 1 there is an algorithm whose approximation ratio is arbitrarily close to 1/2. No<lb>randomized algorithm can obtain an approximation ratio better than 1/2 + o(1);<lb>• If the noise is adversarial, no non-trivial approximation guarantee can be obtained. ∗Supported by ISF 1241/12;<lb>†Supported by NSF grant CCF-1301976, CAREER CCF-1452961, Google Faculty Research Award, Facebook Faculty<lb>Award.<lb>ar<lb>X<lb>iv<lb>:1<lb>60<lb>1.<lb>03<lb>09<lb>5v<lb>3<lb>[<lb>cs<lb>.D<lb>S]<lb>4<lb>N<lb>ov<lb>2<lb>01<lb>6",
    "creator" : "LaTeX with hyperref package"
  }
}