{
  "name" : "1506.01071.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Aleksey Buzmakov", "Sergei O. Kuznetsov", "Amedeo Napoli" ],
    "emails" : [ "aleksey.buzmakov@inria.fr,", "skuznetsov@hse.ru,", "amedeo.napoli@loria.fr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n50 6.\n01 07\n1v 2"
    }, {
      "heading" : "1 Introduction",
      "text" : "Interestingness measures were proposed to overcome the problem of combinatorial explosion of the number of valid patterns that can be discovered in a dataset [18]. For example, pattern support, i.e., the number of objects covered by the pattern, is one of the most famous measures of pattern quality.\n∗The final publication is available at link.springer.com\nIn particular, support satisfies the property of anti-monotonicity (aka “a priori principle”), i.e., the larger the pattern is the smaller the support is [12, 1]. Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.\nSome of these measures (e.g., support, robustness for generators [17], or upper bound constraint of MCCS [16]) are “globally anti-monotonic”, i.e., for any two patterns X ⊑ Y we have M(X) ≥ M(Y ), where M is a measure and ⊑ denotes the (subsumption) order relation on patterns. When a measure is anti-monotonic, it is relatively easy to find patterns whose measure is higher than a certain threshold (e.g., patterns with a support higher than a threshold). In contrast some other measures are called “locally anti-monotonic”, i.e., for any pattern X there is an immediate subpattern Y ≺ X such that M(Y ) ≥ M(X). Then the right strategy should be selected for traversing the search space, e.g., a pattern Y should be extended only to patterns X such that M(Y ) ≥ M(X). For example, for “locally anti-monotonic” cosine interest [4], the extension of a pattern Y consists in adding only attributes with a smaller support than any attribute from Y . The most difficult case for selecting valid patterns occurs when a measure is not locally anti-monotonic. Then, valid patterns can be retained by postfiltering, i.e., finding a (large set of) patterns satisfying an antimonotone constraint and filtering them w.r.t. the chosen nonmonotonic measure (i.e., neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].\nMost of the measures are only applicable to one type of patterns, e.g., pattern leverage or cosine interest can be applied only to binary data since their definitions involve single attributes. “Pattern independent measures” usually relies on support of the pattern and/or on support of other patterns from the search space. In particular, support, stability [10], margin-closeness [13] and robustness [17] are pattern independent measures. In this paper we work with interval tuple data, where only pattern independent measures as well as specific measures for interval tuples can be applied. In addition, given a measure, it can be difficult to define a good threshold. Thus various approaches for finding top-K patterns were introduced [7, 21, 20], with the basic idea to automatically adjust the threshold for a measure M.\nIn this paper we introduce a new algorithm θ-Σοφια, i.e., Sofia, for “Searching for Optimal Formal Intents Algorithm” for a interestingness threshold θ, for extracting the best patterns of a kind, e.g., itemsets, interval tuples, strings, graph patterns, etc. θ-Σοφια algorithm is applicable to a class of measures called “projection-antimonotonic measures” or more precisely “measures antimonotonic w.r.t. a chain of projections”. This class includes globally antimonotonic measures such as support, locally anti-monotonic measures such as cosine interest and some of the nonmonotonic measures such as stability or robustness of closed patterns. The main novelty of this paper is θ-Σοφια, a new efficient algorithm for finding best patterns of different kinds w.r.t. projectionantimonotonic measures which constitutes a rather large class of measures.\nThe remaining of the paper is organized as follows. The formalization of the current approach is based on Formal Concept Analysis (FCA) [6] and pattern structures [5] which are introduced in Section 2. Then, θ-Σοφια algorithm is detailed in Section 3 first for an arbitrary measure and second for the ∆-measure. Experiments and a discussion are proposed in Section 4, before conclusion."
    }, {
      "heading" : "2 Data Model",
      "text" : ""
    }, {
      "heading" : "2.1 FCA and Pattern structures",
      "text" : "Formal Concept Analysis (FCA) is a formalism for knowledge discovery and data mining thanks to the design of concept lattices [6]. It is also convenient for describing models of itemset mining, and, since [14], lattices of closed itemsets (i.e., concept lattices) and closed descriptions are used for concise representation of association rules. For more complex data such as sequences and graphs one can use an extension of the basic model, called pattern structures [5]. With pattern structures it is possible to define closed descriptions and to give a concise representation of association rules for different descriptions with a natural order (such as subgraph isomorphism order) [11, 8].\nA pattern structure is a triple (G, (D,⊓), δ), where G is a set of objects, (D,⊓) is a complete meet-semilattice of descriptions and δ : G → D maps an object to a description.\nThe intersection ⊓ gives the similarity of two descriptions. Standard FCA can be presented in terms of a pattern structure. A formal context (G,M, I), where G is a set of objects, M is a set of attributes and I ⊆ G×M an incidence relation giving information about attributes related to objects, is represented as a pattern structure (G, (℘(M),∩), δ), where (℘(M),∩) is a semilattice of subsets of M with ∩ being the set-theoretical intersection. If x = {a, b, c} and y = {a, c, d}, then x ⊓ y = x ∩ y = {a, c}. The mapping δ : G→ ℘(M) is given by δ(g) = {m ∈ M | (g,m) ∈ I} and returns the description of a given object as a set of attributes.\nThe following mappings or diamond operators give a Galois connection between the powerset of objects and descriptions:\nA⋄ := l\ng∈A\nδ(g), for A ⊆ G\nd⋄ := {g ∈ G | d ⊑ δ(g)}, for d ∈ D\nGiven a subset of objects A, A⋄ returns the description which is common to all objects in A. Given a description d, d⋄ is the set of all objects whose description subsumes d. A partial order ⊑ (subsumption) on descriptions from D is defined w.r.t. the similarity operation ⊓: c ⊑ d ⇔ c ⊓ d = c, and c is subsumed by d.\nA pattern concept of a pattern structure (G, (D,⊓), δ) is a pair (A, d), where A ⊆ G, called pattern extent and d ∈ D, called pattern intent, such that A⋄ = d and d⋄ = A. A pattern extent is a closed set of objects, and a pattern intent is\na closed description, e.g., a closed itemset when descriptions are given as sets of items (attributes). As shown in [11], descriptions closed in terms of counting inference (which is a standard data mining approach), such as closed graphs [23], are elements of pattern intents.\nA pattern extent corresponds to the maximal set of objects A whose descriptions subsume the description d, where d is the maximal common description for objects in A. The set of all pattern concepts is partially ordered w.r.t. inclusion on extents, i.e., (A1, d1) ≤ (A2, d2) iff A1 ⊆ A2 (or, equivalently, d2 ⊑ d1), making a lattice, called pattern lattice."
    }, {
      "heading" : "2.2 Interval pattern structure",
      "text" : "A possible instantiation of pattern structures is interval pattern structures introduced to support efficient processing of numerical data without binarization [8]. Given k numerical or interval attributes whose values are of the form [a, b], where a, b ∈ R, the language of a pattern space is given by tuples of intervals of size k. For simplicity, we denote intervals of the form [a, a] by a.\nFigure 1a exemplifies an interval dataset. It contains 6 objects and 2 attributes. An interval as a value of an attribute corresponds to an uncertainty in the value of the attribute. For example, the value of m1 for g2 is known exactly, while the value of m2 is lying in [1, 2]. Given this intuition for intervals it is natural to define similarity of two intervals as their convex hull, since by adding new objects one increases the uncertainty. For example, for g1 the value of m1 is 0, while for g6 it is 1, thus given the set {g1, g6}, the uncertainty of m1 in this set is [0, 1], i.e., the similarity of g1 and g6 w.r.t. m1 is [0, 1]. More formally, given two intervals [a, b] and [c, d], the similarity of these two intervals is given by [a, b] ⊓ [c, d] = [min(a, c),max(b, d)]. Given a tuple of intervals, the similarity is computed component-wise. For example, g⋄1 ⊓ g ⋄ 6 = 〈[0, 1]; [0, 2]〉. Reciprocally, 〈[0, 1]; [0, 2]〉 = {g1, g2, · · · , g6}. The resulting concept lattice is shown in Figure 1b. Concept extents are shown by indices of objects, intents are given in angle brackets, the numbers on edges and on concepts are related to interestingness of concepts and will be described in the next subsection."
    }, {
      "heading" : "2.3 Stability index of a concept",
      "text" : "For real datasets, the number of patterns can be very large, even computing the number of closed patterns is a #P-complete problem [9]. Different measures were tested for selecting most interesting patterns, such as stability [10]. Stability measures the independence of a concept intent w.r.t. randomness in data.\nGiven a concept C, concept stability Stab(C) is the relative number of subsets of the concept extent (denoted by Ext(C)), whose descriptions, i.e., the result of (·)⋄ is equal to the concept intent (denoted by Int(C)).\nStab(C) := |{s ∈ ℘(Ext(C)) | s⋄ = Int(C)}|\n|℘(Ext(C))| (1)\nHere ℘(P ) is the powerset of P . The larger the stability, the more objects can be deleted from the context without affecting the intent of the concept, i.e., the intent of the most stable concepts is likely to be a characteristic pattern of a given phenomenon and not an artifact of a dataset.\nWe say that a concept is stable if its stability is higher than a given threshold θ; a pattern p is stable if there is a concept in the lattice with p as the intent and the concept is stable.\nExample 1 Figure 1b shows a lattice for the context in Figure 1a. Concept extents are given by their indices, i.e., {g1, g2} is given by 12. The extent of the highlighted concept C is Ext(C) = {g2, g3, g4}, thus, its powerset contains 23 elements. Descriptions of 2 subsets of Ext(C) ({g4} and ∅) are different from the intent of C, Int(C) = {m3}, while all other subsets of Ext(C) have a common set of attributes equal to 〈0; [1, 2]〉. So, Stab(C) = 2 3−2 23 = 0.75. Stability of other concepts is shown in brackets. It should be noticed that stability of all comparable patterns for Int(C) in the lattice is smaller than the stability of C, which highlights the nonmonotonicity of stability.\nConcept stability is closely related to the robustness of a closed pattern [17]. Indeed, robustness is the probability of a closed pattern to be found in a subset of the dataset. To define this probability, the authors define a weight for every subset given as a probability of obtaining this subset by removing objects from the dataset, where every object is removed with probability α, e.g., given a subset of objects X ⊆ G, the probability of the induced subset is given by p(Dα = (X, (D,⊓), δ)) = α|X|(1 − α)|G\\X|. Stability in this case is the robustness of closed pattern if the weights of subsets of the dataset are equal to 2−|G|.\nThe problem of computing concept stability is #P-complete [10]. A fast computable stability estimate was proposed in [3], where it was shown that this estimate ranks concepts almost in the same way as stability does. In particular,\nStab(C) ≤ 1 − 2−∆(C), where ∆(C) = min D≤C |Ext(C) \\ Ext(D)|, i.e., the minimal difference in supports between concept C and all its nearest subconcepts. For a threshold θ, patterns p with ∆(p) ≥ θ are called Δ-stable patterns.\nExample 2 Consider the example in Figure 1. Every edge in the figure is labeled with the difference in support between the concepts this edge connects. Thus, Δ of a pattern is the minimum label of the edges going down from the concept. The value ∆(({g2, g3, g4}; 〈0; [1, 2]〉)) is equal to 2. Another example is ∆((G; 〈[0, 1]; [0, 2]〉)) = 2. For this example we can also see that Δ-measure is not anti-monotonic either.\nΔ-measure is related to the work of margin-closeness of an itemset [13]. In this work, given a set of patterns, e.g., frequent closed patterns, the authors rank them by the minimal distance in their support to the closest superpattern divided over the support of the pattern. In our case, the minimal distance is exactly the Δ-measure of the pattern.\nStability andΔ-measure are not anti-monotonic but rather projection-antimonotonic. Patterns w.r.t. such kind of measures can be mined by a specialized algorithm introduced in Section 3. But before we should introduce projections of pattern structures in order to properly define projection-antimonotonicity and the algorithm."
    }, {
      "heading" : "2.4 Projections of Pattern Structures",
      "text" : "The approach proposed in this paper is based on projections introduced for reducing complexity of computing pattern lattices [5].\nA projection ψ : D → D is an “interior operator”, i.e., it is (1) monotonic (x ⊑ y ⇒ ψ(x) ⊑ ψ(y)), (2) contractive (ψ(x) ⊑ x) and (3) idempotent (ψ(ψ(x)) = ψ(x)). A projected pattern structure ψ((G, (D,⊓), δ)) is a pattern structure (G, (Dψ,⊓ψ), ψ ◦ δ), where Dψ = ψ(D) = {d ∈ D | ∃d∗ ∈ D : ψ(d∗) = d} and ∀x, y ∈ D, x ⊓ψ y := ψ(x ⊓ y).\nExample 3 Consider the example in Figure 1. If we remove a column corresponding to an attribute, e.g., the attribute m2, from the context in Figure 1a, we define a projection, given by ψ(〈[a, b]; [c, d]〉) = 〈[a, b]; [−∞,+∞]〉, meaning that no value of m2 is taken into account.\nGiven a projection ψ we call ψ(D) = {d ∈ D | ψ(d) = d} the fixed set of ψ. Note that, if ψ(d) 6= d, then there is no other d̃ such that ψ(d̃) = d because of idempotency of projections. Hence, any element outside the fixed set of the projection ψ is pruned from the description space. Given the notion of a fixed set we can define a partial order on projections.\nDefinition 1 Given a pattern structure P = (G, (D,⊓), δ) and two projections ψ1 and ψ2, we say that ψ1 is simpler than ψ2 (ψ2 is more detailed than ψ1), denoted by ψ1 < ψ2, if ψ1(D) ⊂ ψ2(D), i.e., ψ1 prunes more descriptions than ψ2.\nOur algorithm is based on this order on projections. The simpler a projection ψ is, the less patterns we can find in ψ(P), and the less computational efforts one should take. Thus, we compute a set of patterns for a simpler projection, then we remove unpromising patterns and extend our pattern structure and the found patterns to a more detailed projection. This allows us to reduce the size of patterns within a simpler projection in order to reduce the computational complexity of more detailed projection."
    }, {
      "heading" : "2.5 Projections of Interval Pattern Structures",
      "text" : "Let us first consider interval pattern structures with only one attributem. Let us denote byW = {w1, · · · , w|W |} all possible values of the left and right endpoints of the intervals corresponding to the attribute in a dataset, so that w1 < w2 < · · · < w|W |. By reducing the setW of possible values for the left or the right end of the interval we define a projection. For example, if {w1} is the only possible value for the left endpoint of an interval and {w|W |} is the only possible value of the right endpoint of an interval, then all interval patterns are projected to [w1, w|W |]. Let us consider this in more detail.\nLet two sets L,R ⊂ W such that w1 ∈ L and w|W | ∈ R be constraints on possible values on the left and right endpoints of an interval, respectively. Then a projection is defined as follows:\nψm[L,R]([a, b]) = [max{l ∈ L|l ≤ a},min{r ∈ R|r ≥ b}] . (2)\nRequiring that w1 ∈ L and w|W | ∈ R we ensure that the sets used for minimal and maximal functions are not empty. It is not hard to see that (2) is a projection. The projections given by (2) are ordered w.r.t. simplicity (Definition 1). Indeed, given L1 ⊆ L and R1 ⊆ R, we have ψm[L1,R1] < ψm[L,R], because of inclusion of fixed sets. Let us notice that a projection ψm[W,W ] does not modify the lattice of concepts for the current dataset, since any interval for the value set W is possible. We also notice that a projection ψm[L,R] is defined for one interval, while we can combine the projections for different attributes in a tuple to a single projection for the whole tuple ψm1[L1,R1]m2[L2,R2]....\nExample 4 Consider example in Figure 1. Let us consider a projection\nψm1[{0,1},{1}]m2[{0,2},{0,2}].\nThe fixed set of this projection consists of {[0, 1], 1}× {0, 2, [0, 2]}, i.e., 6 intervals. Let us find the projection of (g2)\n⋄ = 〈0; [1, 2]〉 in a component-wise way: ψm1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; ψm2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval. Thus,\nψm1[{0,1},{1}]m2[{0,2},{0,2}](〈0; [1, 2]〉) = 〈[0, 1]; [0, 2]〉 .\nThe lattice corresponding to this projection is shown in Figure 2."
    }, {
      "heading" : "3 θ-Σοφια Algorithm",
      "text" : ""
    }, {
      "heading" : "3.1 Anti-monotonicity w.r.t. a Projection",
      "text" : "Our algorithm is based on the projection-antimonotonicity, a new idea introduced in this paper. Many interestingness measures for patterns, e.g., stability, are not (anti-)monotonic w.r.t. subsumption order on patterns. A measure M is called anti-monotonic, if for two patterns q ⊑ p, M(q) ≥ M(p). For instance, support is a anti-monotonic measure w.r.t. pattern order and it allows for efficient generation of patterns with support larger than a threshold [1, 12, 14]. The projection-antimonotonicity is a generalization of standard anti-monotonicity and allows for efficient work with a larger set of interestingness measures.\nDefinition 2 Given a pattern structure P and a projection ψ, a measure M is called anti-monotonic w.r.t. the projection ψ, if\n(∀p ∈ ψ(P))(∀q ∈ P, ψ(q) = p) Mψ(p) ≥ M(q), (3)\nwhere Mψ(p) is the measure M of a pattern p computed in ψ(P).\nHere, for any pattern p of a projected pattern structure we check that a preimage q of p for ψ has a measure smaller than the measure of p. It should be noticed that a measure M for a pattern p can yield different values if M is computed in P or in ψ(P). Thus we use the notation Mψ for the measure M computed in ψ(P). The property of a measure given in Definition 2 is called projection-antimonotonicity.\nIt should be noticed that classical anti-monotonic measures are projectionantimonotonic for any projection. Indeed, because of contractivity of ψ (ψ(p) ⊑ p), for any anti-monotonic measure one has M(ψ(p)) ≥ M(p). This definition covers also the cases where a measure M is only locally anti-monotonic, i.e., given a pattern p there is an immediate subpattern q ≺ p such that M(q) ≥ M(p), see e.g., the cosine interest of an itemset, which is only locally antimonotonic [4]. Moreover, this definition covers also some measures that are not locally anti-monotonic. As we mentioned in Examples 1 and 2 stability and Δmeasure are not locally anti-monotonic. However, it can be shown that they are anti-monotonic w.r.t. any projection [2]. Moreover, following the same strategy\none can prove that robustness of closed patterns from [17] is also anti-monotonic w.r.t. any projection. In particular, the robustness of closed patterns defines a anti-monotonic constraint w.r.t. any projection.\nThus, given a measure M anti-monotonic w.r.t. a projection ψ, if p is a pattern such that Mψ(p) < θ, then M(q) < θ for any preimage q of p for ψ. Hence, if, given a pattern p of ψ(P), one can find all patterns q of P such that ψ(q) = p, it is possible to first find all patterns of ψ(P) and then to filter them w.r.t. Mψ and a threshold, and finally to compute the preimages of filtered patterns. It allows one to cut earlier unpromising branches of the search space or adjust a threshold for finding only a limited number of best patterns."
    }, {
      "heading" : "3.2 Anti-monotonicity w.r.t. a Chain of Projections",
      "text" : "However, given just one projection, it can be hard to efficiently discover the patterns, because the projection is either hard to compute or the number of unpromising patterns that can be pruned is not high. Hence we introduce a chain of projections ψ0 < ψ1 < · · · < ψk = 1, where a pattern lattice for ψ0(P) can be easily computed and 1 is the identity projection, i.e., (∀x)1(x) = x. For example, to find frequent itemsets, we typically search for small frequent itemsets and then extend them to larger ones. This corresponds to extension to a more detailed projection.\nDefinition 3 Given a pattern structure P and a chain of projections ψ0 < ψ1 < · · · < ψk = 1, a measure M is called anti-monotonic w.r.t. the chain of projections if M is anti-monotonic w.r.t. all ψi for 0 ≤ i ≤ k.\nExample 5 Let us construct a chain of projections satisfying (2) for the example in Figure 1. The value set for the first attribute is W1 = {0, 1} and the value set for the second is W2 = {0, 1, 2}. Let us start the chain from a projection ψ0 = ψm1[{0},{1}]m2[{0},{2}]. This projection allows only for one pattern 〈[0, 1]; [0, 2]〉, i.e., the concept lattice is easily found. Then we increase the complexity of a projection by allowing more patterns. For example, we can enrich the first component of a tuple without affecting the second one, i.e., a projection ψ1 = ψm1[{0,1},{0,1}]m2[{0},{2}]. This projection allows for 3 patterns, i.e., any possible interval of the first component and only one interval [0,2] for the second component. Let us notice that it is not hard to find preimages for ψ0 in ψ1(D). Indeed, for any pattern p from ψ0(D) one should just modify either the left side of the first interval of p by one value, or the right side of the first interval of p.\nThen we can introduce a projection that slightly enrich the second component of a tuple, e.g., ψ2 = ψm1[{0,1},{0,1}]m2[{0,1},{1,2}] and finally we have ψ3 = ψm1[W1,W1]m2[W2,W2]. Finding preimages in this chain is not a hard problem, since on every set we can only slightly change left and/or right side of the second interval in a tuple. Thus, starting from a simple projection and making transitions from one projection to another, we can cut unpromising branches and efficiently find the set of interesting patterns."
    }, {
      "heading" : "3.3 Algorithms",
      "text" : "Data: A pattern structure P, a chain of projections Ψ = {ψ0, ψ1, · · · , ψk}, a measure M anti-monotonic for the chain Ψ, and a threshold θ for M.\n1 Function ExtendProjection(i, θ, Pi−1) Data: i is the projection number to which we should extend\n(0 < i ≤ k), θ is a threshold value for M, and Pi−1 is the set of patterns for the projection ψi−1.\nResult: The set Pi of all patterns with the value of measure M higher than the threshold θ for ψi.\n2 Pi ←− ∅; 3 /* Put all preimages in ψi(P) for any pattern p */ 4 foreach p ∈ Pi−1 do 5 Pi ←− Pi ∪ Preimages(i,p) 6 /* Filter patterns in Pi to have a value of M higher than\nθ */\n7 foreach p ∈ Pi do 8 if Mψi(p) ≤ θ then 9 Pi ←− Pi \\ {p}\n10 Function Algorithm θ-Σοφια Result: The set P of all patterns with a value of M higher than the threshold θ for P. 11 /* Find all patterns in ψ0(P) with a value of M higher\nthan θ */\n12 P ←− FindPatterns(θ, ψ0); 13 /* Run through out the chain Ψ and find the patterns for ψi(P) */ 14 foreach 0 < i ≤ k do 15 P ←− ExtendProjection(i, θ,P);\nAlgorithm 1: The θ-Σοφια algorithm for finding patterns in P with a value of a measure M higher than a threshold θ.\nGiven a measure anti-monotonic w.r.t. a chain of projections, if we are able to find all preimages of any element in the fixed set of ψi that belong to a fixed set of ψi+1, then we can find all patterns of P with a value of M higher than a given threshold θ. We call this algorithm θ-Σοφια and its pseudocode is given in Algorithm 1. In lines 11-12 we find all patterns for ψ0(P) satisfying the constraint that a value of M is higher than a threshold. Then in lines 13- 15 we iteratively extend projections from simpler to more detailed ones. The extension is done by constructing the set Pi of preimages of the set Pi−1 (lines 2-5) and then by removing the patterns that do not satisfy the constraint from Pi (lines 6-9).\nThe algorithm is sound and complete, since first, a pattern p is included\ninto the set of preimages of p (ψ(p) = p) and second, if we remove a pattern p from the set P , then the value M(p) < θ and, hence, the measure value of any preimage of p is less than θ by the projection-antimonotonicity of M. The worst case time complexity of θ-Σοφια algorithm is\nT(θ-Σοφια) = T(FindPatterns(ψ0))+\n+ k · max 0<i≤k |Pi| · (T(Preimages) + T(M)), (4)\nwhere k is the number of projections in the chain, T(X ) is time for computing operation X . Since projection ψ0 can be chosen to be very simple, in a typical case the complexity of FindPatterns(θ, ψ0) can be low or even constant. The complexities of Preimages and M depend on the measure, the chain of projections, and the kind of patterns. In many cases max\n0<i≤k |Pi| can be exponential in\nthe size of the input, because the number of patterns can be exponential. It can be a difficult task to define the threshold θ such that the maximal cardinality of Pi is not larger than a given number. This can be solved by an automatically adjustment of the threshold θ, which is not discussed here."
    }, {
      "heading" : "3.4 θ-Σοφια Algorithm for Interval Tuple Data",
      "text" : "In this subsection we consider a pattern structure K = (G, (DI ,⊓), δ), where DI is a semilattice of interval tuple descriptions. We say that every component of a tuple p corresponds to an attribute m ∈ M , where M is the set of interval attributes. Thus, the size of any tuple in DI is |M |, and for any attribute m ∈M we can denote the corresponding interval by m(p). We also denote the value set of m by Wm. Since the set Wm is totally ordered we also denote by W (j) m and W (−j) m the sets containing the first j (smallest) elements and the last j (largest) elements from Wm, respectively. A projection chain for interval tuple data is formed in the same way as discussed in Example 5. We start from the projection containing only one pattern corresponding to the largest interval in each component, i.e., for an attribute m the projection is of the form ψm[W (1) m ,W (−1) m ]. Then to pass to a next projection, we select the attribute m, and for this attribute we extend the projection from ψm[W (j) m ,W (−j) m ] to ψm[W (j+1) m ,W (−j−1) m ]. Thus, there are k = max m∈M |Wm| · |M | projections.\nFinding preimages in this case is not hard, since to make a projection more detailed one should just extend the corresponding interval in left and/or on right end of the interval, i.e., there are only 4 possible preimages for a pattern when passing from one projection to another in this chain. Thus, we have proved the following\nProposition 1 The worst case complexity for θ-Σοφια algorithm for interval tuple data is\nT(θ-Σοφια intervals ) = max m∈M |Wm| · |M | · max 0<i≤k |Pi| · T(M). (5)\n."
    }, {
      "heading" : "3.5 θ-Σοφια Algorithm for Closed Patterns",
      "text" : "Closed frequent itemsets are widely used as a condensed representation of all frequent itemsets since [14]. Here we show how we can adapt the algorithm for closed patterns. A closed pattern in ψi−1(P) is not necessarily closed in ψi(P). However, the extents of ψ(P) are extents of P [5]. Thus, we associate the closed patterns with extents and then work with extents instead of patterns, i.e., a pattern structure P = (G, (D,⊓), δ) is transformed into PC = (G, (DC ,⊓C), δC), where DC = 2\nG. Moreover, for all x, y ∈ DC we have x⊓C y = (x⋄⊓y⋄)⋄, where diamond operator is computed in P and δC(g ∈ G) = {g}. Hence, every pattern p in DC corresponds to a closed pattern p\n⋄ in D. A projection ψ of P induces a projection ψC of PC , given by ψC(X ⊆ G) = ψ(X⋄)⋄ with (·)⋄ for P."
    }, {
      "heading" : "3.6 Δ-measure and θ-Σοφια Algorithm",
      "text" : "In this subsection we show that Δ-measure is anti-monotonic for any projection; it is a stronger condition than the one required by Definition 3. Δ-measure works for closed patterns, and, hence, we identify every description by its extent (Subsection 3.5).\nProposition 2 ∆ is anti-monotonic for any projection ψ.\nProof. By properties of a projection, an extent of ψ(P) is an extent of P [5]. Let us consider an extent E and an extent of its descendant in ψ(P). Let us suppose that Ep is a preimage of E for the projection ψ. Since Ec and Ep are extents in P, the set Ecp = Ec ∩ Ep is an extent in P (the intersection of two closed sets is a closed set). Since Ep is a preimage of E, then Ep 6≤ Ec (otherwise, Ep is a preimage of Ec and not of E). Then, Ecp 6= Ep and Ecp ≤ Ep. Hence, ∆(Ep) ≤ |Ep\\Ecp| ≤ |E \\Ec|. So, given a preimage Ep of E, (∀Ec ⊆ E)∆(Ep) ≤ |E \\Ec|, i.e., ∆(Ep) ≤ ∆(E). Thus, we can use Δ-measure in combination with θ-Σοφια."
    }, {
      "heading" : "3.7 Example of Δ-Stable Patterns in Interval Tuple Data",
      "text" : "Let us consider the example in Figure 1 and show how we can find all Δ-stable patterns with a threshold θ = 2. The chain of projections for this example is given in Example 5, it contains 4 projections:\nψ0 = ψm1[{0},{1}]m2[{0},{2}] ψ1 = ψm1[{0,1},{0,1}]m2[{0},{2}] ψ2 = ψm1[{0,1},{0,1}]m2[{0,1},{1,2}] ψ3 = ψm1[{0,1},{0,1}]m2[{0,1,2},{0,1,2}]\nSince we are looking for closed patterns, every pattern can be identified by its extent. In Table 1 all patterns are given by their extents, i.e., by elements of DC . For every pattern Δ-measure is shown for every ψi. A cell is shown in grey if the pattern is no more considered (the value of Δ less than 2). A cell has a dash “–”, if a pattern in the row has not been generated for this projection.\nFor the example in Figure 1 the global process is as follows. At the beginning ψ0(DI) contains only one element corresponding to pattern extent 123456 (a short cut for {g1, g2, g3, g4, g5, g6}) with a description 〈[0, 1]; [0, 2]〉. Then, in ψ1(G, (DI ,⊓), δ) possible preimages of 123456 are patterns with descriptions 〈0; [0, 2]〉 and 〈1; [0, 2]〉 given by pattern extents 1234 and 56, respectively. Then we continue with these three patterns which are all Δ-stable for the moment. The pattern extents 123456 and 56 have no preimages for the transition ψ1 → ψ2, while the pattern extent 1234 has two preimages with descriptions 〈0; [0, 1]〉 and 〈0; [1, 2]〉 for this projection, which correspond to pattern extents 1 and 234. The first one is not Δ-stable and thus is no more considered. Moreover, the pattern extent 1234 is not Δ-stable (because of 234) and should also be removed. Finally, in transition ψ2 → ψ3 only extent-pattern 234 has a preimage, a pattern extent 4, which is not Δ-stable. In such a way, we have started from a very simple projection ψ0 and achieved the projection ψ3 that gives us the Δ-stable patterns of the target pattern structure."
    }, {
      "heading" : "4 Experiments and Discussion",
      "text" : "In this section we compare our approach to approaches based on postfiltering. Indeed, there is no approach that can directly mine stable-like pattern, e.g., stable, Δ-stable or robust patterns. The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17]. Recently it was also shown that it is more efficient to mine interval tuple data without binarization [8]. In their paper the authors introduce algorithm MinIntChange for working directly with interval tuple data. Thus we compare θ-Σοφια and MinIntChange for finding Δ-stable patterns. We find Δ-stable concepts with θ-Σοφια and then adjust frequency threshold θ such that all Δ-stable patterns are among the frequent ones.\nThe experiments are carried out on an “Intel(R) Core(TM) i7-2600 CPU @ 3.40GHz” computer with 8Gb of memory under Ubuntu 14.04 operating system. The algorithms are not parallelized and are coded in C++."
    }, {
      "heading" : "4.1 Dataset Simplification",
      "text" : "For interval tuple data stable patterns can be very deep in the search space, such that neither of the algorithms can find them quickly. Thus, we join some similar values for every attribute in an interval in the following way. Given a threshold 0 < β, two consequent numbers wi and wi+1 from a value set W are joined in the same interval if wi+1 − wi < β. In order to properly set the threshold β, we use another threshold 0 < γ < 1, which is much easier to set.\nIf we assume that the values of the attributem are distributed around several states with centers w̃1, · · · , w̃l, then it is natural to think that the difference between the closest centers abs(w̃i − w̃i±1) are much larger than the difference between the closest values. Ordering all values in the increasing order and finding the maximal difference δmax can give us an idea of typical distance between the states in the data. Thus, γ is defined as a proportion of this distance that should be considered as a distance between states, i.e., we put β = γ · δmax. If the distance between closest values in W are always the same, then even γ = 0.99 does not join values in intervals. However, if there are two states and the values are distributed very closely to one of these two states, then even γ = 0.01 can join values into one of two intervals corresponding to the states."
    }, {
      "heading" : "4.2 Datasets",
      "text" : "We take several datasets from the Bilkent University database 1. The datasets are summarized in Table 2. The names of datasets are given by standard abbreviations used in the database of Bilkent University. For every dataset we provide the number of objects and attributes and the threshold γ for which the experiments are carried out. For example, database EM has 61 objects, 9 numeric attributes, and the threshold γ is set to 0.3. Categorical attributes and rows with missing values, if any, are removed from the datasets."
    }, {
      "heading" : "4.3 Experiments",
      "text" : "In Table 2 we show the computation time for finding the best Δ-stable pattern (or patterns if they have the same value for Δ-measure) for θ-Σοφια and for MinIntChange. The last algorithm is abbreviated as MIC. Since MinIntChange algorithm sometimes produces too many patterns, i.e., we do not have enough memory in our computer to check all of them, we interrupt the procedure and show the corresponding time in grey. We also show the number of the best patterns and the corresponding threshold ∆. The support threshold θ for finding the best Δ-stable patterns is also shown. For example, dataset CN contains 5362 best Δ-stable patterns, all having a Δ of 2. To find all these patterns with a postfiltering, we should mine frequent patterns with a support threshold lower than 30 or 30105 = 30%. θ-Σοφια computes all these patterns in 2.4 seconds, while\n1http://funapp.cs.bilkent.edu.tr/DataSets/\nMinIntChange requires at least 28 seconds and the procedure was interrupted without continuation.\nAs we can see, θ-Σοφια is significantly faster than MinIntChange in all datasets. In the two datasets CA and PT, MinIntChange was stopped before computing all patterns and the runtime did not exceed the runtime of θ-Σοφια. However, in both cases, MinIntChange achieved less than 10% of the required operations."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper we have introduced a new class of interestingness measures that are anti-monotonic w.r.t. a chain of projections. We have designed a new algorithm, called θ-Σοφια, which is able to efficiently find the best patterns w.r.t. such interestingness measures for interval tuple data. The experiments reported in the paper are the witness of the efficiency of the θ-Σοφια algorithms compared to indirect approaches based on postfiltering. Many future research directions are possible. Different measures should be studied in combination with θ-Σοφια. One of them is robustness, which is very close to stability and can be applied to nonbinary data. Moreover, the choice of a projection chain is not a simple one and can affect the algorithm efficiency. Thus, a deep study of suitable projection chains should be carried out.\nAcknowledgments: this research was supported by the Basic Research Program at\nthe National Research University Higher School of Economics (Moscow, Russia) and by the BioIntelligence project (France)."
    } ],
    "references" : [ {
      "title" : "Fast algorithms for mining association rules",
      "author" : [ "Rakesh Agrawal", "Ramakrishnan Srikant", "Others" ],
      "venue" : "In Proc. 20th int. conf. very large data bases, VLDB,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1994
    }, {
      "title" : "On Projections of Sequential Pattern Structures (with an application on care trajectories)",
      "author" : [ "Aleksey Buzmakov", "Elias Egho", "Nicolas Jay", "Sergei O. Kuznetsov", "Amedeo Napoli", "Chedy Räıssi" ],
      "venue" : "In Proc. 10th Int. Conf. Concept Lattices Their Appl.,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2013
    }, {
      "title" : "Scalable Estimates of Concept Stability",
      "author" : [ "Aleksey Buzmakov", "Sergei O. Kuznetsov", "Amedeo Napoli" ],
      "venue" : "Form. Concept Anal.,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2014
    }, {
      "title" : "Scaling up cosine interesting pattern discovery: A depth-first method",
      "author" : [ "Jie Cao", "Zhiang Wu", "Junjie Wu" ],
      "venue" : "Inf. Sci. (Ny).,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2014
    }, {
      "title" : "Pattern Structures and Their Projections",
      "author" : [ "Bernhard Ganter", "Sergei O. Kuznetsov" ],
      "venue" : "Concept. Struct. Broadening Base,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2001
    }, {
      "title" : "Formal Concept Analysis: Mathematical Foundations",
      "author" : [ "Bernhard Ganter", "Rudolf Wille" ],
      "venue" : "Springer, 1st edition,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1999
    }, {
      "title" : "Mining top-k frequent closed patterns without minimum support",
      "author" : [ "Jiawei Han", "Jianyong Wang", "Ying Lu", "P Tzvetkov" ],
      "venue" : "In Data Mining,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2002
    }, {
      "title" : "Revisiting Numerical Pattern Mining with Formal Concept Analysis",
      "author" : [ "Mehdi Kaytoue", "Sergei O. Kuznetsov", "Amedeo Napoli" ],
      "venue" : "IJCAI",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2011
    }, {
      "title" : "On Computing the Size of a Lattice and Related Decision Problems",
      "author" : [ "Sergei O. Kuznetsov" ],
      "venue" : null,
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2001
    }, {
      "title" : "On stability of a formal concept",
      "author" : [ "Sergei O. Kuznetsov" ],
      "venue" : "Ann. Math. Artif. Intell.,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2007
    }, {
      "title" : "Learning Closed Sets of Labeled Graphs for Chemical Applications",
      "author" : [ "Sergei O. Kuznetsov", "Mikhail V. Samokhin" ],
      "venue" : "Inductive Log. Program. SE - 12,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2005
    }, {
      "title" : "Efficient Algorithms for Discovering Association Rules",
      "author" : [ "Heikki Mannila", "Hannu Toivonen", "A Inkeri Verkamo" ],
      "venue" : "In Knowl. Discov. Data Min.,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1994
    }, {
      "title" : "Efficient mining of all margin-closed itemsets with applications in temporal knowledge discovery and classification by compression",
      "author" : [ "Fabian Moerchen", "Michael Thies", "Alfred Ultsch" ],
      "venue" : "Knowl. Inf. Syst.,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2011
    }, {
      "title" : "Efficient Mining of Association Rules Using Closed Itemset Lattices",
      "author" : [ "Nicolas Pasquier", "Yves Bastide", "Rafik Taouil", "Lotfi Lakhal" ],
      "venue" : "Inf. Syst.,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1999
    }, {
      "title" : "On succinct representation of knowledge community taxonomies with formal concept analysis",
      "author" : [ "Camille Roth", "Sergei A. Obiedkov", "Derrick G. Kourie" ],
      "venue" : "Int. J. Found. Comput. Sci.,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2008
    }, {
      "title" : "Interesting pattern mining in multi-relational data",
      "author" : [ "Eirini Spyropoulou", "Tijl De Bie", "Mario Boley" ],
      "venue" : "Data Min. Knowl. Discov.,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2013
    }, {
      "title" : "Finding Robust Itemsets under Subsampling",
      "author" : [ "Nikolaj Tatti", "Fabian Moerchen", "Toon Calders" ],
      "venue" : "ACM Trans. Database Syst.,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2014
    }, {
      "title" : "Interesting Patterns",
      "author" : [ "Jilles Vreeken", "Nikolaj Tatti" ],
      "venue" : "Freq. Pattern Min.,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2014
    }, {
      "title" : "Self-sufficient itemsets",
      "author" : [ "Geoffrey I. Webb" ],
      "venue" : "ACM Trans. Knowl. Discov. Data,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2010
    }, {
      "title" : "Filtered-top-k association discovery",
      "author" : [ "Geoffrey I. Webb" ],
      "venue" : "Wiley Interdiscip. Rev. Data Min. Knowl. Discov.,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2011
    }, {
      "title" : "Extracting redundancy-aware top-k patterns",
      "author" : [ "Dong Xin", "Hong Cheng", "Xifeng Yan", "Jiawei Han" ],
      "venue" : "In Proc. 12th ACM SIGKDD Int. Conf. Knowl. Discov. data Min. - KDD",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2006
    }, {
      "title" : "Mining significant graph patterns by leap search",
      "author" : [ "Xifeng Yan", "Hong Cheng", "Jiawei Han", "Philip S. Yu" ],
      "venue" : "In Proc. 2008 ACM SIGMOD Int. Conf. Manag. data - SIGMOD",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2008
    }, {
      "title" : "CloSpan: Mining Closed Sequential Patterns in Large Databases",
      "author" : [ "Xifeng Yan", "Jiawei Han", "Ramin Afshar" ],
      "venue" : "In Proc. SIAM Int’l Conf. Data Min.,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2003
    }, {
      "title" : "Mining itemset utilities from transaction databases",
      "author" : [ "Hong Yao", "Howard J Hamilton" ],
      "venue" : "Data Knowl. Eng.,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "Interestingness measures were proposed to overcome the problem of combinatorial explosion of the number of valid patterns that can be discovered in a dataset [18].",
      "startOffset" : 158,
      "endOffset" : 162
    }, {
      "referenceID" : 11,
      "context" : ", the larger the pattern is the smaller the support is [12, 1].",
      "startOffset" : 55,
      "endOffset" : 62
    }, {
      "referenceID" : 0,
      "context" : ", the larger the pattern is the smaller the support is [12, 1].",
      "startOffset" : 55,
      "endOffset" : 62
    }, {
      "referenceID" : 23,
      "context" : "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 9,
      "context" : "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.",
      "startOffset" : 88,
      "endOffset" : 96
    }, {
      "referenceID" : 14,
      "context" : "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.",
      "startOffset" : 88,
      "endOffset" : 96
    }, {
      "referenceID" : 18,
      "context" : "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 12,
      "context" : "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.",
      "startOffset" : 138,
      "endOffset" : 142
    }, {
      "referenceID" : 15,
      "context" : "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 3,
      "context" : "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.",
      "startOffset" : 171,
      "endOffset" : 174
    }, {
      "referenceID" : 16,
      "context" : "Many other measures can be mentioned such as utility constraint [24], pattern stability [10, 15], pattern leverage [19], margin closeness [13], MCCS [16], cosine interest [4], pattern robustness [17], etc.",
      "startOffset" : 195,
      "endOffset" : 199
    }, {
      "referenceID" : 16,
      "context" : ", support, robustness for generators [17], or upper bound constraint of MCCS [16]) are “globally anti-monotonic”, i.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 15,
      "context" : ", support, robustness for generators [17], or upper bound constraint of MCCS [16]) are “globally anti-monotonic”, i.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 3,
      "context" : "For example, for “locally anti-monotonic” cosine interest [4], the extension of a pattern Y consists in adding only attributes with a smaller support than any attribute from Y .",
      "startOffset" : 58,
      "endOffset" : 61
    }, {
      "referenceID" : 14,
      "context" : ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].",
      "startOffset" : 40,
      "endOffset" : 52
    }, {
      "referenceID" : 12,
      "context" : ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].",
      "startOffset" : 40,
      "endOffset" : 52
    }, {
      "referenceID" : 16,
      "context" : ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].",
      "startOffset" : 40,
      "endOffset" : 52
    }, {
      "referenceID" : 21,
      "context" : ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].",
      "startOffset" : 94,
      "endOffset" : 98
    }, {
      "referenceID" : 18,
      "context" : ", neither monotonic nor anti-monotonic) [15, 13, 17], or using heuristics such as leap search [22] or low probability of finding interesting patterns in the current branch [19].",
      "startOffset" : 172,
      "endOffset" : 176
    }, {
      "referenceID" : 9,
      "context" : "In particular, support, stability [10], margin-closeness [13] and robustness [17] are pattern independent measures.",
      "startOffset" : 34,
      "endOffset" : 38
    }, {
      "referenceID" : 12,
      "context" : "In particular, support, stability [10], margin-closeness [13] and robustness [17] are pattern independent measures.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 16,
      "context" : "In particular, support, stability [10], margin-closeness [13] and robustness [17] are pattern independent measures.",
      "startOffset" : 77,
      "endOffset" : 81
    }, {
      "referenceID" : 6,
      "context" : "Thus various approaches for finding top-K patterns were introduced [7, 21, 20], with the basic idea to automatically adjust the threshold for a measure M.",
      "startOffset" : 67,
      "endOffset" : 78
    }, {
      "referenceID" : 20,
      "context" : "Thus various approaches for finding top-K patterns were introduced [7, 21, 20], with the basic idea to automatically adjust the threshold for a measure M.",
      "startOffset" : 67,
      "endOffset" : 78
    }, {
      "referenceID" : 19,
      "context" : "Thus various approaches for finding top-K patterns were introduced [7, 21, 20], with the basic idea to automatically adjust the threshold for a measure M.",
      "startOffset" : 67,
      "endOffset" : 78
    }, {
      "referenceID" : 5,
      "context" : "The formalization of the current approach is based on Formal Concept Analysis (FCA) [6] and pattern structures [5] which are introduced in Section 2.",
      "startOffset" : 84,
      "endOffset" : 87
    }, {
      "referenceID" : 4,
      "context" : "The formalization of the current approach is based on Formal Concept Analysis (FCA) [6] and pattern structures [5] which are introduced in Section 2.",
      "startOffset" : 111,
      "endOffset" : 114
    }, {
      "referenceID" : 5,
      "context" : "Formal Concept Analysis (FCA) is a formalism for knowledge discovery and data mining thanks to the design of concept lattices [6].",
      "startOffset" : 126,
      "endOffset" : 129
    }, {
      "referenceID" : 13,
      "context" : "It is also convenient for describing models of itemset mining, and, since [14], lattices of closed itemsets (i.",
      "startOffset" : 74,
      "endOffset" : 78
    }, {
      "referenceID" : 4,
      "context" : "For more complex data such as sequences and graphs one can use an extension of the basic model, called pattern structures [5].",
      "startOffset" : 122,
      "endOffset" : 125
    }, {
      "referenceID" : 10,
      "context" : "With pattern structures it is possible to define closed descriptions and to give a concise representation of association rules for different descriptions with a natural order (such as subgraph isomorphism order) [11, 8].",
      "startOffset" : 212,
      "endOffset" : 219
    }, {
      "referenceID" : 7,
      "context" : "With pattern structures it is possible to define closed descriptions and to give a concise representation of association rules for different descriptions with a natural order (such as subgraph isomorphism order) [11, 8].",
      "startOffset" : 212,
      "endOffset" : 219
    }, {
      "referenceID" : 10,
      "context" : "As shown in [11], descriptions closed in terms of counting inference (which is a standard data mining approach), such as closed graphs [23], are elements of pattern intents.",
      "startOffset" : 12,
      "endOffset" : 16
    }, {
      "referenceID" : 22,
      "context" : "As shown in [11], descriptions closed in terms of counting inference (which is a standard data mining approach), such as closed graphs [23], are elements of pattern intents.",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 7,
      "context" : "A possible instantiation of pattern structures is interval pattern structures introduced to support efficient processing of numerical data without binarization [8].",
      "startOffset" : 160,
      "endOffset" : 163
    }, {
      "referenceID" : 0,
      "context" : "For example, the value of m1 for g2 is known exactly, while the value of m2 is lying in [1, 2].",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 1,
      "context" : "For example, the value of m1 for g2 is known exactly, while the value of m2 is lying in [1, 2].",
      "startOffset" : 88,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : "For example, for g1 the value of m1 is 0, while for g6 it is 1, thus given the set {g1, g6}, the uncertainty of m1 in this set is [0, 1], i.",
      "startOffset" : 130,
      "endOffset" : 136
    }, {
      "referenceID" : 0,
      "context" : "m1 is [0, 1].",
      "startOffset" : 6,
      "endOffset" : 12
    }, {
      "referenceID" : 0,
      "context" : "For example, g 1 ⊓ g ⋄ 6 = 〈[0, 1]; [0, 2]〉.",
      "startOffset" : 28,
      "endOffset" : 34
    }, {
      "referenceID" : 1,
      "context" : "For example, g 1 ⊓ g ⋄ 6 = 〈[0, 1]; [0, 2]〉.",
      "startOffset" : 36,
      "endOffset" : 42
    }, {
      "referenceID" : 0,
      "context" : "Reciprocally, 〈[0, 1]; [0, 2]〉 = {g1, g2, · · · , g6}.",
      "startOffset" : 15,
      "endOffset" : 21
    }, {
      "referenceID" : 1,
      "context" : "Reciprocally, 〈[0, 1]; [0, 2]〉 = {g1, g2, · · · , g6}.",
      "startOffset" : 23,
      "endOffset" : 29
    }, {
      "referenceID" : 8,
      "context" : "For real datasets, the number of patterns can be very large, even computing the number of closed patterns is a #P-complete problem [9].",
      "startOffset" : 131,
      "endOffset" : 134
    }, {
      "referenceID" : 9,
      "context" : "Different measures were tested for selecting most interesting patterns, such as stability [10].",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]",
      "startOffset" : 18,
      "endOffset" : 24
    }, {
      "referenceID" : 1,
      "context" : "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]",
      "startOffset" : 18,
      "endOffset" : 24
    }, {
      "referenceID" : 0,
      "context" : "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]",
      "startOffset" : 30,
      "endOffset" : 36
    }, {
      "referenceID" : 1,
      "context" : "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]",
      "startOffset" : 30,
      "endOffset" : 36
    }, {
      "referenceID" : 1,
      "context" : "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]",
      "startOffset" : 49,
      "endOffset" : 55
    }, {
      "referenceID" : 1,
      "context" : "m1 m2 g1 0 0 g2 0 [1, 2] g3 0 [1, 2] g4 0 2 g5 1 [0, 2] g6 1 [0, 2]",
      "startOffset" : 61,
      "endOffset" : 67
    }, {
      "referenceID" : 0,
      "context" : "(∅;⊤)[1] (4; 〈0; 2〉)[0.",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 0,
      "context" : "1 (234; 〈0; [1, 2]〉)[0.",
      "startOffset" : 12,
      "endOffset" : 18
    }, {
      "referenceID" : 1,
      "context" : "1 (234; 〈0; [1, 2]〉)[0.",
      "startOffset" : 12,
      "endOffset" : 18
    }, {
      "referenceID" : 1,
      "context" : "2 (1234; 〈0; [0, 2]〉)[0.",
      "startOffset" : 13,
      "endOffset" : 19
    }, {
      "referenceID" : 1,
      "context" : "3 (56; 〈1; [0, 2]〉)[0.",
      "startOffset" : 11,
      "endOffset" : 17
    }, {
      "referenceID" : 0,
      "context" : "2 (123456; 〈[0, 1]; [0, 2]〉)[0.",
      "startOffset" : 12,
      "endOffset" : 18
    }, {
      "referenceID" : 1,
      "context" : "2 (123456; 〈[0, 1]; [0, 2]〉)[0.",
      "startOffset" : 20,
      "endOffset" : 26
    }, {
      "referenceID" : 0,
      "context" : "Descriptions of 2 subsets of Ext(C) ({g4} and ∅) are different from the intent of C, Int(C) = {m3}, while all other subsets of Ext(C) have a common set of attributes equal to 〈0; [1, 2]〉.",
      "startOffset" : 179,
      "endOffset" : 185
    }, {
      "referenceID" : 1,
      "context" : "Descriptions of 2 subsets of Ext(C) ({g4} and ∅) are different from the intent of C, Int(C) = {m3}, while all other subsets of Ext(C) have a common set of attributes equal to 〈0; [1, 2]〉.",
      "startOffset" : 179,
      "endOffset" : 185
    }, {
      "referenceID" : 16,
      "context" : "Concept stability is closely related to the robustness of a closed pattern [17].",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 9,
      "context" : "The problem of computing concept stability is #P-complete [10].",
      "startOffset" : 58,
      "endOffset" : 62
    }, {
      "referenceID" : 2,
      "context" : "A fast computable stability estimate was proposed in [3], where it was shown that this estimate ranks concepts almost in the same way as stability does.",
      "startOffset" : 53,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "The value ∆(({g2, g3, g4}; 〈0; [1, 2]〉)) is equal to 2.",
      "startOffset" : 31,
      "endOffset" : 37
    }, {
      "referenceID" : 1,
      "context" : "The value ∆(({g2, g3, g4}; 〈0; [1, 2]〉)) is equal to 2.",
      "startOffset" : 31,
      "endOffset" : 37
    }, {
      "referenceID" : 0,
      "context" : "Another example is ∆((G; 〈[0, 1]; [0, 2]〉)) = 2.",
      "startOffset" : 26,
      "endOffset" : 32
    }, {
      "referenceID" : 1,
      "context" : "Another example is ∆((G; 〈[0, 1]; [0, 2]〉)) = 2.",
      "startOffset" : 34,
      "endOffset" : 40
    }, {
      "referenceID" : 12,
      "context" : "Δ-measure is related to the work of margin-closeness of an itemset [13].",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 4,
      "context" : "The approach proposed in this paper is based on projections introduced for reducing complexity of computing pattern lattices [5].",
      "startOffset" : 125,
      "endOffset" : 128
    }, {
      "referenceID" : 0,
      "context" : "The fixed set of this projection consists of {[0, 1], 1}× {0, 2, [0, 2]}, i.",
      "startOffset" : 46,
      "endOffset" : 52
    }, {
      "referenceID" : 1,
      "context" : "The fixed set of this projection consists of {[0, 1], 1}× {0, 2, [0, 2]}, i.",
      "startOffset" : 65,
      "endOffset" : 71
    }, {
      "referenceID" : 0,
      "context" : "Let us find the projection of (g2) ⋄ = 〈0; [1, 2]〉 in a component-wise way: ψm1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; ψm2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.",
      "startOffset" : 43,
      "endOffset" : 49
    }, {
      "referenceID" : 1,
      "context" : "Let us find the projection of (g2) ⋄ = 〈0; [1, 2]〉 in a component-wise way: ψm1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; ψm2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.",
      "startOffset" : 43,
      "endOffset" : 49
    }, {
      "referenceID" : 0,
      "context" : "Let us find the projection of (g2) ⋄ = 〈0; [1, 2]〉 in a component-wise way: ψm1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; ψm2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.",
      "startOffset" : 96,
      "endOffset" : 102
    }, {
      "referenceID" : 0,
      "context" : "Let us find the projection of (g2) ⋄ = 〈0; [1, 2]〉 in a component-wise way: ψm1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; ψm2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.",
      "startOffset" : 236,
      "endOffset" : 242
    }, {
      "referenceID" : 1,
      "context" : "Let us find the projection of (g2) ⋄ = 〈0; [1, 2]〉 in a component-wise way: ψm1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; ψm2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.",
      "startOffset" : 236,
      "endOffset" : 242
    }, {
      "referenceID" : 1,
      "context" : "Let us find the projection of (g2) ⋄ = 〈0; [1, 2]〉 in a component-wise way: ψm1[{0,1},{1}](0) = [0, 1], since 0 is allowed on the left endpoint of an interval but not allowed to be on the right endpoint of an interval; ψm2[{0,2},{0,2}]([1, 2]) = [0, 2] since 1 is not allowed on the left endpoint of an interval.",
      "startOffset" : 246,
      "endOffset" : 252
    }, {
      "referenceID" : 0,
      "context" : "ψm1[{0,1},{1}]m2[{0,2},{0,2}](〈0; [1, 2]〉) = 〈[0, 1]; [0, 2]〉 .",
      "startOffset" : 34,
      "endOffset" : 40
    }, {
      "referenceID" : 1,
      "context" : "ψm1[{0,1},{1}]m2[{0,2},{0,2}](〈0; [1, 2]〉) = 〈[0, 1]; [0, 2]〉 .",
      "startOffset" : 34,
      "endOffset" : 40
    }, {
      "referenceID" : 0,
      "context" : "ψm1[{0,1},{1}]m2[{0,2},{0,2}](〈0; [1, 2]〉) = 〈[0, 1]; [0, 2]〉 .",
      "startOffset" : 46,
      "endOffset" : 52
    }, {
      "referenceID" : 1,
      "context" : "ψm1[{0,1},{1}]m2[{0,2},{0,2}](〈0; [1, 2]〉) = 〈[0, 1]; [0, 2]〉 .",
      "startOffset" : 54,
      "endOffset" : 60
    }, {
      "referenceID" : 0,
      "context" : "(∅;⊤) (4; 〈[0, 1]; 2〉) (1; 〈[0, 1]; 0〉) (56; 〈1; [0, 2]〉) (123456; 〈[0, 1]; [0, 2]〉)",
      "startOffset" : 11,
      "endOffset" : 17
    }, {
      "referenceID" : 0,
      "context" : "(∅;⊤) (4; 〈[0, 1]; 2〉) (1; 〈[0, 1]; 0〉) (56; 〈1; [0, 2]〉) (123456; 〈[0, 1]; [0, 2]〉)",
      "startOffset" : 28,
      "endOffset" : 34
    }, {
      "referenceID" : 1,
      "context" : "(∅;⊤) (4; 〈[0, 1]; 2〉) (1; 〈[0, 1]; 0〉) (56; 〈1; [0, 2]〉) (123456; 〈[0, 1]; [0, 2]〉)",
      "startOffset" : 49,
      "endOffset" : 55
    }, {
      "referenceID" : 0,
      "context" : "(∅;⊤) (4; 〈[0, 1]; 2〉) (1; 〈[0, 1]; 0〉) (56; 〈1; [0, 2]〉) (123456; 〈[0, 1]; [0, 2]〉)",
      "startOffset" : 68,
      "endOffset" : 74
    }, {
      "referenceID" : 1,
      "context" : "(∅;⊤) (4; 〈[0, 1]; 2〉) (1; 〈[0, 1]; 0〉) (56; 〈1; [0, 2]〉) (123456; 〈[0, 1]; [0, 2]〉)",
      "startOffset" : 76,
      "endOffset" : 82
    }, {
      "referenceID" : 0,
      "context" : "pattern order and it allows for efficient generation of patterns with support larger than a threshold [1, 12, 14].",
      "startOffset" : 102,
      "endOffset" : 113
    }, {
      "referenceID" : 11,
      "context" : "pattern order and it allows for efficient generation of patterns with support larger than a threshold [1, 12, 14].",
      "startOffset" : 102,
      "endOffset" : 113
    }, {
      "referenceID" : 13,
      "context" : "pattern order and it allows for efficient generation of patterns with support larger than a threshold [1, 12, 14].",
      "startOffset" : 102,
      "endOffset" : 113
    }, {
      "referenceID" : 3,
      "context" : ", the cosine interest of an itemset, which is only locally antimonotonic [4].",
      "startOffset" : 73,
      "endOffset" : 76
    }, {
      "referenceID" : 1,
      "context" : "any projection [2].",
      "startOffset" : 15,
      "endOffset" : 18
    }, {
      "referenceID" : 16,
      "context" : "one can prove that robustness of closed patterns from [17] is also anti-monotonic w.",
      "startOffset" : 54,
      "endOffset" : 58
    }, {
      "referenceID" : 0,
      "context" : "This projection allows only for one pattern 〈[0, 1]; [0, 2]〉, i.",
      "startOffset" : 45,
      "endOffset" : 51
    }, {
      "referenceID" : 1,
      "context" : "This projection allows only for one pattern 〈[0, 1]; [0, 2]〉, i.",
      "startOffset" : 53,
      "endOffset" : 59
    }, {
      "referenceID" : 1,
      "context" : ", any possible interval of the first component and only one interval [0,2] for the second component.",
      "startOffset" : 69,
      "endOffset" : 74
    }, {
      "referenceID" : 13,
      "context" : "Closed frequent itemsets are widely used as a condensed representation of all frequent itemsets since [14].",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 4,
      "context" : "However, the extents of ψ(P) are extents of P [5].",
      "startOffset" : 46,
      "endOffset" : 49
    }, {
      "referenceID" : 4,
      "context" : "By properties of a projection, an extent of ψ(P) is an extent of P [5].",
      "startOffset" : 67,
      "endOffset" : 70
    }, {
      "referenceID" : 0,
      "context" : "At the beginning ψ0(DI) contains only one element corresponding to pattern extent 123456 (a short cut for {g1, g2, g3, g4, g5, g6}) with a description 〈[0, 1]; [0, 2]〉.",
      "startOffset" : 152,
      "endOffset" : 158
    }, {
      "referenceID" : 1,
      "context" : "At the beginning ψ0(DI) contains only one element corresponding to pattern extent 123456 (a short cut for {g1, g2, g3, g4, g5, g6}) with a description 〈[0, 1]; [0, 2]〉.",
      "startOffset" : 160,
      "endOffset" : 166
    }, {
      "referenceID" : 1,
      "context" : "Then, in ψ1(G, (DI ,⊓), δ) possible preimages of 123456 are patterns with descriptions 〈0; [0, 2]〉 and 〈1; [0, 2]〉 given by pattern extents 1234 and 56, respectively.",
      "startOffset" : 91,
      "endOffset" : 97
    }, {
      "referenceID" : 1,
      "context" : "Then, in ψ1(G, (DI ,⊓), δ) possible preimages of 123456 are patterns with descriptions 〈0; [0, 2]〉 and 〈1; [0, 2]〉 given by pattern extents 1234 and 56, respectively.",
      "startOffset" : 107,
      "endOffset" : 113
    }, {
      "referenceID" : 0,
      "context" : "The pattern extents 123456 and 56 have no preimages for the transition ψ1 → ψ2, while the pattern extent 1234 has two preimages with descriptions 〈0; [0, 1]〉 and 〈0; [1, 2]〉 for this projection, which correspond to pattern extents 1 and 234.",
      "startOffset" : 150,
      "endOffset" : 156
    }, {
      "referenceID" : 0,
      "context" : "The pattern extents 123456 and 56 have no preimages for the transition ψ1 → ψ2, while the pattern extent 1234 has two preimages with descriptions 〈0; [0, 1]〉 and 〈0; [1, 2]〉 for this projection, which correspond to pattern extents 1 and 234.",
      "startOffset" : 166,
      "endOffset" : 172
    }, {
      "referenceID" : 1,
      "context" : "The pattern extents 123456 and 56 have no preimages for the transition ψ1 → ψ2, while the pattern extent 1234 has two preimages with descriptions 〈0; [0, 1]〉 and 〈0; [1, 2]〉 for this projection, which correspond to pattern extents 1 and 234.",
      "startOffset" : 166,
      "endOffset" : 172
    }, {
      "referenceID" : 14,
      "context" : "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].",
      "startOffset" : 69,
      "endOffset" : 84
    }, {
      "referenceID" : 12,
      "context" : "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].",
      "startOffset" : 69,
      "endOffset" : 84
    }, {
      "referenceID" : 1,
      "context" : "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].",
      "startOffset" : 69,
      "endOffset" : 84
    }, {
      "referenceID" : 16,
      "context" : "The known approaches use postfiltering to mine such kind of patterns [15, 13, 2, 17].",
      "startOffset" : 69,
      "endOffset" : 84
    }, {
      "referenceID" : 7,
      "context" : "Recently it was also shown that it is more efficient to mine interval tuple data without binarization [8].",
      "startOffset" : 102,
      "endOffset" : 105
    } ],
    "year" : 2015,
    "abstractText" : "In pattern mining, the main challenge is the exponential explosion of the set of patterns. Typically, to solve this problem, a constraint for pattern selection is introduced. One of the first constraints proposed in pattern mining is support (frequency) of a pattern in a dataset. Frequency is an anti-monotonic function, i.e., given an infrequent pattern, all its superpatterns are not frequent. However, many other constraints for pattern selection are not (anti-)monotonic, which makes it difficult to generate patterns satisfying these constraints. In this paper we introduce the notion of projection-antimonotonicity and θ-Σοφια algorithm that allows efficient generation of the best patterns for some nonmonotonic constraints. In this paper we consider stability and Δ-measure, which are nonmonotonic constraints, and apply them to interval tuple datasets. In the experiments, we compute best interval tuple patterns w.r.t. these measures and show the advantage of our approach over postfiltering approaches.",
    "creator" : "LaTeX with hyperref package"
  }
}