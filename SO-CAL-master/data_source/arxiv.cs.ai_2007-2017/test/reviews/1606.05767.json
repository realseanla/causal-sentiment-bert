{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2016", "title": "On Reward Function for Survival", "abstract": "Obtaining a survival strategy (policy) is one of the fundamental problems of biological agents. In this paper, we generalize the formulation of previous research related to the survival of an agent and we formulate the survival problem as a maximization of the multi-step survival probability in future time steps. We introduce a method for converting the maximization of multi-step survival probability into a classical reinforcement learning problem. Using this conversion, the reward function (negative temporal cost function) is expressed as the log of the temporal survival probability. And we show that the objective function of the reinforcement learning in this sense is proportional to the variational lower bound of the original problem. Finally, We empirically demonstrate that the agent learns survival behavior by using the reward function introduced in this paper.", "histories": [["v1", "Sat, 18 Jun 2016 15:33:04 GMT  (693kb,D)", "https://arxiv.org/abs/1606.05767v1", "Joint 8th International Conference on Soft Computing and Intelligent Systems and 17th International Symposium on Advanced Intelligent Systems"], ["v2", "Sun, 24 Jul 2016 13:19:23 GMT  (693kb,D)", "http://arxiv.org/abs/1606.05767v2", "Joint 8th International Conference on Soft Computing and Intelligent Systems and 17th International Symposium on Advanced Intelligent Systems"]], "COMMENTS": "Joint 8th International Conference on Soft Computing and Intelligent Systems and 17th International Symposium on Advanced Intelligent Systems", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["naoto yoshida"], "accepted": false, "id": "1606.05767"}
