{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Mar-2017", "title": "MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation", "abstract": "In this paper, we present MidiNet, a deep convolutional neural network (CNN) based generative adversarial network (GAN) that is intended to provide a general, highly adaptive network structure for symbolic-domain music generation. The network takes random noise as input and generates a melody sequence one mea- sure (bar) after another. Moreover, it has a novel reflective CNN sub-model that allows us to guide the generation process by providing not only 1D but also 2D conditions. In our implementation, we used the intended chord of the current bar as a 1D condition to provide a harmonic context, and the melody generated for the preceding bar previously as a 2D condition to provide sequential information. The output of the network is a 16 by 128 matrix each time, representing the presence of each of the 128 MIDI notes in the generated melody sequence of that bar, with the smallest temporal unit being the sixteenth note. MidiNet can generate music of arbitrary number of bars, by concatenating these 16 by 128 matrices. The melody sequence can then be played back with a synthesizer. We provide example clips showing the effectiveness of MidiNet in generating harmonic music.", "histories": [["v1", "Fri, 31 Mar 2017 10:59:58 GMT  (719kb,D)", "http://arxiv.org/abs/1703.10847v1", "6 pages"], ["v2", "Tue, 18 Jul 2017 08:07:36 GMT  (2062kb,D)", "http://arxiv.org/abs/1703.10847v2", "8 pages, Accepted to ISMIR (International Society of Music Information Retrieval) Conference 2017"]], "COMMENTS": "6 pages", "reviews": [], "SUBJECTS": "cs.SD cs.AI", "authors": ["li-chia yang", "szu-yu chou", "yi-hsuan yang"], "accepted": false, "id": "1703.10847"}
