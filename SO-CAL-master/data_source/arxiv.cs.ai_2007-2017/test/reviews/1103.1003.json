{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Mar-2011", "title": "Teraflop-scale Incremental Machine Learning", "abstract": "We propose a long-term memory design for artificial general intelligence based on Solomonoff's incremental machine learning methods. We use R5RS Scheme and its standard library with a few omissions as the reference machine. We introduce a Levin Search variant based on Stochastic Context Free Grammar together with four synergistic update algorithms that use the same grammar as a guiding probability distribution of programs. The update algorithms include adjusting production probabilities, re-using previous solutions, learning programming idioms and discovery of frequent subprograms. Experiments with two training sequences demonstrate that our approach to incremental learning is effective.", "histories": [["v1", "Sat, 5 Mar 2011 03:41:30 GMT  (35kb,S)", "http://arxiv.org/abs/1103.1003v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["eray \\\"ozkural"], "accepted": false, "id": "1103.1003"}
