{
  "name" : "1206.3536.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Identifying Independence in Relational Models",
    "authors" : [ "Marc Maier", "David Jensen" ],
    "emails" : [ "maier@cs.umass.edu", "jensen@cs.umass.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "The rules of d -separation provide a framework for deriving conditional independence facts from model structure. However, this theory only applies to simple directed graphical models. We introduce relational d -separation, a theory for deriving conditional independence in relational models. We provide a sound, complete, and computationally efficient method for relational d -separation, and we present empirical results that demonstrate effectiveness."
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "The rules of d -separation are the foundation for algorithmic derivation of the conditional independence facts implied by the structure of a directed graphical model (Geiger et al., 1990). Accurate reasoning about such conditional independence facts is the basis for constraint-based algorithms, such as PC, FCI, and MMHC, that are widely used to learn the structure of Bayesian networks (Spirtes et al., 2000; Tsamardinos et al., 2006).\nBayesian networks assume that data instances are independent and identically distributed, but many real-world systems are characterized by interacting heterogeneous entities. Over the past 15 years, researchers have devised more expressive classes of directed graphical models, such as probabilistic relational models (PRMs), that remove this assumption (Getoor and Taskar, 2007). Many practical applications have benefited from learning and reasoning with these models. Examples include analysis of gene regulatory interactions (Segal et al., 2001), scholarly citations (Taskar et al., 2001), and biological cellular networks (Friedman, 2004).\nFORMSEDITS\nUSER\nExpertise\nPAGE\nQuality\nCATEGORY\nViews\n(a) Example relational model of Wikipedia consisting of users editing pages, grouped by categories. Expertise of editors causes page quality, which in turn influences the number of views a category receives. (Edges in relational models have specifications—see body of text for details.)\nRoger Expertise\nFootball Quality\nSports Views\nSally Expertise\nBaseball Quality\nEDITS\nEDITS\nED ITS\nFOR MS\nFORMS\n(b) Example fragment of a ground graph. The quality of the Football page is influenced by the expertise of both Roger and Sally. The views of the Sports category is caused by the quality of both pages in the category.\nFigure 1: An example relational model and small portion of a ground graph for the Wikipedia domain.\nIn this paper, we show that d -separation does not correctly produce conditional independence facts when applied directly to relational models. We introduce an alternative representation that enables an algorithm for deriving conditional independence facts from relational models. We show that this algorithm is sound, complete, and computationally efficient, and we provide an empirical demonstration of the effectiveness of our approach across synthetic causal structures of relational domains."
    }, {
      "heading" : "2 EXAMPLE",
      "text" : "Consider the common problem among social media developers of attracting and retaining readers. For example, an administrator of Wikipedia may be interested in increasing the visibility of certain categories of articles. The administrator may believe\nar X\niv :1\n20 6.\n35 36\nv1 [\ncs .A\nI] 1\n5 Ju\nn 20\nthat Wikipedia operates under the model depicted in Figure 1(a) and needs to verify the model structure in order to effectively determine next actions.\nNäıvely applying d -separation to the model in Figure 1(a) suggests that user expertise in writing Wikipedia pages is conditionally independent of category views given the quality of edited pages. However, as we show below, d -separation does not apply directly to relational models. A necessary precondition for inference is to apply a model to a data instantiation. This process yields a ground graph, to which d -separation can be applied. For a Bayesian network, a ground graph consists of replicates of the model structure for each data instance. In contrast, a relational model defines a template for how dependencies apply to a data instantiation, resulting in a ground graph with varying structure.\nFigure 1(b) shows a small fragment of a ground graph for the relational model in Figure 1(a). This ground graph illustrates that simply conditioning on page quality can activate a path through the expertise of other users who edit the same pages—we call this a relational d-connecting path. Checking d - separation on the ground graph indicates that to d - separate user expertise from category views, we must not only condition on the quality of edited pages, but also on the expertise of other users who edit those pages (e.g., Roger.Expertise ⊥⊥ Sports.Views | {Football.Quality, Sally.Expertise}).\nThis example highlights important concepts that drive our formalization and solution for relational d - separation. Since the conditional independence facts derived from d -separation hold for all faithful distributions a model can represent, the implications of relational d -separation should analogously hold for all faithful distributions of variables for the space of all possible ground graphs. It is simple to show that d - separation holds for any ground graph of a Bayesian network—every ground graph is a set of independent, identical instances of the model. However, relational models are templates for ground graphs that vary by the relational structure of the underlying data (e.g., different pages are edited by varying numbers of users). Furthermore, d -separation only applies directly to the ground graphs of relational models, but the all-ground-graphs semantics prohibits reasoning about a single model instantiation. Therefore, relational d -separation queries must be answered without respect to ground graphs. Additionally, the example illustrates how relational dependencies can exhibit d -connecting paths that are only manifest in ground graphs, not the model repre-\nsentation. Below, we describe a new representation that can be used to reason about d -separation for relational models."
    }, {
      "heading" : "3 RELATIONAL DATA",
      "text" : "In this section, we formally define the concepts of relational data and models that provide the basis for the theoretical framework for relational d - separation. A relational schema is a top-level description of what data exist in a particular domain. Specifically (adapted from Heckerman et al. (2007)):\nDefinition 1 (Relational schema) A relational schema S = (E ,R,A) consists of a set of entity classes E = {E1, . . . , Em}; relationship classes R = {R1, . . . , Rn}, where each Ri = {E1, . . . , Ej} with Ej ∈ E ; attribute classes A(I) for each item I ∈ E ∪ R; and cardinality function card(R,E) = {one, many} for each R ∈ R and each E ∈ R.\nThe schema for the example in Figure 1 consists of entities E = {User, Page, Category}; relationships R = {Edits, Forms}, where Edits = {User, Page}, Forms = {Page, Category} and all cardinalities are many (e.g., card(Edits,User) = many); and attributes A(User) = {Expertise}, A(Page) = {Quality}, and A(Category) = {Views}. A schema is a template for the underlying skeleton, a specific instantiation of entities and relationships. Specifically (adapted from Heckerman et al. (2007)):\nDefinition 2 (Relational skeleton) A relational skeleton σER is an instantiation of entity sets σ(E) for each E ∈ E and relationship sets σ(R) for each R ∈ R, adhering to its cardinality constraints. Let r ∈ σ(R) where R = {E1, . . . , Ej} be denoted as r(e1, . . . , ej) where ei ∈ σ(Ei) and Ei ∈ E .\nAn example skeleton (in gray) can be seen underlying the ground graph of Figure 1(b).\nIn order to specify a model over a relational domain, we must define a space of possible variables and dependencies. For relational data, not only do we consider intrinsic entity and relationship attributes, but also variables reachable via the relational skeleton.\nDefinition 3 (Relational path) A relational path [I1, . . . , Ik] for relational schema S is an alternating sequence of entity and relationship classes I1, . . . , Ik ∈ E ∪ R such that for all j > 1 (1) if Ij ∈ E , then Ij−1 ∈ R with Ij ∈ Ij−1, (2) if\nIj ∈ R, then Ij−1 ∈ E with Ij−1 ∈ Ij , and (3) for each ordered triple 〈Ij−1, Ij , Ij+1〉 in [I1, . . . , Ik], if Ij ∈ R, then Ij−1 6= Ij+1 and if Ij ∈ E , then either Ij−1 6= Ij+1 or ∃Ie ∈ Ij−1 such that Ij 6= Ie and card(Ij−1, Ie) = many. I1 is called the base item, or perspective, of the relational path.\nThis definition generalizes the notion of “slot chains” from the PRM framework (Getoor et al., 2007) by including cardinality constraints. Since relational paths may become arbitrarily long, we limit the path length by a hop threshold. Items reachable by a relational path are defined by:\nDefinition 4 (Terminal set) For any skeleton σER and any i1 ∈ σ(I1), a terminal set P |i1 for relational path P = [I1, . . . , Ik] can be defined inductively as\n[I1]|i1 = {i1} [I1, . . . , Ik−1, Ik]|i1 =⋃\nik−1∈[I1,...,Ik−1]|i1 {ik | ((ik−1 ∈ ik if Ik ∈ R)\n∨ (ik ∈ ik−1 if Ik ∈ E)) ∧ ik /∈ [I1, . . . , Ij ]|i1 for j = 1 to k− 1}\nA terminal set consists of reachable instances of class Ik, the terminal item on the path. To produce a terminal set, traverse the skeleton by beginning at a single base item i1 ∈ σ(I1), follow instances of the items in the relational path, and reach a target set of Ik instances. The definition implies a “bridge burning” semantics under which no instantiated items are revisited. This enforces, for example, that Roger is not included in the set of other editors of the Football page in the terminal set [User, Edits, Page, Edits, User]|Roger = {Sally}.\nIt is common for terminal sets of two relational paths originating at the same base item instance to overlap. If two relational paths with the same base and target items diverge in the middle of the path, then for some skeleton, their terminal sets will intersect.\nLemma 1 For any schema S and any two relational paths P1 = [I1, . . . , Im, . . . , Ik] and P2 = [I1, . . . , In, . . . , Ik] with Im 6= In, there exists a skeleton σER such that P1|i1 ∩ P2|i1 6= ∅ for some i1 ∈ σ(I1).\nProof. Proof by construction. Let S be an arbitrary schema with two arbitrary relational paths P1 = [I1, . . . , Im, . . . , Ik] and P2 = [I1, . . . , In, . . . , Ik] where Im 6= In. Construct a skeleton σER with the following procedure: First, for entity classes (skipping relationship classes), simultaneously traverse P1 and P2 from I1 until the\npaths diverge. For each Ij ∈ E reached, add a unique ij to σ(Ij). Repeat, traversing P1 and P2 backwards from Ik until they diverge. Then, for both P1 and P2, add unique instances for items in the divergent subpaths. Repeat for relationship classes. For each Ij ∈ R reached, add a unique relationship instance connecting the entity instances created above that follow P1 and P2 and add unique instances for entity classes not on P1 and P2. This process constructs an admissible skeleton—all instances are unique and assumes no cardinality constraints aside from those required by Definition 3. By construction, ∃i1 ∈ σ(I1) such that P1|i1 ∩ P2|i1 = {ik} 6= ∅.\nFor the example skeleton in Figure 1(b), [User, Edits, Page, Edits, User, Edits, Page]|Roger = {Baseball} = [User, Edits, Page, Forms, Category, Forms, Page]|Roger. As we show below, the intersection is crucial for relational d -separation because individual variable instances can belong to multiple relational variables, and we must consider all paths of dependence among them. Given the definition for relational paths, it is simple to define relational variables and their instances.\nDefinition 5 (Relational variable) A relational variable [I1, . . . , Ik].V for relational schema S consists of a relational path [I1, . . . , Ik] and an attribute class V ∈ A(Ik).\nDefinition 6 (Relational variable instance) For any skeleton σER and any i1 ∈ σ(I1), a relational variable instance P.V |i1 for relational variable P.V = [I1, . . . , Ik].V is the set of variables {ik.V | V ∈ A(ik) ∧ ik ∈ P |i1}.\nDefinition 4 implies that relational variable instances are frequently sets of more than one value, and Lemma 1 provides the conditions under which we can expect overlap to occur. Given the formal definitions for relational variables, we can now define relational dependencies.\nDefinition 7 (Relational dependency) A relational dependency D = [I1, . . . , Ik].V1 → [I1].V2 consists of two relational variables with a common base item and corresponds to a directed probabilistic dependence from [I1, . . . , Ik].V1 to [I1].V2.\nThe example dependencies displayed in Figure 1(a) can be specified as [Page, Edits, User].Expertise → [Page].Quality and [Category, Forms, Page].Quality → [Category].V iews. Depending on the context, V1 and V2 can be referred to as treatment and outcome, cause and effect, or parent\nand child. Without loss of generality, Definition 7 provides a canonical specification for dependencies, with the outcome relational variable restricted to singleton paths, thus ensuring that outcomes consist of a single value. Relational models are simply a collection of relational dependencies, defined as:\nDefinition 8 (Relational model) The structure of a relational model M = (S,D) consists of a relational schema S paired with a set of relational dependencies D defined over S.\nThis definition is consistent with and expressible as DAPER models (Heckerman et al., 2007). A parameterized relational model would also contain local probability distributions for every attribute class A(I) for each I ∈ E ∪ R in order to represent a joint probability distribution. Note that without existence variables on entity and relationship classes, relational models are not truly generative as the skeleton must be generated prior to the attributes. We can choose simple processes for generating skeletons, allowing us to focus on relational models of attributes and leaving structural causes and effects as future work. Just as the relational schema is a template for skeletons, a relational model can be viewed as a template for ground graphs (i.e., how dependencies apply to skeletons).\nDefinition 9 (Ground graph) The ground graph GGMσER = (V,E) for relational model M = (S,D) and skeleton σER is a directed graph with nodes V = A(σER) = {i.X | I ∈ E ∪R∧X ∈ A(I) ∧ i ∈ σ(I)} and edges E = {ik.Y → ij .X | ik.Y, ij .X ∈ V ∧ ik.Y ∈ [Ij , . . . , Ik].Y |ij ∧ [Ij , . . . , Ik].Y → [Ij ].X ∈ D}.\nBy Lemma 1 and Definition 9, we can see that the same canonical dependency involving ik.Y and ij .X can connect many other relational variables for which ik and ij are elements. These additional, implied dependencies form the crux of the challenge of identifying independence in relational models, a solution for which is presented in the following section."
    }, {
      "heading" : "4 RELATIONAL D-SEPARATION",
      "text" : "Conditional independence can be entailed by the rules of d -separation, but only for simple directed acyclic graphs. For Bayesian networks, the model structure corresponds exactly to ground graphs. In contrast, relational models are templates for ground graphs that vary with underlying skeletons. Since conditional independence facts must hold across all model instantiations, reasoning about d -separation for relational models is inherently more challenging.\nDefinition 10 (Relational d-separation) Let X, Y, and Z be three sets of distinct relational variables for perspective B ∈ E ∪ R defined over relational schema S. Then, for relational model M, X and Y are d -separated by Z if and only if, for any skeleton σER, X|b and Y|b are d -separated by Z|b in ground graph GGMσER for all b ∈ σ(B).\nIn other words, for X and Y to be d -separated by Z for relational model M, d -separation must hold for all instantiations of those relational variables for any possible skeleton. This is a conservative definition, but it is consistent with the semantics of d -separation on Bayesian networks—it only guarantees independence.\nAnswering relational d -separation queries is challenging for the following reasons:\nAll-ground-graphs semantics: Although possible to verify d -separation on a single ground graph, the conclusion may not generalize (as required by definition) and ground graphs can be arbitrarily large. Implicitly, d -separation on Bayesian networks makes the same claim, but all ground graphs are identical to the structure of the model.\nRelational models are templates: Relational models may be directed acyclic graphs, but they are templates for ground graphs. The rules of d - separation do not directly apply to relational models, only to ground graphs.\nRelational variables may overlap: Relational variables frequently consist of sets of values that may overlap, as described by Lemma 1. Consequently, there exist non-intuitive implications of dependencies that must be accounted for, such as relational d -connecting paths (see the example in Figure 1).\nRelational dependency specification: Relational models are defined with respect to canonical dependencies, each specified from a single perspective. However, variables in a ground graph may belong to multiple relational variable instances, each defined from different perspectives. Thus, to determine which dependencies exist between arbitrary relational variables, we need methods to translate and extend the canonically specified dependencies."
    }, {
      "heading" : "4.1 SOLUTION",
      "text" : "The definition of relational d -separation and its challenges suggests a solution that abstracts over all possible ground graphs and explicitly represents the overlap between pairs of relational variables. We developed a new representation, called an abstract\nground graph, that captures all dependencies among relational variables for any ground graph, using knowledge of only the schema and the model.\nDefinition 11 (Abstract ground graph) An abstract ground graph AGGMBh = (V,E) for relational model M = (S,D), perspective B ∈ E ∪ R, and hop threshold h ∈ N0 is an abstraction of the dependencies D for all possible ground graphs GGMσER of M on arbitrary skeletons σER.\nThe set of nodes in AGGMBh, V = RV ∪ IV , is the union of all relational variables RV ={\n[B, . . . , Ij ].V | length([B, . . . , Ij ]) ≤ h + 1 }\nand the intersections between pairs of relational variables that could intersect IV = { X∩Y |X,Y ∈ RV ∧X = [B, . . . , Ik, . . . , Ij ].V ∧ Y = [B, . . . , Il, . . . , Ij ].V ∧ Ik 6= Il } .\nThe set of edges in AGGMBh is E = RV E ∪ IV E, where RV E ⊂ RV × RV and IV E ⊂ IV × RV ∪ RV × IV . RV E is the set of edges between pairs of relational variables: RV E = { [B, . . . , Ik].V1 → [B, . . . , Ij ].V2 | [Ij , . . . , Ik].V1 → [Ij ].V2 ∈ D ∧ [B, . . . , Ik] ∈ extend([B, . . . , Ij ], [Ij , . . . , Ik]) } .\nIV E is the set of edges inherited by both relational variable sources of every intersection variable: IV E = { X → [B, . . . , Ij ].V2 | X = P1.V1 ∩ P2.V1 ∈ IV ∧ (P1.V 1 → [B, . . . , Ij ].V2 ∈ RV E ∨ P2.V1 → [B, . . . , Ij ].V2 ∈ RV E) } ∪ { [B, . . . , Ij ].V1 → X | X = P1.V2 ∩ P2.V2 ∈ IV ∧ ([B, . . . , Ij ].V1 → P1.V 1 ∈ RV E ∨ [B, . . . , Ij ].V1 → P2.V1 ∈ RV E) } .\nThe extend method is defined below. Essentially, an abstract ground graph for relational model M, perspective B ∈ E ∪R, and hop threshold h follows three simple steps: (1) add a node for all relational variables limited by h; (2) add edges for every direct cause of every relational variable; and (3) for each pair of intersecting relational variables, add a new “intersection” node that inherits the direct causes and effects from both of its sources. Then, answer queries of the form “Are X and Y d -separated by Z” by (1) augmenting X, Y, and Z with their corresponding intersection variables and (2) using the rules of d -separation on the abstract ground graph for the common perspective of the relational variables in X, Y, and Z.\nFigure 2 shows the abstract ground graph for the Wikipedia example from the User perspective with hop threshold h = 6. The abstract ground graph illustrates why it is necessary to condition on both edited page quality ([User, Edits, Page].Quality) and the expertise of other users edit-\ning the same pages ([User, Edits, Page, Edits, User].Expertise) in order to d -separate individual user expertise ([User].Expertise) from the number of category views of edited pages ([User, Edits, Page, Forms, Category].Views).\nUsing the algorithm devised by Geiger et al. (1990), relational d -separation queries can be answered in O(|E|) time with respect to the number of edges in the abstract ground graph. In practice, the size of an abstract ground graph depends on the relational schema (i.e., number of entities, relationships, cardinalities, and attributes), as well as the hop threshold limiting the length of relational paths. For the example in Figure 2, the abstract ground graph has 7 nodes and 7 edges (including 1 intersection node with 2 edges); for h = 8, it would have 15 nodes and 25 edges (including 5 intersection nodes with 16 edges). Furthermore, abstract ground graphs are invariant to the size of ground graphs, even though ground graphs can be arbitrarily large (i.e., relational databases have no maximum size).\nNext, we formally define the method for translating canonically specified dependencies to dependencies between arbitrary relational variables.\nDefinition 12 (Extending relational paths) Let Porig = [I1, . . . , Ij ] and Pext = [Ij , . . . , Ik] be two relational paths for schema S. The following three functions extend Porig with Pext: extend(Porig, Pext) = { truncate(concat(Porig[0 : length(Porig) − i + 1], Pext[i : length(Pext)])) | i ∈ pivots(reverse(Porig), Pext) } ;\npivots(P1, P2) = {i | P1[0 : i] = P2[0 : i]};\ntruncate(P ) = if ∃〈Ij−1, Ij , Ij+1〉 ∈ P (Ij ∈ R ∧ Ij−1 = Ij+1) ∨ (Ij ∈ E ∧ Ij−1 = Ij+1 ∧ ∀Ie ∈ Ij−1 Ij 6= Ie ∧ card(Ij−1, Ie) = one), then truncate(P − [Ij , Ij+1]); else P ;\nwhere concat, length, reverse, and [i : j] inclusiveexclusive sublist are standard functions of lists.\nFor example, extend([User, Edits, Page], [Page, Edits, User]) = {[User, Edits, Page, Edits, User]} and truncate([User, Edits, User]) = [User]. Truncating a relational path preserves the set of reachable instances, removing only redundant items along the path. For the following lemma, we define candidate relational paths as those produced internally to the extend method.\nLemma 2 For any skeleton σER and candidate relational path P = [I1, . . . , Ik], ∀i1 ∈ σ(I1) P |i1 = truncate(P )|i1 .\nProof. Let σER be an arbitrary skeleton, let P = [I1, . . . , Ik] be an arbitrary relational path, and let i1 ∈ σ(I1) be arbitrary. There are three cases:\n(1) P = truncate(P ). Then, P |i1 = truncate(P )|i1 .\n(2) Let 〈I1, I2, I3〉 be an ordered triple in P with I2 ∈ R and I1 = I3. Then, [I1, I2, I3] = [I1, I2, I1] and, by definition,\n⋃ i2∈[I1,I2]|i1\n[I2, I1]|i2 = {i1}. So, [I1, I2, I1]|i1 = ∅ = [I1, I2, I3]|i1 because instances cannot be revisited. Removing [I2, I3] from P does not change which instances are reached. So, P |i1 = truncate(P )|i1 .\n(3) Let 〈I1, I2, I3〉 be an ordered triple in P with I2 ∈ E , I1 = I3, and ∀Ie ∈ I1 card(I1, Ie) = one if Ie 6= I2. Then, for all i2 ∈ σ(I2) there is at most one i1 with i2 ∈ i1. So, [I1, I2, I3] = [I1, I2, I1] and, by definition,\n⋃ i2∈[I1,I2]|i1\n[I2, I1]|i2 = {i1}. So, [I1, I2, I1]|i1 = ∅ = [I1, I2, I3]|i1 and P |i1 = truncate(P )|i1 as in case (2).\nThis method for extending relational paths invariably produces a set of reachable items that are also reachable by the two original paths.\nLemma 3 For any skeleton σER and relational paths Porig = [I1, . . . , Ij ] and Pext = [Ij , . . . , Ik] with P = extend(Porig, Pext), ∀i1 ∈ σ(I1) ∀P ∈ P ∀ik ∈ P |i1 ∃ij ∈ Porig|i1 such that ik ∈ Pext|ij .\nProof. Proof by contradiction. Let σER be an arbitrary skeleton, let i1 ∈ σ(I1) be arbitrary, and let ik ∈ P |i1 be arbitrary for some P ∈ P. Assume that ∀ij ∈ Porig|i1 ik /∈ Pext|ij . Let c ∈ pivots(reverse(Porig), Pext) such that P = truncate(concat(Porig[0 : length(Porig) − c + 1], Pext[c : length(Pext)])). By Lemma 2, we can ignore truncation. There are two subcases: (a) c = 1. Then, P = [I1, . . . , Ij , . . . , Ik], where ik is reached by traversing σER from i1 via some ij to ik. But the path from i1 to ij implies that ij ∈ [I1, . . . , Ij ]|i1 = Porig|i1 , and the path from ij to ik\nimplies that ik ∈ [Ij , . . . , Ik]|ij = Pext|ij . So, there must exist an ij ∈ Porig|i1 such that ik ∈ Pext|ij . (b) c > 1. Then, P = [I1, . . . , Im, . . . , Ik], where ik is reached by traversing σER from i1 via some im to ik. The path from i1 to im implies that im ∈ [I1, . . . , Im]|i1 = Porig[0 : length(Porig) − c + 1]|i1 , and the path from im to ik implies that ik ∈ [Im, . . . , Ik]|im = Pext[c − 1 : length(Pext)]|im . But ∃ij ∈ [Im, . . . , Ij ]|im = Porig[length(Porig)− c : length(Porig)]|im with im ∈ [Ij , . . . , Im]|ij = Pext[0 : c+ 1]|ij . So, ik ∈ [Ij , . . . , Im, . . . , Ik]|ij = Pext|ij .\nBecause the set of relational paths produced by extend yields a subset of the items reachable via both paths, it is necessary to consider the instances not reached. There exists an alternative relational path P ′orig that intersects with Porig that, when using extend, catches the remaining instances.\nLemma 4 For any skeleton σER and two relational paths Porig = [I1, . . . , Ij ] and Pext = [Ij , . . . , Ik] with P = extend(Porig, Pext), ∀i1 ∈ σ(I1) ∀ij ∈ Porig|i1 ∀ik ∈ Pext|ij if ∀P ∈ P ik /∈ P |i1 , then ∃P ′orig such that ij ∈ Porig|i1 ∩ P ′orig|i1 and ik ∈ P ′|i1 for some P ′ ∈ extend(P ′orig, Pext).\nProof. Let σER be an arbitrary skeleton, and let i1 ∈ σ(I1), ij ∈ Porig|i1 , and ik ∈ Pext|ij be arbitrary instances such that ik /∈ P |i1 for any P ∈ P. Since there exists no pivot that yields a common subsequence in Porig and Pext that reaches ik, there must be paths in the skeleton from i1 to ij via im and ij to ik via im such that the traversals from im to ij is via some il and ij to im is via some in, where il 6= in. So, Porig = [I1, . . . , Im, . . . , Il, . . . , Ij ] and Pext = [Ij , . . . , In, . . . , Im, . . . , Ik] with Il 6= In. Let P ′orig = [I1, . . . , Im, . . . , In, . . . , Ij ], which captures the traversal from i1 to im to in to ij . So, ij ∈ Porig|i1 ∩ P ′orig|i1 . Let P ′ = [I1, . . . , Im, . . . , Ik] ∈ extend(P ′orig, Pext) with pivot at Im. Then, ik ∈ P ′|i1 ."
    }, {
      "heading" : "4.2 PROOF OF CORRECTNESS",
      "text" : "The correctness of our approach to relational d - separation relies on several facts: (1) d -separation is valid for directed acyclic graphs (DAGs); (2) ground graphs are DAGs; and (3) abstract ground graphs are DAGs and represent all edges in all possible ground graphs. It would follow that d -separation on abstract ground graphs, augmented by intersection variables, holds for all ground graphs. Using the previous definitions and lemmas, the following sequence of results proves the correctness of our approach to identifying independence in relational models.\nTheorem 1 The rules of d -separation are sound and complete for directed acyclic graphs.\nProof. Due to Verma and Pearl (1988) for soundness and Geiger and Pearl (1988) for completeness.\nLemma 5 For any acyclic relational modelM and skeleton σER, the ground graph GGMσER is a directed acyclic graph.\nProof. Due to both Heckerman et al. (2007) for DAPER models and Getoor (2001) for PRMs.\nTheorem 2 For any acyclic relational model M, perspective B ∈ E ∪ R, and hop threshold h ∈ N0, AGGMBh abstracts GGMσER for all skeletons σER.\nProof. Let M = (S,D) be an arbitrary acyclic relational model, let B ∈ E ∪ R be arbitrary, and let h ∈ N0 be an arbitrary hop threshold. Assume that all relational paths in the proof have length less than h+2; otherwise, reject the path by assumption that dependence does not travel farther than h hops. There are two facts to prove that AGGMBh is a valid abstraction of GGMσER for all skeletons σER:\n(1) Every edge in AGGMBh corresponds to an edge in GGMσER for some σER. There are three subcases, one for each edge type in an abstract ground graph:\n(a) Let [B, . . . , Ik].V1 → [B, . . . , Ij ].V2 ∈ RV E be arbitrary. Assume by contradiction that ∀b ∈ σ(B) ∀ik ∈ [B, . . . , Ik]|b ∀ij ∈ [B, . . . , Ij ]|b ik.V1 → ij .V2 /∈ GGMσER for any skeleton σER. By Definition 11, [Ij , . . . , Ik].V1 → [Ij ].V2 ∈ D and [B, . . . , Ik] ∈ extend([B, . . . , Ij ], [Ij , . . . , Ik]). So, by Definition 9, ∀ij ∈ σ(Ij) ∀ik ∈ [Ij , . . . , Ik]|ij ik.V1 → ij .V2 ∈ GGMσER for any skeleton σER. Let σER be an arbitrary skeleton, and let b ∈ σ(B) be arbitrary. By Lemma 3, ∀ik ∈ [B, . . . , Ik]|b ∃ij ∈ [B, . . . , Ij ]|b such that ik ∈ [Ij , . . . , Ik]|ij . So, ∀b ∈ σ(B) ∀ik ∈ [B, . . . , Ik]|b ∃ij ∈ [B, . . . , Ij ]|b such that ik.V1 → ij .V2 ∈ GGMσER for any skeleton σER.\n(b) Let P1.V1 ∩ P2.V1 → [B, . . . , Ij ].V 2 ∈ IV E be arbitrary, where P1 = [B, . . . , Im, . . . , Ik] and P2 = [B, . . . , In, . . . , Ik] with Im 6= In. By Lemma 1, there exists a skeleton σER such that P1|b ∩ P2|b 6= ∅ for some b ∈ σ(B). Let ik ∈ P1|b ∩ P2|b for such a b ∈ σ(B) for σER. Assume by contradiction that ∀ij ∈ [B, . . . , Ij ]|b ik.V1 → ij .V2 /∈ GGMσER . By Definition 11, either P1.V1 → [B, . . . , Ij ].V2 ∈ RV E or P2.V1 → [B, . . . , Ij ].V2 ∈ RV E. Then, as shown in case (a), ∃ij ∈ [B, . . . , Ij ]|b such that ik.V1 → ij .V2 ∈ GGMσER .\n(c) Let [B, . . . , Ik].V1 → P1.V2 ∩ P2.V2 ∈ IV E be\narbitrary, where P1 = [B, . . . , Im, . . . , Ij ] and P2 = [B, . . . , In, . . . , Ij ] with Im 6= In. The proof follows case (b) to show that ∀ik ∈ [B, . . . , Ik]|b∃ij ∈ P1.V2∩ P2.V2|b such that ik.V1 → ij .V2 ∈ GGMσER for some skeleton σER and b ∈ σ(B) for which P1|b∩P2|b 6= ∅.\n(2) For any skeleton σER, every edge in GGMσER is represented by some edge in AGGMBh. Let σER be an arbitrary skeleton, and let ik.V1 → ij .V2 ∈ GGMσER be an arbitrary edge drawn from [Ij , . . . , Ik].V1 → [Ij ].V2 ∈ D where ∃b ∈ σ(B) such that Pk.V1 = {Pk.V1 | ik.V1 ∈ Pk.V1|b ∧ Pk.V1 ∈ AGGMBh} 6= ∅ and Pj.V2 = {Pj .V2 | ij .V2 ∈ Pj .V2|b ∧ Pj .V2 ∈ AGGMBh} 6= ∅. Then, ∀Pk.V1 ∈ Pk.V1 ∀Pj .V2 ∈ Pj.V2 either (a) Pk.V1 → Pj .V2 ∈ AGGMBh, (b) Pk.V1 ∩ P ′k.V1 → Pj .V2 ∈ AGGMBh, where P ′k.V1 ∈ Pk.V1, or (c) Pk.V1 → Pj .V2 ∩ P ′j .V2 ∈ AGGMBh, where P ′j .V2 ∈ Pj.V2. Let Pk.V1 ∈ Pk.V1, Pj .V2 ∈ Pj.V2 be arbitrary.\n(a) If Pk ∈ extend(Pj , [Ij , . . . , Ik]), then Pk.V1 → Pj .V2 ∈ AGGMBh by Definition 11.\n(b) If Pk /∈ extend(Pj , [Ij , . . . , Ik]), but ∃P ′k ∈ extend(Pj , [Ij , . . . , Ik]) such that ik ∈ P ′k|b, then P ′k.V1 ∈ Pk.V1, P ′k.V1 → Pj .V2 ∈ AGGMBh, and Pk.V1∩P ′k.V1 → Pj .V2 ∈ AGGMBh by Definition 11.\n(c) If ∀P ∈ extend(Pj , [Ij , . . . , Ik])ik /∈ P |b, then, by Lemma 4, ∃P ′j such that ij ∈ P ′j |b and Pk ∈ extend(P ′j , [Ij , . . . , Ik]). So, P ′j .V2 ∈ Pj.V2, Pk.V1 → P ′j .V2 ∈ AGGMBh, and Pk.V1 → P ′j .V2 ∩ Pj .V2 ∈ AGGMBh by Definition 11.\nTheorem 2 guarantees that, up to the hop threshold, abstract ground graphs capture all possible paths of dependence between any pair of variables in any ground graph. This also provides the reason why explicitly representing the intersection between pairs of relational variables is necessary and sufficient.\nCorollary 1 For any acyclic relational model M, perspective B ∈ E ∪ R, and hop threshold h ∈ N0, AGGMBh is a directed acylic graph.\nProof. Let M be an arbitrary acyclic relational model, let B ∈ E ∪ R be arbitrary, and let h ∈ N0 be arbitrary. Theorem 2 implies that every edge in AGGMBh corresponds to an edge in GGMσER for some σER. So a cycle in AGGMBh could only be the result of a cycle in GGMσER , but by Lemma 5, GGMσER is a directed acyclic graph.\nCorollary 1 ensures that d -separation applies directly to abstract ground graphs because they are DAGs. In the following theorem, let W̄ be the set of augmented nodes in an abstract ground graph—\nW̄ = W ∪ ⋃ W∈W{W ∩ W ′ | W ∩ W ′ ∈ AGGMBh}—for the set of relational variables W.\nTheorem 3 For any relational modelM and skeleton σER, X and Y are d -separated by Z onGGMσER if X̄ and Ȳ are d -separated by Z̄ on AGGMBh up to hop threshold h and the common perspective B.\nProof. LetM be an arbitrary relational model, let σER be an arbitrary skeleton, and let X̄ and Ȳ be d -separated given Z̄ on AGGMBh for three distinct arbitrary sets of relational variables from perspective B up to hop threshold h. Assume by contradiction that ∃b ∈ σ(B) such that X|b and Y|b are not d - separated by Z|b in GGMσER . Then, there exists a d -connecting path p from some x ∈ X|b to some y ∈ Y|b given all z ∈ Z|b. By Theorem 2, AGGMBh abstracts GGMσER , so all edges in GGMσER are captured by AGGMBh. So, path p must be represented from all nodes in {n | x ∈ n|b} to all nodes in {n | y ∈ n|b} in AGGMBh. If p is d -connecting in GGMσER , then it is d -connecting in AGGMBh, implying that X̄ and Ȳ are not d -separated by Z̄. So, X|b and Y|b must be d -separated by Z|b, and, by Definition 10, X and Y are d -separated by Z on GGMσER .\nTheorem 4 Relational d -separation is sound and complete for abstract ground graphs up to a specified hop threshold.\nProof. By Theorem 1, Corollary 1, and Theorem 3."
    }, {
      "heading" : "5 EXPERIMENTS",
      "text" : "To complement the theoretical results, we present a series of experiments on synthetic data. We implemented relational d -separation, as well as random generators of schemas, models, and queries."
    }, {
      "heading" : "5.1 ABSTRACT GROUND GRAPH SIZE",
      "text" : "Abstract ground graphs (AGGs) explicitly represent the intersection among relational variables and extend the canonically specified dependencies of relational models. Consequently, it is important to quantify how large an AGG can be (i.e., how many nodes and edges are created) and determine which factors influence its size. We ran 500 trials for each combination of number of entities (1–4), relationships (ranging from one less than the number of entities to pairwise relationships with randomly selected cardinalities), attributes for each entity and relationship (∼ Pois(1.0) + 1), and dependencies (1–10).\nWe discovered the following facts: (1) as the number of entities, relationships, attributes, and many cardinalities increases, the AGG grows with respect to both nodes and edges; (2) as the number of dependencies in the model increases, the number of edges increases, but the number of nodes is invariant; and (3) AGGs with relationship perspectives are larger than entity perspectives because more relational variables can be defined. Figure 3 depicts how AGG size (measured as the average number of nodes and edges) varies with respect to the number of many cardinalities in the schema and the number of dependencies in the model. Note that for a single entity, AGGs are equivalent to Bayesian networks."
    }, {
      "heading" : "5.2 MINIMAL SEPARATING SET SIZE",
      "text" : "Because AGGs can become large, one might expect that separating sets1 would also grow to impractical sizes. Fortunately, relational d -separation produces minimal separating sets that are empirically observed to be small. We ran 100 trials for each setting of number of entities (1–4), relationships (one less than the number of entities with randomly selected cardinalities), total number of attributes fixed to 10, and dependencies (1–10). For each relational model, we identified one minimal separating set for up to 100 randomly chosen pairs of conditionally independent relational variables. To discover a minimal separating set between relational variables X and Y, we modified Algorithm 4 devised by Tian et al. (1998) by starting with all parents of X̄ and Ȳ, augmented with the set of nodes they subsume in the AGG. Note that while the discovered separating sets are minimal (i.e., no proper subset is a separating set), they are not necessarily of minimum\n1If X and Y are d-separated given Z, then Z is a separating set for X and Y.\nsize. Figure 4 shows the frequency of separating set size as both the number of entities and dependencies vary. The experimental results indicate that separating set size is strongly influenced by model density, primarily because the number of potential d -connecting paths increases as the number of dependencies increases."
    }, {
      "heading" : "5.3 EMPIRICAL VALIDITY",
      "text" : "As a practical demonstration, we examine how the expectations of the relational d -separation theory match the results of statistical tests on actual data. We parameterize relational models using additive linear equations, the average aggregate for relational variables, and uniformly distributed error terms. If Y has no parents, then Y ∼ , and Y ∼ ∑\nX∈par(Y )\n0.9\n|par(Y )| avg(X) + .1 otherwise. To\ntest a query X ⊥⊥ Y | Z, we use linear regression, testing the coefficient of avg(X) in the equation Y ∼ β0+β1avg(X)+· · ·+βiavg(Zi) for each Zi ∈ Z.\nFor 100 trials, we randomly generated a schema and model for varying numbers of entities (1–4), relationships (one less than the number of entities), and attributes for each entity and relationship ∼ Pois(1.0) + 1. We then tested up to 100 true and false relational d -separation queries across 100 skeletons (i.e., instantiated relational databases) with 1,000 instances of each entity. For each query, we measured the average strength of effect (measured as the proportion of remaining variance) and proportion of trials for which each query was significant (α = 0.01 adjusted with Bonferroni correction with the number of queries per trial). Figure 5 depicts the distribution of the average strength of effect and proportion of significant trials across both true and false queries for varying numbers of entities.\nIn the vast majority of cases, relational d -separation is consistent with tests on actual data. For approximately 17,000 true queries, 0.8% have an average effect size greater than 0.01, 3.7% are significant in more than one trial, and only 0.7% cross both\nthresholds. Aside from Type I error, a small number of cases exhibit an interaction between aggregation and relational structure (i.e., the cardinality of relational variables). Simple linear regression does not account for these interaction effects, suggesting the need for more accurate statistical tests of conditional independence for relational data."
    }, {
      "heading" : "6 SUMMARY AND DIRECTIONS",
      "text" : "In this paper, we extend the theory of d -separation to models of relational data. We formally define relational d -separation and offer a sound, complete, and computationally efficient approach to deriving conditional independence facts from relational models. We also provide an empirical evaluation of relational d -separation on synthetic data.\nThe results of this paper imply flaws in the design and analysis of some real-world studies. If researchers of social or economic systems choose inappropriate data and model representations, then their analyses may omit important classes of dependencies (i.e., they may conclude causal dependence where conditional independence was not detected). Our work indicates that researchers should carefully consider how to represent their domains in order to accurately reason about conditional independence.\nOur experiments also suggest that more accurate tests of conditional independence for relational data need to be developed, specifically those that can address the interaction of relational structure and aggregation. Additionally, this work focuses on relational models of attributes; future work should con-\nsider models of relationship and entity existence. Finally, the theory could also be extended to incorporate functional or deterministic dependencies, as D-separation does for Bayesian networks."
    } ],
    "references" : [ {
      "title" : "Inferring cellular networks using probabilistic graphical models",
      "author" : [ "N. Friedman" ],
      "venue" : "Science, 303:799–805,",
      "citeRegEx" : "Friedman.,? \\Q2004\\E",
      "shortCiteRegEx" : "Friedman.",
      "year" : 2004
    }, {
      "title" : "On the logic of causal models",
      "author" : [ "D. Geiger", "J. Pearl" ],
      "venue" : "In Proceedings of the Fourth Annual Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Geiger and Pearl.,? \\Q1988\\E",
      "shortCiteRegEx" : "Geiger and Pearl.",
      "year" : 1988
    }, {
      "title" : "Identifying independence in",
      "author" : [ "D. Geiger", "T. Verma", "J. Pearl" ],
      "venue" : "Bayesian networks. Networks,",
      "citeRegEx" : "Geiger et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Geiger et al\\.",
      "year" : 1990
    }, {
      "title" : "Learning Statistical Models from Relational Data",
      "author" : [ "L. Getoor" ],
      "venue" : "PhD thesis, Stanford University,",
      "citeRegEx" : "Getoor.,? \\Q2001\\E",
      "shortCiteRegEx" : "Getoor.",
      "year" : 2001
    }, {
      "title" : "Introduction to Statistical Relational Learning",
      "author" : [ "L. Getoor", "B. Taskar", "editors" ],
      "venue" : null,
      "citeRegEx" : "Getoor et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Getoor et al\\.",
      "year" : 2007
    }, {
      "title" : "Probabilistic relational models",
      "author" : [ "L. Getoor", "N. Friedman", "D. Koller", "A. Pfeffer", "B. Taskar" ],
      "venue" : null,
      "citeRegEx" : "Getoor et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Getoor et al\\.",
      "year" : 2007
    }, {
      "title" : "Probabilistic entity-relationship models, PRMs, and plate models",
      "author" : [ "D. Heckerman", "C. Meek", "D. Koller" ],
      "venue" : null,
      "citeRegEx" : "Heckerman et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Heckerman et al\\.",
      "year" : 2007
    }, {
      "title" : "Rich probabilistic models for gene expression",
      "author" : [ "E. Segal", "B. Taskar", "A. Gasch", "N. Friedman", "D. Koller" ],
      "venue" : "Bioinformatics, 17(suppl 1):S243–S252,",
      "citeRegEx" : "Segal et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Segal et al\\.",
      "year" : 2001
    }, {
      "title" : "Causation, Prediction and Search",
      "author" : [ "P. Spirtes", "C. Glymour", "R. Scheines" ],
      "venue" : null,
      "citeRegEx" : "Spirtes et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Spirtes et al\\.",
      "year" : 2000
    }, {
      "title" : "Probabilistic classification and clustering in relational data",
      "author" : [ "B. Taskar", "E. Segal", "D. Koller" ],
      "venue" : "In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Taskar et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Taskar et al\\.",
      "year" : 2001
    }, {
      "title" : "Finding Minimal Dseparators",
      "author" : [ "J. Tian", "A. Paz", "J. Pearl" ],
      "venue" : "Technical Report R-254,",
      "citeRegEx" : "Tian et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Tian et al\\.",
      "year" : 1998
    }, {
      "title" : "The max-min hill-climbing Bayesian network structure learning algorithm",
      "author" : [ "I. Tsamardinos", "L.E. Brown", "C.F. Aliferis" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Tsamardinos et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Tsamardinos et al\\.",
      "year" : 2006
    }, {
      "title" : "Causal networks: Semantics and expressiveness",
      "author" : [ "T. Verma", "J. Pearl" ],
      "venue" : "In Proceedings of the Fourth Annual Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Verma and Pearl.,? \\Q1988\\E",
      "shortCiteRegEx" : "Verma and Pearl.",
      "year" : 1988
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "ical model (Geiger et al., 1990).",
      "startOffset" : 11,
      "endOffset" : 32
    }, {
      "referenceID" : 8,
      "context" : "Accurate reasoning about such conditional independence facts is the basis for constraint-based algorithms, such as PC, FCI, and MMHC, that are widely used to learn the structure of Bayesian networks (Spirtes et al., 2000; Tsamardinos et al., 2006).",
      "startOffset" : 199,
      "endOffset" : 247
    }, {
      "referenceID" : 11,
      "context" : "Accurate reasoning about such conditional independence facts is the basis for constraint-based algorithms, such as PC, FCI, and MMHC, that are widely used to learn the structure of Bayesian networks (Spirtes et al., 2000; Tsamardinos et al., 2006).",
      "startOffset" : 199,
      "endOffset" : 247
    }, {
      "referenceID" : 7,
      "context" : "Examples include analysis of gene regulatory interactions (Segal et al., 2001), scholarly citations (Taskar et al.",
      "startOffset" : 58,
      "endOffset" : 78
    }, {
      "referenceID" : 9,
      "context" : ", 2001), scholarly citations (Taskar et al., 2001), and biological cellular networks (Friedman, 2004).",
      "startOffset" : 29,
      "endOffset" : 50
    }, {
      "referenceID" : 0,
      "context" : ", 2001), and biological cellular networks (Friedman, 2004).",
      "startOffset" : 42,
      "endOffset" : 58
    }, {
      "referenceID" : 6,
      "context" : "Specifically (adapted from Heckerman et al. (2007)):",
      "startOffset" : 27,
      "endOffset" : 51
    }, {
      "referenceID" : 6,
      "context" : "Specifically (adapted from Heckerman et al. (2007)):",
      "startOffset" : 27,
      "endOffset" : 51
    }, {
      "referenceID" : 4,
      "context" : "from the PRM framework (Getoor et al., 2007) by including cardinality constraints.",
      "startOffset" : 23,
      "endOffset" : 44
    }, {
      "referenceID" : 6,
      "context" : "This definition is consistent with and expressible as DAPER models (Heckerman et al., 2007).",
      "startOffset" : 67,
      "endOffset" : 91
    }, {
      "referenceID" : 2,
      "context" : "Using the algorithm devised by Geiger et al. (1990),",
      "startOffset" : 31,
      "endOffset" : 52
    }, {
      "referenceID" : 11,
      "context" : "Due to Verma and Pearl (1988) for soundness and Geiger and Pearl (1988) for completeness.",
      "startOffset" : 7,
      "endOffset" : 30
    }, {
      "referenceID" : 1,
      "context" : "Due to Verma and Pearl (1988) for soundness and Geiger and Pearl (1988) for completeness.",
      "startOffset" : 48,
      "endOffset" : 72
    }, {
      "referenceID" : 5,
      "context" : "Due to both Heckerman et al. (2007) for DAPER models and Getoor (2001) for PRMs.",
      "startOffset" : 12,
      "endOffset" : 36
    }, {
      "referenceID" : 3,
      "context" : "(2007) for DAPER models and Getoor (2001) for PRMs.",
      "startOffset" : 28,
      "endOffset" : 42
    }, {
      "referenceID" : 10,
      "context" : "To discover a minimal separating set between relational variables X and Y, we modified Algorithm 4 devised by Tian et al. (1998) by starting with all parents of X̄ and Ȳ, augmented with the set of nodes they subsume in the AGG.",
      "startOffset" : 110,
      "endOffset" : 129
    } ],
    "year" : 2017,
    "abstractText" : "The rules of d -separation provide a framework for deriving conditional independence facts from model structure. However, this theory only applies to simple directed graphical models. We introduce relational d -separation, a theory for deriving conditional independence in relational models. We provide a sound, complete, and computationally efficient method for relational d -separation, and we present empirical results that demonstrate effectiveness.",
    "creator" : "LaTeX with hyperref package"
  }
}