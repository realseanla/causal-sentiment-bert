{
  "name" : "1606.07525.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Relating Knowledge and Coordinated Action: The Knowledge of Preconditions Principle",
    "authors" : [ "Yoram Moses" ],
    "emails" : [ "moses@ee.technion.ac.il" ],
    "sections" : [ {
      "heading" : null,
      "text" : "R. Ramanujam (Ed.): TARK 2015 EPTCS 215, 2016, pp. 231–245, doi:10.4204/EPTCS.215.17\nc© Yoram Moses This work is licensed under the Creative Commons Attribution License.\nRelating Knowledge and Coordinated Action: The Knowledge of Preconditions Principle\nYoram Moses∗\nTechnion—Israel Institute of Technology\nmoses@ee.technion.ac.il\nThe Knowledge of Preconditions principle (KoP) is proposed as a widely applicable connection between knowledge and action in multi-agent systems. Roughly speaking, it asserts that if some condition ϕ is a necessary condition for performing a given action α , then knowing ϕ is also a necessary condition for performing α . Since the specifications of tasks often involve necessary conditions for actions, the KoP principle shows that such specifications induce knowledge preconditions for the actions. Distributed protocols or multi-agent plans that satisfy the specifications must ensure that this knowledge be attained, and that it is detected by the agents as a condition for action. The knowledge of preconditions principle is formalised in the runs and systems framework, and is proven to hold in a wide class of settings. Well-known connections between knowledge and coordinated action are extended and shown to derive directly from the KoP principle: a common knowledge of preconditions principle is established showing that common knowledge is a necessary condition for performing simultaneous actions, and a nested knowledge of preconditions principle is proven, showing that coordinating actions to be performed in linear temporal order requires a corresponding form of nested knowledge.\nKeywords: Knowledge, multi-agent systems, common knowledge, nested knowledge, coordinated action, knowledge of preconditions principle."
    }, {
      "heading" : "1 Introduction",
      "text" : "While epistemology, the study of knowledge, has been a topic of interest in philosophical circles for centuries and perhaps even millennia, in the last half century it has seen a flurry of activity and applications in other fields such as AI [19], game theory [2] and distributed computing [13]. At least in the latter two fields a particular, information-based, notion of knowledge plays a prominent and useful role.\nThis paper proposes an essential connection between knowledge and action in such a setting. Using doesi(α) to denote “Agent i is performing action α” and Kiϕ to denote that Agent i knows the fact ϕ , the connection can intuitively be formulated as follows:\nThe KNOWLEDGE OF PRECONDITIONS Principle (KoP):\nIf ϕ is a necessary condition for doesi(α)\nthen Kiϕ is a necessary condition for doesi(α)\nThis statement appears deceptively simple. In fact, many successful applications of knowledge to the design and analysis of distributed protocols over the last three decades are rooted in the KoP. Moreover, some of the deeper insights obtained by knowledge theory in this field can be derived in a fairly direct\n∗The Israel Pollak academic chair at Technion. This work was supported in part by ISF grant 1520/11."
    }, {
      "heading" : "75 100 80 100",
      "text" : "fashion from the KoP. We will argue and demonstrate that this principle lies at the heart of coordination in many distributed and multi-agent systems.\nThis paper is structured as follows. Section 1.1 illustrates the central role of knowledge in a natural distributed systems application. Section 1.2 provides a high-level discussion of the knowledge of preconditions principle and its connection to coordinating actions. In Section 2 we review and discuss the modelling of knowledge in the runs and systems model of distributed systems based on [10]. A formal statement and proof of the KoP are presented in Section 3. Then, in Section 4, the KoP is used to establish a common knowledge of preconditions principle. It states that in order to perform simultaneously coordinated actions, agents must first attain common knowledge of any of the actions’ preconditions. An example of its use is provided in Section 4.1. Section 5 present an additional use of the KoP, and shows that coordinating a sequence of actions to occur in a prescribed temporal order requires attaining nested knowledge of their preconditions. Finally, Section 6 discusses additional applications, extensions and future directions."
    }, {
      "heading" : "1.1 The Case for Knowledge in Distributed Systems",
      "text" : "Why should knowledge play a central role in distributed computing? As pointed out in [13], most everyone who designs or even just tries to study the workings of a distributed protocol is quickly found talking in terms of knowledge, making statements such as “once the process receives an acknowledgement, it knows that the other process is ready. . . ”. An essential aspect of distributed systems is the fact that an agent chooses which action to perform based on the local information available to it, which typically provides only a partial view of the overall state of the system. To get a sense of the role of knowledge in distributed systems, consider the following example.\nExample 1. Given is a distributed network modeled by a graph, with agents located at the nodes, and the edges standing for communication channels (see Figure 1). In the problem we shall call Computing the Max (or CTM for short), each agent i starts out with a natural number vi ∈N as an initial value. The goal is to have Agent 1 print the maximum of all of the initial values (we denote this value by Max), and print nothing else. In the instance depicted in Figure 1, the maximal value happens to be 100. Initially, Agent 1 clearly can’t print its own initial value of 75. Suppose that Agent 1 receives a message µ , “v2 = 100” from Agent 2 reporting that its value is 100. At this point, Agent 1 has access to the maximum, and printing 100 would satisfy the problem specification. Compare this with a setting that is the same in all respects, except that Agent 3’s value is v3 = 150. In this case, of course, Max 6= 100 and so printing 100 is forbidden. But if Agent 1 can receive the same message µ under similar circumstances in both scenarios,\nthen it is unable to distinguish whether or not Max = 100 upon receiving µ . Intuitively, even in the first scenario, the agent does not know that Max = 100.\nWhat information does Agent 1 need, then, in order to be able to print the maximum? Notice that it is not necessary, in general, to collect all of the initial values in order to print the maximum. For example, suppose that the agents follow a bottom-up protocol in which values are sent from right to left, starting from Agent 4, and every agent passes to the left the larger of its own value and the value it received from its neighbor on the right (if such a neighbor exists). In this protocol, Agent 1 can clearly print the maximum after receiving the message “v2 = 100”, and seeing just one value besides its own. Interestingly, even collecting all of the values is not a sufficient condition for printing the Max. Imagine a setting in which the network is as in Figure 1, but Agent 1 considers it possible that there are more than four nodes in the network. In this case, even if Agent 1 receives all (four) values, it may still need to wait for proof that there is no additional, larger, value in the system.\nCTM is a simplified example in the spirit of many distributed systems applications. In fact, a central problem called Leader Election, for example, is often solved by computing a node with maximal ID [1, 17]. The solution to such a problem is typically in the form of a set of short computer programs (jointly constituting a distributed protocol), each executed at one of the nodes. When the nodes follow such a protocol, the resulting execution should satisfy the problem specification. Of course, the programs are written in a standard programming language, without any reference to knowledge or possibility. In the vast majority of cases, the programs in question do not enumerate and/or explore possible states or scenarios. Indeed, the program designer is typically unfamiliar with formal notions of knowledge. This being the case, what sense does it make to talk of Agent 1 in Example 1 “knowing” or “not knowing” that Max = c? Can it make sense to say that the Agent “considers it possible that there may be more than four nodes in the system”? After all, we may be talking about a 10-line program. It has no soul. Does it have thoughts, doubts and mental states?\nSince agents act based on their local information, a protocol designer must ensure that agents obtain the necessary information for a given task, and that this information is applied correctly. Using the information-based notion of knowledge, the designer can ascribe knowledge to an agent without requiring it to have a soul, feelings, and self-awareness. As seen in the CTM example, it is natural to think in terms of whether or not Agent 1 knows Max = c at any given point in a run of a protocol solving CTM. (A formal definition of knowledge will be provided in Section 2.) Suppose that a protocol is designed to solve CTM in networks that may have a variety of sizes. If Agent 1 does not start out with local information ensuring that there are no more than four nodes in the system, then from the point of view of an outside observer the agent can be thought of as “considering it possible” that there may be more than four nodes.\nEven in a simple network as in Figure 1, the CTM problem can be posed in different models, which can differ in essential aspects. A solution to CTM in one model might not solve the problem in another model. Indeed, the rationale behind distinct solutions, as well as their details, may vary considerably. Are there common features shared by all solutions to CTM?\nInterestingly, all solutions to CTM, in all models, share one property: Agent 1 must know that Max = c in order to print the value c. Indeed, the ability to print the answer in a protocol for CTM reduces to detecting when the Max value is known. Of course, once Agent 1 knows that Max = c it can safely print c. Hence, knowing that Max = c is not just necessary, but also a sufficient condition for printing c. The CTM problem shows that knowledge and attaining knowledge can be a central and crucial aspect of a standard distributed application.\nThe need to know Max = c in solving CTM suggests that we consider a natural question: When does Agent 1 know that Max = c? The answer is less straightforward than we might initially expect.\nWhat is known depends in a crucial way on the protocol that the agents are following. Thus, in the setting of Example 1, if the agents follow the bottom-up protocol, then Agent 1 knows the maximum once it receives a single message from Agent 2. Knowledge is also significantly affected by features of the model. In CTM, if there is an upper bound (say 100) on the possible initial values, then an agent that sees this value knows the maximum. Knowledge about the network topology and properties of communication play a role as well. For example, consider a model in which Agent 1 has a clock, and a single clock cycle suffices for a message to be delivered, digested, and acted upon. Suppose that the protocol is such that all agents start simultaneously at time 0 and an agent forwards a value towards Agent 1 only if this value is larger than any value it has previously sent. Then in the network of Figure 1 Agent 1 will receive a message with value 100 from Agent 2 at time 1, and no further messages. If Agent 1 knows that the diameter of the network is 3, it will not know the maximum upon receiving this message. However, without receiving any further messages, at time 3 Agent 1 will know that the maximum is 100; no larger value can be lurking in the system."
    }, {
      "heading" : "1.2 KoP and Coordination",
      "text" : "The fact that Max = c is a necessary condition for printing c is an essential feature of the CTM problem. We have argued that, in fact, K1(Max = c) is also a necessary condition for printing c, as the KoP would suggest. But this is just one instance. Let us briefly consider another example.\nExample 2. Consider a bank whose ATMs are designed in such a way that an ATM will dispense cash only to a customer whose account shows a sufficiently large positive balance. Along comes Alice, who has a large positive balance, and tries to obtain a modest sum from the ATM. On this day, however, the ATM is unable to communicate with the rest of the bank and it declines to pay Alice. Thus, despite the fact that Alice has good credit, the ATM frustrates her and denies her request. Apparently, given its specification, the ATM has no choice. Intuitively, in order to satisfy the credit restriction, the ATM needs to know that a customer has good credit before dispensing cash. If the ATM may pay a customer that is not known to have good credit, there will be possible scenarios in which the ATM will violate its specification, and pay a customer that does not have credit. Notice, however, that the specification said nothing about the ATM’s knowledge. It only imposed a restriction on the ATM’s action, based on the state of Alice’s account.\nBoth the CTM problem and the ATM example are instances in which the KoP clearly applies. The intuitive argument for why the KoP should apply very broadly is straightforward. If ϕ is a necessary condition for performing α , and agent i ever performs α without knowing ϕ , then there should be a possible scenario that is indistinguishable to agent i, in which ϕ does not hold. Since the two scenarios are indistinguishable, the agent can perform α in the second scenario, and violate the requirement that ϕ is a necessary condition. A formal statement and proof requires a definition of necessary conditions, knowledge, as well as capturing a sense in which an action at one point implies the same action at any other, indistinguishable, point. This will be done in Section 3.\nMost tasks in distributed systems are described by way of a specification. Such specifications typically impose a variety of necessary conditions for actions. The KoP implies that even though such specifications often do not explicitly discuss the agents’ knowledge, they do in fact impose knowledge preconditions. Observe that the KoP applies to a task regardless of the means that are used to implement it. Any engineer implementing a particular task will have to ensure that preconditions are known when actions are taken. This is true whether or not the engineer reasons explicitly in terms of knowledge, and it is true even if the engineer is not even aware of the knowledge terminology. (Normally, neither may be\nthe case, of course.) The need to satisfy the KoP suggests that the design of distributed implementations must involve at least two steps. One is to make sure that the required knowledge is made available to an agent who needs to performed a prescribed action, and the other is ensuring that the agent detect that it knows the required preconditions. This is quite different from common practice in engineering distributed implementations [28].\nWe remark that the KoP can be expected to hold in a variety of multi-agent settings well beyond the realm of distributed systems. Thus, for example, suppose that a jellyfish is naturally designed so that it will never sting its own flesh. By the KoP, the cell activating the sting at a given point needs to know that it is not stinging the jellyfish’s body when it “fires” its sting. The jellyfish is thus designed with some form of a “friend or foe” mechanism that is used in the course of activating the sting. Various biological activities can similarly be considered in light of the KoP: How does the organism know that certain preconditions are met? Our last example will come from the social science arena. Suppose that a society designs a legal system, that is required to satisfy the constraint that only people who are guilty of a particular crime are ever put in jail for committing this crime. By the KoP, the judge (or jury) must know that the person committed this crime in order to send him to jail.\nAs discussed above, specifications impose preconditions. Typically, these conditions relate an action to facts about the world (e.g., the maximal value, or the customer’s good credit). In many cases, however, actions of different agents need to be coordinated. Consider a variant of CTM in which in addition to Agent 1 printing the maximum, Agent 4 needs to perform an action (say print the same value or print the minimal value), but not before Agent 1 does. Then Agent 1 performing her action is a condition for 4’s action. In particular, Agent 4 would need to know that Agent 1 has already come to know Max = c for some c before 4 acts. In some cases, the identity of actions performed needs to be coordinated.\nFor a final example, suppose that Alice should perform an action αA only if Bob performs an action αB at least 5 time steps earlier. Then she needs to know that Bob acted at least 5 steps before when she acts. Indeed, if ψ is a necessary condition for αB, then Alice must know that “Bob knew ψ at least 5 time steps ago” when she acts, since knowing ψ is a necessary condition for Bob’s performing αB (see [4, 5]). As these examples illustrate, given KoP, coordination can give rise to nested knowledge.\nSimple instances of the KoP are often quite straightforward. Ensuring and detecting K1(Max = c) is often fairly intuitive, and it not justify the overhead involved in developing a theory of knowledge for multi-agent systems. However, satisfying statements involving nested knowledge in particular models of computation can quickly become nontrivial. For this, it is best to have a clear mathematical model of knowledge in multi-agent systems. The next section reviews the runs and systems model."
    }, {
      "heading" : "2 Modeling Knowledge Using Runs and Systems",
      "text" : "We now review the runs and systems model of knowledge of [10, 13]. The interested reader should consult [10] for more details. A global state is an “instantaneous snapshot” of the system at a given time. Let G denote a set of global states. Time will be identified with the natural numbers N= {0,1,2, . . .} for ease of exposition. A run is a function r: N→ G associating a global state with each instant of time. Thus, r(0) is the run’s initial state, r(1) is the next global state, and so on. A system is a set R of runs. The same global state can appear in different runs, and in some systems may even appear more than once in the same run.\nA central notion in our framework is that of an agent’s local state, whose role is to capture the agent’s local information at a given point. The precise details of the local state depend on the application. It could be the complete contents of an agent’s memory at the given instant, or the complete sequence of events\nthat it has observed so far. for example. The rule of thumb is that the local state should consist of the local information that the agent may use when deciding which actions to take. Thus, for example, if agents are finite-state machines, it is often natural to identify an agent’s local state with the automaton state that it is in. Formally, we assume that every global state determines a unique local state for each agent. We denote agent i’s local state in the global state r(t) by ri(t). Moreover, a global state with n agents A = {1, . . . ,n} will have the form r(t) = 〈re(t),r1(t), . . . ,rn(t)〉, where re(t) is called the local state of the environment, and will serve to represent all aspects of the global state that are not included in the agents’ local states. For example, it could represent messages in transit, the current topology of the network including what links may be down, etc."
    }, {
      "heading" : "2.1 Syntax and Semantics",
      "text" : "We are interested in a propositional logic of knowledge, in which propositional facts and epistemic facts can be expressed. Facts will be considered to be true or false at a point (r, t), with respect to a system R. More formally, given a set Φ of primitive propositions and a set P= {1, . . . ,n} of the agents in the system, we define a propositional language L Kn (Φ) by closing Φ under negation ‘¬’ and conjunction ‘∧’, as well as under knowledge operators Ki for all i ∈ P (see [14]). Thus, for example, if p,q ∈ Φ are primitive propositions and i, j ∈ P are agents, then ¬Ki p∧K jKi¬K jq is a formula in L Kn (Φ). We typically omit the set Φ and call L Kn the language for knowledge with n agents.\nIn a multi-agent system facts about the world, as well as the knowledge that agents have, can change dynamically from one time point to the next. We thus consider the truth of formulas of L Kn at points of a system R, where a point is a pair (r, t) ∈ R×N, and it is used to refer to time t in the run r. We denote the set of points of a system R by Pts(R), R×N. Points will play the role of states of a Kripke structure.\nThe set Φ of primitive propositions used in the analysis of any given multi-agent system R will depend on the application. Their truth at the points of the system needs to be explicitly defined. This is done by an interpretation π : Φ×Pts(R)→ {T,F}, where π ( q,(r, t) ) = T means that the proposition q holds at (r, t). Formally, an interpreted system w.r.t. a set Φ of primitive propositions is a pair (R,π) consisting of the system R and interpretation π for Φ over Pts(R). Just as we typically omit explicit reference to Φ, we shall omit π as well, when this is unambiguous.\nWe assume from here on that the environment’s state re(t) in a global state r(t) contains a “history” component h that records all actions taken by all agents at times 0,1,. . . ,t−1. Formally, we take h to be a set of triples 〈α, i, t ′〉, which grows monotonically in time. An action α is considered to be performed by i at the point (r, t) if and only if the triple 〈α, i, t〉, denoting that action α was performed by agent i at time t, appears in the history component h of re(t ′) for all times t ′ > t.1 For the analysis in this paper, we will also assume that Φ includes propositions of the form doesi(α) and didi(α) for agents i ∈ P and actions α . With this assumption, what actions are performed at any given point (r, t) is uniquely determined by the run r.\nWe will consider interpretations π that, on these propositions, are defined by π ( doesi(α),(r, t) ) = T iff agent i performs α at (r, t)\nπ ( didi(α),(r, t) ) = T iff π ( doesi(α),(r, t ′) ) = T holds for some t ′ ≤ t\nWe allow t ′ = t in the definition of didi(α) for technical convenience; it simplifies our later analysis slightly.\n1Our definition does not imply or assume that the actions are observed, observable or recorded by any of the agents. Whether that is the case depends on the application.\nOur model of knowledge will follow the standard Kripke-style possible worlds approach. The possibility relations that we use are induced directly from the system R being analyzed; two points are considered indistinguishable to an agent if its local states at the two points are the same. More formally:\nDefinition 2.1. If ri(t) = r′i(t ′), then (r, t) and (r′, t ′) are called indistinguishable to i, denoted by (r, t)≈i (r′, t ′).\nFormulae of L Kn are interpreted at a point (r, t) of an interpreted system (R,π) by means of the satisfaction relation ‘|=’, which is defined inductively by:\n(R,r, t) |= p iff (r, t) ∈ π(p); (R,r, t) |= ¬ϕ iff (R,r, t) 6|= ϕ; (R,r, t) |= ϕ ∧ψ iff both (R,r, t) |= ϕ and (R,r, t) |= ψ; (R,r, t) |= Kiϕ iff (R,r′, t ′) |= ϕ for all (r′, t ′) ∈ Pts(R) such that (r′, t ′)≈i (r, t).\nWe say that ϕ is valid in the system R, and write R |= ϕ , if (R,r, t) |= ϕ for all points (r, t) ∈ Pts(R). We say that ϕ validly implies ψ in R if ϕ ⇒ ψ is valid in R. Since, by Definition 2.1, the ≈i relations are equivalence relations, each knowledge operator Ki satisfies the S5 axiom system [14]. In particular, it satisfies the knowledge property (or Knowledge Axiom) that Kiϕ ⇒ ϕ is valid in all systems.\nIt is instructive to relate our modeling using runs and systems to standard multi-agent Kripke structures. For every system R there is a corresponding Kripke structure MR = (SR,π,∼1, . . . ,∼n) for n agents such that SR = Pts(R) and ‘∼i’ = ‘≈i’ for every i. They correspond in that (R,r, t) |= ϕ iff MR,(r, t) |= ϕ is guaranteed for all (r, t) ∈ Pts(R) = SR and ϕ ∈L Kn (Φ) (for details, see [10]).\nThe system R will determine the space of possible runs and possible points, which play a crucial role in determining the truth of facts involving knowledge. For example, consider a run r in which Alice sends Bob a message at time 1, and Bob receives it at time 2. If R is a system in which messages may be lost, or may take longer than one time step to be delivered, then Alice would not know at time 2 ( i.e.,\nw.r.t. (R,r,2) )\nthat her message has been delivered, because there is another run r′ ∈ R that she cannot tell apart from r at time 2, in which her message is not (or not yet) delivered by that time. The same run r also belongs to another system R′ in which messages are always reliably delivered in exactly one round. With respect to (R′,r,2), however, Alice would know at time 2 that her message has been delivered.\nOur definition of knowledge is rather flexible and widely applicable. The set R of the possible runs immediately induces what the agents know. Observe that the definition of knowledge is completely external. It ascribes knowledge to agents in the system even if the protocol they follow, as well as the actions that they perform, do not involve the knowledge terminology in any way. Moreover, the agents do not need to be complex or sophisticated for the definition to apply. Indeed, in a model of a very simple system consisting of a bed lamp and its electric cable, a switch in the OFF state can be said to know that the lamp is not lit; what the same switch would know in the ON state would depend on the system R under consideration, which determines the runs considered possible. E.g., if R contains a run in which the lamp is burnt out, then in the ON state the switch would not know that the lamp is shining light. On the other hand, if the lamp can never burn out, and the cord, plug and switch are in proper working order in all runs of R, then in the ON state the switch would know that the lamp is shining light. As this example shows, knowledge under this definition does not require the “knower” to compute what it knows. Indeed, this definition of knowledge is not sensitive to the computational complexity of determining what is known. In most cases, of course, we will ascribe knowledge to agents or components that can perform actions, which is not the case in the light switch example. And agents might need to explicitly establish whether they know relevant facts. We now provide a statement and proof of the knowledge of preconditions principle KoP."
    }, {
      "heading" : "3 Formalizing the Knowledge of Preconditions Principle",
      "text" : "Intuitively, the KoP states that if a particular fact ψ is a necessary condition for an agent to perform an action α , then the agent must in fact know ψ in order to act. In other words, knowing ψ is also a necessary condition for performing the action. We formalize the claim and prove it as follows. We say that ψ is a necessary condition for doesi(α) in R if (R,r, t) |= doesi(α) holds only if (R,r, t) |= ψ , for all (r, t) ∈ Pts(R). Clearly, the customer’s good credit is a necessary condition for the ATM dispensing cash. That is, suppose that a bank makes use of a correct implementation of an ATM protocol, which satisfies the credit requirement. Then, in the system R consisting of the set of all possible histories (runs) of the bank’s (and the ATM’s) transactions, good credit is a necessary condition for receiving cash from the ATM.\nIt is often of interest to consider facts whose truth depends only on a given agent’s loca state. Such, for example, may be the receipt of a message, or the observation of a signal, by the agent. Whether x = 0 for a local variable x, for example, would be a natural local fact. Moreover, if an agent has perfect recall, then any events that it has observed in the past will give rise to local facts. Finally, since knowledge is defined based on an agent’s local state, then a fact of the form Kiϕ constitutes a local fact. Indeed, there is a simple way to define the local facts above using knowledge. Namely, we say that ϕ is i-local in R if R |= (ϕ ⇒ Kiϕ).\nThe formalism of [10] defines protocols as explicit objects, and defines contexts that describe the possible initial states and the model of computation. This provides a convenient and modular way of constructing systems. Namely, given a protocol P and a context γ , the system R = R(P,γ) is defined to be the set of all runs of protocol P in γ . The runs of this system embody all of the properties of the context, as they arise in runs of P. This includes, for example, any timing assumptions, possible values encountered, possible topologies of the network, etc. They also embody the relevant properties of the protocol, because in all runs considered possible the agents follow P.\nIn this paper, we do not define protocols and contexts. Rather, we treat the KoP in a slightly simpler and more abstract setting. We say that an action α is a conscious action for i in R if i’s local state completely determines whether i performs α . If its local state at two points (r, t) and (r′, t ′) of R is the same, then (R,r, t) |= doesi(α) iff (R,r′, t ′) |= doesi(α). Conscious actions are quite prevalent in many systems of interest. For example, suppose that agent i follows a deterministic protocol, so that its action at any given point is a function of its local state. If, in addition, agent i is allowed to move at every time step, then all of its actions are conscious actions. We remark that, since conscious actions depend on an agent’s local state, then if α is conscious for i in R then (R,r, t) |= doesi(α) holds iff (R,r, t) |= Kidoesi(α) does, for all (r, t) ∈ Pts(R).\nWe are now ready to prove a formal version of the KoP: Theorem 3.1 (The KoP Theorem). Let α be a conscious action for i in R. If ψ is a necessary condition for doesi(α) in R, then Kiψ is also a necessary condition for doesi(α) in R.\nProof. We will show the contrapositive. Let α be a conscious action for i in R, and assume that Kiψ is not a necessary condition for doesi(α) in R. Namely, there exists a point (r, t) ∈ Pts(R) such that both (R,r, t) |= doesi(α) and (R,r, t) 6|= Kiψ . Given the latter, we have by the definition of ‘|=’ for Ki that there exists a point (r′, t ′) ∈ Pts(R) such that both (r′, t ′) ≈i (r, t) and (R,r′, t ′) 6|= ψ . Since α is a conscious action for i in R and (R,r, t) |= doesi(α) we have that (R,r, t) |= Kidoesi(α). It follows from (r′, t ′) ≈i (r, t) by the definition of ‘|=’ for Ki that (R,r′, t ′) |= doesi(α) holds. But since (R,r′, t ′) 6|= ψ , we conclude that ψ is not a necessary condition for doesi(α) in R, establishing the countrapositive claim.\nTheorem 3.1 applies to all multi-agent systems. It immediately implies, for example, that a necessary condition for the ATM to dispense cash is Katm(good credit). The theorem is model independent; it does not depend on timing assumptions, on the topology of the system (even on whether agents communicate by message passing or via reading and writing to registers in a shared memory), or on the nature of the activity that is carried out. For every necessary condition for a conscious action, knowing that the condition holds is also a necessary condition."
    }, {
      "heading" : "4 Coordinating Simultaneous Actions",
      "text" : "Recall that the language L Kn contains formulas in which knowledge operators can be nested to arbitrary finite depth. It is sometimes useful to consider a state of knowledge called common knowledge that goes beyond any particular nested formula. Intuitively, a fact ψ is common knowledge if everyone knowing that everyone knows . . . , that everyone knows the fact ψ , to every finite depth. Common knowledge has a number of equivalent definitions, one of which is as follows:\nDefinition 4.1 (Common Knowledge). Fix a set of agents G and a fact ψ . We denote by CGψ the fact that ψ is common knowledge to G. Its truth at points of a system R is defined by:\n(R,r, t) |=CGψ iff (R,r, t) |= Ki1Ki2 · · ·Kimψ holds for all 〈i1, i2, . . . , im〉 ∈ Gm and all m≥ 1. Common knowledge, a term coined by Lewis in [18], plays an important role in the analysis of games [2], distributed systems [13], and many other multi-agent settings. Clearly, common knowledge is much stronger than “plain” knowledge. Indeed, CGψ validly implies K jψ , for all agents j ∈ G. Since common knowledge requires infinitely many facts to hold, it is not a priori obvious that CGϕ can be attained at a reasonable cost, or even whether it can ever be attained at all, in settings of interest (see [7, 10, 13]). We will now show that there are natural applications for which attaining common knowledge is essential.\nIntuitively, distinct actions are simultaneous in R if they can only be performed together; whenever one is performed, all of them are performed simultaneously. It is possible to define simultaneous coordination formally in terms of necessary conditions:\nDefinition 4.2 (Simultaneous Actions). Let G be a set of agents. We say that a set of actions A = {αi}i∈G is (necessarily) simultaneous in R if doesi(αi) is a necessary condition for does j(α j) in R, for all i, j ∈ G.\nSuppose that the actions in A are simultaneous in R in the above sense. Then the KoP immediately implies (by Theorem 3.1) that a necessary condition for performing an action in A is knowing that the other actions are also (currently) being performed. In fact, however, much more must be true. We now present a strong variant of the KoP, which shows that in order to perform simultaneous actions agents must attain common knowledge of their necessary conditions. Notice that in order to allow a set of actions by the agents in G to be simultaneous, the system R must be sufficiently deterministic to ensure that if i, j ∈ G are distinct agents and (R,r, t) |= doesi(α) holds, then j will be scheduled to perform an action at (r, t). For otherwise, there would be no way to ensure simultaneous execution of the actions by the agents in G. Conscious actions fit this setting well in this case. We proceed as follows.\nTheorem 4.3 (C-K of Preconditions). Let G be a set of agents and let A = {αi}i∈G be a set of necessarily simultaneous actions in the system R. Moreover, suppose that each action αi ∈ A is a conscious action for its agent i in R. If ψ is a necessary condition for doesi(αi) for some i ∈ G, then CGψ is a necessary condition for does j(α j), for all j ∈ G.\nProof. Assume that A is a set of necessarily simultaneous actions for G in R. It is straightforward to show the following claim.\nObservation 1. Let αi,α j ∈ A be the actions for agents i and j, respectively. If a fact ϕ is a necessary condition for doesi(αi) in R then ϕ is also a necessary condition for does j(α j) in R.\nTo prove this observation notice that, by assumption, both (a) R |= does j(α j)⇒ doesi(αi) and (b) R |= doesi(αi)⇒ ϕ hold. For all (r, t) ∈ Pts(R), if (R,r, t) |= does j(α j) then (R,r, t) |= doesi(αi) holds by (a) and so (R,r, t) |= ϕ by (b). Thus, ϕ is a necessary condition for does j(α j) in R.\nAssume that ψ is a necessary condition for doesi(αi), for some i ∈ G. We shall prove by induction on m ≥ 0 that Ki1Ki2 · · ·Kimψ is a necessary condition for does j(α j) in R, for every j ∈ G and all sequences 〈i1, . . . , im〉 ∈ Gm (of m agent names from G). This will establish that (R,r, t) |= does j(α j) implies (R,r, t) |= CGψ for all (r, t) ∈ Pts(R), and thus CGψ is a necessary condition for does j(α j) for all j ∈ G, as claimed.\n• Base case: Let m = 0. The claim in this case is that if ψ is a necessary condition for doesi(αi) then ψ is also a necessary condition for does j(α j). This is precisely Observation 1, with ϕ , ψ .\n• Inductive step: Let m≥ 1, and assume that the claim holds for all j′ ∈G and all sequences in Gm−1. Fix j ∈ G and a sequence 〈i1, i2, . . . , im〉 ∈ Gm. Its suffix 〈i2, . . . , im〉 is a sequence in Gm−1. Thus, Ki2 · · ·Kimψ is a necessary condition for doesi1(αi1) by the inductive hypothesis for m− 1 (applied to Gm−1 and agent j′ = i1 ∈ G). Given that αi1 is a conscious action by i1, we can apply Theorem 3.1 to the necessary condition Ki2 · · ·Kimψ and obtain that Ki1Ki2 · · ·Kimψ is a necessary condition for doesi1(αi1). By Observation 1 we have that Ki1Ki2 · · ·Kimψ is also a necessary condition for does j(α j) in R, and we are done."
    }, {
      "heading" : "4.1 Common Knowledge and the Firing Squad Problem",
      "text" : "As an illustration of the applicability of Theorem 4.3 to a concrete application, consider a simple version of the Firing Squad problem. In this instance, the set of agents G in the system must simultaneously perform an action (say each agent i ∈ G should perform the action firei) in response to the receipt, by any agent in G, of a particular external input called a ‘go’ message. The firei action can stand for a simultaneous change in shared copies of a database, a public announcement at different sites of the system, or any other actions that need to take place simultaneously. Moreover, firei actions are allowed only if they are preceded by such a go message. For simplicity, we consider a case in which none of the agents in G may fail, and they all must satisfy the specification.\nLet ψgo be a proposition that is true at (r, t) ∈ Pts(R) if a go message is received by any of the agents in G at a point (r, t ′) of r at a time t ′ ≤ t. According to the specification of the Firing Squad problem, ψgo is a necessary condition for the firei actions. An immediate consequence of Theorem 4.3 is:\nCorollary 4.4. CGψgo is a necessary condition for all firei actions in the Firing Squad problem.\nGiven Corollary 4.4, any solution to the firing squad problem must first attain common knowledge that a go message has been received. It is well-known (see [11, 13]) that common knowledge of a fact is observed simultaneously at all agents it involves. Suppose that every i ∈G performs firei when CGψgo first holds. Since all agents in G will come to know that CGψgo immediately, they will fire simultaneously, as required by the problem specification. Indeed, Theorem 4.3 shows that this is the first time at which they can perform according to a correct protocol. Implementing simultaneous tasks such as the Firing\nSquad therefore inherently involves, and often reduces to, ensuring and detecting CGψgo. Recall that depending on the properties of the system, attaining such common knowledge might be impossible in some cases, or it might incur a substantial cost in others. Just as in the case of the KoP, this necessity is not due to our formalism. It is only exposed by our analysis. In every protocol that implements such a task correctly, the firing actions cannot be performed unless CGψgo is attained.\nThere is an extensive literature on using common knowledge to obtain optimal protocols for simultaneous tasks [8, 9, 16, 20, 21, 23, 24, 26, 25]. Typically, they involve an explicit proof that common knowledge of a particular fact is a necessary condition for performing a set A of necessarily simultaneous actions. Theorem 4.3 or a variant of it suited for fault-tolerant systems can be used to establish this result in all of these cases. Moreover, one of the main insights from the analysis of [13] and of [11] is that when simultaneous actions are performed, the participating agents have common knowledge that they are being performed. Theorem 4.3 is a strict generalization of this fact."
    }, {
      "heading" : "5 Temporally Ordering Actions",
      "text" : "So far, we have seen two essential connections between knowledge and coordinated action: performing actions requires knowledge of their necessary conditions, and performing simultaneous actions requires common knowledge of their necessary conditions. We now further extend the connection between states of knowledge and coordination, by showing that temporally ordering actions depends on attaining nested knowledge of necessary conditions. Following [5], we define temporally ordered actions:\nDefinition 5.1 (Ben Zvi and Moses). A sequence of actions 〈α1, . . . ,αk〉 (for agents 1, . . . ,k, respectively) is (linearly) ordered in R if did j−1(α j−1) is a necessary condition for does j(α j) in R.\nObserve that this definition does not force an action α j to occur in a run in which α j−1 occurs. Rather, if an action α j is performed in a given run, then it must be preceded by all actions α1, . . . ,α j−1. Moreover, if we denote the time at which an action αi is performed in a run r by ti, then we require that t j−1 ≤ t j for every action α j performed in r. Claim 1. Assume that the sequence 〈α1, . . . ,αk〉 is ordered in R. Then R |= ( did j(α j)⇒ did j−1(α j−1)\n) for all 2≤ j ≤ k.\nProof. Assume that (R,r, t) |= did j(α j). Then, by definition of did j(α j), we have (R,r, t̂ ) |= does j(α j) for some t̂ ≤ t. The fact that 〈α1, . . . ,αk〉 is ordered in R implies that did j−1(α j−1) is a necessary condition for does j(α j) in the system R, and so (R,r, t̂ ) |= did j−1(α j−1). Since did j−1(α j−1) is a stable fact and t ≥ t̂, we obtain that (R,r, t) |= did j−1(α j−1). The claim follows.\nWe say that a fact ϕ is stable in R if once true, ϕ remains true. Formally, if (R,r, t) |= ϕ and t ′ > t then (R,r, t ′) |= ϕ , for all r ∈ R and t, t ′ ≥ 0. Notice that while doesi(α) is, in general, not a stable fact, didi(α) is always stable. Definition 5.2. We say that agent i recalls ψ in R if the fact Kiψ is stable in R.\nThe notion of perfect recall, capturing the assumption that agents remember all events that they take part in, is popular in the analysis of games and multi-agent systems [10, 29]. While perfect recall is a nontrivial assumption often requiring significant storage costs, selective recall of single facts such as does j(α j) is a much weaker assumption, that can be assumed of a system R essentially without loss of generality. By adding a single bit to Agent j’s local state, whose value is 0 as long as j has not performed α j and 1 once the action has been performed, we can obtain a system R′ that is isomorphic to R, in which Agent j recalls does j(α j).\nClaim 2. Assume that α j is a conscious action for j in R, and that j recalls did j(α j) in R. Then did j(α j) is a j-local fact in R.\nProof. Suppose that (R,r, t) |= did j(α j). Then, by definition of did j(α j), we have (R,r, t̂ ) |= does j(α j) for some t̂ ≤ t. Choose an arbitrary (r′, t ′) ∈ Pts(R) satisfying that (r′, t ′) ≈ j (r, t̂ ). It follows that (R,r′, t ′) |= does j(α j) since α j is a conscious action for j in R. By definition of did j(α j) it follows that (R,r′, t ′) |= did j(α j). Now, by definition of |= for K j we have that (R,r, t̂ ) |= K jdid j(α j). By assumption, j recalls did j(α j) in R, and so K jdid j(α j) is stable in R. Thus, since t ≥ t̂, we obtain that (R,r, t) |= K jdid j(α j), as claimed.\nWe can now show:\nTheorem 5.3 (Ordering and Nested Knowledge). Assume that\n• the actions 〈α1, . . . ,αk〉 are ordered in R, • each agent j = 1, . . . ,k recalls did j(α j) in R, • α j is a conscious action for j in R, for all j = 1, . . . ,k, and • ψ is a stable necessary condition for the first action does1(α1) in R\nThen K jK j−1 · · ·K1ψ is a necessary condition for the j th action does j(α j) in R, for all j ≤ k.\nProof. Assuming the conditions of the theorem, we will prove by induction on j ≤ k that did j(α j) validly implies K jK j−1 · · ·K1ψ in R. Since does j(α j) validly implies did j(α j) by definition of did j(α j), this will yield that K jK j−1 · · ·K1ψ is a necessary condition for does j(α j) in R, as claimed. We proceed with the inductive argument.\n• Base case j = 1: Assume that (R,r, t) |= did1(α1). Claim 2 implies that (R,r, t) |= K1did1(α1). Let (r′, t ′)∈Pts(R) be an arbitrary point satisfying that (r′, t ′)≈1 (r, t). Then (R,r′, t ′) |= did1(α1) by the knowledge property. Thus, (R,r′, t̂ ) |= does1(α1) holds for some t̂ ≤ t ′, and because ψ is a necessary condition for does1(α1) in R, we obtain that (R,r, t̂ ) |= ψ . Since ψ is stable and t ′ ≥ t̂, we have that (R,r′, t ′) |= ψ . By choice of (r′, t ′) we have that (R,r, t) |= K1ψ , as claimed. • Inductive step: Let j > 1 and assume that K j−1 · · ·K1ψ is a necessary condition for did j−1(α j−1)\nin R. Moreover, let (R,r, t) |= did j(α j). Since α j is a conscious action for j, Claim 2 implies that (R,r, t) |= K jdid j(α j). Choose an arbitrary (r′, t ′) ∈ Pts(R) satisfying that (r′, t ′)≈ j (r, t). By definition of K j, it follows that (R,r′, t ′) |= did j(α j). By Claim 1, since the sequence 〈α1, . . . ,αk〉 is ordered in R and j > 1 we have that (R,r′, t ′) |= did j−1(α j−1). We now apply the inductive hypothesis to obtain that (R,r′, t ′) |=K j−1 · · ·K1ψ . Finally, we obtain that (R,r, t) |=K jK j−1 · · ·K1ψ by choice of (r′, t ′) and the definition of ‘|=’ for K j. The claim now follows.\nA slightly more restricted version of Theorem 5.3 was proved in [5]. Rather than consider an arbitrary necessary condition for α1, they proved a version for the case in which the first action α1 is triggered by an external input to agent 1. Technically, the proofs are quite similar.\nTheorem 5.3 provides a necessary, but possibly not sufficient, condition for ordering actions in distributed systems. If agent j acts strictly later than when K jK j−1 · · ·K1ψ first holds, then it may be inappropriate for agent j+1 to act when it knows that the fact K jK j−1 · · ·K1ψ holds (i.e., when K j+1K j · · ·K1ψ first holds). Nevertheless, Theorem 5.3 is often very useful because it can be used as a guide for efficiently, and sometimes even optimally, performing a sequence of ordered actions. Intuitively, suppose\nthat we have a protocol whose goal is to perform 〈α1, . . . ,αk〉 in response to an externally generated trigger ψ (such as the ‘go’ message in Firing Squad). In particular, assume that ψ is a necessary condition for α1. Keeping the communication aspects of this protocol fixed, an optimally fast solution would be for each agent j ≤ k to perform α j when K jK j−1 · · ·K1ψ first holds. Let R be the set of runs of such a protocol with r ∈ R, and let t j and t j−1 be the earliest times at which (R,r, t j) |= K jK j−1 · · ·K1ψ and (R,r, t j−1) |= K j−1 · · ·K1ψ hold in a run r, respectively. The knowledge property guarantees that K jK j−1 · · ·K1ψ validly implies that K j−1 · · ·K1ψ in R, and so t j ≥ t j−1. Since, by assumption, α j is performed at time t j and α j−1 at t j−1, we have that agents perform actions in linear temporal order, as required by Definition 5.1. Clearly, none of the actions can be performed any earlier, as Theorem 5.3 shows. We conclude that in time-efficient protocols, the nested knowledge formula presented by the theorem can be both necessary and sufficient. In this sense, Theorem 5.3 suggests a recipe for obtaining time-efficient solutions for ordering actions.\nJust as Theorem 4.3 implies that common knowledge is a necessary condition for simultaneous actions, we now have by Theorem 5.3 that nested knowledge is a necessary condition for performing actions in linear temporal order. And just as there is an established literature on when common knowledge is and is not attainable and on how it may arise, there are results concerning the communication structure that underlies attaining nested knowledge. Indeed, in a seminal paper [7], Chandy and Misra showed that in asynchronous systems R, if (R,r, t) |= ¬ϕ and at a time t ′ > t (R,r, t ′) |= K jK j−1 · · ·K1ϕ , then there must be a message chain in the run r between times t and t ′, passing through the agents 1,2,. . . , j in this order (possibly involving additional agents as well). Given Theorem 5.3, this implies that the only way to coordinate actions in a linear temporal order in an asynchronous setting is by way of such message chains.2\nMore recently, Ben Zvi and Moses extended Chandy and Misra’s work to systems in which communication is not asynchronous, but rather agents may have access to clocks and the transmission time for each of the channels is bounded [5]. They show that a communication structure called a centipede must be constructed in order to obtain nested knowledge of spontaneous facts such as the arrival of an external input. They prove a slightly more restricted instance of Theorem 5.3 (without using KoP directly), and use it to show that ordering actions in their setting requires the construction of the appropriate centipedes. Finally, Parikh and Krasucki analyze the ability to create levels of knowledge consisting of collections of nested knowledge formulas in [27]. Theorem 5.3 relates levels of knowledge to coordination."
    }, {
      "heading" : "6 Discussion",
      "text" : "This paper formulated the knowledge of preconditions principle and presented three theorems relating knowledge and coordinated action: the first is the KoP itself—necessary conditions for an action must be known to hold when the action is performed. Next, we showed that necessary conditions for simultaneous actions must be commonly known when the actions are taken. Finally, nested knowledge is a necessary condition for coordinating linearly ordered actions. The latter two are fairly direct consequences of the KoP. We discussed some of the uses of the latter two results in Sections 4 and 5. Indeed the KoP has many further implications.\nIn recent years, several works that make use of KoP have appeared, citing the unpublished [22]. For example, Castañeda, Gonczarowski and Moses used the KoP to analyze the consensus problem [6],\n2Theorems 3.1 and 5.3 depend on conscious actions and therefore do not apply to asynchronous systems. Nevertheless, variants of these theorems can be presented that do apply to asynchronous systems and nondeterministic protocols. Details will appear in [22].\nin which agents need to agree on a binary value in a fault-prone system. They designed a protocol in two steps—applying the KoP once to derive a rule by which, roughly, agents decide on 0 when they know of an initial value of 0. Then, they applied the KoP again assuming that this is the rule used for making decisions on 0, and obtained a rule involving nested knowledge (roughly, a statement of the form “knowing that nobody knows 0”) for deciding on the value 1. The result of their analysis was a very efficient solution to consensus that is optimal in a strong sense: It is the first unbeatable consensus protocol. No protocol can strictly dominate it, by having processes always decide at least as fast, and sometimes strictly faster, than this protocol does. The work of [6] complements an earlier work by Halpern, Moses and Waarts [15], in which a fixed point analysis of optimal consensus was obtained. The latter, too, is closely related to the KoP.\nGonczarowski and Moses used the KoP to analyze the epistemic requirements of more general forms of coordination [12]. Namely, they considered a setting in which k agents need to perform actions, and there are time bounds on the relative times at which the actions of any pair of agents is performed. The simple instance in which all bounds are 0 is precisely that of the simultaneous actions considered in Section 4. They show that such coordination requires vectorial fixed points of knowledge conditions, which are naturally related to fixed points and equilibria. The papers [3, 4, 5, 12] together can all be viewed as making use of the KoP to provide insights into the interaction between time and communication for coordinating actions in a distributed and multi-agent system. Describing them is beyond the scope of the current paper.\nThe most significant aspect of the KoP, in our view, is the fact that it places a new emphasis on the epistemic aspects of problem solving in a multi-agent system. Simple necessary conditions induce epistemic conditions. Thus, in order to act correctly, one needs a mechanism ensuring that the agents obtain the necessary knowledge, and that they discover that they have this knowledge. Most problems and solutions are not posed or described in this fashion. We believe that the KoP encapsulates an important connection between knowledge, action and coordination that will find many applications in the future."
    } ],
    "references" : [ {
      "title" : "Distributed Computing: Fundamentals, Simulations and Advanced Topics",
      "author" : [ "Hagit Attiya", "Jennifer Welch" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2004
    }, {
      "title" : "Agreeing to disagree",
      "author" : [ "R.J. Aumann" ],
      "venue" : "Annals of Statistics",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1976
    }, {
      "title" : "Agent-Time Epistemics and Coordination",
      "author" : [ "Ido Ben-Zvi", "Yoram Moses" ],
      "venue" : "Proceedings of ICLA, pp. 97–108,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2013
    }, {
      "title" : "The Shape of Reactive Coordination Tasks",
      "author" : [ "Ido Ben-Zvi", "Yoram Moses" ],
      "venue" : "Proceedings of TARK, TARK XIV,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2013
    }, {
      "title" : "Beyond Lamport’s Happened-before: On Time Bounds and the Ordering of Events in Distributed Systems",
      "author" : [ "Ido Ben-Zvi", "Yoram Moses" ],
      "venue" : "J. ACM 61(2),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2014
    }, {
      "title" : "How processes learn",
      "author" : [ "K.M. Chandy", "J. Misra" ],
      "venue" : "Distributed Computing",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1986
    }, {
      "title" : "An optimal self-stabilizing firing squad",
      "author" : [ "Danny Dolev", "Ezra N Hoch", "Yoram Moses" ],
      "venue" : "SIAM Journal on Computing",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2012
    }, {
      "title" : "Knowledge and common knowledge in a Byzantine environment: crash failures",
      "author" : [ "C. Dwork", "Y. Moses" ],
      "venue" : "Information and Computation",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1990
    }, {
      "title" : "Reasoning about Knowledge",
      "author" : [ "R. Fagin", "J.Y. Halpern", "Y. Moses", "M.Y. Vardi" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2003
    }, {
      "title" : "Common knowledge revisited",
      "author" : [ "Ronald Fagin", "Joseph Y. Halpern", "Yoram Moses", "Vardi. Moshe Y" ],
      "venue" : "Annals of Pure and Applied Logic",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1999
    }, {
      "title" : "Timely common knowledge: Characterising asymmetric distributed coordination via vectorial fixed points",
      "author" : [ "Y Gonczarowski", "Y Moses" ],
      "venue" : "Proceedings of TARK XIV",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2013
    }, {
      "title" : "Knowledge and Common Knowledge in a Distributed Environment",
      "author" : [ "J.Y. Halpern", "Y. Moses" ],
      "venue" : "Journal of the ACM 37(3),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1990
    }, {
      "title" : "A guide to completeness and complexity for modal logics of knowledge and belief",
      "author" : [ "J.Y. Halpern", "Y. Moses" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1992
    }, {
      "title" : "A Characterization of Eventual Byzantine Agreement",
      "author" : [ "Joseph Y. Halpern", "Yoram Moses", "Orli Waarts" ],
      "venue" : "SIAM J. Comput",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2001
    }, {
      "title" : "Transforming worst-case optimal solutions for simultaneous tasks into all-case optimal solutions",
      "author" : [ "Maurice P Herlihy", "Yoram Moses", "Mark R Tuttle" ],
      "venue" : "Proceedings of the 30th annual ACM SIGACT-SIGOPS symposium on Principles of distributed computing,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2011
    }, {
      "title" : "Distributed Systems-Towards a Formal Approach",
      "author" : [ "Gérard Le Lann" ],
      "venue" : "IFIP Congress,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 1977
    }, {
      "title" : "Convention, A Philosophical Study",
      "author" : [ "D. Lewis" ],
      "venue" : null,
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1969
    }, {
      "title" : "Continuous consensus via common knowledge",
      "author" : [ "Tal Mizrahi", "Yoram Moses" ],
      "venue" : "Distributed Computing",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2008
    }, {
      "title" : "Continuous consensus with ambiguous failures",
      "author" : [ "Tal Mizrahi", "Yoram Moses" ],
      "venue" : "Distributed Computing and Networking,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2008
    }, {
      "title" : "Programming simultaneous actions using common knowledge",
      "author" : [ "Y. Moses", "M.R. Tuttle" ],
      "venue" : "Algorithmica 3,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1988
    }, {
      "title" : "Consistent coordination and continual common knowledge",
      "author" : [ "G. Neiger" ],
      "venue" : null,
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 1990
    }, {
      "title" : "Common knowledge and consistent simultaneous coordination",
      "author" : [ "G. Neiger", "M.R. Tuttle" ],
      "venue" : "Distributed Computing",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 1993
    }, {
      "title" : "Using knowledge to optimally achieve coordination in distributed systems",
      "author" : [ "Gil Neiger", "Rida A Bazzi" ],
      "venue" : "Theoretical computer science",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1999
    }, {
      "title" : "Levels of knowledge in distributed computing",
      "author" : [ "R. Parikh", "P. Krasucki" ],
      "venue" : "Sādhanā",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1992
    }, {
      "title" : "Implementing fault-tolerant services using the state machine approach: A tutorial",
      "author" : [ "Fred B Schneider" ],
      "venue" : "ACM Computing Surveys (CSUR) 22(4),",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1990
    }, {
      "title" : "Reexamination of the perfectness concept for equilibrium points in extensive games",
      "author" : [ "R. Selten" ],
      "venue" : "International Journal of Game Theory",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 1975
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "While epistemology, the study of knowledge, has been a topic of interest in philosophical circles for centuries and perhaps even millennia, in the last half century it has seen a flurry of activity and applications in other fields such as AI [19], game theory [2] and distributed computing [13].",
      "startOffset" : 260,
      "endOffset" : 263
    }, {
      "referenceID" : 11,
      "context" : "While epistemology, the study of knowledge, has been a topic of interest in philosophical circles for centuries and perhaps even millennia, in the last half century it has seen a flurry of activity and applications in other fields such as AI [19], game theory [2] and distributed computing [13].",
      "startOffset" : 290,
      "endOffset" : 294
    }, {
      "referenceID" : 8,
      "context" : "In Section 2 we review and discuss the modelling of knowledge in the runs and systems model of distributed systems based on [10].",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 11,
      "context" : "Why should knowledge play a central role in distributed computing? As pointed out in [13], most everyone who designs or even just tries to study the workings of a distributed protocol is quickly found talking in terms of knowledge, making statements such as “once the process receives an acknowledgement, it knows that the other process is ready.",
      "startOffset" : 85,
      "endOffset" : 89
    }, {
      "referenceID" : 0,
      "context" : "In fact, a central problem called Leader Election, for example, is often solved by computing a node with maximal ID [1, 17].",
      "startOffset" : 116,
      "endOffset" : 123
    }, {
      "referenceID" : 15,
      "context" : "In fact, a central problem called Leader Election, for example, is often solved by computing a node with maximal ID [1, 17].",
      "startOffset" : 116,
      "endOffset" : 123
    }, {
      "referenceID" : 24,
      "context" : "This is quite different from common practice in engineering distributed implementations [28].",
      "startOffset" : 88,
      "endOffset" : 92
    }, {
      "referenceID" : 3,
      "context" : "Indeed, if ψ is a necessary condition for αB, then Alice must know that “Bob knew ψ at least 5 time steps ago” when she acts, since knowing ψ is a necessary condition for Bob’s performing αB (see [4, 5]).",
      "startOffset" : 196,
      "endOffset" : 202
    }, {
      "referenceID" : 4,
      "context" : "Indeed, if ψ is a necessary condition for αB, then Alice must know that “Bob knew ψ at least 5 time steps ago” when she acts, since knowing ψ is a necessary condition for Bob’s performing αB (see [4, 5]).",
      "startOffset" : 196,
      "endOffset" : 202
    }, {
      "referenceID" : 8,
      "context" : "We now review the runs and systems model of knowledge of [10, 13].",
      "startOffset" : 57,
      "endOffset" : 65
    }, {
      "referenceID" : 11,
      "context" : "We now review the runs and systems model of knowledge of [10, 13].",
      "startOffset" : 57,
      "endOffset" : 65
    }, {
      "referenceID" : 8,
      "context" : "The interested reader should consult [10] for more details.",
      "startOffset" : 37,
      "endOffset" : 41
    }, {
      "referenceID" : 12,
      "context" : ",n} of the agents in the system, we define a propositional language L K n (Φ) by closing Φ under negation ‘¬’ and conjunction ‘∧’, as well as under knowledge operators Ki for all i ∈ P (see [14]).",
      "startOffset" : 190,
      "endOffset" : 194
    }, {
      "referenceID" : 12,
      "context" : "1, the ≈i relations are equivalence relations, each knowledge operator Ki satisfies the S5 axiom system [14].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 8,
      "context" : "They correspond in that (R,r, t) |= φ iff MR,(r, t) |= φ is guaranteed for all (r, t) ∈ Pts(R) = SR and φ ∈L K n (Φ) (for details, see [10]).",
      "startOffset" : 135,
      "endOffset" : 139
    }, {
      "referenceID" : 8,
      "context" : "The formalism of [10] defines protocols as explicit objects, and defines contexts that describe the possible initial states and the model of computation.",
      "startOffset" : 17,
      "endOffset" : 21
    }, {
      "referenceID" : 16,
      "context" : "Common knowledge, a term coined by Lewis in [18], plays an important role in the analysis of games [2], distributed systems [13], and many other multi-agent settings.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 1,
      "context" : "Common knowledge, a term coined by Lewis in [18], plays an important role in the analysis of games [2], distributed systems [13], and many other multi-agent settings.",
      "startOffset" : 99,
      "endOffset" : 102
    }, {
      "referenceID" : 11,
      "context" : "Common knowledge, a term coined by Lewis in [18], plays an important role in the analysis of games [2], distributed systems [13], and many other multi-agent settings.",
      "startOffset" : 124,
      "endOffset" : 128
    }, {
      "referenceID" : 5,
      "context" : "Since common knowledge requires infinitely many facts to hold, it is not a priori obvious that CGφ can be attained at a reasonable cost, or even whether it can ever be attained at all, in settings of interest (see [7, 10, 13]).",
      "startOffset" : 214,
      "endOffset" : 225
    }, {
      "referenceID" : 8,
      "context" : "Since common knowledge requires infinitely many facts to hold, it is not a priori obvious that CGφ can be attained at a reasonable cost, or even whether it can ever be attained at all, in settings of interest (see [7, 10, 13]).",
      "startOffset" : 214,
      "endOffset" : 225
    }, {
      "referenceID" : 11,
      "context" : "Since common knowledge requires infinitely many facts to hold, it is not a priori obvious that CGφ can be attained at a reasonable cost, or even whether it can ever be attained at all, in settings of interest (see [7, 10, 13]).",
      "startOffset" : 214,
      "endOffset" : 225
    }, {
      "referenceID" : 9,
      "context" : "It is well-known (see [11, 13]) that common knowledge of a fact is observed simultaneously at all agents it involves.",
      "startOffset" : 22,
      "endOffset" : 30
    }, {
      "referenceID" : 11,
      "context" : "It is well-known (see [11, 13]) that common knowledge of a fact is observed simultaneously at all agents it involves.",
      "startOffset" : 22,
      "endOffset" : 30
    }, {
      "referenceID" : 6,
      "context" : "There is an extensive literature on using common knowledge to obtain optimal protocols for simultaneous tasks [8, 9, 16, 20, 21, 23, 24, 26, 25].",
      "startOffset" : 110,
      "endOffset" : 144
    }, {
      "referenceID" : 7,
      "context" : "There is an extensive literature on using common knowledge to obtain optimal protocols for simultaneous tasks [8, 9, 16, 20, 21, 23, 24, 26, 25].",
      "startOffset" : 110,
      "endOffset" : 144
    }, {
      "referenceID" : 14,
      "context" : "There is an extensive literature on using common knowledge to obtain optimal protocols for simultaneous tasks [8, 9, 16, 20, 21, 23, 24, 26, 25].",
      "startOffset" : 110,
      "endOffset" : 144
    }, {
      "referenceID" : 17,
      "context" : "There is an extensive literature on using common knowledge to obtain optimal protocols for simultaneous tasks [8, 9, 16, 20, 21, 23, 24, 26, 25].",
      "startOffset" : 110,
      "endOffset" : 144
    }, {
      "referenceID" : 18,
      "context" : "There is an extensive literature on using common knowledge to obtain optimal protocols for simultaneous tasks [8, 9, 16, 20, 21, 23, 24, 26, 25].",
      "startOffset" : 110,
      "endOffset" : 144
    }, {
      "referenceID" : 19,
      "context" : "There is an extensive literature on using common knowledge to obtain optimal protocols for simultaneous tasks [8, 9, 16, 20, 21, 23, 24, 26, 25].",
      "startOffset" : 110,
      "endOffset" : 144
    }, {
      "referenceID" : 20,
      "context" : "There is an extensive literature on using common knowledge to obtain optimal protocols for simultaneous tasks [8, 9, 16, 20, 21, 23, 24, 26, 25].",
      "startOffset" : 110,
      "endOffset" : 144
    }, {
      "referenceID" : 22,
      "context" : "There is an extensive literature on using common knowledge to obtain optimal protocols for simultaneous tasks [8, 9, 16, 20, 21, 23, 24, 26, 25].",
      "startOffset" : 110,
      "endOffset" : 144
    }, {
      "referenceID" : 21,
      "context" : "There is an extensive literature on using common knowledge to obtain optimal protocols for simultaneous tasks [8, 9, 16, 20, 21, 23, 24, 26, 25].",
      "startOffset" : 110,
      "endOffset" : 144
    }, {
      "referenceID" : 11,
      "context" : "Moreover, one of the main insights from the analysis of [13] and of [11] is that when simultaneous actions are performed, the participating agents have common knowledge that they are being performed.",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 9,
      "context" : "Moreover, one of the main insights from the analysis of [13] and of [11] is that when simultaneous actions are performed, the participating agents have common knowledge that they are being performed.",
      "startOffset" : 68,
      "endOffset" : 72
    }, {
      "referenceID" : 4,
      "context" : "Following [5], we define temporally ordered actions:",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 8,
      "context" : "The notion of perfect recall, capturing the assumption that agents remember all events that they take part in, is popular in the analysis of games and multi-agent systems [10, 29].",
      "startOffset" : 171,
      "endOffset" : 179
    }, {
      "referenceID" : 25,
      "context" : "The notion of perfect recall, capturing the assumption that agents remember all events that they take part in, is popular in the analysis of games and multi-agent systems [10, 29].",
      "startOffset" : 171,
      "endOffset" : 179
    }, {
      "referenceID" : 4,
      "context" : "3 was proved in [5].",
      "startOffset" : 16,
      "endOffset" : 19
    }, {
      "referenceID" : 5,
      "context" : "Indeed, in a seminal paper [7], Chandy and Misra showed that in asynchronous systems R, if (R,r, t) |= ¬φ and at a time t ′ > t (R,r, t ′) |= K jK j−1 · · ·K1φ , then there must be a message chain in the run r between times t and t ′, passing through the agents 1,2,.",
      "startOffset" : 27,
      "endOffset" : 30
    }, {
      "referenceID" : 4,
      "context" : "More recently, Ben Zvi and Moses extended Chandy and Misra’s work to systems in which communication is not asynchronous, but rather agents may have access to clocks and the transmission time for each of the channels is bounded [5].",
      "startOffset" : 227,
      "endOffset" : 230
    }, {
      "referenceID" : 23,
      "context" : "Finally, Parikh and Krasucki analyze the ability to create levels of knowledge consisting of collections of nested knowledge formulas in [27].",
      "startOffset" : 137,
      "endOffset" : 141
    }, {
      "referenceID" : 13,
      "context" : "The work of [6] complements an earlier work by Halpern, Moses and Waarts [15], in which a fixed point analysis of optimal consensus was obtained.",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 10,
      "context" : "Gonczarowski and Moses used the KoP to analyze the epistemic requirements of more general forms of coordination [12].",
      "startOffset" : 112,
      "endOffset" : 116
    }, {
      "referenceID" : 2,
      "context" : "The papers [3, 4, 5, 12] together can all be viewed as making use of the KoP to provide insights into the interaction between time and communication for coordinating actions in a distributed and multi-agent system.",
      "startOffset" : 11,
      "endOffset" : 24
    }, {
      "referenceID" : 3,
      "context" : "The papers [3, 4, 5, 12] together can all be viewed as making use of the KoP to provide insights into the interaction between time and communication for coordinating actions in a distributed and multi-agent system.",
      "startOffset" : 11,
      "endOffset" : 24
    }, {
      "referenceID" : 4,
      "context" : "The papers [3, 4, 5, 12] together can all be viewed as making use of the KoP to provide insights into the interaction between time and communication for coordinating actions in a distributed and multi-agent system.",
      "startOffset" : 11,
      "endOffset" : 24
    }, {
      "referenceID" : 10,
      "context" : "The papers [3, 4, 5, 12] together can all be viewed as making use of the KoP to provide insights into the interaction between time and communication for coordinating actions in a distributed and multi-agent system.",
      "startOffset" : 11,
      "endOffset" : 24
    } ],
    "year" : 2016,
    "abstractText" : "The Knowledge of Preconditions principle (KoP) is proposed as a widely applicable connection between knowledge and action in multi-agent systems. Roughly speaking, it asserts that if some condition φ is a necessary condition for performing a given action α , then knowing φ is also a necessary condition for performing α . Since the specifications of tasks often involve necessary conditions for actions, the KoP principle shows that such specifications induce knowledge preconditions for the actions. Distributed protocols or multi-agent plans that satisfy the specifications must ensure that this knowledge be attained, and that it is detected by the agents as a condition for action. The knowledge of preconditions principle is formalised in the runs and systems framework, and is proven to hold in a wide class of settings. Well-known connections between knowledge and coordinated action are extended and shown to derive directly from the KoP principle: a common knowledge of preconditions principle is established showing that common knowledge is a necessary condition for performing simultaneous actions, and a nested knowledge of preconditions principle is proven, showing that coordinating actions to be performed in linear temporal order requires a corresponding form of nested knowledge.",
    "creator" : "LaTeX with hyperref package"
  }
}