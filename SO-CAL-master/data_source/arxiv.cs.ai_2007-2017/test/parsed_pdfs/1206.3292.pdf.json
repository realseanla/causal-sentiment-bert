{
  "name" : "1206.3292.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Identifying Dynamic Sequential Plans",
    "authors" : [ "Jin Tian" ],
    "emails" : [ "jtian@cs.iastate.edu" ],
    "sections" : [ {
      "heading" : null,
      "text" : "We address the problem of identifying dynamic sequential plans in the framework of causal Bayesian networks, and show that the problem is reduced to identifying causal effects, for which there are complete identification algorithms available in the literature."
    }, {
      "heading" : "1 Introduction",
      "text" : "This paper deals with the problem of evaluating the effects of sequential plans from a combination of nonexperimental data and qualitative causal assumptions. The causal assumptions will be represented in the form of an acyclic causal diagram [Spirtes et al., 1993, Heckerman and Shachter, 1995, Lauritzen, 2000, Pearl, 2000] in which arrows represent the potential existence of direct causal relationships between the corresponding variables. The causal diagram may contain unmeasured variables, and our task is to decide whether we can estimate the effects of a sequence of actions from the observed data.\nWe motivate the study by considering a medical treatment problem discussed in [Pearl and Robins, 1995, Dawid and Didelez, 2005]. There are a sequence of medical treatments (X1, . . . , Xk) applied to a patient over time. We have observations Zi before and between the treatments. Doctors may prescribe a treatment based on previous treatments and observations. There is a outcome variable Y (say survival) of special interest and we want to estimate the effects of the sequential treatments on Y . In general there may be unobserved confounders that have influence on the observed variables.\nThere are different possible strategies for choosing the treatment action (Xi). The simplest action involves fixing the value of Xi to a particular value x∗i , called atomic intervention and denoted\nby do(x∗i ) in [Pearl, 2000], e.g. fixing the dosage of a treatment irrespective of any observations on the patient. A unconditional plan consists of a sequence of pre-defined atomic actions. The problem of identifying unconditional plans is to compute the distribution of Y under atomic interventions on a set X of action variables, denoted by Px(y) = P (y|do(x)), a quantity known as the causal effects of X on Y . Sufficient graphical criteria for the identifiability of unconditional plans are derived in [Pearl and Robins, 1995]. Recently the general problem of identifying causal effects Px(y) in a causal diagram containing unobserved variables has been solved and complete algorithms for identification are given in [Tian and Pearl, 2003, Shpitser and Pearl, 2006b, Huang and Valtorta, 2006].\nIn general we may want to use dynamic treatment strategies in which the values of action variables (Xi) are determined based on the previously observed variables and previously taken actions. Sufficient graphical criteria for the identifiability of dynamic plans are derived in [Dawid and Didelez, 2005]. However the identifiability problem is far from being solved.\nIn this paper, we show that the problem of identifying dynamic sequential plans can be reduced to the well-studied problem of identifying causal effects and therefore essentially solved the sequential plan identification problem. Although Pearl (2000, Section 4.2) has suggested that dynamic conditional plans may be identified by identifying conditional causal effects of the form Px(y|c), for which complete identification algorithms have been developed [Tian, 2004, Shpitser and Pearl, 2006a], in this paper, we will show that this gives a sufficient condition for identifying dynamic sequential plans but it is not necessary.\nThe rest of the paper is organized as follows. In Section 2, we review the work in [Dawid and Didelez, 2005] and define useful notation. In Section 3, we formulate the sequential plan problem in the framework of causal Bayesian networks. We\nshow how to reduce the problem of identifying dynamic sequential plans into a problem of identifying causal effects in Section 4, and discuss in Section 5 the problem versus that of identifying unconditional plans and conditional causal effects. Section 6 concludes the paper."
    }, {
      "heading" : "2 Previous Work and Notation",
      "text" : "Dawid and Didelez (2005) formulated the problem of identifying dynamic sequential plans in the framework of regime indicators and influence diagrams. An influence diagram (ID) is a DAG over a set V = {V1, . . . , Vn} of variables that also includes regime indicators as special nodes of their own called decision nodes [Dawid, 2002]. We assume that all variables are discrete. The DAG is assumed to represent conditional independence assertions that each variable is independent of all its non-descendants given its direct parents in the graph.1 These assertions imply that the joint probability function P (v) = P (v1, . . . , vn) factorizes according to the product [Pearl, 1988]\nP (v) = ∏\ni\nP (vi|pai) (1)\nwhere pai are (values of) the parents of variable Vi in the graph.2\nThe question of causal inference is considered as a problem of inference across different regimes, in which we may intervene in certain variables in certain ways and observe the behavior of other variables. Regime indicators are used to represent different types of interventions. Here we will roughly follow the notation used in [Didelez et al., 2006]. The regime indicator for an intervention in a variable Vi is denoted by σVi and can take values in a set of strategies. Under strategy σVi , the conditional probability P (vi|pai) is changed to P (vi|pai;σVi). We will consider the following types of interventions.\n• Idle regime σVi = ∅: No intervention takes place, therefore\nP (vi|pai;σVi = ∅) = P (vi|pai).\nThe idle regime is also called the observational regime under which we will assume that observational data has been collected. Therefore P (vi|pai) can be estimated from data if Vi and Pai are observed.\n1We use family relationships such as “parents,” “children,” and “ancestors” to describe the obvious graphical relationships.\n2We use uppercase letters to represent variables or sets of variables, and use corresponding lowercase letters to represent their values (instantiations).\n• Atomic intervention σVi = do(v ∗ i ): The strat-\negy of setting Vi to a fixed value v ∗ i , denoted by do(Vi = v ∗ i ) or simply do(v ∗ i ) in Pearl (2000), such that\nP (vi|pai;σVi = do(v ∗ i )) = δ(vi, v ∗ i ),\nwhere δ(vi, v ∗ i ) is one if vi = v ∗ i and zero otherwise.\n• Conditional intervention σVi = do(g(c)): In general, Vi may be made to respond in a specified way to some set C of previously observed variables, denoted by do(Vi = g(c)) in Pearl (2000), such that\nP (vi|pai;σVi = do(g(c))) = δ(vi, g(c)),\nwhere g(.) is a pre-specified deterministic function and the variables in C can not be descendants of Vi.\n• Random intervention σVi = dC : More generally, we may let Vi take on a random value according to some distribution possibly depending on some set C of previously observed variables such that\nP (vi|pai;σVi = dC) = P ∗(vi|c),\nwhere P ∗(vi|c) is a pre-specified probability distribution and the variables in C can not be descendants of Vi.\nIn a sequential decision problem, we may intervene, at least in principle, in a set of variables X = {Xi} ⊂ V , called control variables or action variables, and are interested in the response of a variable Y , called response variable or outcome variable. Let Z be the rest of observed variables which are often called covariates. The variables are assumed to be ordered in a sequence (L1, X1, . . . , LK , XK , Y ) where Li ⊆ Z are the set of observed covariates after Xi−1 and before Xi. We denote L̄i = (L1, . . . , Li) and X̄i = (X1, . . . , Xi).\nGiven an intervention strategy σX = {σXi}, under a condition called simple stability which says that the observed covariates Li and the outcome Y are independent of how action variables are generated once all earlier observables (L̄i−1, X̄i−1 for Li; X,Z for Y ) are given, Dawid and Didelez (2005) show that the postintervention distribution of Y is identified as\nP (y;σX) = ∑\nx,z\nP (y|x, z) ∏\ni\nP (li|l̄i−1, x̄i−1)\n∏\ni\nP (xi|x̄i−1, l̄i;σXi), (2)\nwhere P (xi|x̄i−1, l̄i;σXi) are determined by the chosen regime and the other quantities can be estimated from\nobservational data. Eq. (2) is known as the G-formula, and has been obtained in [Robins, 1986, Robins, 1987] in the framework of potential response models.\nWhen there are unobserved confounders, the simple stability may not hold. Dawid and Didelez (2005) makes extended stability assumption which essentially is (simple) stability with respect to the extended domain that includes unobserved U variables ignoring the distinction between Z and U . The G-formula (2) no longer holds unless we include unobserved U variables, but then the conditional probabilities involving U variables can no longer be estimated from the data. Sufficient graphical criteria for identifying P (y;σX) are derived. The criteria were obtained by identifying graphical conditions under which the simple stability can be regained such that the G-formula can be used, and by extending the work in [Pearl and Robins, 1995] to dynamic plans."
    }, {
      "heading" : "3 Problem Formulation",
      "text" : "In this paper, we will formulate the sequential plan problem in the framework of causal Bayesian networks. A causal Bayesian network (CBN) consists of a DAG G over a set V = {V1, . . . , Vn} of variables, called a causal diagram. The interpretation of such a graph has two components, probabilistic and causal. The probabilistic interpretation views G as representing conditional independence assertions such that the joint probability function P (v) = P (v1, . . . , vn) factorizes according to Eq. (1). The causal interpretation views the directed edges in G as representing causal influences between the corresponding variables. In this interpretation, the factorization of (1) still holds, but the factors are further assumed to represent autonomous data-generation processes, that is, each conditional probability P (vi|pai) represents a stochastic process by which the values of Vi are chosen in response to the values pai (previously chosen for Vi’s parents), and the stochastic variation of this assignment is assumed independent of the variations in all other assignments. Moreover, each assignment process remains invariant to possible changes in the assignment processes that govern other variables in the system. This modularity assumption enables us to predict the effects of interventions, whenever interventions are described as specific modifications of some factors in the product of (1). We typically assume that every variable Vi can potentially be manipulated by external intervention. So we might think of a CBN as an ID such that each node is (implicitly) pointed to by a corresponding regime/intervention indicator.\nIn a sequential decision problem, we may intervene in a set of action variables X = {Xi} ⊂ V , and are\ninterested in the response of a set of outcome variables Y . Assume that all the variables V are observed and let the rest of covariate variables be Z = {Zi} = V \\ (X ∪ Y ). Given an intervention strategy σX = {σXi}, by modularity assumption, we can predict the effects of σX as\nP (v;σX)\n= ∏\ni\nP (yi|payi) ∏\ni\nP (zi|pazi) ∏\ni\nP (xi|paxi ;σXi),\n(3)\nwhere, by modularity assumption, those conditional probabilities corresponding to unmanipulated variables remain unaltered. We note that Dawid and Didelez’s (2005) simple stability assumption leads to Eq. (3) in the framework of CBNs. We see that, given a CBN, whenever all variables in V are observed, the consequence of an intervention strategy on the outcome variables Y is computed as\nP (y;σX) = ∑\nx,z\n∏\ni\nP (yi|payi) ∏\ni\nP (zi|pazi)\n∏\ni\nP (xi|paxi ;σXi), (4)\nwhere P (xi|paxi ;σXi) are determined by the chosen regime and the other quantities can be estimated from observational data. We note that the G-formula (2) can be reduced to Eq. (4) by using the conditional independence relationships implied by the CBN that each variable is independent of all its non-descendants given its parents.\nIn general we may be concerned with confounding effects due to unobserved influential variables. In the presence of unobserved confounders, the distribution over observed variables can no longer factorize according to (1). Letting V = Y ∪ Z ∪ X and U = {U1, . . . , Un′} stand for the sets of observed and unobserved variables, respectively, the observed probability distribution, P (v), becomes a mixture of products:\nP (v) = ∑\nu\n∏\n{i|Vi∈V }\nP (vi|pavi) ∏\n{i|Ui∈U}\nP (ui|paui).\n(5)\nWe still make modularity assumption in the CBN with unobserved variables, and the effects of an intervention strategy σX on the outcome variables Y can be expressed as\nP (y;σX) = ∑\nx,z,u\n∏\ni\nP (yi|payi) ∏\ni\nP (zi|pazi)\n∏\ni\nP (xi|paxi ;σXi) ∏\ni\nP (ui|paui).\n(6)\nWe note that Dawid and Didelez’s (2005) extended stability assumption leads to Eq. (6) in the framework of CBNs. In (6), the quantities P (yi|payi) and P (zi|pazi) (and P (ui|paui)) may involve elements of U and may not be estimable from data. Then the question of identifiability arises, i.e., whether it is possible to express P (y;σX) as a function of the observed distribution P (v).\nDefinition 1 [Plan Identifiability] A sequential plan is said to be identifiable if P (y;σX) is uniquely computable from the observed distribution P (v)."
    }, {
      "heading" : "4 Identification of Sequential Plans",
      "text" : "First we make the following assumption about the type of interventions we will consider.\nAssumption 1 P (xi|paxi ;σXi) does not depend on the unobserved variable. That is, for conditional intervention σXi = do(g(c)) or random intervention σXi = dC , we require C ⊆ X ∪ Z.\nThis assumption corresponds to Condition 6.6 or 7.2 in [Dawid and Didelez, 2005].\nUnder Assumption 1, Eq. (6) becomes\nP (y;σX) = ∑\nx,z\n∏\ni\nP (xi|paxi ;σXi) ∑\nu\n∏\ni\nP (yi|payi)\n∏\ni\nP (zi|pazi) ∏\ni\nP (ui|paui) (7)\n= ∑\nx,z\n∏\ni\nP (xi|paxi ;σXi)Px(y, z) (8)\nObviously a sufficient condition for P (y;σX) being identifiable is that the causal effect Px(y, z) is identifiable. In particular, a simple sufficient condition for Px(y, z) being identifiable is if all the parents of action (X) variables are observables, which is Condition 6.3 in [Dawid and Didelez, 2005].\nProposition 1 If all the parents of action (X) variables are observables, then P (y;σX) is identifiable [Dawid and Didelez, 2005].\nProof: If all the parents of action (X) variables are observables, then P (xi|paxi) contains no unobserved (U) variables, and Eq. (5) can be written as\nP (v) = ∏\ni\nP (xi|paxi)Px(y, z), (9)\nfrom which we obtain that Px(y, z) is identified as\nPx(y, z) = p(x, y, z)∏ i P (xi|paxi)\n(10)\n= ∏\n{i|Vi∈Y ∪Z}\nP (vi|v̄i), (11)\nwhere we have used the chain rule assuming an order of V variables that is consistent with the DAG and v̄i denotes the V variables ordered ahead of Vi. Hence the sequential plan is identified as\nP (y;σX) = ∑\nx,z\n∏\ni\nP (xi|paxi ;σXi) ∏\n{i|Vi∈Y ∪Z}\nP (vi|v̄i),\n(12)\nwhich is essentially the G-formula (2).\nIn general Px(y, z) being identifiable is not a necessary condition for P (y;σX) being identifiable. Eq. (7) may be simplified in that a factor P (zi|pazi) may be summed out (using\n∑ zi\nP (zi|pazi) = 1) if Zi does not appear in any other factors (graphically, if Zi does not have any children). We can derive stronger identification criterion by summing out as many factors as possible from Eq. (7). Before presenting our result, we first introduce some notation.\nFollowing [Tian and Pearl, 2003], for any observed set S ⊆ V of variables, we define the quantity Q[S] to denote the post-intervention distribution of S under atomic interventions to all other variables:\nQ[S](v) = Pv\\s(s)\n= ∑\nu\n∏\n{i|Vi∈S}\nP (vi|pavi) ∏\n{i|Ui∈U}\nP (ui|paui).\n(13)\nFor convenience, we will often write Q[S](v) as Q[S]. Eq. (7) can be written as\nP (y;σX) = ∑\nx,z\n∏\ni\nP (xi|paxi ;σXi)Q[Y ∪ Z]. (14)\nLet GσX denote the manipulated graph under the intervention strategy σX , which can be constructed from the original causal graph G as follows:\n• For an atomic intervention σXi = do(xi), cut off all the arrows entering Xi;\n• For a conditional intervention σXi = do(gi(ci)) or a random intervention σXi = dCi , cut off all the arrows entering Xi and then add an arrow entering Xi from each variable in Ci.\nBased on Eq. (14), we obtain the following sufficient criterion for identifying P (y;σX).\nTheorem 1 Let ZD be the set of variables in Z that are ancestors of Y in GσX . P (y;σX) is identifiable if the causal effects Q[Y ∪ ZD] = Px,z\\zD (y, zD) is identifiable.\nProof: Let XD be the set of variables in X that are ancestors of Y in GσX . Then all the non-ancestors of Y can be summed out from Eq. (14) leading to P (y;σX) = ∑\nxD,zD\n∏\n{i|Xi∈XD}\nP (xi|paxi ;σXi)Q[Y ∪ ZD]\n(15)\n= ∑\nxD,zD\n∏\n{i|Xi∈XD}\nP (xi|paxi ;σXi)Px,z\\zD (y, zD).\n(16)\nWe conjecture that the condition in Theorem 1 is also necessary. It might appear that Eq. (15) can be further simplified as follows. Let ZσXD be the set of Z variables that appear in the term∏\n{i|Xi∈XD} P (xi|paxi ;σXi) (the set of conditioning variables in the strategy σXD ). Then the term∏ {i|Xi∈XD} P (xi|paxi ;σXi) is a function of XD and ZσXD . Eq. (15) becomes\nP (y;σX) = ∑\nxD,zσXD\n∏\n{i|Xi∈XD}\nP (xi|paxi ;σXi) ∑\nzD\\zσXD\nQ[Y ∪ ZD]\n(17)\n≡ ∑\nxD,zσXD\ng(xD, zσXD ) ∑\nzD\\zσXD\nQ[Y ∪ ZD] (18)\nFrom Eq. (18), P (y;σX) is identifiable if∑ zD\\zσXD Q[Y ∪ ZD] is identifiable, and intuitively, the condition appears to be necessary too, since the term g(xD, zσXD ) is specified externally and no more factors can be summed out (as far as the function g(.) is not independent of any variables in zσXD ). A strict proof of this necessity is still under study.\nOn the other hand, due to the fact that none of the factors corresponding to the variables in ZD \\ ZσXD can be summed out from Q[Y ∪ZD], it has been shown that\n∑ zD\\zσXD Q[Y ∪ ZD] can be identified only via\nidentifying Q[Y ∪ZD] and it is a if and only if condition (Lemma 11 in [Huang and Valtorta, 2006]). So from the point of view of identifying P (y;σX) the reduction from Eq. (15) to Eq. (17) is not necessary.\nWe therefore have reduced the problem of identifying dynamic sequential plans P (y;σX) into that of identifying causal effects Q[Y ∪ ZD] while the latter problem has been solved and complete algorithms are given in [Tian and Pearl, 2003, Shpitser and Pearl, 2006b, Huang and Valtorta, 2006].\nWe demonstrate the application of Theorem 1 and the identification process with an example. Consider the problem of identifying P (y;σX1 , σX2) in Figure 1, which was studied in [Dawid and Didelez, 2005] and is troubling to the methods presented therein. Theorem 1 calls for identifying Q[{Y,Z}] which can be shown to be identifiable. We are given the observational distribution\nP (v) = P (y|x1, x2, z)P (x2)Q[{Z,X1}], (19)\nwhere\nQ[{Z,X1}] = ∑\nu\nP (z|x2, u)P (x1|u)P (u). (20)\nWe want to compute\nP (y;σX1 , σX2)\n= ∑\nx1,x2,z\nP (x1;σX1)P (x2;σX2)P (y|x1, x2, z)Q[{Z}],\n(21)\nwhich calls for computing Q[{Z}]. From Eq. (20), it is clear that\nQ[{Z}] = ∑\nx1\nQ[{Z,X1}]. (22)\nFrom Eq. (19), we obtain\nQ[{Z,X1}] = P (z, x1|x2) (23)\nTherefore Q[{Z}] is identified and we finally obtain\nP (y;σX1 , σX2)\n= ∑\nx1,x2,z\nP (x1;σX1)P (x2;σX2)P (y|x1, x2, z)P (z|x2).\n(24)"
    }, {
      "heading" : "5 Discussion",
      "text" : ""
    }, {
      "heading" : "5.1 Unconditional plans are easier",
      "text" : "In general identifying dynamic plans is more difficult than identifying unconditional plans that involve only atomic interventions. Let an intervention strategy σ′X consist of all atomic interventions. Then the manipulated graph Gσ′\nX is a subgraph of GσX . Let Z ′ D be the\nset of variables in Z that are ancestors of Y in Gσ′ X . Then Z ′D is a subset of ZD. We have\nP (y;σ′X) = Px(y) = ∑\nz′ D\nQ[Y ∪ Z ′D]. (25)\nTherefore identifying Px(y) calls for identifying Q[Y ∪ Z ′D] while P (y;σX) calls for identifying Q[Y ∪ ZD]. Now we have\nQ[Y ∪ Z ′D] = ∑\nzD\\z′D\nQ[Y ∪ ZD] (26)\nThe factors of the variables in ZD\\Z ′ D are summed out from Q[Y ∪ZD] since the variables in ZD \\Z ′ D can be ancestors of Y only through Xi’s. In general, whenever Q[Y ∪ZD] (and therefore P (y;σX)) is identifiable, then Px(y) is identifiable. However, it is possible that Px(y) is identifiable but Q[Y ∪ZD] (and therefore P (y;σX)) is not.\nWe demonstrate this point with an example. Consider the problem of identifying P (y;σX1 , σX2) in Figure 2(a), which was studied in [Pearl and Robins, 1995]. If P (x2|x1, z;σX2) depends on Z, say σX2 = do(g(x1, z)), then ZD = {Z}, and by Theorem 1, to identify P (y;σX1 , σX2) we need to identify Q[{Y,Z}], which can be shown to be not identifiable (by theorems in [Huang and Valtorta, 2006]). More specifically, given the observational distribution\nP (v) = P (x2|x1, z)Q[{X1, Z, Y }], (27)\nwe want to identify\nP (y;σX1 , σX2)\n= ∑\nx1,x2,z\nP (x1;σX1)P (x2|x1, z;σX2)Q[{Y,Z}] (28)\nFrom Eq. (28), we see that if P (x2|x1, z;σX2) depends on Z, then the identifiability of P (y;σX1 , σX2) depends on the identifiability of Q[{Y,Z}]. We therefore conclude that P (y;σX1 , σX2) is not identifiable.\nOn the other hand, if P (x2|x1, z;σX2) is independent of Z, say P (x2|x1, z;σX2) = P\n∗(x2|x1) (or σX2 = do(x2)), then the set ZD of variables in Z that are ancestors of Y in GσX becomes empty (see Figure 2(b)), and, by Theorem 1, the identifiability of P (y;σX1 , σX2) depends on the identifiability of Q[{Y }]. In fact, in this case, Eq. (28) becomes\nP (y;σX1 , σX2 = dX1)\n= ∑\nx1,x2\nP (x1;σX1)P ∗(x2|x1)\n∑\nz\nQ[{Y,Z}]\n= ∑\nx1,x2\nP (x1;σX1)P ∗(x2|x1)Q[{Y }] (29)\nFrom Eq. (27) we obtain\nQ[{X1, Z, Y }] = P (v)/P (x2|x1, z)\n= P (y|x1, x2, z)P (x1, z). (30)\nIt can be shown (or confirmed) that\nQ[{Y }] = ∑ z Q[{X1, Z, Y }]∑\ny,z Q[{X1, Z, Y }]\n= ∑\nz\nP (y|x1, x2, z)P (z|x1). (31)\nWe obtain\nP (y;σX1 , σX2 = dX1)\n= ∑\nx1,x2\nP (x1;σX1)P ∗(x2|x1)\n∑\nz\nP (y|x1, x2, z)P (z|x1).\n(32)\nAnd in particular, the unconditional plan is identified as\nPx1,x2(y) = Q[{Y }] = ∑\nz\nP (y|x1, x2, z)P (z|x1).\n(33)\n5.2 Identification via conditional causal\neffects?\nPearl (2000) has suggested that dynamic sequential plans involving conditional and random interventions\nmay be identified by identifying conditional causal effects of the form Px(y|z). For interventions on a single variable X, we can show [Pearl, 2000, Section 4.2] that\nP (y;σX = do(g(z))) = ∑\nz\nPx(y|z)|x=g(z)P (z),\nand\nP (y;σX = dZ) = ∑\nx,z\nPx(y|z)P ∗(x|z)P (z).\nTherefore it appears that P (y;σX) is identifiable if and only if Px(y|z) is identifiable.\nThis idea was generalized to dynamic sequential plans. Consider a plan involving a sequence of conditional interventions σXi = do(gi(Ci)). Let ZσX = Z ∩ (∪iCi) be the set of conditioning variables in the strategy σX . Pearl (2006) shows that\nP (y;σX) = ∑\nzσX\nPxz (y|zσX )Pxz (zσX ), (34)\nwhere xz are the values attained by X when the conditioning set ZσX takes the values zσX . Pearl then suggests that sequential conditional plans can be identified by identifying conditional causal effects Px(y|z) and Px(z). This motivated the study of the identifiability of conditional causal effects and complete algorithms have been developed in [Tian, 2004, Shpitser and Pearl, 2006a].\nNext we show that although the identification of Pxz (y|zσX ) and Pxz (zσX ) is sufficient for identifying P (y;σX), it is nonetheless not necessary. Rewrite Eq. (34) in the following\nP (y;σX) = ∑\nx,zσX\nδ(xi, gi(Ci))Px(y, zσX ) (35)\n= ∑\nx,zσX\nδ(xi, gi(Ci)) ∑\nz\\zσX\nQ[Y,Z] (36)\nComparing the reduction from Eq. (14) into (17) with the reduction from (14) to (36), we obtain that if XD = X then (36) is equivalent to (17), otherwise Eq. (36) may be further reduced in that more factors could be summed out from Q[Y,Z]. We obtain the following conclusion\n• If all the variables in X are ancestors of Y in GσX , then the sequential plan P (y;σX) can be identified by identifying the causal effects Px(y, zσX ), otherwise it is possible that P (y;σX) is identifiable even if Px(y, zσX ) is not.\nWe demonstrate this point with an example. Consider the problem of identifying P (y;σX) where\nσX = {σX1 = do(g1(Z1)), σX2 = do(g2(Z2)), σX3 = do(g3(Z3))} in Figure 3(a). The graph GσX is shown in Figure 3(b). We have ZD = {Z1, Z3}, and Theorem 1 calls for identifying Q[{Y,Z1, Z3}] which can be shown to be identifiable. On the other hand, Px1x2x3(y, z1, z2, z3) = Q[{Y,Z1, Z2, Z3}] is not identifiable. More specifically, given the observational distribution\nP (v) =P (y|x1, x3, z3)P (x3|x2, z3)P (z1)Q[{X2, Z3}]\nQ[{X1, Z2}], (37)\nwe want to identify\nP (y;σX)\n= ∑\nxi,zi\n∏\ni\nδ(xi, gi(zi))P (y|x1, x3, z3)P (z1)\nQ[{Z3}]Q[{Z2}] (38)\n= ∑\nx1,x3,z1,z3\nδ(x1, g1(z1))δ(x3, g3(z3))P (y|x1, x3, z3)\nP (z1)Q[{Z3}], (39)\nwhere Q[{Z3}] can be identified as\nQ[{Z3}] = ∑\nu2\nP (z3|u2)P (u2) = P (z3). (40)\nWe obtain\nP (y;σX) = ∑\nz1,z3\nP (y|g1(z1), g3(z3), z3)P (z1)P (z3).\n(41)\nOn the other hand,\nPx1x2x3(y, z1, z2, z3)\n= P (y|x1, x3, z3)P (z1)Q[{Z3}]Q[{Z2}]\n= P (y|x1, x3, z3)P (z1)P (z3)Q[{Z2}] (42)\nis not identifiable since Q[{Z2}] is not identifiable. In fact the conditional causal effect\nPx1x2x3(y|z1, z2, z3) = P (y|x1, x3, z3) (43)\nis identifiable but the causal effect\nPx1x2x3(z1, z2, z3) = P (z1)P (z3)Q[{Z2}] (44)\nis not identifiable."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We present a method for identifying dynamic sequential plans. A closed-form expression for the probability of the outcome variables under a dynamic plan can be obtained in terms of the observed distribution, by using the algorithms for identifying causal effects available in the literature."
    }, {
      "heading" : "Acknowledgments",
      "text" : "This research was partly supported by NSF grant IIS0347846."
    } ],
    "references" : [ {
      "title" : "Identifying the consequences of dynamic treatment strategies",
      "author" : [ "A.P. Dawid", "V. Didelez" ],
      "venue" : "Technical report, Department of Statistical Science, University College London, UK",
      "citeRegEx" : "Dawid and Didelez. 2005",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Influence diagrams for causal modelling and inference",
      "author" : [ "A.P. Dawid" ],
      "venue" : "International Statistical Review, 70(2)",
      "citeRegEx" : "Dawid. 2002",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Direct and indirect effects of sequential treatments",
      "author" : [ "V. Didelez", "A.P. Dawid", "S. Geneletti" ],
      "venue" : "Proceedings of the 22nd Annual Conference on Uncertainty in Artifical Intelligence, pages 138–146",
      "citeRegEx" : "Didelez et al.. 2006",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Decision-theoretic foundations for causal reasoning",
      "author" : [ "D. Heckerman", "R. Shachter" ],
      "venue" : "Journal of Artificial Intelligence Research, 3:405–430",
      "citeRegEx" : "Heckerman and Shachter. 1995",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Identifiability in causal bayesian networks: A sound and complete algorithm",
      "author" : [ "Huang", "Valtorta", "2006] Y. Huang", "M. Valtorta" ],
      "venue" : "In Proceedings of the Twenty-First National Conference on Artificial Intelligence,",
      "citeRegEx" : "Huang et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2006
    }, {
      "title" : "Graphical models for causal inference",
      "author" : [ "S. Lauritzen" ],
      "venue" : "O.E. Barndorff-Nielsen, D. Cox, and C. Kluppelberg, editors, Complex Stochastic Systems, chapter 2, pages 67–112. Chapman and Hall/CRC Press, London/Boca Raton",
      "citeRegEx" : "Lauritzen. 2000",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Probabilistic evaluation of sequential plans from causal models with hidden variables",
      "author" : [ "Pearl", "Robins" ],
      "venue" : "Uncertainty in Artificial Intelligence",
      "citeRegEx" : "Pearl and Robins,? \\Q1995\\E",
      "shortCiteRegEx" : "Pearl and Robins",
      "year" : 1995
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems",
      "author" : [ "J. Pearl" ],
      "venue" : "Morgan Kaufmann, San Mateo, CA",
      "citeRegEx" : "Pearl. 1988",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "Causality: Models",
      "author" : [ "J. Pearl" ],
      "venue" : "Reasoning, and Inference. Cambridge University Press, NY",
      "citeRegEx" : "Pearl. 2000",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "A new approach to causal inference in mortality studies with a sustained exposure period – applications to control of the healthy workers survivor effect",
      "author" : [ "J.M. Robins" ],
      "venue" : "Mathematical Modeling, 7:1393–1512",
      "citeRegEx" : "Robins. 1986",
      "shortCiteRegEx" : null,
      "year" : 1986
    }, {
      "title" : "A graphical approach to the identification and estimation of causal parameters in mortality studies with sustained exposure periods",
      "author" : [ "J.M. Robins" ],
      "venue" : "Journal of Chronic Diseases, 40(Suppl 2):139S–161S",
      "citeRegEx" : "Robins. 1987",
      "shortCiteRegEx" : null,
      "year" : 1987
    }, {
      "title" : "Identification of conditional interventional distributions",
      "author" : [ "Shpitser", "Pearl", "2006a] I. Shpitser", "J. Pearl" ],
      "venue" : "Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Shpitser et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Shpitser et al\\.",
      "year" : 2006
    }, {
      "title" : "Identification of joint interventional distributions in recursive semi-markovian causal models",
      "author" : [ "Shpitser", "Pearl", "2006b] I. Shpitser", "J. Pearl" ],
      "venue" : "In Proceedings of the Twenty-First National Conference on Artificial Intelligence,",
      "citeRegEx" : "Shpitser et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Shpitser et al\\.",
      "year" : 2006
    }, {
      "title" : "Causation",
      "author" : [ "P. Spirtes", "C. Glymour", "R. Scheines" ],
      "venue" : "Prediction, and Search. Springer-Verlag, New York",
      "citeRegEx" : "Spirtes et al.. 1993",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Technical Report R-290-L",
      "author" : [ "J. Tian", "J. Pearl. On the identification of causal effects" ],
      "venue" : "Department of Computer Science, University of California, Los Angeles,",
      "citeRegEx" : "Tian and Pearl. 2003",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Identifying conditional causal effects",
      "author" : [ "J. Tian" ],
      "venue" : "Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI)",
      "citeRegEx" : "Tian. 2004",
      "shortCiteRegEx" : null,
      "year" : 2004
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "The simplest action involves fixing the value of Xi to a particular value xi , called atomic intervention and denoted by do(xi ) in [Pearl, 2000], e.",
      "startOffset" : 132,
      "endOffset" : 145
    }, {
      "referenceID" : 6,
      "context" : "Sufficient graphical criteria for the identifiability of unconditional plans are derived in [Pearl and Robins, 1995].",
      "startOffset" : 92,
      "endOffset" : 116
    }, {
      "referenceID" : 0,
      "context" : "Sufficient graphical criteria for the identifiability of dynamic plans are derived in [Dawid and Didelez, 2005].",
      "startOffset" : 86,
      "endOffset" : 111
    }, {
      "referenceID" : 0,
      "context" : "In Section 2, we review the work in [Dawid and Didelez, 2005] and define useful notation.",
      "startOffset" : 36,
      "endOffset" : 61
    }, {
      "referenceID" : 1,
      "context" : ", Vn} of variables that also includes regime indicators as special nodes of their own called decision nodes [Dawid, 2002].",
      "startOffset" : 108,
      "endOffset" : 121
    }, {
      "referenceID" : 7,
      "context" : ", vn) factorizes according to the product [Pearl, 1988] P (v) = ∏",
      "startOffset" : 42,
      "endOffset" : 55
    }, {
      "referenceID" : 2,
      "context" : "Here we will roughly follow the notation used in [Didelez et al., 2006].",
      "startOffset" : 49,
      "endOffset" : 71
    }, {
      "referenceID" : 6,
      "context" : "The criteria were obtained by identifying graphical conditions under which the simple stability can be regained such that the G-formula can be used, and by extending the work in [Pearl and Robins, 1995] to dynamic plans.",
      "startOffset" : 178,
      "endOffset" : 202
    }, {
      "referenceID" : 0,
      "context" : "2 in [Dawid and Didelez, 2005].",
      "startOffset" : 5,
      "endOffset" : 30
    }, {
      "referenceID" : 0,
      "context" : "3 in [Dawid and Didelez, 2005].",
      "startOffset" : 5,
      "endOffset" : 30
    }, {
      "referenceID" : 0,
      "context" : "Proposition 1 If all the parents of action (X) variables are observables, then P (y;σX) is identifiable [Dawid and Didelez, 2005].",
      "startOffset" : 104,
      "endOffset" : 129
    }, {
      "referenceID" : 14,
      "context" : "Following [Tian and Pearl, 2003], for any observed set S ⊆ V of variables, we define the quantity Q[S] to denote the post-intervention distribution of S under atomic interventions to all other variables:",
      "startOffset" : 10,
      "endOffset" : 32
    }, {
      "referenceID" : 0,
      "context" : "Consider the problem of identifying P (y;σX1 , σX2) in Figure 1, which was studied in [Dawid and Didelez, 2005] and is troubling to the methods presented therein.",
      "startOffset" : 86,
      "endOffset" : 111
    }, {
      "referenceID" : 6,
      "context" : "Consider the problem of identifying P (y;σX1 , σX2) in Figure 2(a), which was studied in [Pearl and Robins, 1995].",
      "startOffset" : 89,
      "endOffset" : 113
    } ],
    "year" : 0,
    "abstractText" : "We address the problem of identifying dynamic sequential plans in the framework of causal Bayesian networks, and show that the problem is reduced to identifying causal effects, for which there are complete identification algorithms available in the literature.",
    "creator" : null
  }
}