{"title": "Parsing for Universal Dependencies without training", "abstract": "We present UDP, an unsupervised parsing algorithm for Universal Dependencies (UD) based on  PageRank and a small set of specific dependency head rules. The parser requires no training, and it is competitive with a delexicalized transfer system. UDP offers a linguistically sound unsupervised alternative to cross-lingual UD parsing. It is distinctly robust to domain change across languages.", "id": "151", "reviews": [{"comments": "This paper describes a new deterministic dependency parsing algorithm and\nanalyses its behaviour across a range of languages.\nThe core of the algorithm is a set of rules defining permitted dependencies\nbased on POS tags.\nThe algorithm starts by ranking words using a slightly biased PageRank over a\ngraph with edges defined by the permitted dependencies.\nStepping through the ranking, each word is linked to the closest word that will\nmaintain a tree and is permitted by the head rules and a directionality\nconstraint.\n\nOverall, the paper is interesting and clearly presented, though seems to differ\nonly slightly from Sogaard (2012), \"Unsupervised Dependency Parsing without\nTraining\".\nI have a few questions and suggestions:\n\nHead Rules (Table 1) - It would be good to have some analysis of these rules in\nrelation to the corpus.\nFor example, in section 3.1 the fact that they do not always lead to a\nconnected graph is mentioned, but not how frequently it occurs, or how large\nthe components typically are.\n\nI was surprised that head direction was chosen using the test data rather than\ntraining or development data.\nGiven how fast the decision converges (10-15 sentences), this is not a major\nissue, but a surprising choice.\n\nHow does tie-breaking for words with the same PageRank score work?\nDoes it impact performance significantly, or are ties rare enough that it\ndoesn't have an impact?\n\nThe various types of constraints (head rules, directionality, distance) will\nlead to upper bounds on possible performance of the system.\nIt would be informative to include oracle results for each constraint, to show\nhow much they hurt the maximum possible score.\nThat would be particularly helpful for guiding future work in terms of where to\ntry to modify this system.\n\nMinor:\n\n- 4.1, \"we obtain [the] rank\"\n\n- Table 5 and Table 7 have columns in different orders. I found the Table 7\narrangement clearer.\n\n- 6.1, \"isolate the [contribution] of both\"", "is_meta_review": null, "RECOMMENDATION": "3", "REPLICABILITY": "4", "PRESENTATION_FORMAT": "Poster", "CLARITY": "4", "MEANINGFUL_COMPARISON": "5", "SUBSTANCE": "3", "REVIEWER_CONFIDENCE": "4", "SOUNDNESS_CORRECTNESS": "4", "APPROPRIATENESS": "5", "IMPACT": "2", "ORIGINALITY": "2"}, {"comments": "The authors proposed an unsupervised algorithm for Universal Dependencies that\ndoes not require training. The tagging is based on PageRank for the words and a\nsmall amount of hard-coded rules.\nThe article is well written, very detailed and the intuition behind all prior\ninformation being added to the model is explained clearly.\nI think that the contribution is substantial to the field of unsupervised\nparsing, and the possibilities for future work presented by the authors give\nrise to additional research.", "is_meta_review": null, "RECOMMENDATION": "4", "REPLICABILITY": "5", "PRESENTATION_FORMAT": "Oral Presentation", "CLARITY": "5", "MEANINGFUL_COMPARISON": "5", "SUBSTANCE": "5", "REVIEWER_CONFIDENCE": "4", "SOUNDNESS_CORRECTNESS": "4", "APPROPRIATENESS": "5", "IMPACT": "4", "ORIGINALITY": "4"}, {"comments": "This paper presents a way to parse trees (namely the universal dependency\ntreebanks) by relying only on POS and by using a modified version of the\nPageRank to give more way to some meaningful words (as opposed to stop words).\n\nThis idea is interesting though very closed to what was done in S\u00c3\u00b8gaard\n(2012)'s paper. The personalization factor giving more weight to the main\npredicate is nice but it would have been better to take it to the next level.\nAs far as I can tell, the personalization is solely used for the main predicate\nand its weight of 5 seems arbitrary.\n\nRegarding the evaluation and the detailed analyses, some charts would have been\nbeneficial, because it is sometimes hard to get the gist out of the tables.\nFinally, it would have been interesting to get the scores of the POS tagging in\nthe prediction mode to be able to see if the degradation in parsing performance\nis heavily correlated to the degradation in tagging performance (which is what\nwe expect).\n\nAll in all, the paper is interesting but the increment over the work of\nS\u00c3\u00b8gaard (2012) is small.\n\nSmaller issues:\n-------------------\n\nl. 207 : The the main idea -> The main idea", "is_meta_review": null, "RECOMMENDATION": "3", "REPLICABILITY": "4", "PRESENTATION_FORMAT": "Poster", "CLARITY": "4", "MEANINGFUL_COMPARISON": "3", "SUBSTANCE": "3", "REVIEWER_CONFIDENCE": "4", "SOUNDNESS_CORRECTNESS": "4", "APPROPRIATENESS": "5", "IMPACT": "3", "ORIGINALITY": "2"}]}
