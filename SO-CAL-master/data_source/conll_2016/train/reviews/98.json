{"title": "Delexicalized and Minimally Supervised Parsing on Universal Dependencies", "abstract": "In this paper, we compare delexicalized transfer and minimally supervised parsing techniques on 32 different languages from Universal Dependencies treebank collection. The minimal supervision is in adding handcrafted universal grammatical rules for POS tags. The rules are incorporated into the unsupervised dependency parser in forms of external prior probabilities. We also experiment with learning this probabilities from other treebanks. The average attachment score of our parser is slightly lower then the delexicalized transfer parser, however, it performs better for languages from less resourced language families (non-Indo-European) and is therefore suitable for those, for which the treebanks often do not exist.", "id": "98", "reviews": [{"comments": "This paper presents results on the UD treebanks to test delexicalized transfer\nparsers and an unsupervised parser which is enriched with external\nprobabilities.\n\nThe paper is interesting, but I think it could be improved further.\n\n(5.2) \"McDonald et al. (2011) presented 61.7% of averaged accuracy over 8\nlanguages. On the same languages, our transfer parser on UD reached 70.1%.\"\nMcdonald et al could not use the UD treebanks since they were not available,\nyou should definitely state that this is the case here.\n\nIn footnote 9 you say: \"We used the Malt parser with its default feature set.\nTuning in this specific delexicalized task would probably bring a\nbit better results.\" You are using MaltParser with default settings, why don't\nyou use MaltOptimizer? Optimizing one model would be very easy. \nIn the same way MSTParser could be optimized further.\nIn the same line, why don't you use more recent parsers that produce better\nresults? These parsers have been already applied to universal dependencies with\nthe leave one out setup (see references below). For instance, the authors say\nthat  the unsupervised parser \"performs better for languages from less\nresourced language families (non-Indo-European)\", it would be interesting to\nsee whether this holds with more recent (and cross lingual) parsers.\n\nProbabilities: Why do you use this probabilities? it seems like a random\ndecision (Tables 3-4) (esp 3), at least we need more details or a set of\nexperiments to see whether they make sense or not.\n\nThere are some papers that the authors should take into account.\n\n1. Cross-Lingual Dependency Parsing with Universal Dependencies and Predicted\nPoS Labels\nJ Tiedemann\n2. One model, two languages: training bilingual parsers with harmonized\ntreebanks\nD Vilares, MA Alonso, C G\u00c3\u00b3mez-Rodr\u00c3\u00adguez  (it presents results with\nMaltParser)\n\nAnd for results with more recent parsers (and also delexicalized parsers):\n1. Crosslingual dependency parsing based on distributed representations. \nJiang Guo, Wanxiang Che, David\nYarowsky, Haifeng Wang, and Ting Liu. 2015.  In Proc. of ACL\n\n2. Many languages, one parser\nW Ammar, G Mulcaire, M Ballesteros, C Dyer, NA Smith\n\n-Minor points:\n I don't think we need Table 1 and Table 2, this could be solved with a\nfootnote to the UD website. Perhaps Table 2 should be included due to the\nprobabilities, but Table 1 definitely not.", "is_meta_review": null, "RECOMMENDATION": "2", "REPLICABILITY": "4", "PRESENTATION_FORMAT": "Poster", "CLARITY": "4", "MEANINGFUL_COMPARISON": "3", "SUBSTANCE": "2", "REVIEWER_CONFIDENCE": "4", "SOUNDNESS_CORRECTNESS": "4", "APPROPRIATENESS": "5", "IMPACT": "2", "ORIGINALITY": "3"}, {"comments": "This paper evaluates a minimally supervised dependency parser -- a version of\nthe DMV model with manually set prior probabilities -- on (most of) the\ntreebanks from Universal Dependencies, v1.2. It reports results that are on\naverage slightly lower than a couple of delexicalized transfer parsers but\n(sometimes substantially) better on a few non-Indo-European languages.\n\nThe idea of biasing an otherwise unsupervised parser with some basic\n\"universal\" rules have been used a number of times before in the literature, so\nthe main value of the present paper is an empirical evaluation of this approach\non the new UD treebanks. However, the approach and evaluation leaves some \nquestions unanswered.\n\nFirst of all, I want to know why only unlabeled parsing is considered. This may\nhave been appropriate (or at least necessary) before dependency labels were\nstandardised, but the whole point of UD is to give a uniform analysis in terms\nof typed dependencies, and any parsing approach that does not take this into\naccount seems misguided. And since the approach is based on manually defined\nuniversal rules, it would have been easy enough to formulate rules for labeled\ndependencies.\n\nSecond, I would like to know more about how the prior probabilities were set\nor, in other words, what universal grammar they are meant to encode and how.\nWere alternatives tested and, if so, how were they evaluated? In the present\nversion of the paper, we are just presented with a bunch of numbers without any\nexplanation or justification except that they are \u00e2\u0080\u009cbased on UD annotation\nstyle\u00e2\u0080\u009d.\n\nThird, one of the main claims of the paper is that the unsupervised system\nworks better for non-Indo-European languages. This seems to be supported by the\nraw numbers, but what exactly is going on here? What types of dependencies are\nhandled better by the unsupervised system? Even though a full error analysis\nwould be out of scope in a short paper, an analysis of a small sample could be\nreally interesting.\n\nFinally, the comparison to the delexicalized transfer parsers seems to be\nbiased by a number of factors. Restricting it to unlabeled dependencies is one\nsuch thing, since the delexicalized parser could easily have produced labeled\ndependencies. Another thing is the amount of training data, which was\narbitrarily restricted to 10,000 tokens per treebank. Finally, it seems that\nthe delexicalized parsers were not properly tuned. Just replacing word forms\nand lemmas by underscores without revising the feature models is not likely to\nproduce optimal results.", "is_meta_review": null, "RECOMMENDATION": "3", "REPLICABILITY": "3", "PRESENTATION_FORMAT": "Poster", "CLARITY": "4", "MEANINGFUL_COMPARISON": "4", "SUBSTANCE": "4", "REVIEWER_CONFIDENCE": "4", "SOUNDNESS_CORRECTNESS": "3", "APPROPRIATENESS": "5", "IMPACT": "2", "ORIGINALITY": "2"}]}
