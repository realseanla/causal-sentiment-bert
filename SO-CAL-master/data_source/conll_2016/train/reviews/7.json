{"title": "Random Positive-Only Projections: PPMI-Enabled Incremental Semantic Space Construction", "abstract": "We introduce positive-only projection (PoP), a novel technique for constructing semantic spaces and word embeddings. The PoP method is based on random projections. Hence, it is highly scalable and computationally efficient. In contrast to previous methods that use random projection matrices R with the expected value of 0 (i.e., E(R)=0), the proposed method uses R with E(R)>0. We use Kendall's tau_b distance to compute vector similarities in the resulting non-Gaussian spaces. Most importantly, since E(R), weighting methods such as positive pointwise mutual information (PPMI) can be applied to PoP-constructed spaces after their construction for efficiently transferring PoP embeddings onto spaces that are discriminative for semantic similarity assessments. Our PoP-constructed models, combined with PPMI, achieve an average score of 0.75 in the MEN relatedness test, which is comparable to results obtained by state-of-the-art top-performing algorithms.", "id": "7", "reviews": [{"comments": "I am buying some of the motivation: the proposed method is much faster to train\nthan it is to train a neural network. Also, it keeps some properties of the\ndistribution when going to lower dimensionality. \n\nHowever, I am not convinced why it is so important for vectors to be\ntransformable with PPMI.\n\nMost importantly, there is no direct comparison to related work.\n\nDetailed comments:\n\n- p.3: The definition of Kendall's tau that the authors use is strange. This is\nNOT the original formula; I am not sure what it is and where it comes from.\n\n- p.3: Why not use Spearman correlation as is standard in semantic tasks (and\nas teh authors do at evaluation time)?\n\n- The datasets chosen for evaluation are not the standard ones for measuring\nsemantic relatedness that the NLP community prefers. It is nice to try other\nsets, but I would recommend to also include results on the standard ones.\n\n- I can only see two lines on Figure 1. Where is the third line?\n\n- There is no direct comparison to related work, just a statement that \n\nSome typos:\n\n- large extend -- extent", "is_meta_review": null, "RECOMMENDATION": "2", "REPLICABILITY": "3", "PRESENTATION_FORMAT": "Poster", "CLARITY": "3", "MEANINGFUL_COMPARISON": "2", "SUBSTANCE": "3", "REVIEWER_CONFIDENCE": "4", "SOUNDNESS_CORRECTNESS": "3", "APPROPRIATENESS": "5", "IMPACT": "2", "ORIGINALITY": "3"}, {"comments": "The paper presents a positive-only projection (PoP) word embedding method. This\nis a random projection method with a random projection matrix whose expected\nvalue is positive. The authors argue that this enables the application of PPMI\nwhich is not possible with an expected value of 0 and that being a random\nprojection method, their computation is efficient.\n\nMy main reservation about this paper has to do with its clarity. Particularly:\n\n1. I could not understand the core difference between the method proposed in\nthe paper and previous random projection methods. Hence, I could not understand\nhow (and whether) the advantages the authors argue to achieve hold.\n\n2. It was hard to follow the arguments of the paper starting from the\nintroduction. \n\n3. Some of the arguments of the paper are not supported: \n\n- Line 114: Sentence starts with \"in addition\"\n\n- Line 137: Sentence starts with \"Since\"\n\n- Line 154: Sentence starts with \"thus\"\n\n4. While I have worked on vector space modeling (who hasn't ?), I am not an\nexpert to random projections and have not used them in my research. It was hard\nfor me to understand the logic behind this research avenue from the paper. I\nbelieve that a paper should be self contained and possible to follow by people\nwith some experience in the field.\n\n5. The paper has lots of English mistakes (86: \"To a large extend\", 142: \"such\nPPMI\").\n\nIn addition, I cannot see why the paper is evaluating only on MEN. There are a\ncouple of standard benchmarks (MEN, WordSeim, SimLex and a couple of others) -\nif you present a new method, I feel that it is insufficient to evaluate only on\none dataset unless you provide a good justification.\n\nI recommend that the authors will substantially improve the presentation in the\npaper and will resubmit to another conference.", "is_meta_review": null, "RECOMMENDATION": "2", "REPLICABILITY": "3", "PRESENTATION_FORMAT": "Oral Presentation", "CLARITY": "2", "MEANINGFUL_COMPARISON": "4", "SUBSTANCE": "4", "REVIEWER_CONFIDENCE": "3", "SOUNDNESS_CORRECTNESS": "3", "APPROPRIATENESS": "5", "IMPACT": "3", "ORIGINALITY": "4"}]}
