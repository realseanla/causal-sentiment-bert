{"reviews": [{"IMPACT": "4", "SUBSTANCE": "3", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "- Strengths: The idea to investigate the types of relations between lexical\nitems is very interesting and challenging. The authors make a good argument why\ngoing beyond analogy testing makes sense.  \n\n- Weaknesses: The paper does not justify or otherwise contextualize the choice\nof clustering for evaluation, rather than using a classification task, despite\nthe fact that classification tasks are more straightforward to evaluate. No\nattempt is being made to explain the overall level of the results. How well\nwould humans do on this task (given only the words, no context)?\n\n- General Discussion:\n\nI have read the authors' response.", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "2"}, {"IMPACT": "4", "SUBSTANCE": "2", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Poster", "comments": "This paper investigates the application of distributional vectors of meaning in\ntasks that involve the identification of semantic relations, similar to the\nanalogical reasoning task of Mikolov et al. (2013): Given an expression of the\nform \u201cX is for France what London is for the UK\u201d, X can be approximated by\nthe simple vector arithmetic operation London-UK+France. The authors argue that\nthis simple method can only capture very specific forms of analogies, and they\npresent a measure that aims at identifying a wider range of relations in a more\neffective way.\n\nI admit I find the idea of a single vector space model being able to capture a\nnumber of semantic relationships and analogies rather radical and infeasible.\nAs the authors mention in the paper, a number of studies already suggest for\nthe opposite. The reason is quite simple: behind all these models lies (some\nform of) the distributional hypothesis (words in similar contexts have similar\nmeanings), and this poses certain limitations in their expressive abilities;\nfor example, words like \u201cbig\u201d and \u201csmall\u201d will always be considered as\nsemantically similar from a vector perspective (although they express opposite\nmeanings), since they occur in similar contexts. So I cannot see how the\nexample given in Figure 1 is relevant to the very nature of vector spaces (or\nto any other semantic model for that matter!): there is a certain analogy\nbetween \u201cman-king\u201d, and \u201cwoman-queen\u201d, but asking from a word space to\ncapture \u201chas-a\u201d relationships of the form \u201cowl-has-claws\u201d, hence\n\u201chospital-has-walls\u201d, doesn\u2019t make much sense to me.\n\nThe motivation behind the main proposal of the paper (a similarity measure that\ninvolves a form of cross-comparison between vectors of words and vectors\nrepresenting the contexts of the words) is not clearly explained. Further, the\nmeasure is tested on the relation categories of the SemEval 2010 task with\nrather unsatisfactory results; in almost all cases, a simple baseline that\ntakes into account only partial similarities between the tested word pairs\npresent very high performance, with a difference from the best-performing model\nwhich seems to me statistically insignificant. So from both a methodological\nand an experimental perspective, the paper has weaknesses, and in its current\nform seems to describe work in progress;  as such I am inclined against its\npresentation in ACL.\n\n(Formatting issue: The authors use the LaTeX styles for ACL 2016 \u2014 this\nshould be fixed in case the paper is accepted).\n\nAUTHORS RESPONSE\n================\nThank you for the clarifications. I am still not comfortable with the idea of a\nmetric or a vector space that tries to capture both semantic and relational\nsimilarity, and I think you don't present enough experimental evidence that\nyour method works. I have to agree with one of the other reviewers that a more\nappropriate format for this work would be a short paper.", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "2", "CLARITY": "3", "REVIEWER_CONFIDENCE": "4"}, {"IMPACT": "4", "SUBSTANCE": "1", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Poster", "comments": "This paper presents a comparison of several vector combination techniques on\nthe task of relation classification.\n\n- Strengths:\n\nThe paper is clearly written and easy to understand.\n\n- Weaknesses:\n\nMy main complaint about the paper is the significance of its contributions. I\nbelieve it might be suitable as a short paper, but certainly not a full-length\npaper.\n\nUnfortunately, there is little original thought and no significantly strong\nexperimental results to back it up. The only contribution of this paper is an\n'in-out' similarity metric, which is itself adapted from previous work. The\nresults seem to be sensitive to the choice of clusters and only majorly\noutperforms a very naive baseline when the number of clusters is set to the\nexact value in the data beforehand.\n\nI think that relation classification or clustering from semantic vector space\nmodels is a very interesting and challenging problem. This work might be useful\nas an experimental nugget for future reference on vector combination and\ncomparison techniques, as a short paper. Unfortunately, it does not have the\nsubstance to merit a full-length paper.", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "2", "CLARITY": "4", "REVIEWER_CONFIDENCE": "4"}], "abstract": "Word embeddings are used with success for a variety of tasks involving lexical semantic similarities between individual words. Using unsupervised methods and just cosine similarity, encouraging results were obtained for analogical similarities. In this paper, we explore the potential of pre-trained word embeddings to identify generic types of semantic relations in an unsupervised experiment. We propose a new relational similarity measure based on the combination of word2vec's CBOW input and output vectors which outperforms concurrent vector representations, when used for unsupervised clustering on SemEval 2010 Relation Classification data.", "histories": [], "id": 563, "title": "Exploring Vector Spaces for Semantic Relations"}
