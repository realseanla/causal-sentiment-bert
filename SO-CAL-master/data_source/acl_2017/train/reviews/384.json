{"reviews": [{"IMPACT": "3", "SUBSTANCE": "2", "APPROPRIATENESS": "2", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "- Strengths:\n - the model if theoretically solid and motivated by formal semantics. \n\n- Weaknesses:\n\n - The paper is about is-a relation extraction but the majority of literature\nabout taxonomization is not referenced in the paper, inter alia:\n\nFlati Tiziano, Vannella Daniele, Pasini Tommaso, Navigli Roberto.\n2016. MultiWiBi: The multilingual Wikipedia bitaxonomy project.\n\nSoren Auer, Christian Bizer, Georgi Kobilarov, Jens \u00a8\nLehmann, Richard Cyganiak, and Zachary Ive.\n2007. DBpedia: A nucleus for a web of open data.\n\nGerard de Melo and Gerhard Weikum. 2010. MENTA:\nInducing Multilingual Taxonomies from Wikipedia.\n\nZornitsa Kozareva and Eduard H. Hovy. 2010. A\nSemi-Supervised Method to Learn and Construct\nTaxonomies Using the Web. \n\nVivi Nastase, Michael Strube, Benjamin Boerschinger,\nCaecilia Zirn, and Anas Elghafari. 2010. WikiNet:\nA Very Large Scale Multi-Lingual Concept Network.\n\nSimone Paolo Ponzetto and Michael Strube. 2007.\nDeriving a large scale taxonomy from Wikipedia.\n\nSimone Paolo Ponzetto and Michael Strube. 2011.\nTaxonomy induction based on a collaboratively built\nknowledge repository. \n\nFabian M. Suchanek, Gjergji Kasneci, and Gerhard\nWeikum. 2008. YAGO: A large ontology from\nWikipedia and WordNet. \n\nPaola Velardi, Stefano Faralli, and Roberto Navigli.\n2013. OntoLearn Reloaded: A graph-based algorithm\nfor taxonomy induction. \n\n - Experiments are poor, they only compare against \"Hearst patterns\" without\ntaking into account the works previously cited.\n\n- General Discussion:\n The paper is easy to follow and the supplementary material is also well\nwritten and useful, however the paper lack of references of is a relation\nextraction and taxonomization literature. The same apply for the experiments.\nIn fact no meaningful comparison is performed and the authors not even take\ninto account the existence of other systems (more recent than hearst patterns).\n\nI read authors answers but still i'm not convinced that they couldn't perform\nmore evaluations. I understand that they have a solid theoretical motivation\nbut still, i think that comparison are very important to asses if the\ntheoretical intuitions of the authors are confirmed also in practice. While\nit's true that all the works i suggested as comparison build taxonomies, is\nalso true that a comparison is possible considering the edges of a taxonomy.\n\nAnyway, considering the detailed author answer and the discussion with the\nother reviewer i can rise my score to 3 even if i still think that this paper\nis poor of experiments and does not frame correctly in the is-a relation\nextraction / taxonomy building literature.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "3", "CLARITY": "4", "REVIEWER_CONFIDENCE": "5"}, {"IMPACT": "3", "SUBSTANCE": "3", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "- Strengths:\n\nThis paper presents an approach for fine-grained IsA extraction by learning\nmodifier interpretations. The motivation of the paper is easy to understand and\nthis is an interesting task. In addition, the approach seems solid in general\nand the experimental results show that the approach increases in the number of\nfine-grained classes that can be populated.\n\n- Weaknesses:\n\nSome parts of the paper are hard to follow. It is unclear to me why D((e, p,\no)) is multiplied by w in Eq (7) and why the weight for e in Eq. (8) is\nexplained as the product of how often e has been observed with some property\nand the weight of that property for the class MH. In addition, it also seems\nunclear how effective introducing compositional models itself is in increasing\nthe coverage. I think one of the major factors of the increase of the coverage\nis the modifier expansion, which seems to also be applicable to the baseline\n'Hearst'. It would be interesting to see the scores 'Hearst' with modifier\nexpansion.\n\n- General Discussion:\n\nOverall, the task is interesting and the approach is generally solid. However,\nsince this paper has weaknesses described above, I'm ambivalent about this\npaper.\n\n- Minor comment:\n\nI'm confused with some notations. For example, it is unclear for me what 'H'\nstands for. It seems that 'H' sometimes represents a class such as in (e, H)\n(- O, but sometimes represents a noun phrase such as in (H, p, N, w) (- D. Is\nmy\nunderstanding correct?\n\nIn Paragraph \"Precision-Recall Analysis\", why the authors use area under the\nROC curve instead of area under the Precision-Recall curve, despite the\nparagraph title \"Precision-Recall Analysis\"?\n\n- After reading the response:\n\nThank you for the response. I'm not fully satisfied with the response as to the\nmodifier expansion. I do not think the modifier expansion can be applied to\nHearst as to the proposed method. However, I'm wondering whether there is no\nway to take into account the similar modifiers to improve the coverage of\nHearst. I'm actually between 3 and 4, but since it seems still unclear how\neffective introducing compositional models itself is, I keep my recommendation\nas it is.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "3", "CLARITY": "3", "REVIEWER_CONFIDENCE": "2"}, {"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "- strengths\nThis is a novel approach to modeling the compositional structure of complex\ncategories that maintains a set theoretic interpretation of common nouns and\nmodifiers, while also permitting a distributional interpretation of head\nmodification. The approach is well motivated and clearly defined and the\nexperiments show that show that this decomposed representation can improve upon\nthe Hearst-pattern derived IsA relations upon which it is trained in terms of\ncoverage.\n\n- weaknesses\nThe experiments are encouraging. However, it would be nice to see ROC curves\nfor the new approach alone, not in an ensemble with Hearst patterns. Table 5\ntells us that Mods_I increases coverage at the cost of precision and Figure 2\ntells us that Mods_I matches Hearst pattern precision for the high precision\nregion of the data. However, neither of these tell us whether the model can\ndistinguish between the high and low precision regions, and the ROC curves\n(which would tell us this) are only available for ensembled models.\n\nI believe that Eqn. 7 has an unnecessary $w$ since it is already the case that\n$w=D(\\rangle e, p, o \\langle)$.\n\n- discussion\nOverall, this is a nice idea that is well described and evaluated. I think this\npaper would be a good addition to ACL.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "3"}], "abstract": "We present a method for populating fine-grained classes (e.g., \u201c1950s American jazz musicians\u201d) with instances (e.g., Charles Mingus ). While state-of-the-art methods tend to treat class labels as single lexical units, the proposed method considers each of the individual modifiers in the class label relative to the head. An evaluation on the task of reconstructing Wikipedia category pages demonstrates a >10 point increase in AUC, over a strong baseline relying on widely-used Hearst patterns.", "histories": [], "id": "384", "title": "Identifying 1950s American Jazz Musicians: Fine-Grained IsA Extraction via Modifier Composition"}
