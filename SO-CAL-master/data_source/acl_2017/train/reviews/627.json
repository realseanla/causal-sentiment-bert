{"reviews": [{"IMPACT": "3", "SUBSTANCE": "3", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "5", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "This paper presents a dialogue agent where the belief tracker and the dialogue\nmanager are jointly optimised using the reinforce algorithm. It learns from\ninteraction with a user simulator. There are two training phases. The first is\nan imitation learning phase where the system is initialised using supervising\nlearning from a rule-based model. Then there is a reinforcement learning phase\nwhere the system has jointly been optimised using the RL objective.\n\n- Strengths: This paper presents a framework where a differentiable access to\nthe KB is integrated in the joint optimisation. This is the biggest\ncontribution of the paper. \n\n- Weaknesses: Firstly, this is not a truly end-to-end system considering the\nresponse generation was handcrafted rather than learnt. Also, their E2E model\nactually overfits to the simulator and performs poorly in human evaluation.\nThis begs the question whether the authors are actually selling the idea of E2E\nlearning or the soft-KB access. The soft-KB access actually brings consistent\nimprovement, however the idea of end-to-end learning not so much. The authors\ntried to explain the merits of E2E in Figure 5 but I also fail to see the\ndifference. In addition, the authors didn't motivate the reason for using the\nreinforce algorithm which is known to suffer from high variance problem. They\ndidn't attempt to improve it by using a baseline or perhaps considering the\nnatural actor-critic algorithm which is known to perform better.\n\n- General Discussion: Apart from the mentioned weaknesses, I think the\nexperiments are solid and this is generally an acceptable paper. However, if\nthey crystallised the paper around the idea which actually improves the\nperformance (the soft KB access) but not the idea of E2E learning the paper\nwould be better.", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "4", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "4", "REVIEWER_CONFIDENCE": "4"}], "abstract": "This paper proposes KB-InfoBot - a multi-turn dialogue agent which helps users search Knowledge Bases (KBs) without composing complicated queries. Such goal-oriented dialogue agents typically need to interact with an external database to access real-world knowledge. Previous systems achieved this by issuing a symbolic query to the KB to retrieve entries based on their attributes. However, such symbolic operations break the differentiability of the system and prevent end-to-end training of neural dialogue agents. In this paper, we address this limitation by replacing symbolic queries with an induced ``soft'' posterior distribution over the KB that indicates which entities the user is interested in. Integrating the soft retrieval process with a reinforcement learner leads to higher task success rate and reward in both simulations and against real users. We also present a fully neural end-to-end agent, trained entirely from user feedback, and discuss its application towards personalized dialogue agents.", "histories": [], "id": 627, "title": "Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access"}
