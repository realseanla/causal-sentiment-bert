{"reviews": [{"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "Dear Authors\n\nthanks for replying to our review comments, which clarifies some detail\nquestions. I appreciate your promise to publish the code, which will be very\nhelpful to other researchers. \n\nBased on this, i increased my overall score to 4. \n\nStrengths:\n- well-written\n- extensive experiments\n- good results\n\n- Weaknesses:\n- nothing ground-breaking, application of existing technologies\n- code not available\n- results are as could be expected\n\n- General Discussion:\n- why didn't you use established audio features such as MFCCs?\n\n- Minor Details:\n- L155 and other places: a LSTM -> an LSTM\n- L160, L216 and other Places: why are there hyphens (-) after the text?\n- L205: explanation of convolution is not clear\n- Table1 should appear earlier, on page 2 already cited\n- L263: is 3D-CNN a standard approach in video processing? alternatives?\n- L375, 378: the ^ should probably positioned above the y\n- L380: \"to check overfitting\" -> did you mean \"to avoid\"?\n- L403, 408..: put names in \" \" or write them italic, to make it easier to\nrecognize them\n- L420: a SVM -> an SVM\n- L448: Output ... are -> wrong numerus, either \"Outputs\", or use \"is\" \n- L489: superflous whitespace after \"layer\"\n- L516, 519: \"concatenation\" should not be in a new line\n- L567: why don't you know the exact number of persons?\n- L626: remove comma after Since\n- L651: doesnt -> does not \n- L777: insert \"hand, the\" after other\n- References: need some cleanup: L823 superflous whitespace, L831 Munich, L860\nwhat is ACL(1)?, L888 superflous ), L894 Volume, L951 superflous new lines,\nL956 indent Linguistics properly", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "3"}], "abstract": "Multimodal sentiment analysis is a developing area of research, which involves the identification of sentiments in videos. Current research considers utterances as independent entities, i.e., ignores the interdependencies and relations among the utterances of a video. In this paper, we propose a LSTM-based model that enables utterances to capture contextual information from their surroundings in the same video, thus aiding the classification process. Our method shows 5-10% performance improvement over the state of the art and high robustness to generalizability.", "histories": [], "id": "182", "title": "Context-Dependent Sentiment Analysis in User-Generated Videos"}
