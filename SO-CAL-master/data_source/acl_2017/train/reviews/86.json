{"reviews": [{"IMPACT": "3", "SUBSTANCE": "5", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "Summary: The paper proposes a neural model for predicting Python syntax trees\nfrom text descriptions. Guided by the actual Python grammar, the model\ngenerates tree nodes sequentially in a depth-first fashion. Key ideas include\ninjecting the information from the parent node as part of the LSTM input, a\npointer network for copying the terminals, and unary closure which collapses\nchains of unary productions to reduce the tree size. The model is evaluated on\nthree datasets from different domains and outperforms almost all previous work.\n\nStrengths:\n\nThe paper is overall very well-written. The explanation of system is clear, and\nthe analysis is thorough.\n\nThe system itself is a natural extension of various ideas. The most similar\nwork include tree-based generation with parent feeding (Dong and Lapata, 2016)\nand various RNN-based semantic parsing with copy mechanism (Jia and\nLiang, 2016; Ling et al., 2016). [The guidance of parsing based on grammar is\nalso explored in Chen Liang et al., 2016 (https://arxiv.org/abs/1611.00020)\nwhere a code-assist system is used to ensure that the code\nis valid.] Nevertheless, the model is this paper stands out as it is able to\ngenerate much longer and more complex programs than most previous work\nmentioned. \n\nWeaknesses:\n\nThe evaluation is done on code accuracy (exact match) and BLEU score. These\nmetrics (especially BLEU) might not be the best metrics for evaluating the\ncorrectness of programs. For instance, the first example in Table 5 shows that\nwhile the first two lines in boxes A and B are different, they have the same\nsemantics. Another example is that variable names can be different. Evaluation\nbased on what the code does (e.g., using test cases or static code analysis)\nwould be more convincing.\n\nAnother point about evaluation: other systems (e.g., NMT baseline) may generate\ncode with syntactic error. Would it be possible to include the result on the\nhighest-scoring well-formed code (e.g., using beam search) that these baseline\nsystems generate? This would give a fairer comparison since these system can\nchoose to prune malformed code.\n\nGeneral Discussion:\n\n* Lines 120-121: some approaches that use domain-specific languages were also\nguided by a grammar. One example is Berant and Liang, 2014, which uses a pretty\nlimited grammar for logical forms (Table 1). In addition to comparing to that\nline of work, emphasizing that the grammar in this paper is much larger than\nmost previous work would make this work stronger.\n\n* Lines 389-397: For the parent feeding mechanism, is the child index being\nused? In other words, is p_t different when generating a first child versus a\nsecond child? In Seq2Tree (Dong and Lapata, 2016) the two non-terminals would\nhave different hidden states.\n\n* Line 373: Are the possible tokens embedded? Is it assumed that the set of\npossible tokens is known beforehand?\n\n* The examples in the appendix are nice.\n\n---\n\nI have read the author response.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "4"}, {"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "This paper presents a method for translating natural language descriptions into\nsource code via a model constrained by the grammar of the programming language\nof the source code.  I liked this paper - it's well written, addresses a hard\nand interesting problem by taking advantage of inherent constraints, and shows\nsignificant performance improvements. \n\nStrengths:\n- Addresses an interesting and important problem space. \n- Constraints inherent to the output space are incorporated well into the\nmodel. \n- Good evaluation and comparisons; also showing how the different aspects of\nthe model impact performance.\n- Clearly written paper.\n\nWeaknesses:\n- My primary and only major issue with the paper is the evaluation metrics.\nWhile accuracy and BLEU4 are easy to compute, I don't think they give a\nsufficiently complete picture.                          Accuracy can easily miss\ncorrectly\ngenerated\ncode because of trivial (and for program functionality, inconsequential)\nchanges.  You could get 0% accuracy with 100% functional correctness.  As for\nBLEU, I'm not sure how well it evaluates code where you can perform significant\nchanges (e.g., tree transformations of the AST) without changing functionality.\n I understand why BLEU is being used, but it seems to me to be particularly\nproblematic given its token level n-gram evaluation.  Perhaps BLEU can be\napplied to the ASTs of both reference code and generated code after some level\nof normalization of the ASTs?  What I would really like to see is an evaluation\ntesting for functional equivalence of reference and generated code. \nUnderstandably this is difficult since test code will have to be written for\neach reference.  However, even if this is done for a random (reasonably small)\nsubsample of the datasets, I think it would give a much more meaningful\npicture. \n\nMinor issues:\n- Page 2, para 2: \"structural information helps to model information flow\nwithin the network\": by \"network\", do you mean the AST?\n\n- Section 4.2.1, Action Embedding: Are the action embedding vectors in W_R and\nW_G simply one-hot vectors or do you actually have a non-trivial embedding for\nthe actions?  If so, how is it computed?  If not, what is the difference\nbetween the vectors of W_R and e(r) in equation 4?\n\n- Section 5.2, Preprocessing:  If you replace quoted strings in the\ndescriptions for the DJANGO dataset, how are cases where those strings need to\nbe copied into the generated code handled?  It is also mentioned (in the\nsupplementary material) that infrequent words are filtered out.  If so, how do\nyou handles cases where those words describe the variable name or a literal\nthat needs to be in the code?\n\nI have read the author response.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "4", "REVIEWER_CONFIDENCE": "4"}, {"IMPACT": "3", "SUBSTANCE": "5", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "- Strengths:\n\nThe approach proposed in the paper seems reasonable, and the experimental\nresults make the approach seem promising. There are two features of the \napproach. One feature is that the approach is for general-purpose programming\nlanguages. It might be applicable to Java, C++, etc. However, proof \nis still needed. Another feature is its data-driven syntactic neural model,\nwhich is described in Section 3 (together with Section 4 I think). \nBy the neural model, it brings around 10% improvement over another same-purpose\napproach LPN in accuracy (according to the experimental data). \nOverall, this is nice work with clear motivation, methodology, data analysis,\nand well-organized presentation.\n\n- Weaknesses:\n\n1. At Line 110, the authors mentioned hypothesis space. I did not know what it\nmeans until I read the supplementary materials. Because such materials \nwill not be included in the full paper, in my opinion it is better to give some\nexplanation on hypothesis space. \n\n2. Section 3 introduces the grammar model and Section 4 describes Action\nprobability estimation. My understanding is that the latter is a part of the\nformer. The two section titles do not reflect this relation. At least Section 3\ndoes not explain all about the grammar model. \n\n3. About the experimental data, I'm wondering how the authors train their model\nbefore doing the experiments. How many datasets are used. Is it true that \nmore the model get trained, more accuracy can be obtained?  How about the\nefficiency of the two approaches, the one in the paper and LPN?   \n\n4. Are there differences between the neural network-based approaches that are\nused for code generation of general-purpose language and those of domain\nspecific ones? \n\n5. The authors claim that their approach scale up to generation of complex\nprograms. I did not find any argument in the paper to backup this conclusion. \n\nMinor comments:\n\nLine 117: The underlying syntax => the syntax of which language? (NL or PL?)\nLine 148: Are there any constraints on x? \nLine 327: The decoder uses a RNN => The decoder uses an RNN?\nReference:  format is inconsistent\n\n- General Discussion:\n\nThis paper proposes a data-driven syntax-based neural network model for code\ngeneration in general-purpose programming langauge, i.e., Python. \nThe main idea of the approach is first to generate a best-possible AST using a\nprobabilistic grammar model for a given statement in natural language, and\nthen ecode AST into surce code using deterministic generation tools. Generating\ncode from an AST is relatively easy. The key point is the first step. \nExperimental results provided in the paper show the proposed approach\noutperform some other state-of-the-art approaches.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "4"}], "abstract": "We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing data-driven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches.", "histories": [], "id": "86", "title": "A Syntactic Neural Model for General-Purpose Code Generation"}
