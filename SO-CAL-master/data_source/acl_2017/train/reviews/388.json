{"reviews": [{"IMPACT": "3", "SUBSTANCE": "5", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "This paper describes interesting and ambitious work: the automated conversion\nof Universal Dependency grammar structures into [what the paper calls] semantic\nlogical form representations.  In essence, each UD construct is assigned a\ntarget construction in logical form, and a procedure is defined to effect the\nconversion, working \u2018inside-out\u2019 using an intermediate form to ensure\nproper nesting of substructures into encapsulating ones.  Two evaluations are\ncarried out: comparing the results to gold-standard lambda structures and\nmeasuring the effectiveness of the resulting lambda expressions in actually\ndelivering the answers to questions from two QA sets.  \n\nIt is impossible to describe all this adequately in the space provided.  The\nauthors have taken some care to cover all principal parts, but there are still\nmany missing details.  I would love to see a longer version of the paper! \nParticularly the QA results are short-changed; it would have been nice to learn\nwhich types of question are not handled, and which are not answered correctly,\nand why not.  This information would have been useful to gaining better insight\ninto the limitations of the logical form representations.  \n\nThat leads to my main concern/objection.  This logical form representation is\nnot in fact a \u2018real\u2019 semantic one.                          It is, essentially, a\nrather\nclose\nrewrite of the dependency structure of the input, with some (good) steps toward\n\u2018semanticization\u2019, including the insertion of lambda operators, the\nexplicit inclusion of dropped arguments (via the enhancement operation), and\nthe introduction of appropriate types/units for such constructions as eventive\nadjectives and nouns like \u201crunning horse\u201d and \u201cpresident in 2009\u201d.  But\nmany (even simple) aspects of semantic are either not present (at least, not in\nthe paper) and/or simply wrong.  Missing: quantification (as in \u201cevery\u201d or\n\u201call\u201d); numbers (as in \u201c20\u201d or \u201cjust over 1000\u201d); various forms of\nreference (as in \u201che\u201d, \u201cthat man\u201d, \u201cwhat I said before\u201d); negation\nand modals, which change the semantics in interesting ways; inter-event\nrelationships (as in the subevent relationship between the events in \u201cthe\nvacation was nice, but traveling was a pain\u201d; etc. etc.  To add them one can\neasily cheat, by treating these items as if they were just unusual words and\ndefining obvious and simple lambda formulas for them.  But they in fact require\nspecific treatment; for example, a number requires the creation of a separate\nset object in the representation, with its own canonical variable (allowing\nlater text to refer to \u201cone of them\u201d and bind the variable properly).  For\nanother example, Person A\u2019s model of an event may differ from Person B\u2019s,\nso one needs two representation symbols for the event, plus a coupling and\nmapping between them.  For another example, one has to be able to handle time,\neven if simply by temporally indexing events and states.  None of this is here,\nand it is not immediately obvious how this would be added.  In some cases, as\nDRT shows, quantifier and referential scoping is not trivial.  \n\nIt is easy to point to missing things, and unfair to the paper in some sense;\nyou can\u2019t be expected to do it all.  But you cannot be allowed to make\nobvious errors.  Very disturbing is the assignment of event relations strictly\nin parallel with the verb\u2019s (or noun\u2019s) syntactic roles.  No-one can claim\nseriously that \u201che broke the window\u201d and \u201cthe window broke\u201d has\n\u201che\u201d and \u201cthe window\u201d filling the same semantic role for \u201cbreak\u201d. \nThat\u2019s simply not correct, and one cannot dismiss the problem, as the paper\ndoes, to some nebulous subsequent semantic processing.                          This\nreally\nneeds\nadequate treatment, even in this paper.  This is to my mind the principal\nshortcoming of this work; for me this is the make-or-break point as to whether\nI would fight to have the paper accepted in the conference.  (I would have been\nfar happier if the authors had simply acknowledged that this aspect is wrong\nand will be worked on in future, with a sketch saying how: perhaps by reference\nto FrameNet and semantic filler requirements.)                          \n\nIndependent of the representation, the notation conversion procedure is\nreasonably clear.  I like the facts that it is rather cleaner and simpler than\nits predecessor (based on Stanford dependencies), and also that the authors\nhave the courage of submitting non-neural work to the ACL in these days of\nunbridled and giddy enthusiasm for anything neural.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "3", "CLARITY": "4", "REVIEWER_CONFIDENCE": "4"}], "abstract": "Universal Dependencies (UD) provides a cross-linguistically uniform syntactic representation, with the aim of advancing multilingual applications of parsing and natural language understanding. Reddy et al. (2016) recently developed a semantic interface for (English) Stanford Dependencies, based on the lambda calculus.  In this work, we introduce UDepLambda, a similar semantic interface for UD, which allows mapping natural language to logical forms in an almost language-independent framework. We evaluate our approach on semantic parsing for the task of question answering against Freebase.  To facilitate multilingual evaluation, we provide German and Spanish translations of the WebQuestions and GraphQuestions datasets. Results show that UDepLambda outperforms strong baselines across languages and datasets.  For English, it achieves the strongest result to date on GraphQuestions, with competitive results on WebQuestions.", "histories": [], "id": 388, "title": "Universal Semantic Parsing"}
