{"reviews": [{"IMPACT": "5", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "5", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "Thanks for the response. I look forward to reading about the effect of\nincentives and the ambiguity of the language in the domain.\n\nReview before author response:\nThe paper proposes a way to build natural language interfaces by allowing a set\nof users to define new concepts and syntax. It's an (non-trivial) extension of\nS. I. Wang, P. Liang, and C. Manning. 2016. Learning language games through\ninteraction\n\nQuestions:\n- What is the size of the vocabulary used \n- Is it possible to position this paper with respect to previous work on\ninverse reinforcement learning and imitation learning ?\n\nStrengths:\n- The paper is well written\n- It provides a compelling direction/solution to the problem of dealing with a\nlarge set of possible programs while learning natural language interfaces. \n\nWeaknesses:\n- The authors should discuss the effect of the incentives on the final\nperformance ? Were other alternatives considered ? \n- While the paper claims that the method can be extended to more practical\ndomains, it is not clear to me how straightforward it is going to be. How\nsensitive is the method to the size of the vocabulary required in a domain ?\nWould increased ambiguity in natural language create new problems ? These\nquestions are not discussed in the current experiments.\n- A real-world application would definitely strengthen the paper even more.", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "4", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "4", "REVIEWER_CONFIDENCE": "4"}, {"IMPACT": "5", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "5", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "- Strengths: This paper reports on an interesting project to enable people to\ndesign their own language for interacting with a computer program, in place of\nusing a programming language. The specific construction that the authors focus\non is the ability for people to make definitions. Very nicely, they can make\nrecursive definitions to arrive at a very general way of giving a command. The\nexample showing how the user could generate definitions to create a palm tree\nwas motivating. The approach using learning of grammars to capture new cases\nseems like a good one. \n\n- Weaknesses: This seems to be an extension of the ACL 2016 paper on a similar\ntopic. It would be helpful to be more explicit about what is new in this paper\nover the old one. \n\nThere was not much comparison with previous work: no related work section. \n\nThe features for learning are interesting but it's not always clear how they\nwould come into play. For example, it would be good to see an example of how\nthe social features influenced the outcome. I did not otherwise see how people\nwork together to create a language. \n\n- General Discussion:", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "4", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "4", "REVIEWER_CONFIDENCE": "4"}, {"IMPACT": "5", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "5", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "- Strengths:\n\nThe ideas and the task addressed in this paper are beautiful and original.\nCombining indirect supervision (accepting the resulting parse) with direct\nsupervision (giving a definition) makes it a particularly powerful way of\ninteractively building a natural language interface to a programming language.\nThe proposed has a wide range of potential applications. \n\n- Weaknesses:\n\nThe paper has several typos and language errors and some text seems to be\nmissing from the end of section 6. It could benefit from careful proofreading\nby a native English speaker. \n\n- General Discussion:\n\nThe paper presents a method for collaborative naturalization of a 'core'\nprogramming language by a community of users through incremental expansion of\nthe syntax of the language. This expansion is performed interactively, whereby\na user just types a command in the naturalized language, and then either\nselects through a list of candidate parses or provides a definition also in the\nnatural language. The users give intuitive definitions using literals instead\nof variables (e.g. \"select orange\"), which makes this method applicable to\nnon-programmers. \nA grammar is induced incrementally which is used to provide the candidate\nparses.\n\nI have read the authors' response.", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "4", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "3"}], "abstract": "Our goal is to create a convenient natural language interface for performing well-specified but complex actions such as analyzing data, manipulating text, and querying databases. However, existing natural language interfaces for such tasks are quite primitive compared to the power one wields with a programming language. To bridge this gap, we start with a core programming language and allow users to ``naturalize'' the core language incrementally by defining alternative, more natural syntax and increasingly complex concepts in terms of compositions of simpler ones. In a voxel world, we show that a community of users can simultaneously teach a common system a diverse language and use it to build hundreds of complex voxel structures. Over the course of three days, these users went from using only the core language to using the naturalized language in 85.9\\% of the last 10K utterances.", "histories": [], "id": 706, "title": "Naturalizing a Programming Language via Interactive Learning"}
