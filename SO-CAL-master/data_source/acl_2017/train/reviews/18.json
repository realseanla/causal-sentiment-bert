{"reviews": [{"SUBSTANCE": "4", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "- Strengths:\n\n-- A well-motivated approach, with a clear description and solid results.\n\n- Weaknesses:\n\n-- Nothing substantial other than the comments below. \n\n- General Discussion:\n\nThe paper describes a new method called attention-over-attention for reading\ncomprehension. First layers of the network compute a vector for each query word\nand document word, resulting in a |Q|xK matrix for the query and a |D|xK for\nthe document. Since the answer is a document word, an attention mechanism is\nused for assigning weights to each word, depending on their interaction with\nquery words. In this work, the authors deepen a traditional attention mechanism\nby computing a weight for each query word through a separate attention and then\nusing that to weight the main attention over document words. Evaluation is\nproperly conducted on benchmark datasets, and various insights are presented\nthrough an analysis of the results as well as a comparison to prior work. I\nthink this is a solid piece of work on an important problem, and the method is\nwell-motivated and clearly described, so that researchers can easily reproduce\nresults and apply the same techniques to other similar tasks.\n\n- Other remarks:\n\n-- p4, Equation 12: I am assuming i is iterating over training set and p(w) is\nreferring to P(w|D,Q) in the previous equation? Please clarify to avoid\nconfusion.\n\n-- I am wondering whether you explored/discussed initializing word embeddings\nwith existing vectors such as Google News or Glove? Is there a reason to\nbelieve the general-purpose word semantics would not be useful in this task?\n\n-- p6 L589-592: It is not clear what the authors are referring to when they say\n'letting the model explicitly learn weights between individual attentions'? Is\nthis referring to their own architecture, more specifically the GRU output\nindirectly affecting how much attention will be applied to each query and\ndocument word? Clarifying that would be useful. Also, I think the improvement\non validation is not 4.1, rather 4.0 (72.2-68.2).\n\n-- p7 Table 5: why do you think the weight for local LM is relatively higher\nfor the CN task while the benefit of adding it is less? Since you included the\ntable, I think it'll be nice to provide some insights to the reader.\n\n-- I would have liked to see the software released as part of this submission.\n\n-- Typo p2 L162 right column: \"is not that effective than expected\" --> \"is not\nas effective as expected\"?\n\n-- Typo p7 L689 right column: \"appear much frequent\" --> \"appears more\nfrequently\"?\n\n-- Typo p8 L719-721 left column: \"the model is hard to\" --> \"it is hard for the\nmodel to\"? & \"hard to made\" --> \"hard to make\"?", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "5", "CLARITY": "5", "REVIEWER_CONFIDENCE": "4"}], "abstract": "Cloze-style reading comprehension is a representative problem in mining relationship between document and query. In this paper, we present a simple but novel model called attention-over-attention reader for better solving cloze-style reading comprehension task. The proposed model aims to place another attention mechanism over the document-level attention and induces ``attended attention'' for final answer predictions. One advantage of our model is that it is simpler than related works while giving excellent performance. In addition to the primary model, we also propose an N-best re-ranking strategy to double check the validity of the candidates and further improve the performance. Experimental results show that the proposed methods significantly outperform various state-of-the-art systems by a large margin in public datasets, such as CNN and Children's Book Test.", "histories": [], "id": 18, "title": "Attention-over-Attention Neural Networks for Reading Comprehension"}
