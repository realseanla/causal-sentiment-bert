{"reviews": [{"IMPACT": "3", "SUBSTANCE": "3", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "5", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "This work proposes to apply dilated convolutions for sequence tagging\n(specifically, named entity recognition). It also introduces some novel ideas\n(sharing the dilated convolution block, predicting the tags at each convolution\nlevel), which I think will prove useful to the community. The paper performs\nextensive ablation experiments to show the effectiveness of their approach.\nI found the writing to be very clear, and the experiments were exceptionally\nthorough.\n\nStrengths:  \n- Extensive experiments against various architectures (LSTM, LSTM + CRF)       \n- Novel architectural/training ideas (sharing blocks)  \n\nWeaknesses:  \n- Only applied to English NER--this is a big concern since the title of the\npaper seems to reference sequence-tagging directly.  \n- Section 4.1 could be clearer. For example, I presume there is padding to make\nsure the output resolution after each block is the same as the input\nresolution.  Might be good to mention this.  \n- I think an ablation study of number of layers vs perf might be interesting.\n\nRESPONSE TO AUTHOR REBUTTAL:\n\nThank you very much for a thoughtful response. Given that the authors have\nagreed to make the content be more specific to NER as opposed to\nsequence-tagging, I have revised my score upward.", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "4", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "4", "REVIEWER_CONFIDENCE": "5"}, {"IMPACT": "3", "SUBSTANCE": "3", "APPROPRIATENESS": "4", "MEANINGFUL_COMPARISON": "5", "PRESENTATION_FORMAT": "Poster", "comments": "- Strengths:\n\nThe main strength promised by the paper is the speed advantage at the same\naccuracy level.\n\n- Weaknesses:\n\nPresentation of the approach leaves a lot to be desired. Sections 3 and 4 need\nto be much clearer, from concept definition to explaining the architecture and\nparameterization. In particular Section 4.1 and the parameter tieing used need\nto be crystal clear, since that is one of the main contributions of the paper.\n\nMore experiments supporting the vast speed improvements promised need to be\npresented. The results in Table 2 are good but not great. A speed-up of 4-6X is\nnothing all that transformative.\n\n- General Discussion:\n\nWhat exactly is \"Viterbi prediction\"? The term/concept is far from established;\nthe reader could guess but there must be a better way to phrase it.\n\nReference Weiss et al., 2015 has a typo.", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "4", "is_meta_review": null, "RECOMMENDATION": "3", "CLARITY": "2", "REVIEWER_CONFIDENCE": "4"}], "abstract": "Bi-directional LSTMs have emerged as a standard method for obtaining per-token vector representations serving as input to various token labeling tasks (whether followed by Viterbi prediction or independent classification).  This paper proposes an alternative to Bi-LSTMs for this purpose: iterated dilated convolutional neural networks (ID-CNNs), which have better capacity than traditional CNNs for large context and structured prediction.  We describe a distinct combination of network structure, parameter sharing and training procedures that is not only more accurate than Bi-LSTM-CRFs, but also 8x faster at test time on long sequences.  Moreover, ID-CNNs with independent classification enable a dramatic 14x test-time speedup, while still attaining accuracy comparable to the Bi-LSTM-CRF.  We further demonstrate the ability of ID-CNNs to combine evidence over long sequences by demonstrating their improved accuracy on whole-document (rather than per-sentence) inference.  Unlike LSTMs whose sequential processing on sentences of length N requires O(N) time even in the face of parallelism, IDCNNs permit fixed-depth convolutions to run in parallel across entire documents.  Today when many companies run basic NLP on the entire web and large-volume traffic, faster methods are paramount to saving time and energy costs.", "histories": [], "id": 636, "title": "Fast and Accurate Sequence Labeling with Iterated Dilated Convolutions"}
