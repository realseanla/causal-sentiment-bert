{"reviews": [{"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "This paper details a method of achieving translation from morphologically\nimpoverished languages (e.g. Chinese) to morphologically rich ones (e.g.\nSpanish) in a two-step process. First, a system translates into a simplified\nversion of the target language. Second, a system chooses morphological features\nfor each generated target word, and inflects the words based on those features.\n\nWhile I wish the authors would apply the work to more than one language pair, I\nbelieve the issue addressed by this work is one of the most important and\nunder-addressed problems with current MT systems. The approach taken by the\nauthors is very different than many modern approaches based on BPE and\ncharacter-level models, and instead harkens back to approaches such as\n\"Factored Translation Models\" (Koehn and Hoang, 2007) and \"Translating into\nMorphologically Rich Languages with Synthetic Phrases\" (Chahuneau et a. 2013),\nboth of which are unfortunately uncited.\n\nI am also rather suspicious of the fact that the authors present only METEOR\nresults and no BLEU or qualitative improvements. If BLEU scores do not rise,\nperhaps the authors could argue why they believe their approach is still a net\nplus, and back the claim up with METEOR and example sentences.\n\nFurthermore, the authors repeatedly talk about gender and number as the two\nlinguistic features they seek to correctly handle, but seem to completely\noverlook person. Perhaps this is because first and second person pronouns and\nverbs rarely occur in news, but certainly this point at least merits brief\ndiscussion. I would also like to see some discussion of why rescoring hurts\nwith gender. If the accuracy is very good, shouldn the reranker learn to just\nkeep the 1-best?\n\nFinally, while the content of this paper is good overall, it has a huge amount\nof spelling, grammar, word choice, and style errors that render it unfit for\npublication in its current form. Below is dump of some errors that I found.\n\nOverall, I would like to this work in a future conference, hopefully with more\nthan one language pair, more evaluation metrics, and after further\nproofreading.\n\nGeneral error dump:\nLine 062: Zhand --> Zhang\nLine 122: CFR --> CRF\nWhole related work section: consistent use of \\cite when \\newcite is\nappropriate\nIt feels like there's a lot of filler: \"it is important to mention that\", \"it\nis worth mentioning that\", etc\nLine 182, 184: \"The popular phrase-based MT system\" = moses? or PBMT systems in\ngeneral?\nLine 191: \"a software\"\nLine 196: \"academic and commercial level\" -- this should definitely be\npluralized, but are these even levels?\nLine 210: \"a morphology-based simplified target\" makes it sound like this\nsimplified target uses morphology. Perhaps the authors mean \"a morphologically\nsimplified target\"?\nLine 217: \"decide on the morphological simplifications\"?\nTable 1: extra space in \"cuesti\u00f3n\" on the first line and \"titulado\" in the\nlast line.\nTable 1: Perhaps highlight differences between lines in this table somehow?\nHow is the simplification carried out? Is this simplifier hand written by the\nauthors, or does it use an existing tool?\nLine 290: i.e. --> e.g.\nLine 294: \"train on\" or \"train for\"\nLine 320: \"our architecture is inspired by\" or \"Collobert's proposal inspires\nour architecture\"\nLine 324: drop this comma\nLine 338: This equation makes it look like all words share the same word vector\nW\nLine 422: This could also be \"casas blancas\", right? How does the system choose\nbetween the sg. and pl. forms? Remind the reader of the source side\nconditioning here.\nLine 445: This graph is just a lattice, or perhaps more specifically a \"sausage\nlattice\"\nLine 499: Insert \"e.g.\" or similiar: (e.g. producirse)\nLine 500: misspelled \"syllable\"\nLine 500/503: I'd like some examples or further clarity on what palabras llanas\nand palabras estr\u00fajulas are and how you handle all three of these special\ncases.\nLine 570: \"and sentences longer than 50 words\"\nLine 571: \"by means of zh-seg\" (no determiner) or \"by means of the zh-seg tool\"\nLine 574: are you sure this is an \"and\" and not an \"or\"?\nLine 596: \"trained for\" instead of \"trained on\"\nLine 597: corpus --> copora\nLine 604: size is --> sizes are\nLine 613: would bigger embedding sizes help? 1h and 12h are hardly unreasonable\ntraining times.\nLine 615: \"seven and five being the best values\"\nLine 617: Why 70? Increased from what to 70?\nTable 3: These are hyperparameters and not just ordinary parameters of the\nmodel\nLine 650: \"coverage exceeds 99%\"?\nLine 653: \"descending\"\nLine 666: \"quadratic\"\nLine 668: space before \\cites\nLine 676: \"by far\" or \"by a large margin\" instead of \"by large\"\nLine 716: below\nLine 729: \"The standard phrase-based ...\"\nzh-seg citation lists the year as 2016, but the tool actually was released in\n2009", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "1", "CLARITY": "3", "REVIEWER_CONFIDENCE": "4"}, {"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "The paper describes a method for improving two-step translation using deep\nlearning. Results are presented for Chinese->Spanish translation, but the\napproach seems to be largely language-independent.\n\nThe setting is fairly typical for two-step MT. The first step translates into a\nmorphologically underspecified version of the target language. The second step\nthen uses machine learning to fill in the missing morphological categories and\nproduces the final system output by inflecting the underspecified forms (using\na morphological generator). The main novelty of this work is the choice of deep\nNNs as classifiers in the second step. The authors also propose a rescoring\nstep which uses a LM to select the best variant.\n\nOverall, this is solid work with good empirical results: the classifier models\nreach a high accuracy (clearly outperforming baselines such as SVMs) and the\nimprovement is apparent even in the final translation quality.\n\nMy main problem with the paper is the lack of a comparison with some\nstraightforward deep-learning baselines. Specifically, you have a structured\nprediction problem and you address it with independent local decisions followed\nby a rescoring step. (Unless I misunderstood the approach.) But this is a\nsequence labeling task which RNNs are well suited for. How would e.g. a\nbidirectional LSTM network do when trained and used in the standard sequence\nlabeling setting? After reading the author response, I still think that\nbaselines (including the standard LSTM) are run in the same framework, i.e.\nindependently for each local label. If that's not the case, it should have been\nclarified better in the response. This is a problem because you're not using\nthe RNNs in the standard way and yet you don't justify why your way is better\nor compare the two approaches.\n\nThe final re-scoring step is not entirely clear to me. Do you rescore n-best\nsentences? What features do you use? Or are you searching a weighted graph for\nthe single optimal path? This needs to be explained more clearly in the paper.\n(My current impression is that you produce a graph, then look for K best paths\nin it, generate the inflected sentences from these K paths and *then* use a LM\n-- and nothing else -- to select the best variant. But I'm not sure from\nreading the paper.) This was not addressed in the response.\n\nYou report that larger word embeddings lead to a longer training time. Do they\nalso influence the final results?\n\nCan you attempt to explain why adding information from the source sentence\nhurts? This seems a bit counter-intuitive -- does e.g. the number information\nnot get entirely lost sometimes because of this? I would appreciate a more\nthorough discussion on this in the final version, perhaps with a couple of\nconvincing examples.\n\nThe paper contains a number of typos and the general level of English may not\nbe sufficient for presentation at ACL.\n\nMinor corrections:\n\ncontext of the application of MT -> context of application for MT\n\nIn this cases, MT is faced in two-steps -> In this case, MT is divided into two\nsteps\n\nmarkov -> Markov\n\nCFR -> CRF\n\ntask was based on a direct translation -> task was based on direct translation\n\ntask provided corpus -> task provided corpora\n\nthe phrase-based system has dramatically -> the phrase-based approach...\n\ninvestigated different set of features -> ...sets of features\n\nwords as source of information -> words as the source...\n\ncorrespondant -> corresponding\n\nClasses for gender classifier -> Classes for the...\n\nfor number classifier -> for the...\n\nThis layer's input consists in -> ...consists of\n\nto extract most relevant -> ...the most...\n\nSigmoid does not output results in [-1, 1] but rather (0, 1). A tanh layer\nwould produce (-1, 1).\n\ninformation of a word consists in itself -> ...of itself\n\nthis $A$ set -> the set $A$\n\nempty sentences and longer than 50 words -> empty sentences and sentences\nlonger than...\n\nclassifier is trained on -> classifier is trained in\n\naproximately -> approximately\n\ncoverage raises the 99% -> coverage exceeds 99% (unless I misunderstand)\n\nin descendant order -> in descending order\n\ncuadratic -> quadratic (in multiple places)\n\nbut best results -> but the best results\n\nRescoring step improves -> The rescoring step...\n\nare not be comparable -> are not comparable", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "2", "CLARITY": "4", "REVIEWER_CONFIDENCE": "4"}, {"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "This paper presents a method for generating morphology, focusing on gender and\nnumber, using deep learning techniques. From a morphologically simplified\nSpanish text, the proposed approach uses a classifier to reassign the gender\nand number for each token, when necessary. The authors compared their approach\nwith other learning algorithms, and evaluated it in machine translation on the\nChinese-to-Spanish (Zh->Es) translation direction.\n\nRecently, the task of generating gender and number has been rarely tackled,\nmorphology generation methods usually target, and are evaluated on,\nmorphologically-rich languages like German or Finnish.\nHowever, calling the work presented in this paper \u201cmorphology\ngeneration\u201c\u00a0is a bit overselling as the proposed method clearly deals only\nwith\ngender and number. And given the fact that some rules are handcrafted for this\nspecific task, I do not think this method can be straightforwardly applied to\ndo more complex morphology generation for morphologically-rich languages.\n\nThis paper is relatively clear in the sections presenting the proposed method.\nA\nlot of work has been done to design the method and I think it can have some\ninteresting impact on various NLP tasks. However the evaluation part of\nthis work is barely understandable as many details of what is done, or why it\nis done, are missing. From this evaluation, we cannot know if the proposed\nmethod brings improvements over state-of-the-art methods while the experiments\ncannot be replicated. Furthermore, no analysis of the results obtained is\nprovided. Since half a page is still available, there was the possibility\nto provide more information to make more clear the evaluation. This work lacks\nof motivation. Why do you think deep learning can especially improve gender and\nnumber generation over state-of-the-art methods?\n\nIn your paper, the word \u201ccontribution\u201c should be used more wisely, as it is\nnow in the paper, it is not obvious what are the real contributions (more\ndetails below). \n\nabstract:\nwhat do you mean by unbalanced languages?\n\nsection 1:\nYou claim that your main contribution is the use of deep learning. Just the use\nof deep learning in some NLP task is not a contribution.\n\nsection 2:\nYou claim that neural machine translation (NMT), mentioned as \u201cneural\napproximations\u201c,  does not achieve state-of-the-art results for Zh->Es. I\nrecommend to remove this claim from the paper, or to discuss it more, since\nJunczys-Dowmunt et al. (2016), during the last IWSLT, presented some results\nfor Zh->Es with the UN corpus, showing that NMT outperforms SMT by around 10\nBLEU points.\n\nsection 5.1:\nYou wrote that using the Zh->Es language pair is one of your main\ncontributions. Just using a language pair is not a contribution. Nonetheless, I\nthink it is nice to see a paper on machine translation that does not focus of\nimproving machine translation for English.\nThe numbers provided in Table 2 were computed before or after preprocessing?\nWhy did you remove the sentences longer than 50 tokens?\nPrecise how did you obtain development and test sets, or provide them. Your\nexperiments are currently no replicable especially because of that.\n\nsection 5.2:\nYou wrote that you used Moses and its default parameters, but the default\nparameters of Moses are not the same depending on the version, so you should\nprovide the number of the version used.\n\nsection 5.3:\nWhat do you mean by \u201chardware cost\u201c?\nTable 3: more details should be provided regarding how did you obtain these\nvalues. You chose these values given the classifier accuracy, but how precisely\nand on what data did you train and test the classifiers? On the same data used\nin section 6?\nIf I understood the experiments properly, you used simplified Spanish. But I\ncannot find in the text how do you simplify Spanish. And how do you use it to\ntrain the classifier and the SMT system? \n\nsection 6:\nYour method is better than other classification\nalgorithms, but it says nothing about how it performs compared to the\nstate-of-the-art methods. You should at least precise why you chose these\nclassifications algorithms for comparison. Furthermore, how your rules impact\nthese results? And more generally, how do you explain such a high accuracy for\nyou method?\nDid you implement all these classification algorithms by yourselves? If not,\nyou must provide the URL or cite the framework you used.\nFor the SMT experiments, I guess you trained your phrase table on simplified\nSpanish. You must precise it.\nYou chose METEOR over other metrics like BLEU to evaluate your results. You\nmust provide some explanation for this choice. I particularly appreciate when I\nsee a MT paper that does not use BLEU for evaluation, but if you use METEOR,\nyou must mention which version you used. METEOR has largely changed since 2005.\nYou cited the paper of 2005, did you use the 2005 version? Or did you use the\nlast one with paraphrases? \nAre your METEOR scores statistically significant?\n\nsection 7:\nAs future work you mentioned \u201cfurther simplify morphology\u201c. In this paper,\nyou do not present any simplification of morphology, so I think that choosing\nthe word\n\u201cfurther\u201c is misleading.\n\nsome typos:\nfemenine\nensambling\ncuadratic\n\nstyle:\nplain text citations should be rewritten like this: \u201c(Toutanova et al, 2008)\nbuilt\u00a0\u201c should be \u201cToutanova et al. (2008) built \u201c\nplace the caption of your tables below the table and not above, and with more\nspace between the table and its caption.\nYou used the ACL 2016 template. You must use the new one prepared for ACL 2017.\nMore generally, I suggest that you read again the FAQ and the submission\ninstructions provided on the ACL 2017 website. It will greatly help you to\nimprove the paper. There are also important information regarding references:\nyou must provide DOI or URL of all ACL papers in your references.\n\n-----------------------\n\nAfter authors response:\n\nThank you for your response.\n\nYou wrote that rules are added just as post-processing, but does it mean that\nyou do not apply them to compute your classification results? Or if you do\napply them before computing these results, I'm still wondering about their\nimpact on these results.\n\nYou wrote that Spanish is simplified as shown in Table 1, but it does not\nanswer my question: how did you obtain these simplifications exactly? (rules?\nsoftware? etc.) The reader need to now that to reproduce your approach.\n\nThe classification algorithms presented in Table 5 are not state-of-the-art, or\nif they are you need to cite some paper. Furthermore, this table only tells\nthat deep learning gives the best results for classification, but it does not\ntell at all if your approach is better than state-of-the-art approach for\nmachine translation. You need to compare your approach with other\nstate-of-the-art morphology generation approaches (described in related work)\ndesigned for machine translation. If you do that your paper will be much more\nconvincing in my opinion.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "2", "CLARITY": "3", "REVIEWER_CONFIDENCE": "5"}], "abstract": "Morphology in unbalanced languages remains a big challenge in the context of machine translation. In this paper, we propose to de-couple machine translation from morphology generation in order to better deal with the problem. We investigate the morphology simplification with a reasonable trade-off between expected gain and generation complexity. For the Chinese-Spanish task, optimum morphological simplification is in gender and number. For this purpose, we design a new classification architecture which, compared to other standard machine learning techniques, obtains the best results. This proposed neural-based architecture consists of several layers: an embedding, a convolutional followed by a recurrent neural network and, finally, ends with sigmoid and softmax layers. We obtain classification results over 98% accuracy in gender classification, over 93% in number classification, and an overall translation improvement of 0.7 METEOR.", "histories": [], "id": 369, "title": "Morphology Generation for Statistical Machine Translation using Deep Learning Techniques"}
