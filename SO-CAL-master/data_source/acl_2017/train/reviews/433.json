{"reviews": [{"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "The paper describes a deep-learning-based model for parsing the creole\nSingaporean English to Universal Dependencies. They implement a parser based on\nthe model by Dozat and Manning (2016) and add neural stacking (Chen et al.,\n2016) to it. They train an English model and then use some of the hidden\nrepresentations of the English model as input to their Singlish parser. This\nallows them to make use of the much larger English training set along with a\nsmall Singlish treebank, which they annotate. They show that their approach\n(LAS 76.57) works better than just using an English parser (LAS 65.6) or\ntraining a parser on their small Singlish data set (LAS 64.01). They also\nanalyze for which\ncommon constructions, their approach improves parsing quality. \n\nThey also describe and evaluate a stacked POS model based on Chen et al.\n(2016), they discuss how common constructions should be analyzed in the UD\nframework, and they provide an annotated treebank of 1,200 sentences. 100 of\nthem were annotated by two people and their inter-annotator agreement was 85.3\nUAS and 75.7 LAS.\n\n- Strengths:\n\n - They obtain good results and their experimental setup appears to be solid.\n\n - They perform many careful analyses and explore the influence on many\nparameters of their model.\n\n - They provide a small Singlish treebank annotated according to the Universal\nDependencies v1.4 guidelines.\n\n - They propose very sound guidelines on how to analyze common Singlish\nconstructions in UD.\n\n - Their method is linguistically informed and they nicely exploit similarity\nbetween standard English and the creole Singaporean English.\n\n - The paper presents methods for a low-resource language.\n\n - They are not just applying an existing English method to another language\nbut instead present a method that can be potentially used for other closely\nrelated language pairs.\n\n - They use a well-motivated method for selecting the sentences to include in\ntheir treebank.\n\n - The paper is very well written and easy to read.\n\n- Weaknesses:\n\n - The annotation quality seems to be rather poor. They performed double\nannotation of 100 sentences and their inter-annotator agreement is just 75.72%\nin terms of LAS. This makes it hard to assess how reliable the estimate of the\nLAS of their model is, and the LAS of their model is in fact slightly higher\nthan the inter-annotator agreement. \n\nUPDATE: Their rebuttal convincingly argued that the second annotator who just\nannotated the 100 examples to compute the IAA didn't follow the annotation\nguidelines for several common constructions. Once the second annotator fixed\nthese issues, the IAA was reasonable, so I no longer consider this a real\nissue.\n\n- General Discussion:\n\nI am a bit concerned about the apparently rather poor annotation quality of the\ndata and how this might influence the results, but overall, I liked the paper\na lot and I think this would be a good contribution to the conference.\n\n- Questions for the authors:\n\n - Who annotated the sentences? You just mention that 100 sentences were\nannotated by one of the authors to compute inter=annotator agreement but you\ndon't mention who annotated all the sentences.\n\n - Why was the inter-annotator agreement so low? In which cases was there\ndisagreement? Did you subsequently discuss and fix the sentences for which\nthere was disagreement?\n\n - Table A2: There seem to be a lot of discourse relations (almost as many as\ndobj relations) in your treebank. Is this just an artifact of the colloquial\nlanguage or did you use \"discourse\" for things that are not considered\n\"discourse\" in other languages in UD?\n\n - Table A3: Are all of these discourse particles or discourse + imported\nvocab? If the latter, perhaps put them in separate tables, and glosses would be\nhelpful.\n\n- Low-level comments:\n\n - It would have been interesting if you had compared your approach to the one\nby Martinez et al. (2017, https://arxiv.org/pdf/1701.03163.pdf). Perhaps you\nshould mention this paper in the reference section.\n\n - You use the word \"grammar\" in a slightly strange way. I think replacing\n\"grammar\" with syntactic constructions would make it clearer what you try to\nconvey. (e.g., line 90)\n\n - Line 291: I don't think this can be regarded as a variant of\nit-extraposition. But I agree with the analysis in Figure 2, so perhaps just\nget rid of this sentence.\n\n - Line 152: I think the model by Dozat and Manning (2016) is no longer\nstate-of-the art, so perhaps just replace it with \"very high performing model\"\nor something like that.\n\n - It would be helpful if you provided glosses in Figure 2.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "4"}, {"IMPACT": "3", "SUBSTANCE": "3", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "- Strengths:\nNice results, nice data set. Not so much work on Creole-like languages,\nespecially English.  \n\n- Weaknesses:\nA global feeling of \"Deja-vu\", a lot of similar techniques have been applied to\nother domains, other ressource-low languages. Replace word embeddings by\nclusters and neural models by whatever was in fashion 5 years ago and we can\nfind more or less the same applied to Urdu or out-of-domain parsing. I liked\nthis paper though, but I would have appreciated the authors to highlight more\ntheir contributions and position their work better within the literature.\n\n- General Discussion:\n\nThis paper presents a set of experiments designed a) to show the effectiveness\nof a neural parser  in a scarce resource scenario and b) to introduce a new\ndata set of Creole English (from Singapour, called Singlish). While this data\nset is relatively small (1200 annotated sentences, used with 80k unlabeled\nsentences for word embeddings induction), the authors manage to present\nrespectable results via interesting approach even though using features from\nrelatively close languages are not unknown from the parsing community (see all\nthe line of work on parsing Urdu/Hindi, on Arabic dialect using MSA based\nparsers, and so on).\nAssuming we can see Singlish as an extreme of Out-of-domain English and given\nall the set of experiments, I wonder why the authors didn\u2019t try the classical\ntechnique on domain-adaptation, namely training with UD_EN+90% of the Singlish\nwithin a 10 cross fold experiment ? just so we can have another interesting\nbaseline (with and without word embeddings, with bi-lingual embeddings if\nenough parallel data is available).\nI think that paper is interesting but I really would have appreciated more\npositioning regarding all previous work in parsing low-ressources languages and\nextreme domain adaptation. A table presenting some results for Irish and other\nvery small treebanks would be nice.\nAlso how come the IAA is so low regarding the labeled relations?\n\n*****************************************\nNote after reading the authors' answer\n*****************************************\n\nThanks for your clarifications (especially for redoing the IAA evaluation). I\nraised my recommendation to 4, I hope it'll get accepted.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "5"}, {"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "The authors construct a new dataset of 1200 Singaporean English (Singlish)\nsentences annotated with Universal Dependencies. They show that they can\nimprove the performance of a POS tagger and a dependency parser on the Singlish\ncorpus by integrating English syntactic knowledge via a neural stacking model.\n\n- Strengths:\nSinglish is a low-resource language. The NLP community needs more data for low\nresource languages, and the dataset accompanying this paper is a useful\ncontribution. There is also relatively little NLP research on creoles, and the\npotential of using transfer-learning to analyze creoles, and this paper makes a\nnice contribution in that area.\n\nThe experimental setup used by the authors is clear. They provide convincing\nevidence that incorporating knowledge from an English-trained parser into a\nSinglish parser outperforms both an English-only parser and a Singlish-only\nparser on the Singlish data. They also provide a good overview of the relevant\ndifferences between English and Singlish for the purposes of syntactic parser\nand a useful analysis of how different parsing models handle these\nSinglish-specific constructions.\n\n- Weaknesses:\n\nThere are three main issues I see with this paper:\n*  There is insufficient comparison to the UD annotation of non-English\nlanguages. Many of the constructions they bring up as specific to Singlish are\nalso present in other UD languages, and the annotations should ideally be\nconsistent between Singlish and these languages.\n*  I'd like to see an analysis on the impact of training data size. A central\nclaim of this paper is that using English data can improve performance on a\nlow-resource language like Singlish. How much more Singlish data would be\nneeded before the English data became unnecessary?\n*  What happens if you train a single POS/dep parsing model on the concatenated\nUD Web and Singlish datasets? This is much simpler than incorporating neural\nstacking. The case for neural stacking is stronger if it can outperform this\nbaseline.\n\n- General Discussion:\nLine 073: \u201cPOS taggers and dependency parsers perform poorly on such Singlish\ntexts based on our observations\u201d - be more clear that you will quantify this\nlater. As such, it seems a bit hand-wavy.\n\nLine 169: Comparison to neural network models for multi-lingual parsing. As far\nas I can tell, you don't directly try the approach of mapping Singlish and\nEnglish word embeddings into the same embedding space.\n\nLine 212: Introduction of UD Eng. At this point, it is appropriate to point out\nthat the Singlish data is also web data, so the domain matches UD Eng.\n\nLine 245: \u201cAll borrowed words are annotated according to their original\nmeanings\u201d. Does this mean they have the same POS as in  the language from\nwhich they were borrowed? Or the POS of their usage in Singlish?\n\nFigure 2: Standard English glosses would be very useful in understanding the\nconstructions and checking the correctness of the UD relations used.\n\nLine 280: Topic prominence: You should compare with the \u201cdislocated\u201d label\nin UD. From the UD paper: \u201cThe dislocated relation captures preposed (topics)\nand postposed elements\u201d. The syntax you are describing sounds similar to a\ntopic-comment-style syntax; if it is different, then you should make it clear\nhow.\n\nLine 294: \u201cSecond, noun phrases used to modify the predicate with the\npresence of a preposition is regarded as a \u201cnsubj\u201d (nominal subject).\u201d\nHere, I need a gloss to determine if this analysis makes sense. If the phrase\nis really being used to modify the predicate, then this should not be nsubj. UD\nmakes a distinction between core arguments (nsubj, dobj, etc) and modifiers. If\nthis is a case of modification, then you should use one of the modification\nrelations, not a core argument relation. Should clarify the language here.\n\nLine 308: \u201cIn UD-Eng standards, predicative \u201cbe\u201d is the only verb used as\na copula, which often depends on its complement to avoid copular head.\u201d This\nis an explicit decision made in UD, to increase parallelism with non-copular\nlanguages (e.g., Singlish). You should call this out. I think the rest of the\ndiscussion of copula handling is not necessary.\n\nLine 322: \u201cNP deletion: Noun-phrase (NP) deletion often results in null\nsubjects or objects.\u201d This is common in other languages (zero-anaphora in\ne.g. Spanish, Italian, Russian, Japanese\u2026 )Would be good to point this out,\nand also point to how this is dealt with in UD in those languages (I believe\nthe same way you handle it).\n\nLing 330: Subj/verb inversion is common in interrogatives in other languages\n(\u201cFue Marta al supermercado/Did Marta go to the supermarket?\u201d). Tag\nquestions are present in English (though perhaps are not as frequent). You\nshould make sure that your analysis is consistent with these languages.\n\nSec 3.3 Data Selection and Annotation:\nThe way you chose the Singlish sentences, of course an English parser will do\npoorly (they are chosen to be disimilar to sentences an English parser has seen\nbefore). But do you have a sense of how a standard English parser does overall\non Singlish, if it is not filtered this way? How common are sentences with\nout-of-vocabulary terms or the constructions you discussed in 3.2?\n\nA language will not necessarily capture unusual sentence structure,\nparticularly around long-distance dependencies. Did you investigate whether\nthis method did a good job of capturing sentences with the grammatical\ndifferences to English you discussed in Section 3.2?\n\nLine 415: \u201cthe inter-annotator agreement has an unlabeled attachment score\n(UAS) of 85.30% and a labeled attachment score (LAS) of 75.72%.\u201d\n*  What\u2019s the agreement on POS tags? Is this integrated with LAS?\n*  Note that in Silveira et al 2014, which produced UD-Eng, they measured 94%\ninter-annotator agreement on a per-token basis. Why the discrepancy?\n\nPOS tagging and dep parsing sections:\nFor both POS-tagging and dep parsing, I\u2019d like to see some analysis on the\neffect of training set size. E.g., how much more Singlish data would be needed\nto train a POS tagger/dep parser entirely on Singlish and get the same accuracy\nas the stacked model?\n\nWhat happens if you just concatenate the datasets? E.g., train a model on a\nhybrid dataset of EN and Singlish, and see what the result is?\n\nLine 681: typo: \u201cpre-rained\u201d should be \u201cpre-trained\u201d\n\n742 \u201cThe neural stacking model leads to the biggest improvement over nearly\nall categories except for a slightly lower yet competitive performance on \u201cNP\nDeletion\u201d cases\u201d --- seems that the English data strongly biases the parser\nto expect an explicit subj/obj. you could try deleting subj/obj from some\nEnglish sentences to improve performance on this construction.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "3"}], "abstract": "Singlish can be interesting to the ACL community both linguistically as a major creole based on English, and computationally for information extraction and sentiment analysis of regional social media. We investigate dependency parsing of Singlish by constructing a dependency treebank under the Universal Dependencies scheme, and then training a neural network model by integrating English syntactic knowledge into a state-of-the-art parser trained on the Singlish treebank. Results show that English knowledge can lead to 25% relative error reduction, resulting in a parser of 84.47% accuracies. To the best of our knowledge, we are the first to use neural stacking to improve cross-lingual dependency parsing on low-resource languages. We make both our annotation and parser available for further research.", "histories": [], "id": "433", "title": "Universal Dependencies Parsing for Colloquial Singaporean English"}
