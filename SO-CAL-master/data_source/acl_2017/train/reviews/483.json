{"reviews": [{"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "- Strengths:\n\nThis is the first neural network-based approach to argumentation\nmining. The proposed method used a Pointer Network (PN) model with\nmulti-task learning and outperformed previous methods in the\nexperiments on two datasets.\n\n- Weaknesses:\n\nThis is basically an application of PN to argumentation\nmining. Although the combination of PN and multi-task learning for\nthis task is novel, its novelty is not enough for ACL long\npublication. The lack of qualitative analysis and error analysis is\nalso a major concern.\n\n- General Discussion:\n\nBesides the weaknesses mentioned above, the use of PN is not\nwell-motivated. Although three characteristics of PN were described in\nl.138-143, these are not a strong motivation against the use of\nbi-directional LSTMs and the attention mechanism. The authors should\ndescribe what problems are solved by PN and discuss in the experiments\nhow much these problems are solved.\n\nFigures 2 and 3 are difficult to understand. What are the self link to\nD1 and the links from D2 to E1 and D3/D4 to E2? These are just the\noutputs from the decoder and not links. The decoder LSTM does not have\nan input from e_j in these figures, but it does in Equation (3). Also,\nin Figure 3, the abbreviation \"FC\" is not defined.\n\nEquation (8) is strange. To calculate the probability of each\ncomponent type, the probability of E_i is calculated.\n\nIn the experiments, I did not understand why only \"PN\", which is not a\njoint model, was performed for the microtext corpus.\n\nIt is not clear whether the BLSTM model is trained with the joint-task\nobjective.\n\nThere are some studies on discourse parsing using the attention\nmechanism. The authors should describe the differences from these studies.\n\nMinor issues:\n\nl.128: should related -> should be related\n\nl.215: (2015) is floating\n\nl.706: it able -> it is able\n\nI raised my recommendation score after reading the convincing author responses.\nI strongly recommend that the authors should discuss improved examples by PN as\nwell as the details of feature ablation.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "3", "CLARITY": "2", "REVIEWER_CONFIDENCE": "5"}, {"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "The paper presents an application of Pointer Networks, a recurrent neural\nnetwork model original used for solving algorithmic tasks, to two subtasks of\nArgumentation Mining: determining the types of Argument Components, and finding\nthe links between them. The model achieves state-of-the-art results.\n\nStrengths:\n\n- Thorough review of prior art in the specific formulation of argument mining\nhandled in this paper.\n- Simple and effective modification of an existing model to make it suitable\nfor\nthe task. The model is mostly explained clearly.\n- Strong results as compared to prior art in this task.\n\nWeaknesses:\n\n- 071: This formulation of argumentation mining is just one of several proposed\nsubtask divisions, and this should be mentioned. For example, in [1], claims\nare detected and classified before any supporting evidence is detected.\nFurthermore, [2] applied neural networks to this task, so it is inaccurate to\nsay (as is claimed in the abstract of this paper) that this work is the first\nNN-based approach to argumentation mining.\n- Two things must be improved in the presentation of the model: (1) What is the\npooling method used for embedding features (line 397)? and (2) Equation (7) in\nline 472 is not clear enough: is E_i the random variable representing the\n*type* of AC i, or its *identity*? Both are supposedly modeled (the latter by\nfeature representation), and need to be defined. Furthermore, it seems like the\nLHS of equation (7) should be a conditional probability.\n- There are several unclear things about Table 2: first, why are the three\nfirst\nbaselines evaluated only by macro f1 and the individual f1 scores are missing?\nThis is not explained in the text. Second, why is only the \"PN\" model\npresented? Is this the same PN as in Table 1, or actually the Joint Model? What\nabout the other three?\n- It is not mentioned which dataset the experiment described in Table 4 was\nperformed on.\n\nGeneral Discussion:\n\n- 132: There has to be a lengthier introduction to pointer networks, mentioning\nrecurrent neural networks in general, for the benefit of readers unfamiliar\nwith \"sequence-to-sequence models\". Also, the citation of Sutskever et al.\n(2014) in line 145 should be at the first mention of the term, and the\ndifference with respect to recursive neural networks should be explained before\nthe paragraph starting in line 233 (tree structure etc.).\n- 348: The elu activation requires an explanation and citation (still not\nenough\nwell-known).\n- 501: \"MC\", \"Cl\" and \"Pr\" should be explained in the label.\n- 577: A sentence about how these hyperparameters were obtained would be\nappropriate.\n- 590: The decision to do early stopping only by link prediction accuracy\nshould\nbe explained (i.e. why not average with type accuracy, for example?).\n- 594: Inference at test time is briefly explained, but would benefit from more\ndetails.\n- 617: Specify what the length of an AC is measured in (words?).\n- 644: The referent of \"these\" in \"Neither of these\" is unclear.\n- 684: \"Minimum\" should be \"Maximum\".\n- 694: The performance w.r.t. the amount of training data is indeed surprising,\nbut other models have also achieved almost the same results - this is\nespecially surprising because NNs usually need more data. It would be good to\nsay this.\n- 745: This could alternatively show that structural cues are less important\nfor\nthis task.\n- Some minor typos should be corrected (e.g. \"which is show\", line 161).\n\n[1] Rinott, Ruty, et al. \"Show Me Your Evidence-an Automatic Method for Context\nDependent Evidence Detection.\" EMNLP. 2015.\n\n[2] Laha, Anirban, and Vikas Raykar. \"An Empirical Evaluation of various Deep\nLearning Architectures for Bi-Sequence Classification Tasks.\" COLING. 2016.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "3", "REVIEWER_CONFIDENCE": "3"}], "abstract": "Argumentation mining seeks to uncover the argument structure present in argumentative text. In order to determine this structure, one must understand how different individual components of the overall argument are linked. General consensus in this field dictates that the argument components form a hierarchy of persuasion, which manifests itself in a tree structure. This work provides the first neural network-based approach to argumentation mining, focusing on the dual tasks of extracting links between argument components, and classifying types of argument components. We propose to use a joint model based on a Pointer Network architecture to simultaneously solve these tasks. In doing so, we construct a joint model that simultaneously attempts to learn the type of argument component, as well as continuing to predict links between argument components. The proposed joint model achieves state-of-the-art results on two separate evaluation corpora, achieving far superior performance than a regular Pointer Network model. Our results show that optimizing for both tasks is crucial for high performance.", "histories": [], "id": 483, "title": "Here's My Point: Argumentation Mining with Pointer Networks"}
