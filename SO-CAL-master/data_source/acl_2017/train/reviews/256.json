{"reviews": [{"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "Review, ACL 2017, paper 256:\n\nThis paper extends the line of work which models generation in dialogue as a\nsequence to sequence generation problem, where the past N-1 utterances (the\n\u2018dialogue context\u2019) are encoded into a context vector (plus potential\nother, hand-crafted features), which is then decoded into a response: the Nth\nturn in the dialogue. As it stands, such models tend to suffer from lack of\ndiversity, specificity and local coherence in the kinds of response they tend\nto produce when trained over large dialogue datasets containing many topics\n(e.g. Cornell, Opensubtitles, Ubuntu, etc.). Rather than attempting to produce\ndiverse responses using the decoder, e.g. through word-by-word beam search\n(which has been shown not to work very well, even lose crucial information\nabout grammar and valid sequences), or via a different objective function (such\nas in Li et. al.\u2019s work) the authors introduce a latent variable, z, over\nwhich a probability distribution is induced as part of the network. At\nprediction time, after encoding utterances 1 to k, a context z is sampled, and\nthe decoder is greedily used to generate a response from this. The evaluation\nshows small improvements in BLEU scores over a vanilla seq2seq model that does\nnot involve learning a probability distribution over contexts and sampling from\nthis.\n\nThe paper is certainly impressive from a technical point of view, i.e. in the\napplication of deep learning methods, specifically conditioned variational auto\nencoders, to the problem of response generation, and its attendant difficulties\nin training such models. Their use of Information-Retrieval techniques to get\nmore than one reference response is also interesting. \n\nI have some conceptual comments on the introduction and the motivations behind\nthe work, some on the model architecture, and the evaluation which I write\nbelow in turn:\n\nComments on the introduction and motivations\u2026. \n\nThe authors seem not fully aware of the long history of this field, and its\nvarious facets, whether from a theoretical perspective, or from an applied one.\n\n1. \u201c[the dialogue manager] typically takes a new utterance and the dialogue\ncontext as input, and generates discourse level decisions.\u201d \n\n        This is not accurate. Traditionally at least, the job of the dialogue\nmanager is to select actions (dialogue acts) in a particular dialogue context.\nThe                    action chosen is then passed to a separate generation\nmodule\nfor\nrealisation. Dialogue management is usually done in the context of task-based\nsystems which are goal driven. The dialogue manager is to choose actions which\nare optimal in some sense, e.g. reach a goal (e.g. book a restaurant) in as few\nsteps as possible. See publications from Lemon & Pietquin, 2012, Rieser, Keizer\nand colleagues, and various publications from Steve Young, Milica Gasic and\ncolleagues for an overview of the large literature on Reinforcement Learning\nand MDP models for task-based dialogue systems.\n\n2. The authors need to make a clear distinction between task-based,\ngoal-oriented dialogue, and chatbots/social bots, the latter being usually no\nmore than a language model, albeit a sophisticated one (though see Wen et. al.\n2016). What is required from these two types of system is usually distinct.\nWhereas the former is required to complete a task, the latter is, perhaps only\nrequired to keep the user engaged. Indeed the data-driven methods that have\nbeen used to build such systems are usually very different. \n3. The authors refer to \u2018open-domain\u2019 conversation. I would suggest that\nthere is no such thing as open-domain conversation - conversation is always in\nthe context of some activity and for doing/achieving something specific in the\nworld. And it is this overarching goal, the overarching activity, this\noverarching genre, which determines the outward shape of dialogues and\ndetermines what sorts of dialogue structure are coherent. Coherence itself is\nactivity/context-specific. Indeed a human is not capable of open-domain\ndialogue: if they are faced with a conversational topic or genre that they have\nnever participated in, they would embarrass themselves with utterances that\nwould look incoherent and out of place to others already familiar with it.\n(think of a random person on the street trying to follow the conversations at\nsome coffee break at ACL). This is the fundamental problem I see with systems\nthat attempt to use data from an EXTREMELY DIVERSE, open-ended set of\nconversational genres (e.g. movie subtitles) in order to train one model,\nmushing everything together so that what emerges at the other end is just very\ngood grammatical structure. Or very generic responses. \n\nComments on the model architecture:\n\nRather than generate from a single encoded context, the authors induce a\ndistribution over possible contexts, sample from this, and generate greedily\nwith the decoder. It seems to me that this general model is counter intuitive,\nand goes against evidence from the Linguistic/Psycholinguistic literature on\ndialogue: this literature shows that people tend to resolve potential problems\nin understanding and acceptance very locally - i.e. make sure they agree on\nwhat the context of the conversation is - and only then move on with the rest\nof the conversation, so that at any given point, there is little uncertainty\nabout the current context of the conversation. The massive diversity one sees\nresults from the diversity in what the conversation is actually trying to\nachieve (see above), diversity in topics and contexts etc, so that in a given,\nfixed context, there is a multitude of possible next actions, all coherent, but\nleading the conversation down a different path.\n\nIt therefore seems strange to me at least to shift the burden of explaining\ndiversity and coherence in follow-up actions to that of the\nlinguistic/verbal/surface contexts in which they are uttered, though of course,\nuncertainty here can also arise as a result of mismatches in vocabulary,\ngrammars, concepts, people\u2019s backgrounds etc. But this probably wouldn\u2019t\nexplain much of the variation in follow-up response. \n\nIn fact, at least as far as task-based Dialogue systems are concerned, the\nchallenge is to capture synonymy of contexts, i.e. dialogues that are distinct\non the surface, but lead to the same or similar context, either in virtue of\ninteractional and syntactic equivalence relations, or synonymy relations that\nmight hold in a particular domain between words or sequences of words (e.g.\n\u201cwhat is your destination?\u201d = \u201cwhere would you like to go?\u201d in a flight\nbooking domain). See e.g. Bordes & Weston, 2016; and Kalatzis, Eshghi & Lemon,\n2016 - the latter use a grammar to cluster semantically similar dialogues.\n\nComments on the evaluation:\n\nThe authors seek to show that their model can generate more coherent, and more\ndiverse responses. The evaluation method, though very interesting, seems to\naddress coherence but not diversity, despite what they say in section 5.2:\n\nThe precision and recall metrics measure distance between ground truth\nutterances and the ones the model generates, but not that between the generated\nutterances themselves (unless I\u2019m misunderstanding the evaluation method).\nSee e.g. Li et al. who measure diversity by counting the number distinct\nn-grams in the generated responses.\n\nFurthermore, I\u2019m not sure that the increase in BLEU scores are meaningful:\nthey are very small. In the qualitative assessment of the generated responses,\none certainly sees more diversity, and more contentful utterances in the\nexamples provided. But I can\u2019t see how frequent such cases in fact are.\n\nAlso, it would have made for a stronger, more meaningful paper if the authors\nhad compared their results with other work, (e.g. Li et. al) that use very\ndifferent methods to promote diversity (e.g. by using a different objective\nfunction). The authors in fact do not mention this, or characterise it\nproperly, despite actually referring to Li et. al. 2015.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "4"}, {"IMPACT": "3", "SUBSTANCE": "5", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "This paper presents a neural sequence-to-sequence model for encoding dialog\ncontexts followed by decoding system responses in open-domain conversations.\nThe authors introduced conditional variational autoencoder (CVAE) which is a\ndeep neural network-based generative model to learn the latent variables for\ndescribing responses conditioning dialog contexts and dialog acts.\nThe proposed models achieved better performances than the baseline based on RNN\nencoder-decoder without latent variables in both quantitative and qualitative\nevaluations.\n\nThis paper is well written with clear descriptions, theoretically sound ideas,\nreasonable comparisons, and also detailed analysis.\nI have just a few minor comments as follows:\n\n- Would it be possible to provide statistical significance of the results from\nthe proposed models compared to the baseline in quantitative evaluation? The\ndifferences don't seem that much for some metrics.\n\n- Considering the importance of dialog act in kgCVAE model, the DA tagging\nperformances should affect the quality of the final results. Would it be there\nany possibility to achieve further improvement by using better DA tagger?\nRecently, deep learning models have achieved better performances than SVM also\nin DA tagging.\n\n- What do you think about doing human evaluation as a part of qualitative\nanalysis? It could be costly, but worth a try to analyze the results in more\npragmatic perspective.\n\n- As a future direction, it could be also interesting if kgCVAE model is\napplied to more task-oriented human-machine conversations which usually have\nmuch richer linguistic features available than open conversation.\n\n- In Table 1, 'BLUE-1 recall' needs to be corrected to 'BLEU-1 recall'.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "5", "CLARITY": "4", "REVIEWER_CONFIDENCE": "4"}], "abstract": "While recent neural encoder-decoder models have shown great promise in modeling open-domain conversations, they often generate dull and generic responses. Unlike past work that has focused on diversifying the output of the decoder from word-level to alleviate this problem, we present a novel framework based on conditional variational autoencoders that capture the discourse-level diversity in the encoder. Our model uses latent variables to learn a distribution over potential conversational intents and generates diverse responses using only greedy decoders. We have further developed a novel variant that is integrated with linguistic prior knowledge for better performance. Finally, the training procedure is improved through introducing a bag-of-word loss. Our proposed models have been validated to generate significantly more diverse responses than baseline approaches and exhibit competence of discourse-level decision-making.", "histories": [], "id": "256", "title": "Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders"}
