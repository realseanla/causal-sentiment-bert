{"reviews": [{"IMPACT": "3", "SUBSTANCE": "3", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "- Strengths:\n\nDetailed guidelines and explicit illustrations.\n\n- Weaknesses:\n\nThe document-independent crowdsourcing annotation is unreliable. \n\n- General Discussion:\n\nThis work creates a new benchmark corpus for concept-map-based MDS. It is well\norganized and written clearly. The supplement materials are sufficient. I have\ntwo questions here.\n1)              Is it necessary to treat concept map extraction as a separate\ntask?\nOn\nthe one hand, many generic summarization systems build a similar knowledge\ngraph and then generate summaries accordingly. On the other hand, with the\nincrease of the node number, the concept map becomes growing hard to\ndistinguish. Thus, the general summaries should be more readable.\n2)              How can you determine the importance of a concept independent of\nthe\ndocuments? The definition of summarization is to reserve the main concepts of\ndocuments. Therefore, the importance of a concept highly depends on the\ndocuments. For example, in the given topic of coal mining accidents, assume\nthere are two concepts: A) an instance of coal mining accidents and B) a cause\nof coal mining accidents. Then, if the document describes a series of coal\nmining accidents, A is more important than B. In comparison, if the document\nexplores why coal mining accidents happen, B is more significant than A.\nTherefore, just given the topic and two concepts A&B, it is impossible to judge\ntheir relative importance.\n\nI appreciate the great effort spent by authors to build this dataset. However,\nthis dataset is more like a knowledge graph based on common sense rather than\nsummary.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "3", "CLARITY": "5", "REVIEWER_CONFIDENCE": "5"}, {"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "Strengths:\n\nThis paper presents an approach to creating concept maps using crowdsourcing.\nThe general ideas are interesting and the main contribution lies in the\ncollection of the dataset. As such, I imagine that the dataset will be a\nvaluable resource for further research in this field. Clearly a lot of effort\nhas gone into this work.\n\nWeaknesses:\n\nOverall I felt this paper a bit overstated in placed. As an example, the\nauthors claim a new crowdsourcing scheme as one of their contributions. This\nclaims is quite strong though and it reads more like the authors are applying\nbest practice in crowdsourcing to their work. This isn\u2019t a novel methods\nthen, it\u2019s rather a well thought and sound application of existing knowledge.\n\nSimilarly, the authors claim that they develop and present a new corpus. This\nseems true and I can see how a lot of effort was invested in its preparation,\nbut then Section 4.1 reveals that actually this is based on an existing\ndataset. \n\nThis is more a criticism of the presentation than the work though.\n\nGeneral discussion:\n\nWhere do the summary sentences come from for the crowdsource task? Aren\u2019t\nthey still quite subjective?\n\nWhere do the clusters come from? Are they part of the TAC2008b dataset? \n\nIn 4.6 expert annotators are used to create the gold standard concept maps.\nMore information is needed in this section I would say as it seems to be quite\ncrucial. How were they trained, what made them experts?", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "3", "CLARITY": "3", "REVIEWER_CONFIDENCE": "2"}], "abstract": "Concept maps can be used to concisely represent important information and bring structure into large document collections. Therefore, we study a variant of multi-document summarization that produces summaries in the form of concept maps. However, suitable evaluation datasets for this task are currently missing. To close this gap, we present a newly created corpus of concept maps that summarize heterogeneous collections of web documents on educational topics. It was created using a novel crowdsourcing approach that allows us to efficiently determine important elements in large document collections. We release the corpus along with a baseline system and proposed evaluation protocol to enable further research on this variant of summarization.", "histories": [], "id": 331, "title": "Connecting the dots: Summarizing and Structuring Large Document Collections Using Concept Maps"}
