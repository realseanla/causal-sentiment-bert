{"reviews": [{"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "2", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "- Strengths:\nThis paper proposes a novel approach for dialogue state tracking that benefits\nfrom representing slot values with pre-trained embeddings and learns to compose\nthem into distributed representations of user utterances and dialogue context.\nExperiments performed on two datasets show consistent and significant\nimprovements over the baseline of previous delexicalization based approach.\nAlternative approaches (i.e., XAVIER, GloVe, Program-SL999) for pre-training\nword embeddings have been investigated.\n\n- Weaknesses:\nAlthough one of the main motivations for using embeddings is to generalize to\nmore complex dialogue domains where delexicalization may not scale for, the\ndatasets used seem limited.    I wonder how the approach would compare with and\nwithout a separate slot tagging component on more complex dialogues. For\nexample, when computing similarity between the utterance and slot value pairs,\none can actually limit the estimation to the span of the slot values. This\nshould be applicable even when the values do not match.\n\nI think the examples in the intro is misleading, shouldn\u2019t the dialogue state\nalso include \u201crestaurant_name=The House\u201d? This brings another question, how\ndoes resolution of coreferences impact this task?\n\n- General Discussion:\nOn the overall, use of pre-trained word embeddings is a great idea, and the\nspecific approach for using them is exciting.", "SOUNDNESS_CORRECTNESS": "4", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "4", "REVIEWER_CONFIDENCE": "4"}, {"IMPACT": "3", "SUBSTANCE": "3", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "2", "PRESENTATION_FORMAT": "Poster", "comments": "This paper presents a neural network-based framework for dialogue state\ntracking.\nThe main contribution of this work is on learning representations of user\nutterances, system outputs, and also ontology entries, all of which are based\non pre-trained word vectors.\nParticularly for the utterance representation, the authors compared two\ndifferent neural network models: NBT-DNN and NBT-CNN.\nThe learned representations are combined with each other and finally used in\nthe downstream network to make binary decision for a given slot value pair.\nThe experiment shows that the proposed framework achieved significant\nperformance improvements compared to the baseline with the delexicalized\napproach.\n\nIt's generally a quality work with clear goal, reasonable idea, and improved\nresults from previous studies.\nBut the paper itself doesn't seem to be very well organized to effectively\ndeliver the details especially to readers who are not familiar with this area.\n\nFirst of all, more formal definition of DST needs to be given at the beginning\nof this paper.\nIt is not clear enough and could be more confusing after coupling with SLU.\nMy suggestion is to provide a general architecture of dialogue system described\nin Section 1 rather than Section 2, followed by the problem definition of DST\nfocusing on its relationships to other components including ASR, SLU, and\npolicy learning.\n\nAnd it would also help to improve the readability if all the notations used\nthroughout the paper are defined in an earlier section.\nSome symbols (e.g. t_q, t_s, t_v) are used much earlier than their\ndescriptions.\n\nBelow are other comments or questions:\n\n- Would it be possible to perform the separate SLU with this model? If no, the\nterm 'joint' could be misleading that this model is able to handle both tasks.\n\n- Could you please provide some statistics about how many errors were corrected\nfrom the original DSTC2 dataset?\nIf it is not very huge, the experiment could include the comparisons also with\nother published work including DSTC2 entries using the same dataset.\n\n- What do you think about using RNNs or LSTMs to learn the sequential aspects\nin learning utterance representations?\nConsidering the recent successes of these recurrent networks in SLU problems,\nit could be effective to DST as well.\n\n- Some more details about the semantic dictionary used with the baseline would\nhelp to imply the cost for building this kind of resources manually.\n\n- It would be great if you could give some samples which were not correctly\npredicted by the baseline but solved with your proposed models.", "SOUNDNESS_CORRECTNESS": "4", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "3", "REVIEWER_CONFIDENCE": "5"}], "abstract": "One of the core components of modern spoken dialogue systems is the belief tracker, which estimates the user's goal at every step of the dialogue. However, most current approaches have difficulty scaling to larger, more complex dialogue domains. This is due to their dependency on either: a) Spoken Language Understanding models that require large amounts of annotated training data; or b) hand-crafted lexicons for capturing some of the linguistic variation in users' language. We propose a novel Neural Belief Tracking (NBT) framework which overcomes these problems by building on recent advances in representation learning. NBT models reason over pre-trained word vectors, learning to compose them into distributed representations of user utterances and dialogue context. Our evaluation on two datasets shows that this approach surpasses past limitations, matching the performance of state-of-the-art models which rely on hand-crafted semantic lexicons and outperforming them when such lexicons are not provided.", "histories": [], "id": 122, "title": "Neural Belief Tracker: Data-Driven Dialogue State Tracking"}
