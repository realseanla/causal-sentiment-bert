{"reviews": [{"IMPACT": "4", "SUBSTANCE": "5", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Poster", "comments": "- Strengths:\n\nThe authors use established neural network methods (adversarial networks --\nGoodfellow et al, NIPS-2014) to take advantage of 8 different Chinese work\nbreaking test sets, with 8 different notions of what counts as a word in\nChinese.\n\nThis paper could have implications for many NLP tasks where we have slightly\ndifferent notions of what counts as correct.  We have been thinking of that\nproblem in terms of adaptation, but it is possible that Goodfellow et al is a\nmore useful way of thinking about this problem.\n\n- Weaknesses:\n\nWe need a name for the problem mentioned above.  How about: the elusive gold\nstandard.  I prefer that term to multi-criteria.\n\nThe motivation seems to be unnecessarily narrow.  The elusive gold standard\ncomes up in all sorts of applications, not just Chinese Word Segmentation.\n\nThe motivation makes unnecessary assumptions about how much the reader knows\nabout Chinese.              When you don't know much about something, you think it is\neasier than it is.  Many non-Chinese readers (like this reviewer) think that\nChinese is simpler than it is.              It is easy to assume that Chinese Word\nSegmentation is about as easy as tokenizing English text into strings delimited\nby white space.  But my guess is that IAA (inter-annotator agreement) is pretty\nlow in Chinese.  The point you are trying to make in Table 1 is that there is\nconsiderable room for disagreement among native speakers of Chinese.\n\nI think it would help if you could point out that there are many NLP tasks\nwhere there is considerable room for disagreement.  Some tasks like machine\ntranslation, information retrieval and web search have so much room for\ndisagreement that the metrics for those tasks have been designed to allow for\nmultiple correct answers.  For other tasks, like part of speech tagging, we\ntend to sweep the elusive gold standard problem under a rug, and hope it will\njust go away.  But in fact, progress on tagging has stalled because we don't\nknow how to distinguish differences of opinions from errors.  When two\nannotators return two different answers, it is a difference of opinion.  But\nwhen a machine returns a different answer, the machine is almost always wrong.\n\nThis reader got stuck on the term: adversary.  I think the NIPS paper used that\nbecause it was modeling noise under \"murphy's law.\"  It is often wise to assume\nthe worst.\n\nBut I don't think it is helpful to think of differences of opinion as an\nadversarial game like chess.  In chess, it makes sense to think that your\nopponent is out to get you, but I'm not sure that's the most helpful way to\nthink about differences of opinion.\n\nI think it would clarify what you are doing to say that you are applying an\nestablished method from NIPS (that uses the term \"adversarial\") to deal with\nthe elusive gold standard problem.  And then point out that the elusive gold\nstandard problem is a very common problem.  You will study it in the context of\na particular problem in Chinese, but the problem is much more general than\nthat.\n\n- General Discussion:\n\nI found much of the paper unnecessarily hard going.  I'm not up on Chinese or\nthe latest in NIPS, which doesn't help.  But even so, there are some small\nissues with English, and some larger problems with exposition.\n\nConsider Table 4.  Line 525 makes an assertion about the first block and depth\nof networks.  Specifically, which lines in Table 4 support that assertion.\n\nI assume that P and R refer to precision and recall, but where is that\nexplained.  I assume that F is the standard F measure, and OOV is\nout-of-vocabulary, but again, I shouldn't have to assume such things.\n\nThere are many numbers in Table 4.  What counts as significance?  Which numbers\nare even comparable?  Can we compare numbers across cols?  Is performance on\none collection comparable to performance on another?  Line 560 suggests that\nthe adversarial method is not significant.  What should I take away from Table\n4?  Line 794 claims that you have a significant solution to what I call the\nelusive gold standard problem.              But which numbers in Table 4 justify that\nclaim?\n\nSmall quibbles about English:\n\nworks --> work (in many places).  Work is a  mass noun, not a count noun\n(unlike \"conclusion\").              One can say one conclusion, two conclusions, but\nmore/less/some work (not one work, two works).\n\nline 493: each dataset, not each datasets\n\nline 485: Three datasets use traditional Chinese (AS, CITY, CKIP) and the other\nfive use simplified Chinese.\n\nline 509: random --> randomize", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "3", "REVIEWER_CONFIDENCE": "3"}, {"IMPACT": "4", "SUBSTANCE": "5", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "The paper proposes a method to train models for Chinese word segmentation (CWS)\non datasets having multiple segmentation criteria.\n\n- Strengths:\n1. Multi-criteria learning is interesting and promising.\n2. The proposed model is also interesting and achieves a large improvement from\nbaselines.\n\n- Weaknesses:\n1. The proposed method is not compared with other CWS models. The baseline\nmodel (Bi-LSTM) is proposed in [1] and [2]. However, these model is proposed\nnot for CWS but for POS tagging and NE tagging. The description \"In this paper,\nwe employ the state-of-the-art architecture ...\" (in Section 2) is misleading.\n2. The purpose of experiments in Section 6.4 is unclear. In Sec. 6.4, the\npurpose is that investigating \"datasets in traditional Chinese and simplified\nChinese could help each other.\" However, in the experimental setting, the model\nis separately trained on simplified Chinese and traditional Chinese, and the\nshared parameters are fixed after training on simplified Chinese. What is\nexpected to fixed shared parameters?\n\n- General Discussion:\nThe paper should be more interesting if there are more detailed discussion\nabout the datasets that adversarial multi-criteria learning does not boost the\nperformance.\n\n[1] Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional lstm-crf models for\nsequence tagging. arXiv preprint arXiv:1508.01991.\n[2] Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via\nbi-directional lstm-cnns-crf. arXiv preprint arXiv:1603.01354 .", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "4", "REVIEWER_CONFIDENCE": "4"}], "abstract": "Different linguistic perspectives causes many diverse segmentation criteria for Chinese word segmentation (CWS). Most existing methods focus on improve the performance for each single criterion. However, it is interesting to exploit these different criteria and mining their common underlying knowledge. In this paper, we propose adversarial multi-criteria learning for CWS by integrating shared knowledge from multiple heterogeneous segmentation criteria.  Experiments on eight corpora with heterogeneous segmentation criteria show that the performance of each corpus obtains a significant improvement, compared to single-criterion learning. Source codes of this paper are available on Github.", "histories": [], "id": "326", "title": "Adversarial Multi-Criteria Learning for Chinese Word Segmentation"}
