{"reviews": [{"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "- Strengths: Useful modeling contribution, and potentially useful annotated\ndata, for an important problem -- event extraction for the relationships\nbetween countries as expressed in news text.\n\n- Weaknesses: Many points are not explained well in the paper. \n\n- General Discussion:\n\nThis work tackles an important and interesting event extraction problem --\nidentifying positive and negative interactions between pairs of countries in\nthe world (or rather, between actors affiliated with countries).  The primary\ncontribution is an application of supervised, structured neural network models\nfor sentence-level event/relation extraction.  While previous work has examined\ntasks in the overall area, to my knowledge there has not been any publicly\navailble sentence-level annotated data for the problem -- the authors here make\na contribution as well by annotating some data included with the submission; if\nit is released, it could be useful for future researchers in this area.\n\nThe proposed models -- which seem to be an application of various\ntree-structured recursive neural network models -- demonstrate a nice\nperformance increase compared to a fairly convincing, broad set of baselines\n(if we are able to trust them; see below).  The paper also presents a manual\nevaluation of the inferred time series from a news corpus which is nice to see.\n\nI'm torn about this paper.  The problem is a terrific one and the application\nof the recursive models seems like a contribution to this problem. \nUnfortunately, many aspects of the models, experimentation, and evaluation are\nnot explained very well.  The same work, with a more carefully written paper,\ncould be really great.\n\nSome notes:\n\n- Baselines need more explanation.  For example, the sentiment lexicon is not\nexplained for the SVM.                    The LSTM classifier is left highly\nunspecified\n(L407-409) -- there are multiple different architectures to use an LSTM for\nclassification.  How was it trained?  Is there a reference for the approach? \nAre the authors using off-the-shelf code (in which case, please refer and cite,\nwhich would also make it easier for the reader to understand and replicate if\nnecessary)?  It would be impossible to replicate based on the two-line\nexplanation here.  \n\n- (The supplied code does not seem to include the baselines, just the recursive\nNN models.  It's great the authors supplied code for part of the system so I\ndon't want to penalize them for missing it -- but this is relevant since the\npaper itself has so few details on the baselines that they could not really be\nreplicated based on the explanation in the paper.)\n\n- How were the recursive NN models trained?\n\n- The visualization section is only a minor contribution; there isn't really\nany innovation or findings about what works or doesn't work here.\n\nLine by line:\n\nL97-99: Unclear. Why is this problem difficult?  Compared to what? (also the\nsentence is somewhat ungrammatical...)\n\nL231 - the trees are binarized, but how?\n\nFootnote 2 -- \"the tensor version\" - needs citation to explain what's being\nreferred to.\n\nL314: How are non-state verbs defined?                    Does the definition of\n\"event\nword\"s\nhere come from any particular previous work that motivates it?                   \nPlease\nrefer to\nsomething appropriate or related.\n\nFootnote 4: of course the collapsed form doesn't work, because the authors\naren't using dependency labels -- the point of stanford collapsed form is to\nremove prepositions from the dependeny path and instead incorporate them into\nthe labels.\n\nL414: How are the CAMEO/TABARI categories mapped to positive and negative\nentries?  Is performance sensitive to this mapping?  It seems like a hard task\n(there are hundreds of those CAMEO categories....) Did the authors consider\nusing the Goldstein scaling, which has been used in political science, as well\nas the cited work by O'Connor et al.?  Or is it bad to use for some reason?\n\nL400-401: what is the sentiment lexicon and why is it appropriate for the task?\n\nL439-440: Not clear.  \"We failed at finding an alpha meeting the requirements\nfor the FT model.\"  What does that mean? What are the requirements? What did\nthe authors do in their attempt to find it?\n\nL447,L470: \"precision and recall values are based on NEG and POS classes\". \nWhat does this mean?  So there's a 3x3 contingency table of gold and predicted\n(POS, NEU, NEG) classes, but this sentence leaves ambiguous how precision and\nrecall are calculated from this information.\n\n5.1 aggregations: this seems fine though fairly ad-hoc.  Is this temporal\nsmoothing function a standard one?  There's not much justification for it,\nespecially given something simpler like a fixed window average could have been\nused.\n\n5.2 visualizations: this seems pretty ad-hoc without much justification for the\nchoices.  The graph visualization shown does not seem to illustrate much. \nShould also discuss related work in 2d spatial visualization of country-country\nrelationships by Peter Hoff and Michael Ward.\n\n5.3\nL638-639: \"unions of countries\" isn't a well defined concept.  mMybe the\nauthors mean \"international organizations\"?\n\nL646-648: how were these 5 strong and 5 weak peaks selected?  In particular,\nhow were they chosen if there were more than 5 such peaks?\n\nL680-683: This needs more examples or explanation of what it means to judge the\npolarity of a peak.  What does it look like if the algorithm is wrong?               \n   \nHow\nhard was this to assess?  What was agreement rate if that can be judged?\n\nL738-740: The authors claim Gerrish and O'Connor et al. have a different\n\"purpose and outputs\" than the authors' work.  That's not right.  Both those\nworks try to do both (1) extract time series or other statistical information\nabout the polarity of the relationships between countries, and *also* (2)\nextract topical keywords to explain aspects of the relationships.  The paper\nhere is only concerned with #1 and less concerned with #2, but certainly the\nprevious work addresses #1.  It's fine to not address #2 but this last sentence\nseems like a pretty odd statement.\n\nThat raises the question -- Gerrish and O'Connor both conduct evaluations with\nan external database of country relations developed in political science\n(\"MID\", military interstate disputes).              Why don't the authors of this\nwork do\nthis evaluation as well?  There are various weaknesses of the MID data, but the\nevaluation approach needs to be discussed or justified.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "2", "CLARITY": "2", "REVIEWER_CONFIDENCE": "4"}], "abstract": "In this article, we explore how text mining can help producing reliable, high-level numerical data for multi-document relation extraction applications. We combine neural network techniques, information aggregation and visualization methods to extract event-based relations with a good tolerance to noise. We describe a search engine based on these methods, identifying the evolution of alliance and opposition relations between countries.", "histories": [], "id": 376, "title": "Event-based, Recursive Neural Networks for the Extraction and Aggregation of International Alliance Relations"}
