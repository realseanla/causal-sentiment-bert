{"reviews": [{"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Poster", "comments": "- Summary: \n\nThe paper introduces a new dataset for a sarcasm interpretation task\nand a system (called Sarcasm SIGN) based on machine translation framework\nMoses. The new dataset was collected from 3000 sarcastic tweets (with hashtag\n`#sarcasm) and 5 interpretations for each from humans. The Sarcasm SIGN is\nbuilt\nbased on Moses by replacing sentimental words by their corresponding clusters\non the source side (sarcasm) and then de-cluster their translations on the\ntarget side (non-sarcasm). Sarcasm SIGN performs on par with Moses on the MT\nevaluation metrics, but outperforms Moses in terms of fluency and adequacy. \n\n- Strengths:\n\nthe paper is well written\n\nthe dataset is collected in a proper manner\n\nthe experiments are carefully done and the analysis is sound.\n\n- Weaknesses:\n\nlack statistics of the datsets (e.g. average length, vocabulary size)\n\nthe baseline (Moses) is not proper because of the small size of the dataset\n\nthe assumption \"sarcastic tweets often differ from their non sarcastic\ninterpretations in as little as one sentiment word\" is not supported by the\ndata. \n\n- General Discussion: This discussion gives more details about the weaknesses\nof the paper. \n\nHalf of the paper is about the new dataset for sarcasm interpretation.\nHowever, the paper doesn't show important information about the dataset such as\naverage length, vocabulary size. More importantly, the paper doesn't show any\nstatistical evidence to support their method of focusing on sentimental words. \n\nBecause the dataset is small (only 3000 tweets), I guess that many words are\nrare. Therefore, Moses alone is not a proper baseline. A proper baseline should\nbe a MT system that can handle rare words very well. In fact, using\nclustering and declustering (as in Sarcasm SIGN) is a way to handle rare words.\n\nSarcasm SIGN is built based on the assumption that \"sarcastic tweets often\ndiffer from their non sarcastic interpretations in as little as one sentiment\nword\". Table 1 however strongly disagrees with this assumption: the human\ninterpretations are often different from the tweets at not only sentimental\nwords. I thus strongly suggest the authors to give statistical evidence from\nthe dataset that supports their assumption. Otherwise, the whole idea of\nSarcasm SIGN is just a hack.\n\n--------------------------------------------------------------\n\nI have read the authors' response. I don't change my decision because of the\nfollowing reasons: \n\n- the authors wrote that \"the Fiverr workers might not take this strategy\": to\nme it is not the spirit of corpus-based NLP. A model must be built to fit given\ndata, not that the data must follow some assumption that the model is built on.\n\n- the authors wrote that \"the BLEU scores of Moses and SIGN are above 60, which\nis generally considered decent in the MT literature\": to me the number 60\ndoesn't \nshow anything at all because the sentences in the dataset are very short. And\nthat,\nif we look at table 6, %changed of Moses is only 42%, meaning that even more\nthan half of the time translation is simply copying, the BLUE score is more\nthan 60.\n\n- \"While higher scores might be achieved with MT systems that explicitly\naddress rare words, these systems don't focus on sentiment words\": it's true,\nbut I was wondering whether sentiment words are rare in the corpus. If they\nare, those MT systems should obviously handle them (in addition to other rare\nwords).", "SOUNDNESS_CORRECTNESS": "4", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "3", "CLARITY": "4", "REVIEWER_CONFIDENCE": "3"}, {"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Poster", "comments": "- Strengths:\n\n(1) A new dataset would be useful for other researchers in this area\n\n(2) An algorithm with sentiment words based machine translation is proposed to\ninterpret sarcasm tweets.\n\n- Weaknesses:\n\n(1) Do not provide detailed statistics of constructed dataset.\n\n(2) Integrating sentiment word clustering with machine translation techniques\nonly is simple and straightforward, novelty may be a challenging issue. \n\n- General Discussion:\n\nOverall, this paper is well written. The experiments are conducted carefully\nand the analysis is reasonable. \n\nI offer some comments as follows.\n(1) According to data collection process, each tweet should be annotated\nfive times. How to determine which one is regarded as gold standard for measure\nperformance?\n\n(2) The MT technique (Moses) is well known, but it may not be a good\nbaseline. Another MT technique (RNN) should be put together for comparison.   \n\n(3) Differ from most work focuses on sarcasm detection. The research topic\nis interesting. It attempts to interpret sarcasm for reflecting semantics.", "SOUNDNESS_CORRECTNESS": "4", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "3", "CLARITY": "5", "REVIEWER_CONFIDENCE": "3"}, {"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Poster", "comments": "This paper focuses on interpreting sarcasm written in Twitter identifying\nsentiment words and then using a machine translation engine to find an\nequivalent not sarcastic tweet. \n\nEDIT: Thank you for your answers, I appreaciate it. I added one line commenting\nabout it.\n\n- Strengths:\n\nAmong the positive aspects of your work, I would like to mention the parallel\ncorpus you presented. I think it will be very useful for other researchers in\nthe area for identifying and interpreting sarcasm in social media. An important\ncontribution is also the attempt to evaluate the parallel corpora using\nexisting measures such as the ones used in MT tasks. But also because you used\nhuman judgements to evaluate the corpora in 3 aspects: fluency, adequacy and\nequivalent sentiment.\n\n- Room for improvement:\n\nTackling the problem of interpretation as a monolingual machine translations\ntask is interesting, while I do appreciate the intent to compare the MT with\ntwo architectures, I think that due the relatively small dataset (needed for\nRNN) used it was predictable that the \u201cNeural interpretation\u201d is performing\nworse than \u201cmoses interpretation\u201d. You came to the same conclusion after\nseeing the results in Table3. In addition to comparing with this architecture,\nI would've liked to see other configuration of the MT used with moses. Or at\nleast, you should provide some explanation of why you use the configuration\ndescribed in lines 433 through 442; to me this choice is not justified. \n  - thank you for your response, I understand it is difficult to write down all\nthe details but I hope you include a line with some of your answer in the\npaper, I believe this could add valuable information.\n\nWhen you presented SING, it is clear that you evaluate some of its components\nbeforehand, i.e. the MT. But other important components are not evaluated,\nparticularly, the clustering you used of positive and negative words. While you\ndid said you used k-means as a clustering algorithm it is not clear to me why\nyou wanted to create clusters with 10 words. Why not test with other number of\nk, instead of 7 and 16, for positive and negative words respectively. Also you\ncould try another algorithm beside kmeans, for instance, the star clustering\nalgorithm (Aslam et al. 2004), that do not require a k parameter. \n   - thanks for clarifying.\n\nYou say that SIGN searches the tweet for sentiment words if it found one it\nchanges it for the cluster ID that contain that word. I am assuming that there\nis not a limit for the number of sentiment words found, and the MT decides by\nitself how many sentiment words to change. For example, for the tweet provided\nin Section 9: \u201cConstantly being irritated, anxious and depressed is a great\nfeeling\u201d the clustering stage of SIGN should do something like \u201cConstantly\nbeing cluster-i, cluster-j and cluster-k is a cluster-h feeling\u201d, Is that\ncorrect? If not, please explain what SIGN do.\n    - Thanks for clarifying\n\n- Minor comments:\n\nIn line 704, section 7, you said: \u201cSIGN-context\u2019s interpretations differ\nfrom the original sarcastic tweet in 68.5% of the cases, which come closer to\nthe 73.8% in the gold standard human interpretations.\u201d This means that 25% of\nthe human interpretations are the same as the original tweet? Do you have any\nidea why is that?\n\nIn section 6, line 539 you could eliminate the footnote 7 by adding \u201cits\ncluster ID\u201d or \u201cits cluster number\u201d.\n\nReferences:\nAslam, Javed A., Pelekhov, Ekaterina, and Rus, Daniela. \"The star clustering\nalgorithm for static and dynamic information organization..\" Journal of Graph\nAlgorithms and Applications 8.1 (2004): 95-129. <http://eudml.org/doc/51529>.", "SOUNDNESS_CORRECTNESS": "4", "ORIGINALITY": "3", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "4"}], "abstract": "Sarcasm is a form of speech in which speakers say the opposite of what they truly mean in order to convey a strong sentiment. In other words, \u201dSarcasm is the giant chasm between what I say, and the person who doesn\u2019t get it.\u201d. In this paper we present the novel task of sarcasm interpretation, defined as the generation of a non-sarcastic utterance conveying the same message as the original sarcastic one. We introduce a novel dataset of 3000 sarcastic tweets, each interpreted by five human judges. Addressing the task as monolingual machine translation (MT), we experiment with MT algorithms and evaluation measures. We then present SIGN: an MT based sarcasm interpretation algorithm that targets sentiment words, a defining element of textual sarcasm. We show that while the scores of n-gram based automatic measures are similar for all interpretation models, SIGN\u2019s interpretations are scored higher by humans for adequacy and sentiment polarity. We conclude with a discussion on future research directions for our new task.", "histories": [], "id": "96", "title": "Sarcasm SIGN: Interpreting Sarcasm with Sentiment Based Monolingual Machine Translation"}
