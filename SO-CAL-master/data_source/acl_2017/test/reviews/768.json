{"reviews": [{"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "- Strengths: A well written paper, examining the use of context in lexical\nentailment task is a great idea, a well defined approach and experimental\nset-up and good analysis of the results \n\n- Weaknesses: Some information is missing or insufficient, e.g., the table\ncaptions should be more descriptive, a clear description for each of the word\ntype features should be given.\n\nGeneral Discussion: \n\nThe paper presents a proposal of consideration of context\nin lexical entailment task. The results from the experiments demonstrate that\ncontext-informed models do better than context-agnostic models on the\nentailment task. \n\nI liked the idea of creating negative examples to get negative annotations\nautomatically in the two ways described in the paper based on WordNet positive\nexamples. (new dataset; an interesting method to develop dataset)\n\nI also liked the idea of transforming already-used context-agnostic\nrepresentations into contextualized representations, experimenting with\ndifferent ways to get contextualized representations (i.e., mask vs\ncontetx2vec), and testing the model on 3 different datasets (generalizability\nnot just across different datasets but also cross-linguistically).\n\nMotivations for various decisions in the experimental design were good to\nsee, e.g., why authors used the split they used for CONTEXT-PPDB (it showed\nthat they thought out clearly what exactly they were doing and why).\n\nLines 431-434: authors might want to state briefly how the class weights were\ndetermined and added to account for the unbalanced data in the CONTEXT-WN\nexperiments. Would it affect direct comparisons with previous work, in what\nways? \n\nChange in Line 589: directionality 4 --> directionality, as in Table 4\n\nSuggested change in Line 696-697: is-a hierarchy of WordNet --> \"is-a\"\nhierarchy of WordNet \n\nFor the sake of completeness, represent \"mask\" also in Figure 1.\n\nI have read the author response.", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "4", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "4", "REVIEWER_CONFIDENCE": "2"}, {"IMPACT": "3", "SUBSTANCE": "1", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Poster", "comments": "This paper proposes a method for recognizing lexical entailment (specifically,\nhypernymy) in context. The proposed method represents each context by\naveraging, min-pooling, and max-pooling its word embeddings. These\nrepresentations are combined with the target word's embedding via element-wise\nmultiplication. The in-context representation of the left-hand-side argument is\nconcatenated to that of the right-hand-side argument's, creating a single\nvectorial representation of the input. This input is then fed into a logistic\nregression classifier.\n\nIn my view, the paper has two major weaknesses. First, the classification model\nused in this paper (concat + linear classifier) was shown to be inherently\nunable to learn relations in \"Do Supervised Distributional Methods Really Learn\nLexical Inference Relations?\" (Levy et al., 2015). Second, the paper makes\nsuperiority claims in the text that are simply not substantiated in the\nquantitative results. In addition, there are several clarity and experiment\nsetup issues that give an overall feeling that the paper is still half-baked.\n\n= Classification Model =\n\nConcatenating two word vectors as input for a linear classifier was\nmathematically proven to be incapable of learning a relation between words\n(Levy et al., 2015). What is the motivation behind using this model in the\ncontextual setting?\n\nWhile this handicap might be somewhat mitigated by adding similarity features,\nall these features are symmetric (including the Euclidean distance, since |L-R|\n= |R-L|). Why do we expect these features to detect entailment?\n\nI am not convinced that this is a reasonable classification model for the task.\n\n= Superiority Claims =\n\nThe authors claim that their contextual representation is superior to\ncontext2vec. This is not evident from the paper, because:\n\n1) The best result (F1) in both table 3 and table 4 (excluding PPDB features)\nis the 7th row. To my understanding, this variant does not use the proposed\ncontextual representation; in fact, it uses the context2vec representation for\nthe word type.\n\n2) This experiment uses ready-made embeddings (GloVe) and parameters\n(context2vec) that were tuned on completely different datasets with very\ndifferent sizes. Comparing the two is empirically flawed, and probably biased\ntowards the method using GloVe (which was a trained on a much larger corpus).\n\nIn addition, it seems that the biggest boost in performance comes from adding\nsimilarity features and not from the proposed context representation. This is\nnot discussed.\n\n= Miscellaneous Comments =\n\n- I liked the WordNet dataset - using the example sentences is a nice trick.\n\n- I don\u2019t quite understand why the task of cross-lingual lexical entailment\nis interesting or even reasonable.\n\n- Some basic baselines are really missing. Instead of the \"random\" baseline,\nhow well does the \"all true\" baseline perform? What about the context-agnostic\nsymmetric cosine similarity of the two target words?\n\n- In general, the tables are very difficult to read. The caption should make\nthe tables self-explanatory. Also, it is unclear what each variant means;\nperhaps a more precise description (in text) of each variant could help the\nreader understand?\n\n- What are the PPDB-specific features? This is really unclear.\n\n- I could not understand 8.1.\n\n- Table 4 is overfull.\n\n- In table 4, the F1 of \"random\" should be 0.25.\n\n- Typo in line 462: should be \"Table 3\"\n\n= Author Response =\n\nThank you for addressing my comments. Unfortunately, there are still some\nstanding issues that prevent me from accepting this paper:\n\n- The problem I see with the base model is not that it is learning prototypical\nhypernyms, but that it's mathematically not able to learn a relation.\n\n- It appears that we have a different reading of tables 3 and 4. Maybe this is\na clarity issue, but it prevents me from understanding how the claim that\ncontextual representations substantially improve performance is supported.\nFurthermore, it seems like other factors (e.g. similarity features) have a\ngreater effect.", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "4", "is_meta_review": null, "RECOMMENDATION": "2", "CLARITY": "3", "REVIEWER_CONFIDENCE": "5"}, {"IMPACT": "3", "SUBSTANCE": "3", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "4", "PRESENTATION_FORMAT": "Poster", "comments": "This paper addresses the task of lexical entailment detection in context, e.g.\nis \"chess\" a kind of \"game\" given a sentence containing each of the words --\nrelevant for QA. The major contributions are:\n\n(1) a new dataset derived from WordNet using synset exemplar sentences, and \n\n(2) a \"context relevance mask\" for a word vector, accomplished by elementwise\nmultiplication with feature vectors derived from the context sentence. Fed to a\nlogistic regression classifier, the masked word vectors just beat state of the\nart on entailment prediction on a PPDB-derived dataset from previous\nliterature. Combined with other existing features, they beat state of the art\nby a few points. They also beats the baseline on the new WN-derived dataset,\nalthough the best-scoring method on that dataset doesn't use the masked\nrepresentations.\n\nThe paper also introduces some simple word similarity features (cosine,\neuclidean distance) which accompany other cross-context similarity features\nfrom previous literature. All of the similarity features, together, improve the\nclassification results by a large amount, but the features in the present paper\nare a relatively small contribution.\n\nThe task is interesting, and the work seems to be correct as far as it goes,\nbut incremental. The method of producing the mask vectors is taken from\nexisting literature on encoding variable-length sequences into min/max/mean\nvectors, but I don't think they've been used as masks before, so this is novel.\nHowever, excluding the PPDB features it looks like the best result does not use\nthe representation introduced in the paper.\n\nA few more specific points:\n\nIn the creation of the new Context-WN dataset, are there a lot of false\nnegatives resulting from similar synsets in the \"permuted\" examples? If you\ntake word w, with synsets i and j, is it guaranteed that the exemplar context\nfor a hypernym synset of j is a bad entailment context for i? What if i and j\nare semantically close?\n\nWhy does the masked representation hurt classification with the\ncontext-agnostic word vectors (rows 3, 5 in Table 3) when row 1 does so well?\nWouldn't the classifier learn to ignore the context-agnostic features?\n\nThe paper should make clearer which similarity measures are new and which are\nfrom previous literature. It currently says that previous lit used the \"most\nsalient\" similarity features, but that's not informative to the reader.\n\nThe paper should be clearer about the contribution of the masked vectors vs the\nsimilarity features. It seems like similarity is doing most of the work.\n\nI don't understand the intuition behind the Macro-F1 measure, or how it relates\nto \"how sensitive are our models to changes in context\" -- what changes? How do\nwe expect Macro-F1 to compare with F1?\n\nThe cross-language task is not well motivated.\n\nMissing a relevant citation: Learning to Distinguish Hypernyms and Co-Hyponyms.\nJulie Weeds, Daoud Clarke, Jeremy Reffin, David Weir and Bill Keller. COLING\n2014.\n\n==\n\nI have read the author response. As noted in the original reviews, a quick\nexamination of the tables shows that the similarity features make the largest\ncontribution to the improvement in F-score on the two datasets (aside from PPDB\nfeatures). The author response makes the point that similarities include\ncontextualized representations. However, the similarity features are a mixed\nbag, including both contextualized and non-contextualized representations. This\nwould need to be teased out more (as acknowledged in the response).\n\nNeither Table 3 nor 4 gives results using only the masked representations\nwithout the similarity features. This makes the contribution of the masked\nrepresentations difficult to isolate.", "SOUNDNESS_CORRECTNESS": "3", "ORIGINALITY": "4", "is_meta_review": null, "RECOMMENDATION": "2", "CLARITY": "2", "REVIEWER_CONFIDENCE": "4"}], "abstract": "Detecting entailment between words is a key task for several NLP applications. Previous work has largely focused on entailment between words out of context. We propose, instead, to address lexical entailment in context, providing exemplar sentences to ground the meaning of words considered in the entailment relation. We show that contextualized word representations constructed from existing word embeddings, and word-context similarity features lead to significant improvements over context-agnostic models on two novel entailment test sets, and also improve the state-of-the-art on the related task of detecting semantic relations in context.", "histories": [], "id": 768, "title": "Detecting Lexical Entailment in Context"}
