{"reviews": [{"IMPACT": "3", "SUBSTANCE": "3", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Poster", "comments": "- Strengths: The authors have nice coverage of a different range of language\nsettings to isolate the way that relatedness and amount of morphology interact\n(i.e., translating between closely related morphologically rich languages vs\ndistant ones) in affecting what the system learns about morphology. They\ninclude an illuminating analysis of what parts of the architecture end up being\nresponsible for learning morphology, particularly in examining how the\nattention mechanism leads to more impoverished target side representations.\nTheir findings are of high interest and practical usefulness for other users of\nNMT. \n\n- Weaknesses: They gloss over the details of their character-based encoder.\nThere are many different ways to learn character-based representations, and\nomitting a discussion of how they do this leaves open questions about the\ngenerality of their findings. Also, their analysis could've been made more\ninteresting had they chosen languages with richer and more challenging\nmorphology such as Turkish or Finnish, accompanied by finer-grained morphology\nprediction and analysis.\n\n- General Discussion: This paper brings insight into what NMT models learn\nabout morphology by training NMT systems and using the encoder or decoder\nrepresentations, respectively, as input feature representations to a POS- or\nmorphology-tagging classification task. This paper is a straightforward\nextension of \"Does String-Based Neural MT Learn Source Syntax?,\" using the same\nmethodology but this time applied to morphology. Their findings offer useful\ninsights into what NMT systems learn.", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "4"}, {"IMPACT": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "MEANINGFUL_COMPARISON": "3", "PRESENTATION_FORMAT": "Oral Presentation", "comments": "Strengths:\n\n- This paper describes experiments that aim to address a crucial\nproblem for NMT: understanding what does the model learn about morphology and\nsyntax, etc..\n- Very clear objectives and experiments effectively laid down.              Good\nstate\nof the art review and comparison. In general, this paper is a pleasure to read.\n- Sound experimentation framework. Encoder/Decoder Recurrent layer\noutputs are used to train POS/morphological classifiers. They show the effect\nof certain changes in the framework on the classifier accuracy (e.g. use\ncharacters instead of words).\n- Experimentation is carried out on many language pairs.\n- Interesting conclusions derived from this work, and not all agree with\nintuition.\n\nWeaknesses:\n\n -  The contrast of character-based vs word-based representations  is slightly\nlacking: NMT with byte-pair encoding is showing v. strong performance in the\nliterature. It would have been more relevant to have BPE in the mix, or replace\nword-based representations if three is too many.\n - Section 1: \"\u2026 while higher layers are more focused on word meaning\";\nsimilar sentence in Section 7. I am ready to agree with this intuition, but I\nthink the experiments in this paper do not support this particular sentence.\nTherefore it should not be included, or it should be clearly stressed that this\nis a reasonable hypothesis based on indirect evidence (translation performance\nimproves but morphology on higher layers does not).\n\nDiscussion:\n\nThis is a  fine paper that presents a thorough and systematic analysis of the\nNMT model, and derives several interesting conclusions based on many data\npoints across several language pairs. I find particularly interesting that (a)\nthe target language affects the quality of the encoding on the source side; in\nparticular, when the target side is a morphologically-poor language (English)\nthe pos tagger accuracy for the encoder improves. (b) increasing the depth of\nthe encoder does not improve pos accuracy (more experiments needed to determine\nwhat does it improve); (c) the attention layer hurts the quality of the decoder\nrepresentations.  I wonder if (a) and (c) are actually related? The attention\nhurts the decoder representation, which is more difficult to learn for a\nmorphologically rich language; in turn, the encoders learn based on the global\nobjective, and this backpropagates through the decoder. Would this not be a\nstrong\nindication that we need separate objectives to govern the encoder/decoder\nmodules of\nthe NMT model?", "SOUNDNESS_CORRECTNESS": "5", "ORIGINALITY": "5", "is_meta_review": null, "RECOMMENDATION": "4", "CLARITY": "5", "REVIEWER_CONFIDENCE": "4"}], "abstract": "Neural machine translation (MT) models obtain state-of-the-art performance while maintaining a simple, end-to-end architecture. However, little is known about what these models learn about source and target languages during the training process. In this work, we analyze the representations learned by neural MT models at various levels of granularity and empirically evaluate the quality of the representations for learning morphology through extrinsic part-of-speech and morphological tagging tasks. We conduct a thorough investigation along several parameters: word-based vs. character-based representations, depth of the encoding layer, the identity of the target language, and encoder vs. decoder representations. Our data-driven, quantitative evaluation sheds light on important aspects in the neural MT system and its ability to capture word structure.", "histories": [], "id": 496, "title": "What do Neural Machine Translation Models Learn about Morphology?"}
