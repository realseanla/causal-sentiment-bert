{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2013", "title": "Factorial Hidden Markov Models for Learning Representations of Natural Language", "abstract": "Most representation learning algorithms for language and image processing are local, in that they identify features for a data point based on surrounding points. Yet in language processing, the correct meaning of a word often depends on its global context. As a step toward incorporating global context into representation learning, we develop a representation learning algorithm that incorporates joint prediction into its technique for producing features for a word. We develop efficient variational methods for learning Factorial Hidden Markov Models from large texts, and use variational distributions to produce features for each word that are sensitive to the entire input sequence, not just to a local context window. Experiments on part-of-speech tagging and chunking indicate that the features are competitive with or better than existing state-of-the-art representation learning methods.", "histories": [["v1", "Fri, 20 Dec 2013 22:44:26 GMT  (43kb)", "https://arxiv.org/abs/1312.6168v1", "11 pages, 2 tabels, ICLR-2014"], ["v2", "Wed, 15 Jan 2014 04:49:47 GMT  (43kb)", "http://arxiv.org/abs/1312.6168v2", "11 pages, 2 tables, ICLR-2014"], ["v3", "Tue, 18 Feb 2014 11:22:30 GMT  (45kb)", "http://arxiv.org/abs/1312.6168v3", "12 pages, 2 tables, ICLR-2014"]], "COMMENTS": "11 pages, 2 tabels, ICLR-2014", "reviews": [], "SUBJECTS": "cs.LG cs.CL", "authors": ["anjan nepal", "alexander yates"], "accepted": false, "id": "1312.6168"}
