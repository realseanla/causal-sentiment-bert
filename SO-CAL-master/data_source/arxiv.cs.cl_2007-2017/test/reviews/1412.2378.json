{"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Dec-2014", "title": "Learning Word Representations from Relational Graphs", "abstract": "Attributes of words and relations between two words are central to numerous tasks in Artificial Intelligence such as knowledge representation, similarity measurement, and analogy detection. Often when two words share one or more attributes in common, they are connected by some semantic relations. On the other hand, if there are numerous semantic relations between two words, we can expect some of the attributes of one of the words to be inherited by the other. Motivated by this close connection between attributes and relations, given a relational graph in which words are inter- connected via numerous semantic relations, we propose a method to learn a latent representation for the individual words. The proposed method considers not only the co-occurrences of words as done by existing approaches for word representation learning, but also the semantic relations in which two words co-occur. To evaluate the accuracy of the word representations learnt using the proposed method, we use the learnt word representations to solve semantic word analogy problems. Our experimental results show that it is possible to learn better word representations by using semantic semantics between words.", "histories": [["v1", "Sun, 7 Dec 2014 17:49:53 GMT  (211kb,D)", "http://arxiv.org/abs/1412.2378v1", "AAAI 2015"]], "COMMENTS": "AAAI 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["danushka bollegala", "takanori maehara", "yuichi yoshida", "ken-ichi kawarabayashi"], "accepted": true, "id": "1412.2378"}
