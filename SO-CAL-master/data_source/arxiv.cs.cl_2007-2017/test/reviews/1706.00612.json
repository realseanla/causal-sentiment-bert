{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2017", "title": "Attentive Convolutional Neural Network based Speech Emotion Recognition: A Study on the Impact of Input Features, Signal Length, and Acted Speech", "abstract": "Speech emotion recognition is an important and challenging task in the realm of human-computer interaction. Prior work proposed a variety of models and feature sets for training a system. In this work, we conduct extensive experiments using an attentive convolutional neural network with multi-view learning objective function. We compare system performance using different lengths of the input signal, different types of acoustic features and different types of emotion speech (improvised/scripted). Our experimental results on the Interactive Emotional Motion Capture (IEMOCAP) database reveal that the recognition performance strongly depends on the type of speech data independent of the choice of input features. Furthermore, we achieved state-of-the-art results on the improvised speech data of IEMOCAP.", "histories": [["v1", "Fri, 2 Jun 2017 10:12:52 GMT  (161kb,D)", "http://arxiv.org/abs/1706.00612v1", "to appear in the proceedings of Interspeech 2017"]], "COMMENTS": "to appear in the proceedings of Interspeech 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["michael neumann", "ngoc thang vu"], "accepted": false, "id": "1706.00612"}
