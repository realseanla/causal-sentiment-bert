{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Apr-2016", "title": "Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction", "abstract": "We demonstrate that an attention-based encoder-decoder model can be used for sentence-level grammatical error identification for the Automated Evaluation of Scientific Writing (AESW) Shared Task 2016. The attention-based encoder-decoder models can be used for the generation of corrections, in addition to error identification, which is of interest for certain end-user applications. We show that a character-based encoder-decoder model is particularly effective, outperforming other results on the AESW Shared Task on its own, and showing gains over a word-based counterpart. Our final model--a combination of three character-based encoder-decoder models, one word-based encoder-decoder model, and a sentence-level CNN--is the highest performing system on the AESW 2016 binary prediction Shared Task.", "histories": [["v1", "Sat, 16 Apr 2016 01:49:09 GMT  (143kb,D)", "http://arxiv.org/abs/1604.04677v1", "To appear at BEA11, as part of the AESW 2016 Shared Task"]], "COMMENTS": "To appear at BEA11, as part of the AESW 2016 Shared Task", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["allen schmaltz", "yoon kim", "alexander m rush", "stuart m shieber"], "accepted": false, "id": "1604.04677"}
