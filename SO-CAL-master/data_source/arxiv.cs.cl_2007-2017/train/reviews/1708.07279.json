{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Aug-2017", "title": "Combining Discrete and Neural Features for Sequence Labeling", "abstract": "Neural network models have recently received heated research attention in the natural language processing community. Compared with traditional models with discrete features, neural models have two main advantages. First, they take low-dimensional, real-valued embedding vectors as inputs, which can be trained over large raw data, thereby addressing the issue of feature sparsity in discrete models. Second, deep neural networks can be used to automatically combine input features, and including non-local features that capture semantic patterns that cannot be expressed using discrete indicator features. As a result, neural network models have achieved competitive accuracies compared with the best discrete models for a range of NLP tasks.", "histories": [["v1", "Thu, 24 Aug 2017 05:24:26 GMT  (575kb,D)", "http://arxiv.org/abs/1708.07279v1", "Accepted by International Conference on Computational Linguistics and Intelligent Text Processing (CICLing) 2016, April"]], "COMMENTS": "Accepted by International Conference on Computational Linguistics and Intelligent Text Processing (CICLing) 2016, April", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jie yang", "zhiyang teng", "meishan zhang", "yue zhang"], "accepted": false, "id": "1708.07279"}
