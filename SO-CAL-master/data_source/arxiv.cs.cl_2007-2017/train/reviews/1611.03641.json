{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2016", "title": "Improving Reliability of Word Similarity Evaluation by Redesigning Annotation Task and Performance Measure", "abstract": "We suggest a new method for creating and using gold-standard datasets for word similarity evaluation. Our goal is to improve the reliability of the evaluation, and we do this by redesigning the annotation task to achieve higher inter-rater agreement, and by defining a performance measure which takes the reliability of each annotation decision in the dataset into account.", "histories": [["v1", "Fri, 11 Nov 2016 10:06:29 GMT  (42kb,D)", "http://arxiv.org/abs/1611.03641v1", null], ["v2", "Mon, 27 Feb 2017 18:38:56 GMT  (34kb,D)", "http://arxiv.org/abs/1611.03641v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["oded avraham", "yoav goldberg"], "accepted": false, "id": "1611.03641"}
