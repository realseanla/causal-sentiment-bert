{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Feb-2014", "title": "Modelling the Lexicon in Unsupervised Part of Speech Induction", "abstract": "Automatically inducing the syntactic part-of-speech categories for words in text is a fundamental task in Computational Linguistics. While the performance of unsupervised tagging models has been slowly improving, current state-of-the-art systems make the obviously incorrect assumption that all tokens of a given word type must share a single part-of-speech tag. This one-tag-per-type heuristic counters the tendency of Hidden Markov Model based taggers to over generate tags for a given word type. However, it is clearly incompatible with basic syntactic theory. In this paper we extend a state-of-the-art Pitman-Yor Hidden Markov Model tagger with an explicit model of the lexicon. In doing so we are able to incorporate a soft bias towards inducing few tags per type. We develop a particle filter for drawing samples from the posterior of our model and present empirical results that show that our model is competitive with and faster than the state-of-the-art without making any unrealistic restrictions.", "histories": [["v1", "Wed, 26 Feb 2014 12:37:04 GMT  (89kb,D)", "http://arxiv.org/abs/1402.6516v1", "To be presented at the 14th Conference of the European Chapter of the Association for Computational Linguistics"]], "COMMENTS": "To be presented at the 14th Conference of the European Chapter of the Association for Computational Linguistics", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["greg dubbin", "phil blunsom"], "accepted": false, "id": "1402.6516"}
