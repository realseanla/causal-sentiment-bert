{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Mar-2016", "title": "Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning", "abstract": "In traditional formulations, information extraction systems operate on a fixed collection of documents. In this work, we explore the task of acquiring and incorporating external evidence to improve extraction accuracy. This process entails query reformulation for search, extraction from new sources and reconciliation of extracted values, which are repeated until sufficient evidence is collected. We approach the problem using a reinforcement learning framework where our model learns to select optimal actions based on contextual information. We employ a deep Q-network, trained to optimize a reward function that reflects extraction accuracy while penalizing extra effort. Our experiments on a publicly available database of shooting incidents demonstrate that our system outperforms traditional extractors by 7.2% on average.", "histories": [["v1", "Fri, 25 Mar 2016 16:38:54 GMT  (1314kb,D)", "http://arxiv.org/abs/1603.07954v1", "10 pages"], ["v2", "Tue, 14 Jun 2016 03:24:37 GMT  (1175kb,D)", "http://arxiv.org/abs/1603.07954v2", "Updated with additional experiments, 10 pages"], ["v3", "Tue, 27 Sep 2016 23:33:28 GMT  (1181kb,D)", "http://arxiv.org/abs/1603.07954v3", "Appearing in EMNLP 2016 (12 pages incl. supplementary material)"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["karthik narasimhan", "adam yala", "regina barzilay"], "accepted": true, "id": "1603.07954"}
