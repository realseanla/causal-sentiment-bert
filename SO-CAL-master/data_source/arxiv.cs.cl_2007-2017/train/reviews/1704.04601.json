{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Apr-2017", "title": "MUSE: Modularizing Unsupervised Sense Embeddings", "abstract": "This paper proposes to address the word sense ambiguity issue in an unsupervised manner, where word sense representations are learned along a word sense selection mechanism given contexts. Prior work about learning multi-sense embeddings suffered from either ambiguity of different-level embeddings or inefficient sense selection. The proposed modular framework, MUSE, implements flexible modules to optimize distinct mechanisms, achieving the first purely sense-level representation learning system with linear-time sense selection. We leverage reinforcement learning to enable joint training on the proposed modules, and introduce various exploration techniques on sense selection for better robustness. The experiments on benchmark data show that the proposed approach achieves the state-of-the-art performance on synonym selection as well as on contextual word similarities in terms of MaxSimC.", "histories": [["v1", "Sat, 15 Apr 2017 07:36:49 GMT  (466kb,D)", "http://arxiv.org/abs/1704.04601v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["guang-he lee", "yun-nung chen"], "accepted": true, "id": "1704.04601"}
