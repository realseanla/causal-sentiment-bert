{"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2017", "title": "Neural Models for Sequence Chunking", "abstract": "Many natural language understanding (NLU) tasks, such as shallow parsing (i.e., text chunking) and semantic slot filling, require the assignment of representative labels to the meaningful chunks in a sentence. Most of the current deep neural network (DNN) based methods consider these tasks as a sequence labeling problem, in which a word, rather than a chunk, is treated as the basic unit for labeling. These chunks are then inferred by the standard IOB (Inside-Outside-Beginning) labels. In this paper, we propose an alternative approach by investigating the use of DNN for sequence chunking, and propose three neural models so that each chunk can be treated as a complete unit for labeling. Experimental results show that the proposed neural sequence chunking models can achieve start-of-the-art performance on both the text chunking and slot filling tasks.", "histories": [["v1", "Sun, 15 Jan 2017 11:08:28 GMT  (224kb,D)", "http://arxiv.org/abs/1701.04027v1", "Accepted by AAAI 2017"]], "COMMENTS": "Accepted by AAAI 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["feifei zhai", "saloni potdar", "bing xiang", "bowen zhou"], "accepted": true, "id": "1701.04027"}
