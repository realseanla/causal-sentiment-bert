{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Nov-2016", "title": "Multi-view Recurrent Neural Acoustic Word Embeddings", "abstract": "Recent work has begun exploring neural acoustic word embeddings--fixed-dimensional vector representations of arbitrary-length speech segments corresponding to words. Such embeddings are applicable to speech retrieval and recognition tasks, where reasoning about whole words may make it possible to avoid ambiguous sub-word representations. The main idea is to map acoustic sequences to fixed-dimensional vectors such that examples of the same word are mapped to similar vectors, while different-word examples are mapped to very different vectors. In this work we take a multi-view approach to learning acoustic word embeddings, in which we jointly learn to embed acoustic sequences and their corresponding character sequences. We use deep bidirectional LSTM embedding models and multi-view contrastive losses. We study the effect of different loss variants, including fixed-margin and cost-sensitive losses. Our acoustic word embeddings improve over previous approaches for the task of word discrimination. We also present results on other tasks that are enabled by the multi-view approach, including cross-view word discrimination and word similarity.", "histories": [["v1", "Mon, 14 Nov 2016 17:47:03 GMT  (900kb)", "https://arxiv.org/abs/1611.04496v1", "In submission to ICLR 2017"], ["v2", "Fri, 10 Mar 2017 23:57:57 GMT  (1464kb,D)", "http://arxiv.org/abs/1611.04496v2", "Appearing in ICLR 2017"]], "COMMENTS": "In submission to ICLR 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["wanjia he", "weiran wang", "karen livescu"], "accepted": true, "id": "1611.04496"}
