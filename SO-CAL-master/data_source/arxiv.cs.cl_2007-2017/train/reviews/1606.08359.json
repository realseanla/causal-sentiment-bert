{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2016", "title": "Lifted Rule Injection for Relation Embeddings", "abstract": "Methods based on representation learning currently hold the state-of-the-art in many natural language processing and knowledge base inference tasks. Yet, a major challenge is how to efficiently incorporate commonsense knowledge into such models. A recent approach regularizes relation and entity representations by propositionalization of first-order logic rules. However, propositionalization does not scale beyond domains with only few entities and rules. In this paper we present a highly efficient method for incorporating implication rules into distributed representations for automated knowledge base construction. We map entity-tuple embeddings into an approximately Boolean space and encourage a partial ordering over relation embeddings based on implication rules mined from WordNet. Surprisingly, we find that the strong restriction of the entity-tuple embedding space does not hurt the expressiveness of the model and even acts as a regularizer that improves generalization. By incorporating few commonsense rules, we achieve an increase of 2 percentage points mean average precision over a matrix factorization baseline, while observing a negligible increase in runtime.", "histories": [["v1", "Mon, 27 Jun 2016 16:39:23 GMT  (292kb,D)", "http://arxiv.org/abs/1606.08359v1", null], ["v2", "Fri, 23 Sep 2016 20:40:25 GMT  (294kb,D)", "http://arxiv.org/abs/1606.08359v2", "Camera-ready version for EMNLP 2016 Conference"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CL", "authors": ["thomas demeester", "tim rockt\u00e4schel", "sebastian riedel"], "accepted": true, "id": "1606.08359"}
