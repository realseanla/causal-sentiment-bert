{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Feb-2016", "title": "Cross-Language Domain Adaptation for Classifying Crisis-Related Short Messages", "abstract": "Rapid crisis response requires real-time analysis of messages. After a disaster happens, volunteers attempt to classify tweets to determine needs, e.g., supplies, infrastructure damage, etc. Given labeled data, supervised machine learning can help classify these messages. Scarcity of labeled data causes poor performance in machine training. Can we reuse old tweets to train classifiers? How can we choose labeled tweets for training? Specifically, we study the usefulness of labeled data of past events. Do labeled tweets in different language help? We observe the performance of our classifiers trained using different combinations of training sets obtained from past disasters. We perform extensive experimentation on real crisis datasets and show that the past labels are useful when both source and target events are of the same type (e.g. both earthquakes). For similar languages (e.g., Italian and Spanish), cross-language domain adaptation was useful, however, when for different languages (e.g., Italian and English), the performance decreased.", "histories": [["v1", "Wed, 17 Feb 2016 12:29:56 GMT  (264kb)", "http://arxiv.org/abs/1602.05388v1", "10 pages"], ["v2", "Tue, 29 Mar 2016 07:18:43 GMT  (264kb)", "http://arxiv.org/abs/1602.05388v2", "ISCRAM 2016, 10 pages, 4 tables"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["muhammad imran", "prasenjit mitra", "jaideep srivastava"], "accepted": false, "id": "1602.05388"}
