{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2017", "title": "Unlabeled Data for Morphological Generation With Character-Based Sequence-to-Sequence Models", "abstract": "We present a semi-supervised way of training a character-based encoder-decoder recurrent neural network for morphological reinflection, the task of generating one inflected word form from another. This is achieved by using unlabeled tokens or random string as training data for an autoencoding task, adapting a network for morphological reinflection, and performing multi-task training. We thus use limited labeled data more effectively, obtaining up to 9.9% improvement over state-of-the-art baselines for 8 different languages.", "histories": [["v1", "Wed, 17 May 2017 11:48:15 GMT  (192kb,D)", "http://arxiv.org/abs/1705.06106v1", null], ["v2", "Fri, 21 Jul 2017 13:02:20 GMT  (460kb,D)", "http://arxiv.org/abs/1705.06106v2", "Accepted at SCLeM 2017"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["katharina kann", "hinrich sch\\\"utze"], "accepted": false, "id": "1705.06106"}
