{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Sep-2016", "title": "Learning Robust Representations of Text", "abstract": "Deep neural networks have achieved remarkable results across many language processing tasks, however these methods are highly sensitive to noise and adversarial attacks. We present a regularization based method for limiting network sensitivity to its inputs, inspired by ideas from computer vision, thus learning models that are more robust. Empirical evaluation over a range of sentiment datasets with a convolutional neural network shows that, compared to a baseline model and the dropout method, our method achieves superior performance over noisy inputs and out-of-domain data.", "histories": [["v1", "Tue, 20 Sep 2016 10:23:47 GMT  (31kb)", "http://arxiv.org/abs/1609.06082v1", "5 pages with 2 pages reference, 2 tables, 1 figure"]], "COMMENTS": "5 pages with 2 pages reference, 2 tables, 1 figure", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yitong li", "trevor cohn", "timothy baldwin"], "accepted": true, "id": "1609.06082"}
