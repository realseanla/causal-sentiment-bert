{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jul-2017", "title": "Tensor Fusion Network for Multimodal Sentiment Analysis", "abstract": "Multimodal sentiment analysis is an increasingly popular research area, which extends the conventional language-based definition of sentiment analysis to a multimodal setup where other relevant modalities accompany language. In this paper, we pose the problem of multimodal sentiment analysis as modeling intra-modality and inter-modality dynamics. We introduce a novel model, termed Tensor Fusion Network, which learns both such dynamics end-to-end. The proposed approach is tailored for the volatile nature of spoken language in online videos as well as accompanying gestures and voice. In the experiments, our model outperforms state-of-the-art approaches for both multimodal and unimodal sentiment analysis.", "histories": [["v1", "Sun, 23 Jul 2017 05:54:20 GMT  (3958kb,D)", "http://arxiv.org/abs/1707.07250v1", "Accepted as full paper in EMNLP 2017"]], "COMMENTS": "Accepted as full paper in EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["amir zadeh", "minghai chen", "soujanya poria", "erik cambria", "louis-philippe morency"], "accepted": true, "id": "1707.07250"}
