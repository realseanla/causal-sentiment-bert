{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Sep-2016", "title": "Distilling an Ensemble of Greedy Dependency Parsers into One MST Parser", "abstract": "We introduce two first-order graph-based dependency parsers achieving a new state of the art. The first is a consensus parser built from an ensemble of independently trained greedy LSTM transition-based parsers with different random initializations. We cast this approach as minimum Bayes risk decoding (under the Hamming cost) and argue that weaker consensus within the ensemble is a useful signal of difficulty or ambiguity. The second parser is a \"distillation\" of the ensemble into a single model. We train the distillation parser using a structured hinge loss objective with a novel cost that incorporates ensemble uncertainty estimates for each possible attachment, thereby avoiding the intractable cross-entropy computations required by applying standard distillation objectives to problems with structured outputs. The first-order distillation parser matches or surpasses the state of the art on English, Chinese, and German.", "histories": [["v1", "Sat, 24 Sep 2016 02:58:26 GMT  (44kb,D)", "http://arxiv.org/abs/1609.07561v1", "10 pages. To appear at EMNLP 2016"]], "COMMENTS": "10 pages. To appear at EMNLP 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["adhiguna kuncoro", "miguel ballesteros", "lingpeng kong", "chris dyer", "noah a smith"], "accepted": true, "id": "1609.07561"}
