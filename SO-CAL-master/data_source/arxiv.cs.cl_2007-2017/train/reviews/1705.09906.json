{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-May-2017", "title": "Listen, Interact and Talk: Learning to Speak via Interaction", "abstract": "One of the long-term goals of artificial intelligence is to build an agent that can communicate intelligently with human in natural language. Most existing work on natural language learning relies heavily on training over a pre-collected dataset with annotated labels, leading to an agent that essentially captures the statistics of the fixed external training data. As the training data is essentially a static snapshot representation of the knowledge from the annotator, the agent trained this way is limited in adaptiveness and generalization of its behavior. Moreover, this is very different from the language learning process of humans, where language is acquired during communication by taking speaking action and learning from the consequences of speaking action in an interactive manner. This paper presents an interactive setting for grounded natural language learning, where an agent learns natural language by interacting with a teacher and learning from feedback, thus learning and improving language skills while taking part in the conversation. To achieve this goal, we propose a model which incorporates both imitation and reinforcement by leveraging jointly sentence and reward feedbacks from the teacher. Experiments are conducted to validate the effectiveness of the proposed approach.", "histories": [["v1", "Sun, 28 May 2017 07:48:14 GMT  (614kb,D)", "http://arxiv.org/abs/1705.09906v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["haichao zhang", "haonan yu", "wei xu"], "accepted": false, "id": "1705.09906"}
