{"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2015", "title": "Multilingual Language Processing From Bytes", "abstract": "We describe an LSTM-based model which we call Byte-to-Span (BTS) that reads text as bytes and outputs span annotations of the form [start, length, label] where start positions, lengths, and labels are separate entries in our vocabulary. Because we operate on unicode bytes rather than language-specific words or characters, we can analyze text in many languages with a single model. Due to the small vocabulary size, these multilingual models are very compact, but produce results similar to or better than the state-of-the-art in Part-of-Speech tagging and Named Entity Recognition that use only the provided training datasets (no external data sources). Our models are learning \"from scratch\" in that they do not rely on any elements of the standard pipeline in Natural Language Processing.", "histories": [["v1", "Tue, 1 Dec 2015 00:23:44 GMT  (49kb,D)", "http://arxiv.org/abs/1512.00103v1", null], ["v2", "Sat, 2 Apr 2016 16:26:23 GMT  (92kb,D)", "http://arxiv.org/abs/1512.00103v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dan gillick", "cliff brunk", "oriol vinyals", "amarnag subramanya"], "accepted": true, "id": "1512.00103"}
