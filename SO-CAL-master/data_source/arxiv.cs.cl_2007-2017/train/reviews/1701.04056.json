{"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2017", "title": "Dialog Context Language Modeling with Recurrent Neural Networks", "abstract": "In this work, we propose contextual language models that incorporate dialog level discourse information into language modeling. Previous works on contextual language model treat preceding utterances as a sequence of inputs, without considering dialog interactions. We design recurrent neural network (RNN) based contextual language models that specially track the interactions between speakers in a dialog. Experiment results on Switchboard Dialog Act Corpus show that the proposed model outperforms conventional single turn based RNN language model by 3.3% on perplexity. The proposed models also demonstrate advantageous performance over other competitive contextual language models.", "histories": [["v1", "Sun, 15 Jan 2017 15:10:29 GMT  (88kb,D)", "http://arxiv.org/abs/1701.04056v1", "Accepted for publication at ICASSP 2017"]], "COMMENTS": "Accepted for publication at ICASSP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["bing liu", "ian lane"], "accepted": true, "id": "1701.04056"}
