{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Sep-2016", "title": "Skipping Word: A Character-Sequential Representation based Framework for Question Answering", "abstract": "Recent works using artificial neural networks based on word distributed representation greatly boost the performance of various natural language learning tasks, especially question answering. Though, they also carry along with some attendant problems, such as corpus selection for embedding learning, dictionary transformation for different learning tasks, etc. In this paper, we propose to straightforwardly model sentences by means of character sequences, and then utilize convolutional neural networks to integrate character embedding learning together with point-wise answer selection training. Compared with deep models pre-trained on word embedding (WE) strategy, our character-sequential representation (CSR) based method shows a much simpler procedure and more stable performance across different benchmarks. Extensive experiments on two benchmark answer selection datasets exhibit the competitive performance compared with the state-of-the-art methods.", "histories": [["v1", "Fri, 2 Sep 2016 11:57:46 GMT  (160kb,D)", "http://arxiv.org/abs/1609.00565v1", "to be accepted as CIKM2016 short paper"]], "COMMENTS": "to be accepted as CIKM2016 short paper", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lingxun meng", "yan li", "mengyi liu", "peng shu"], "accepted": false, "id": "1609.00565"}
