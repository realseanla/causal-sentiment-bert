{"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jul-2017", "title": "Analogs of Linguistic Structure in Deep Representations", "abstract": "We investigate the compositional structure of message vectors computed by a deep network trained on a communication game. By comparing truth-conditional representations of encoder-produced message vectors to human-produced referring expressions, we are able to identify aligned (vector, utterance) pairs with the same meaning. We then search for structured relationships among these aligned pairs to discover simple vector space transformations corresponding to negation, conjunction, and disjunction. Our results suggest that neural representations are capable of spontaneously developing a \"syntax\" with functional analogues to qualitative properties of natural language.", "histories": [["v1", "Tue, 25 Jul 2017 18:10:48 GMT  (2658kb,D)", "http://arxiv.org/abs/1707.08139v1", "In EMNLP 2017"]], "COMMENTS": "In EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL cs.NE", "authors": ["jacob", "reas", "dan klein"], "accepted": true, "id": "1707.08139"}
