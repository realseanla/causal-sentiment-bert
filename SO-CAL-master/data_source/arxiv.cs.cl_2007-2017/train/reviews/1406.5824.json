{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jun-2014", "title": "VideoSET: Video Summary Evaluation through Text", "abstract": "In this paper we present VideoSET, a method for Video Summary Evaluation through Text that can evaluate how well a video summary is able to retain the semantic information contained in its original video. We observe that semantics is most easily expressed in words, and develop a text-based approach for the evaluation. Given a video summary, a text representation of the video summary is first generated, and an NLP-based metric is then used to measure its semantic distance to ground-truth text summaries written by humans. We show that our technique has higher agreement with human judgment than pixel-based distance metrics. We also release text annotations and ground-truth text summaries for a number of publicly available video datasets, for use by the computer vision community.", "histories": [["v1", "Mon, 23 Jun 2014 07:56:23 GMT  (4078kb,D)", "http://arxiv.org/abs/1406.5824v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.CL cs.IR", "authors": ["serena yeung", "alireza fathi", "li fei-fei"], "accepted": false, "id": "1406.5824"}
