{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2017", "title": "Fine-grained human evaluation of neural versus phrase-based machine translation", "abstract": "We compare three approaches to statistical machine translation (pure phrase-based, factored phrase-based and neural) by performing a fine-grained manual evaluation via error annotation of the systems' outputs. The error types in our annotation are compliant with the multidimensional quality metrics (MQM), and the annotation is performed by two annotators. Inter-annotator agreement is high for such a task, and results show that the best performing system (neural) reduces the errors produced by the worst system (phrase-based) by 54%.", "histories": [["v1", "Wed, 14 Jun 2017 09:59:47 GMT  (172kb,D)", "http://arxiv.org/abs/1706.04389v1", "12 pages, 2 figures, The Prague Bulletin of Mathematical Linguistics"]], "COMMENTS": "12 pages, 2 figures, The Prague Bulletin of Mathematical Linguistics", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["filip klubi\\v{c}ka", "antonio toral", "v\\'ictor m s\\'anchez-cartagena"], "accepted": false, "id": "1706.04389"}
