{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Aug-2016", "title": "Hierarchical Attention Model for Improved Machine Comprehension of Spoken Content", "abstract": "Multimedia or spoken content presents more attractive information than plain text content, but the former is more difficult to display on a screen and be selected by a user. As a result, accessing large collections of the former is much more difficult and time-consuming than the latter for humans. It's therefore highly attractive to develop machines which can automatically understand spoken content and summarize the key information for humans to browse over. In this endeavor, a new task of machine comprehension of spoken content was proposed recently. The initial goal was defined as the listening comprehension test of TOEFL, a challenging academic English examination for English learners whose native languages are not English. An Attention-based Multi-hop Recurrent Neural Network (AMRNN) architecture was also proposed for this task, which considered only the sequential relationship within the speech utterances. In this paper, we propose a new Hierarchical Attention Model (HAM), which constructs multi-hopped attention mechanism over tree-structured rather than sequential representations for the utterances. Improved comprehension performance robust with respect to ASR errors were obtained.", "histories": [["v1", "Sun, 28 Aug 2016 06:48:14 GMT  (302kb,D)", "https://arxiv.org/abs/1608.07775v1", null], ["v2", "Sat, 1 Oct 2016 03:19:40 GMT  (302kb,D)", "http://arxiv.org/abs/1608.07775v2", "Copyright 2016 IEEE. Published in the 2016 IEEE Workshop on Spoken Language Technology (SLT 2016)"], ["v3", "Sun, 1 Jan 2017 12:17:13 GMT  (302kb,D)", "http://arxiv.org/abs/1608.07775v3", "Copyright 2016 IEEE. Published in the 2016 IEEE Workshop on Spoken Language Technology (SLT 2016)"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["wei fang", "jui-yang hsu", "hung-yi lee", "lin-shan lee"], "accepted": false, "id": "1608.07775"}
