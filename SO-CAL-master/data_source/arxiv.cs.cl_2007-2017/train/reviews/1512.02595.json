{"conference": "icml", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Dec-2015", "title": "Deep Speech 2: End-to-End Speech Recognition in English and Mandarin", "abstract": "We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech--two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks, end-to-end learning allows us to handle a diverse variety of speech including noisy environments, accents and different languages. Key to our approach is our application of HPC techniques, resulting in a 7x speedup over our previous system. Because of this efficiency, experiments that previously took weeks now run in days. This enables us to iterate more quickly to identify superior architectures and algorithms. As a result, in several cases, our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally, using a technique called Batch Dispatch with GPUs in the data center, we show that our system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.", "histories": [["v1", "Tue, 8 Dec 2015 19:13:50 GMT  (871kb,D)", "http://arxiv.org/abs/1512.02595v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dario amodei", "rishita anubhai", "eric battenberg", "carl case", "jared casper", "bryan catanzaro", "jingdong chen", "mike chrzanowski", "adam coates", "greg diamos", "erich elsen", "jesse engel", "linxi fan", "christopher fougner", "tony han", "awni hannun", "billy jun", "patrick legresley", "libby lin", "sharan narang", "rew ng", "sherjil ozair", "ryan prenger", "jonathan raiman", "sanjeev satheesh", "david seetapun", "shubho sengupta", "yi wang", "zhiqian wang", "chong wang", "bo xiao", "dani yogatama", "jun zhan", "zhenyao zhu"], "accepted": true, "id": "1512.02595"}
