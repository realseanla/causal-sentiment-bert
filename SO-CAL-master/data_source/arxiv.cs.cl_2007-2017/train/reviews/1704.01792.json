{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Apr-2017", "title": "Neural Question Generation from Text: A Preliminary Study", "abstract": "Automatic question generation aims to generate questions from a text passage where the generated questions can be answered by certain sub-spans of the given passage. Traditional methods mainly use rigid heuristic rules to transform a sentence into related questions. In this work, we propose to apply the neural encoder-decoder model to generate meaningful and diverse questions from natural language sentences. The encoder reads the input text and the answer position, to produce an answer-aware input representation, which is fed to the decoder to generate an answer focused question. We conduct a preliminary study on neural question generation from text with the SQuAD dataset, and the experiment results show that our method can produce fluent and diverse questions.", "histories": [["v1", "Thu, 6 Apr 2017 11:44:07 GMT  (244kb,D)", "https://arxiv.org/abs/1704.01792v1", "Submitted to EMNLP 2017"], ["v2", "Sun, 16 Apr 2017 03:27:15 GMT  (338kb,D)", "http://arxiv.org/abs/1704.01792v2", "Submitted to EMNLP 2017"], ["v3", "Tue, 18 Apr 2017 07:54:52 GMT  (337kb,D)", "http://arxiv.org/abs/1704.01792v3", "Submitted to EMNLP 2017"]], "COMMENTS": "Submitted to EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["qingyu zhou", "nan yang", "furu wei", "chuanqi tan", "hangbo bao", "ming zhou"], "accepted": false, "id": "1704.01792"}
