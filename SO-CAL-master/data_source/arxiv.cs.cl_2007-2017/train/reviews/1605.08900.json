{"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-May-2016", "title": "Aspect Level Sentiment Classification with Deep Memory Network", "abstract": "We introduce a deep memory network for aspect level sentiment classification. Unlike feature-based SVM and sequential neural models such as LSTM, this approach explicitly captures the importance of each context word when inferring the sentiment polarity of an aspect. Such importance degree and text representation are calculated with multiple computational layers, each of which is a neural attention model over an external memory. Experiments on laptop and restaurant datasets demonstrate that our approach performs comparable to state-of-art feature based SVM system, and substantially better than LSTM and attention-based LSTM architectures. On both datasets we show that multiple computational layers could improve the performance. Moreover, our approach is also fast. The deep memory network with 9 layers is 15 times faster than LSTM with a CPU implementation.", "histories": [["v1", "Sat, 28 May 2016 14:47:49 GMT  (601kb,D)", "http://arxiv.org/abs/1605.08900v1", null], ["v2", "Sat, 24 Sep 2016 06:04:15 GMT  (311kb,D)", "http://arxiv.org/abs/1605.08900v2", "published in EMNLP 2016"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["duyu tang", "bing qin", "ting liu"], "accepted": true, "id": "1605.08900"}
