{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2017", "title": "pix2code: Generating Code from a Graphical User Interface Screenshot", "abstract": "Transforming a graphical user interface screenshot created by a designer into computer code is a typical task conducted by a developer in order to build customized software, websites and mobile applications. In this paper, we show that Deep Learning techniques can be leveraged to automatically generate code given a graphical user interface screenshot as input. Our model is able to generate code targeting three different platforms (i.e. iOS, Android and web-based technologies) from a single input image with over 77% of accuracy.", "histories": [["v1", "Mon, 22 May 2017 19:32:20 GMT  (1094kb,D)", "http://arxiv.org/abs/1705.07962v1", "Submitted to 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA"], ["v2", "Tue, 19 Sep 2017 11:27:47 GMT  (1079kb,D)", "http://arxiv.org/abs/1705.07962v2", null]], "COMMENTS": "Submitted to 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CL cs.CV cs.NE", "authors": ["tony beltramelli"], "accepted": false, "id": "1705.07962"}
