{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2016", "title": "Exploring Prediction Uncertainty in Machine Translation Quality Estimation", "abstract": "Machine Translation Quality Estimation is a notoriously difficult task, which lessens its usefulness in real-world translation environments. Such scenarios can be improved if quality predictions are accompanied by a measure of uncertainty. However, models in this task are traditionally evaluated only in terms of point estimate metrics, which do not take prediction uncertainty into account. We investigate probabilistic methods for Quality Estimation that can provide well-calibrated uncertainty estimates and evaluate them in terms of their full posterior predictive distributions. We also show how this posterior information can be useful in an asymmetric risk scenario, which aims to capture typical situations in translation workflows.", "histories": [["v1", "Thu, 30 Jun 2016 18:10:46 GMT  (177kb,D)", "http://arxiv.org/abs/1606.09600v1", "Proceedings of CoNLL 2016"]], "COMMENTS": "Proceedings of CoNLL 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["daniel beck", "lucia specia", "trevor cohn"], "accepted": false, "id": "1606.09600"}
