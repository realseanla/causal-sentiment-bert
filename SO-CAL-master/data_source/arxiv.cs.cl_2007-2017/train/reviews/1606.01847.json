{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2016", "title": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding", "abstract": "Modeling textual or visual information with vector representations trained from large language or visual datasets has been successfully explored in recent years. However, tasks such as visual question answering require combining these vector representations with each other. Approaches to multimodal pooling include element-wise multiplication or addition, as well as concatenation of the visual and textual representations. We hypothesize that these methods are not as expressive as an outer product of the visual and textual vectors. As the outer product is typically infeasible due to its high dimensionality, we instead propose utilizing Multimodal Compact Bilinear pooling (MCB) to efficiently and expressively combine multimodal features. We extensively evaluate MCB on the visual question answering and grounding tasks. We consistently show the benefit of MCB over ablations without MCB. For visual question answering, we present an architecture which uses MCB twice, once for predicting attention over spatial features and again to combine the attended representation with the question representation. This model outperforms the state-of-the-art on the Visual7W dataset and the VQA challenge.", "histories": [["v1", "Mon, 6 Jun 2016 17:59:56 GMT  (2194kb,D)", "http://arxiv.org/abs/1606.01847v1", null], ["v2", "Thu, 23 Jun 2016 19:52:41 GMT  (3358kb,D)", "http://arxiv.org/abs/1606.01847v2", "Added qualitative and quantitative results"], ["v3", "Sat, 24 Sep 2016 01:58:59 GMT  (3443kb,D)", "http://arxiv.org/abs/1606.01847v3", "Accepted to EMNLP 2016"]], "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.CL", "authors": ["akira fukui", "dong huk park", "daylen yang", "anna rohrbach", "trevor darrell", "marcus rohrbach"], "accepted": true, "id": "1606.01847"}
