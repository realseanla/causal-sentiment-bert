{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-May-2016", "title": "Machine Translation Evaluation: A Survey", "abstract": "This paper introduces the state-of-the-art MT evaluation survey that contains both manual and automatic evaluation methods. The traditional human evaluation criteria mainly include the intelligibility, fidelity, fluency, adequacy, comprehension, and informativeness. We classify the automatic evaluation methods into two categories, including lexical similarity and linguistic features application. The lexical similarity methods contain edit distance, precision, recall, and word order, etc. The linguistic features can be divided into syntactic features and semantic features. Subsequently, we also introduce the evaluation methods for MT evaluation and the recent quality estimation tasks for MT.", "histories": [["v1", "Sun, 15 May 2016 09:41:00 GMT  (565kb)", "https://arxiv.org/abs/1605.04515v1", "14 pages, 21 formula"], ["v2", "Wed, 18 May 2016 18:38:02 GMT  (567kb)", "http://arxiv.org/abs/1605.04515v2", "14 pages, 21 formula"], ["v3", "Thu, 19 May 2016 16:12:34 GMT  (570kb)", "http://arxiv.org/abs/1605.04515v3", "some revision of the mathematical symbols and recent literature work in the content, and edit of references"], ["v4", "Mon, 23 May 2016 15:48:19 GMT  (643kb)", "http://arxiv.org/abs/1605.04515v4", "We added some further revision of the content, with introducation of previous MT evaluation related survey works from some european MT and language technology projects; fixed some mising references in paraphrase section"], ["v5", "Wed, 25 May 2016 10:30:16 GMT  (649kb)", "http://arxiv.org/abs/1605.04515v5", "We gave more intro information in the abstract about the content structure, the content layout, to make it easier for researchers understand the paper in the first moment. and we add some literature about deep learning for MT and evaluation"], ["v6", "Sun, 19 Jun 2016 12:28:58 GMT  (656kb)", "http://arxiv.org/abs/1605.04515v6", "We gave more intro information in the abstract about the content structure, the content layout, to make it easier for researchers understand the paper in the first moment. and we add some literature about deep learning for MT and evaluation, some literature about task-based MT evaluation"], ["v7", "Tue, 10 Oct 2017 14:04:07 GMT  (1610kb,D)", "http://arxiv.org/abs/1605.04515v7", "We add two presentation figures about Human MT Evaluation, and Automatic MT Evaluation, to make it clear for readers to find the whole structure of the paper. Add some advanced works of MT Evaluation, e.g. Neural models"]], "COMMENTS": "14 pages, 21 formula", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["aaron li-feng han", "derek fai wong"], "accepted": false, "id": "1605.04515"}
