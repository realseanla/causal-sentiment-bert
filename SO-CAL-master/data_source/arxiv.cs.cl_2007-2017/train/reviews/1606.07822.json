{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2016", "title": "Efficient Parallel Learning of Word2Vec", "abstract": "Since its introduction, Word2Vec and its variants are widely used to learn semantics-preserving representations of words or entities in an embedding space, which can be used to produce state-of-art results for various Natural Language Processing tasks. Existing implementations aim to learn efficiently by running multiple threads in parallel while operating on a single model in shared memory, ignoring incidental memory update collisions. We show that these collisions can degrade the efficiency of parallel learning, and propose a straightforward caching strategy that improves the efficiency by a factor of 4.", "histories": [["v1", "Fri, 24 Jun 2016 20:05:53 GMT  (39kb)", "http://arxiv.org/abs/1606.07822v1", "ICML 2016 Machine Learning workshop"]], "COMMENTS": "ICML 2016 Machine Learning workshop", "reviews": [], "SUBJECTS": "cs.CL cs.DC", "authors": ["jeroen b p vuurens", "carsten eickhoff", "arjen p de vries"], "accepted": false, "id": "1606.07822"}
