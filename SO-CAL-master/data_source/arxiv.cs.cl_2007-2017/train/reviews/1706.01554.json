{"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2017", "title": "Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model", "abstract": "We present a novel training framework for neural sequence models, particularly for grounded dialog generation. The standard training paradigm for these models is maximum likelihood estimation (MLE), or minimizing the cross-entropy of the human responses. Across a variety of domains, a recurring problem with MLE trained generative neural dialog models (G) is that they tend to produce 'safe' and generic responses (\"I don't know\", \"I can't tell\"). In contrast, discriminative dialog models (D) that are trained to rank a list of candidate human responses outperform their generative counterparts; in terms of automatic metrics, diversity, and informativeness of the responses. However, D is not useful in practice since it can not be deployed to have real conversations with users.", "histories": [["v1", "Mon, 5 Jun 2017 22:50:37 GMT  (644kb,D)", "http://arxiv.org/abs/1706.01554v1", "11 pages, 3 figures"], ["v2", "Fri, 27 Oct 2017 20:27:07 GMT  (888kb,D)", "http://arxiv.org/abs/1706.01554v2", "11 pages, 3 figures"]], "COMMENTS": "11 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.CL", "authors": ["jiasen lu", "anitha kannan", "jianwei yang", "devi parikh", "dhruv batra"], "accepted": true, "id": "1706.01554"}
