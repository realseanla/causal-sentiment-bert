{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Nov-2016", "title": "Landmark-based consonant voicing detection on multilingual corpora", "abstract": "This paper tests the hypothesis that distinctive feature classifiers anchored at phonetic landmarks can be transferred cross-lingually without loss of accuracy. Three consonant voicing classifiers were developed: (1) manually selected acoustic features anchored at a phonetic landmark, (2) MFCCs (either averaged across the segment or anchored at the landmark), and(3) acoustic features computed using a convolutional neural network (CNN). All detectors are trained on English data (TIMIT),and tested on English, Turkish, and Spanish (performance measured using F1 and accuracy). Experiments demonstrate that manual features outperform all MFCC classifiers, while CNNfeatures outperform both. MFCC-based classifiers suffer an F1reduction of 16% absolute when generalized from English to other languages. Manual features suffer only a 5% F1 reduction,and CNN features actually perform better in Turkish and Span-ish than in the training language, demonstrating that features capable of representing long-term spectral dynamics (CNN and landmark-based features) are able to generalize cross-lingually with little or no loss of accuracy", "histories": [["v1", "Thu, 10 Nov 2016 22:11:16 GMT  (92kb)", "http://arxiv.org/abs/1611.03533v1", "ready to submit to JASA-EL"]], "COMMENTS": "ready to submit to JASA-EL", "reviews": [], "SUBJECTS": "cs.CL cs.SD", "authors": ["xiang kong", "xuesong yang", "mark hasegawa-johnson", "jeung-yoon choi", "stefanie shattuck-hufnagel"], "accepted": false, "id": "1611.03533"}
