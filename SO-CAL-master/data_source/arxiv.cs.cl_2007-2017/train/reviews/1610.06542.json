{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Oct-2016", "title": "Lexicons and Minimum Risk Training for Neural Machine Translation: NAIST-CMU at WAT2016", "abstract": "This year, the Nara Institute of Science and Technology (NAIST)/Carnegie Mellon University (CMU) submission to the Japanese-English translation track of the 2016 Workshop on Asian Translation was based on attentional neural machine translation (NMT) models. In addition to the standard NMT model, we make a number of improvements, most notably the use of discrete translation lexicons to improve probability estimates, and the use of minimum risk training to optimize the MT system for BLEU score. As a result, our system achieved the highest translation evaluation scores for the task.", "histories": [["v1", "Thu, 20 Oct 2016 19:10:09 GMT  (19kb)", "http://arxiv.org/abs/1610.06542v1", "To Appear in the Workshop on Asian Translation (WAT). arXiv admin note: text overlap witharXiv:1606.02006"]], "COMMENTS": "To Appear in the Workshop on Asian Translation (WAT). arXiv admin note: text overlap witharXiv:1606.02006", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["graham neubig"], "accepted": false, "id": "1610.06542"}
