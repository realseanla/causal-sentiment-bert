{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2016", "title": "PSDVec: a Toolbox for Incremental and Scalable Word Embedding", "abstract": "PSDVec is a Python/Perl toolbox that learns word embeddings, i.e. the mapping of words in a natural language to continuous vectors which encode the semantic/syntactic regularities between the words. PSDVec implements a word embedding learning method based on a weighted low-rank positive semidefinite approximation. To scale up the learning process, we implement a blockwise online learning algorithm to learn the embeddings incrementally. This strategy greatly reduces the learning time of word embeddings on a large vocabulary, and can learn the embeddings of new words without re-learning the whole vocabulary. On 9 word similarity/analogy benchmark sets and 2 Natural Language Processing (NLP) tasks, PSDVec produces embeddings that has the best average performance among popular word embedding tools. PSDVec provides a new option for NLP practitioners.", "histories": [["v1", "Fri, 10 Jun 2016 05:55:58 GMT  (28kb)", "http://arxiv.org/abs/1606.03192v1", "12 pages, accepted by Neurocomputing, Software Track on Original Software Publications"]], "COMMENTS": "12 pages, accepted by Neurocomputing, Software Track on Original Software Publications", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["shaohua li", "jun zhu", "chunyan miao"], "accepted": false, "id": "1606.03192"}
