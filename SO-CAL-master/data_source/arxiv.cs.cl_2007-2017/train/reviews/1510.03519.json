{"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Oct-2015", "title": "Bridge Correlational Neural Networks for Multilingual Multimodal Representation Learning", "abstract": "Recently there has been a lot of interest in learning common representations for multiple views of data. These views could belong to different modalities or languages. Typically, such common representations are learned using a parallel corpus between the two views (say, 1M images and their English captions). In this work, we address a real-world scenario where no direct parallel data is available between two views of interest (say, V1 and V2) but parallel data is available between each of these views and a pivot view (V3). We propose a model for learning a common representation for V1, V2 and V3 using only the parallel data available between V1V3 and V2V3. The proposed model is generic and even works when there are n views of interest and only one pivot view which acts as a bridge between them. There are two specific downstream applications that we focus on (i) Transfer learning between languages L1,L2,...,Ln using a pivot language L and (ii) cross modal access between images and a language L1 using a pivot language L2. We evaluate our model using two datasets : (i) publicly available multilingual TED corpus and (ii) a new multilingual multimodal dataset created and released as a part of this work. On both these datasets, our model outperforms state of the art approaches.", "histories": [["v1", "Tue, 13 Oct 2015 03:25:18 GMT  (4707kb,D)", "http://arxiv.org/abs/1510.03519v1", "12 pages"], ["v2", "Sat, 6 Feb 2016 07:44:01 GMT  (4536kb,D)", "http://arxiv.org/abs/1510.03519v2", "12 pages"], ["v3", "Fri, 1 Jul 2016 09:01:19 GMT  (4515kb,D)", "http://arxiv.org/abs/1510.03519v3", "Published at NAACL-HLT 2016"]], "COMMENTS": "12 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["janarthanan rajendran", "mitesh m khapra", "sarath chandar", "balaraman ravindran"], "accepted": true, "id": "1510.03519"}
