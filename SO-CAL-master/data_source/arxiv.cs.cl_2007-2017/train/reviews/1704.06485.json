{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Apr-2017", "title": "Attend to You: Personalized Image Captioning with Context Sequence Memory Networks", "abstract": "We address personalization issues of image captioning, which have not been discussed yet in previous research. For a query image, we aim to generate a descriptive sentence, accounting for prior knowledge such as the user's active vocabularies in previous documents. As applications of personalized image captioning, we tackle two post automation tasks: hashtag prediction and post generation, on our newly collected Instagram dataset, consisting of 1.1M posts from 6.3K users. We propose a novel captioning model named Context Sequence Memory Network (CSMN). Its unique updates over previous memory network models include (i) exploiting memory as a repository for multiple types of context information, (ii) appending previously generated words into memory to capture long-term information without suffering from the vanishing gradient problem, and (iii) adopting CNN memory structure to jointly represent nearby ordered memory slots for better context understanding. With quantitative evaluation and user studies via Amazon Mechanical Turk, we show the effectiveness of the three novel features of CSMN and its performance enhancement for personalized image captioning over state-of-the-art captioning models.", "histories": [["v1", "Fri, 21 Apr 2017 11:29:07 GMT  (3876kb,D)", "http://arxiv.org/abs/1704.06485v1", "Accepted paper at CVPR 2017"], ["v2", "Tue, 25 Apr 2017 23:30:43 GMT  (3879kb,D)", "http://arxiv.org/abs/1704.06485v2", "Accepted paper at CVPR 2017"]], "COMMENTS": "Accepted paper at CVPR 2017", "reviews": [], "SUBJECTS": "cs.CV cs.CL", "authors": ["cesc chunseong park", "byeongchang kim", "gunhee kim"], "accepted": false, "id": "1704.06485"}
