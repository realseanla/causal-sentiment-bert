{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-May-2017", "title": "Analysing Data-To-Text Generation Benchmarks", "abstract": "Recently, several data-sets associating data to text have been created to train data-to-text surface realisers. It is unclear however to what extent the surface realisation task exercised by these data-sets is linguistically challenging. Do these data-sets provide enough variety to encourage the development of generic, high-quality data-to-text surface realisers ? In this paper, we argue that these data-sets have important drawbacks. We back up our claim using statistics, metrics and manual evaluation. We conclude by eliciting a set of criteria for the creation of a data-to-text benchmark which could help better support the development, evaluation and comparison of linguistically sophisticated data-to-text surface realisers.", "histories": [["v1", "Wed, 10 May 2017 14:42:54 GMT  (45kb,D)", "http://arxiv.org/abs/1705.03802v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["laura perez-beltrachini", "claire gardent"], "accepted": false, "id": "1705.03802"}
