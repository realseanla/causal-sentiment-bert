{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2008", "title": "Methods to Integrate a Language Model with Semantic Information for a Word Prediction Component", "abstract": "Most current word prediction systems make use of n-gram language models (LM) to estimate the probability of the following word in a phrase. In the past years there have been many attempts to enrich such language models with further syntactic or semantic information. We want to explore the predictive powers of Latent Semantic Analysis (LSA), a method that has been shown to provide reliable information on long-distance semantic dependencies between words in a context. We present and evaluate here several methods that integrate LSA-based information with a standard language model: a semantic cache, partial reranking, and different forms of interpolation. We found that all methods show significant improvements, compared to the 4-gram baseline, and most of them to a simple cache model as well.", "histories": [["v1", "Wed, 30 Jan 2008 17:10:24 GMT  (198kb)", "http://arxiv.org/abs/0801.4716v1", "10 pages ; EMNLP'2007 Conference (Prague)"]], "COMMENTS": "10 pages ; EMNLP'2007 Conference (Prague)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["tonio wandmacher", "jean-yves antoine"], "accepted": true, "id": "0801.4716"}
