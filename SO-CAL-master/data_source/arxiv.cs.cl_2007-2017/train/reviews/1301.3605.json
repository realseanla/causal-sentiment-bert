{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Feature Learning in Deep Neural Networks - Studies on Speech Recognition Tasks", "abstract": "Recent studies have shown that deep neural networks (DNNs) perform significantly better than shallow networks and Gaussian mixture models (GMMs) on large vocabulary speech recognition tasks. In this paper we argue that the difficulty in speech recognition is primarily caused by the high variability in speech signals. DNNs, which can be considered a joint model of a nonlinear feature transform and a log-linear classifier, achieve improved recognition accuracy by extracting discriminative internal representations that are less sensitive to small perturbations in the input features. However, if test samples are very dissimilar to training samples, DNNs perform poorly. We demonstrate these properties empirically using a series of recognition experiments on mixed narrowband and wideband speech and speech distorted by environmental noise.", "histories": [["v1", "Wed, 16 Jan 2013 07:23:19 GMT  (141kb,D)", "http://arxiv.org/abs/1301.3605v1", "ICLR 2013, 9 pages, 4 figures"], ["v2", "Mon, 21 Jan 2013 07:42:07 GMT  (144kb,D)", "http://arxiv.org/abs/1301.3605v2", "ICLR 2013, 9 pages, 4 figures"], ["v3", "Fri, 8 Mar 2013 19:42:37 GMT  (145kb,D)", "http://arxiv.org/abs/1301.3605v3", "ICLR 2013, 9 pages, 4 figures"]], "COMMENTS": "ICLR 2013, 9 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.LG cs.CL cs.NE", "authors": ["dong yu", "michael l seltzer", "jinyu li", "jui-ting huang", "frank seide"], "accepted": false, "id": "1301.3605"}
