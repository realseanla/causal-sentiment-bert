{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2017", "title": "I2T2I: Learning Text to Image Synthesis with Textual Data Augmentation", "abstract": "Translating information between text and image is a fundamental problem in artificial intelligence that connects natural language processing and computer vision. In the past few years, performance in image caption generation has seen significant improvement through the adoption of recurrent neural networks (RNN). Meanwhile, text-to-image generation begun to generate plausible images using datasets of specific categories like birds and flowers. We've even seen image generation from multi-category datasets such as the Microsoft Common Objects in Context (MSCOCO) through the use of generative adversarial networks (GANs). Synthesizing objects with a complex shape, however, is still challenging. For example, animals and humans have many degrees of freedom, which means that they can take on many complex shapes. We propose a new training method called Image-Text-Image (I2T2I) which integrates text-to-image and image-to-text (image captioning) synthesis to improve the performance of text-to-image synthesis. We demonstrate that %the capability of our method to understand the sentence descriptions, so as to I2T2I can generate better multi-categories images using MSCOCO than the state-of-the-art. We also demonstrate that I2T2I can achieve transfer learning by using a pre-trained image captioning module to generate human images on the MPII Human Pose", "histories": [["v1", "Mon, 20 Mar 2017 11:11:38 GMT  (3792kb,D)", "http://arxiv.org/abs/1703.06676v1", null], ["v2", "Mon, 8 May 2017 18:46:42 GMT  (3792kb,D)", "http://arxiv.org/abs/1703.06676v2", null], ["v3", "Sat, 3 Jun 2017 22:46:46 GMT  (3792kb,D)", "http://arxiv.org/abs/1703.06676v3", "International Conference on Image Processing (ICIP) 2017"]], "reviews": [], "SUBJECTS": "cs.CV cs.CL", "authors": ["hao dong", "jingqing zhang", "douglas mcilwraith", "yike guo"], "accepted": false, "id": "1703.06676"}
