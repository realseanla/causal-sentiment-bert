{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Apr-2016", "title": "An Ensemble Method to Produce High-Quality Word Embeddings", "abstract": "A currently successful approach to computational semantics is to represent words as embeddings in a machine-learned vector space. We present an ensemble method that combines embeddings produced by GloVe (Pennington et al., 2014) and word2vec (Mikolov et al., 2013) with structured knowledge from the semantic networks ConceptNet (Speer and Havasi, 2012) and PPDB (Ganitkevitch et al., 2013), merging their information into a common representation with a large, multilingual vocabulary. The embeddings it produces achieve state-of-the-art performance on many word-similarity evaluations. Its score of $\\rho = .596$ on an evaluation of rare words (Luong et al., 2013) is 16% higher than the previous best known system.", "histories": [["v1", "Wed, 6 Apr 2016 16:58:35 GMT  (96kb,D)", "http://arxiv.org/abs/1604.01692v1", "12 pages, 3 figures"]], "COMMENTS": "12 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["robert speer", "joshua chin"], "accepted": false, "id": "1604.01692"}
