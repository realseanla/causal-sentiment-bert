{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Mar-2016", "title": "Neural Discourse Relation Recognition with Semantic Memory", "abstract": "Humans comprehend the meanings and relations of discourses heavily relying on their semantic memory that encodes general knowledge about concepts and facts. Inspired by this, we propose a neural recognizer for implicit discourse relation analysis, which builds upon a semantic memory that stores knowledge in a distributed fashion. We refer to this recognizer as SeMDER. Starting from word embeddings of discourse arguments, SeMDER employs a shallow encoder to generate a distributed surface representation for a discourse. A semantic encoder with attention to the semantic memory matrix is further established over surface representations. It is able to retrieve a deep semantic meaning representation for the discourse from the memory. Using the surface and semantic representations as input, SeMDER finally predicts implicit discourse relations via a neural recognizer. Experiments on the benchmark data set show that SeMDER benefits from the semantic memory and achieves substantial improvements of 2.56\\% on average over current state-of-the-art baselines in terms of F1-score.", "histories": [["v1", "Sat, 12 Mar 2016 08:54:16 GMT  (191kb,D)", "http://arxiv.org/abs/1603.03873v1", "7 pages"]], "COMMENTS": "7 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["biao zhang", "deyi xiong", "jinsong su"], "accepted": false, "id": "1603.03873"}
