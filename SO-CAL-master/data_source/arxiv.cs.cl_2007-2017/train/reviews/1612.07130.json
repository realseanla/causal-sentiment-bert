{"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Dec-2016", "title": "Sparse Coding of Neural Word Embeddings for Multilingual Sequence Labeling", "abstract": "In this paper we propose and carefully evaluate a sequence labeling framework which solely utilizes sparse indicator features derived from dense distributed word representations. The proposed model obtains (near) state-of-the art performance for both part-of-speech tagging and named entity recognition for a variety of languages. Our model relies only on a few thousand sparse coding-derived features, without applying any modification of the word representations employed for the different tasks. The proposed model has favorable generalization properties as it retains over 89.8% of its average POS tagging accuracy when trained at 1.2% of the total available training data, i.e.~150 sentences per language.", "histories": [["v1", "Wed, 21 Dec 2016 14:17:53 GMT  (150kb,D)", "http://arxiv.org/abs/1612.07130v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["g\\'abor berend"], "accepted": true, "id": "1612.07130"}
