{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Good, Better, Best: Choosing Word Embedding Context", "abstract": "We propose two methods of learning vector representations of words and phrases that each combine sentence context with structural features extracted from dependency trees. Using several variations of neural network classifier, we show that these combined methods lead to improved performance when used as input features for supervised term-matching.", "histories": [["v1", "Thu, 19 Nov 2015 19:13:58 GMT  (12kb)", "http://arxiv.org/abs/1511.06312v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["james cross", "bing xiang", "bowen zhou"], "accepted": false, "id": "1511.06312"}
