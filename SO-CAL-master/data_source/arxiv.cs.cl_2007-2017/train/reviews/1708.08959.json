{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Aug-2017", "title": "A Simple LSTM model for Transition-based Dependency Parsing", "abstract": "We present a simple LSTM-based transition-based dependency parser. Our model is composed of a single LSTM hidden layer replacing the hidden layer in the usual feed-forward network architecture. We also propose a new initialization method that uses the pre-trained weights from a feed-forward neural network to initialize our LSTM-based model. We also show that using dropout on the input layer has a positive effect on performance. Our final parser achieves a 93.06% unlabeled and 91.01% labeled attachment score on the Penn Treebank. We additionally replace LSTMs with GRUs and Elman units in our model and explore the effectiveness of our initialization method on individual gates constituting all three types of RNN units.", "histories": [["v1", "Tue, 29 Aug 2017 18:25:35 GMT  (131kb)", "http://arxiv.org/abs/1708.08959v1", null], ["v2", "Fri, 8 Sep 2017 22:46:59 GMT  (131kb)", "http://arxiv.org/abs/1708.08959v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["mohab elkaref", "bernd bohnet"], "accepted": false, "id": "1708.08959"}
