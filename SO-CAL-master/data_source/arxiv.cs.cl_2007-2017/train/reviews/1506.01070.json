{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2015", "title": "Do Multi-Sense Embeddings Improve Natural Language Understanding?", "abstract": "Learning a distinct representation for each sense of an ambiguous word could lead to more powerful and fine-grained models of vector-space representations. Yet while `multi-sense' methods have been proposed and tested on artificial word-similarity tasks, we don't know if they improve real natural language understanding tasks. In this paper we introduce a pipelined architecture for incorporating multi-sense embeddings into language understanding, and test the performance of a state-of-the-art multi-sense embedding model (based on Chinese Restaurant Processes).", "histories": [["v1", "Tue, 2 Jun 2015 21:30:21 GMT  (163kb)", "http://arxiv.org/abs/1506.01070v1", null], ["v2", "Tue, 18 Aug 2015 04:17:48 GMT  (197kb)", "http://arxiv.org/abs/1506.01070v2", null], ["v3", "Tue, 24 Nov 2015 18:29:40 GMT  (197kb)", "http://arxiv.org/abs/1506.01070v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jiwei li", "dan jurafsky"], "accepted": true, "id": "1506.01070"}
