{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Feb-2017", "title": "How to evaluate word embeddings? On importance of data efficiency and simple supervised tasks", "abstract": "Maybe the single most important goal of representation learning is making subsequent learning faster. Surprisingly, this fact is not well reflected in the way embeddings are evaluated. In addition, recent practice in word embeddings points towards importance of learning specialized representations. We argue that focus of word representation evaluation should reflect those trends and shift towards evaluating what useful information is easily accessible. Specifically, we propose that evaluation should focus on data efficiency and simple supervised tasks, where the amount of available data is varied and scores of a supervised model are reported for each subset (as commonly done in transfer learning).", "histories": [["v1", "Tue, 7 Feb 2017 19:21:50 GMT  (2049kb,D)", "http://arxiv.org/abs/1702.02170v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["stanis{\\l}aw jastrzebski", "damian le\\'sniak", "wojciech marian czarnecki"], "accepted": false, "id": "1702.02170"}
