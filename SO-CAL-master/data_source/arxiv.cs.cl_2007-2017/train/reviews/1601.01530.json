{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jan-2016", "title": "Leveraging Sentence-level Information with Encoder LSTM for Semantic Slot Filling", "abstract": "Recurrent Neural Network (RNN) and one of its specific architectures, Long Short-Term Memory (LSTM), have been widely used for sequence labeling. In this paper, we first enhance LSTM-based sequence labeling to explicitly model label dependencies. Then we propose another enhancement to incorporate the global information spanning over the whole input sequence. The latter proposed method, encoder-labeler LSTM, first encodes the whole input sequence into a fixed length vector with the encoder LSTM, and then uses this encoded vector as the initial state of another LSTM for sequence labeling. Combining these methods, we can predict the label sequence with considering label dependencies and information of whole input sequence. In the experiments of a slot filling task, which is an essential component of natural language understanding, with using the standard ATIS corpus, we achieved the state-of-the-art F1-score of 95.66%.", "histories": [["v1", "Thu, 7 Jan 2016 13:32:31 GMT  (157kb)", "http://arxiv.org/abs/1601.01530v1", null], ["v2", "Tue, 23 Aug 2016 02:06:45 GMT  (605kb)", "http://arxiv.org/abs/1601.01530v2", null], ["v3", "Mon, 29 Aug 2016 00:41:29 GMT  (603kb)", "http://arxiv.org/abs/1601.01530v3", "Accepted in EMNLP 2016"], ["v4", "Wed, 31 Aug 2016 00:30:10 GMT  (512kb)", "http://arxiv.org/abs/1601.01530v4", "Accepted in EMNLP 2016"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["gakuto kurata", "bing xiang", "bowen zhou", "mo yu"], "accepted": true, "id": "1601.01530"}
