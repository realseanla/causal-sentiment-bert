{"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jun-2016", "title": "Data Recombination for Neural Semantic Parsing", "abstract": "Modeling crisp logical regularities is crucial in semantic parsing, making it difficult for neural models with no task-specific prior knowledge to achieve good results. In this paper, we introduce data recombination, a novel framework for injecting such prior knowledge into a model. From the training data, we induce a high-precision synchronous context-free grammar, which captures important conditional independence properties commonly found in semantic parsing. We then train a sequence-to-sequence recurrent network (RNN) model with a novel attention-based copying mechanism on datapoints sampled from this grammar, thereby teaching the model about these structural properties. Data recombination improves the accuracy of our RNN model on three semantic parsing datasets, leading to new state-of-the-art performance on the standard GeoQuery dataset for models with comparable supervision.", "histories": [["v1", "Sat, 11 Jun 2016 20:34:09 GMT  (84kb,D)", "http://arxiv.org/abs/1606.03622v1", "ACL 2016"]], "COMMENTS": "ACL 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["robin jia", "percy liang"], "accepted": true, "id": "1606.03622"}
