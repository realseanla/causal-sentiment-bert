{"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Sep-2016", "title": "Enhanced LSTM for Natural Language Inference", "abstract": "Reasoning and inference are central to human and artificial intelligence. Modeling inference in human language is notoriously challenging but is fundamental to natural language understanding and many applications. With the availability of large annotated data, neural network models have recently advanced the field significantly. In this paper, we present a new state-of-the-art result, achieving the accuracy of 88.3% on the standard benchmark, the Stanford Natural Language Inference dataset. This result is achieved first through our enhanced sequential encoding model, which outperforms the previous best model that employs more complicated network architectures, suggesting that the potential of sequential LSTM-based models have not been fully explored yet in previous work. We further show that by explicitly considering recursive architectures, we achieve additional improvement. Particularly, incorporating syntactic parse information contributes to our best result; it improves the performance even when the parse information is added to an already very strong system.", "histories": [["v1", "Tue, 20 Sep 2016 06:59:31 GMT  (287kb,D)", "http://arxiv.org/abs/1609.06038v1", "10 pages, 2 figures"], ["v2", "Tue, 7 Mar 2017 03:34:41 GMT  (507kb,D)", "http://arxiv.org/abs/1609.06038v2", "Update results, add case analysis"], ["v3", "Wed, 26 Apr 2017 17:37:13 GMT  (604kb,D)", "http://arxiv.org/abs/1609.06038v3", "ACL 2017"]], "COMMENTS": "10 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["qian chen", "xiaodan zhu", "zhen-hua ling", "si wei", "hui jiang 0001", "diana inkpen"], "accepted": true, "id": "1609.06038"}
