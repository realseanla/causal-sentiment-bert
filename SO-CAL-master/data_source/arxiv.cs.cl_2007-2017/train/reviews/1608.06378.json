{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Aug-2016", "title": "Towards Machine Comprehension of Spoken Content: Initial TOEFL Listening Comprehension Test by Machine", "abstract": "Multimedia or spoken content presents more attractive information than plain text content, but it's more difficult to display on a screen and be selected by a user. As a result, accessing large collections of the former is much more difficult and time-consuming than the latter for humans. It's highly attractive to develop a machine which can automatically understand spoken content and summarize the key information for humans to browse over. In this endeavor, we propose a new task of machine comprehension of spoken content. We define the initial goal as the listening comprehension test of TOEFL, a challenging academic English examination for English learners whose native language is not English. We further propose an Attention-based Multi-hop Recurrent Neural Network (AMRNN) architecture for this task, achieving encouraging results in the initial tests. Initial results also have shown that word-level attention is probably more robust than sentence-level attention for this task with ASR errors.", "histories": [["v1", "Tue, 23 Aug 2016 04:27:41 GMT  (7038kb,D)", "http://arxiv.org/abs/1608.06378v1", "Accepted conference paper: \"The Annual Conference of the International Speech Communication Association (Interspeech), 2016\""]], "COMMENTS": "Accepted conference paper: \"The Annual Conference of the International Speech Communication Association (Interspeech), 2016\"", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["bo-hsiang tseng", "sheng-syun shen", "hung-yi lee", "lin-shan lee"], "accepted": false, "id": "1608.06378"}
