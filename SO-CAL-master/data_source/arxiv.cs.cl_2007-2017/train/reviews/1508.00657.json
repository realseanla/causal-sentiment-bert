{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Aug-2015", "title": "Improved Transition-based Parsing by Modeling Characters instead of Words with LSTMs", "abstract": "We present extensions to a continuous-state dependency parsing method that makes it applicable to morphologically rich languages. Starting with a high-performance transition-based parser that uses long short-term memory (LSTM) recurrent neural networks to learn representations of the parser state, we replace look-up based word representations with representations constructed based on the orthographic representations of the words, also using LSTMs. This allows statistical sharing across word forms that are similar on the surface. Experiments for morphologically rich languages show that the parsing model benefits from incorporating the character-based encodings of words.", "histories": [["v1", "Tue, 4 Aug 2015 04:36:36 GMT  (146kb,D)", "http://arxiv.org/abs/1508.00657v1", "In Proceedings of EMNLP 2015"], ["v2", "Tue, 11 Aug 2015 17:33:47 GMT  (172kb,D)", "http://arxiv.org/abs/1508.00657v2", "In Proceedings of EMNLP 2015"]], "COMMENTS": "In Proceedings of EMNLP 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["miguel ballesteros", "chris dyer", "noah a smith"], "accepted": true, "id": "1508.00657"}
