{"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2015", "title": "Non-distributional Word Vector Representations", "abstract": "Data-driven representation learning for words is a technique of central importance in NLP. While indisputably useful as a source of features in downstream tasks, such vectors tend to consist of uninterpretable components whose relationship to the categories of traditional lexical semantic theories is tenuous at best. We present a method for constructing interpretable word vectors from hand-crafted linguistic resources like WordNet, FrameNet etc. These vectors are binary (i.e, contain only 0 and 1) and are 99.9% sparse. We analyze their performance on state-of-the-art evaluation methods for distributional models of word vectors and find they are competitive to standard distributional approaches.", "histories": [["v1", "Wed, 17 Jun 2015 07:40:14 GMT  (21kb)", "http://arxiv.org/abs/1506.05230v1", "Proceedings of ACL 2015"]], "COMMENTS": "Proceedings of ACL 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["manaal faruqui", "chris dyer"], "accepted": true, "id": "1506.05230"}
