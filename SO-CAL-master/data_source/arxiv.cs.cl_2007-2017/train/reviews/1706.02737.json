{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2017", "title": "Advances in Joint CTC-Attention based End-to-End Speech Recognition with a Deep CNN Encoder and RNN-LM", "abstract": "We present a state-of-the-art end-to-end Automatic Speech Recognition (ASR) model. We learn to listen and write characters with a joint Connectionist Temporal Classification (CTC) and attention-based encoder-decoder network. The encoder is a deep Convolutional Neural Network (CNN) based on the VGG network. The CTC network sits on top of the encoder and is jointly trained with the attention-based decoder. During the beam search process, we combine the CTC predictions, the attention-based decoder predictions and a separately trained LSTM language model. We achieve a 5-10\\% error reduction compared to prior systems on spontaneous Japanese and Chinese speech, and our end-to-end model beats out traditional hybrid ASR systems.", "histories": [["v1", "Thu, 8 Jun 2017 19:30:02 GMT  (65kb,D)", "http://arxiv.org/abs/1706.02737v1", "Accepted for INTERSPEECH 2017"]], "COMMENTS": "Accepted for INTERSPEECH 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["takaaki hori", "shinji watanabe", "yu zhang", "william chan"], "accepted": false, "id": "1706.02737"}
