{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Aug-2017", "title": "Paradigm Completion for Derivational Morphology", "abstract": "The generation of complex derived word forms has been an overlooked problem in NLP; we fill this gap by applying neural sequence-to-sequence models to the task. We overview the theoretical motivation for a paradigmatic treatment of derivational morphology, and introduce the task of derivational paradigm completion as a parallel to inflectional paradigm completion. State-of-the-art neural models, adapted from the inflection task, are able to learn a range of derivation patterns, and outperform a non-neural baseline by 16.4%. However, due to semantic, historical, and lexical considerations involved in derivational morphology, future work will be needed to achieve performance parity with inflection-generating systems.", "histories": [["v1", "Wed, 30 Aug 2017 07:55:57 GMT  (21kb)", "http://arxiv.org/abs/1708.09151v1", "EMNLP 2017"]], "COMMENTS": "EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ryan cotterell", "ekaterina vylomova", "huda khayrallah", "christo kirov", "david yarowsky"], "accepted": true, "id": "1708.09151"}
