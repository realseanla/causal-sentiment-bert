{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Oct-2016", "title": "Open-Ended Visual Question-Answering", "abstract": "This thesis report studies methods to solve Visual Question-Answering (VQA) tasks with a Deep Learning framework. As a preliminary step, we explore Long Short-Term Memory (LSTM) networks used in Natural Language Processing (NLP) to tackle Question-Answering (text based). We then modify the previous model to accept an image as an input in addition to the question. For this purpose, we explore the VGG-16 and K-CNN convolutional neural networks to extract visual features from the image. These are merged with the word embedding or with a sentence embedding of the question to predict the answer. This work was successfully submitted to the Visual Question Answering Challenge 2016, where it achieved a 53,62% of accuracy in the test dataset. The developed software has followed the best programming practices and Python code style, providing a consistent baseline in Keras for different configurations.", "histories": [["v1", "Sun, 9 Oct 2016 16:38:31 GMT  (6052kb,D)", "http://arxiv.org/abs/1610.02692v1", "Bachelor thesis report graded with A with honours at ETSETB Telecom BCN school, Universitat Polit\\`ecnica de Catalunya (UPC). June 2016. Source code and models are publicly available atthis http URL"]], "COMMENTS": "Bachelor thesis report graded with A with honours at ETSETB Telecom BCN school, Universitat Polit\\`ecnica de Catalunya (UPC). June 2016. Source code and models are publicly available atthis http URL", "reviews": [], "SUBJECTS": "cs.CL cs.CV cs.MM", "authors": ["issey masuda", "santiago pascual de la puente", "xavier giro-i-nieto"], "accepted": false, "id": "1610.02692"}
