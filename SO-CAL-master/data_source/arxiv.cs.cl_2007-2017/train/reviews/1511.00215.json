{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2015", "title": "A Unified Tagging Solution: Bidirectional LSTM Recurrent Neural Network with Word Embedding", "abstract": "Bidirectional Long Short-Term Memory Recurrent Neural Network (BLSTM-RNN) has been shown to be very effective for modeling and predicting sequential data, e.g. speech utterances or handwritten documents. In this study, we propose to use BLSTM-RNN for a unified tagging solution that can be applied to various tagging tasks including part-of-speech tagging, chunking and named entity recognition. Instead of exploiting specific features carefully optimized for each task, our solution only uses one set of task-independent features and internal representations learnt from unlabeled text for all tasks.Requiring no task specific knowledge or sophisticated feature engineering, our approach gets nearly state-of-the-art performance in all these three tagging tasks.", "histories": [["v1", "Sun, 1 Nov 2015 07:59:48 GMT  (474kb)", "http://arxiv.org/abs/1511.00215v1", "Rejected by EMNLP 2015, score: 4,3,3 (full is 5)"]], "COMMENTS": "Rejected by EMNLP 2015, score: 4,3,3 (full is 5)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["peilu wang", "yao qian", "frank k soong", "lei he", "hai zhao"], "accepted": false, "id": "1511.00215"}
