{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Feb-2017", "title": "Multilingual Multi-modal Embeddings for Natural Language Processing", "abstract": "We propose a novel discriminative model that learns embeddings from multilingual and multi-modal data, meaning that our model can take advantage of images and descriptions in multiple languages to improve embedding quality. To that end, we introduce a modification of a pairwise contrastive estimation optimisation function as our training objective. We evaluate our embeddings on an image-sentence ranking (ISR), a semantic textual similarity (STS), and a neural machine translation (NMT) task. We find that the additional multilingual signals lead to improvements on both the ISR and STS tasks, and the discriminative cost can also be used in re-ranking $n$-best lists produced by NMT models, yielding strong improvements.", "histories": [["v1", "Fri, 3 Feb 2017 18:19:47 GMT  (25kb,D)", "http://arxiv.org/abs/1702.01101v1", "4 pages (5 including references), no figures"]], "COMMENTS": "4 pages (5 including references), no figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["iacer calixto", "qun liu", "nick campbell"], "accepted": false, "id": "1702.01101"}
