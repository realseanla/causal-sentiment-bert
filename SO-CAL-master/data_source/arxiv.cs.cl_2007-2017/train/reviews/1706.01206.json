{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2017", "title": "One-step and Two-step Classification for Abusive Language Detection on Twitter", "abstract": "Automatic abusive language detection is a difficult but important task for online social media. Our research explores a two-step approach of performing classification on abusive language and then classifying into specific types and compares it with one-step approach of doing one multi-class classification for detecting sexist and racist languages. With a public English Twitter corpus of 20 thousand tweets in the type of sexism and racism, our approach shows a promising performance of 0.827 F-measure by using HybridCNN in one-step and 0.824 F-measure by using logistic regression in two-steps.", "histories": [["v1", "Mon, 5 Jun 2017 06:20:23 GMT  (286kb)", "http://arxiv.org/abs/1706.01206v1", "ALW1: 1st Workshop on Abusive Language Online to be held at the annual meeting of the Association of Computational Linguistics (ACL) 2017 (Vancouver, Canada), August 4th, 2017"]], "COMMENTS": "ALW1: 1st Workshop on Abusive Language Online to be held at the annual meeting of the Association of Computational Linguistics (ACL) 2017 (Vancouver, Canada), August 4th, 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ji ho park", "pascale fung"], "accepted": false, "id": "1706.01206"}
