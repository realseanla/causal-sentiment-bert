{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Nov-2016", "title": "Multi-Language Identification Using Convolutional Recurrent Neural Network", "abstract": "Language Identification, being an important aspect of Automatic Speaker Recognition has had many changes and new approaches to ameliorate performance over the last decade. We compare the performance of using audio spectrum in the log scale and using Polyphonic sound sequences from raw audio samples to train the neural network and to classify speech as either English or Spanish. To achieve this, we use the novel approach of using a Convolutional Recurrent Neural Network using Long Short Term Memory (LSTM) or a Gated Recurrent Unit (GRU) for forward propagation of the neural network. Our hypothesis is that the performance of using polyphonic sound sequence as features and both LSTM and GRU as the gating mechanisms for the neural network outperform the traditional MFCC features using a unidirectional Deep Neural Network.", "histories": [["v1", "Sat, 12 Nov 2016 15:59:22 GMT  (861kb)", "http://arxiv.org/abs/1611.04010v1", "10 pages, 6 figures"], ["v2", "Thu, 18 May 2017 09:15:26 GMT  (0kb,I)", "http://arxiv.org/abs/1611.04010v2", "Further experiments were performed on the model using LibriVox speech dataset and it was found that a Time Distributed CRNN model performed better and represented our initial ideas about the speaker recognition task better. The dataset contains speech in three languages - English, Spanish and Czech. A report on our findings along with experimental results will be published soon"]], "COMMENTS": "10 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["vrishabh ajay lakhani", "rohan mahadev"], "accepted": false, "id": "1611.04010"}
