{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jul-2017", "title": "Improving Slot Filling Performance with Attentive Neural Networks on Dependency Structures", "abstract": "Slot Filling (SF) aims to extract the values of certain types of attributes (or slots, such as person:cities\\_of\\_residence) for a given entity from a large collection of source documents. In this paper we propose an effective DNN architecture for SF with the following new strategies: (1). Take a regularized dependency graph instead of a raw sentence as input to DNN, to compress the wide contexts between query and candidate filler; (2). Incorporate two attention mechanisms: local attention learned from query and candidate filler, and global attention learned from external knowledge bases, to guide the model to better select indicative contexts to determine slot type. Experiments show that this framework outperforms state-of-the-art on both relation extraction (16\\% absolute F-score gain) and slot filling validation for each individual system (up to 8.5\\% absolute F-score gain).", "histories": [["v1", "Tue, 4 Jul 2017 17:18:50 GMT  (409kb,D)", "http://arxiv.org/abs/1707.01075v1", "EMNLP'2017"]], "COMMENTS": "EMNLP'2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lifu huang", "avirup sil", "heng ji", "radu florian"], "accepted": true, "id": "1707.01075"}
