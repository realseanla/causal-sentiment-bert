{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2014", "title": "Inducing Language Networks from Continuous Space Word Representations", "abstract": "Recent advancements in unsupervised feature learning have developed powerful latent representations of words. However, it is still not clear what makes one representation better than another and how we can learn the ideal representation. Understanding the structure of latent spaces attained is key to any future advancement in unsupervised learning. In this work, we introduce a new view of continuous space word representations as language networks. We explore two techniques to create language networks from learned features by inducing them for two popular word representation methods and examining the properties of their resulting networks. We find that the induced networks differ from other methods of creating language networks, and that they contain meaningful community structure.", "histories": [["v1", "Thu, 6 Mar 2014 01:36:53 GMT  (4879kb,D)", "https://arxiv.org/abs/1403.1252v1", "14 pages"], ["v2", "Fri, 27 Jun 2014 17:36:43 GMT  (4879kb,D)", "http://arxiv.org/abs/1403.1252v2", "14 pages"]], "COMMENTS": "14 pages", "reviews": [], "SUBJECTS": "cs.LG cs.CL cs.SI", "authors": ["bryan perozzi", "rami al-rfou", "vivek kulkarni", "steven skiena"], "accepted": false, "id": "1403.1252"}
