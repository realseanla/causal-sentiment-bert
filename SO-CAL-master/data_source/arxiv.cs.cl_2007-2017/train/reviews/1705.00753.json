{"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-May-2017", "title": "A Teacher-Student Framework for Zero-Resource Neural Machine Translation", "abstract": "While end-to-end neural machine translation (NMT) has made remarkable progress recently, it still suffers from the data scarcity problem for low-resource language pairs and domains. In this paper, we propose a method for zero-resource NMT by assuming that parallel sentences have close probabilities of generating a sentence in a third language. Based on this assumption, our method is able to train a source-to-target NMT model (\"student\") without parallel corpora available, guided by an existing pivot-to-target NMT model (\"teacher\") on a source-pivot parallel corpus. Experimental results show that the proposed method significantly improves over a baseline pivot-based model by +3.0 BLEU points across various language pairs.", "histories": [["v1", "Tue, 2 May 2017 01:14:06 GMT  (161kb,D)", "http://arxiv.org/abs/1705.00753v1", "Accepted as a long paper by ACL 2017"]], "COMMENTS": "Accepted as a long paper by ACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yun chen", "yang liu", "yong cheng", "victor o k li"], "accepted": true, "id": "1705.00753"}
