{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Feb-2017", "title": "Comparative Study of CNN and RNN for Natural Language Processing", "abstract": "Deep neural networks (DNN) have revolutionized the field of natural language processing (NLP). Convolutional neural network (CNN) and recurrent neural network (RNN), the two main types of DNN architectures, are widely explored to handle various NLP tasks. CNN is supposed to be good at extracting position-invariant features and RNN at modeling units in sequence. The state of the art on many NLP tasks often switches due to the battle between CNNs and RNNs. This work is the first systematic comparison of CNN and RNN on a wide range of representative NLP tasks, aiming to give basic guidance for DNN selection.", "histories": [["v1", "Tue, 7 Feb 2017 08:33:35 GMT  (88kb,D)", "http://arxiv.org/abs/1702.01923v1", "7 pages, 11 figures"]], "COMMENTS": "7 pages, 11 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["wenpeng yin", "katharina kann", "mo yu", "hinrich sch\\\"utze"], "accepted": false, "id": "1702.01923"}
