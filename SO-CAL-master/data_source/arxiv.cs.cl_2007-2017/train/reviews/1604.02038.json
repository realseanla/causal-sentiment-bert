{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Apr-2016", "title": "Sentence Level Recurrent Topic Model: Letting Topics Speak for Themselves", "abstract": "We propose Sentence Level Recurrent Topic Model (SLRTM), a new topic model that assumes the generation of each word within a sentence to depend on both the topic of the sentence and the whole history of its preceding words in the sentence. Different from conventional topic models that largely ignore the sequential order of words or their topic coherence, SLRTM gives full characterization to them by using a Recurrent Neural Networks (RNN) based framework. Experimental results have shown that SLRTM outperforms several strong baselines on various tasks. Furthermore, SLRTM can automatically generate sentences given a topic (i.e., topics to sentences), which is a key technology for real world applications such as personalized short text conversation.", "histories": [["v1", "Thu, 7 Apr 2016 15:29:45 GMT  (54kb,D)", "http://arxiv.org/abs/1604.02038v1", null], ["v2", "Fri, 8 Apr 2016 05:45:44 GMT  (54kb,D)", "http://arxiv.org/abs/1604.02038v2", "The submitted version was done in Feb.2016. Still in improvement"]], "reviews": [], "SUBJECTS": "cs.LG cs.CL cs.IR", "authors": ["fei tian", "bin gao", "di he", "tie-yan liu"], "accepted": false, "id": "1604.02038"}
