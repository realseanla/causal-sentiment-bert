{"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jun-2016", "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text", "abstract": "We present a new reading comprehension dataset, SQuAD, consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset in both manual and automatic ways to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We built a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research.", "histories": [["v1", "Thu, 16 Jun 2016 16:36:00 GMT  (307kb,D)", "http://arxiv.org/abs/1606.05250v1", null], ["v2", "Fri, 7 Oct 2016 03:48:29 GMT  (307kb,D)", "http://arxiv.org/abs/1606.05250v2", "10 pages"], ["v3", "Tue, 11 Oct 2016 02:42:36 GMT  (307kb,D)", "http://arxiv.org/abs/1606.05250v3", "To appear in Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["pranav rajpurkar", "jian zhang", "konstantin lopyrev", "percy liang"], "accepted": true, "id": "1606.05250"}
