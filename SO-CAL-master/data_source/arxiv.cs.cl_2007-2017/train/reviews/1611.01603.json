{"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2016", "title": "Bidirectional Attention Flow for Machine Comprehension", "abstract": "Machine Comprehension (MC), answering questions about a given context, re-quires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these mechanisms use attention to summarize the query and context into a single vectors, couple attentions temporally, and often form a unidirectional attention. In this paper we introduce the Bidirectional Attention Flow (BIDAF) Model, a multi-stage hierarchical process that represents the context at different levels of granularity and uses a bi-directional attention flow mechanism to achieve a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford QA(SQuAD) and CNN/DailyMail Cloze Test datasets.", "histories": [["v1", "Sat, 5 Nov 2016 04:49:00 GMT  (1009kb,D)", "http://arxiv.org/abs/1611.01603v1", null], ["v2", "Mon, 21 Nov 2016 21:34:22 GMT  (1010kb,D)", "http://arxiv.org/abs/1611.01603v2", null], ["v3", "Tue, 29 Nov 2016 18:46:50 GMT  (1011kb,D)", "http://arxiv.org/abs/1611.01603v3", null], ["v4", "Tue, 7 Feb 2017 22:01:42 GMT  (1018kb,D)", "http://arxiv.org/abs/1611.01603v4", "Published as a conference paper at ICLR 2017"], ["v5", "Fri, 24 Feb 2017 19:57:53 GMT  (1017kb,D)", "http://arxiv.org/abs/1611.01603v5", "Published as a conference paper at ICLR 2017"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["minjoon seo", "aniruddha kembhavi", "ali farhadi", "hannaneh hajishirzi"], "accepted": true, "id": "1611.01603"}
