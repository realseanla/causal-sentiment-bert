{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Aug-2014", "title": "Evaluating Neural Word Representations in Tensor-Based Compositional Settings", "abstract": "We provide a comparative study between neural word representations and traditional vector spaces based on co-occurrence counts, in a number of compositional tasks. We use three different semantic spaces and implement seven tensor-based compositional models, which we then test (together with simpler additive and multiplicative approaches) in tasks involving verb disambiguation and sentence similarity. To check their scalability, we additionally evaluate the spaces using simple compositional methods on larger-scale tasks with less constrained language: paraphrase detection and dialogue act tagging. In the more constrained tasks, co-occurrence vectors are competitive, although choice of compositional method is important; on the larger-scale tasks, they are outperformed by neural word embeddings, which show robust, stable performance across the tasks.", "histories": [["v1", "Tue, 26 Aug 2014 16:28:21 GMT  (30kb)", "http://arxiv.org/abs/1408.6179v1", "To be published in EMNLP 2014"]], "COMMENTS": "To be published in EMNLP 2014", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dmitrijs milajevs", "dimitri kartsaklis", "mehrnoosh sadrzadeh", "matthew purver"], "accepted": true, "id": "1408.6179"}
