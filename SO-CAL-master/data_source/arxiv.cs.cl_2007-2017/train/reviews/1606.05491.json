{"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2016", "title": "Sequence-to-Sequence Generation for Spoken Dialogue via Deep Syntax Trees and Strings", "abstract": "We present a natural language generator based on the sequence-to-sequence approach that can be trained to produce natural language strings as well as deep syntax dependency trees from input dialogue acts, and we use it to directly compare two-step generation with separate sentence planning and surface realization stages to a joint, one-step approach. We were able to train both setups successfully using very little training data. The joint setup offers better performance, surpassing state-of-the-art with regards to n-gram-based scores while providing more relevant outputs.", "histories": [["v1", "Fri, 17 Jun 2016 11:51:25 GMT  (116kb,D)", "http://arxiv.org/abs/1606.05491v1", "Accepted as a short paper for ACL 2016"]], "COMMENTS": "Accepted as a short paper for ACL 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ond\\v{r}ej du\\v{s}ek", "filip jur\\v{c}\\'i\\v{c}ek"], "accepted": true, "id": "1606.05491"}
