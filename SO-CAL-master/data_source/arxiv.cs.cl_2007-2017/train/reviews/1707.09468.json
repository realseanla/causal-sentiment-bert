{"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jul-2017", "title": "Zero-Shot Activity Recognition with Verb Attribute Induction", "abstract": "In this paper, we investigate large-scale zero-shot activity recognition by modeling the visual and linguistic attributes of action verbs. For example, the verb \"salute\" has several properties, such as being a light movement, a social act, and short in duration. We use these attributes as the internal mapping between visual and textual representations to reason about a previously unseen action. In contrast to much prior work that assumes access to gold standard attributes for zero-shot classes and focuses primarily on object attributes, our model uniquely learns to infer action attributes from dictionary definitions and distributed word representations. Experimental results confirm that action attributes inferred from language can provide a predictive signal for zero-shot prediction of previously unseen activities.", "histories": [["v1", "Sat, 29 Jul 2017 06:05:52 GMT  (931kb)", "http://arxiv.org/abs/1707.09468v1", "accepted to EMNLP 2017"], ["v2", "Sat, 2 Sep 2017 19:53:20 GMT  (933kb)", "http://arxiv.org/abs/1707.09468v2", "accepted to EMNLP 2017"]], "COMMENTS": "accepted to EMNLP 2017", "reviews": [], "SUBJECTS": "cs.CL cs.CV", "authors": ["rowan zellers", "yejin choi"], "accepted": true, "id": "1707.09468"}
