{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2016", "title": "Learning Word Sense Embeddings from Word Sense Definitions", "abstract": "Word embeddings play a significant role in many modern NLP systems. However, most used word embedding learning methods learn one representation per word which is problematic for polysemous words and homonymous words. To address this problem, we propose a multi-phase word sense embedding retrofitting method which utilizes a lexical ontology to learn one embedding per word sense. We use word sense definitions and relations between word senses defined in a lexical ontology in a different way from existing systems. Experimental results on word similarity task show that our approach remarkablely improves the quality of embeddings.", "histories": [["v1", "Wed, 15 Jun 2016 16:14:09 GMT  (14kb)", "http://arxiv.org/abs/1606.04835v1", "Submitted to COLING 2016"], ["v2", "Mon, 20 Jun 2016 14:59:47 GMT  (21kb)", "http://arxiv.org/abs/1606.04835v2", "Submitted to COLING 2016"], ["v3", "Mon, 18 Jul 2016 13:03:12 GMT  (34kb)", "http://arxiv.org/abs/1606.04835v3", "Submitted to COLING 2016"], ["v4", "Mon, 24 Oct 2016 00:56:54 GMT  (41kb)", "http://arxiv.org/abs/1606.04835v4", "To appear at NLPCC-ICCPOL 2016"]], "COMMENTS": "Submitted to COLING 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["qi li", "tianshi li", "baobao chang"], "accepted": false, "id": "1606.04835"}
