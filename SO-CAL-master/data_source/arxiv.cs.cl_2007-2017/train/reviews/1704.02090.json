{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Apr-2017", "title": "Conceptualization Topic Modeling", "abstract": "Recently, topic modeling has been widely used to discover the abstract topics in text corpora. Most of the existing topic models are based on the assumption of three-layer hierarchical Bayesian structure, i.e. each document is modeled as a probability distribution over topics, and each topic is a probability distribution over words. However, the assumption is not optimal. Intuitively, it's more reasonable to assume that each topic is a probability distribution over concepts, and then each concept is a probability distribution over words, i.e. adding a latent concept layer between topic layer and word layer in traditional three-layer assumption. In this paper, we verify the proposed assumption by incorporating the new assumption in two representative topic models, and obtain two novel topic models. Extensive experiments were conducted among the proposed models and corresponding baselines, and the results show that the proposed models significantly outperform the baselines in terms of case study and perplexity, which means the new assumption is more reasonable than traditional one.", "histories": [["v1", "Fri, 7 Apr 2017 05:12:38 GMT  (1481kb,D)", "http://arxiv.org/abs/1704.02090v1", "7 pages"]], "COMMENTS": "7 pages", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["yi-kun tang", "xian-ling mao", "heyan huang", "guihua wen"], "accepted": false, "id": "1704.02090"}
