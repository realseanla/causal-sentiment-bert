{"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Sep-2016", "title": "Automatic Quality Assessment for Speech Translation Using Joint ASR and MT Features", "abstract": "This paper addresses automatic quality assessment of spoken language translation (SLT). This relatively new task is defined and formalized as a sequence labeling problem where each word in the SLT hypothesis is tagged as good or bad according to a large feature set. We propose several word confidence estimators (WCE) based on our automatic evaluation of transcription (ASR) quality, translation (MT) quality, or both (combined ASR+MT). This research work is possible because we built a specific corpus which contains 6.7k utterances for which a quintuplet containing: ASR output, verbatim transcript, text translation, speech translation and post-edition of translation is built. The conclusion of our multiple experiments using joint ASR and MT features for WCE is that MT features remain the most influent while ASR feature can bring interesting complementary information. Our robust quality estimators for SLT can be used for re-scoring speech translation graphs or for providing feedback to the user in interactive speech translation or computer-assisted speech-to-text scenarios.", "histories": [["v1", "Tue, 20 Sep 2016 08:04:33 GMT  (1624kb,D)", "http://arxiv.org/abs/1609.06049v1", "submitted to MT Journal (special issue on spoken language translation)"]], "COMMENTS": "submitted to MT Journal (special issue on spoken language translation)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["ngoc-tien le", "benjamin lecouteux", "laurent besacier"], "accepted": false, "id": "1609.06049"}
