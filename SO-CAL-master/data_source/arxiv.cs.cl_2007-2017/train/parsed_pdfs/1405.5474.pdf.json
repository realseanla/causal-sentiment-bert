{
  "name" : "1405.5474.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "New Perspectives in Sinographic Language Processing Through the Use of Character Structure",
    "authors" : [ "Yannis Haralambous" ],
    "emails" : [ "yannis.haralambous@telecom-bretagne.eu" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The Chinese script is used mainly in the Chinese and Japanese languages. Chinese characters (or “sinographs”) are notorious for their large number (over 84 thousand have been encoded in Unicode [1]) and their complexity (they can have from 1 stroke, like 一, to as many as 64 strokes, like ;). Despite its complexity, the Chinese script is quite efficient, since semantic and phonetic information is stored in stroke patterns, easily recognizable by native readers. In this paper we will deal with a specific kind of stroke pattern, namely those that exist also as stand-alone characters—we call them subcharacters. We will study the phonetic similarity (called phoneticity) and the semantic relatedness (called semanticity) between a character and its subcharacters. After having built a graph of subcharacter inclusions, and attaching various kinds of information to it, we introduce an enhanced NLP task feature model: together with individual characters we use data contained in their subcharacter graphs. Indeed, in sinographic ? The final publication is available at http://link.springer.com.\nlanguage processing it is customary to combine character-level and word-level processing. The advantage to our approach is that an additional level is added to these two: the level of subcharacters. By exploring this additional level, we go deeper into the inherent structure of sinographic characters—this inherent structure is completely lost in conventional NLP approaches.\nWe believe that this new feature model will prove useful in various branches of statistical NLP. As a first step in that direction, we evaluate our tools by applying them to a text classification task."
    }, {
      "heading" : "1.1 Related Work",
      "text" : "There have been various attempts at describing sinographs in a systematic way: [2] and [3] use generative grammars, [4] uses a Prolog-like language, [5] uses the biological metaphor of gene theory, [6] describes sinographs as objects with features (the Chaon model), [7] defines a formal language type called planar regular language, [8] and [9] describe the topology of sinographs in XML, [10] uses projections of stroke bounding boxes, and [11] use combinatorics of IDS operators.1\nThe OCR community has also shown a strong interest in the structure of sinographs [12].\nAs for considering Chinese script as a network, this has been done in several papers, such as [13, 14] (where edges represent components combined in the same sinograph) or [15], where components and sinographs form a bipartite graph; [16], where edges represent sinographs combined into words; [17], dealing with purely phonemic networks. [14] give an example of a small phono-semantic graph (a bipartite graph where edges connect semantic and phonetic components), but do not enter into the calculations of phoneticity and semanticity. Hanzi Grid [18, 19] maps component inclusions to relations in ontologies.\nFinally the cognitive psychology community is also heavily interested in the (cognitive) processing of phonetic and semantic components [20, 21], and even in the effects of stroke order and radicals on linguistic knowledge [22]."
    }, {
      "heading" : "2 Definitions",
      "text" : ""
    }, {
      "heading" : "2.1 Strokes",
      "text" : "A sinograph consists of a number of strokes, arranged inside an (imaginary) square according to specific patterns. Strokes can be classified as belonging to 36 calligraphic stroke classes. The latter have been encoded in Unicode (table cjk strokes). Furthermore, strokes are always drawn in a very specific order.\n1 Ideographic Description Sequences do not describe sinographs per se, but provide operators ‘ ’ ÷ ◊ ÿ Ÿ ⁄ € ‹ › fi fl for graphically combining existing sinographs in groups of two or three. IDS operators can be arbitrarily nested and have been encoded in Unicode (table ideographic description characters)."
    }, {
      "heading" : "2.2 Components, Subcharacters, Radicals",
      "text" : "In a manner similar to etymological roots in Western languages, readers of sinographs recognize patterns of strokes, so that the meaning of an unknown sinograph can be identified, more or less effectively, by the stroke patterns it contains.\nFrequently appearing patterns of strokes are called components. In this paper we will deal only with components that also exist as isolated sinographs. Using the term “character” in the sense of “Unicode character,” we will call such components, subcharacters. In other words, subcharacters are components having a Unicode identity.\nClassification of sinographs in dictionaries traditionally uses a set of several hundred subcharacters called radicals. We do not discuss radicals in this paper."
    }, {
      "heading" : "2.3 Allographic Classes",
      "text" : "An important property of components is that they can change shape when combined with other components (for example, 火 becomes 灬 when combined, like in 点). Some of these variant shapes have been encoded in Unicode. Also, some sinographs can have variant forms. In particular, during the Chinese writing reform [23], about 1,753 sinographs obtained simplified shapes (for example, 蔔 became 卜), which are encoded separately in Unicode.\nAs these variations in shape do not affect semantic or phonetic properties (at least not at the level of statistical language processing), we merge characters and their variants into sets called allographic classes. For example, 糸 belongs to class [⺯,⺰,糹,糸,纟] where the two first characters belong to the table of Unicode radicals and the others are graphical variants.\nWe obtain 18,686 allographic classes, out of which 87.356% are singletons, the highest number of characters per class is 15 and the average is 1.1382.\nIn the remainder of this paper we will use italics for characters (c, s, . . .) and bold letters for allographic classes (c, s, . . .). The term “subcharacter” will mean a character or an allographic class, depending on the context."
    }, {
      "heading" : "2.4 Semanticity and Phoneticity",
      "text" : "Subcharacters can play a semantic role (when one of their meanings is close to one of the meanings of the sinograph) and/or a phonetic role (when one of their readings is identical or close, in a given language, to one of the readings of the sinograph). In this paper we will deal with Mandarin and Japanese.\nThese two properties of subcharacters in relation to characters can be quantified and are then called semanticity and phoneticity [24]."
    }, {
      "heading" : "3 Resources",
      "text" : ""
    }, {
      "heading" : "3.1 Frequency Lists",
      "text" : "First some notation: let T be a sinographic text (or a corpus considered as a single text). A frequency list A, generated out of T , is an M -tuple of pairs\n(ci, fA(ci)), where the frequency fA(ci) of character ci is defined as #ci#T , that is the number of occurrences of ci in T divided by the length of T . The ci must be pairwise different. A is sorted in decreasing order of frequencies: fA(ci) ≥ fA(cj) when i < j. If N ∈ N, let A1...N be the subtuple of the first N pairs.\nLet char(A) be the underlying set of characters of A. Let A1...N be the sublist of the N first characters of A. Let\ncomcharN (A,A ′) :=\n(char(A1...N ) ∩ char(A′)) ∪ (char(A′1...N ) ∩ char(A))\nbe the set of N -common characters between two lists A and A′. In other words, among the first N characters of A we take those that also belong to A′ and vice versa. We define the N -common coverage factor between A and A′ as:\ncomcovN (A,A ′) :=\n#comchar(A,A′)\nN .\nUsing comcharN (A,A′) as the underlying character set, we obtain sub-lists Ac of A and A′c of A′ (although not noted, Ac depends not only on A but also on A′ and on N , and A′c also on A and N).\nFinally, we define a distance of character frequency lists dN as follows:\ndN (A,A ′) := 1− comcovN (A,A′) ·\nρ(Ac, A ′ c) + 1\n2\nwhere ρ is the Spearman ranking correlation coefficient (ρ takes values in [−1, 1]). We have used three publicly available frequency lists: uni, the language-\nindependent Unihan [25]; sin, the traditional Chinese Sinica compiled by Academia Sinica Taipei; and noz, a Japanese list, taken from [26].\nWe have also compiled our own frequency lists out of five corpora: Chinese Wikipedia (wps for simplified Chinese and wpt for traditional Chinese), Japanese Wikipedia wpj, Chinese Project Gutenberg gut, Chinese GoogleBooks goo, Leeds Chinese Internet Corpus cic [27].\nAs we needed a frequency list suitable for all sinographic languages, we calculated distance dN between them (for N = 3, 000). In Fig. 1 the reader can see a graph of frequency lists with edges proportional to values of dN . One can identify three linguistic clusters, while the Unihan list can be considered as an outlier. After removing the Unihan list we aggregated the remaining lists to form a “Universal Frequency List,” ufl, as the normalized average of noz, wpj, wps,\nwpt, she, goo, sin and gut, defined as follows: if fX(c) is the frequency of character c in corpus X, and #X is the size of the corpus in characters, then:\nchar(ufl) = ⋃\nX∈X char(X), fufl(c) = ∑ X∈X fX(c) ·#char(X) #char(ufl) ,\nwhere X = {noz, wpj, wps, wpt, she, goo, sin, gut}."
    }, {
      "heading" : "3.2 Character Descriptions and Subcharacter Inclusions",
      "text" : "Wenlin Institute kindly provided us with the CDL database of sinographs. This XML file provides an ordered stroke list for each sinograph, and for each stroke, its calligraphic type and coordinates of endpoints. We modified stroke order for the few exceptional cases where components are overlapping.2\nBecause of the many affine transformations a component is subject to, this topological sinograph description is not suitable for effectively detecting subcharacters. On the other hand, use of topological properties is unavoidable, since some sinographs have the same strokes in the same order and combinatorial arrangement but differ by the (relative) size of strokes, the typical example being 士 (scholar) and 土 (earth), where the bottom stroke of the latter is longer than that of the former. For this reason we used a different representation of sinographs, based on relative size of strokes and extrapolated intersection locations. For example, here is the relation between the two first strokes of the sinograph 言, which are of type d (= “dot”) and h (= “horizontal”):\nd (1.4,9.1,0.0,0.6) h\n(see Fig. 2 for the description of the numeric values). Using this affine transformation invariant representation of sinographs, we\nextracted 868,856 subcharacter inclusions from the Wenlin CDL database, where inclusion s→ c of subcharacter s into character cmeans that the code lines of our representation of s are contained, in their identical form, in the representation of c. After merging with data from the CHISE project [28] and with data kindly provided by Cornelia Schindelin [29], and after having removed identities, we got a list of 824,120 strict inclusions. The number is quite high because inclusion chains like:丿→勹→匐→蔔 provide automatically all triangulations丿→匐, 勹→蔔, etc., and there are exponentially many of them. We have detriangulated by taking systematically the longest path, and hence reduced the number of inclusions to 185,801. 2 An important fact about components is that in the sequence of strokes drawn in traditional stroke order, components form subsequences without overlapping : the first stroke of a component is drawn after the last stroke of the preceding component. There are a few exceptions to this rule: sinographs like团 (subcharacter囗 containing 才) where the drawing of the lower horizontal stroke of 囗 is postponed until the drawing of the internal subcharacter 才 has been completed.\nlated intersection locations. The blue lines are skeletons of strokes given by CDL. The values (1.4,9.1,0.0,0.6) correspond to: d((x0,y0)−(x1,y1))\nd((x2,y2)−(x1,y1)) (that is: distance of the in-\ntersection point from (x1, y1) with stroke length as unit), |x4−x3||x2−x1| (stroke box width ratio), |y4−y3||y2−y1| (stroke box height ratio) and d((x0,y0)−(x3,y3)) d((x4,y4)−(x3,y3))\n(again, distance of the intersection point from (x3, y3) with second stroke length as unit), where d is Euclidean distance. When strokes are parallel or orthogonal, some of the parameters are infinite and we write E instead."
    }, {
      "heading" : "3.3 The Inclusion Graph",
      "text" : "We construct a graph, using all sinographs as vertices and representing the inclusions as edges, giving us 74,601 vertices and 185,801 edges. Both the in-degree and out-degree properties of this graph (see Fig. 3) follow a power law distribution of parameters α− = 1.138 (in-degree) and α+ = 1.166 (out-degree). Remarkably, these are a bit low compared to typical scale-free networks like the Web or proteins, which are in the 2–3 range [30].\nAs higher Unicode planes contain rare sinographs which are of little use to common NLP tasks, and for reasons of computational efficiency, we restricted ourselves to the subgraph of sinographs contained in Unicode’s BMP (Basic Multilingual Plane). This subset covers only 91.65% of the sinographs contained in the frequency list, but its frequency-weighted coverage3 is as high as 99.9995%, showing that our choice of BMP is justified.\nBy lifting4 sinograph inclusions to allographic classes we obtain a graph C of 18,686 allographic classes and 39,719 class inclusions.\nIn all, 99.8% of the allographic classes have incoming inclusions (the highest in-degree is 12 for class [蕐]), 14 classes are “sources” (zero in-degree nodes): [一], [丨], [丶], [丿], [亅], [力], [巛], [乀,乁,乛,乚,乙], [乃], [刁], [又], [及], [巜] and [廴]. 87.05% of the classes are leaves (zero out-degree nodes) and the highest out-degree is 996 for class [氵,水]).\n3 If standard coverage is #{ci∈char(ufl)} #{ci∈BMP} where ufl is our Universal Frequency List,\nthen frequency-weighted coverage is defined as ∑ ci∈char(ufl) fufl(ci)∑\nci∈BMP fufl(ci) . 4 If c1, c2 ∈ C we have c1 → c2 iff there is at least one character pair c1 ∈ c1, c2 ∈ c2 such that c1 → c2.\nLogarithmic in-degree distribution\nLogarithmic out-degree distribution\ngraphic classes."
    }, {
      "heading" : "4 Phoneticity",
      "text" : "Unihan provides phonetic data for sinographs in several languages. For this study, we used data for Mandarin Chinese, Japanese On (readings originating from China, and imported to Japan together with the writing system) and Japanese Kun (native Japanese readings). We define phoneticity as the degree of phonetic similarity between subcharacter and character. To calculate it we need a phonetic distance.\nFor Mandarin Chinese we implemented the phonetic distance described in [31].\nFor Japanese we have defined our own phonetic distance.We obtained this distance by applying a methodology given by [32] and [33]: indeed, we defined a distance for syllables, using seven features: consonant place of articulation (weight 4), consonant voicing (1), consonant manner of articulation (4), consonant palatalization (1), vowel frontness (5), vowel height (1), and vowel rounding (1). Distance between syllables is Euclidean in feature space. When sinograph readings have an unequal number of syllables5 we use a sliding window approach to find the shortest phonetic distance between the shorter word and a subword of equal length to the longer one.\nIf d is a phonetic distance between sinographs, let dmin be the distance between allographic classes defined as the minimum distance between class members. We define the phoneticity coefficient ϕ(c1, c2) := 1−dmin(c1,c2) N where N is a normalization constant such that Im(ϕ) = [0, 1]. We will write ϕ(s → c)\n5 Contrary to Chinese language where sinograph readings are monosyllabic, in Japanese they can have up to 12 syllables (the longest readings are nuhitorioshitanameshigaha for 鞼 and hitohenotsutsusodeudenuki for 褠, both being Kun readings).\nfor ϕ(s, c) when s → c is a class inclusion. In Fig. 4, we show the distribution density of ϕ for Mandarin, Japanese On and Kun. One can see that On mimics the distribution of Mandarin (with a lesser ϕ value for the right peak) while Kun has a completely different distribution with a single peak around ϕ = 0.4. Indeed, the historical relation of On and Mandarin is reflected in the similarity of distributions, while in Kun phonetic distance between subcharacter and character is random.\nHere is an example:\nMandarin Jap. On Jap. Kun\n任 rèn nin makaseru, ninau, taeru\n人\nOO\nrén ≈ OO\nnin =\nOO\nhito 6= OO\nwhere the difference between the phonetics of the two characters in Mandarin is at the tone level only, and since tones are not phonemic in Japanese, the sinographs are homophones in On. Incidentally, this inclusion has very low semanticity: 人 means “man” and 任, “to trust.”\nMandarin\nJapanese On\nJapanese Kun"
    }, {
      "heading" : "4.1 The Least Phonetic Chain",
      "text" : "Under the hypothesis that subcharacters with higher phoneticity have statistically lower semanticity and vice versa, we consider the subcharacters with the lowest phoneticity, as these have an increased potential of having higher semanticity. We define the least phonetic chain (pi)i≥0 of a class c as follows: let p0 = c and given pi let pi+1 := argminzϕ(z→ pi), that is, the subcharacter of pi with least phoneticity (see Fig. 5 for an example). We will use this construct in our text classification strategies.\nEdge labels are ϕ values; between parentheses, the subcharacter’s multiplicity."
    }, {
      "heading" : "5 Semanticity",
      "text" : "As semantic resources for sinographic languages we used three WordNets: the Academia Sinica BOW [34] for traditional Chinese, the Chinese WordNet [35] for simplified Chinese and the Japanese WordNet [36]. All three provide English WordNet synset IDs. The single-sinograph entries they contain are rather limited: 3,075 for traditional Chinese, 2,440 for simplified Chinese and 4,941 for Japanese. From these we obtain a first mapping of allographic classes into synset IDs. In all, 2,852 allographic classes are covered, out of which 1,063 have a single synset ID, 581 have two IDs (IDs from different WordNets are not merged), etc. The highest number of IDs is 45, for [刺] (= “thorn”). Only 154 classes share the same synset ID in all three WordNets.\nThe Unihan database also provides meanings for a large number of sinographs, but these meanings are not mapped to WordNet. We used the following method to attach synset IDs to them: let wi be a Chinese or Japanese word attached to synset ID σi in one of the three WordNets; let ei,k be one of the terms of the English WordNet synset with ID σi; if ei,k can be found in Unihan as meaning of a character cj and if cj ∈ wi then we attach synset ID σi to cj . We lift this information to allographic classes.\nHere is an example:\nWordNet 1.6 WordNet 3.0 Unihan\n風疹 BOW // 110160032\n∈\n111412304\n∈\n疹\n∈\nkDefinition 疹\n∈\n33\nmeasles#1\n∈\nmeasles\nSince 疹 has the meaning “measles” in Unihan and is contained in the word 風疹 which belongs to the measles synset, we attach the measles synset ID to 疹.\nThanks to this method, 1,392 additional allographic classes were mapped to at least one WordNet synset ID, raising the number of semantically annotated classes to 4,244."
    }, {
      "heading" : "5.1 Extracting Semantic Relations",
      "text" : "We attempted three methods of estimating semanticity of subcharacters: 1. By measuring distance between WordNet nodes using semantic similarity\nmeasures, such as those of [37–39] or simply the inverse of the shortest path length in the WordNet graph. This method was unfruitful.\n2. By using the following algorithm: whenever there was a semantic relation (hyponymy, meronymy, antonymy, etc.) between twoWordNet synsets σ1 and σ2, and we have a sinograph belonging to a word from σ2 and one of its subcharacters in a word from σ1, we added a unit of “semantic weight” to the inclusion. We counted these over the three WordNets and obtained 6,816 allographic class inclusions of various weights.\nHere is an example:\n114662574 (mineral#1)\n礦物oo 礦3\n114696793 (Greenland spar#1)\nhyponym\nOO\n冰晶石oo 石3\nOO\n“Greenland spar” is an hyponym of “mineral,” 冰晶石 belongs to the synset of the former and 礦物 to that of the latter. Characters 石 and 礦 appear in these two words, and the former being a subcharacter of the latter, we attach a unit of “semantic weight” to it. The (log of the) total amount of units is our tentative semanticity measure.\n3. To a lesser degree, we used the Kāng Xı̄ radical (see next section) as an additional semanticity indicator. We did the following: for every inclusion, we compared the Kāng Xı̄ radicals on both sides: when equal, then this may be a hint that the given subcharacter has higher semanticity than others.\nExample: in the inclusion每→毓, both sinographs have the same Kāng Xı̄ radical 毌, so we assume that每→毓 has higher semanticity than㐬→毓 (which, incidentally, also has higher phoneticity since it is pronounced liú which is closer to yù (毓) than měi (每))."
    }, {
      "heading" : "6 Evaluation",
      "text" : "To evaluate an application of our graph to a common NLP task we attempted text classification on two corpora:\n1. The Sogou Corpus of Chinese news [43], a collection of 2.36 million online articles (611 million sinographs) taken from various sources. We removed all sinographs not in the cjk unified ideographs Unicode table and extracted 5,000 texts per class:\nCategory Avg length Min length Max length Sports 728.23 500 1,000 Finance 714.51 500 1,000 News 699.63 500 1,000 Entertainment 696.36 500 1,000 Global 709.68 500 1,000\n2. A corpus we built from the online archives of Japanese Reuters [44], covering the period from 2007 to today. We removed all sinographs not in the cjk characters Unicode table (including the kana) and extracted 5,000 texts per class. Because of the nature of Reuters news, these texts are shorter than the Chinese ones:\nCategory Avg length Min length Max length Sports 105.54 74 521 Finance 293.79 188 1,262 News 315.69 166 876 Entertainment 94.73 44 588 Global 202.44 44 1,262\nOur baseline is obtained as follows: we take unigrams for all sinographs appearing at least 10 times in the corpus. This results in 4,275 unigrams for the Chinese and 2,010 for the Japanese corpus. Then we apply a linear SVM with 10-fold cross validation. Here are the results obtained:\nAccuracy # of SVs Baseline Chinese 89.605% 4,933 Baseline Japanese 86.925% 4,237"
    }, {
      "heading" : "6.1 Strategy 1: The Most Semantic Chain",
      "text" : "Let ι : s→ c be a class inclusion. We calculate three quantities:\n1. f1(ι): the frequency of character pairs (s ∈ s, c ∈ c) contained in words s ∈ w1, c ∈ w2 belonging to synsets w1 ∈ Σ1, w2 ∈ Σ2 such that there is a semantic relation Σ1 → Σ2 in WordNet (see Section 5);\n2. f2(ι): the frequency of character pairs (s ∈ s, c ∈ c) contained in words s ∈ w1, c ∈ w2 belonging to synsets w1 ∈ Σ1, w2 ∈ Σ2 such that there is a two-step semantic relation Σ1 → Σ′ → Σ2 in WordNet;\n3. r(ι): let r(s, c) be 1 when s and c share the same Kāng Xı̄ radical, and 0 otherwise. r(ι) will be 1nm ∑ s∈s ∑ c∈c r(s, c).\nThe semanticity S(ι) of inclusion ι : s→ c will be:\nS(ι) = 12 log(1 + f1(ι)) + 1 4 log(1 + f2(ι)) + 1 4r(ι),\nnormalized so that its values stay in the interval [0, 1]. Here, coefficients 12 , 1 4 and 1 4 have been obtained heuristically by a grid method applied to a series of tests.\nThe most semantic chain (si)i≥0 of class c is calculated as follows: s0 = c, and, given si, si+1 := argmaxz S(z → si), that is, the subcharacter of si with maximal semanticity.\nLet w(c) be the weight of unigram c, obtained by frequency in the baseline case. Let w(c) := maxc∈c w(c) be the weight of class c. For every member si of the most semantic chain of c, we added a weight w(si) = 1iS(si−1 → si) (with s0 = c) to unigram c.\nWe obtained the following results:\nAccuracy # of SVs Un.w/ mod. Un.added Chinese 92.62% 3,287 594 20 Japanese 89.99% 3,728 524 152\nwhere the two last columns contain the number of updated unigrams and the number of new unigrams. Notice that the increase in performance is similar for Chinese and Japanese, while the number of support vectors needed is higher in Japanese, probably due to the shorter length of texts making the classification task harder."
    }, {
      "heading" : "6.2 Strategy 2: Combining Most Semantic Chain and Least Phonetic Chain",
      "text" : "With the notation of previous sections, let ϕ(s → c) be the phoneticity of inclusion s → c (calculated as explained in Section 4). Recall that the least phonetic chain (pi)i≥0 is obtained by taking p0 = c, and, given pi, pi+1 := argminz ϕ(z,pi). For each pi we define a new class weight w′(pi) as follows:\nw′(pi) = w(pi) + 1 iϕ(pi−1 → pi).\nWe obtained the following results:\nAccuracy # of SVs Un.w/ mod. Un.added Chinese 92.435% 3,299 851 245 Japanese 90.125% 3,737 745 453\nThe value for Chinese is a bit lower than in Strategy 1, but we get a better result for Japanese. We have an increase in the number of new unigrams, due to the fact that we have significantly more phonetically annotated inclusions than semantically annotated ones."
    }, {
      "heading" : "7 Unknown Character Semantic Approximation",
      "text" : "Besides the usual NLP tasks where a semantic relatedness distance is needed, our system can also be applied to the processing of unknown sinographs. Let u be an\nunknown sinograph (i.e., we know neither reading nor meaning), and u its class. In our graph, there is subgraph Gu generated by paths leading to u. The way the graph is built, our subgraph has no cycles. When we leave u and head towards the leaves, for every path si there will be a first node ni for which we have semantic annotation (for example, a WordNet synset ID). Furthermore, we can attach weights to the ni by using the product of semanticity expectations (calculated in a way similar to phoneticity expectations) of the edges of path uni and the distance from u on the path uni.\nWe obtain a vector in the space of WordNet synset IDs. This is not a precise semantic, but it can be used in various statistical NLP tasks.6"
    }, {
      "heading" : "8 Perspectives",
      "text" : "Further work will involve three main areas of focus:\n1. further analyzing the graph and extracting knowledge about sinographic languages;\n2. similarly processing various higher-order graphs (n-grams, words, concepts, . . . ) and studying their interactions;\n3. last, but not least, in the frame of the HanziGraph Project, manually validating the semanticity of the 39,719 class inclusions of our graph by a team of native Chinese/Japanese speakers, using the dedicated Web site http://www.hanzigraph.net."
    } ],
    "references" : [ {
      "title" : "The Unicode Standard, Version 6.0",
      "author" : [ "J.D. Allen", "eds" ],
      "venue" : "Unicode Consortium",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2011
    }, {
      "title" : "Structural patterns of Chinese characters",
      "author" : [ "O. Fujimura", "R. Kagaya" ],
      "venue" : "Proceedings of the International Conference on Computational Linguistics, Sånga-Säby, Sweden.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 1969
    }, {
      "title" : "Toward a generative grammar of Chinese character structure and stroke order",
      "author" : [ "J.C.S. Wang" ],
      "venue" : "PhD thesis, University of Wisconsin-Madison",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 1983
    }, {
      "title" : "Coordinate-independent font description using Kanji as an example",
      "author" : [ "M.J. Dürst" ],
      "venue" : "Electronic Publishing 6(3)",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "漢字基因朱邦復漢字基因工程 (Genetic engineering of Chinese characters) (2003) http://cbflabs.com/down/show.php?id=26",
      "author" : [ "B.F. Chu" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2003
    }, {
      "title" : "Surface or essence: Beyond the coded character set model",
      "author" : [ "S. Moro" ],
      "venue" : "Proceedings of the Glyph and Typesetting Workshop, Kyoto, Japon",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "A Computational Theory of Writing Systems",
      "author" : [ "R. Sproat" ],
      "venue" : "Studies in Natural Language Processing. Cambridge University Press",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "SCML: A Structural Representation for Chinese Characters",
      "author" : [ "D.G. Peebles" ],
      "venue" : "PhD thesis, Dartmouth College",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Wenlin CDL: Character Description Language",
      "author" : [ "T. Bishop", "R. Cook" ],
      "venue" : "Multilingual 18",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Seeking meaning in a space made out of strokes, radicals, characters and compounds",
      "author" : [ "Y. Haralambous" ],
      "venue" : "Proceedings of ISSM’10-11, Aizu-Wakamatsu, Japan.",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Decomposition for ISO/IEC 10646 ideographic characters",
      "author" : [ "L. Qin", "C.S. Tong", "L. Yin", "L.N. Ling" ],
      "venue" : "COLING’02: Proceedings of the 3rd workshop on Asian language resources and international standardization, Association for Computational Linguistics",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Chinese character recognition: history, status and prospects",
      "author" : [ "R. Dai", "C. Liu", "B. Xiao" ],
      "venue" : "Frontiers of Computer Science in China 1",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Network of words",
      "author" : [ "Y. Fujiwara", "Y. Suzuki", "T. Morioka" ],
      "venue" : "Artificial Life and Robotics 7",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Chinese character structure analysis based on complex networks",
      "author" : [ "J. Li", "J. Zhou" ],
      "venue" : "Physica A: Statistical Mechanics and its Applications 380",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Substructure shape analysis for Kanji character recognition",
      "author" : [ "J. Rocha", "H. Fujisawa" ],
      "venue" : "Advances in Structural and Syntactical Pattern Recognition. Springer",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "A character-net based Chinese text segmentation method",
      "author" : [ "L. Zhou", "Q. Liu" ],
      "venue" : "SEMANET ’02 Proceedings of the 2002 workshop on Building and using semantic networks, Association for Computational Linguistics",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Statistical properties of Chinese phonemic networks",
      "author" : [ "S. Yu", "H. Liu", "C. Xu" ],
      "venue" : "Physica A: Statistical Mechanics and its Applications 390",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Hanzi, Concept and Computation: A Preliminary Survey of Chinese Characters as a Knowledge Resource in NLP",
      "author" : [ "S.K. Hsieh" ],
      "venue" : "PhD thesis, Universität Tübingen",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Hanzi grid: toward a knowledge infrastructure for Chinese character-based cultures",
      "author" : [ "Y.M. Chou", "S.K. Hsieh", "C.R. Huang" ],
      "venue" : "Proceedings of the 1st international conference on Intercultural collaboration IWIC’07, Kyoto, Japan, Springer",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Submorphemic processing in reading Chinese",
      "author" : [ "M. Taft", "X. Zhu" ],
      "venue" : "Journal of Experimental Psychology: Learning, Memory and Cognition 23",
      "citeRegEx" : "20",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "Chinese character decoding: a semantic bias",
      "author" : [ "C. Williams", "T. Bever" ],
      "venue" : "Read Writ",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2010
    }, {
      "title" : "The effects of stroke order and radicals on the knowledge of Japanese Kanji orthography, phonology and semantics",
      "author" : [ "K. Tamaoka", "H. Yamada" ],
      "venue" : "Psychologia 43",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Planning Chinese Characters",
      "author" : [ "S. Zhao", "Baldauf", "R.B. Jr." ],
      "venue" : "Reaction, Evolution or Revolution? Volume 9 of Language Policy. Springer",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Sinographemdidaktik",
      "author" : [ "A. Guder-Manitius" ],
      "venue" : "Aspekte einer systematischen Vermittlung der chinesischen Schrift im Unterricht Chinesisch als Fremdsprache. Volume 7 of SinoLinguistica. Julius Groos Verlag, Tübingen",
      "citeRegEx" : "24",
      "shortCiteRegEx" : null,
      "year" : 1999
    }, {
      "title" : "Unicode Standard Annex #38",
      "author" : [ "J.H. Jenkins", "R. Cook" ],
      "venue" : "Unicode Han Database. Technical report, The Unicode Consortium",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A Japanese logographic character frequency list for cognitive science research",
      "author" : [ "N. Chikamatsu", "S. Yokoyama", "H. Nozaki", "E. Long", "S. Fukuda" ],
      "venue" : "Behavior Research Methods, Instruments, & Computers 32(3)",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Creating general-purpose corpora using automated search engine queries",
      "author" : [ "S. Sharoff" ],
      "venue" : "In Baroni, M., Bernardini, S., eds.: WaCky! Working papers on the Web as Corpus, Bologna, GEDIT",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "CHISE: Character processing based on character ontology",
      "author" : [ "T. Morioka" ],
      "venue" : "LKR’08: Proceedings of the 3rd international conference on Large-scale knowledge resources: Construction and application, Springer",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Zur Phonetizität chinesischer Schriftzeichen in der Didaktik des Chinesischen als Fremdsprache",
      "author" : [ "C. Schindelin" ],
      "venue" : "Volume 13 of SinoLinguistica. iudicium, München",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Networks",
      "author" : [ "M.J. Newman" ],
      "venue" : "An introduction. Oxford University Press",
      "citeRegEx" : "30",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "以最佳化及機率分佈判 斷漢字聲符之研究 (Automatic identification of phonetic complements for Chinese characters based on optimization and probability distribution)",
      "author" : [ "C.H. Chang", "S.Y. Li", "S. Lin", "C.Y. Huang", "J.M. Chen" ],
      "venue" : "Proceedings of the 22nd Conference on Computational Linguistics and Speech Processing (ROCLING 2010), Puli, Nantou, Taiwan.",
      "citeRegEx" : "31",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Phonetic distance based cross-lingual search",
      "author" : [ "S. Sriram", "P.P. Talukdar", "S. Badaskar", "K. Bali", "A.G. Ramakrishnan" ],
      "venue" : "Proc. of the 5th International Conf. on Natural Language Processing (KBCS 2004), Hyderabad, India.",
      "citeRegEx" : "32",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "A new algorithm for the alignment of phonetic sequences",
      "author" : [ "G. Kondrak" ],
      "venue" : "NAACL 2000: Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference.",
      "citeRegEx" : "33",
      "shortCiteRegEx" : null,
      "year" : 2000
    }, {
      "title" : "Sinica BOW: Integrating bilingual WordNet and SUMO ontology",
      "author" : [ "C.R. Huang" ],
      "venue" : "International Conference on Natural Language Processing and Knowledge Engineering.",
      "citeRegEx" : "34",
      "shortCiteRegEx" : null,
      "year" : 2003
    }, {
      "title" : "Chinese WordNet (2008) http://www.aturstudio.com/wordnet/ windex.php",
      "author" : [ "Z Gao" ],
      "venue" : null,
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2008
    }, {
      "title" : "Development of the Japanese WordNet",
      "author" : [ "H. Isahara", "F. Bond", "K. Uchimoto", "M. Utiyama", "K. Kanzaki" ],
      "venue" : "Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08).",
      "citeRegEx" : "36",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Semantic similarity based on corpus statistics and lexical taxonomy",
      "author" : [ "J.J. Jiang", "D.W. Conrath" ],
      "venue" : "Proceedings on International Conference on Research in Computational Linguistics, Taiwan 1997.",
      "citeRegEx" : "37",
      "shortCiteRegEx" : null,
      "year" : 1997
    }, {
      "title" : "An information-theoretic definition of similarity",
      "author" : [ "D. Lin" ],
      "venue" : "Proceedings of 15th International Conference On Machine Learning, Madison WI, 1998.",
      "citeRegEx" : "38",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Using information content to evaluate semantic similarity in a taxonomy",
      "author" : [ "P. Resnik" ],
      "venue" : "Proceedings of the 14th International Joint Conference on Artificial Intelligence, Montréal.",
      "citeRegEx" : "39",
      "shortCiteRegEx" : null,
      "year" : 1995
    }, {
      "title" : "Visible speech: The diverse oneness of writing systems",
      "author" : [ "J. DeFrancis" ],
      "venue" : "University of Hawaii Press, Honolulu",
      "citeRegEx" : "40",
      "shortCiteRegEx" : null,
      "year" : 1989
    }, {
      "title" : "Sémantisme et classification dans l’écriture chinoise",
      "author" : [ "F. Bottéro" ],
      "venue" : "Les systèmes de classement des caractères par clés du Shuown Jiezi au Kangxi Zidian. Volume 37 of Mémoires de l’Institut des Hautes Études Chinoises. Collège de France, Paris",
      "citeRegEx" : "41",
      "shortCiteRegEx" : null,
      "year" : 1996
    }, {
      "title" : "Hantology: conceptual system discovery based on orthographic convention",
      "author" : [ "Y.M. Chou", "C.R. Huang" ],
      "venue" : "Ontology and the lexicon, a Natural Language Processing perspective, Cambridge University Press",
      "citeRegEx" : "42",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "A method of part-of-speech guessing of Chinese unknown words based on combined features",
      "author" : [ "H.J. Zhang", "S.M. Shi", "C. Feng", "H.Y. Huang" ],
      "venue" : "International Conference on Machine Learning and Cybernetics.",
      "citeRegEx" : "45",
      "shortCiteRegEx" : null,
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Chinese characters (or “sinographs”) are notorious for their large number (over 84 thousand have been encoded in Unicode [1]) and their complexity (they can have from 1 stroke, like 一, to as many as 64 strokes, like ;).",
      "startOffset" : 121,
      "endOffset" : 124
    }, {
      "referenceID" : 1,
      "context" : "There have been various attempts at describing sinographs in a systematic way: [2] and [3] use generative grammars, [4] uses a Prolog-like language, [5] uses the biological metaphor of gene theory, [6] describes sinographs as objects with features (the Chaon model), [7] defines a formal language type called planar regular language, [8] and [9] describe the topology of sinographs in XML, [10] uses projections of stroke bounding boxes, and [11] use combinatorics of IDS operators.",
      "startOffset" : 79,
      "endOffset" : 82
    }, {
      "referenceID" : 2,
      "context" : "There have been various attempts at describing sinographs in a systematic way: [2] and [3] use generative grammars, [4] uses a Prolog-like language, [5] uses the biological metaphor of gene theory, [6] describes sinographs as objects with features (the Chaon model), [7] defines a formal language type called planar regular language, [8] and [9] describe the topology of sinographs in XML, [10] uses projections of stroke bounding boxes, and [11] use combinatorics of IDS operators.",
      "startOffset" : 87,
      "endOffset" : 90
    }, {
      "referenceID" : 3,
      "context" : "There have been various attempts at describing sinographs in a systematic way: [2] and [3] use generative grammars, [4] uses a Prolog-like language, [5] uses the biological metaphor of gene theory, [6] describes sinographs as objects with features (the Chaon model), [7] defines a formal language type called planar regular language, [8] and [9] describe the topology of sinographs in XML, [10] uses projections of stroke bounding boxes, and [11] use combinatorics of IDS operators.",
      "startOffset" : 116,
      "endOffset" : 119
    }, {
      "referenceID" : 4,
      "context" : "There have been various attempts at describing sinographs in a systematic way: [2] and [3] use generative grammars, [4] uses a Prolog-like language, [5] uses the biological metaphor of gene theory, [6] describes sinographs as objects with features (the Chaon model), [7] defines a formal language type called planar regular language, [8] and [9] describe the topology of sinographs in XML, [10] uses projections of stroke bounding boxes, and [11] use combinatorics of IDS operators.",
      "startOffset" : 149,
      "endOffset" : 152
    }, {
      "referenceID" : 5,
      "context" : "There have been various attempts at describing sinographs in a systematic way: [2] and [3] use generative grammars, [4] uses a Prolog-like language, [5] uses the biological metaphor of gene theory, [6] describes sinographs as objects with features (the Chaon model), [7] defines a formal language type called planar regular language, [8] and [9] describe the topology of sinographs in XML, [10] uses projections of stroke bounding boxes, and [11] use combinatorics of IDS operators.",
      "startOffset" : 198,
      "endOffset" : 201
    }, {
      "referenceID" : 6,
      "context" : "There have been various attempts at describing sinographs in a systematic way: [2] and [3] use generative grammars, [4] uses a Prolog-like language, [5] uses the biological metaphor of gene theory, [6] describes sinographs as objects with features (the Chaon model), [7] defines a formal language type called planar regular language, [8] and [9] describe the topology of sinographs in XML, [10] uses projections of stroke bounding boxes, and [11] use combinatorics of IDS operators.",
      "startOffset" : 267,
      "endOffset" : 270
    }, {
      "referenceID" : 7,
      "context" : "There have been various attempts at describing sinographs in a systematic way: [2] and [3] use generative grammars, [4] uses a Prolog-like language, [5] uses the biological metaphor of gene theory, [6] describes sinographs as objects with features (the Chaon model), [7] defines a formal language type called planar regular language, [8] and [9] describe the topology of sinographs in XML, [10] uses projections of stroke bounding boxes, and [11] use combinatorics of IDS operators.",
      "startOffset" : 334,
      "endOffset" : 337
    }, {
      "referenceID" : 8,
      "context" : "There have been various attempts at describing sinographs in a systematic way: [2] and [3] use generative grammars, [4] uses a Prolog-like language, [5] uses the biological metaphor of gene theory, [6] describes sinographs as objects with features (the Chaon model), [7] defines a formal language type called planar regular language, [8] and [9] describe the topology of sinographs in XML, [10] uses projections of stroke bounding boxes, and [11] use combinatorics of IDS operators.",
      "startOffset" : 342,
      "endOffset" : 345
    }, {
      "referenceID" : 9,
      "context" : "There have been various attempts at describing sinographs in a systematic way: [2] and [3] use generative grammars, [4] uses a Prolog-like language, [5] uses the biological metaphor of gene theory, [6] describes sinographs as objects with features (the Chaon model), [7] defines a formal language type called planar regular language, [8] and [9] describe the topology of sinographs in XML, [10] uses projections of stroke bounding boxes, and [11] use combinatorics of IDS operators.",
      "startOffset" : 390,
      "endOffset" : 394
    }, {
      "referenceID" : 10,
      "context" : "There have been various attempts at describing sinographs in a systematic way: [2] and [3] use generative grammars, [4] uses a Prolog-like language, [5] uses the biological metaphor of gene theory, [6] describes sinographs as objects with features (the Chaon model), [7] defines a formal language type called planar regular language, [8] and [9] describe the topology of sinographs in XML, [10] uses projections of stroke bounding boxes, and [11] use combinatorics of IDS operators.",
      "startOffset" : 442,
      "endOffset" : 446
    }, {
      "referenceID" : 11,
      "context" : "The OCR community has also shown a strong interest in the structure of sinographs [12].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 12,
      "context" : "As for considering Chinese script as a network, this has been done in several papers, such as [13, 14] (where edges represent components combined in the same sinograph) or [15], where components and sinographs form a bipartite graph; [16], where edges represent sinographs combined into words; [17], dealing with purely phonemic networks.",
      "startOffset" : 94,
      "endOffset" : 102
    }, {
      "referenceID" : 13,
      "context" : "As for considering Chinese script as a network, this has been done in several papers, such as [13, 14] (where edges represent components combined in the same sinograph) or [15], where components and sinographs form a bipartite graph; [16], where edges represent sinographs combined into words; [17], dealing with purely phonemic networks.",
      "startOffset" : 94,
      "endOffset" : 102
    }, {
      "referenceID" : 14,
      "context" : "As for considering Chinese script as a network, this has been done in several papers, such as [13, 14] (where edges represent components combined in the same sinograph) or [15], where components and sinographs form a bipartite graph; [16], where edges represent sinographs combined into words; [17], dealing with purely phonemic networks.",
      "startOffset" : 172,
      "endOffset" : 176
    }, {
      "referenceID" : 15,
      "context" : "As for considering Chinese script as a network, this has been done in several papers, such as [13, 14] (where edges represent components combined in the same sinograph) or [15], where components and sinographs form a bipartite graph; [16], where edges represent sinographs combined into words; [17], dealing with purely phonemic networks.",
      "startOffset" : 234,
      "endOffset" : 238
    }, {
      "referenceID" : 16,
      "context" : "As for considering Chinese script as a network, this has been done in several papers, such as [13, 14] (where edges represent components combined in the same sinograph) or [15], where components and sinographs form a bipartite graph; [16], where edges represent sinographs combined into words; [17], dealing with purely phonemic networks.",
      "startOffset" : 294,
      "endOffset" : 298
    }, {
      "referenceID" : 13,
      "context" : "[14] give an example of a small phono-semantic graph (a bipartite graph where edges connect semantic and phonetic components), but do not enter into the calculations of phoneticity and semanticity.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "Hanzi Grid [18, 19] maps component inclusions to relations in ontologies.",
      "startOffset" : 11,
      "endOffset" : 19
    }, {
      "referenceID" : 18,
      "context" : "Hanzi Grid [18, 19] maps component inclusions to relations in ontologies.",
      "startOffset" : 11,
      "endOffset" : 19
    }, {
      "referenceID" : 19,
      "context" : "Finally the cognitive psychology community is also heavily interested in the (cognitive) processing of phonetic and semantic components [20, 21], and even in the effects of stroke order and radicals on linguistic knowledge [22].",
      "startOffset" : 136,
      "endOffset" : 144
    }, {
      "referenceID" : 20,
      "context" : "Finally the cognitive psychology community is also heavily interested in the (cognitive) processing of phonetic and semantic components [20, 21], and even in the effects of stroke order and radicals on linguistic knowledge [22].",
      "startOffset" : 136,
      "endOffset" : 144
    }, {
      "referenceID" : 21,
      "context" : "Finally the cognitive psychology community is also heavily interested in the (cognitive) processing of phonetic and semantic components [20, 21], and even in the effects of stroke order and radicals on linguistic knowledge [22].",
      "startOffset" : 223,
      "endOffset" : 227
    }, {
      "referenceID" : 22,
      "context" : "In particular, during the Chinese writing reform [23], about 1,753 sinographs obtained simplified shapes (for example, 蔔 became 卜), which are encoded separately in Unicode.",
      "startOffset" : 49,
      "endOffset" : 53
    }, {
      "referenceID" : 23,
      "context" : "These two properties of subcharacters in relation to characters can be quantified and are then called semanticity and phoneticity [24].",
      "startOffset" : 130,
      "endOffset" : 134
    }, {
      "referenceID" : 24,
      "context" : "We have used three publicly available frequency lists: uni, the languageindependent Unihan [25]; sin, the traditional Chinese Sinica compiled by Academia Sinica Taipei; and noz, a Japanese list, taken from [26].",
      "startOffset" : 91,
      "endOffset" : 95
    }, {
      "referenceID" : 25,
      "context" : "We have used three publicly available frequency lists: uni, the languageindependent Unihan [25]; sin, the traditional Chinese Sinica compiled by Academia Sinica Taipei; and noz, a Japanese list, taken from [26].",
      "startOffset" : 206,
      "endOffset" : 210
    }, {
      "referenceID" : 26,
      "context" : "We have also compiled our own frequency lists out of five corpora: Chinese Wikipedia (wps for simplified Chinese and wpt for traditional Chinese), Japanese Wikipedia wpj, Chinese Project Gutenberg gut, Chinese GoogleBooks goo, Leeds Chinese Internet Corpus cic [27].",
      "startOffset" : 261,
      "endOffset" : 265
    }, {
      "referenceID" : 27,
      "context" : "After merging with data from the CHISE project [28] and with data kindly provided by Cornelia Schindelin [29], and after having removed identities, we got a list of 824,120 strict inclusions.",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 28,
      "context" : "After merging with data from the CHISE project [28] and with data kindly provided by Cornelia Schindelin [29], and after having removed identities, we got a list of 824,120 strict inclusions.",
      "startOffset" : 105,
      "endOffset" : 109
    }, {
      "referenceID" : 29,
      "context" : "Remarkably, these are a bit low compared to typical scale-free networks like the Web or proteins, which are in the 2–3 range [30].",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 30,
      "context" : "For Mandarin Chinese we implemented the phonetic distance described in [31].",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 31,
      "context" : "We obtained this distance by applying a methodology given by [32] and [33]: indeed, we defined a distance for syllables, using seven features: consonant place of articulation (weight 4), consonant voicing (1), consonant manner of articulation (4), consonant palatalization (1), vowel frontness (5), vowel height (1), and vowel rounding (1).",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 32,
      "context" : "We obtained this distance by applying a methodology given by [32] and [33]: indeed, we defined a distance for syllables, using seven features: consonant place of articulation (weight 4), consonant voicing (1), consonant manner of articulation (4), consonant palatalization (1), vowel frontness (5), vowel height (1), and vowel rounding (1).",
      "startOffset" : 70,
      "endOffset" : 74
    }, {
      "referenceID" : 0,
      "context" : "We define the phoneticity coefficient φ(c1, c2) := 1−dmin(c1,c2) N where N is a normalization constant such that Im(φ) = [0, 1].",
      "startOffset" : 121,
      "endOffset" : 127
    }, {
      "referenceID" : 33,
      "context" : "As semantic resources for sinographic languages we used three WordNets: the Academia Sinica BOW [34] for traditional Chinese, the Chinese WordNet [35] for simplified Chinese and the Japanese WordNet [36].",
      "startOffset" : 96,
      "endOffset" : 100
    }, {
      "referenceID" : 34,
      "context" : "As semantic resources for sinographic languages we used three WordNets: the Academia Sinica BOW [34] for traditional Chinese, the Chinese WordNet [35] for simplified Chinese and the Japanese WordNet [36].",
      "startOffset" : 146,
      "endOffset" : 150
    }, {
      "referenceID" : 35,
      "context" : "As semantic resources for sinographic languages we used three WordNets: the Academia Sinica BOW [34] for traditional Chinese, the Chinese WordNet [35] for simplified Chinese and the Japanese WordNet [36].",
      "startOffset" : 199,
      "endOffset" : 203
    }, {
      "referenceID" : 36,
      "context" : "By measuring distance between WordNet nodes using semantic similarity measures, such as those of [37–39] or simply the inverse of the shortest path length in the WordNet graph.",
      "startOffset" : 97,
      "endOffset" : 104
    }, {
      "referenceID" : 37,
      "context" : "By measuring distance between WordNet nodes using semantic similarity measures, such as those of [37–39] or simply the inverse of the shortest path length in the WordNet graph.",
      "startOffset" : 97,
      "endOffset" : 104
    }, {
      "referenceID" : 38,
      "context" : "By measuring distance between WordNet nodes using semantic similarity measures, such as those of [37–39] or simply the inverse of the shortest path length in the WordNet graph.",
      "startOffset" : 97,
      "endOffset" : 104
    }, {
      "referenceID" : 0,
      "context" : "S(ι) = 12 log(1 + f1(ι)) + 1 4 log(1 + f2(ι)) + 1 4r(ι), normalized so that its values stay in the interval [0, 1].",
      "startOffset" : 108,
      "endOffset" : 114
    } ],
    "year" : 2014,
    "abstractText" : "Chinese characters have a complex and hierarchical graphical structure carrying both semantic and phonetic information. We use this structure to enhance the text model and obtain better results in standard NLP operations. First of all, to tackle the problem of graphical variation we define allographic classes of characters. Next, the relation of inclusion of a subcharacter in a characters, provides us with a directed graph of allographic classes. We provide this graph with two weights: semanticity (semantic relation between subcharacter and character) and phoneticity (phonetic relation) and calculate “most semantic subcharacter paths” for each character. Finally, adding the information contained in these paths to unigrams we claim to increase the efficiency of text mining methods. We evaluate our method on a text classification task on two corpora (Chinese and Japanese) of a total of 18 million characters and get an improvement of 3% on an already high baseline of 89.6% precision, obtained by a linear SVM classifier. Other possible applications and perspectives of the system are discussed.",
    "creator" : "TeX"
  }
}