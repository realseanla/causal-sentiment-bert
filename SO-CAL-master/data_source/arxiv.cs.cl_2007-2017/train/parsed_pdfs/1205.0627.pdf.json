{
  "name" : "1205.0627.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "YANN PONTY" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n20 5.\n06 27\nv1 [\ncs .C\nL ]\n3 M\nay 2"
    }, {
      "heading" : "1. Introduction",
      "text" : "The random generation of combinatorial objects is one of the natural applications of enumerative combinatorics. Following general principles outlined by Wilf [12], Flajolet et al [8] proposed a fully-automated algebraic approach for the extensive class of decomposable combinatorial objects, a large class of objects that includes context-free languages. This pioneering work was later completed by the introduction of Boltzmann samplers, an alternative family of random generation algorithms based on analytical properties of the underlying generating functions [7]. However, these works only addressed the uniform distribution, while many applications of random generation (e.g. in RNA bioinformatics [6]) require non-uniform distributions to be modeled.\nTo that purpose, Denise et al [4] introduced (terminal)-weighted grammars, a non-uniform framework where the terminal symbols (letters) are associated with a real positive value, inherited multiplicatively by words in the language. Such weights were then used, through a trivial renormalization, to induce a probability distribution on the finite set of words of a given length. Generic random generation algorithms were proposed [4] and implemented within a general random generation toolbox [10]. Analytic and numerical approaches were proposed for figuring out suitable set of weights that would mimic a given, observed, distribution [3]. Finally, a multidimensional rejection scheme was explored to sample words of a given composition, yielding efficient algorithms by generalizing the principles of Boltzmann sampling [2].\nMore recently, Weinberg et al [11] proposed an alternative definition for weighted grammars, associating positive real-values to rules instead of terminal letters. The\nKey words and phrases. Weighted Context-Free Grammars; Random Generation; Normal forms.\n1\nauthors proposed a random generation procedure based on formal grammar manipulations, followed by a call to an unranking algorithm due to Martinez and Molinero [9]. However, the relative expressivities, in term of the distribution induced by the respective weighting schemes, of the two formalisms were not compared.\nIn this short note, we establish the equivalence of the two formalisms with respect to their induced distributions. After this short introduction, we remind in Section 2 the definitions of terminal-weighted and rule-weighted grammars. Then we turn to an analysis of the relative expressivities of the two formalisms, and establish in Section 3 that any terminal-weighted grammar can be simulated by a rule-weighted grammar. Furthermore, we use a Greibach Normal Form transformation to prove, in Section 4, that any rule-weighted grammar can be transformed into a terminal-weighted grammar inducing the same probability distribution, from which one concludes on the equivalence of the two formalisms. We conclude in Section 5 with some closing remarks and perspectives."
    }, {
      "heading" : "2. Definitions",
      "text" : "A context-free grammar is a 4-tuple G = (Σ,N ,P ,S) where\n• Σ is the alphabet, i.e. a finite set of terminal symbols, also called letters. • N is a finite set of non-terminal symbols. • P is the finite set of production rules of the formN → X , whereN ∈ N is a non-terminal and X ∈ {Σ ∪ N}∗ is a sequence of letters and non-terminals. • S is the axiom of the grammar, i. e. the initial non-terminal.\nWe will denote by L(G)n the set of all words of length n generated by G. This set is generated by iteratively applying production rules to non-terminals until a word in Σ∗ is obtained.\nNote that the non-terminals on the right-hand side of a production rule can be independently derived. It follows that the derivation process, starting from the initial axiom and ending with a word w over the terminal alphabet, can be represented by a parse tree dw. This (ordered directed) tree associates production rules to each internal node and terminal letters to each leaf, such that the i-th child of a node labeled with N → x1. · · · .xk is either a terminal letter xi ∈ Σ or a further derivation of xi ∈ P , starting from a root node that derives the axiom S.\nAssumptions: Let us assume, for the sake of simplicity, that the grammars considered in the following are unambiguous, i.e. that any word in L(G)n has exactly one associated parse tree. Moreover, let us assume, without loss of generality, that the grammar is given using a binary variant of the Chomsky Normal Form (CNF), which partitions the non-terminals into four classes, restricting their production rules to:\n• Axiom: S → N , N ∈ N , and/or S → ε. • Unions: N → N ′ | N ′′, such that N,N ′, N ′′ ∈ N/{S}. • Products: N → N ′.N ′′, such that N,N ′, N ′′ ∈ N/{S}. • Terminals: N → t, t ∈ Σ.\nFinally, we will postulate the absence of non-productive terminals, e.g. having rules of the form N → N.N ′.\n2.1. Terminal-Weighted Grammars. A non-uniform distribution can be postulated on the language generated by the grammar. To that purpose, two formalisms have been independently proposed, reminded here for the sake of completeness.\nDefinition 2.1 ((Terminal)-Weighted Grammar [4]). A terminal-weighted grammar Gπ is a 5-tuple Gπ = (π,Σ,N ,P ,S) where:\n• (Σ,N ,P ,S) defines a context-free grammar, • π : Σ → R+ is a terminal-weighting function that associates a non-null positive real-valued weight πt to each terminal symbol t.\nThe weight of a word w ∈ L(Gπ) is then given by\nπ(w) = ∏\nt∈Σ\nπ |w|t t\nand extended into a probability distribution over L(G)n by\npπ,n(w) = π(w) ∑\nw∈L(G)n π(w)\n.\n2.2. Rule-Weighted Grammars.\nDefinition 2.2 ((Rule)-Weighted Grammar [11]). A rule-weighted grammar Gλ is a 5-tuple Gλ = (λ,Σ,N ,P ,S) where:\n• (Σ,N ,P ,S) defines a context-free grammar, • λ : P → R+ is a rule-weighting function that associates a positive nonnull real-valued1 weight λr to each derivation r ∈ P , using the notation N →y X to indicate the association of a weight λr = y to a rule r = (N → X).\nThe weight function λ can then be extended multiplicatively over L(Gλ) through\nλ(w) = ∏\nr∈dw r=(N→λrX)\nλr, ∀w ∈ L(Gλ)\nwhere dw is the (unique) parse tree of w in Gλ. This induces a probability distribution over L(Gλ)n such that\npλ,n(w) = λ(w) ∑\nw∈L(Gλ)n λ(w)\n."
    }, {
      "heading" : "3. Any terminal-weighted distribution can be obtained using a rule-weighted grammar",
      "text" : "Theorem 3.1. For any terminal-weighted grammar Gπ, there exists a rule-weighted grammar Gλ, L(Gπ) = L(Gλ), inducing an identical probability distribution.\nProof. We give a constructive proof of this theorem. For any grammar Gπ = (π,Σ,N ,P ,S), let us consider the rule-weighted grammar defined by Gλ := (λ,Σ,N ,P ,S), such that λ(N → t) = πt and λ(·) = 1 otherwise.\nClearly, the production rules and axioms of Gλ and Gπ are identical, therefore one has L(Gλ) = L(Gπ) and, in particular,\nL(Gλ)n = L(Gπ)n, ∀n ≥ 0.\n1More precisely, Weinberg et al restrict their formalism to rational weights, based on the rationale that real-numbers would lead to unstable computations. However their framework could easily be extended to any computable real numbers without loss of precision, e.g. by implementing a confidence intervals approach described in Denise and Zimmermann [5], therefore we consider a trivial extension of this formalism here.\nLet us now remark that any terminal letter t in a produced word w results from the application of a rule of the form N → t, and that the parse trees in Gπ and Gλ of any word w ∈ L(Gπ) = L(Gλ) are identical. It follows that the occurrences of the terminal letter t in w are in bijection with the occurrences of the N → t rule in its parse tree dw, and therefore\nλ(w) = ∏\nr=(N→λr t)∈dw\nλr = ∏\n(N→λr t)∈dw\nπt = π(w), ∀w ∈ L(Gπ).\nSince L(Gλ)n = L(Gπ)n, then one has ∑\nw∈L(Gλ)n\nλ(w) = ∑\nw∈L(Gπ)n\nπ(w),\nand we conclude that, for any length n ≥ 0, one has\npπ,n(w) = λ(w) ∑\nw∈L(Gλ)n λ(w)\n= π(w) ∑\nw∈L(Gπ)n π(w)\n= pλ,n(w)\nwhich proves our claim."
    }, {
      "heading" : "4. Any rule-weighted distribution can be obtained using a terminal-weighted grammar",
      "text" : "Theorem 4.1. For any rule-weighted grammar Gλ, there exists a terminal-weighted grammar Gπ, L(Gλ) = L(Gπ), inducing an identical probability distribution.\nProof. Let us first remind the definition of the Greibach Normal Form (GNF), which requires each production rule to be of the form:\n• S → ε, where S is the axiom, • N → t.X , where t ∈ Σ and X ∈ {Σ ∪N/{S}}∗.\nBased on Lemma 4.2 proven below, we know that any rule-weighted grammar in Chomsky-Normal Form can be transformed into a GNF grammar that generates the same language and induces the same distribution. Let us then assume, without loss of generality, that the input grammar Gλ = (λ,Σ,N ,P ,S) is in GNF.\nBy duplicating the vocabulary, one easily builds a terminal-weighted grammar that induces the same probability distribution as Gλ. Namely, let us define Gπ = (π,Σπ,N ,Pπ,S) such that Σπ := {tr}r∈P , π(tr) := λ(r), and\nPπ := {N → tr.X | r = (N →x t.X) ∈ P} ∪ {S → ε | S →x ε ∈ P}.\nClearly, each terminal letter in a word produced by Gπ can be unambiguously associated with a rule of Gλ, therefore the weight of any non-empty word is preserved. Furthermore, the generated languages of Gλ and Gπ are identical, so the distribution is preserved. Finally, the weight of the empty word ε, implicitly set to 1 in the new grammar, may generally differ from its original value λ(S → ε) in Gλ. However, ε is the only word of length 0, and therefore has probability 1 in both grammars. We conclude that the probability distribution induced by Gλ is the same as that of Gπ.\nLemma 4.2. For any rule-weighted grammar Gλ = (λ,Σ,N ,P ,S), there exists a grammar Hλ′ in Greibach Normal Form inducing the same distribution.\nProof. Again, we use a constructive proof, showing that the weight distribution can be preserved during the transformation of the grammar performed by the Blum and Koch normalisation algorithm [1]. Let us state the algorithm:\n(1) Renumber non-terminals in any order, starting with the Axiom S ⇒ N1. (2) For k = 1 to |N |, consider the non-terminal Nk:\n(a) For each r = (Nk →x Nj.X) ∈ P , such that j < k and\nNj →x1 X1, Nj →x2 X2, · · · , Nj →xm Xm,\nreplace r in P as follows\nFormer rule(s) New rule(s)\nNk →x Nj .X\nNk →x·x1 X1.X Nk →x·x2 X2.X ... Nk →x·xm Xm.X.\n(b) Fix any left-recursive non-terminal Nk by replacing its rules as follows, using an alternative chain-rule construct:\nFormer rule(s) New rule(s)\nNk →x1 Nk.X1 N ′k →x1 X1.N ′ k\nN ′k →x1 X1 ... ...\nNk →xm Nk.Xm N ′k →xm Xm.N ′ k\nN ′k →xm Xm\nNk →y1 Y1 N ′k →y1 Y1.N ′ k\nN ′k →y1 Y1 ... ...\nNk →ym′ Ym′ N ′k →ym′ Ym.N ′ k\nN ′k →ym′ Ym′\n(3) For k = |N | down to 1, consider the non-terminal Nk: (a) For each r = (Nk →x Nj.X) ∈ P , such that j > k and\nNj →x1 X1, Nj →x2 X2, · · · , Nj →xm Xm,\nreplace r in P as follows\nFormer rule(s) New rule(s)\nNk →x Nj .X\nNk →x·x1 X1.X Nk →x·x2 X2.X ... Nk →x·xm Xm.X.\nOne easily verifies that, after any iteration of step (2), the grammar no longer contains any rule Nj → Nl.X such that l ≤ j ≤ k. This holds for Nk which, after the full execution of step (2), does not depend from any non-terminal, and is therefore in GNF. Furthermore, one may assume that, anytime a non-terminal Nk is considered during step (3), every Nj such that k < j is in GNF. Consequently, the expansion of Nj only creates rules that are GNF-compliant, thus Nk is in GNF at the end of the iteration.\nLet us denote by Hλ′ = (λ′,Σ,N ′,P ′,S) the rule-weighted grammar obtained at the end of the execution. One first remarks that both the expansions (Steps (2.a) and (3.a)) and the chain-rule reversal (Steps (2.b)) preserve the generated language,\nso that the language generated by a non-terminal in Gλ is also the language generated by its corresponding non-terminal in Hλ′ . Furthermore, one can prove, by induction on the number of derivations required to generate a word, that the induced probability distribution is kept invariant by rules substitutions operated by the algorithm.\nTo that purpose, let us first extend the definition of a rule-weighting function to include a partial derivation instead of a single non-terminal. Namely, λX(w) will represent the weight of w, as derived from X ∈ {P ∪Σ}∗ and, in particular, one has λS ≡ λ. Let us now consider the rule-weighting functions λ◮ and λ◭, respectively induced by the grammar before and after a modification:\n• Induction hypothesis: Any word w generated from any X{P ∪Σ}∗ using d derivations, 1 ≤ d < n, is such that λ′X(w) = λ ′′ X(w). • Rule expansion (Steps (2.a) and (3.a)): Consider a word w, generated using n derivations from some non-terminal N . Clearly, if N 6= Nk or if the first derivation used is N → X ′ 6= Nj .X , then the rule used to generated w is not affected by the modification. The induction hypothesis applies and one trivially gets λ◮Nk(w) = λ ◭ Nk (w).\nConsider the initial state of the grammar. When w results from a derivation N →x Nj .X , then there exists a (unique) decomposition w = w′.w′′, where w′ is produced by the application of some rule Nj →xi Xi, and w′′ is derived from X . The weight of w is then given by λ◮Nk(w) = x · xi · λ ◮\nXi (w′) · λ◮X(w ′′). In the modified version of the grammar, w = w′.w′′ unambiguous derives from an application of the new rule Nk →x·xi Xi.X (w ′ ∈ L(Xi) and w′′ ∈ L(X)), with associated weight λ◭k (w) = x · xi · λ ′′ k(w ′) · λ◭k (w ′′). Since both w′ and w′′ are generated using less than n derivations, then the induction hypothesis applies and one gets\nλ◭Nk(w) = x · xi · λ ◭ Xi (w′) · λ◭X(w ′′) = x · xi · λ ◮ Xi (w′) · λ◮X(w ′′) = λ◮Nk(w).\n• Chain-rule reversal (Steps (2.b)): Any word produced using the initial leftrecursive chain-rule can be uniquely decomposed as w = w′.w′′1 . · · · .w ′′ p ,\nwhere w′ is generated from some Nk →yq Yq, q ∈ [1,m ′], and each w′′i is generated by some rule Nk →xqi Nk.Xqi , qi ∈ [1,m]. Its weight is therefore given by λ◮Nk(w) = yq · ( ∏m i=1 xqi ) · λ ◮ Yq (w′) · ( ∏m i=1 λ ◮ Xqi (w′′i ) ) .\nAfter chain-rule reversal, the same decomposition w = w′.w′′1 . · · · .w ′′ p holds, but the sequence of derivation is now either Nk →yq Yq (w = w ′), or\nNk →yq Yq.N ′ k →xq1 Yq.Xq1 .N ′ k\nYq.Xq1 . · · · .Xqm−1 .N ′ k\n→xqm Yq.Xq1 . · · · .Xqm w ′.w′′1 . · · · .w ′′ p .\nIn both cases, the induction hypothesis applies for each element of the decomposition, and the weight of w in the new decomposition is given by\nλ◭Nk(w) = yq ·\n(\nm ∏\ni=1\nxqi\n)\n· λ◭Yq (w ′) ·\n(\nm ∏\ni=1\nλ◭Xqi (w′′i )\n)\n= yq ·\n(\nm ∏\ni=1\nxqi\n)\n· λ◮Yq (w ′) ·\n(\nm ∏\ni=1\nλ◮Xqi (w′′i )\n)\n= λ◮Nk(w).\nIt follows that the weight of any word is left unchanged by the substitutions performed in the algorithm. Since the generated language is also preserved, then such a preservation of the weights implies a preservation of the probabilities. We conclude that the returned grammar, in addition to being in GNF, also induces the same probability distribution as Gλ."
    }, {
      "heading" : "5. Conclusion",
      "text" : "Using a trivial modification of the Blum and Koch algorithm [1], we showed that weighting terminal or weighting rules have equal expressive power, i.e. that any distribution captured by the former formalism is also captured by the other and vice-versa.\nWhile both proofs are relatively trivial, going from rule-weighted grammars to terminal-weighted grammars turned out to be more involved than the alternative, leading to an increase of the number of rules. However, this observation might be deceptive, as the choice of the Greibach Normal Form as an intermediate form is only one out of possibly many alternatives, and one could devise more efficient grammar transforms capturing the same distributions. Moreover, it is noteworthy that, even if one chooses to use GNF grammars, there still seems to be a gap between the O(|P|4) size of the grammar returned by the Blum and Koch algorithm, and the minimum O(|P|2) increase observed for some infinite family of grammars, motivating the search for better GNF transformation algorithms."
    } ],
    "references" : [ {
      "title" : "Greibach normal form transformation revisited",
      "author" : [ "Norbert Blum", "Robert Koch" ],
      "venue" : "Information and Computation",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1999
    }, {
      "title" : "Multi-dimensional Boltzmann sampling of languages, Proceedings of AOFA’10 (Vienna)",
      "author" : [ "O. Bodini", "Y. Ponty" ],
      "venue" : "Discrete Mathematics and Theoretical Computer Science Proceedings,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2010
    }, {
      "title" : "Controlled non uniform random generation of decomposable structures",
      "author" : [ "A. Denise", "Y. Ponty", "M. Termier" ],
      "venue" : "Theoretical Computer Science",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2010
    }, {
      "title" : "Random generation of words of context-free languagesaccording to the frequencies of letters, Mathematics and Computer Science: Algorithms,Trees, Combinatorics and probabilities (D",
      "author" : [ "A. Denise", "O. Roques", "M. Termier" ],
      "venue" : "Gardy and A. Mokkadem, eds.), Trends in Mathematics, Birkhaüser,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2000
    }, {
      "title" : "Uniform random generation of decomposable structures using floating-point arithmetic",
      "author" : [ "A. Denise", "P. Zimmermann" ],
      "venue" : "Theor. Comput. Sci",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 1999
    }, {
      "title" : "A statistical sampling algorithm for RNA secondary structure prediction",
      "author" : [ "Y. Ding", "E. Lawrence" ],
      "venue" : "Nucleic Acids Research",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2003
    }, {
      "title" : "Random sampling from Boltzmann principles, Automata, Languages, and Programming (P",
      "author" : [ "P. Duchon", "P. Flajolet", "G. Louchard", "G. Schaeffer" ],
      "venue" : "Widmayer et al., ed.), Lecture Notes in Computer Science,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2002
    }, {
      "title" : "Calculus for the random generation of labelled combinatorial structures",
      "author" : [ "P. Flajolet", "P. Zimmermann", "B. Van Cutsem" ],
      "venue" : "Theoretical Computer Science",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1994
    }, {
      "title" : "A generic approach for the unranking of labeled combinatorial classes",
      "author" : [ "C. Martinez", "X. Molinero" ],
      "venue" : "Random Structures & Algorithms,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2001
    }, {
      "title" : "GenRGenS: Software for generating random genomic sequences and structures, Bioinformatics",
      "author" : [ "Y. Ponty", "M. Termier", "A. Denise" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    }, {
      "title" : "Non uniform generation of combinatorial objects, Tech. report",
      "author" : [ "F. Weinberg", "M.E. Nebel" ],
      "venue" : "Technical Report University of Kaiserslauter,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2010
    }, {
      "title" : "A unified setting for sequencing, ranking, and selection algorithms for combinatorial objects",
      "author" : [ "H.S. Wilf" ],
      "venue" : "Advances in Mathematics",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1977
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "Following general principles outlined by Wilf [12], Flajolet et al [8] proposed a fully-automated algebraic approach for the extensive class of decomposable combinatorial objects, a large class of objects that includes context-free languages.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 7,
      "context" : "Following general principles outlined by Wilf [12], Flajolet et al [8] proposed a fully-automated algebraic approach for the extensive class of decomposable combinatorial objects, a large class of objects that includes context-free languages.",
      "startOffset" : 67,
      "endOffset" : 70
    }, {
      "referenceID" : 6,
      "context" : "This pioneering work was later completed by the introduction of Boltzmann samplers, an alternative family of random generation algorithms based on analytical properties of the underlying generating functions [7].",
      "startOffset" : 208,
      "endOffset" : 211
    }, {
      "referenceID" : 5,
      "context" : "in RNA bioinformatics [6]) require non-uniform distributions to be modeled.",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 3,
      "context" : "To that purpose, Denise et al [4] introduced (terminal)-weighted grammars, a non-uniform framework where the terminal symbols (letters) are associated with a real positive value, inherited multiplicatively by words in the language.",
      "startOffset" : 30,
      "endOffset" : 33
    }, {
      "referenceID" : 3,
      "context" : "Generic random generation algorithms were proposed [4] and implemented within a general random generation toolbox [10].",
      "startOffset" : 51,
      "endOffset" : 54
    }, {
      "referenceID" : 9,
      "context" : "Generic random generation algorithms were proposed [4] and implemented within a general random generation toolbox [10].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 2,
      "context" : "Analytic and numerical approaches were proposed for figuring out suitable set of weights that would mimic a given, observed, distribution [3].",
      "startOffset" : 138,
      "endOffset" : 141
    }, {
      "referenceID" : 1,
      "context" : "Finally, a multidimensional rejection scheme was explored to sample words of a given composition, yielding efficient algorithms by generalizing the principles of Boltzmann sampling [2].",
      "startOffset" : 181,
      "endOffset" : 184
    }, {
      "referenceID" : 10,
      "context" : "More recently, Weinberg et al [11] proposed an alternative definition for weighted grammars, associating positive real-values to rules instead of terminal letters.",
      "startOffset" : 30,
      "endOffset" : 34
    }, {
      "referenceID" : 8,
      "context" : "authors proposed a random generation procedure based on formal grammar manipulations, followed by a call to an unranking algorithm due to Martinez and Molinero [9].",
      "startOffset" : 160,
      "endOffset" : 163
    }, {
      "referenceID" : 3,
      "context" : "1 ((Terminal)-Weighted Grammar [4]).",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 10,
      "context" : "2 ((Rule)-Weighted Grammar [11]).",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 4,
      "context" : "by implementing a confidence intervals approach described in Denise and Zimmermann [5], therefore we consider a trivial extension of this formalism here.",
      "startOffset" : 83,
      "endOffset" : 86
    }, {
      "referenceID" : 0,
      "context" : "Again, we use a constructive proof, showing that the weight distribution can be preserved during the transformation of the grammar performed by the Blum and Koch normalisation algorithm [1].",
      "startOffset" : 186,
      "endOffset" : 189
    }, {
      "referenceID" : 0,
      "context" : "Using a trivial modification of the Blum and Koch algorithm [1], we showed that weighting terminal or weighting rules have equal expressive power, i.",
      "startOffset" : 60,
      "endOffset" : 63
    } ],
    "year" : 2013,
    "abstractText" : "Two formalisms have recently been proposed to perform a nonuniform random generation of combinatorial objects based on context-free grammars. The former, introduced by Denise et al, associates weights with letters, while the latter, recently explored by Weinberg et al in the context of random generation, associates weights to transitions. In this short note, we use a trivial modification of the Greibach Normal Form transformation algorithm, due to Blum and Koch, to show the equivalent expressivities of these two formalisms.",
    "creator" : "LaTeX with hyperref package"
  }
}