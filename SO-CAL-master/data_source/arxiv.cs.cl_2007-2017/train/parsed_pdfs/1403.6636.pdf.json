{
  "name" : "1403.6636.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Sign Language Lexical Recognition With Propositional Dynamic Logic",
    "authors" : [ "Arturo Curiel", "Paul Sabatier", "Christophe Collet" ],
    "emails" : [ "curiel@irit.fr", "collet@irit.fr" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Sign languages (SL), the vernaculars of deaf people, are complete, rich, standalone communication systems which have evolved in parallel with oral languages (Valli and Lucas, 2000). However, in contrast to the last ones, research in automatic SL processing has not yet managed to build a complete, formal definition oriented to their automatic recognition (Cuxac and Dalle, 2007). In SL, both hands and nonmanual features (NMF), e.g. facial muscles, can convey information with their placements,\n∗Supported by CONACYT (Mexico) scholarship program.\nconfigurations and movements. These particular conditions can difficult the construction of a formal description with common natural language processing (NLP) methods, since the existing modeling techniques are mostly designed to work with one-channel sound productions inherent to oral languages, rather than with the multi-channel partially-synchronized information induced by SLs.\nOur research strives to address the formalization problem by introducing a logical language that lets us represent SL from the lowest level, so as to render the recognition task more approachable. For this, we use an instance of a formal logic, specifically Propositional Dynamic Logic (PDL), as a possible description language for SL signs.\nFor the rest of this section, we will present a brief introduction to current research efforts in the area. Section 2 presents a general description of our formalism, while section 3 shows how our work can be used when confronted with real world data. Finally, section 4 present our final observations and future work.\nImages for the examples where taken from (DictaSign, 2012) corpus."
    }, {
      "heading" : "1.1 Current Sign Language Research",
      "text" : "Extensive efforts have been made to achieve efficient automatic capture and representation of the subtle nuances commonly present in sign language discourse (Ong and Ranganath, 2005). Research ranges from the development of hand and body trackers (Dreuw et al., 2009; Gianni and Dalle, 2009), to the design of high level SL representation models (Lejeune, 2004; Lenseigne and Dalle, 2006). Linguistic research in the area has focused on the characterization of corporal expressions into meaningful transcriptions (Dreuw et al., 2010; Stokoe, 2005) or common patterns across SL (Aronoff\nar X\niv :1\n40 3.\n66 36\nv1 [\ncs .C\nL ]\n2 6\nM ar\n2 01\n4\net al., 2005; Meir et al., 2006; Wittmann, 1991), so as to gain understanding of the underlying mechanisms of SL communication.\nWorks like (Losson and Vannobel, 1998) deal with the creation of a lexical description oriented to computer-based sign animation. Report (Filhol, 2009) describes a lexical specification to address the same problem. Both propose a thoroughly geometrical parametric encoding of signs, thus leaving behind meaningful information necessary for recognition and introducing data beyond the scope of recognition. This complicates the reutilization of their formal descriptions. Besides, they don’t take in account the presence of partial information. Treating partiality is important for us, since it is often the case with automatic tools that incomplete or unrecognizable information arises. Finally, little to no work has been directed towards the unification of raw collected data from SL corpora with higher level descriptions (Dalle, 2006)."
    }, {
      "heading" : "2 Propositional Dynamic Logic for",
      "text" : "SL\nPropositional Dynamic Logic (PDL) is a multimodal logic, first defined by (Fischer and Ladner, 1979). It provides a language for describing programs, their correctness and termination, by allowing them to be modal operators. We work with our own variant of this logic, the Propositional Dynamic Logic for Sign Language (PDLSL), which is just an instantiation of PDL where we take signers’ movements as programs.\nOur sign formalization is based on the approach of (Liddell and Johnson, 1989) and (Filhol, 2008). They describe signs as sequences of immutable key postures and movement transitions.\nIn general, each key posture will be characterized by the concurrent parametric state of each body articulator over a time-interval. For us, a body articulator is any relevant body part involved in signing. The parameters taken in account can vary from articulator to articulator, but most of the time they comprise their configurations, orientations and their placement within one or more places of articulation. Transitions will correspond to the movements executed between fixed postures."
    }, {
      "heading" : "2.1 Syntax",
      "text" : "We need to define some primitive sets that will limit the domain of our logical language.\nDefinition 2.1 (Sign Language primitives). Let BSL = {D,W,R,L} be the set of relevant body articulators for SL, where D, W, R and L represent the dominant, weak, right and left hands, respectively. Both D and W can be aliases for the right or left hands, but they change depending on whether the signer is right-handed or left-handed, or even depending on the context. Let Ψ be the two-dimensional projection of a human body skeleton, seen by the front. We define the set of places of articulation for SL as ΛSL = {HEAD, CHEST, NEUTRAL, . . .}, such that for each λ ∈ ΛSL, λ is a sub-plane of Ψ, as shown graphically in figure 1. Let CSL be the set of possible morphological configurations for a hand. Let ∆ = {↑,↗,→,↘, ↓,↙,←,↖} be the set of relative directions from the signer’s point of view, where each arrow represents one of eight possible two-dimensional direction vectors that share the same origin. For vector δ ∈ ∆, we define vector ←− δ as the same as δ but with the inverted abscissa axis, such that ←− δ ∈ ∆. Let vector δ̂ indicate movement with respect to the dominant or weak hand in the following manner:\nδ̂ = { δ if D ≡ R or W ≡ L ←− δ if D ≡ L or W ≡ R\nFinally, let −→v1 and −→v2 be any two vectors with the same origin. We denote the rotation angle between the two as θ(−→v1 ,−→v2).\nNow we define the set of atomic propositions that we will use to characterize fixed states, and a set of atomic actions to describe movements.\nDefinition 2.2 (Atomic Propositions for SL Body Articulators ΦSL). The set of atomic propositions for SL articulators (ΦSL) is defined as:\nΦSL = {β1δβ2 ,Ξ β1 λ , T β1 β2 ,Fβ1c ,∠δβ1}\nwhere β1, β2 ∈ BSL, δ ∈ ∆, λ ∈ ΛSL and c ∈ CSL.\nIntuitively, β1δβ2 indicates that articulator β1 is placed in relative direction δ with respect to articulator β2. Let the current place of articulation of β2 be the origin point of β2’s Cartesian system (Cβ2). Let vector −→ β1 describe the current place of articulation of β1 in Cβ2. Proposition β1δβ2 holds when ∀\n−→v ∈ ∆, θ( −→ β1, δ) ≤ θ( −→ β1, −→v ).\nΞβ1λ asserts that articulator β1 is located in λ. T β1β2 is active whenever articulator β1 physically touches articulator β2. Fβ1c indicates that c is the morphological configuration of articulator β1. Finally, ∠δβ1 means that an articulator β1 is oriented towards direction δ ∈ ∆. For hands, ∠δβ1 will hold whenever the vector perpendicular to the plane of the palm has the smallest rotation angle with respect to δ.\nDefinition 2.3 (Atomic Actions for SL Body Articulators ΠSL). The atomic actions for SL articulators ( ΠSL) are given by the following set:\nΠSL = {δβ1 ,!β1}\nwhere δ ∈ ∆ and β1 ∈ BSL. Let β1’s position before movement be the origin of β1’s Cartesian system (Cβ1) and −→ β1 be the position vector of β1 in Cβ1 after moving. Action δβ1 indicates that β1 moves in relative direction δ in Cβ1 if ∀ −→v ∈ ∆, θ( −→ β1, δ) ≤ θ( −→ β1, −→v ).\nAction !β1 occurs when articulator β1 moves rapidly and continuously (thrills) with-\nout changing it’s current place of articulation.\nDefinition 2.4 (Action Language for SL Body Articulators ASL). The action language for body articulators (ASL) is given by the following rule:\nα ::= π | α ∩ α | α ∪ α | α;α | α∗\nwhere π ∈ ΠSL. Intuitively, α ∩ α indicates the concurrent execution of two actions, while α ∪ α means that at least one of two actions will be nondeterministically executed. Action α;α describes the sequential execution of two actions. Finally, action α∗ indicates the reflexive transitive closure of α.\nDefinition 2.5 (Language PDLSL ). The formulae ϕ of PDLSL are given by the following rule:\nϕ ::= > | p | ¬ϕ | ϕ ∧ ϕ | [α]ϕ\nwhere p ∈ ΦSL, α ∈ ASL."
    }, {
      "heading" : "2.2 Semantics",
      "text" : "PDLSL formulas are interpreted over labeled transition systems (LTS), in the spirit of the possible worlds model introduced by (Hintikka, 1962). Models correspond to connected graphs representing key postures and transitions: states are determined by the values of their propositions, while edges represent sets of executed movements. Here we present only a small extract of the logic semantics.\nDefinition 2.6 (Sign Language Utterance Model USL). A sign language utterance model (USL), is a tuple USL = (S,R, J·KΠSL , J·KΦSL) where:\n• S is a non-empty set of states\n• R is a transition relation R ⊆ S×S where, ∀s ∈ S, ∃s′ ∈ S such that (s, s′) ∈ R.\n• J·KΠSL : ΠSL → R, denotes the function mapping actions to the set of binary relations.\n• J·KΦSL : S → 2ΦSL , maps each state to a set of atomic propositions.\nWe also need to define a structure over sequences of states to model internal dependencies between them, nevertheless we decided to omit the rest of our semantics, alongside satisfaction conditions, for the sake of readability."
    }, {
      "heading" : "3 Use Case: Semi-Automatic Sign Recognition",
      "text" : "We now present an example of how we can use our formalism in a semi-automatic sign recognition system. Figure 2 shows a simple module diagram exemplifying information flow in the system’s architecture. We proceed to briefly describe each of our modules and how they work together."
    }, {
      "heading" : "3.1 Tracking and Segmentation Module",
      "text" : "The process starts by capturing relevant information from video corpora. We use an existing head and hand tracker expressly developed for SL research (Gonzalez and Collet, 2011). This tool analyses individual video instances, and returns the frame-by-frame positions of the tracked articulators. By using this information, the module can immediately calculate speeds and directions on the fly for each hand.\nThe module further employs the method proposed by the authors in (Gonzalez and Collet, 2012) to achieve sub-lexical segmentation from the previously calculated data. Like them, we use the relative velocity between hands to identify when hands either move at the same time, independently or don’t move at all. With these, we can produce a set of possible key postures and transitions that will serve as input to the modeling module."
    }, {
      "heading" : "3.2 Model Extraction Module",
      "text" : "This module calculates a propositional state for each static posture, where atomic PDLSL\nformulas codify the information tracked in the previous part. Detected movements are interpreted as PDLSL actions between states.\nFigure 3 shows an example of the process. Here, each key posture is codified into propositions acknowledging the hand positions with respect to each other (R←L ), their place of articulation (e.g. “left hand floats over the torse” with ΞLTORSE), their configuration (e.g. “right hand is open” with FROPENPALM_CONFIG) and their movements (e.g. “left hand moves to the upleft direction” with ↗L).\nThis module also checks that the generated graph is correct: it will discard simple tracking errors to ensure that the resulting LTS will remain consistent."
    }, {
      "heading" : "3.3 Verification Module",
      "text" : "First of all, the verification module has to be loaded with a database of sign descriptions encoded as PDLSL formulas. These will characterize the specific sequence of key postures that morphologically describe a sign. For example, let’s take the case for sign “route” in FSL, shown in figure 4, with the following PDLSL formulation,\nExample 3.1 (ROUTEFSL formula).\n(ΞRFACE ∧ ΞLFACE ∧ L→R ∧ FRCLAMP ∧ FLCLAMP ∧ T RL )→ [←R ∩ →L](L→R ∧ FRCLAMP ∧ FLCLAMP ∧ ¬T RL )\n(1)\nFormula (1) describes ROUTEFSL as a sign with two key postures, connected by a twohand simultaneous movement (represented with operator ∩). It also indicates the position of each hand, their orientation, whether they touch and their respective configurations (in this example, both hold the same CLAMP configuration).\nThe module can then verify whether a sign formula in the lexical database holds in any sub-sequence of states of the graph generated in the previous step. Algorithm 1 sums up the process.\nAlgorithm 1 PDLSL Verification Algorithm Require: SL modelMSL Require: connected graph GSL Require: lexical database DBSL 1: Proposals_For[state_qty] 2: for state s ∈ GSL do 3: for sign ϕ ∈ DBSL where s ∈ ϕ do 4: if MSL, s |= ϕ then 5: Proposals_For[s].append(ϕ) 6: end if 7: end for 8: end for 9: return Proposals_For\nFor each state, the algorithm returns a set of possible signs. Expert users (or higher level algorithms) can further refine the process by introducing additional information previously missed by the tracker."
    }, {
      "heading" : "4 Conclusions and Future Work",
      "text" : "We have shown how a logical language can be used to model SL signs for semi-automatic recognition, albeit with some restrictions. The traits we have chosen to represent were imposed by the limits of the tracking tools we had to our disposition, most notably working\nwith 2D coordinates. With these in mind, we tried to design something flexible that could be easily adapted by computer scientists and linguists alike. Our primitive sets, were intentionally defined in a very general fashion due to the same reason: all of the perceived directions, articulators and places of articulation can easily change their domains, depending on the SL we are modeling or the technological constraints we have to deal with. Propositions can also be changed, or even induced, by existing written sign representation languages such as Zebedee (Filhol, 2008) or HamNoSys (Hanke, 2004), mainly for the sake of extendability.\nFrom the application side, we still need to create an extensive sign database codified in PDLSL and try recognition on other corpora, with different tracking information. For verification and model extraction, further optimizations are expected, including the handling of data inconsistencies and repairing broken queries when verifying the graph.\nRegarding our theoretical issues, future work will be centered in improving our language to better comply with SL research. This includes adding new features, like incorporating probability representation to improve recognition. We also expect to finish the definition of our formal semantics, as well as proving correction and complexity of our algorithms."
    } ],
    "references" : [ {
      "title" : "The paradox of sign language morphology",
      "author" : [ "Aronoff et al.2005] Mark Aronoff", "Irit Meir", "Wendy Sandler" ],
      "venue" : null,
      "citeRegEx" : "Aronoff et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Aronoff et al\\.",
      "year" : 2005
    }, {
      "title" : "Problématique des chercheurs en traitement automatique des langues des signes, volume 48 of Traitement Automatique des Langues",
      "author" : [ "Cuxac", "Dalle2007] Christian Cuxac", "Patrice Dalle" ],
      "venue" : "Lavoisier,",
      "citeRegEx" : "Cuxac et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Cuxac et al\\.",
      "year" : 2007
    }, {
      "title" : "High level models for sign language analysis by a vision system. In Workshop on the Representation and Processing of Sign Language: Lexicographic Matters and Didactic Scenarios (LREC), Italy, ELDA, page",
      "author" : [ "Patrice Dalle" ],
      "venue" : null,
      "citeRegEx" : "Dalle.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dalle.",
      "year" : 2006
    }, {
      "title" : "Enhancing a sign",
      "author" : [ "Dreuw et al.2009] Philippe Dreuw", "Daniel Stein", "Hermann Ney" ],
      "venue" : null,
      "citeRegEx" : "Dreuw et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Dreuw et al\\.",
      "year" : 2009
    }, {
      "title" : "The SignSpeak project - bridging the gap between signers and speakers",
      "author" : [ "Dreuw et al.2010] Philippe Dreuw", "Hermann Ney", "Gregorio Martinez", "Onno Crasborn", "Justus Piater", "Jose Miguel Moya", "Mark Wheatley" ],
      "venue" : null,
      "citeRegEx" : "Dreuw et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Dreuw et al\\.",
      "year" : 2010
    }, {
      "title" : "Modèle descriptif des signes pour un traitement automatique des langues des signes",
      "author" : [ "Michael Filhol" ],
      "venue" : "Ph.D. thesis,",
      "citeRegEx" : "Filhol.,? \\Q2008\\E",
      "shortCiteRegEx" : "Filhol.",
      "year" : 2008
    }, {
      "title" : "Zebedee: a lexical description model for sign language synthesis",
      "author" : [ "Michael Filhol" ],
      "venue" : null,
      "citeRegEx" : "Filhol.,? \\Q2009\\E",
      "shortCiteRegEx" : "Filhol.",
      "year" : 2009
    }, {
      "title" : "Propositional dynamic logic of regular programs",
      "author" : [ "Fischer", "Ladner1979] Michael J. Fischer", "Richard E. Ladner" ],
      "venue" : "Journal of Computer and System Sciences,",
      "citeRegEx" : "Fischer et al\\.,? \\Q1979\\E",
      "shortCiteRegEx" : "Fischer et al\\.",
      "year" : 1979
    }, {
      "title" : "Robust tracking for processing of videos of communication’s gestures. GestureBased Human-Computer Interaction and Simulation, page 93–101",
      "author" : [ "Gianni", "Dalle2009] Frédéric Gianni", "Patrice Dalle" ],
      "venue" : null,
      "citeRegEx" : "Gianni et al\\.,? \\Q2009\\E",
      "shortCiteRegEx" : "Gianni et al\\.",
      "year" : 2009
    }, {
      "title" : "Robust body parts tracking using particle filter and dynamic template",
      "author" : [ "Gonzalez", "Collet2011] Matilde Gonzalez", "Christophe Collet" ],
      "venue" : "In 2011 18th IEEE International Conference on Image Processing (ICIP),",
      "citeRegEx" : "Gonzalez et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Gonzalez et al\\.",
      "year" : 2011
    }, {
      "title" : "Sign segmentation using dynamics and hand configuration for semiautomatic annotation of sign language corpora",
      "author" : [ "Gonzalez", "Collet2012] Matilde Gonzalez", "Christophe Collet" ],
      "venue" : null,
      "citeRegEx" : "Gonzalez et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gonzalez et al\\.",
      "year" : 2012
    }, {
      "title" : "HamNoSys—Representing sign language data in language resources and language processing contexts",
      "author" : [ "Thomas Hanke" ],
      "venue" : "In Proceedings of the Workshop",
      "citeRegEx" : "Hanke.,? \\Q2004\\E",
      "shortCiteRegEx" : "Hanke.",
      "year" : 2004
    }, {
      "title" : "Analyse sémantico-cognitive d’énoncés en Langue des Signes Fran\\ccaise pour une génération automatique de séquences gestuelles",
      "author" : [ "Fanch Lejeune" ],
      "venue" : "Ph.D. thesis,",
      "citeRegEx" : "Lejeune.,? \\Q2004\\E",
      "shortCiteRegEx" : "Lejeune.",
      "year" : 2004
    }, {
      "title" : "Using signing space as a representation for sign language processing",
      "author" : [ "Lenseigne", "Dalle2006] Boris Lenseigne", "Patrice Dalle" ],
      "venue" : null,
      "citeRegEx" : "Lenseigne et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Lenseigne et al\\.",
      "year" : 2006
    }, {
      "title" : "American sign language: The phonological base",
      "author" : [ "Liddell", "Johnson1989] S.K. Liddell", "R.E. Johnson" ],
      "venue" : null,
      "citeRegEx" : "Liddell et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Liddell et al\\.",
      "year" : 1989
    }, {
      "title" : "Sign language formal description and synthesis",
      "author" : [ "Losson", "Vannobel1998] Olivier Losson", "Jean-Marc Vannobel" ],
      "venue" : "INT.JOURNAL OF VIRTUAL REALITY,",
      "citeRegEx" : "Losson et al\\.,? \\Q1998\\E",
      "shortCiteRegEx" : "Losson et al\\.",
      "year" : 1998
    }, {
      "title" : "Re-thinking sign language verb classes: the body as subject. In Sign Languages: Spinning and Unraveling the Past, Present and Future",
      "author" : [ "Meir et al.2006] Irit Meir", "Carol Padden", "Mark Aronoff", "Wendy Sandler" ],
      "venue" : null,
      "citeRegEx" : "Meir et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Meir et al\\.",
      "year" : 2006
    }, {
      "title" : "Automatic sign language analysis: a survey and the future beyond lexical meaning",
      "author" : [ "Ong", "Ranganath2005] Sylvie C.W. Ong", "Surendra Ranganath" ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "Ong et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Ong et al\\.",
      "year" : 2005
    }, {
      "title" : "Sign language structure: An outline of the visual communication systems of the american deaf",
      "author" : [ "William C. Stokoe" ],
      "venue" : "Journal of Deaf Studies and Deaf Education,",
      "citeRegEx" : "Stokoe.,? \\Q2005\\E",
      "shortCiteRegEx" : "Stokoe.",
      "year" : 2005
    }, {
      "title" : "Linguistics of American Sign Language Text, 3rd Edition: An Introduction",
      "author" : [ "Valli", "Lucas2000] Clayton Valli", "Ceil Lucas" ],
      "venue" : null,
      "citeRegEx" : "Valli et al\\.,? \\Q2000\\E",
      "shortCiteRegEx" : "Valli et al\\.",
      "year" : 2000
    }, {
      "title" : "Classification linguistique des langues signées non vocalement",
      "author" : [ "Henri Wittmann" ],
      "venue" : "Revue québécoise de linguistique théorique et appliquée,",
      "citeRegEx" : "Wittmann.,? \\Q1991\\E",
      "shortCiteRegEx" : "Wittmann.",
      "year" : 1991
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "Research ranges from the development of hand and body trackers (Dreuw et al., 2009; Gianni and Dalle, 2009), to the design of high level SL representation models (Lejeune, 2004; Lenseigne and Dalle, 2006).",
      "startOffset" : 63,
      "endOffset" : 107
    }, {
      "referenceID" : 12,
      "context" : ", 2009; Gianni and Dalle, 2009), to the design of high level SL representation models (Lejeune, 2004; Lenseigne and Dalle, 2006).",
      "startOffset" : 86,
      "endOffset" : 128
    }, {
      "referenceID" : 4,
      "context" : "Linguistic research in the area has focused on the characterization of corporal expressions into meaningful transcriptions (Dreuw et al., 2010; Stokoe, 2005) or common patterns across SL (Aronoff ar X iv :1 40 3.",
      "startOffset" : 123,
      "endOffset" : 157
    }, {
      "referenceID" : 18,
      "context" : "Linguistic research in the area has focused on the characterization of corporal expressions into meaningful transcriptions (Dreuw et al., 2010; Stokoe, 2005) or common patterns across SL (Aronoff ar X iv :1 40 3.",
      "startOffset" : 123,
      "endOffset" : 157
    }, {
      "referenceID" : 6,
      "context" : "Report (Filhol, 2009) describes a lexical specification to address the same problem.",
      "startOffset" : 7,
      "endOffset" : 21
    }, {
      "referenceID" : 2,
      "context" : "Finally, little to no work has been directed towards the unification of raw collected data from SL corpora with higher level descriptions (Dalle, 2006).",
      "startOffset" : 138,
      "endOffset" : 151
    }, {
      "referenceID" : 5,
      "context" : "Our sign formalization is based on the approach of (Liddell and Johnson, 1989) and (Filhol, 2008).",
      "startOffset" : 83,
      "endOffset" : 97
    }, {
      "referenceID" : 5,
      "context" : "Propositions can also be changed, or even induced, by existing written sign representation languages such as Zebedee (Filhol, 2008) or HamNoSys (Hanke, 2004), mainly for the sake of extendability.",
      "startOffset" : 117,
      "endOffset" : 131
    }, {
      "referenceID" : 11,
      "context" : "Propositions can also be changed, or even induced, by existing written sign representation languages such as Zebedee (Filhol, 2008) or HamNoSys (Hanke, 2004), mainly for the sake of extendability.",
      "startOffset" : 144,
      "endOffset" : 157
    } ],
    "year" : 2014,
    "abstractText" : "This paper explores the use of Propositional Dynamic Logic (PDL) as a suitable formal framework for describing Sign Language (SL), the language of deaf people, in the context of natural language processing. SLs are visual, complete, standalone languages which are just as expressive as oral languages. Signs in SL usually correspond to sequences of highly specific body postures interleaved with movements, which make reference to real world objects, characters or situations. Here we propose a formal representation of SL signs, that will help us with the analysis of automatically-collected hand tracking data from French Sign Language (FSL) video corpora. We further show how such a representation could help us with the design of computer aided SL verification tools, which in turn would bring us closer to the development of an automatic recognition system for these languages.",
    "creator" : "LaTeX with hyperref package"
  }
}