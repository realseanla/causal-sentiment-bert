{
  "name" : "1104.4321.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Seeking Meaning in a Space Made out of Strokes, Radicals, Characters and Compounds",
    "authors" : [ "Yannis Haralambous" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction: the Chinese Writing System",
      "text" : "The Chinese writing system uses characters (called hànzì in Chinese, kanji in Japanese, and hanja in Korean) which are logographic (i.e., a grapheme represents a word or a morpheme). KangXi, one of the most important Chinese dictionaries, includes more than 47,000 characters, and Unicode v. 6 [15] encodes almost 75,000 of them. Such quantities of symbols would require superhuman abilities to memorize if there were not an internal structure allowing the reader to infer at least an approximation of the character’s meaning. This structure is based on radicals and on strokes."
    }, {
      "heading" : "1.1 Radicals",
      "text" : "Quoting [14], “there are actually two different Chinese terms that can be translated into the word radical, making this word potentially confusing. First there are approximatively 214 unit called bùshǒu, that are used to look up a character in a dictionary. For horizontally structured characters, these are often found on the left-hand side. [...] Second, though there is the larger set of components, called bùjiàn that includes all components no matter where in the character they appear.” They later add that in a Chinese dictionary they found 541 such radicals.\nUnicode has encoded the former 214 in a dedicated character table (see Fig. 1). In the Unihan database, which is provided by the Unicode Consortium, each of the 75,000 characters encoded in Unicode is marked as being based on one of these radicals. The CHISE project [8] provides a decomposition of characters into radicals plus some calligraphic strokes.\nBesides characters that are exact copies of radicals, characters can be graphical (horizontal, vertical, enclosing) combinations of radicals (including multiple copies of the same radical as\n*The University of Aizu and Télécom Bretagne.\n2FDFKangxi Radicals2F00\nin 林 and 森, which are the double and triple copy of 木), or combinations of radicals and individual strokes, like in 犬 which is radical 大 with an additional stroke (cf. §2).\nAs explained in [13], about 80% of the most frequent characters in Chinese are semanticphonetic compounds. These characters contain at least two radicals, of which the one (usually the one on the left) bears the meaning of the character and the other (on the right) provides partial information regarding the pronunciation of the character. For example, 沐 means “take a bath” and it contains, on the left, the radical水 for ‘water’ (in its special graphical form氵, used whenever it appears on the left half of a character) and on the right a radical pronounced mù, so that the character itself is also pronounced mù. Characters which have the pronunciation of their phonetic radical are called regular. Other possible cases are those that have the same pronunciation but with a different tone (semi-regular) and those that have an entirely different pronunciation (irregular).\nAccording to TomoMorioka [9], Japanese on reading of kanjis often inherits from this (Chinese) feature of having a phonetic right component, but generally modern Japanese speakers are not conscious of this underlying structure."
    }, {
      "heading" : "1.2 Strokes",
      "text" : "Chinese characters are drawn using a specific repertoire of strokes. While there is a consensus on the very basic strokes, their combinations are considered by some authors as equally fundamental strokes and not by others. In Fig. 2 one can see the basic calligraphic strokes as encoded by Unicode and those used by the Character Description Language. The two tables agree on most of the strokes with just a few exceptions which are always combinations of the basic strokes.\nCharacter Description Language [1] is a project of theWenlin Institute aiming to graphically describe all Chinese characters through their strokes. A CDL description of a character is an XML element containing a recursive structure, the leaves of which are fundamental calligraphic strokes. To accurately place a stroke in the ideographic square, the coordinates of the bounding box of the stroke are used, as in the following example:\n<cdl char=’京’ uni=’4eac’> <comp points=’0,0 128,68’ >\n<comp char=’亠’ uni=’4ea0’ points=’0,0 128,38’ > <stroke type=’d’ points=’54,0 68,92’ /> <stroke type=’h’ points=’0,128 128,128’ /> </comp> <comp char=’口’ uni=’53e3’ points=’30,74 98,128’ >\n<comp points=’0,0 128,128’ > <stroke type=’s’ points=’0,0 0,128’ tail=’long’ /> <stroke type=’hz’ points=’0,0 128,0 128,128’ head=’cut’ tail=’long’ /> </comp> <stroke type=’h’ points=’0,128 128,128’ head=’cut’ tail=’cut’ />\n</comp> </comp> <comp points=’0,68 124,128’ >\n<stroke type=’sg’ points=’68,0 68,128 38,99’ head=’cut’ /> <stroke type=’p’ points=’35,40 0,115’ tail=’long’ /> <stroke type=’d’ points=’87,34 128,115’ />\n</comp> </cdl>\nwhere d (and d′), h (and h′), s, hz, p, and sg are the fundamental calligraphic strokes diǎn, héng, shù, héng-zhé, piě and shù-gōu from Table 2.\nThe example above is not in standard CDL syntax; in fact, whey have recursively replaced closed <comp> elements by open elements (with or without Unicode ID and glyph) containg other <comp> elements as well as <stroke> elements, which are the leaves of our CDL tree."
    }, {
      "heading" : "1.3 Going from strokes to radicals to characters",
      "text" : "With strokes we can form bùshǒu radicals, which bear meaning. But there are also “phonetic” radicals, which, supposedly bear no meaning but indicate pronunciation, and there are also other components in characters, always obtained by using graphical elements from the same set of calligraphic strokes.\nThis leads us to raise the question: “when we go from strokes to radicals, components and characters, when does meaning arise?” In other words: do specific combinations of strokes, other than bùshǒu radicals, carry meaning, or contribute to supply meaning?"
    }, {
      "heading" : "1.4 Compound words",
      "text" : "Regarding meaning, there is another semantic stratum in the Chinese writing system, namely that of compounds. A compound is a group of mostly two (but sometimes more) Chinese characters where emerges a newmeaning, different from the sequence of individual meanings. A typical example is 百姓 which a compound of 百 (a hundred) and 姓 (surname) and means “farmer.”\nJapanese WordNet [6] contains more than 40,000 compound word entries (written as two or more kanji letters).\nSo actually there are four structural levels of the Chinese writing system:\n1. stroke;\n2. radical, be it bùshǒu, phonetic, or just a graphical component;\n3. character;\n4. compound word.\nWe can compare this stratification with that of matter: strokes can be compared to elementary particles, which form atoms (radicals). Atoms connect in various ways to form molecules (characters), and molecules form macromolecular structures (compound words)."
    }, {
      "heading" : "2 Our model",
      "text" : "To study the Chinese writing system we use the following model: Let K be the set of all Chinese characters as encoded in Unicode, and G be a graph with set of vertices K. Each k ∈ K carries the following information:\n1. the main bùshǒu radical (information obtained from Unihan database);\n2. strokes of the character (information obtained from CDL);\n3. one or more meanings in Chinese or Japanese (information obtained from Japanese and Chinese WordNets).\nItems 1 and 2 are mandatory; item 3 is optional (and depends on the use or not of a given character in one of the two languages, as well on the completeness of the two WordNet databases).\nIn the remainder of this section we describe various edge schemes which can be added to G, as well as induced weights on edges and vertices."
    }, {
      "heading" : "2.1 Modeling strokes",
      "text" : "Let us first formalize the notion of stroke. In CDL every stroke has a type (it belongs to one of the 39 fundamental calligraphic strokes of Fig. 2) and a bounding box. On Fig. 3, the reader can see the decomposition of character 京 (= capital) into strokes, and the corresponding bounding boxes. It should be noted that we have numbered the boxes according to the standard order of strokes, but this information is not contained in CDL, so our model of the character must be independent of stroke order.\nWe would like to model strokes so that:\n1. frequent pattern search may be possible;\n2. order of strokes is not taken into consideration;\n3. patterns depend upon stroke type and geometric disposal, but not on size;\n4. the model should be robust with respect to small bounding box variations;\n5. the modeling algorithm should be entirely automatic, without human intervention.\nIt should be noted that in the literature one can find many Chinese character description schemes, based on two different goals:\n1. OCR (for example, [12, 7, 2], where the input data is a bitmap image and structure must be extracted from it;\n2. font generation [3, 11], where the input data is some logical and well organized database (containing a description of the character skeleton) and the output is a typographically acceptable Chinese character font.\nOur model lies between those approaches, since our input data (CDL) is much more precise than a bitmap image, but does not contain a logical description of a character skeleton.\nAs can be seen on Fig. 3, character 京 contains two strokes of type h, two d and one s, hz, sg and p. We define S(京) = {h, hz, . . .} the set of strokes of 京. To describe the geometric\ndisposal of S(京) we take horizontal and vertical projections of the stroke bounding boxes (see Fig. 4).\nLet hℓ be the projection of the left side of the bounding box of stroke h, and hr , ht, hb those of the right, top and bottom sides, resp. We have total orders for each dimension:\npℓ = hℓ < sℓ = hzℓ < h′ℓ < sr < sgℓ < pr < dℓ < sgr < dr < d ′ ℓ < h ′ r < hzr < d ′ r < hr,\ndt > ht > db = hb > hzt > st > h′t = sgt > sb = h ′ b = hzb > pt = d ′ t > pb = d ′ b > sgb.\nBy using concatenation to represent strict inequality and brackets for enclosing equal values, we obtain the following notation:\n[pℓhℓ][sℓhzℓ]h′ℓsrsgℓprdℓsgrdrd ′ ℓh ′ rhzrd ′ rhr,\ndtht[dbhb]hztst[h′tsgt][sbh ′ bhzb][ptd ′ t][pbd ′ b]sgb.\nwhich we consider the description of character 京. It is clear that this description is independent of the order and of the (absolute) size of strokes. To make it more robust, we can round up the numeric values before comparison1.\nInterpreting brackets as parts of regular expressions, we can consider all the strings in which every [x1x2 · · ·xn] is replaced by some xi. These are words of a formal language, whose alphabet is the set of xℓ, xr, xt, xb for each bounding box x. To find frequent patterns we can use common subword detection techniques.\nTo illustrate this method, let us compare characters 京 and 余, whose CDL description is:\n<cdl char=’余’ uni=’4f59’> <comp char=’\uD840\uDDA2’ uni=’201a2’ points=’0,0 128,48’ >\n<stroke type=’p’ points=’64,0 0,128’ tail=’long’ /> <stroke type=’n’ points=’64,0 128,128’ head=’cut’ />\n</comp> <comp points=’0,46 124,128’ >\n<stroke type=’h’ points=’39,0 91,0’ /> <stroke type=’h’ points=’17,41 116,41’ /> <stroke type=’sg’ points=’67,0 67,128 39,116’ head=’cut’ />\n1Nevertheless, this is a delicate issue, since although most values can be rounded without changing the global aspect of the character, in some cases a small change may bear a new reading. This is the case of stroke 1 vs. stroke 2: if stroke 1 would continue underneath stroke 2, the reading of the character could be different. One needs only compare characters 力 (= strength) and 刀 (= knife): disappearance of the small vertical extension on top of 力 because of rounding calculations leads to wrong identification of the character.\n<stroke type=’p’ points=’43,59 0,125’ tail=’long’ /> <stroke type=’d’ points=’88,59 128,116’ />\n</comp> </cdl>\nAs we can see already in the CDL code, these two characters share the same lower part (strokes sg, p, d). The formula of 余 is:\npℓp ′ ℓh ′ ℓhℓsgℓp ′ rhℓsgrprdℓhr[h ′ rdr]nr,\nptntht[hbsgt]nbpbh′th ′ b[p ′ tdt][p ′ bdb]sgb.\nLet us compare the two:\n京 余 hor. [pℓhℓ][sℓhzℓ]h′ℓsrsgℓprdℓsgrdrd′ℓh′rhzrd′rhr pℓp′ℓh′ℓhℓsgℓp′rhℓsgrprdℓhr[h′rdr]nr vert. dtht[dbhb]hztst[h′tsgt][sbh′bhzb][ptd′t][pbd′b]sgb ptntht[hbsgt]nbpbh′th′b[p′tdt][p′bdb]sgb\nBy renaming strokes p′ → p and d → d′ in 余, we see that the boundaries of p, d′ and sg keep the same relative orders both in horizontal and vertical direction:\n京 余 hor. [pℓhℓ][sℓhzℓ]h′ℓsrsgℓprdℓsgrdrd′ℓh′rhzrd′rhr p′ℓpℓh′ℓhℓsgℓprhℓsgrp′rd′ℓhr[h′rd′r]nr vert. dtht[dbhb]hztst[h′tsgt][sbh′bhzb][ptd′t][pbd′b]sgb p′tntht[hbsgt]nbp′bh′th′b[ptd′t][pbd′b]sgb\nnamely pℓ < sgℓ < pr < sgr < d′ℓ < d′r and sgt > pt = d′t > pb = d′b > sgb. We say that characters 京 and 余 share the pattern of three strokes p, d′ and sg.\nLet us formalize this approach:\n• let K be the set of all Chinese characters, T = {h, t, s, sg, p, . . .} the set of types of calligraphic strokes;\n• let k ∈ K be a Chinese character of N(k) strokes, S(k) = {s1, . . . , sN(k)} its set of strokes, τ(sj) ∈ S the type of stroke sj , (ℓ(sj), b(sj), r(sj), t(sj)) ∈ R4 the bounding box of sj (where ℓ is the horizontal projection of left side, r the hor. proj. of right side, b the vertical projection of the lower side, and t the vert. proj. of upper side);\n• then there is a total order of sets {ℓ(s1), r(s1), ℓ(s2), r(s2), . . . , ℓ(sN(k)), r(sN(k))} and {t(s1), b(s1), . . . , t(sN(k)), b(sN(k))} such that we can write\nϕ(si1) • ϕ(si2) • · · · • ϕ(siN(k)) ψ(sj1) • ψ(sj2) • · · · • ψ(sjN(k))\nwhere ϕ is either ℓ or r, ψ is either t or b, and • is either = or <;\n• in the above expression the order of terms is not relevant whenever • denotes equality=. This means that we have as many equivalent expressions as there are permutations of the terms separated by = signs;\n• we call the equivalence class σ(k) of these expressions, the signature of k."
    }, {
      "heading" : "2.2 Common strokes and frequent patterns",
      "text" : "Using the notation of previous section, we say that k, k′ ∈ K have common strokes γ1, γ2, . . . , γm ∈ S(k) and γ′1, γ′2, . . . , γ′m ∈ S(k′) whenever τ(γi) = τ(γ′i) for all i, and the gi and g′i all appear in the signatures of k and k′, in the same order.\nOur first edge-structure GS on G will be the following: two Chinese characters k and k′ are connected by an edge e(k, k′) of weightwS(k, k′) if and only if they contain exactlywS(k, k′) > 0 common strokes, as defined above. To each edge e corresponds a set of common strokes Γ(e) = {γ1, . . . , γwS(k,k′)}.\nExperiment 1. Calculate GS and find the most frequent subsets of all Γ(e).\nAmong the most frequent subsets we expect to find bùshǒu radicals, and probably also other components. In the remainder of this paper, we will investigate whether the weight wS can be correlated with semantic similarity."
    }, {
      "heading" : "2.3 Radical segmentation",
      "text" : "A different approach to Chinese character description is to decompose them into bùshǒu radicals and a few strokes, using not precise coordinates or local behavior as in the method provided above, but Ideographic Description Sequences (IDS). These use special characters⿰⿱⿲⿳ ⿴⿵⿶⿷⿸⿹⿺⿻ as operators to denote specific geometric assemblings of character pairs or triples. For example, ⿰力囗 means that character 加 can be assembled by a horizontal combination of 力 and 囗. Operators can be combined, so for example 衋 can be written as ⿳聿⿰⿱一白⿱一白⿱丿皿 (that is: ⿳(聿⿰(⿱(一白)⿱(一白))⿱(丿皿))).\nThe CHISE project [8] has provided IDS descriptions of all Unicode-encoded Chinese characters, segmenting them into bùshǒu radicals and 1,683 components (the glyphs of which are taken from various resources, such as GT [20], CDP [16, 17], CNS 11643 [18], Dai Kanwa dictionary [19], and others. For instance we find that our example from last section 京 has the (radicals-only) IDS⿱⿱亠口小, which means: first assemble 亠 and口 and then add a squeezed version of 小 underneath.\nWe can formalize that process as follows:\n• let K be the set of all Unicode Chinese characters, B the set of bùshǒu radicals and A a set of auxiliary strokes used in CHISE;\n• let IDS = {⿰,⿱,⿲,⿳,⿴,⿵,⿶,⿷,⿸,⿹,⿺,⿻} be the twelve IDS operators, defined as follows:\nX : (K ∪ A)2 → K if X ∈ {⿰,⿱,⿴,⿵,⿶,⿷,⿸,⿹,⿺,⿻}, X : (K ∪ A)3 → K if X ∈ {⿲,⿳.}\nand such that if #(k) is the number of strokes of k ∈ K and X ∈ IDS, then #(X(k, k′)) = #(k) + #(k′) (and #(X(k, k′, k′′)) = #(k) + #(k′) + #(k′′))2;\n• let G be a formal grammar with nonterminals K \\ B, terminals B ∪ A, and production rules of the form\nk → X(κ, κ′) where X ∈ {⿰,⿱,⿴,⿵,⿶,⿷,⿸,⿹,⿺,⿻}, or k → X(κ, κ′, κ′′) where X ∈ {⿲,⿳.}\nwhere κ, κ′ and κ′′ ∈ K ∪ A; 2There is an exception to this rule: in some cases a bùshǒu radical may change form when combined with other\nradicals or strokes, and its new form may have a different number of strokes than the original.\n• then every k ∈ K can be derived into a (possibly nonunique) word in (IDS∪B∪A)∗ (that is: a word consisting only of IDS operators, bùshǒu radicals and elements from A. We denote that word by R(k)."
    }, {
      "heading" : "2.4 Common components and heaviest characters",
      "text" : "If we call the elements c∗ of B ∪A components, we can use an approach similar that described in §2.2 and say that k, k′ ∈ K have common components c1, c2, . . . , cm ∈ B ∪ A, whenever c1, c2, . . . , cm ∈ R(k) ∩R(k′).\nOur second edge-structure GR on G is the following: two Chinese characters k and k′ are connected by an edge r(k, k′) of weightwR(k, k′) if and only if they contain exactlywR(k, k′) > 0 common components, as defined above. To each edge r corresponds a set of common strokes R(r) = {c1, . . . , cwR(k,k′)}.\nThe weight wR allocates one unit to each common component of k and k′:\nwR(k, k′) = ∑\nci∈R(k)∩R(k′)\n1.\nWe generalize this weight in the following fashion:\nwgR(k, k′) = ∑\nci∈R(k)∩R(k′)\nλ(ci)λ′(ci) 2\nd(ci) + d′(ci)\nwhere:\n• λ(c0) > 0 when c0 is the main semantic bùshǒu radical of k (as given in the Unihan database), and λ′(c0) > 0) when it is the main semantic radical of k′. For all other components λ(c) = λ′(c) = 1. In this way we can give more importance to the main semantic radical of each character;\n• d(c) is the depth of c in k (and d′(c) the depth of c in k′), defined as follows: it is the minimum number of productions needed to obtain c from k (resp. from k′). For example, in 抭 → ⿰扌⿱宀儿, 儿 is of depth 2, while in 圥 → ⿱土儿 it is of depth 1. As the size of radicals is halved (and sometimes even divided by three) whenever an IDS operator is applied, depth corresponds not only to length of the minimal path in the derivation tree, but also to the inverse of size. This refinement of the weight allows us to prioritize large components3.\nIf we take λ ≡ λ′ ≡ d ≡ d′ ≡ 1 then wgR ≡ wR.\nExperiment 2. Calculate GR and find the heaviest cliques. If the weight of a vertex is the sum of the weights of the edges adjacent to it, find the heaviest vertices.\n3A possible variant of this weight would be to consider not the average of the weights of components in the two characters, but to prioritize cases where the components are of the same size (even if this size is small). In that case, the formula would be:\nwgR(k, k ′) = ∑ ci∈R(k)∩R(k′) λ(ci)λ ′(ci)\n1\n|d(ci) − d′(ci)| + 1 ."
    }, {
      "heading" : "2.5 Components vs. Strokes",
      "text" : "Experiment 3. If (GS , wS) is the graph G with edges and weight derived from strokes and (GR, wgR) that derived from components with generalized weight, measure the similarity of the two graphs.\nQuestions 1. Which of the two provides better disambiguation of Chinese characters? If we cluster them, do we obtain the same clusters? Does the additional complexity of GS provide useful information, not available in GR?"
    }, {
      "heading" : "2.6 Characters, Compounds and Meaning",
      "text" : "While English (and other Western) WordNet provides sets of synonyms (called synsets) for words and collocations, the situation is a bit more complicated for sinographic languages. In [5], Hsieh & Huang introduce HanziNet, an ontological character net, in which they align Chinese characters which “share a given putatively primitive meaning extracted from traditional philological resources.” They propose a new notion: a conset is a “group of Chinese characters similar in concept and each of which shares similar conceptual information with the other characters in the same conset.”\nThe difference between HanziNet and Chinese WordNet is that the former provides only single Chinese characters as conset of a Chinese character, while the latter provides both single characters and compound ones as synset of a given monocharacter or multicharacter word. For example, for the same example character 京, Chinese WordNet supplies the following five senses:\n1. 京1:「首都」 (capital)\n2. 京2:「北京」,「北平」,「燕京」,「平」 (Beijing)\n3. 京3:「京都」 (Kyoto)\n4. 京4: 兆的十倍 (ten trillion)\n5. 京5: (proper noun, name),\nwhile in HanziNet the same character gives: [to be completed once we obtain HanziNet data from Academia Sinica] Our next edge-structure GM on G will be the following: two Chinese characters k and k′ are connected by an edge m(k, k′) if and only if they share a common meaning in Chinese or Japanese WordNet or in the Unihan database, and by an edge H(k, k′) if and only if k is an hyperonym of k′ in one of these resources.\nExperiment 4. Calculate GM and evaluate the similarity between GM , and GS and GR. For how many edges of these two graphs do we have corresponding edges in GM?\nComparing the stroke, radical, and meaning graphs allows us to answer the fundamental question of this article: “Is there a correlation between sharing strokes/radicals and sharing meaning?”\nThe two edge types m, H are to be considered separately: in the first case we have pure synonyms, while in the second case we have a hyperonymy/hyponymy relation. If a stroke or radical edge is attested for the same pair of characters, verify if it goes in the opposite sense (k hyperonymous of k′ ⇒ #S(k) < #S(k′) and/or #R(k) < #R(k′). These studies are to be conducted separately for Japanese and Chinese.\nOnce the data are loaded in the various graphs, we will apply (large) graph mining methods to obtain relations between strokes, radicals, characters and meaning."
    }, {
      "heading" : "Acknowledgments",
      "text" : "The author would like to thank: (1) the University of Aizu and in particular Prof. Michael Cohen for inviting him for a three-month stay in his laboratory, and (2) Richard Cook and Tom Bishop from the Wenlin Institute for the tremendous work they have done in describing Chinese characters and for allowing him to use the XML data of CDL in this paper. Without their help this paper would not be possible."
    } ],
    "references" : [ {
      "title" : "Wenlin CDL: Character Description Language, Multi- Lingual Computing",
      "author" : [ "Bishop", "Tom", "Cook", "Richard" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2007
    }, {
      "title" : "Chinese character recognition: history, status and prospects",
      "author" : [ "Dai", "Ru-Wei", "Liu", "Cheng-Lin", "Xiao", "Bai-Hua" ],
      "venue" : "Front. Comput. Sci. China",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2007
    }, {
      "title" : "Coordinate-independent font description using Kanji as an example",
      "author" : [ "Duerst", "Martin" ],
      "venue" : "Electronic Publishing",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 1993
    }, {
      "title" : "When Conset meets Synset: A Preliminary Survey of an Ontological Lexical Resource based on Chinese Characters",
      "author" : [ "Hsieh", "Shu-Kai", "Huang", "Chu-Ren" ],
      "venue" : "Proc. of the COLING/ACL",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2006
    }, {
      "title" : "Development of the Japanese WordNet",
      "author" : [ "Isahara", "Hitoshi", "Bond", "Francis", "Uchimoto", "Kiyotaka", "Utiyama", "Masao", "Kanzaki", "Kyoko" ],
      "venue" : "Proc. of the Sixth International Language Resources and Evaluation",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2008
    }, {
      "title" : "Statistical Character Structure Modeling and its Application to Handwritten Chinese Character Recognition",
      "author" : [ "Kim", "In-Jung", "Jin-Hyung" ],
      "venue" : "IEEE Trans. on Pattern Analysis and Machine Intelligence,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2003
    }, {
      "title" : "CHISE: Character Processing Based on Character Ontology",
      "author" : [ "Morioka", "Tomohiko" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2008
    }, {
      "title" : "Surface of Essence: Beyond the Coded Character Set Model, in 書体・組版ワークショップ 資料集",
      "author" : [ "Moro", "Shigeki" ],
      "venue" : "(Proc. of the Glyph and Typesetting Workshop in Kyōtō),",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2003
    }, {
      "title" : "SCML: A Structural Representation for Chinese Characters, Dartmouth College Technical Report TR2007-592",
      "author" : [ "Peebles", "Daniel G" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2007
    }, {
      "title" : "Substructure Shape Analysis for Kanji Character Recognition",
      "author" : [ "Rocha", "Jairo", "Fujisawa", "Hiromichi" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1996
    }, {
      "title" : "Learning to Read Chinese: The Development of Metalinguistic Awareness, in Reading Chinese Script",
      "author" : [ "Shu", "Hua", "Anderson", "Richard C" ],
      "venue" : "A Cognitive Analysis, Lawrence Erlbaum Associates Publishers,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1999
    }, {
      "title" : "Submorphemic Processing in Reading Chinese, Journal of Experimental Psychology: Learning, Memory and Cognition",
      "author" : [ "Taft", "Marcus", "Zhu", "Xiao-Ping" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1997
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "1 Radicals Quoting [14], “there are actually two different Chinese terms that can be translated into the word radical, making this word potentially confusing.",
      "startOffset" : 19,
      "endOffset" : 23
    }, {
      "referenceID" : 6,
      "context" : "The CHISE project [8] provides a decomposition of characters into radicals plus some calligraphic strokes.",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 10,
      "context" : "As explained in [13], about 80% of the most frequent characters in Chinese are semanticphonetic compounds.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 0,
      "context" : "Character Description Language [1] is a project of theWenlin Institute aiming to graphically describe all Chinese characters through their strokes.",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 4,
      "context" : "” Japanese WordNet [6] contains more than 40,000 compound word entries (written as two or more kanji letters).",
      "startOffset" : 19,
      "endOffset" : 22
    }, {
      "referenceID" : 9,
      "context" : "OCR (for example, [12, 7, 2], where the input data is a bitmap image and structure must be extracted from it; 2.",
      "startOffset" : 18,
      "endOffset" : 28
    }, {
      "referenceID" : 5,
      "context" : "OCR (for example, [12, 7, 2], where the input data is a bitmap image and structure must be extracted from it; 2.",
      "startOffset" : 18,
      "endOffset" : 28
    }, {
      "referenceID" : 1,
      "context" : "OCR (for example, [12, 7, 2], where the input data is a bitmap image and structure must be extracted from it; 2.",
      "startOffset" : 18,
      "endOffset" : 28
    }, {
      "referenceID" : 2,
      "context" : "font generation [3, 11], where the input data is some logical and well organized database (containing a description of the character skeleton) and the output is a typographically acceptable Chinese character font.",
      "startOffset" : 16,
      "endOffset" : 23
    }, {
      "referenceID" : 8,
      "context" : "font generation [3, 11], where the input data is some logical and well organized database (containing a description of the character skeleton) and the output is a typographically acceptable Chinese character font.",
      "startOffset" : 16,
      "endOffset" : 23
    }, {
      "referenceID" : 6,
      "context" : "The CHISE project [8] has provided IDS descriptions of all Unicode-encoded Chinese characters, segmenting them into bùshǒu radicals and 1,683 components (the glyphs of which are taken from various resources, such as GT [20], CDP [16, 17], CNS 11643 [18], Dai Kanwa dictionary [19], and others.",
      "startOffset" : 18,
      "endOffset" : 21
    } ],
    "year" : 2011,
    "abstractText" : "Chinese characters can be compared to a molecular structure: a character is analogous to a molecule, radicals are like atoms, calligraphic strokes correspond to elementary particles, and when characters form compounds, they are like molecular structures. In chemistry the conjunction of all of these structural levels produces what we perceive as matter. In language, the conjunction of strokes, radicals, characters, and compounds produces meaning. But when does meaning arise? We all know that radicals are, in some sense, the basic semantic components of Chinese script, but what about strokes? Considering the fact that many characters are made by adding individual strokes to (combinations of) radicals, we can legitimately ask the question whether strokes carry meaning, or not. In this talk I will present my project of extending traditional NLP techniques to radicals and strokes, aiming to obtain a deeper understanding of the way ideographic languages model the world.",
    "creator" : " XeTeX output 2011.03.01:1359"
  }
}