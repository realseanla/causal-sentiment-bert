{
  "name" : "1302.5645.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "D’ingénieur en informatique",
    "authors" : [ "Houari Boumediene", "Djallel Bouneffouf" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Université des Sciences et Technologie Houari Boumediene\nTHESE\nSpécialité : Informatique\nOption : Recherche\nPrésentée pour obtenir le titre :\nD’ingénieur en informatique\nPar\nDjallel Bouneffouf\nRapport du stage effectué au laboratoire de recherche en\nInformatique de Toulouse (IRIT)\nRôle de l’inférence temporelle dans la\nreconnaissance de l’inférence textuelle\nSoutenu le 18 juin 2008 devant le jury composé de :\nMadame A.Aissani Présidente\nMonsieur H.Azzoune Examinateur\nMadame F.Khellaf Directrice de thèse\nRésumé du projet\nCe projet s‟insère dans le cadre du traitement du langage nature. Il a pour objectif le développement d‟un système de reconnaissance d‟inférence textuelle, nommé TIMINF. Ce type de système permet de détecter, étant donné deux portions de textes, si un des textes est sémantiquement déduit de l‟autre. Nous nous sommes focalisés sur l‟apport de l‟inférence temporelle dans ce type de système. Pour cela, nous avons constitué et analysé un corpus construit à partir de questions collectées à travers le web. Cette étude, nous a permis de classer différents types d‟inférences temporelles et de concevoir l‟architecture informatique de TIMINF qui a pour but l‟intégration d‟un module d‟inférence temporelle dans un système de détection d‟inférence textuelle. Nous proposons, également d‟évaluer les performances des sorties du système TIMINF sur un corpus de test avec la même stratégie adopté dans le challenge RTE.\nMot clef : Traitement du langage naturel, reconnaissance d‟inférence textuelle, inférence temporelle, système question réponse, Recherche d‟information.\nProject summary\nThis project is a part of nature language processing and its aims to develop a system of recognition inference text-appointed TIMINF. This type of system can detect, given two portions of text, if a text is semantically deducted from the other. We focused on making the inference time in this type of system. For that we have built and analyzed a body built from questions collected through the web. This study has enabled us to classify different types of times inferences and for designing the architecture of TIMINF which seeks to integrate a module inference time in a detection system inference text. We also assess the performance of sorties TIMINF system on a test corpus with the same strategy adopted in the challenge RTE.\nKeyword: Natural language processing, recognizing of textual entailment, temporal inference, question answering system, Information Retrieval.\nTable des matières\nIntroduction générale .................................................................................................................. 1\nChapitre 1 : LE TALN et LE RTE\n1) Introduction ............................................................................................................................ 6\n2) Brève historique du traitement automatique du langage naturel ........................................... 6\n3) Les niveaux de traitement ...................................................................................................... 7\n3.1) Le niveau lexical ............................................................................................................. 7 3.2) Le niveau syntaxique ...................................................................................................... 8 3.3) Le niveau sémantique...................................................................................................... 9 3.4) Le niveau pragmatique .................................................................................................... 9\n4) Les difficultés du TALN : ambiguïté ................................................................................... 10\n4.1) Ambiguïté des graphèmes (lettres) ............................................................................... 10 4.2) Ambiguïté dans les propriétés grammaticales et sémantiques ...................................... 10 4.3) Ambiguïté de la fonction grammaticale des groupes de mots ...................................... 10 4.4) Ambiguïté de la portée des quantificateurs, des conjonctions et des prépositions ....... 11 4.5) Ambiguïté sur l’interprétation à donner en contexte à un énoncé ................................ 11\n5) La reconnaissance de l’inférence textuelle (RTE) ............................................................... 11\n5.1) Introduction .............................................................................................................. 11 5.2) Les applications du RTE .......................................................................................... 12\n5.2.1) La recherche d’information .................................................................................... 12 5.2.2) L’extraction d’information ..................................................................................... 13 5.2.3) Le système question- réponse ................................................................................ 14 5.2.4) La traduction automatique ..................................................................................... 14 5.2.4) Le résumé automatique .......................................................................................... 14 5.2.5) L’acquisition des Paraphrases (AP) ........................................................................... 14 5.3) Le challenge “PASCAL Recognizing of Textual Entailment” ................................ 15\n5.3.1) La préparation du corpus ....................................................................................... 15 5.3.2) Les directives de jugements ................................................................................... 16 5.3.3) Les mesures d’évaluation ...............................................................................................\n5.4) L’analyse des principales méthodes utilisées ................................................................... 17\n5.4.1) Les prétraitements ...................................................................................................... 17\n5.4.1.1) Le Niveau lexical ............................................................................................. 17\n5.4.1.2) Le niveau syntaxique .......................................................................................... 18 5.4.1.3) Le niveau sémantique ......................................................................................... 19 5.4.2) Les différents niveaux d’inférence textuelle .............................................................. 20\n5.4.2.1) L’inférence au niveau lexical ........................................................................... 20\n5.4.2.2) L’inférence au niveau lexico syntaxique ............................................................ 23 5.4.2.3) L’inférence sémantique (logique) ....................................................................... 24\n5.4.3) Les ressources utilisées .............................................................................................. 24\n5.4.3.1) Le WordNet ........................................................................................................ 24\n5.4.3.2) Le FrameNet ................................................................................................... 25\n5.4.3.3) Le Cyc ................................................................................................................ 25 5.5.4) Quelques exemples d’inférence utilisés par des groupes de recherches ................. 26\n5.5.4.1) La reconnaissance de l’inférence textuelle basée sur l’analyse de dépendance\net WordNet (Université nationale de l’éducation a distance de Madrid) ...................... 27\n5.5.4.2) COGEX (université du Texas, USA) ...................................................................... 29 5.5.5) Conclusion ................................................................................................................. 31\n5.6) Conclusion ........................................................................................................................ 32\nChapitre 2: Le temps dans la langue\n1) Introduction .......................................................................................................................... 34\n2) la structure de points ........................................................................................................... 34\n3) la structure d’intervalles ...................................................................................................... 35\n4) la structure d’événements ................................................................................................... 35"
    }, {
      "heading" : "5) La théorie d’Allen ................................................................................................................ 36",
      "text" : "5) le temps dans la langue ....................................................................................................... 37\n5.1) Le modèle de Reichenbach ........................................................................................... 38 5.2) Les adverbiaux temporels ............................................................................................. 39\n6) L’inférence temporelle ......................................................................................................... 39\n6.1) Le travail du groupe Human Language Technology Research Institut (HLTRI) sur l’inférence temporelle ......................................................................................................... 40 6.2) Synthése ........................................................................................................................ 41\n7) Conclusion ........................................................................................................................... 41\nChapitre 3 : L'élaboration du corpus\n1) Introduction .......................................................................................................................... 44\n2) L’élaboration du corpus ....................................................................................................... 44\n3) Classification de l’inférence temporelle .............................................................................. 47\n3.1) Les inférences entre expressions temporelles ............................................................... 47\n3.1.1) Les inférences entre dates ...................................................................................... 48 3.1.2) les inférences entre adverbiaux temporels ............................................................. 49 3.1.3) Les inférences entre dates et adverbiaux temporels ............................................... 49 3.3.2) Les inférences entre évènements............................................................................ 49\n3.3.2.1) Les relations entre évènements temporels ....................................................... 50\n3.3.2.2) Les inférences lexico sémantiques ................................................................... 51\n3.3.4) Les inférences entre évènements et expressions temporelles ............................... 51\n3) Le bilan de l’étude du corpus ............................................................................................... 52\n4) Conclusion ........................................................................................................................... 53\nChapitre 4 : La présentation du système TIMINF\n1) Introduction .......................................................................................................................... 55\n2) Architecture informatique de TIMINF ................................................................................ 55\n2.1) Le prétraitement ............................................................................................................ 57\n2.1.1) Le projet TARSQI .................................................................................................. 57\n2.1.1.1) Treetagger ........................................................................................................ 58\n2.1.1.2) GUTime ........................................................................................................... 59\n2.1.1.3) Evita ................................................................................................................. 60\n2.1.1.4) GutenLink ........................................................................................................ 61\n2.1.1.5) Slinket .............................................................................................................. 63\n2.1.1.6) SputLink ........................................................................................................... 64\n2.1.1.7) L’utilisation de TARSQI .................................................................................. 64\n2.1.1.8) L’intégration de TARSQI au système TIMINF ............................................... 66\n2.1.2) L’analyse syntaxique.............................................................................................. 66\n2.1.2.1) La présentation de link grammar parser ........................................................... 66\n2.1.2.2) L’intégration du link parser à notre système .................................................... 67\n2.2) Les test d’inférence textuelle ........................................................................................ 68\n2.2.1) Les testes d’inférences entre événements et entre sujets ....................................... 68\n2.2.1.1) L’inférence entre sujets ................................................................................... 69\n2.2.1.2) L’inférence entre évènements ......................................................................... 70\n2.2.2) Le balisage des expressions temporelles non détectées par TARSQI ................... 71 2.3) Les Ressources linguistiques ........................................................................................ 72\n2.3.1) Les ressources externes ......................................................................................... 72 2.3.1) Les ressources internes ......................................................................................... 73 2.4) Les tests d’inférences temporelles ................................................................................ 73\n2.4.1) Les règles d’inférences ........................................................................................ 73\n2.4.1.1) Les définitions des fonctions utilisés dans l’abstraction des règles d’inférence\n....................................................................................................................................... 74\n4.1.1.2) Les règles du groupe 1 ..................................................................................... 75\n4.1.1.3) La règle du groupe 2 ........................................................................................ 81\n4.2.2) Le superviseur ........................................................................................................ 82 4.4) Conclusion .................................................................................................................... 84\nChapitre 5: La mise en œuvre et L'évaluation du système TIMEINF\n1) Introduction .......................................................................................................................... 86\n2) environnement et outils utilisés ........................................................................................... 86\n2.1) Python ........................................................................................................................... 86 2.2) TARSQI ........................................................................................................................ 87\n2.2.1) Installation .............................................................................................................. 87 2.2.2) Utilisation de la boite à outils TARSQI ................................................................. 88 2.2.3) Utilisation de la boite à outils d’interface graphique ............................................. 88 2.3) Link Parseur .................................................................................................................. 89 2.4) PyWordNet ................................................................................................................... 90\n2.4.1) Installation .............................................................................................................. 90 2.4.2) Utilisation de PyWordNet dans notre système ...................................................... 90\n3) Exemple d’exécution du TIMINF sur un exemple du corpus .............................................. 92\n3.1) TARSQI ........................................................................................................................ 92 3.2) Analyse syntaxique ....................................................................................................... 93 3.3) Inférence entre sujets et événements ............................................................................. 94 3.4) Balisages des expressions temporelles non détectées par TARSQI ............................. 94 3.5) Superviseur ................................................................................................................... 94\n4) L’évaluation de notre système ............................................................................................. 95\n4.1) l’évaluation du système sur le corpus de développement ............................................. 95 4.2) Evaluation du système avec le corpus de test ............................................................... 96 4.4) Analyse des erreurs causées par le système. ................................................................. 96\n5) Conclusion ........................................................................................................................... 97\nConclusion générale et perspectives......................................................................................... 98\nReferences .............................................................................................................................. 102\nAnnexe ................................................................................................................................... 103\nTable des illustrations\nLes figures\nFigure 2.1 : Exemple de moteur de recherche a base de mot clé ....................................................... 12\nFigure 1.2 : Exemple où le moteur de recherche à base de mot clé ne marche pas ........................... 13\nFigure 1.3 : Exemple du corpus annoté ............................................................................................. 16\nFigure 1.4 : Sortie du TreeTagger ...................................................................................................... 18\nFigure 1.5 : Exemple d‟annotation syntaxique .................................................................................. 19\nFigure 1.6 : Exemple de structure prédicat argument ........................................................................ 20\nFigure 1.7 : L‟architecture du système .............................................................................................. 27\nFigure 1.8: Exemple de recouvrement entre arbre de dépendance .................................................... 28\nFigure 1.9: Architecture du système UNED ...................................................................................... 29\nFigure 1.10 : Architecture du système ............................................................................................... 30\nFigure 2.1: Représentation des relations d‟Allen ............................................................................... 37\nFigure 2.2: règles d‟inférence temporelle .......................................................................................... 40\nFigure 2.3: application des règles d‟inférences sur un exemple du corpus RTE ............................... 40\nFigure 3.1 : représente la réponse du système AnswerBus ................................................................ 45\nFigure 3.2 : Exemple du corpus annoté ............................................................................................. 46\nFigure 3.3 : Pourcentage de paires par types d‟inférences ................................................................. 47\nFigure 3.4 : Nombre de paires par types d‟inférences ....................................................................... 50\nFigure 3.5 : Nombre de paires par types d‟inférences ....................................................................... 51\nFigure 3.6 : Pourcentage de paires par types d‟inférences ................................................................. 53\nFigure 4.1 : architecture du système TIMINF ................................................................................... 56\nFigure 4.2 : Architecture du module TARSQI ................................................................................... 57\nFigure 4.3 : Sortie en format tableau de TreeTagger ......................................................................... 58\nFigure 4.4 : Sortie en format XML de TreeTagger ............................................................................ 59\nFigure 4.5: Sortie du module GUTime .............................................................................................. 60\nFigure 4.6 : Sortie du module Evita ................................................................................................... 61\nFigure 4.7 : Sortie du module GutenLink .......................................................................................... 62\nFigure 4.8 : Sortie du module SLINKET ........................................................................................... 63\nFigure 4.10 : Entrée format simple-xml ………………………………………………………………………………...64\nFigure 4.9: Inférence effectué par le module SputLINK ................................................................... 65\nFigure 4.11 : Sortie du module GutenLink ........................................................................................ 66\nFigure 4.12 : L‟analyse syntaxique .................................................................................................... 66\nFigure 4.13 : Sortie du module Link Grammar Parser....................................................................... 67\nFigure 4.14 : L‟inférence entre évènements et sujets ........................................................................ 68\nFigure 4.15 : Exemple d‟inférence entre sujets ................................................................................. 69\nFigure 4.16 : Exemple d‟inférence entre évènements ........................................................................ 70\nFigure 4.17 : exemple de balisages d‟expressions temporelles ......................................................... 71\nFigure 4.18 : Ressources linguistiques ............................................................................................... 72\nFigure 4.19 : Règles d‟inférences ...................................................................................................... 73\nFigure 4.20 : Règle R1 d‟inférence temporelle .................................................................................. 76\nFigure 4.21 : Règle R2 d‟inférence temporelle .................................................................................. 77\nFigure 4.22 : Règle R3 d‟inférence temporelle .................................................................................. 78\nFigure 4.23: Règle R4 d‟inférence temporelle ................................................................................... 79\nFigure 4.24 : Règle R5 d‟inférence temporelle .................................................................................. 80\nFigure 4.25 : Règle R6 d‟inférence temporelle .................................................................................. 82\nFigure 4.26 : Architecture du superviseur .......................................................................................... 83\nFigure 5.1 : Shell python .................................................................................................................... 86\nFigure 5.2 : Comment exécuter un programme ................................................................................. 87\nFigure 5.3 : Capture d‟écran de l‟interface TARSQI ......................................................................... 89\nFigure 5.4 : Capture d‟écran de l‟interface de link parser ................................................................. 90\nFigure 5.5 : La fonction d‟interfaçage avec WordNet ....................................................................... 91\nFigure 5.6 : Entré simple-xml ............................................................................................................ 92\nFigure 5.7 : Sortie TARSQI ............................................................................................................... 93\nFigure 5.8: Sortie de l‟analyseur syntaxique ...................................................................................... 93\nFigure 5.9 : Inférence entre sujets et évènements .............................................................................. 94\nFigure 5.10: Balisages des expressions temporelles .......................................................................... 94\nIntroduction générale\nNous regroupons sous le vocable de traitement automatique du langage naturel (TALN) l‟ensemble des recherches et développements visant à modéliser et à reproduire, à l‟aide de machines, la capacité humaine à produire et à comprendre des énoncés linguistiques dans le but de communication (Yvon, 2007).\nLes deux sources principales de motivation à l‟étude du TALN sont d‟une part; la volonté de modéliser une compétence fascinante (le langage), afin de tester des hypothèses sur les mécanismes de la communication humaine, ou plus généralement sur la nature de la cognition humaine et d‟autre part le besoin de disposer d‟applications capables de traiter efficacement les morceaux d‟informations « naturelles» (documents écrits ou sonores) aujourd‟hui disponibles sous forme électronique (mails, pages HTML, documents hypermédias, etc).\nLe TALN est un champ de savoir et de techniques élaborés autour de problématiques diverses. Les concepts et techniques qu‟il utilise se trouvent à la croisée de multiples champs disciplinaires : l‟Intelligence Artificielle «traditionnelle», l‟informatique théorique, la logique, la linguistique, mais aussi les neurosciences, les statistiques, etc.\nUne des principales problématiques du TALN est que dans une langue en général, nous pouvons toujours exprimer la même idée avec plusieurs phrases différentes, ce qui pose un vrai problème d‟ambiguïté, que les chercheurs, dans tous les domaines du traitement du langage, veulent résoudre.\nExtraction d‟information (EI), question réponse (QR), recherche d‟information (RI), résumé automatique et traduction automatique sont des exemples d‟applications qui ont besoin d‟évaluer la relation sémantique entre des segments de textes, c‟est-à-dire, si un segment de texte peut être sémantiquement déduit d‟un autre.\nAu début du traitement du langage naturel, le problème d‟ambiguïté était dispersé dans ses différentes applications et chaque groupe de recherche traite le problème à sa façon, mais cela a produit une grande perte de temps. Pour cela, les chercheurs ont choisi d‟unifier leurs forces pour créer un domaine qui a pour but de centraliser le problème d‟ambiguïté et de proposer des méthodes de traitement du langage au niveau lexical, syntaxique et sémantique indépendamment d'une application donnée. La reconnaissance de l‟inférence textuelle (RTE) est née.\nAinsi: on dira qu'un texte, noté T (texte), infère un texte, noté H (hypothése), si et seulement si H peut être inféré à partir de T (Dagan et al, 05).\nExemple d'inférence dite TRUE T: Since its formation in 1948, Israel was involved in many wars with neighboring Arab countries. H: Israel was established in 1948.\nExemple d'inférence dite FALSE T: Since its formation in 1948, Israel was involved in many wars with neighboring Arab countries. H: Israel was established before 1948.\nLe Pascal RTE est un concoure qui à débuter en 2005 et son objectif et de comparer les réalisations des différents groupes de recherches travaillant sur le RTE. Il y a eu trois compétitions Pascal RTE (2005, 2006 et 2007) et dans ces trois compétitions, les principales méthodes utilisées sont basées sur:\n- le word matching (contage de mot) : l‟inférence entre le texte T et H est vrai si le nombre de mot similaire entre les deux segments de textes est élevé.\nExemple: T: Amine eats chocolates in the kitchen. H : Amine eats chocolates.\nDans l‟exemple l‟inférence est considéré comme vrai par l‟algorithme puisqu‟il a 100 % des mots du texte H qui existe dans le texte T. nous appelons cette méthode le comptage de mots ou en anglais « le word matching ».\n- l'inférence lexicale : T infère H si les mots contenus dans la phrase H peuvent être déduits de T après des transformations lexicales.\n- les relations de dépendances syntaxiques (telles que les relations entre un verbe et ses arguments). Un matching entre les graphes de dépendances de T et H est alors effectué.\n- l'inférence logique: transformer T et H en une représentation logique (souvent du premier ordre) puis vérifier si H est une déduction logique de T.\nPour le moment, les aspects temporels ne sont pas du tout abordés (reconnaissances des dates, expressions temporelles, événements, ordonnancement d'événements dans le temps, etc.) dans le RTE. Pour cela, notre projet, nommé TIMINF, pour « Time-inference », vise à modéliser, à développer et à évaluer l‟apport de l‟inférence temporelle dans le domaine de la reconnaissance de l‟inférence textuelle (RTE).\nMotivation\nNotre approche est motivée par les constatations suivantes : La plupart des systèmes de détection d‟inférence textuelle évalués au Pascal RTE, se sont focalisés sur les principales inférences (lexical, syntaxique et logique) et pour le moment, les aspects temporels ne sont pas du tout abordés. Aussi les groupes travaillant sur les inférences temporells ne se basent que sur l‟amélioration des détéctions des relations temporelles existentes entre évenements et expressions temporelles et n‟essayent en aucun cas d‟intégrer leurs travaux a un systéme d‟inférence textuelle.\nMéthodologie de travail Pour parvenir à la réalisation du système d‟inférence textuelle intégrant l‟inférence temporelle. Nous avons en premier lieu étudié les différents méthodes existantes dans la reconnaissance de l‟inférence textuelle pour cela nous nous sommes basés sur les trois\nchallenges qui se sont déroulés pour avoir un état des lieux sur les différentes méthodes existant.\nEnsuite nous avons étudié la logique temporelle et son application sur le langage naturel, pour pouvoir avoir une idée de l‟intégration du temps dans la langue. Apres avoir étudié les différentes inférences textuelles et temporelles nous avons entamé l‟étude des relations temporelles qui peuvent exister entre deux ségments de textes à travers un corpus que nous avons élaboré. La suite logique à notre projet est de concevoir notre systéme d‟inférnece textuelle intégrant les différentes régles d‟inférences temporelles découvertes au paravant.\nNous terminons notre travail avec l‟évaluation de notre système et l‟étude des différentes failles existentes en proposant quelques perspectives de recherche future.\nPlan du mémoire\nLe plan que nous adoptons dans ce manuscrit reflète les différentes évolutions de notre projet. Ce document comporte cinq chapitres. Après avoir étudié les différentes approches adoptées pour traiter l‟inférence textuelle dans le premier chapitre, le deuxième chapitre présente le temps dans la langue et aussi une étude sur l‟inférence temporelle.\nDans le chapitre trois nous avons entrepris une démarche expérimentale à base de corpus afin de dégager différentes classes d‟inférence temporelle. A partir de cette analyse, la seconde étape a été de concevoir l‟architecture d‟un système de reconnaissance d‟inférence textuelle présenté dans le chapitre 4.\nEnfin une fois le système conçu, nous nous sommes intéressés dans le dernier chapitre à l‟évaluation des sorties de notre système en le confrontant à un corpus de test adapté. Nous résumons, en conclusion de ce manuscrit, les différentes contributions de ce projet et nous donnons plusieurs pistes de recherches futures.\nPartie 1\nL'état de l‟art\nRésumé\nAvant d‟entamer la conception de notre système d‟inférence, nous avons besoin d‟explorer les deux notions d‟inférences textuelles et temporelles. Pour cela la partie état de l‟art de notre mémoire est constituée de deux chapitres contenants successivement un large tour d‟horizon sur l‟inférence textuelle et ses différents niveaux de traitements. Le deuxième chapitre va contenir l‟étude de la logique temporelle sous ses différentes facettes et les différentes techniques d‟inférences temporelles existantes à nos jours.\n-Chapitre 1-\nLE TALN ET LE RTE\nChapitre 1"
    }, {
      "heading" : "Le TALN et Le RTE",
      "text" : ""
    }, {
      "heading" : "1) Introduction",
      "text" : "Dans ce chapitre, nous commencerons par clarifier quelques concepts linguistiques, en étudiant les différents niveaux de représentation et de traitement des énoncés linguistiques. La section suivante est consacrée à l‟étude de l‟inférence textuelle où nous présentons les différentes applications du RTE et les principaux niveaux d‟inférences textuelles nous détaillons les étapes de développement du challenge Pascale RTE qui a été mis en œuvre pour évaluer les avances des groupes de recherches dans ce domaine. Nous terminons ce chapitre par la présentation de quelques méthodes d‟inférences utilisées par des groupes de recherches évaluées dans le challenge Pascal RTE."
    }, {
      "heading" : "2) Brève historique du traitement automatique du",
      "text" : "langage naturel\nHistoriquement, les premiers travaux importants dans le domaine du TALN ont porté sur la traduction automatique, avec, dès 1954, la mise au point du premier traducteur automatique (très rudimentaire). Quelques phrases russes, sélectionnées à l‟avance, furent traduites automatiquement en anglais.\nDepuis 1954, de lourds financements ont été investis et de nombreuses recherches ont été lancées. Les principaux travaux présentés concernent alors la fabrication et la manipulation de dictionnaires électroniques, car les techniques de traduction consistent essentiellement à traduire mot à mot, avec ensuite un éventuel réarrangement de l‟ordre des mots.\nCette conception simpliste de la traduction a conduit à l‟exemple célèbre suivant : la phrase The spirit is willing but the flesh is weak (l‟esprit est fort mais la chair est faible) fut traduite en russe puis retraduite en anglais. Cela donna quelque chose comme : The vodka is strong but the meat is rotten (la vodka est forte mais la viande est pourrie) !\nCe qui ressort de cet exemple, c‟est que de nombreuses connaissances contextuelles (i.e. portant sur la situation décrite) et encyclopédiques (i.e. portant sur le monde en général) sont nécessaires pour trouver la traduction correcte d‟un mot (par exemple ici spirit, qui, suivant les contextes peut se traduire comme esprit ou comme alcool).\nPosant comme conjecture que tout aspect de l‟intelligence humaine peut être décrit de façon suffisamment précise pour qu‟une machine le simule, les figures les plus marquantes de l‟époque (John Mc Carthy, Marvin Minsky, Allan Newell, Herbert Simon) y discutent des\npossibilités de créer des programmes d‟ordinateurs qui se comportent intelligemment, et en particulier qui soient capables d‟utiliser le langage.\nAujourd‟hui, le champ du traitement du langage naturel est un champ de recherche très actif. De nombreuses applications industrielles (traduction automatique, recherche documentaire, interfaces en langage naturel), qui commencent à atteindre le grand public, sont là pour témoigner de l‟importance des avancées accomplies mais également des progrès qu‟il reste encore à accomplir."
    }, {
      "heading" : "3) Les niveaux de traitement",
      "text" : "Nous introduisons dans cette section les différents niveaux de traitements nécessaires pour parvenir à une compréhension complète d‟un énoncé en langage naturel. Ces niveaux correspondent à des modules qu‟il faudrait développer et faire coopérer dans le cadre d‟une application complète de traitement de la langue.\nNous considérons à titre d‟exemple l‟énoncé suivant :\n(1) Le président des antialcooliques mangeait une pomme avec un couteau,\nNous envisageons les traitements successifs qu‟il convient d‟appliquer à cet énoncé pour parvenir automatiquement à sa compréhension la plus complète. Il nous faudra successivement : – identifier les composants lexicaux, et leurs propriétés : c‟est l‟étape de traitement lexical ; – identifier des constituants (groupe) de plus haut niveau, et les relations (de dominance) qu‟ils entretiennent entre eux : c‟est l‟étape de traitement syntaxique ; – construire une représentation du sens de cet énoncé, en associant à chaque concept évoqué un objet ou une action dans un monde de référence (réel ou imaginaire) : c‟est l‟étape de traitement sémantique. – identifier enfin la fonction de l‟énoncé dans le contexte particulier de la situation dans lequel il a été produit : c‟est l‟étape de traitement pragmatique."
    }, {
      "heading" : "3.1) Le niveau lexical",
      "text" : "Le but de cette étape de traitement est de passer des formes atomiques (tokens) identifiées par le segmenteur de mots (Nugues, 2006), c‟est-à-dire de reconnaître dans chaque chaîne de caractères une (ou plusieurs) unité(s) linguistique(s), dotée(s) de caractéristiques propres (son sens, sa prononciation, ses propriétés syntaxiques, etc).\nSelon l‟exemple (1), l‟étape d‟identification lexicale devrait conduire à un résultat voisin de celui donné ci-dessous, dans lequel on peut constater en particulier l‟ambiguïté d‟une forme telle que président: cette chaîne correspond à deux formes du verbe présider (indicatif et subjonctif), ainsi à une forme nominale, et sa prononciation diffère selon qu‟elle représente un nom ou un verbe.\nOn conçoit aisément que pour les mots les plus fréquents, comme « le », la solution la plus simple est de rechercher la forme dans (un lexique) 1 précompilé. Dans les faits, c‟est effectivement ce qui se passe, y compris pour des formes plus rares, dans la mesure où l‟utilisation des formalismes de représentations compacts permettant un accès optimisé (par exemple sous la forme d‟automates d‟états finis), et l‟augmentation de la taille des mémoires rend possible la manipulation de vastes lexiques (de l‟ordre de centaines de milliers de formes). Pour autant, cette solution ne résout pas tous les problèmes. Le langage est création, et de nouvelles formes surgissent tous les jours, que ce soit par emprunt à d‟autres langues (il n‟y a qu‟a écouté parler les enseignants des autres modules de la dominante informatique !), ou, plus fréquemment, par l‟application de procédés réguliers de créations de mots, qui nous permettent de composer pratiquement à volonté de nouvelles formes immédiatement compréhensibles par tous les locuteurs de notre langue : si j‟aime lire Proust, ne peut-on pas dire que je m‟emproustise, que de proustien je deviens proustiste, voire proustophile, puis que, lassé, je me désemproustise... Ce phénomène n‟a rien de marginal, puisqu‟il est admis que, même si l‟on dispose d‟un lexique complet du français, environ 5 à 10 % des mots d‟un article de journal pris au hasard ne figureront pas dans ce lexique. La solution purement lexicale atteint là ses limites, et il faut donc mettre en œuvre d‟autres approches, de manière à traiter aussi les formes hors-lexiques."
    }, {
      "heading" : "3.2) Le niveau syntaxique",
      "text" : "La syntaxe est l‟étude des contraintes portant sur les successions licites de formes qui doivent être prises en compte lorsque l‟on cherche à décrire les séquences constituant des phrases grammaticalement correctes: toutes les suites de mots ne forment pas des phrases acceptables (Ligauzat, 1994). La description des contraintes caractéristiques d‟une langue donnée se fait par le biais d‟une grammaire.\nLes modèles et les formalismes grammaticaux proposés dans le cadre du traitement automatique du langage sont particulièrement nombreux et variés. Le niveau syntaxique est donc le niveau conceptuel concerné par le calcul de la validité de certaines séquences de mots, les séquences grammaticales ou bien-formées. On conçoit bien l‟importance d‟un tel traitement dans une application de génération, pour laquelle il est essentiel que la machine engendre des énoncés corrects. Dans une application de compréhension, la machine analyse des textes qui lui sont fournis, et dont on peut supposer qu‟ils sont grammaticaux. Pourquoi donc, dans ce cas, mettre en œuvre des connaissances syntaxiques ?\nUne première motivation provient du fait que les textes ne sont pas toujours grammaticaux, par exemple à cause des fautes d‟orthographes. Une analyse syntaxique peut donc permettre de choisir entre plusieurs corrections à apporter à une phrase incorrecte, mais également se révéler bien utile pour améliorer les sorties d‟un système de reconnaissance optique de caractère ou d‟encore un système de reconnaissance de la parole.\n1 En linguistique, le lexique d'une langue constitue l'ensemble de ses lemmes ou, d'une manière plus courante mais moins précise, « l'ensemble de ses mots ». Toujours dans les usages courants, on utilise, plus facilement le terme vocabulaire.\nUne seconde raison est que l‟entrée du module syntaxique est une série de formes étiquetées morpho syntaxiquement, une forme pouvant avoir plusieurs étiquettes différentes. Une première fonction du module syntaxique consiste donc à désambiguïser la suite d‟étiquettes, en éliminant les séquences qui correspondent à des énoncés grammaticalement invalides."
    }, {
      "heading" : "3.3) Le niveau sémantique",
      "text" : "Intuitivement, la sémantique se préoccupe du sens des énoncés (yvon, 2007). Une phrase comme Le jardin de la porte mange le ciel, bien que grammaticalement parfaitement correcte, n‟a pas de sens dans la plupart des contextes. Mais qu‟est ce que le sens ? Pour une expression comme la bouteille de droite dans la phrase :\nSers-toi du vin. Non, pas celui-là, prends la bouteille de droite.\nLe sens correspond à l‟objet (au concept) désigné. Dans cet exemple, le sens dépend étroitement du contexte : il faut une représentation de la scène pour savoir de quelle bouteille, et donc de quel vin, il s‟agit.\nPour une expression prédicative, comme Il commande un Margaux 1982, le sens peut être représenté par un prédicat logique comme <demander(paul,chateau_margaux_82)>. L‟identification d‟un tel prédicat dépend encore une fois du contexte. Le verbe commander aurait en effet renvoyé à un autre prédicat s‟il s‟agissait de commander un navire."
    }, {
      "heading" : "3.4) Le niveau pragmatique",
      "text" : "Le niveau pragmatique est parfaitement dissociable du niveau sémantique. Alors que la sémantique se préoccupe du sens des énoncés, la pragmatique porte sur les attitudes (vérité, désirabilité, probabilité) que les locuteurs adoptent vis à vis des énoncés et sur les opérations logiques que ces attitudes déclenchent (yvon, 2007).\nHistoriquement, certains linguistes ont appelé pragmatique tout traitement du langage faisant intervenir le contexte d‟énonciation. Ce critère présente fort peu d‟intérêt, dans la mesure où les processus sémantiques sont les mêmes, que le contexte intervienne ou non. En revanche, il existe une distinction très importante, basée sur la notion d‟inférence logique. Considérons l‟exemple suivant :\n(a) Pierre : viendras-tu au bal ce soir ?\n(b) Marie : j‟ai entendu que Paul y sera !\nLa seconde phrase sera interprétée comme une réponse négative si l‟on sait que Marie n‟aime pas Paul.\nCette interprétation n‟est pas de nature sémantique. À partir de la compréhension du sens de l‟intervention de Marie, Pierre réalise une inférence logique en utilisant une connaissance contextuelle, l‟inimitié entre Paul et Marie. Pierre conclut que Marie ne veut pas aller au bal, autrement dit il reconstruit l‟attitude de Marie par rapport à son propre énoncé. Cette opération n‟est pas une construction conceptuelle, c‟est une opération logique. Elle appartient donc à la pragmatique.\nLes techniques correspondant à ce niveau de traitement sont encore très mal maîtrisées. Le niveau pragmatique, même si les techniques qui lui correspondent ne sont pas encore stabilisées, apparaît moins difficile à aborder que le niveau sémantique. Il semble en effet qu‟il repose sur un ensemble de principes fixes, comme le principe de pertinence, qu‟il s‟agit de modéliser correctement. La détermination de l‟intention argumentative de l‟auteur ou du locuteur est essentielle dans bon nombre d‟applications, notamment la gestion de dialogue, le résumé de texte, la traduction automatique, les systèmes d‟aide contextuelle ou d‟enseignement, etc. On attend donc des progrès significatifs à ce niveau dans les années qui viennent."
    }, {
      "heading" : "4) Les difficultés du TALN : ambiguïté",
      "text" : "Le langage naturel est ambigu, et cette ambiguïté se manifeste par la multitude d‟interprétations possibles pour chacune des entités linguistiques pertinentes pour un niveau de traitement, comme en témoignent les exemples suivants :"
    }, {
      "heading" : "4.1) Ambiguïté des graphèmes (lettres)",
      "text" : "Cette ambigüité existe dans le processus d‟encodage orthographique en comparant la prononciation du i dans lit, poire et maison.\n4.2) Ambiguïté dans les propriétés grammaticales et\nsémantiques\nAinsi mange est ambigu à la fois morpho-syntaxiquement, puisqu‟il correspond aux formes indicatives et subjonctives du verbe manger), mais aussi sémantiquement. En effet, cette forme peut aussi bien référer (dans un style familier) à un ensemble d‟actions conventionnelles (comme de s‟assoir à une table, mettre une serviette, utiliser divers ustensiles, ceci éventuellement en maintenant une interaction avec un autre humain) avec pour vision finale d‟ingérer de la nourriture (auquel il ne requière pas de complément d‟objet direct); et à l‟action consistant à effectivement ingérer un type particulier de nourriture (auquel cas il requiert un complément d‟objet direct), etc. Comparez en effet :\n(a) Demain, Paul mange avec ma sœur. (b) Paul mange son pain au chocolat.\nAinsi que les déductions que l‟on peut faire à partir de ces deux énoncés : de (a), on peut raisonnablement conclure que Paul sera assis à une table, disposera de couverts,... ; tout ceci n‟est pas nécessairement vrai dans le cas de l‟énoncé (b)."
    }, {
      "heading" : "4.3) Ambiguïté de la fonction grammaticale des groupes de",
      "text" : "mots\nL‟ambigüité est illustrée par la phrase :\nil poursuit la jeune fille à vélo.\nDans cet exemple à vélo est soit un complément de manière de poursuivre (et c‟est il qui pédale), soit un complément de nom de fille (et c‟est elle qui mouline) ;"
    }, {
      "heading" : "4.4) Ambiguïté de la portée des quantificateurs, des",
      "text" : "conjonctions et des prépositions\nAinsi, dans Tous mes amis ont pris un verre, nous pouvons supposer que chacun avait un verre différent, mais dans Tous les témoins ont entendu un cri, il est probable que c‟était le même cri pour tous les témoins. De même, lorsque l‟on évoque les chiens et les chats de Paul, l‟interprétation la plus naturelle consiste à comprendre de Paul comme le complément de nom du groupe les chats et les chiens ; cette lecture est beaucoup moins naturelle dans les chiens de race et les chats de Paul ;\n4.5) Ambiguïté sur l‟interprétation à donner en contexte à\nun énoncé\nNous comparons ainsi la « signification » de non, dans les deux échanges suivants :\n(a) Si je vais en cours demain ? Non (négation) (b) Tu vas en cours demain ! Non ! (j’y crois pas).\nEn effet, l‟ambiguïté est un problème majeur du TALN. Pour y pallier les chercheurs ont crée un domaine qui a pour but de centraliser ce problème et de proposer des méthodes de traitement du langage au niveau lexical, syntaxique et sémantique indépendamment d'une application donnée. Dans ce qui suit nous allons explorer ce domaine ainsi que ces différentes applications.\n5) La reconnaissance de l‟inférence textuelle (RTE)"
    }, {
      "heading" : "5.1) Introduction",
      "text" : "Le RTE est un domaine de recherche assez récent en traitement du langage (2005) qui a pour but de fédérer les recherches en TALN afin de proposer des méthodes de traitement du langage au niveau lexical, syntaxique et sémantique indépendamment d'une application donnée (résumé automatique, système de question réponse ou encore la recherche d'information). Le RTE vise à déterminer automatiquement si un segment de texte (H) est déduit d‟un autre segment de texte (T) (Dagan et al, 05).\nExemple :\nT : « Amine a 40 degrés de fièvre, sa mère l’a pris immédiatement à l’hôpital ».\nH : « Amine est malade ».\nDans l‟exemple ci dessus, comprendre que le segment H est déduit du segment T, est une déduction simple pour l‟être humain, mais pour la machine c‟est tout autre. Pour cela, les chercheurs ont proposé plusieurs approches pour résoudre le problème.\nDans l‟exemple, pour dire que H est inféré de T le système doit lier le fait d‟être malade (texte H) avec le mot hôpital et fièvre (texte T) pour déduire qu‟il y a inférence.\nDans cette section, nous présentons les différentes applications du RTE, puis nous détaillons les étapes de développement du challenge Pascale RTE qui a été mis en œuvre pour évaluer les avances des groupes de recherches dans ce domaine.\nNous développons dans la section 2, les principaux niveaux d‟inférences textuelles et nous terminons ce chapitre par la présentation de quelques méthodes d‟inférences utilisées par des groupes de recherches évaluées dans le challenge pascal RTE."
    }, {
      "heading" : "5.2) Les applications du RTE",
      "text" : "L‟inférence entre des segments de textes est au cœur de plusieurs applications du traitement automatique du langage naturel (TALN). Nous décrivons dans ce qui suit comment le RTE contribue dans ces différents domaines :"
    }, {
      "heading" : "5.2.1) La recherche d‟information",
      "text" : "La recherche d'information est la science qui consiste à rechercher l'information dans des documents, des bases de données, qu'elles soient relationnelles ou mises en réseau par des liens hypertextes (Joachims, 2003).\nLa recherche d'information est un domaine historiquement lié aux sciences de l'information et à la bibliothéconomie qui ont toujours eu le souci d‟établir des représentations des documents dans le but d'en récupérer des informations, à travers la construction d‟index. L‟informatique a permis le développement d‟outils pour traiter l‟information et à établir la représentation des documents au moment de leur indexation, ainsi que pour rechercher l‟information. Les approches qui étaient utilisées auparavant se basaient sur la recherche de mots clés dans les textes. Le problème dans ces systèmes c‟est qu‟ils ne prennent en compte ni les relations entre les mots clés ni leurs sens.\nExemple 1 :\nFigure 1.1 : Exemple de moteur de recherche a base de mot clé\nDans cet exemple (Figure 1.1) nous remarquons qu‟un moteur de recherche fonctionnant à base de mot clé comme Google fait bien ce type de recherche et répond bien à la question simple comme « the first president Algerie » puisque la simple recherche des mots clés dans les différents documents permet de donner une bonne réponse à l‟utilisateur.\nExemple 2 :\nDans cet exemple (Figure 1.2) nous remarquons que l‟utilisation des mots clés seuls peut nous mener à un document qui n‟a aucune relation avec notre requête et qui montre que l‟inférence sémantique est indispensable à la recherche d‟information."
    }, {
      "heading" : "5.2.2) L‟extraction d‟information",
      "text" : "L'extraction d'information consiste à identifier l'information bien précise d'un texte en langue naturelle et à la représenter sous forme structurée. Par exemple, à partir d'un rapport sur un accident d‟automobile, un système d'extraction d'information sera capable d'identifier la date et le lieu de l'accident, le type d'incident, ainsi que les victimes. Ces informations pourront ensuite être stockées dans une base de données pour y effectuer des recherches ultérieures ou être utilisées comme base à la génération automatique de résumés (Kosseim., 2005).\nL'extraction d'information s'avère très pratique dans l'industrie où des opérations d'extractions y sont quotidiennement effectuées à la main. Nous pensons, par exemple, au traitement de rapports de filature d'une agence de surveillance, à la gestion de dépêches d'une agence de presse, à la manipulation de rapports d'incidents d'une compagnie d'assurances, etc. Un système d'extraction d'information permet de traiter automatiquement et plus rapidement de grandes quantités de documents.\nDans ce cas de figure le RTE donne son apport dans la détection de l‟information."
    }, {
      "heading" : "5.2.3) Le système question- réponse",
      "text" : "Les systèmes Questions/Réponses sont capables de répondre à des questions écrites en langage naturel en cherchant la réponse dans un corpus de textes. Ils sont classiquement constitués d'un ensemble de modules réalisant respectivement : une analyse de la question, une recherche de portions de documents pertinents et une extraction de la réponse à l'aide de motifs d'extractions, ou patterns en anglais (Nyberg et al, 2002). Le système doit identifier le segment de texte qui contient la réponse. L‟inférence entre le texte T et le segment H peut aider à détecter le segment qui contient la réponse.\nExemple : H : « who is Ariel Sharon ? ». T : « Israel‟s Prime Minister, Ariel Sharon, visited Prague ». Le système effectue d‟abord une transformation à l‟affirmatif de la question « Ariel Sharon is Isreal‟s Prime Minister » puis une comparaison entre le segment de texte T et le segment H. Si H est inféré de T comme dans l‟exemple alors T est accepté comme un segment contenant la réponse à la question H."
    }, {
      "heading" : "5.2.4) La traduction automatique",
      "text" : "La traduction automatique désigne, au sens strict, le fait de traduire entièrement un texte grâce à un ou plusieurs programmes informatiques, sans qu'un traducteur humain n'ait à intervenir (Laurian et Marie, 1996). La traduction automatique est encore très imparfaite, et la génération de traduction d'une qualité comparable à celle de traducteurs humains relève encore de l'utopie.\nPour évaluer les performances de la machine, le RTE permet de comparer la traduction faite par la machine avec celle faite par l‟humain."
    }, {
      "heading" : "5.2.5) Le résumé automatique",
      "text" : "Le résumé automatique se propose de faire une extraction de l‟information jugée importante d‟un texte d‟entré pour construire, à partir de cette information, un nouveau texte de sortie, condensé. Ce nouveau texte permet d‟éviter la lecture en entier du document source.\nLe RTE est utilisé pour trouver les redondances d‟informations. Si un segment de texte infère un autre, un des deux va être supprimé. En particulier c‟est intéressant dans les applications qui font le résumé de plusieurs documents. S‟il y a plusieurs documents qui relatent le même fait, un seul doit être pris."
    }, {
      "heading" : "5.2.6) L‟acquisition des Paraphrases (AP)",
      "text" : "Une paraphrase, c‟est le fait de dire avec d‟autres mots, d‟autres termes ce qui est dit dans un texte, un paragraphe.\nDans ce cas de figure le RTE est utilisé pour détecter l‟inférence entre le texte paraphrasé et le texte d‟origine. Comme dans l‟exemple suivant où les deux phrases ont le même sens avec juste une autre disposition des mots dans la phrase. Exemple : T : « Ce médicament est commercialisé au Canada seulement ». H : « La commercialisation de ce médicament s‟est effectuée au Canada seulement ».\n5.3) Le challenge “PASCAL Recognizing of Textual Entailment”\nLe Pascal recognition of Textual Entailment est un concours qui a débuté en 2005. Il se déroule chaque année et son objectif, est de fournir à la communauté du TAL un nouveau point de repère pour vérifier les progrès dans la reconnaissance l‟inférence textuelle, et de comparer les réalisations des différents groupes de recherches travaillant dans ce domaine ( http://www.pascal-network.org/Challenges/RTE/ ).\nSuite au succès du premier RTE un nouveau RTE a été organisé, avec 23 groupes venus du monde entier (par rapport à 17 pour le premier défi) qui ont présenté les résultats de leurs systèmes. Les représentants des groupes participants ont présenté leurs travaux au PASCAL Challenges atelier en avril 2006 à Venise, Italie.\nL'événement a été un succès et le nombre de participants et leurs contributions à la discussion ont démontré que le Textual Entailment est un domaine en expansion rapide. Déjà, les ateliers ont donné naissance à un nombre impressionnant de publications dans les grandes conférences, en plus des travaux en cours. Les démarches entreprises pour réaliser le concours sont :\n Préparation du corpus.\n Etablissement des mesures d‟évaluations. Dans ce qui suit les démarches citées sont détaillées."
    }, {
      "heading" : "5.3.1) La préparation du corpus",
      "text" : "La première étape à entreprendre consiste à créer le corpus de texte-hypothèse (T-H) pair de petit segment de texte, qui correspond à des informations collectées à travers le web dans des domaines différents. Les exemples ont été collectés manuellement pour l‟inférence par des annotateurs humains. Les exemples ont été divisés en deux types de corpus (Corpus de développement et Corpus de test).\nLe corpus de développement est utilisé au début de challenge pour donner aux utilisateurs la possibilité de tester leurs systèmes et de faire des petites mises au point pour se préparer au test.\nLe corpus de test est utilisé pour l‟évaluation finale.\n1. Pour le RTE 1 Le corpus était composé de 567 paires de (H-T) pour le développement et 800 pairs pour le test. Le choix d‟un large corpus est justifié par la nécessité d‟avoir des résultats statistiques significatifs.\nLe corpus est collecté en respectant les différentes applications du traitement de langage naturel (QR, RI, IE., PP…) et la collecte des exemples est faite par niveau d‟inférence : L‟analyse lexique, syntaxique, logique et connaissance du monde, et les différents niveaux de difficultés.\nLe corpus doit inclure 50% d‟un exemple de T-H correspondant à de vraies inférences et 50% de fausses inférences. Pour cela, chaque exemple (T-H) est jugé vrai ou faux par l‟annotateur qui crée l‟exemple. Puis l‟exemple est évalué par un second juge qui évalue les paires de textes et d‟hypothèses, sans avoir pris conscience de leurs contextes.\nLes annotateurs étaient d‟accord avec le jugement dans 80% des exemples, ce qui correspond à 0.6 Kappa2, les 20% du corpus où il n‟y a pas eu d‟accord ont été supprimés). Le reste du corpus est considéré comme un «gold standard» ou « BASELINE » pour l‟évaluation.\nLe but de cette manœuvre est de créer un corpus où il n‟y aura pas de jugements controverses. Pour effectuer leurs jugements et annoter le corpus les annotateurs suivent des directives. Dans ce qui suit, nous allons citer les différentes directives qui étaient prises en considération."
    }, {
      "heading" : "5.3.2) Les directives de jugements",
      "text" : " L‟inférence est une relation à un seul sens.\n L‟hypothèse doit être inférée d‟un texte, mais le texte ne doit pas forcement être inféré de l‟hypothèse.\n L‟hypothèse doit être inférée entièrement du texte. L‟inférence est fausse s‟il reste une partie de l‟hypothèse qui ne peut être inférée par le texte.\n2 Kappa (J.Cohen, 1960) :c‟est une mesure statistique pour calculer a quel point deux personnes (ou groupes de personnes) A et B sont d‟accord pour classer N éléments dans K catégories mutuellement exclusives.\n les cas où l‟inférence est probable doit être jugé comme vrai.\n il est autorisé d‟utiliser les connaissances du monde comme dans l‟exemple le chiffre d’affaire de Google est de 50 millions de dollars. On doit savoir que Google est une\nentreprise donc on peut lui attribuer la possibilité d‟avoir un chiffre d‟affaire."
    }, {
      "heading" : "5.3.3) Les mesures d‟évaluation",
      "text" : "Le système d‟annotation du corpus adopté dans les deux challenges précédant est binaire, c‟est-à-dire que le système donne deux résultats possibles soit l‟inférence entre les deux textes est vrai ou fausse}. Le résultat est comparé au „GOLD standard‟, et le pourcentage donnant le nombre de fois où il y a similitude entre le système et le „gold standard‟ donne „l‟accuracy‟ du système. L‟accuracy est une mesure standard dans les systèmes de traitement du langage naturel. Elle est fréquemment utilisée pour évaluer les performances des applications, (Beyer et al. 2005). Elle est calculée comme ceci. Accuracy = X / Y. Où : X : représente le nombre de fois où les résultats du système sont similaires au gold standard. Y : représente le nombre de paires contenu dans le corpus de test. Par exemple Le nombre de résultats similaires est de 500 paires et le corpus est de 800 paires, l‟accuracy est de 500/800 qui est égale à 62,5%."
    }, {
      "heading" : "5.4) L‟analyse des principales méthodes utilisées",
      "text" : "Dans ce qui suit, nous allons présenter les différentes étapes de traitements effectuées pour détecter l‟inférence textuelle."
    }, {
      "heading" : "5.4.1) Les prétraitements",
      "text" : "Quelque soit la technique adoptée pour effectuer l‟inférence textuelle, il est nécessaire de pré traiter les données brutes avant d‟appliquer les techniques d‟inférences. Dans le RTE trois niveaux de prétraitements ont été utilisés:\n Niveau lexical pour éviter les problèmes liés à la morphologie de mots.\n Niveau syntaxique pour pouvoir donner une structure préalable au texte.\n Niveau sémantique pour analyser les sens des mots.\nCi-dessous nous allons présenter les différents niveaux de prétraitements existants et utiliser pour l‟inférence textuelle."
    }, {
      "heading" : "5.4.1.1) Le Niveau lexical",
      "text" : "L‟objectif du prétraitement au niveau du \"mot\" est de réduire les variations dues à la morphologie et d‟éviter que des petites erreurs initiales se propagent dans toutes les étapes du traitement. Pour cela, différentes transformations ont été introduites :\nA) La tokenisation\nL‟objectif de la tokenisation est de trouver les unités de base du \"sens \" dans les textes. Pour cela, les systèmes doivent résoudre différents problèmes comme la gestion des blancs, de la ponctuation, des retours lignes et des fins de paragraphes.\nB) La lemmatisation\nLa lemmatisation d'une forme d'un mot consiste à en prendre sa forme canonique. Celle-ci est définie comme ceci : Quand c‟est un verbe on doit le mètre à l'infinitif :\nExemple : Parti (verbe) -> partir\nPour les autres mots, ils doivent être mis au masculin singulier.\nExemple : Parti (nom) -> parti\nPour effectuer l‟analyse lexicale, différents outil qui ont été mis en point. Le TreeTagger est un des outils le plus utilisés pour la langue anglaise.\nLe TreeTagger effectue une tokinisation, une lemmatisation et un étiquetage comme le montre l‟exemple suivant :\nExemple d‟entrée dans le TreeTagger : « Le TreeTagger est facile à utiliser ».\nLa figure suivante reprend la sortie du logiciel."
    }, {
      "heading" : "5.4.1.2) Le niveau syntaxique",
      "text" : "L‟objectif de cette étape est de décrire les structures de phrases possibles et d‟analyser les phrases en structures. La structure révélée par l'analyse donne alors précisément la façon dont les règles syntaxiques sont combinées dans le texte. Cette structure est souvent une hiérarchie de syntagmes, représentée par un arbre syntaxique dont les nœuds peuvent être décorés (dotés d'informations complémentaires).\nNous illustrons cette analyse avec la sortie d‟un des outils utilisés dans l‟annotation syntaxique (SYNTEX) 3 .\nNous remarquons dans l‟exemple ci-dessus que l‟analyse morphosyntaxique permet d‟étiqueter les mots et l‟analyse syntaxique permet de les relier entre eux."
    }, {
      "heading" : "5.4.1.3) Le niveau sémantique",
      "text" : "Pour simplifier, nous pouvons dire que l'analyse sémantique s'appuie, entre autres, sur la compréhension du sens des mots des textes, contrairement aux analyses lexicales ou grammaticales, qui analysent les mots à partir du lexique ou de la grammaire. Dans le cadre de l'analyse sémantique, il est donc fondamental d'analyser le sens des mots pour comprendre ce qu'on dit. Pour cela plusieurs approches ont été adoptées pour annoter les relations entre les mots pour mieux cerner leur sens. Une de ces approches est la structure prédicat argument qui est expliquée ci-dessous.\nLa structure que nous appelons prédicative est un graphe de relation prédicat-argument, où les prédicats représentent l‟action. Une relation prédicative correspond à une relation de dépendance syntaxique. Le prédicat peut avoir plusieurs types d‟arguments (sujet, complément d‟objet direct et complément d‟objet indirect).\n3 La fonction de cet analyseur est d'identifier des relations de dépendances entre mots et d'extraire d'un corpus des syntagmes (verbaux, nominaux, adjectivaux) (Bourigault, 2000).\nExemple :\n5.4.2) Les différents niveaux d‟inférence textuelle\nDans cette section nous allons présenter les différents niveaux d‟inférences (Lexical, lexico syntaxique, sémantique (logique) et connaissance du monde) utilisées pour la détection de l‟inférence textuelle.\n5.4.2.1) L‟inférence au niveau lexical\nA ce niveau, l‟inférence entre deux segments de textes est accepté s‟il existe des mots semblables entre T et H, où les mots contenus dans la phrase H peuvent être inférés de T après des transformations lexicales (vanderwede et al., 2005). Les trois techniques d‟inférence sont ci-dessous :\nA) Les dérivations morphologiques\nCe mécanisme d‟inférence considère que deux des termes sont équivalents si l‟un peut être obtenu de l‟autre après une dérivation morphologique. Il existe trois type de dérivations morphologiques :\n- La normalisation\nExemple : T : « l‟acquisition d‟un AIRBUS A380 par le roi FAHD ». H : « le roi FAHD a acquis un AIRBUS A380 ».\nLa transformation <d’acquisition> en <a acquis > a permis de faire la déduction de l‟inférence entre les deux textes.\n- La dérivation nominale\nExemple\nT : Le GIA a donne de la terreur au peuple algérien.\nH : Le GIA est un groupe terroriste.\nLa transformation de terreur en terroriste a permis de faire la déduction de l‟inférence entre les deux textes.\n- Les relations entre noms et verbes\nExemple\nT : Mark gagne à tous les coups.\nH : Mark est un gagnant.\nLa transformation de Mark est un gagnant en Mark gagne a permis de faire la déduction de l‟inférence entre les deux textes.\nB) Les relations ontologiques\nUne ontologie est un ensemble structuré de concepts permettant de donner un sens aux informations. Elle est aussi un modèle de données qui représente un ensemble de concepts dans un domaine et les rapports entre ces concepts (Bourigault, 2004). Elle est employée pour raisonner au sujet des objets dans ce domaine. Les concepts sont organisés dans un graphe dont les relations peuvent être : des relations sémantiques et des relations de subsomption. L'objectif premier d'une ontologie est de modéliser un ensemble de connaissances dans un domaine donné. Ce mécanisme d‟inférence se réfère à la relation ontologique qui existe entre deux termes. Ces différentes relations sont citées ci dessous.\n- La synonymie\nReprésente un ensemble de mots interchangeables dans un contexte donné. Elle est souvent utilisée pour reconnaître l‟inférence.\nExemple\nT : « Jane a abattue Mark ».\nH : « Jane a tué Mark ».\nAutre exemple comme („‟commencer‟‟/‟‟démarrer‟‟), („‟enlever „‟/‟‟ retirer‟‟).\n- La généralisation (hypernymie)\nLa relation d‟Hypernymie est le terme générique utilisé pour désigner une classe englobant des instances de classes plus spécifiques. Y est un hypernyme de X si X est un type de Y.\nExemple\nT : « On a coupé le sapin ».\nH : « On a coupé l‟arbre ».\nLa relation entre l‟arbre et le sapin (l‟arbre est une généralisation sapin) a permis l‟inférence entre les deux textes.\n- L‟hyponymie\nLa relation Hyponymie est le terme spécifique utilisé pour désigner un membre d'une classe (relation inverse de Hypernymie). X est un hyponyme de Y si X est un type de Y.\nExemple\nT : John a pris un moyen de transport pour terrestre pour faire le trajet Toulouse paris.\nH : John a fait Toulouse Paris en TGV.\nLa relation entre moyen de transport pour terrestre et TGV qui a permis l‟inférence entre les deux textes.\n- La relation de Méronymie\nX est un méronyme de Y si X est une partie de Y.\nExemple :\n{Avion} a comme méronyme {{porte}, {moteur}} ;\nC) La connaissance du monde dans l‟analyse lexique\nCe mécanisme d‟inférence se réfère à la connaissance du monde pour détecter l‟inférence au niveau lexical (Len Schubert, 2002).\nExemple :\n„‟Taliban  organisation „‟et „‟yahoo  moteur de recherche „‟\n5.4.2.2) L‟inférence au niveau lexico syntaxique\nAu niveau lexico syntaxique l‟hypothèse est représentée par des relations de dépendances syntaxiques. La relation d‟inférence entre T et H est définit comme un recouvrement des relations de H par les relations de T, ou le recouvrement est obtenu après une séquence de transformation appliquée à la relation de T. Les différents s types de transformations sont spécifies par :\nA) Les transformations syntaxiques\nDans ce mécanisme d‟inférence, la transformation se fait entre les structures syntaxiques qui ont les mêmes éléments lexicaux et préservent le sens de la relation entre elles (Vanderwende et al..,2005). Ce genre de mécanisme inclut la transformation passive active et l‟apposition 4 . Exemple : « Mon chat, ce gentil petit siamois, est assis sur cette table ». « Il peut devenir : Mon chat est assis sur cette table, ce gentil petit siamois ! ».\nB) L‟inférence basée sur les paraphrases\nDans ce mécanisme d‟inférence, la transformation modifie la structure syntaxique du segment du texte et quelques éléments lexicaux, mais elle garde la relation d‟inférence entre le segment de texte original et celui qui est transformé. Ce type de relation entre les deux segments est appelé dans la littérature « Paraphrase ». Des méthodes pour effectuer la transformation sont proposées dans (Lin et Pantel, 2001). Exemple : T : « Ce médicament est commercialisé au Canada seulement ». H : « La commercialisation de ce médicament s‟est effectuée au Canada seulement ».\nC) La coréférence\nLa relation de coréférence met en relation un pronom et un antécédent éloigné l‟un de l‟autre dans la phrase. Par exemple : « L‟Italie et l‟Allemagne ont tous deux joué deux matchs, ils n‟ont perdu aucun match encore ». Infère à\n« Ni l‟Italie ni l‟Allemagne n‟a encore perdu un match », cela inclut la transformation de\ncoréférence « ils  l‟Italie et l‟Allemagne ».\n4 L‟apposition est une construction grammaticale dans laquelle deux éléments, normalement substantif expressions, sont placés à côté de l'autre, avec un élément servant à définir ou modifier les autres.. Lorsque ce dispositif est utilisé, les deux éléments sont censés être à l'apposition. Par exemple, dans l'expression \"mon ami Alice\" le nom \"Alice\" est à l'apposition de \"mon ami\".\n5.4.2.3) L‟inférence sémantique (logique)\nA ce niveau, l‟inférence entre deux segments de textes est acceptée si le sens des deux phrases se concorde. En d‟autre termes, l‟inférence textuelle est considérée comme un problème d‟implication logique entre les sens des deux phrases (Tatu et al., 2006). Pour cela, la structure prédicat argument est souvent utilisée, c'est-à-dire que, les segments de textes T et H sont transformés en prédicat et à travers des déductions logiques comme par exemple l‟utilisation de la (preuve par réfutation 5 ) on arrive à déduire l‟inférence. Un exemple des systèmes utilisant cette méthode d‟inférence est décrit dans la section (5.5.4.2)."
    }, {
      "heading" : "5.4.3) Les ressources utilisées",
      "text" : "Dans les différents techniques d‟inférence textuelle plusieurs ressources sont utilisées (WordNet, framnet, Cyc…). L‟ensemble constitue un « écosystème » complet couvrant des aspects lexicaux, syntaxiques et sémantiques. Combinées, ces ressources fournissent un point de départ intéressant pour des développements sémantiques en TAL ou dans le cadre du Web sémantique, telle que la recherche d‟information, l‟inférence pour la compréhension automatique de textes, la désambiguïsation lexicale, la résolution d‟anaphore et aussi l‟inférence textuelle. Dans ce qui suit, nous allons définir les différentes ressources existantes et utilisées pour détecter l‟inférence textuelle."
    }, {
      "heading" : "5.4.3.1) Le WordNet",
      "text" : "WordNet (Miller, 1995) est une base de données lexicale développée depuis 1985 par des linguistes du laboratoire des sciences cognitives de l'université de Princeton. C‟est un réseau sémantique de la langue anglaise, qui est fondé sur une théorie psychologique du langage. La première version diffusée remonte à juin 1991. Son but est de répertorier de classifier et de mettre en relation de diverses manières le contenu sémantique et lexical de la langue anglaise. Le système se présente sous la forme d'une base de données électronique (Chaumartin, 2007).\nLe synset (ensemble de synonymes) est la composante atomique sur laquelle repose WordNet. Un synset correspond à un groupe de mots, dénotant un sens ou un usage particulier. Un synset est défini par les relations qu'il entretient avec les sens voisins. Les noms et verbes sont organisés en hiérarchies. Des relations d‟hyperonymie et d‟hyponymie relient les « ancêtres » des noms et des verbes avec leurs «spécialisations». Au niveau racine, ces hiérarchies sont organisées en types de base.\nÀ l'instar d'un dictionnaire traditionnel, WordNet offre ainsi, pour chaque mot, une liste de synsets correspondant à toutes ses acceptions répertoriées. Mais les synsets ont également d'autres usages : ils peuvent représenter des concepts plus abstraits, de plus haut niveau que les mots et leurs sens, qu'on peut organiser sous forme d'ontologie. Nous pouvons ainsi interroger le système quant aux hyperonymes d'un mot particulier. À partir par exemple du\n5 La réfutation est un procédé logique consistant à prouver la fausseté ou l'insuffisance d'une proposition ou d'un argument.\nsens le plus commun du nom \"car\" (correspondant au synset \"1. car, auto...\"), la relation d'hyperonymie définit un arbre de concepts de plus en plus généraux:\n1. car, auto, automobile, machine, motorcar\n=> motor vehicle, automotive vehicle\n=> vehicle\n=> conveyance, transport\n=> instrumentality, instrumentation\n=> artifact, artefact\n=> object, physical object\n=> entity, something\nDans cet exemple, il est clair que le dernier concept, \"entity, something\", est le plus général, le plus abstrait (il pourrait ainsi être le super-concept d'une multitude de concepts plus spécialisés).\nNous pouvons également interroger le système quant à la relation inverse de l'hypernymie, l'hyponymie. WordNet offre en fait une multitude d'autres ontologies, faisant usage de relations sémantiques plus spécialisées et restrictives. Nous pouvons ainsi interroger le système quant aux méronymes d'un mot ou d'un concept, les parties constitutives d'un objet (\"HAS-PART\"). Les méronymes associés au sens \"car, auto...\" du mot \"car\" sont :\n1. car, auto, automobile, machine, motorcar\nHAS PART: accelerator, accelerator pedal, gas pedal, gas,\nthrottle, gun\nHAS PART: air bag\nHAS PART: auto accessory\nHAS PART: automobile engine\nHAS PART: automobile horn, car horn, motor horn, horn\n(...)"
    }, {
      "heading" : "5.4.3.2) Le FrameNet",
      "text" : "FrameNet (Baker, Fillmore et Lowe, 1998), projet mené à Berkeley à l‟initiative de Charles Fillmore, est fondé sur la sémantique des cadres (frame semantics). FrameNet a pour objectif de documenter la combinatoire syntaxique et sémantique pour chacun des sens d‟une entrée lexicale à travers une annotation manuelle d‟exemples choisis dans des corpus sur des critères de représentativité lexicographique. Les annotations sont ensuite synthétisées dans des tables, qui résument pour chaque mot les cadres avec leurs arguments syntaxiques."
    }, {
      "heading" : "5.4.3.3) Le Cyc",
      "text" : "Cyc est un projet d‟Intelligence Artificielle lancé en 1984 par Doug Lenat. Cyc vise à regrouper une ontologie et une base de données complètes sur le sens commun, pour permettre à des applications d'intélligence artificielle. D‟effectuer des raisonnements similaires à ceux des humains. Des fragments de connaissances typiques sont par exemple : « les chats ont quatre pattes » ; « Paris est la capitale de la France ». Elles contiennent des\ntermes (PARIS, FRANCE, CHAT?) et des assertions (« Paris est la capitale de la France ») qui relient ces termes entre eux. Grâce au moteur d‟inférence fourni avec la base Cyc, il est possible d‟obtenir une réponse à une question comme « Quelle est la capitale de la France ? » La base Cyc contient des millions d‟assertions (faits et règles) rentrées à la main."
    }, {
      "heading" : "5.5) L‟analyse des systèmes participant au RTE 2",
      "text" : "Nous avons marqués pour chaque groupe de recherche participant au RTE2 les types d‟inférences utilisés. Les résultats sont affiches dans le tableau 1.6.\nTableau 1.1 Représentation des différents types d‟inférences entrepris par les groupes de\nrecherches\n5.5.4) Quelques exemples d‟inférence utilisés par des groupes de recherches\nDans le RTE 2 nous avons remarqué que tous les groupes de recherches n‟ont pas utilisé d‟inférence temporelle dans leurs systèmes et à l‟heure actuelle, les résultats du RTE 3 ne sont pas encore publiés officiellement mais d‟après notre lecture des différentes publications des groupes de recherches participant au RTE3, il y a deux groupes qui ont fait allusion à l‟inférence temporelle. Pour cela, nous avons choisi de décrire leurs systèmes.\nType d‟analyse\nGroupes de recherches\nlexicale\nsyntaxique lexico-\nsémantique\nLogique numérique\nTemporelle\nUNED + + + +\nUMESS +\nMITRE + +\nIRST + +\nGOGEX + + +\nLCC‟S + +\nC&C + +\n5.5.4.1) La reconnaissance de l‟inférence textuelle basée sur l‟analyse de dépendance et WordNet (Université nationale de l‟éducation a distance de\nMadrid)\nLe système présenté montre comment des informations sémantiques peuvent être extraites du texte en utilisant les structurations syntaxiques données par l‟analyse de dépendance, et des ressources lexico- sémantiques comme Word Net peuvent développer le RTE.\nLes techniques utilisées par ce système sont les suivantes :\n l‟analyse dépendance du texte et de l‟hypothèse.\n l‟inférence lexicale entre les nœuds des arbres en utilisant Word Net.\n la concordance entre les arbres de dépendance basée sur la notion de l‟inclusion.\nA) L‟architecture du système\nL‟architecture du système est montrée dans la figure suivante (Figure 1.7) :\nCette architecture est composée de Trois modules :\n L‟analyse de dépendance : Elle consiste à normaliser les informations du dataset, de générer les dépendances existantes entre les mots et de donner à la sortie un arbre de\ndépendance constitué de nœuds qui représentent les mots de la phrase et d‟arcs qui représentent les dépendances entre les nœuds. Ce travail est réalisé par un logiciel nommé « Lin‟s Minipar ».\n L‟analyse lexicale : prend les informations données par l‟analyse de dépendance et retourne les mots de l‟hypothèse H qui sont infères du texte T. Ce module utilise\nWordNet pour détecter les relations de (synonymie, hyponymie, meronymie ) entre les unîtes lexicales.\n Les relations entre les arbres de dépendance : le but est de déduire si l‟arbre de l‟hypothèse est recouvert par l‟arbre de dépendance du texte, Pour cela, la règle établie\nest qu‟un arc est dit recouvert s‟il est dans le même emplacement que dans l‟arbre représentant le texte et il y a une inférence entre ces nœuds et celle du texte. La figure ci-dessous (figure 1.8) reprend ce genre de recouvrement.\nB) L‟expérimentation du système\nLe groupe a soumi deux systèmes au challenge.\n- Système 1 Le systeme1 n‟utilise que les deux premiers modules, et la décision de l‟existence d‟inférence est prise par rapport au nombre de nœuds de l‟hypothèse infère de l‟arbre de dépendance du texte.\n- Système 2 Le système 2 utilise les 3 modules et la décision est prise par rapport au nombre d‟arc\nrecouverts.\nLes résultats sont affiches dans le tableau 1.2. L‟utilisation de WordNet seule a donné de bons résultats, mais en ajoutant le module de recouvrement il décroît les performances du système.\nTableau 1.2: Les valeurs de précision des systèmes\nLes systèmes Précision\nSystème 1 : 56,37 %\nSystème 2 : 54,75 %\nLa notion de recouvrement n‟est pas appropriée pour le RTE, car un large recouvrement n‟implique pas une inférence sémantique, et un faible recouvrement n‟implique pas une différence sémantique. L‟utilisation de Word Net a contribué à l‟inférence au niveau lexical et a augmenté les performances du système. Dans cette direction, les prochaines étapes seront de reconnaître et d‟évaluer les inférences entre les expressions numériques, les entités nommées 6 et les expressions temporelles.\nC) L‟évolution du système\nCe qui a été développé pour le RTE2 est un module pour la détection des expressions numériques, ce qui a permis d‟augmenter fortement la précision (harrera et al.,2006). La figure suivante montre comment le module est introduit dans leur système.\nDans le RTE 3, le groupe s‟est focalisé sur l‟inférence entre les entités nommées. Il a défini les relations d‟inférences entre les entités nommées (Rodrigo et al., 2007). Exemple :\n- Nom propre E1 infère nom propre E2 si une chaîne E1 contient la chaîne E2. - une expression du temps t1 infère une expression du temps T2 si l‟intervalle de temps\nexprimée dans t1 est inclus dans l‟intervalle T2.\nCe module de d‟inférence a lui aussi contribué à augmenter la précision (Rodrigo et al, 2007)."
    }, {
      "heading" : "5.5.4.2) COGEX (université du Texas, USA)",
      "text" : "Le système utilise une approche logique pour résoudre l‟inférence textuelle. En d‟autres termes, l‟inférence textuelle est considérée comme un problème d‟implication logique entre les sens des deux phrases (Tatu et al., 2006). La description du système et l‟évolution qui s‟est produite dans chaque challenge est décrite dans ce qui suit.\n6 Les entités nommées désignent l'ensemble des noms de personnes, de lieux, d'entreprise contenues dans un texte.\nA) La description du système\nLa première étape consiste à transformer le texte et l‟hypothèse en forme logique (Moldovan and Rus, 2001).\nPour cela il faut d‟abord transformer du langage nature a un format prédicat argument, pour cella le groupe utilise WordNet pour lier le prédicat avec ses argument. Concrètement WordNet produit des relations entre les synsets, et chaque synset lui correspond un prédicat.\nLe prédicat peut avoir un ou plusieurs arguments et le prédicat qui correspond au nom a un seul argument en général, et le prédicat qui correspond à un verbe a trois arguments : l‟événement, le sujet et le complément d‟objet. Pour chaque relation dans la chaîne lexicale 7 , le système génère un axiome utilisant les prédicats qui correspondent au synset de la relation.\nPar exemple : il y a une relation d‟inférence entre le verbe vendre et le verbe payer. Le système génère l‟axiome suivant pour cette relation : Vendre_VB_1(e1,x1,x2)  payer_VB_1(e1,x1,x3) Ce type d‟axiome contribue à l‟inférence quand une chaîne lexicale est trouvée.\nApres la transformation des deux paires de texte en format logique le groupe utilise la preuve par « l‟absurde » ou „‟preuve par contradiction‟‟ (Wos, 1998). La négation de l‟hypothèse H est réalisée s‟il y a une contradiction ou une déduction de contradiction par rapport au texte T, nous concluons que l‟hyponyme est dérivable du texte.\nB) L‟évolution du système\nIl a été développé pour le RTE 2 un module qui traite la négation dans la transformation du texte en prédicat et un autre module qui fait une analyse sémantique en tant que pré traitement pour donner les relations existantes entre le verbe et ses arguments et aussi entre les arguments eux- mêmes (Tatu et al.,2006).\nPour le RTE3 le groupe a développé et intégrer a leur système plusieurs outils. Dans ce qui suit nous allons présenter l‟architecture du système et les nouveaux outils conçus et utilises pour améliorer l‟inférence. Le schéma du dernier système conçu pour le RTE 3 par le groupe est donné par la figure cidessous.\n7 Une chaîne lexicale est une chaîne où il y a une relation entre deux synsets.\n- EXtended WordNet XWN (eXtended WordNet) est un projet qui a pour but d‟enrichir les relations du dictionnaire WordNet avec des relations sémantique entre les synsets et les transforment en format logique (Tatu et Moldovan, 2007).\n- TARSQI\nC‟est un système modulaire pour l'annotation automatique temporelle qui ajoute les expressions du temps, des événements et des relations temporelles de l'actualité des textes (Venhaguane et al. ,2005).\n- Outil pour la gestion des coréférences\nPour relier les phrases dans les textes longs et, résoudre le problème qui est apporté par les coréférences dans l‟inférence textuelle, l‟outil développé combine l‟algorithme Hobbs (Hobbs, 1978) et l‟algorithme de résolution d‟anaphore (Lappin and Leass, 1994). Pour le RTE, il est important d‟avoir les relations entre les prédicats d‟un long texte.\nExemple 1 : George Bush grandit à Greenwich au Connecticut, Il est à l'époque membre d'une confrérie étudiante secrète devenue célèbre. Lier George Bush et il, est une des taches que l‟outil doit résoudre.\nLe développement du XWN-KB a eu un impact considérable sur le RTE, mais l‟utilisation du TARSQI n‟a donné aucun impact sur le résultat car l‟utilisation des expressions temporelles dans ce corpus est inexistante."
    }, {
      "heading" : "5.5.5) Conclusion",
      "text" : "Dans les travaux entamés par UNED sur les entités nommées, le groupe a établi plusieurs règles d‟inférence entre les entités nommées, parmi lesquelles se trouve une règle d‟inférence entre les expressions temporelles. Celle-ci peut être considérer comme une contribution implicite à l‟inférence temporelle. Mais concrètement l‟inférence temporelle est considérée comme une perspective pour leurs prochaines recherches."
    }, {
      "heading" : "5.6) Conclusion",
      "text" : "Dans ce chapitre nous avons explorés l‟apport du RTE dans les différentes applications du TALN (RI, QR, EI et RA) et nous avons exploré les différentes approches utilisées pour détecter l‟inférence (lexical, lexico syntaxique, sémantique et logique). Aussi nous avons analysé les approches des différents groupes de recherches qui ont participe au challenge Pascal RTE. Cette étape nous a permis de découvrir les chemins qui n‟ont pas encore été pris pour détecter l‟inférence textuelle. Enfin nous nous sommes focalisés à décrire les systèmes qui ont mentionné l‟aspect temporel dans leurs recherches. Nous avons remarqué que dans les trois RTE qui se sont déroulés, l‟inférence temporelle est une perspective qui n‟est pas encore entamée. Nous allons justement décrire dans le prochain chapitre l‟aspect temporel dans le RTE.\n- Chapitre 2 -\nLe temps et la langue\nChapitre 2\nLe temps et la langue"
    }, {
      "heading" : "1) Introduction",
      "text" : "Avant d‟entamer notre travail sur l‟inférence textuelle, nous avons besoin d‟explorer la notion du temps dans ses différentes bannières, d‟abord par rapport à la logique modale et aussi par rapport à la langue.\nLe mot « temps » recouvre plusieurs significations en français, et il est nécessaire pour la compréhension de distinguer le temps grammatical du temps notionnel. Le second est représenté en logique par une ligne droite et infinie, avec un point marquant le présent et séparant le passé du futur. Le temps grammatical désigne les marques linguistiques utilisées pour exprimer le temps notionnel dans le langage (l‟imparfait, le présent de l‟indicatif, etc.…).\nDans ce qui suit nous allons explorer ces deux notions du temps, du point de vu logique avec ces différentes représentations (structure de points, structure d‟intervalles, événement et Allen) ensuite au point de vu langage. Nous terminons avec une étude sur l‟inférence temporelle élaborée par l‟un des groupes les plus abouti dans le domaine."
    }, {
      "heading" : "2) La structure de points",
      "text" : "La conception du temps est couramment reliée à la notion de point ou d‟instant sur un axe temporel. Les points permettent en effet d‟utiliser les structures de nombres (entiers, rationnels ou réels). Cette conception est largement utilisée dans la modélisation de phénomènes évoluant dans le temps. Cette structure temporelle doit être manipulée avec un langage logique ; la logique du temps, historiquement très liée au développement des logiques modales. Elle est basée sur les\nconnecteurs logiques habituels () et les opérateurs temporels P (passé) et F (futur). Ainsi, si l‟action de chanter effectuée par John est notée p, on aura les représentations suivantes : - John chante : p - John chanta : Pp - John chantera : Fp - John avait chanté : PPp (on se place dans le passé d‟un point situé au passé lui-même) - John aura chanté : FPp\nCes formules seront enrichies avec de nouveaux opérateurs similaires à ceux utilisés en logique modale (Bras, 1990). Toutes les logiques dérivées de la logique du temps sont basées sur une ontologie de points. Nous allons maintenant nous intéresser à des ontologies d‟intervalles."
    }, {
      "heading" : "3) La structure d‟intervalles",
      "text" : "Du point de vue philosophique, il semble que le concept de point dépourvu de durée ne correspond pas à la réalité : Du point de vue linguistique, il est encore plus évident qu‟une entité ponctuelle est mal adaptée pour l‟expression de la référence temporelle. Même les expressions dites ponctuelles se référent à des périodes étendus, comme dans les exemples suivants : A six heures précises, Harry quitta son bureau.\nUne structure d‟intervalle est définie par < I, <, >, avec I un ensemble non vide d‟entités\ntemporelles, des relations de précédence (<) et d‟inclusion (). Voici quelques propriétés de cette structure :\n\nest un ordre partiel, elle est en effet :\nRéflexive : (xxx.\nAntisymétrique : (x(y(xy  yx  xy).\nTransitive : (x(x xyyzxz).\nNous pouvons également remplacer la relation (par la relation O (overlap) qui exprime que deux événements ont une partie commune, et définie par rapport à l‟inclusion:\nxOy (z) (zx  zy)\nLa mise en place des logiques temporelles basées sur les sémantiques d‟intervalles amènent à des résultats relativement complexes, qu‟il n‟est pas nécessaire d‟exposer ici. Des critiques ont été adressées aux sémantiques d‟intervalles, notamment en ce qui concerne la difficulté de définir la vérité d‟une proposition (vraie sur toutes intervalles ? sur au moins l‟un deux ?). Ces problèmes ont provoqué la nécessité de concevoir une entité plus globale et plus complète."
    }, {
      "heading" : "4) La structure d‟événements",
      "text" : "L‟événement est une nouvelle entité primitive, de durée non nulle et fini, correspondant intuitivement à des fragments de notre perception du monde. Pour les linguistes comme pour les philosophes, les logiciens et les spécialistes de l‟intelligence artificielle, la tendance est de préférer les événements aux intervalles car les événements ont une structure à portée non seulement temporelle, mais aussi spatiale. Davidson a proposé de traiter les événements comme des objets, ajoutant à l‟ensemble des individus d‟un modèle, un ensemble d‟événements, par exemple, la phrase Marie aime Paul n‟est plus représentée par aimer (Paul, Marie), mais par : Aimer(e, Paul, Marie)\nUne structure d‟événement est définie par Kamp par le triplet<E, , >, où E est un ensemble\nd‟entités de base non nulle,  est la relation de précédence, et O la relation de recouvrement si e1Oe2 alors une partie de e1 au moins a eu lieu en même temps que e2.\nest asymétrique : (e1 e2) (e2  e1)\n est transitive : (e1 e2)  (e2 e3)  (e1 e3)\nO est symétrique : (e1 e2)  (e2 e1)\nO est réflexive : (e1 e2)\nPrincipe de séparation : (e1 e2)   (e1 e2)\nTransitive mixte : (e1 e2) (e2 e3)  (e3 e4)  (e1 e4)\nPrincipe de linéarité : (e1 e2) (e1 e2) (e2 e1) Ces conditions minimales sont dictées par l‟intuition lorsque nous avons des événements et des relations qui les lient.\nNous avons présenté trois ontologies (structures de points, structures d‟intervalles et structures d‟événements). Il est fondamental de séparer le niveau temporel (points et intervalles) du niveau relatif à l‟expérience du monde (événements). En effet, si les relations définies dans les structures d‟événements sont des relations temporelles, les événements sont également des expériences, des « faits » qui ont lieu et qui déterminent la structure du temps. C‟est pourquoi nous pouvons dire que la logique d‟Allen, que nous allons présenter, permet de rattacher les deux notions.\n5) La théorie d‟Allen Selon Allen, deux intervalles peuvent être liés entre eux par les 13 relations primitives suivantes (Bras, 1990). Où X et Y sont des termes de types intervalles de temps (on appelle « relation inverse » la relation correspondante entre Y et X) :\nRelation Symbole Symbole\nrelation inverse\nX beforeY < >\nX equalsY  \nX meetsY M Mi\nX overlapsY O Oi\nX duringY D Di\nX startsY S Si\nX finishes Y F Fi\nTableau 2.1: Les relations d‟Allen\nLes relations sont mutuellement exclusives : une seule relation est possible entre deux intervalles.\nIl est possible de composer les relations. Ainsi, la transitivité des relations entre intervalles est définie par:\n I  j k (( I < j) (j < k) I < k)\n I  j k ((I mj) (j d k) (I o k)  (I d k)  (I s k))\nIl existe 169 relations de transitivité de ce type.\nDeux intervalles peuvent être reliés par une relation primitive, mais aussi par une relation complexe ; il est ainsi possible de représenter une connaissance incomplète des relations. La connaissance temporelle sur un ensemble d‟intervalles peut être représentée par un réseau de contraintes. Il s‟agit d‟un graphe orienté dont les nœuds représentent les intervalles et dont les arcs sont étiquetés par la relation entre les intervalles.\nL‟exemple suivant, très simple, permet d‟illustrer rapidement le raisonnement sur les intervalles : Paul entra dans la pièce (1). Marie regardait la télévision (2) .Elle l’éteint (3). (1) Et (2) introduisent l‟assertion temporelle suivante : I entre during I regarde_television Puis, en examinant (2) et (3), nous obtenons :\nI regarde_television meet I enteindre- television"
    }, {
      "heading" : "5) Le temps dans la langue",
      "text" : "Qu'est-ce qui distingue le temps linguistique des autres notions de temps? \"Ce que le temps linguistique a de particulier c'est qu'il est organiquement lié à l'exercice de la parole, qu'il se définit et s'ordonne comme fonction du discours. Ce temps a son centre – un centre, à la fois, générateur et axial - dans le présent de l'instance de la parole\" (Benveniste, 1974). Le discours instaure un maintenant, moment de l'énonciation. En opposition au maintenant, nous créons un alors. Ce maintenant est donc le fondement des oppositions de la langue."
    }, {
      "heading" : "5.1) Le modèle de Reichenbach",
      "text" : "Reichenbach a proposé, pour modéliser la sémantique des temps grammaticaux, les trois repères suivants : E le moment de l‟événement S le moment de l‟énonciation ou de la parole (Speech Time) R le moment de référence Les relations possibles entre repères sont la relation de simultanéité) notée « , » et la relation de précédence notée « _ ». La nouveauté réside surtout dans l‟ajout d‟un moment de référence, qui permet de prendre en considération certains temps composés. Ainsi, la représentation de quelques temps grammaticaux à l‟aide du modèle de Reichenbach est la suivante : Passé simple je vis Paul E, R_S Plus-que-parfait j‟avais vu Paul E_R_S Futur je verrai Paul S_E,R Futur antérieur j‟aurai vu Paul S_E_R"
    }, {
      "heading" : "5.2) Les adverbiaux temporels",
      "text" : "Un adverbial est un élément (mot ou groupe de mots) ayant une fonction similaire à celle d‟un adverbe ou d‟un complément circonstanciel, c‟est-à-dire qu‟il modifie le verbe auquel il est rattaché (Charolles, 1997). Nous pouvons le supprimer sans rendre la syntaxe ni la sémantique de la phrase incorrecte. Ainsi, les passages soulignés des exemples suivants ont une fonction adverbiale temporelle : Paul arrive demain. Marie est revenue à cinq heures. Nous pouvons distinguer : Les adverbiaux de référence temporelle dont le rôle est d‟exprimer la localisation d‟un événement dans le temps : demain. Les adverbiaux de durée : pendant une heure, en trois jours Les adverbiaux de durée : pendent une heure. Les adverbiaux de fréquence : souvent, tous les mois. Les adverbiaux itératifs : trois fois, plusieurs fois. Les adverbiaux de quantification : toujours, quelquefois. Les adverbiaux présuppositionnels : encore, déjà."
    }, {
      "heading" : "6) L‟inférence temporelle",
      "text" : "Si l‟annotation des marqueurs du temps dans le discours sont l‟objet de plusieurs sujets de recherches, l‟étude de l‟inférence temporelle et ses applications ne sont qu‟à ses débuts. Ce problème commence à générer des travaux en informatique linguistique liés aux enjeux que représentent les informations temporelles entre autre pour la recherche d‟information et les systèmes questions-réponses.\nAvec l‟exploration de ce nouveau champ d‟action dans le traitement du langage naturel, l‟inférence temporelle nous permet d‟établir des relations temporelles existantes entre évènements dans un texte, de détecter les relations existantes entre expressions temporelles et aussi les relations entre expressions temporelles et événements.\nDans ce qui suit nous présentons l‟une des recherches les plus abouti dans le domaine."
    }, {
      "heading" : "6.1) Le travail du groupe Human Language Technology Research",
      "text" : "Institut (HLTRI) sur l‟inférence temporelle :\nHLTRI est un groupe de recherche travaillant sur l‟inférence temporelle. Il est aussi membre de l‟organisation fondatrice du langage (TimeML 8 ) qui est un langage de spécification d‟événements et d‟expressions temporelles dans le langage naturel. Afin d‟étudier l‟inférence temporelle dans le langage naturel, le groupe (HLTRI) a établi un grand corpus de questions-réponses qui sont fondées sur la recherche d‟information temporelle. Les questions sont annotées comme ceci: • Expressions temporelles, annotées par la balise TIMEX3. • La balise EVENT correspond à un événement. • LIEN est une balise qui code les relations entre éléments temporels.\nPour découvrir les relations temporelles entre les événements dans un texte, le groupe a utilisé la représentation graphique. Les nœuds du graphe sont représentés par les événements et les arcs entre les nœuds sont soit des relations TLink, SLink ou ALink. Pour classer les événements dans un même texte, il utilise les trois relations ALINK, TLINK, SLINK et entre les évènements de deux textes différents il n‟utilise que le module TLINK. - TLink, représentant les relations temporelles entre les événements ou entre un événement et une expression temporelle. - SLink ou relation de subordination, est utilisée pour introduire des contextes et des relations entre deux événements. - ALink ou relation aspectuelle, représentant la relation aspectuelle entre un événement et son argument (en général c‟est un autre événement). Afin d‟avoir toutes les relations temporelles possibles entre les évènements des deux textes, le groupe a conçu un module d‟inférence temporelle. À partir des différents liens TLINK, ALINK et SLINK existant entre les expressions temporelles et les événements, le module infère de nouveaux liens non détectés auparavant. Pour cela le groupe a définit plusieurs règles d‟inférences qui sont citées ci-dessous :\n8 TimeML a été développé dans le cadre de trois ateliers AQUAINT et des projets. En 2002, TERQAS atelier vise à renforcer la langue naturelle de répondre à la question des systèmes de réponse temps-fondé des questions sur les événements et les entités dans des articles de journaux. La première version de TimeML a été définie et la TimeBank corpus a été créé comme une illustration. Tango a un atelier de suivi dans lequel un outil graphique d'annotation a été développé. Actuellement, le TARSQI projet développe des algorithmes qui balise les événements et le temps des expressions NL textes dans le temps et l'ancrage et l'ordre des événements. En outre, TimeML a été examinée et encouragée dans: ARTE atelier ACL : Annoter et Raisonnement sur le temps et les événements (Juillet 2006), Séminaire Dagstuhl Annoter, l'extraction et le raisonnement sur le temps et les événements (avril, 2005).\nConcrètement le module suit les étapes suivantes : Etape1:trouver T1 et T2, deux expressions temporelles dans la phrase ou des phrases adjacentes. Etape2:Rechercher des événements E1 et E2 lié à T1 et T2 respectivement. Etape3:Trouver une relation CE1 lien entre E1 et d'autres événements. Etape4:Trouver relation CE2 lien entre E2 et d'autres événements. Etape5:Utiliser une inférence temporelle reliant CE2 et CE1.\nLors de l'application de la procédure à l'exemple illustré dans la figure 2.3 le module suit les étapes suivantes : Etape 1: trouver les expressions temporelles t1 et t2. Etape 2: événements e1 et e4 reliées à t1 et t2 avec TLink : is_includes. Etape 3: détecter la chaîne des événements (e1, e2, e3). Etape 5: T1 et T2 sont liés (par un ANCHORTIME (t2)=t1), ce qui signifie que e1, e2, e4 et e3 sont simultanés."
    }, {
      "heading" : "6.2) Synthése",
      "text" : "Ce groupe s‟est focalisé sur la déduction de nouvelles relations entre évenements. Cette étude sur l‟inférence temporelle a permis d‟établir plusieurs régles d‟inférences reliant les évenements et les expressions temporelles."
    }, {
      "heading" : "7) Conclusion",
      "text" : "Dans ce chapitre nous avons exploré la logique temporelle et ses applications dans le traitement du langage Naturel. Nous avons aussi illustré avec les travaux du groupe (HLTRI) les différents types d‟inférences temporelles existants, Nous avons remarqué que ce groupe ne se base que sur l‟amélioration des détections des relations temporelles existantes entre évenements et expressions temporelles. Nous nous sommes inspirés de ces travaux dans notre façon de procéder pour élaborer le corpus et concevoir nos inférences. Nous allons montrer dans les prochains chapitres comment nous avons concrétisé cet objectif.\nPartie 2\nConception, réalisation et mise en œuvre du\nsystème TIMINF\nRésumé :\nCette partie de notre mémoire est composée de trois chapitres qui regroupent la conception et la réalisation de notre projet. Dans le chapitre trois, nous avons entrepris une démarche expérimentale à base de corpus afin de dégager les différentes classes d‟inférence temporelle et à partir de cette analyse, nous avons conçu l‟architecture du système de reconnaissance d‟inférence textuelle TIMINF présenté dans le chapitre quatre. Nous nous sommes intéressés dans le dernier chapitre à l‟évaluation des sorties de notre système en le confrontant à un corpus de test adapté.\n- Chapitre 3 -\nL‟élaboration et étude du corpus\nChapitre 3\nL‟élaboration et l‟étude du corpus"
    }, {
      "heading" : "1) Introduction",
      "text" : "L‟importance du RTE dans le TALN a poussé les chercheurs à s‟investir dans ce domaine et à explorer différents chemins pour parvenir à détecter et à classifier différents types d‟inférences.\nDans les chapitres précedents, nous avons d‟abord étudié les groupes travaillant sur la reconaissance de l‟inférence textuelle et nous avons remarqué qu‟aucun groupe n‟utilisait l‟inférence temporelle dans son système. Dans le chapitre précedent nous avons étudié le temps dans la langue et nous avons remarqué que les groupes travaillant sur l‟inférence temporelle se base sur l‟amélioration des détéctions des relations temporelles existantes entre évènements et expressions temporelles mais ils n‟essayaient en aucun cas d‟intégrer leurs travaux a un systéme d‟inférence textuelle.\nAfin de répondre au manque de l‟inférence temporelle dans le RTE, notre objectif est d‟intégrer le système de détéction d‟inférence temporelle dans un systéme d‟inférence textuelle. Pour cela, nous avons l‟obligation d‟étudier les relations temporelles qui peuvent exister entre deux ségments de textes à travers un corpus que nous avons élaboré. Ceci nous a permis de distinguer différents types d‟inférences. Nous allons montrer tout au long de ce chapitre comment nous avons concrétisé ces différents objectifs."
    }, {
      "heading" : "2) L‟élaboration du corpus",
      "text" : "La première étape à entreprendre consiste à créer le corpus constitué de paires de textes et hypothèses (T-H) qui correspond à des informations collectées à travers le web dans des domaines différents. Nous avons choisi d‟établir notre corpus en langue anglaise car jusqu'à nos jours les recherches les plus abouties sur l‟inférence temporelle et aussi sur le RTE sont en langue anglaise.\nPour cela, nous avons choisi d‟utiliser le corpus de questions élaborées pour le test par la compagne d‟évaluation des systèmes de recherches d‟informations (clef 9 ) pour l‟année 2006.\n9 Le lien du challenge clef : http://www.elda.org/article225.html\nLe challenge CLEF est crée en 2000 pour fournir une infrastructure visant à soutenir le développement, d'essai et d'évaluation des systèmes de cross-langue de recherche d'information dans plusieurs langues européennes (Français, Italien, Allemand).\nPour pouvoir développer et évaluer notre système, nous avons sélectionné des questions portant sur des événements temporels et nous avons soumis ces questions au système de question-réponse answerbus 10 disponible sur le web. Nous avons récupéré les réponses correspondantes et nous les avons modifiées pour obtenir l‟inférence souhaitée. Nous avons aussi transformé les questions à l‟affirmatif.\nNous illustrons ces démarches par l‟exemple montré ci-dessous :\nLa question numéro 13 du corpus de test de challenge clef 2006:\nIn what year did the catastrophe in Chernobyl happen?\nLa requête va être mise dans le système de question réponse Answerbus. Le résultat est montré ci-dessous :\nNous choisissons la première réponse donnée par le système qui est :\n10 http://www.answerbus.com\nH: It is not by accident that one of the versions explaining the catastrophe at the Chernobyl AES on 26 April 1986 (because smaller-scale accidents happened there before) ties up the cause of the tragedy with experiments at \"Chernobyl-Two\" .\nAussi, nous transformons la question en affirmatif en répondant à la question. Comme résultat nous avons la réponse suivante :"
    }, {
      "heading" : "T: the catastrophe of Chernobyl happens in 1987.",
      "text" : "Finalement nous avons une paire de texte de la forme :"
    }, {
      "heading" : "T: the catastrophe of Chernobyl happens in 1987.",
      "text" : "H: It is not by accident that one of the versions explaining the catastrophe at the Chernobyl AES on 26 April 1986 (because smaller-scale accidents happened there before) ties up the cause of the tragedy with experiments at \"Chernobyl-Two\" .\nComme dans le challenge RTE, les exemples sont divisés en deux types de corpus (corpus de développement et corpus de test).\nLes deux corpus sont constitués de 30 paires de textes et chaque portion du corpus doit inclure 50% d‟exemples avec une inférence vrai 50% d‟exemples avec une inférence fausse. Pour cela, chaque exemple (T-H) paire est jugé par un annotateur pour voir s‟il y a une inférence textuelle dans la paire de texte entre (T-H) ou pas.\nLa figure suivante montre un exemple du corpus après annotation :\nL‟exemple est évalué par un second juge qui évalue les paires de textes et d‟hypothèses, sans avoir pris conscience de leurs contextes.\nLes annotateurs étaient d‟accord avec le jugement dans 86,66 % des exemples, ce qui correspond à 0.6 Kappa qui est une mesure statistique pour calculer a quel point deux personnes A et B sont d‟accord pour classer N éléments dans K catégories mutuellement exclusives, les 13,33% du corpus où il n‟y a pas eu d‟accord ont été supprimés. Le reste du corpus est considéré comme un «gold standard» ou « BASELINE » pour l‟évaluation."
    }, {
      "heading" : "3) Classification de l‟inférence temporelle",
      "text" : "Apres avoir conçu notre corpus, nous avons annoté manuellement les événements, les dates et les différents types d‟inférences (lexicales, syntaxiques et temporelles) existant entre les segments de textes. Cela nous a permis de détecter les différents types d‟inférences temporelles entre les segments de textes. Nous détaillons dans ce qui suit les différentes classes que nous avons distingué:"
    }, {
      "heading" : "3.1) Les inférences entre expressions temporelles",
      "text" : "L‟inférence permet d‟établir des relations temporelles liant date, heure et durée entre elles. Dans le même contexte, nous avons distingué trois types d‟inférences temporelles liant des expressions temporelles.\nCette figure représente le nombre de paires de textes pour chaque sous classe d‟inférence dans notre corpus de développement.\nDans ce qui suit, nous présentons les trois types d‟inférences :"
    }, {
      "heading" : "3.1.1) Les inférences entre dates",
      "text" : "C‟est la relation temporelle entre qui peut y avoir entre les dates du texte T et les dates du texte H.\nL‟exemple suivant permet de montrer la relation qui peut exister entre les dates.\nExemple 1:\n<pair id=\"8\" value=\"TRUE\" > T: the football world cup finished on t1: july 12 th 2006. H: the football world cup finished in t2: july 2006.\nDans cet exemple, nous remarquons que l‟inclusion entre les deux dates t1 et t2 a permis d‟avoir l‟inférence temporelle.\nExemple 2:\n1) <pair id=\"1\" value=\"TRUE\" > T: the second world war finished in t1: 1945. H: the end of the second world war took part t2: between 1940 and 1950.\nDans cet exemple nous remarquons aussi que l‟inclusion entre les deux dates t1 et t2 a permis d‟avoir l‟inférence temporelle."
    }, {
      "heading" : "3.1.2) Les inférences entre adverbiaux temporels",
      "text" : "L‟inférence permet d‟établir une relation temporelle entre adverbiaux de référence temporelle qui exprime la localisation d‟un événement dans le temps. L‟exemple suivant permet de montrer la relation qui peut exister entre deux adverbiaux temporels.\nExemple 1:\n<pair id=\"15\" value=\"TRUE\" > T: he has worked during 10 days. H: He has worked for many days.\nDans cet exemple, nous pouvons remarquer que l‟adverbial temporel « During 10 days » l‟infère l‟adverbial « many days ».\nExemple 2:\n14) <pair id=\"14\" value=\"TRUE\" > T: the day before yesterday, Paul disappeared. H: two days ago, Paul disappeared.\nDans cet exemple nous remarquons que l‟adverbial temporel « the day before yesterday» infère l‟adverbial « two days ago»."
    }, {
      "heading" : "3.1.3) Les inférences entre dates et adverbiaux temporels",
      "text" : "L‟inférence permet d‟établir des relations temporelles entre dates et adverbes. L‟exemple suivant permet de montrer la relation qui peut exister entre un adverbial temporel et une date.\nExemple 1:\n18) <pair id=\"18\" value=\"TRUE\" > T: the building collapsed at 2 o‟clock p.m. H: in the afternoon the building collapsed.\nDans l‟exemple précédant nous pouvons remarquer que « 2 o‟clock p.m » infère l‟adverbial «the afternoon ».\nExemple 2:\n19) <pair id=\"19\" value=\"TRUE\" > T: Mark has arrived on Monday, the day after Celine has arrived. H: Celine has arrived on Tuesday.\nDans l‟exemple précédant nous pouvons remarquer que si nous ajoutons « the day after » à « Monday» nous arrivons à «Tuesday». Ceci implique une inférence entre ces adverbiaux temporels."
    }, {
      "heading" : "3.3.2) Les inférences entre évènements",
      "text" : "L‟inférence permet d‟établir des relations temporelles entre événements. Dans ce contexte, nous avons détecté deux types d‟inférences, une qui demande la relation entre événements pour détecter l‟inférence, et l‟autre ne demande que l‟inférence lexico sémantique. Cette figure présente le nombre de paires de textes dans chaque sous classe dans le corpus."
    }, {
      "heading" : "3.3.2.1) Les relations entre évènements temporels",
      "text" : "La relation temporelle entre événements est établie par rapport aux relations qu‟elle peut avoir avec d‟autres événements dans le texte.\nL‟exemple suivant permet de montrer la relation qui peut exister entre un adverbial temporel et une date.\nExemple 1:\n22) <pair id=\"22\" value=\"TRUE\" > T: since the death of Turing, the scientific community gives the Turing prize to researchers who found out discoveries in computer science. H: The Turing prize was not given before the death of Turing.\nDans l‟exemple précédent, nous pouvons apercevoir que les deux événements « given » apparaissant dans les deux segments dépendent d‟autres événements « the death of turing » pour se situer dans le temps.\nExemple 2:\n23) <pair id=\"23\" value=\"TRUE\" > T: Algeria has become independent. H: before its independence Algeria was colonized.\nDans l‟exemple précédent, nous pouvons apercevoir que l‟événement « independent » apparaissant dans le segment H, dépendent de l‟événement « was colonized » pour se situer dans le temps."
    }, {
      "heading" : "3.3.2.2) Les inférences lexico sémantiques",
      "text" : "La relation temporelle entre événements est établie par rapport aux relations sémantiques qui peuvent exister entre eux. L‟exemple suivant permet de montrer la relation lexico-sémantique existante entre deux évènements.\nExemple 1:\n26) <pair id=\"26\" value=\"TRUE\" > T: France has won the match against Brasil. H: France has played the match against Brasil.\nDans l‟exemple précédent, nous pouvons constater que l‟évènement « won » se produit après l‟évènement « played ».\nExemple 2:\n27) <pair id=\"27\" value=\"TRUE\" > T : Amine was dreaming . H : Amine was sleeping deeply. Dans l‟exemple précédant nous pouvons constater que l‟évènement « was dreaming» se produit durant l‟évènement « was sleeping deeply»."
    }, {
      "heading" : "3.3.4) Les inférences entre évènements et expressions temporelles",
      "text" : "L‟inférence permet d‟établir des relations temporelles entre événements et expressions temporelles. Cette figure représente le nombre de paires de textes où existe ce type d‟inférence.\nL‟exemple suivant permet de montrer la relation temporelle existante entre évènements et expressions temporelles. Exemple 1:\n29) <pair id=\"29\" value=\"TRUE\" > T: Japan gave weapons back after the explosion of the first atomic bomb. H: Japan gave weapons back in 1945.\nDans l‟exemple précédent, nous pouvons remarquer que l‟évènement « the explosion of the first atomic bomb » est ancré temporellement avec l‟expression temporelle «1945 ».\nExemple 2:\n30) <pair id=\"30\" value=\"TRUE\" > T: Germany has become unified since the fall down of the Berlin wall. H: Germany unified 19 years ago.\nDans l‟exemple précédent, nous pouvons remarquer que l‟évènement «the fall down of the Berlin wall» est ancré temporellement avec l‟expression temporelle «19 years ago».\n4) Le bilan de l‟étude du corpus\nDans notre élaboration du corpus, nous nous sommes limités à des segments de textes relativement brefs et concrets. Nous retrouvons dans ce corpus des inférences temporelles sous des formes variées. Le tableau suivant représente le pourcentage de paires du corpus de développement par type d‟inférence temporelle existante, sachant qu‟il existe 30 paires dans notre corpus.\nTypes d‟inférences\ntemporelles\nNombres de paires\nInférences entre expressions\ntemporelles\n21/30\nInférences entre évènements\n6/30\nInférences entre évènements\net expressions temporelles\n3/30\nTableau 3.1 : Nombre de paire dans le corpus\nCette figure représente le pourcentage de paires de chaque type d‟inférence dans le corpus de développement :\nNous constatons que notre corpus de développement a un pourcentage élevé de paires contenant une inférence temporelle entre expression temporelle et cela est dû à une forte présence de questions d‟ordres temporelles extraites du corpus de test du challenge clé. Les détails des corpus de test et de développement sont disponibles en annexe."
    }, {
      "heading" : "5) Conclusion",
      "text" : "Dans ce chapitre nous avons expliqué, comment nous avons élaboré un corpus contenant des paires de segments de textes integrant des relations temporelles, ensuite nous avons fait une classification des différents types d‟inférences temporelles existantes dans le corpus. La suite logique de ce travail consiste à déduire des régles d‟inférences temporelles et à les intégrer à un systéme d‟inférence texuelle. Ces démarches sont l‟objet du chapitre suivant que nous allons exposer.\n- Chapitre 4 -\nLa présentation du système TIMINF\nChapitre 4"
    }, {
      "heading" : "La présentation du système TIMINF",
      "text" : ""
    }, {
      "heading" : "1) Introduction",
      "text" : "Nous présentons, dans ce chapitre notre projet d‟inférence temporelle, nommé TIMINF. Ce projet a pour but de développer et d‟évaluer l‟apport de l‟inférence temporelle dans la reconnaissance de l‟inférence textuelle.\nL‟un des principaux défis de ce type de système est de permettre aux systèmes d‟inférences textuelles, d‟ouvrir un voile sur l‟inférence temporelle et d‟explorer cette nouvelle approche. Dans ce cadre, l‟objectif de TIMINF est de définir ce que devrait être un système d‟inférence textuelle intégrant l‟aspect temporel dans son fonctionnement, qui tient en compte la relation entre expression temporelle et relation entre les évènements dans la déduction de l‟inférence textuelle.\nNous allons montrer tout au long de ce document comment nous avons concrétisé cet objectif. Nous décrivons alors les principaux modules constituant le système."
    }, {
      "heading" : "2) Architecture informatique de TIMINF",
      "text" : "L‟architecture générale de TIMINF, telle que déduite de l‟analyse du corpus présenté au chapitre précédant, est illustrée dans la figure 4.1 suivante. Cette dernière s‟articule autour de trois étapes essentielles qui sont :\n Le prétraitement qui permet de repérer les données temporelles et les composants syntaxiques de la paire de texte (T, H).\n L‟inférence textuelle qui contient les modules de test d‟inférence textuelle et du balisage des expressions temporelles.\n L‟inférence temporelle qui contient les moteurs d‟inférence et les règles d‟inférences.\nFigure 4.1 : Architecture du système TIMINF\nDans ce qui suit nous présentons les différents modules constituants le système TIMINF.\nAnalyse\nsyntaxique T TARSQI\nBalisages des expressions temporelles non détectées par TARSQI\nSuperviseur\nYE YES\nRee Règles d‟inférences\nRee Paire de texte\nRee Ressources\nl‟inguistiques\nT Test d‟inférence\nT temporelle\nYES NO\nD Test\nd‟inférence textuelle\nD pré traitement\nInférence entre sujets\nInférence entre événements"
    }, {
      "heading" : "2.1) Le prétraitement",
      "text" : "Le prétraitement est effectué par les deux modules TARSQI et LINK parseur. Ces deux modules s‟exécutent en parallèle et nous permettent respectivement de repérer les données temporelles et les composants syntaxiques de la paire de texte (T, H). Nous détaillerons dans ce qui suit les deux modules et leurs utilisations dans notre système."
    }, {
      "heading" : "2.1.1) Le projet TARSQI",
      "text" : "TARSQI est un outil permettant d‟organiser des textes en langages naturels en fonction de leurs caractéristiques temporelles (Pustejovsky et al., 2003). Son objectif est d‟annoter les données temporelles dans un texte en langage naturel, d'extraire des données temporelles à partir de textes et d‟effectuer des raisonnements sur les données temporelles (http://www.timeml.org). Afin de répondre à ces différents objectifs, le module TARSQI utilise les balises TimeML pour marquer les expressions temporelles, les événements, les relations temporelles et les Subordinations syntaxiques des événements. Le système TARSQI est mis en place comme une cascade de modules successivement ajoutés. L'architecture du système est définie dans le schéma ci-dessous.\nFigure 4.2 : Architecture du module TARSQI\ninf(e1,e2 )=vrai\ndocument entrant : étiqueté par TreeTagger\nGUTime : détection des expressions temporelles\nSlinket : identifie les relations subordonnées entre deux événements\nSputLINK : détection des relations implicites entre événements\nGUTenLINK : représente la relation entre deux objets temporels\nE Evita : système de reconnaissance d‟événements\nDocument TimeML\nLe module TARSQI doit avoir comme entrée des documents prétraités syntaxiquement. Pour cela, les concepteurs de TARSQI ont choisi d‟utiliser une analyse morphosyntaxique avec le module TreeTagger.\nDans ce qui suit nous allons décrire le module TreeTagger."
    }, {
      "heading" : "2.1.1.1) TreeTagger",
      "text" : "C‟est un système d'étiquetage automatique des catégories grammaticales des mots avec lemmatisation et tokenisation (Helmut Schmid, 1994) (www.ims.unistuttgart.de/projekte/corplex/TreeTagger/).\nLe module Treetagger a comme entrée un texte brut et il admet deux types de sorties :\nA) Une sortie en forme de tableau\nComme il est montré dans l‟exemple suivant (figure 4.3), le mode de sortie est un tableau représentant l‟étiquetage des mots dans la phrase.\nSachant que :\nMot : représente le mot étiqueté.\nPOS : représente la catégorie grammaticale du mot par exemple (VB pour verbe, DT pour un déterminant…..).\nLemme : représente la lemmatisation du mot.\nB) Sortie format XML\nAvec La sortie format XML, chaque mot est tagué avec les balises de TreeTagger.\nExemple d‟entrée, sortie TreeTagger :\nLes balises utilisées par TreeTagger sont :\n <BODY> contient le corps du document.\n <TEXT> contient le texte.\n Les phrases doivent être marquées d'un <s>.\n Le groupe nominal est balisé avec <NG> et le groupe verbal avec <VG>.\n chaque mot dans la phrase est balisé par <LEX>.\nLes attributs utilisés par TreeTagger sont :\n Stem : représente la lemmatisation du mot qui est balisé.\n Pos : donne la catégorie grammaticale du mot balisé. (DT pour déterminant-nom, PP pour une préposition…). pour en savoir plus sur les différents symboles utilisés\npar Treetagger pour étiquetter les différentes catégories grammaticales, toutes les définitions des symboles sont disponibles sur le site (www.ims.unistuttgart.de/projekte/corplex/TreeTagger/)."
    }, {
      "heading" : "2.1.1.2) GUTime",
      "text" : "L'étiqueteur GUTime, développé à l'Université de Georgetown, utilise TIMEX3 tag pour représenter les expressions temporelles, telles que : les dates, les heures, les durées, etc (Mani et Wilson, 2000).\nIl existe 3 types d‟informations temporelles détectées par TIMEX3.\nDATE : c'est-à-dire les années, les mois et les jours.\nExemple:\nUSA were touched by terrorism in September 11, 2001.\nTIME : c'est-à-dire les heures de la journée.\nExemple:\nThe building collapsed at 2 o'clock p.m.\nDURATION : représente un intervalle de temps entre deux dates.\nExemple:\nThe end of the second world war happened between 1940 and 1950.\nUn exemple de sortie du module GUTime est montré ci-dessous :\nLes attributs de TIMEX3 dans l‟exemple sont :\nTid : donne l‟identifiant de l‟expression temporelle, pour chaque expression tagger par TIMEX a son propre identifiant. Type : chaque TIMEX est assigné à ces différents types {DATE, TIME, DURATION}. TemporalFunction : c‟est un attribut qui retourne si la date est précise dans le temps ou pas.\nExemple:\nNext Tuesday  TemporalFunction= true. September 11,2001 TemporalFunction= false.\nAnchorTimeID : s‟il y a un ancrage temporel de l‟expression temporelle identifiée par Tid avec une autre expression temporelle, AnchorTimeID donne son identifiant."
    }, {
      "heading" : "2.1.1.3) Evita",
      "text" : "Evita est un système de reconnaissance d‟événements, pour cela le module utilise deux balises de TIMEML (EVENT et MAKEINTANCE) qui sont décrites ci-dessous :\nA) EVENT\nEVENT est utilisé pour annoter les événements dans un texte, syntaxiquement, les évènements sont généralement des verbes, mais un nom peut aussi être utilisé pour dénoter un événement. Les différentes classes d‟événements qui sont détectées sont représentées ci-dessous.\n occurence : la plupart des événements font partie de cette classe. Ils décrivent ce qui se produit dans le monde.\n state : les états décrivant les circonstances dans lesquelles un événement a lieu et dont l‟état peut être modifié ; et les états introduits par les i-action, i-state et reporting.\n Reporting : description de l‟action d‟une personne par un acte narratif.\n i-action : une action intentionnelle introduisant un autre événement, comme un essai, une enquête, un rapport, un ordre, une demande, une promesse, une nomination.\n i-state : similaire à i-action mais pour identifier un état tel que penser, ressentir. suspecter, douter, vouloir, désirer, détester, être prêt, être capable.\n aspectual : un événement débutant, terminant ou continuant une action.\n Perception : constatation physique d‟un événement telle qu‟entendre ou voir l‟action.\nB) MAKEINSTANCE\nMAKEINSTANCE est une réalisation de lien, il indique les différentes instances d'un événement donné.\nDans l‟annotation, les <EVENT> ne participe jamais à une relation, c‟est la réalisation (<MAKEINSTANCE>) de l‟événement qui y participe et chaque EVENT introduit au moins un correspondant MAKEINSTANCE.\nUn exemple de sortie du module Evita est montré ci-dessous:\nLes attributs de EVENT dans l‟exemple sont : Eid : donne l‟identifiant de l‟évènement, pour chaque évènement tagger par EVENT a son propre identifiant. Class : détermine la classe auquel appartient l‟évènement. Les attributs de MAKEINSTANCE dans l‟exemple sont : eventID : donne l‟identifiant de l‟évènement, pour chaque évènement tagger par EVENT a son propre identifiant. Eiid : instance de l‟événement trouvé dans le texte. Pos : donne la catégorie grammaticale du mot balisé. Tense : donne le temps de l‟évènement si l‟évènement est un verbe."
    }, {
      "heading" : "2.1.1.4) GutenLink",
      "text" : "GutenLink est un module de TARSQI qui utilise les balises TLINK de TIMEML pour représenter la relation entre deux objets temporels, que ce soit deux événements, deux marqueurs temporels ou un marqueur temporel et un événement. Il y a quatorze types de relations identifiées par le module, bien que certaines soient simplement l‟inverse d‟autre :\n before et after spécifient qu‟un objet temporel précède ou suit l‟autre objet temporel de la relation ;\n ibefore et iafter spécifient qu‟un objet temporel est immédiatement avant ou après un autre.\n includes et is-included spécifient qu‟un objet temporel inclut ou est inclus dans un autre, p. ex. John arrived in Montreal yesterday.\n during spécifie que l‟état ou l‟événement se poursuit durant une période de temps, p. ex. John taught for 90 minutes.\n during-inv est l‟inverse de la relation précédente.\n simultaneous spécifie que deux instances d‟événements semblent coïncider dans le Temps.\n identity indique que deux objets temporels représentent le même événement.\n begins spécifie qu‟un événement débute par l‟objet temporel avec lequel il est lié.\n begun-by est l‟inverse de begin, elle relie un objet temporel à un événement débutant par l‟objet temporel.\n ends et ended-by sont similaires aux deux relations précédentes sauf qu‟elles Spécifient la fin de l‟événement.\nUn exemple de sortie du module GutenLink est montré ci-dessous :\nLes attributs de TLINK dans l‟exemple sont :\neventInstanceID : donne l‟identifiant de l‟évènement. relatedToTime : donne l‟identifiant de l‟expression temporelle. relType : donne la relation temporelle existant entre les l‟expressions temporelles, ils utilisent pour cela les relations d‟Allen."
    }, {
      "heading" : "2.1.1.5) Slinket",
      "text" : "Les liens subordonnants <SLINK> identifient les relations entre deux événements. Ils sont habituellement introduits par des verbes modaux qui impliquent une confirmation.\nLes liens subordonnants sont définis selon six types de relations qui interagissent avec les classes d‟événements reporting, i-state et i-action (modal introduit la possibilité d‟un événement, p. ex. John promised Mary to buy some beer).\nLes différentes classes d‟événements qui sont détectées sont représentées ci-dessous.\n evidential introduit la perception ou le compte-rendu de l‟événement, p. ex. Johnsaid he bought a pack of beer.\n neg-evidential introduit la perception ou rapporte que l‟événement ne s‟est pas réalisé, p. ex. John denied he bought beers\n factive est une action qui implique ou présuppose qu‟un événement a déjà eu lieu, p. ex. John managed to leave the party.\n counter-factive est la négation de la relation précédente p. ex. John forgot to buy beers.\n conditional indique que la réalisation de l‟action entraînera l‟événement en relation.\nUn exemple de sortie du module SLINKET est montré ci-dessous:\nLes attributs de SLINK dans l‟exemple sont :\neventInstanceID : c‟est l‟identifiant de l‟évènement concerné par la relation de subordination. subordinatedEventInstance : c‟est l‟identifiant de l‟évènement subordonné. relType : donne la relation temporelle existante entre entités."
    }, {
      "heading" : "2.1.1.6) SputLink",
      "text" : "Le module SputLink effectue des inférences temporelles en tenant compte des relations temporelles déjà générées par les modules qui le précèdent, c‟est-à-dire (GUTenLINK et Slinket) et génère de nouvelles relations temporelles. SputLink est fondé sur l‟algèbre d‟intervalle fondé par James Allen's en 1983. Allen réduit tous les évènements et expressions de temps à 13 intervalles de bases et identifie les relations entre les intervalles. Les informations temporelles dans un document sont représentées comme un graphe où les événements et les expressions temporelles forment les nœuds, les relations temporelles forment les arcs.\nExemple\nEvenement Before(a,b)= a précéde b A B C A C\nFigure 4.9: Inférence effectué par le module SputLINK\nAinsi, si A précède B et B précède C. des deux relations, on déduit que A précède C.\n2.1.1.7) L’utilisation de TARSQI\nAfin de permettre la portabilité du module TARSQI, les concepteurs ont proposé deux formats d‟entrée possible à TARSQI qui sont décrits ci-dessous:\nA) Format simple–xml\nAvec ce format, l‟analyse morphosyntaxique est incluse dans le module TARSQI. L‟entrée est représentée par le format suivant:\nExemple d‟entrée simple-xml.\nBefore(A,B) Before(B,C) Before(A,C)\nLes balises de simpe_xml :\n <DOC> pour annoter le début et la fin du document.\n <DOCID> contient le type du document.\n <TEXT> contient le texte.\nB) Format RTE3\nAvec ce format, l‟analyse morphosyntaxique n‟est pas incluse dans le module TARSQI et nous avons comme entrée le format RTE3, qui est le résultat d‟un prétraitement effectué par le groupe COGEX qui travaille sur le RTE. Le groupe a choisi de développer son propre prétraitement.\nNous présentons dans ce qui suit un exemple de sortie du format RTE3 :\nExemple :\n<XML version=\"1.0\" ?>\n<pair length=\"short\" task=\"IE\" id=\"1\">\n<t><s>text1</s></t>\n<br/><h><s><NG>\n<HEAD><lex start=\"0\" end=\"12\" pos=\"NNP\" stem=\"Le Beau Serge\">Le Beau Serge</lex> </HEAD></NG><VG><lex start=\"14\" end=\"16\" pos=\"VBD\" stem=\"be\">was</lex>\n<HEAD><lex start=\"18\" end=\"25\" pos=\"VBN\" stem=\"direct\">directed</lex> </HEAD></VG>\n<HEAD><lex start=\"27\" end=\"28\" pos=\"IN\" stem=\"by\">by</lex> </HEAD><NG>\n<HEAD><lex start=\"30\" end=\"36\" pos=\"NNP\" stem=\"Chabrol\">Chabrol</lex> </HEAD></NG><lex start=\"37\" end=\"37\" pos=\".\" stem=\".\">.</lex> </s></h>\n</pair>\nFigure 4.11 : Sortie du module GutenLink\nLes balises du format RTE3 sont :\n Les phrases doivent être marquées d'<s>.\n Les groupes nominaux sont balisés avec <NG> et les groupes verbaux avec <VG>.\n Les débuts de phrases sont marqués par des balises <HEAD>.\n <t> représente la premier phrase et <s> représente la deuxième phrase.\n <pair> représente la paire de phrases.\nLes attributs :\n Start : représente la position du caractère de début de la chaine dans le texte.\n End : représente la position du caractère de fin de la chaine dans le texte.\n Stem : représente la lemmatisation du mot qui est balisé.\n Pos : donne la catégorie grammaticale du mot balisé."
    }, {
      "heading" : "2.1.1.8) L’intégration de TARSQI au système TIMINF",
      "text" : "Dans notre système d‟inférence, nous avons utilisé le format simple-xml au lieu de RTE3 car nous avons choisi d‟utiliser le module TreeTagger pour l‟analyse morphosyntaxique qui est intégré dans le module TARSQI dans le format simple-xml.\nEn plus de la détection des expressions temporelles, la phase de prétraitement intègre l‟analyse syntaxique pour détecter la relation grammaticale entre les mots dans une phrase. Dans ce qui suit, nous allons présenter l‟outil que nous avons choisi pour effectuer l‟analyse syntaxique."
    }, {
      "heading" : "2.1.2) L‟analyse syntaxique",
      "text" : ""
    }, {
      "heading" : "2.1.2.1) Présentation de link grammar parser",
      "text" : "Nous avons utilisé le Link Grammar Parser (Sleator et Temperley, 1991) qui est un analyseur syntaxique de la langue anglaise, basé sur la dépendance syntaxique. Partant d’une phrase fournie en entrée, cet analyseur produit un ou plusieurs graphes de dépendances, qui consistent en un ensemble de liens reliant des paires de mots. Les nœuds du graphe sont les mots de la phrase. Certains d’entre eux ont un suffixe qui indique la partie du discours (nom, verbe, adjectif,adverbe, préposition, etc.).\nLes arcs étiquetés relient les nœuds du graphe. Chaque étiquette précise un rôle grammatical (D pour déterminant-nom, S pour sujet-verbe…). Dans ce qui suit, nous montrons un exemple de sortie du parseur Link Grammar Parser. Exemple :\nLes définitions des différents liens représentés dans le graphe sont les suivantes :\nEE adverbe se connecte à un autre adverbe. Ssconnecte le sujet au verbe. Xpconnecte le début et la fin de la phrase. MVaconnecte le verbe à l‟adverbe. Wd le premier mot est un sujet. .v verbe. .e adverbe. LEFT-WALL  détermine le début de la phrase.\nPour en savoir plus sur les différents symboles utilisés par Link Grammar Parser pour étiqueter les différents liens grammaticaux, toutes les définitions des symboles sont disponibles sur le lien suivant (www.link.cs.cmu.edu/link/)."
    }, {
      "heading" : "2.1.2.2) L’intégration du link parser à notre système",
      "text" : "Concrètement l‟analyseur syntaxique nous a permis de détecter les sujets dans les deux segments de textes (T, H) et de les baliser avec nos propres balises comme il figure dans l‟exemple suivant.\nExemple:\n<pair id=\"28\" value=\"TRUE\" > <s> <syntax type: sujet>Poland</syntax> became a communistic state in 1945.</s><s> <syntax type: sujet>Poland</syntax> has become a communistic state since the invasion of Russians.</s>\nLa balise <syntaxe type: sujet>sujet</syntaxe> est choisi pour baliser les sujets dans la paire(T, H).\nApres l‟analyse syntaxique et le traitement par TARSQI, la paire de texte est prête à être soumise au test d‟inférence textuelle qui a besoin des prétraitements effectués précédemment pour tester l‟inférence textuelle. Dans ce qui suit nous décrivons les différents constituants de la phase de test d‟inférence textuelle."
    }, {
      "heading" : "2.2) Les tests d‟inférences textuelles",
      "text" : "La deuxième phase s‟articule autour de deux modules. Le premier permet de tester l‟inférence textuelle pour savoir s‟il y a une inférence textuelle ou pas et le deuxième module permet de détecter les expressions temporelles non détectées par TARSQI. Les deux modules exploitent des ressources linguistiques.\nDans ce qui suit nous allons présenter les deux modules et les ressources linguistiques utilisées :"
    }, {
      "heading" : "2.2.1) Les tests d‟inférences entre événements et entre sujets",
      "text" : "Le but de ce module est de détecter s‟il y a une inférence textuelle entre les deux paires de textes (T, H).\nLe module est mis en place comme une cascade de sous modules successives. Le premier module détecte les inférences textuelles entre les sujets des deux segments de textes (T, H) et\nle deuxième détecte les inférences textuelles entre évènements des deux segments de textes (T, H).\nNous décrivons ci-dessous les deux modules d‟inférences :\n2.2.1.1) L‟inférence entre sujets\nLe module d‟inférence entre sujets détecte s‟il y a une inférence textuelle entre les sujets du texte H avec les sujets du texte T. Pour cela, le module utilise les sorties du module LINK parser c'est-à-dire que pour chaque sujet détecté, dans le texte H nous recherchons s‟il y a une relation de synonymie avec un des sujets du texte T. Pour cela, le module emploie WordNet pour retrouver toutes les relations ontologiques qui lient les deux entités (l‟utilisation de wordNet dans notre système est détaillée dans le chapitre cinq). Aussi nous utilisons le comptage de mots pour comparer des groupes de mots (l‟algorithme de comptage de mots est expliqué dans l‟exemple (1)).\nCe module accepte comme entrée au module le résultat de l‟analyse syntaxique des paires de texte T et H et en sortie il existe deux possibilités :\n Si le module trouve une équivalence entre deux sujets, il déclenche le module d‟inférence entre événements en lui envoyant les événements correspondants aux\ndeux sujets.\n Si le module ne trouve pas d‟équivalence entre sujets, le module envoie le message « pas d‟inférence » au module du test d‟inférence.\nExemple (1) : paire numéro 3 du corpus de développement.\nFigure 3.12 : exemple d‟inférence entre sujets\nFigure 3.15 : Exemple d‟inférence entre sujets\nDans l‟exemple suivant le module détecte tous les sujets contenus dans le segment T et le segment H et les met dans deux listes différentes, ensuit il effectue la comparaison entre les évènements des deux listes.\nDans notre exemple la première liste ne contient qu‟un seul sujet {S1} et la deuxième liste contient le sujet {S2}. Une relation d‟équivalence est détectée entre les évènements S1 et S2.\nT: The Algerian revolution war started on 1st November 1954 and\nS1\ncaused the death of 1, 5 million of martyrs and lasted 7 years.\nH: The Algerian war ended in July 5 th, 1962.\nS2\nRelation d‟équivalence entre S1 et S2\nPour détecter l‟équivalence le module utilise l‟algorithme de comptage de mots pour déduire l‟inférence entre «the Algerian war » et « the Algerian revolution war».\nLe comptage de mots : L‟algorithme récupère les deux groupes deux mots dans deux listes différents et compare chaque mot d‟une liste avec les mots contenu dans la deuxième liste et s‟il y a un seul mot qui est semblable ou sous mot d‟un mot de la deuxième liste, il considère qu‟il y a une inférence entre sujets."
    }, {
      "heading" : "2.2.1.2) L‟inférence entre évènements",
      "text" : "Le module d‟inférence entre évènements détecte s‟il y a une relation ontologique entre les deux évènements reçus du module d‟inférence entre sujets. Pour cela, le module emploie WORDNET pour retrouver toutes les relations qui lient les deux entités.\nLe module a comme entrée les évènements reçus du module d‟inférence entre sujets et le balisage de TARSQI et comme sortie les résultats suivants :\n S‟il trouve une équivalence entre deux évènements, il envoie le message « oui» au module de test d‟inférence.\n S‟il trouve deux évènements contraires, il envoie le message « non » au module de test d‟inférence.\n S‟il ne trouve pas de relation entre événements, il envoie le message « pas d‟inférence » au module de test d‟inférence.\nExemple :\nFigure 4.16 : Exemple d‟inférence entre évènements\nDans l‟exemple ci-dessus le module détecte une liste d‟évènements dans le texte T {E1, E2, E3} et une autre liste d‟évènements dans le texte H {E1} et effectue la comparaison entre les évènements des deux listes. Une relation ontologique (synonymie) est détectée entre les évènements E4 et E3.\nT: the Algerian revolution war started in 1 November 1954 and\nE1\ncaused the death of 1,5 million of martyrs and finished 7 years.\nE3 E3\nH : the algerian war ended in july 5, 1962.\nE4\nRelation de synonymie entre E4 et E3"
    }, {
      "heading" : "2.2.2) Le balisage des expressions temporelles non détectées par",
      "text" : "TARSQI\nNous avons remarqué qu‟au niveau de la détection des expressions temporelles, les modules de balisages existant ont un manque au niveau de la détection des entités nommées et des adverbiaux temporels.\nDans ce qui suit nous montrons les différentes balises utilisées :\nEntités nommées : elles sont balisées par <NE TYPE=\" \" Val=‟‟ „‟>entité nommée</NE>.\n TYPE contient le type d‟expression temporelle {date, durée}.\n Val contient la date ou la durée correspondante.\nExemple :\nFigure 4.17 : Exemple de balisages d‟expressions temporelles\nNotre objectif avec le balisage de « the fall down of the Berlin Wall» est de repérer l‟évènement dans le temps.\nDans l‟exemple précédent le balisage avec le module TARSQI ne détecte que « fall » comme événement et ne le relie pas à une date.\nAdverbiaux temporels : ils sont balisés par <TIMEX3 tid=\"t\" TYPE=\" \" VAL=\"\" >\n TYPE contient le type d‟expression temporelle {date, durée}.\n Val contient les entités que nous avons mises pour représenter les expressions temporelles.\nDans ce qui suit nous relions à chaque expression les symboles correspondants.\n Les jours de la semaine c‟est à dire {Monday, Tuesday, Wednesday, Thursday, Friday Saturday, Sunday} sont représentés respectivement par des nombres de 1\nà 7,\nT: Germany has become unified since t2: the fall down of the Berlin Wall.\nH: Germany unified t1: 19 years ago.\nT2 est balisé ainsi:\n<NE TYPE=\" date \" Val=‟‟ 1989 „‟> the fall down of the Berlin Wall</NE>.\n {Day before yesterday, two days ago, Yesterday}, sont représentés respectivement par {-2, -2, -1}\n {everyday often} sont représentés avec {often}.\n {Someday, Many days, morning, evening, Afternoon} sont représentés respectivement par PSD, PMD, aMORNING, aNIGHT et AFTERNOON."
    }, {
      "heading" : "2.3) Les Ressources linguistiques",
      "text" : "Deux types de ressources sont utilisés :"
    }, {
      "heading" : "2.3.1) Les ressources externes",
      "text" : "Dans la conception de notre module d‟inférence, l‟utilisation d‟une ressource lexicale est indispensable au bon fonctionnement des deux modules (inférence entre sujets et inférence entre événements). Pour cela, nous avons choisi d‟utiliser Wordnet qui est la base de données lexicale qui correspond le plus à notre besoin en termes de relations ontologiques entre mots."
    }, {
      "heading" : "2.3.1) Les ressources internes",
      "text" : "Ce module est en fait une base de données lexicale contenant les différentes entités nommées qui sont utilisées par le module de balisage pour annoter les expressions temporelles non détectées par le module TARSQI. Puisque notre objectif est de se focaliser sur l‟inférence entre expressions temporelles, non pas sur leur détection, nous avons effectué une annotation manuelle de ces expressions temporelles sachant qu‟il existe des logiciels payant qui peuvent effectuer la détection."
    }, {
      "heading" : "2.4) Les tests d‟inférences temporelles",
      "text" : "Cette phase permet de détecter s‟il y a une inférence temporelle et aussi textuelle entre les deux segments de textes T et H. Pour cela, nous utilisons un superviseur qui communique avec une base de règles d‟inférences et d‟après les résultats de la phase précédente (phase de test d‟inférence textuelle), il décide de la règle à utiliser.\nDans ce qui suit nous décrivons les modules constituants cette phase."
    }, {
      "heading" : "2.4.1) Les règles d‟inférences",
      "text" : "Les règles d‟inférences sont divisées en deux groupes.\nGroupe 1 : contient les fonctions qui testent si les événements ont un ancrage temporel identique.\nGroupe 2 : contient les fonctions qui testent si les événements ont un ancrage temporel différent.\n2.4.1.1) Définition des fonctions utilisées dans l‟abstraction des règles\nd‟inférences\nDans ce qui suit, nous allons définir toutes les fonctions que nous avons utilisées dans l‟abstraction de nos règles d‟inférences.\nSachant que S représente un des textes T ou H de la paire, E représente un événement dans le texte et t représente une expression temporelle.\n <S, E>: indique que l‟événement E est dans le segment de texte S.\n Subj (<S, E>): la fonction retourne le sujet de l‟évènement E dans le segment S.\n Equivalent (<S,E1>,<S,E2>): la fonction retourne s‟il y a une équivalence entre E1 et E2 ou pas.\n Contraire (<S,E1>,<S,E2>): la fonction retourne s‟il y a une antonymie entre E1 et E2 ou pas.\n Inclut (<S,t>,<S,t>): la fonction retourne si t est inclut dans l‟intervalle de t‟ ou pas.\n Egale (<S, t1>,<S, t2>): la fonction retourne s‟il y a une équivalence entre t1 et t2 ou pas.\n Début (<S,t>,<S,E>,type): la fonction et booléen et renvoi vrai ou faux, si t est la date de debut de l‟événement E ou pas.\n After(<S,E1>,<S,E2>,type): la fonction retourne s‟il y a une équivalence entre t1 et t2 ou pas.\n before(<S,E1>,<S,E2>,type): la fonction retourne si E1 est avant E2 ou pas .\n Fin (<S,E>,<S, t>,type): la fonction retourne si t est la date de fin de l‟événement E ou pas.\n Relation (<S, E>,<S,t>,type): indique s‟il y a une relation TLINK entre l‟événement E et la date t. Tel que l‟argument type indique le type d‟expression temporelle {date,\ndurée}.\n Inf (T, H): indique, en sortie s‟il y à une inférence entre les segments de textes T et H ou pas.\n Somme(<S, t1>,<S,t2>): renvoi en sortie la somme des deux dates.\n Différence(<S, t1>,<S,t2>): renvoi en sortie la différence entre les deux dates.\nLes symboles utilisés dans les schémas de représentation de nos règles d‟inférences sont présentés ci-dessous :\n: représente le lien entre les deux évènements.\n: représente le lien entre les deux expressions temporelles.\n: représente les éléments du texte T.\n: représente les éléments du texte H.\n: représente le lien entre les événements et expressions temporelles.\n: représente l‟événement.\n: représente l‟expression temporelle.\n.t : représente une date.\n.e : représente un évènement.\n.d : représente une durée.\nAinsi, les différentes règles d‟inférences conçues sont reparties comme suit :"
    }, {
      "heading" : "4.1.1.2) Les règles du groupe 1",
      "text" : "Ces règles permettent de savoir s‟il y a un ancrage temporel entre évènements.\nSi équivalent (<T, e1>, <H, e2>) ^ équivalent (<T, Subj (<T, e1>)>, <H, Subj (<H,e2>)>) alors :\nA) Règle R1\nSi les différentes conditions se réunissent c‟est-à-dire :\n détecter une équivalence entre les deux évènements (e1, e2)\n chaque événement est relie avec la même relation TLINK avec une date e1t1 et e2t2\n les dates sont égales.\nNous aurons une inférence temporelle et textuelle entre les segments T et H.\nL‟abstraction de la règle R1 est représentée dans ce qui suit :\no Si relation (<T,e1>,< T,t> ,date) ^ relation (<H,e2>, <H,t‟>,date)\nalors Inf(T,H)= Vraie SSi inclus(<T,t> ,<H, t‟>) v égale(<T,t> ,<H, t‟>)\nsinon inf(T,H)=Faux\nLes numéros des exemples dans le corpus de développement où les règles peuvent s‟appliquer : 8, 7, 15, 14, 18, 28, 29, 30.\nCette figure représente la règle d‟inférence R1:\nDans l‟exemple qui suit, nous allons appliquer la règle R1 sur la paire numéro 8 du corpus.\n8) <pair id=\"9\" value=\"TRUE\" > T: since its e1: creation in 1948, Israel had faced a lot of conflict with the Arabic countries. H: Israel e2: was conceived in 1948.\nPuisque l‟événement e1 se déroule en 1948 et l‟événement e2 se déroule entre 1948 et puisque e2 est le synonyme de e1 alors il y a une inférence temporelle entre e1 et e2.\nB) Règle R2\nSi les différentes conditions se réunissent c‟est-à-dire :\n détecter une équivalence entre les deux évènements (e1, e2)\n t1 est la date de début de l‟évènement e1, t2 est la date de fin de l‟évènement e1 et l‟événement e2 est relié a une durée e2d.\n la différence entre les dates t1 et t2 est égale à la durée d.\nNous aurons une inférence temporelle et textuelle entre les segments T et H.\nL‟abstraction de la règle R2 est représentée dans ce qui suit :\no Si debut(<T,e1>,<T,t>,date) ^ fin(<T,e1>,<T,t‟>,date) ^ relation(<H,e2>, <H,t‟‟>,durée)\nAlors Inf(T,H)= égale(Différence (<T,t>,<T,t‟>) , <H,t‟‟>)\nsinon Inf(T,H)=Faux\nLes numéros des exemples dans le corpus de développement où les règles peuvent s‟appliquer: 4, 12.\nCette figure représente la règle d‟inférence R2 :\nDans l‟exemple qui suit, nous allons appliquer la règle R2 sur la paire numéro 4 du corpus.\n4) <pair id=\"4\" value=\"TRUE\" > T: Pasteur began looking for the germ that causes rabies in 1880, and in july 1885 he found the efficient vaccine against the illness. H: to find the vaccine, Pasteur‟s researches took five years.\nPuisque l‟événement e1 se déroule au même moment que l‟évènement e2 car si nous ajoutons « 7 years» à « november the first 1954» nous serions en 1962 qui est la date où s‟est déroulé l‟évènement e2 et puisque e2 est le synonyme de e1 alors il y a une inférence temporelle entre e1 et e2.\nC) Règle R3\nSi les différentes conditions se réunissent c‟est-à-dire :\n détecter une équivalence entre les deux évènements (e1, e2)\n t1 est la date de début de l‟évènement e1, événement e1 est relié a une durée e1d et t2 est la date de fin de l‟évènement e1.\n la somme entre la date t1et la durée d est égale à t2.\nNous aurons une inférence temporelle et textuelle entre les segments T et H.\nL‟abstraction de la règle R3 est représentée dans ce qui suit :\no Si debut(<T,e1>,<T,t>,date) ^ relation(<T,e1>,<T,t‟>,durée) ^ fin(<H,e2>, <H,t‟‟>,date)\nAlors Inf(T,H)= egal(Somme(<T,t>, <T,t‟>) , <H,t‟‟>)\nsinon Inf(T,H)= Faux\nLes numéros des exemples dans le corpus de développement où les règles peuvent s‟appliquer : 3, 11.\nCette figure représente la règle d‟inférence R3:\nDans l‟exemple qui suit, nous allons appliquer la règle R3 sur la paire numéro 3 du corpus de développement.\n3) <pair id=\"3\" value=\"TRUE\" >\nT: the Algerian revolution war started on november the first 1954, it caused the death of 1,5 million of martyrs and it e1: lasted 7 years. H: the Algerian revolution war e2: ended on july the fifth 1962.\nL‟événement e1 se déroule au même moment que l‟événement e2 car si on ajoute « 7 years» à « november the first 1954» nous serions en 1962 qui est la date où se déroule l‟évènement e2 et puisque e2 est le synonyme de e1 alors il y a une inférence temporelle entre e1 et e2.\nD) Règle R4\nSi les différentes conditions se réunissent c‟est-à-dire :\n détecter une équivalence entre les deux évènements (e1, e2)\n t1 est la date de fin de l‟évènement e1, événement e1 est relié à une durée e1d et t2 est la date de début de l‟évènement e1.\n la somme entre la date t1 et la durée d est égale a t2.\nNous aurons une inférence temporelle et textuelle entre les segments T et H.\nL‟abstraction de la règle R4 est représentée dans ce qui suit :\no Si relation(<T,e1>,<T,t>,durée) ^ fin(<T,e1>,<T, t‟>,date) ^ debut(<H,e2>, <H, t‟‟>,date)\nAlors Inf(T, H)= égale(Différence (<T, t‟>,<T, t>),<H, t‟‟>)\nsinon Inf(T, H)=Faux\nLes numéros des exemples dans le corpus de développement où les règles peuvent s‟appliquer : 10, 20.\nCette figure représente la règle d‟inférence R4:\nDans l‟exemple qui suit, nous allons appliquer la règle R4 sur la paire numéro 10 du corpus.\n10) <pair id=\"11\" value=\"TRUE\" > T: on t1: december 2nd 1804, Napoleon Bonaparte became the emperor of the French, before d1: one year exactly, he e1: won the battle of Austerlitz. H: in t2: 1803, Napoleon e2: won the battle of Austerlitz.\nL‟événement e1 se déroule au même moment que l‟événement e2 car si on réduit « one year exactly » à « december 2nd 1804 » nous serions en 1803 qui est la date où se déroule l‟évènement e2 et puisque e2 est le synonyme de e1 alors il y a une inférence temporelle entre e1 et e2.\nE) Règle R5\nSi les différentes conditions se réunissent c‟est-à-dire :\n détecter une équivalence entre les deux évènements (e1, e2)\n l‟événement e1 est relié avec une relation TLINK e1t2 et l‟événement e1 est relié avec la même relation TLINK à une durée e2d.\n inclusion entre la date t1 et la durée d.\nNous aurons une inférence temporelle et textuelle entre les segments T et H.\nL‟abstraction de la règle R5 est représentée dans ce qui suit :\no Relation (<T, e1>, < T,t> ,date) ^ relation(<H,e2>, <H,t‟>,durée)\nalors Inf(T, H)= Vraie SSi inclus(<T,t> ,<H, t‟>)\nsinon inf(T, H)=Faux\nLe numéro de l‟exemple dans le corpus de développement où cette règle peut être appliquée: 1. Cette figure représente la règle d‟inférence R5:\nApplication de la règle 5 sur la paire numéro 1 du corpus.\n1) <pair id=\"1\" value=\"TRUE\" > T: the second world war e1: finished in 1945. H: the end of the second world war e2: took part between 1940 and 1950.\nPuisque l‟événement e1 ce déroule en 1945 et l‟événement e2 se déroule entre 1940 et 1950 et puisque e2 est le synonyme de e1 alors il y a une inférence temporelle entre e1 et e2."
    }, {
      "heading" : "4.1.1.3) Groupe 2",
      "text" : "Cette règle permet de savoir s‟il n‟y a pas d‟ancrage temporel entre évènements.\nSi contraire(<T,e1> ,<H,e2>) ^ équivalent(<T ,Subj(e1)> , <T,subj(e2)>) =<H,Subj(e2)>)\nA) Règle R6\nSi les différentes conditions se réunissent c‟est-à-dire :\n détecter que l‟évènement e1 est le contraire de l‟évènement e2.\n l‟événement e1 se produit soit avant ou après e2.\nNous aurons une inférence temporelle et textuelle entre les segments T et H.\nL‟abstraction de la règle R6 est représentée dans ce qui suit :\nSi relation (<T, e1>, <T, t>, date) ^ relation(<H, e2>, <H, t‟>, date)\nAlors\nInf(T, H) = Vraie SSi before(relation (<T,e1>,<T,t>, date), relation(<H, e2>,\n<H, t‟>, date)\nv\nafter(relation (<T, e1>,<T, t>, date) , relation(<H, e2>, <H, t‟>, date)\nsinon inf(T, H)=Faux\nLes numéros des exemples dans le corpus de développement où les règles peuvent s‟appliquer : 2, 5.\nCette figure représente la règle d‟inférence R6:\nApplication de la règle 6 sur la paire 2 du corpus.\n2) <pair id=\"2\" value=\"TRUE\" >\nT: Algeria got its e1: independence in 1962.\nH: Before 1962 Algeria was e2: colonized.\nDans cet exemple ci-dessus, puisque l‟événement e1 se déroule en 1962 et l‟événement e2 se déroule avant l‟évènement e1 et puisque e2 est l‟antonyme de e1 alors il y a une inférence temporelle entre e1 et e2."
    }, {
      "heading" : "4.2.2) Le superviseur",
      "text" : "Ce module, accepte en entrée, les résultats du module « inférence entre événements », le résultat de « TARSQI », « les ressources » à ajouter et « les règles d‟inférences » et en sortie, il indique s‟il y une inférence textuelle ou pas.\nLe superviseur permet de choisir les règles d‟inférences temporelles à appliquer et de décider de l‟existence ou pas de l‟inférence textuelle.\nAinsi, le superviseur applique la procédure suivante:\n Si le module a comme message « pas d‟inférence » de la phase précédente c'est-àdire du module de test d‟inférence le superviseur va afficher, « pas d‟inférence\ntextuelle ».\n Si le module a comme message « non » qui veut dire qu‟il y a une relation d‟antonymie entre les évènements le module va exécuter les règles d‟inférences\ntemporelles qui détectent si les deux évènements ne sont pas ancrés temporellement.\n Si le module a comme message « oui » qui veut dire qu‟il y a une relation de synonymie entre les évènements, le module va exécuter les règles d‟inférences\ntemporelles qui détectent si les événements sont ancrés temporellement.\nNous représentons dans la figure suivante l‟architecture du superviseur :\nFigure 4.26 : Architecture du superviseur\nFichier texte\nPas d‟inférence\nOui\noui\nOui Non\nOui\noui\nOui Non\nOui Non Oui\noui\nOui Non Oui\noui\nPas d‟inférence\nPas d‟inférence Inférence vrai\nPas d‟inférence Inférence vrai\nTest d‟inférence entre\nsujets\nTest d‟inférence entre\névènements\nTest des règles d‟inférences du groupe 1 Test d‟antonymie\nTest de synonymie\nTest des règles\nd‟inférences du groupe 2 Pas d‟inférence\nOui oui\nOui oui Oui Non\nOui Non\nIl existe des cas où plusieurs règles peuvent s‟appliquer. Pour cela, le superviseur prend les mesures suivantes :\n S‟il existe une fonction qui retourne une fausse inférence temporelle, cela implique qu‟il n‟y a pas d‟inférence textuelle entre les segments T et H.\n Si toutes les fonctions retournent une inférence temporelle, cela implique qu‟il y a une inférence textuelle entre les segments T et H.\nComme il est montré dans la Figure 4.27 le superviseur exécute les règles du même groupe une par une."
    }, {
      "heading" : "4.4) Conclusion",
      "text" : "Nous avons présenté dans ce chapitre, notre projet TIMINF. Son architecture informatique se base sur cinq modules principaux. Les deux modules TARSQI et Link Grammar Parser constituent la phase de prétraitement indispensable à la phase de test d‟inférence, qui nous permet de détecter l‟inférence entre évènements et sujets. Le module de balisage qui est inclue dans la deuxième phase est utilisé pour baliser les expressions temporelles non détectées par TARSQI."
    }, {
      "heading" : "Le superviseur est le dernier module de notre système. Celui ci communique avec une base de",
      "text" : "règle et décide des choix des règles d’inférences temporelles a appliqué. Il a aussi le rôle de tester l’inférence textuelle entre les phrases T et H d’après les données reçues de tous les composants du système. Nous allons présenter dans le chapitre qui suit les différentes étapes de la mise en œuvre du système TIMINF ainsi qu‟une étude expérimentale.\n- Chapitre 5 -"
    }, {
      "heading" : "La mise en œuvre et l‟évaluation du système",
      "text" : "TIMINF\nChapitre 5"
    }, {
      "heading" : "La mise en œuvre et l‟évaluation du système",
      "text" : "TIMINF"
    }, {
      "heading" : "1) Introduction",
      "text" : "Dans ce chapitre nous allons expliquer l‟installation des différents outils utilisés pour aboutir à notre objectif. Nous donnons aussi un exemple de déroulement de notre système qui résume les principales spécifications de notre projet et montre comment les différents modules peuvent être mis en œuvre dans un système de test d‟inférence textuelle intégrant l‟aspect temporel dans ses décisions. Nous finissons ce chapitre avec l‟évaluation de notre système."
    }, {
      "heading" : "2) Environnement et outils utilisés",
      "text" : ""
    }, {
      "heading" : "2.1) Python",
      "text" : "Pour concevoir notre système nous avons choisi d‟utiliser le langage de programmation Python qui a fait ses preuves dans la programmation de nombres applications du TALN. Python est un langage portable, dynamique, extensible, gratuit, qui permet une approche modulaire et orientée objet de la programmation. Python est développé depuis 1989 par Guido van Rossum et de nombreux contributeurs bénévoles (Swinnen, 2005).\nL'interpréteur peut être lancé directement depuis la ligne de commande (dans un « shell » Linux, ou bien dans une fenêtre DOS sous Windows) : il suffit d'y taper la commande \"python\" (en supposant que le logiciel lui-même ait été correctement installé). Nous utilisons une interface graphique telle que Windows. Pour cela nous avons préféré travailler dans un environnement de travail spécialisé tel que IDLE. Avec IDLE sous Windows, notre environnement de travail ressemblera à celui-ci : Les trois caractères « supérieur à » constituent le signal d'invité, ou prompt principal, lequel indique que Python est prêt à exécuter une commande.\nPour rédiger nos séquences d'instructions nous avons utilisé l'éditeur incorporé dans une interface de développement telle que IDLE). Il serait parfaitement possible d'utiliser un système de traitement de textes, à la condition d'effectuer la sauvegarde sous un format \"texte pur\" (sans balises de mise en page). Il est cependant préférable d'utiliser un véritable éditeur ANSI \"intelligent\" tel que nedit ou IDLE, muni d'une fonction de coloration syntaxique pour Python, qui aide à éviter les fautes de syntaxe. La figure ci-dessous illustre l'utilisation de l'éditeur IDLE). Sous (windows) :\nPar la suite, pour tester l'exécution de notre programme, il nous suffit de lancer l'interpréteur Python en lui fournissant (comme argument) le nom du fichier qui contient le script. Par exemple, si nous avons placé un script dans un fichier nommé « MonScript », il suffira d'entrer la commande suivante dans une fenêtre de terminal pour que ce script s'exécute : python MonScript Dans l'explorateur Windows, nous pouvons lancer l'exécution de notre script en effectuant un simple clic de souris sur l'icône correspondante ou dans IDLE, en lançant l'exécution du script en cours d'édition, directement à l'aide de la combinaison de touches <Ctrl-F5>."
    }, {
      "heading" : "2.2) TARSQI",
      "text" : "Nous décrivons dans ce qui suit le processus d‟installation de TARSQI dans un environnement Linux puisqu‟il n'existe pas actuellement une version Windows de TARSQI. Toutefois, le code est écrit pour être multiplateforme. Le groupe TIMEML travaille actuellement sur une version de TARSQI adapté pour Windows qui sera publiée dès que possible."
    }, {
      "heading" : "2.2.1) L‟installation",
      "text" : ""
    }, {
      "heading" : "La boîte à outils requiert au moins la version 2,3 de Python et la version 5,8 de Perl. La boîte à outils a été testée sur les plates-formes suivantes: Red Hat Linux 5, avec Python 2.4.3 et Perl 5.8.8",
      "text" : "Mac OS X, avec Python 2.3.5 et Perl 5.8.8\nPour installer TARSQI, nous avons d‟abord téléchargé et décompresser l'archive dans un répertoire et, taper dans l‟invité de commande ce qui suit :\n% Gunzip-c TTK-1.0.tar.gz | tar xp\nCette commande permet de décompresser le contenu dans un répertoire nommé TTK-1,0,\nqui est un répertoire choisi par nous.\nLa boîte à outils TARSQI est conçue pour fonctionner de façon transparente avec le SGI TreeTagger. Le TreeTagger doit être installé dans ttk-1.0/code/components/preprocessing/treetagger/\nCe répertoire doit avoir des sous-répertoires bin et lib.\n2.2.2) L‟utilisation de la boite à outils TARSQI\nPour exécuter l'outil TARSQI, nous devons ouvrir un terminal, aller au répertoire où se trouve le fichier tarsqi.py et taper :\npython tarsqi.py <input_type> [drapeaux] <infile> <outfile>\n<input_type>: Il existe deux formats d‟entrée de TARSQI : simple-xml et rte3.\n[drapeaux]: Avec les drapeaux nous pouvons exécuter un seul ou plusieurs module de TARSQI où l‟ordre des modules est important. En voici un exemple:\n[drapeaux]= préprocesseur, GUTIME, EVITA\nL‟exemple montre une demande d‟exécution des 3 premiers modules de TARSQI."
    }, {
      "heading" : "2.2.3) L‟utilisation de la boite à outils d‟interface graphique",
      "text" : "La Boîte à outils d'interface graphique peut être utilisée en tapant :\n% Pythonw gui.py\nL'interface graphique a trois avantages sur l'utilisation de la version en ligne de commande:\n Il est plus rapide lors de l'utilisation sur un fichier par fichier, parce que toutes les bibliothèques sont chargées soit au démarrage ou lorsque le premier fichier est traité.\n Il est plus facile à utiliser.\n Il permet à l'utilisateur de taper certains points d'entrée et voir ce qui se passe. Le principal inconvénient est qu'il n'est pas possible de traiter tous les fichiers dans un répertoire. Voici une capture d'écran:\nLes fonctionnalités peuvent être résumées comme suit:\n Utilisez \"Chargez le fichier\" pour sélectionner un fichier à traiter.  Utilisez \"Texte de charge\" à saisir du texte. Cette opération va créer un fichier\ndans le dossier data / en / répertoire utilisateur, qui est ensuite sélectionné comme fichier d'entrée.  Utilisez « Processus de dossier » pour traiter le fichier d'entrée conformes aux\nparamètres sélectionnés."
    }, {
      "heading" : "2.3) Link Parseur",
      "text" : "L’installation de ce module n’est pas difficile, puisque après avoir téléchargé le système de puis le lien suivant (http://www.abisource.org/projects/link-grammar/), nous avons décompressé le contenu dans un répertoire de notre choix. Il suffit d’un click sur l’exécutable contenu dans le répertoire."
    }, {
      "heading" : "Il suffit d’écrire le texte que nous voulons analyser et nous aurons l’analyse syntaxique.",
      "text" : ""
    }, {
      "heading" : "2.4) PyWordNet",
      "text" : "Dans notre module nous avons choisi d‟utiliser une version de WordNet qui correspond au choix de notre langage de programmation. En effet, PyWordNet est une interface Python pour la base de données WordNet qui permet avec des fonctions du langage python de consulter la base de données WordNet. Exemple : Si nous tapons l‟expression suivante dans l‟invité de commande python :\nNous interrogeons la base de données sur les différents sens du mot « dog ». {'dog' in {noun: dog, domestic dog, Canis familiaris}"
    }, {
      "heading" : "2.4.1) L‟installation",
      "text" : "Pour installer Pywordnet, il nous a fallu d‟abord Télécharger et installer WordNet de 2.0 qui est disponible sur le site http://www.cogsci.princeton.edu/ wn ~ /. Aussi nous avons téléchargé PyWordNet de http://sourceforge.net/projects/pywordnet et décompresser dans le répertoire. Ensuite avec l‟invité de commande nous accédons au répertoire contenant les fichiers décompressés et nous tapons python setup.py.\nCette commande va permettre concrètement d‟installer les deux bibliothèques nécessaires au bon fonctionnement du système. Les deux bibliothèques sont respectivement wordnet.py contient la base de données et wntools.py contient les fonctions qui permettent de consulter la base de données.\n>>> N['dog'] dog(n.) >>> N['dog'].getSenses()\n2.4.2) L‟utilisation de PyWordNet dans notre système\nPour savoir si les mots sont antonyme ou synonymie, qui est l‟objet du module inférence entre sujet et événement, nous avons utilisé la fonction meet (mot1, mot2, Synonymie) de la bibliothèque PyWordNet qui permet de donner vrai s‟il y a une synonymie entre les deux.\nLa même chose pour l‟antonyme mot et meet (mot1, mot2, antonymie) qui permet de donner vrai si „il y a une antonymie entre les deux mots.\nCette figure représente la fonction qui détecte s‟il y a une antonymie entre deux mots programmés en Python :\nDans ce qui suit nous allons illustrer nos travaux avec le déroulement d‟un exemple du corpus sur notre système. Nous allons citer les différentes phases de traitement de la paire de textes."
    }, {
      "heading" : "3) Exemple d‟exécution du TIMINF sur un exemple",
      "text" : "du corpus\nNous avons choisi pour l‟exemple, la paire numéro 8 du corpus de développement.\nComme il est montré dans l‟exemple ci-dessous la première étape est de transformer le texte brut en format simple-xml, pour cela nous avons balisé manuellement les paires du corpus."
    }, {
      "heading" : "3.1) TARSQI",
      "text" : "Le module TARSQI va permettre de détecter les deux événements de la paire de deux textes (T,H) qui correspondent dans l‟exemple au verbe collapsed qui est l‟évènement des deux segments de textes.\nLa commande qui permet d‟enclencher le module TARSQI avec le format simpel-xml dans un environnement UNIX c‟est :\npython tarsqi.py simple-xml (le nom du fichier contenant les deux segments de textes) (le nom du fichier de sortie).\nCi-dessous nous montrons la sortie TARSQI correspondant à l‟exemple :"
    }, {
      "heading" : "3.2) L‟analyse syntaxique",
      "text" : "L‟analyse syntaxique se fait en parallèle avec TARSQI et elle va permettre de détecter les sujets des deux segments de textes, qui correspond dans l‟exemple à the building.\nCi-dessous nous montrons la sortie de LINK Parseur correspondante à l‟exemple :"
    }, {
      "heading" : "3.3) L‟inférence entre sujets et événements",
      "text" : "Comme il est montré dans l‟exemple ci-dessous le module de test d‟inférence entre sujets et évènements va permettre de détecter l‟équivalence entre les deux sujets et les deux évènements des segments T et H."
    }, {
      "heading" : "3.4) Le balisages des expressions temporelles non détectées",
      "text" : "par TARSQI\nComme il est montré dans l‟exemple ci-dessous, le balisage des expressions temporelles va permettre de positionner l‟expression temporelle dans le temps. Dans l‟exemple il détermine que the afternoon c‟est l‟intervalle temporel entre midi et 18 heures."
    }, {
      "heading" : "3.5) Le superviseur",
      "text" : "L‟équivalence entre les sujets et les évènements est détectée par la phase d‟inférence textuelle et d‟ancrage entre les expressions temporelles (2 o‟clock et the afternoon) est détecté par l‟application de la régle R5 de la base de règles d‟inférences qui stipule que si les différentes conditions se réunissent c‟est-à-dire :\n détecter une équivalence entre les deux évènements (e1, e2)\n l‟événement e1 est relié avec une relation TLINK e1t2 et l‟événement e1 est relié avec la même relation TLINK à une durée e2d.\n inclusion entre la date t1 et la durée d.\nNous aurons une inférence temporelle et textuelle entre les segments T et H.\nDes deux résultats précédents le superviseur décide qu‟il y a une inférence textuelle entre les segments T et H.\nCette figure représente les différentes conditions nécessaires à une inférence textuelle."
    }, {
      "heading" : "4) L‟évaluation de notre système",
      "text" : "Notre objectif consiste à améliorer les systèmes d‟inférences textuelles. Dans ce cadre, nous avons choisi d‟évaluer notre système d‟inférence avec le système d‟évaluation adopté par le challenge RTE. Pour cela, nous devons évaluer le système par rapport au corpus de développement et aussi par rapport au corpus de test.\nChaque paire du corpus est lancée dans notre système qui donne en sortie s‟il y a une inférence textuelle ou pas. Les résultats sont comparés au « GOLD standard » que nous avons établi dans notre étape de conception du corpus. Le pourcentage donnant le nombre de fois où il y a similitude entre notre système et le « gold standard » donne « l‟accuracy » du système. l‟accuracy est une mesure standard fréquemment utilisée dans les systèmes de traitements du langage naturel.\nDans ce qui suit, nous allons présenter les résultats préliminaires des évaluations des deux corpus.\n4.1) L‟évaluation du système sur le corpus de développement\nNous avons élaboré notre système d‟après l‟étude des inférences existantes dans le corpus de développement. Ce corpus nous a permis de tester notre système plusieurs fois en effectuant à chaque fois des modifications jusqu'à ce qu‟on arrive à concevoir un système qui a donné 100% d‟accuracy par rapport à ce corpus."
    }, {
      "heading" : "4.2) L‟évaluation du système avec le corpus de test",
      "text" : "Le corpus de test est constitué de 30 paires de textes, 15 d‟entres elles sont évaluées comme contenant une inférence textuelle fausse et les autres sont évalués comme vrai.\nNous avons soumis ce corpus a notre système qui nous a permis de calculer l‟accuracy.\nLes résultats d‟accuracy sont montrés dans le tableau suivant :\nLes systémes L‟accuracy\nSystème 58 %\nTableau 2.1 : Le tableau représente l‟accuracy du système\nLes résultats de l‟évaluation sont encouragent puisque nos résultats sont plus élevés que la moyenne de l‟accuracy des systèmes participants au RTE 2 qui sont de 56.6 %.\nDans ce qui suit nous allons étudier les causes de défaillance de notre système."
    }, {
      "heading" : "4.4) L‟analyse des erreurs causées par le système",
      "text" : "D‟après notre étude des résultats donnés par notre système nous avons pu élaborer un tableau contenant des statistiques concernant les causes d‟échecs de notre système.\nProblème Pourcentage\nd‟erreur dans le corpus\nAnalyse syntaxique\n38 %\nTARSQI 62 %\nTableau 3.2 : les causes d‟erreurs du système\nNous remarquons dans ce tableau que les majeures parties des erreurs commises par notre système sont en générale causé par la déficience de l‟outil TARSQI.\nEn effet, TARSQI ne détecte pas plusieurs choses. Par exemple, au niveau de la détection des évènements où nous avons remarqué que TARSQI ne détecte pas les verbes composés comme un événement mais plutôt comme deux évènements indépendants.\nExemple: paire numéro 1 du corpus de test. T: the First World War spent 7 years.\nH: World War I, also known as the First World War, the Great War and the War To End All Wars, was a global military conflict which took place primarily in Europe from 1914 to 1918.\nDans l‟exemple la détection de l‟événement took place par TARSQI n‟a pas pu se faire car took place est un verbe composé.\nAussi les erreurs de notre système viennent de l‟analyse syntaxique effectuer en pré traitement par link parser où les sujets des verbes ne sont pas détectés.\nExemple: paire numéro 10 du corpus de test.\nT: Protracted military S1: conflict between Iran and Iraq. It officially began on t1: Sept. 22, 1980, finally, in July, 1988, Iran was forced to accept a United Nations–mandated cease-fire. H: With more than 100000 Iranian victims of Iraq's chemical weapons during the ten-year war, Iran is one of the countries most severely afflicted by weapons.\nDans l‟exemple précédant, la relation entre la date t1 et le sujet S1 n‟est pas détecté par TARSQI puisque l‟analyse syntaxique n‟a pas pu auparavant relier entre conflict et it."
    }, {
      "heading" : "5) Conclusion",
      "text" : "Nous avons présenté dans ce chapitre le processus d‟installation de nos différents outils nécessaires au bon fonctionnement de notre système. Nous avons également présenté le déroulement de notre système sur un exemple du corpus qui a permis de montrer comment les différents modules étaient mis en œuvre dans notre système.\nEnfin, nous avons donné les performances de notre système qui étaient encourageantes et nous avons étudié les différentes failles de notre système. Cela a permis de monter que l‟inférence temporelle à un besoin inéluctable aux d‟autres modules d‟inférences.\nConclusion générale et perspective\nNous avons présenté, tout au long de ce manuscrit, notre démarche pour la conception d‟un système d‟inférence textuelle considérant l‟inférence temporelle dans sa décision. Pour cela nous avons d‟abord exploré l‟apport du RTE dans les différentes applications du TAL (RI, QR, EI et RA) et étudié les différentes approches utilisées pour détecter l‟inférence (lexical, lexico syntaxique, sémantique et logique). Puis nous avons analysé les approches des différents groupes de recherches qui ont participé aux trois challenges Pascal RTE. Cette étape nous a permis de découvrir les chemins qui n‟ont pas encore été étudiés pour détecter l‟inférence textuelle.\nEnsuite, nous avons exploré la logique temporelle, ses applications dans le traitement du langage nature et les différents types d‟inférences temporelles existantes. Cette étude nous a permis de constater qu‟il n‟y a pas de travail à nos jours liant l‟inférence temporelle et la reconnaissance de l‟inférence temporelle.\nNous avons élaboré un corpus contenant des paires de segments de textes integrant des relations temporelles et nous avons fait une classification des différents types d‟inférences temporelles existants dans le corpus.\nLa suite logique de ce travail est de déduire des régles d‟inférences temporelles et les intégrer à un systéme de reconnaissance d‟inférence texuelle.\nUne fois le systéme concu, nous avons évalué ses performances avec la méme stategie d‟evaluation adoptée dans le challenge pascal RTE. Cette evaluation nous a donné des résultats encourageants.\nEnfin, nous avons étudié les différentes failles de notre système. Cela a permis de prévoir plusieurs perspectives de recherches.\nContribution\nEtant donné les objectifs que nous nous sommes fixés pour ce projet, les principales contributions de TIMINF peuvent être résumées comme suit :\nL‟élaboration d‟un corpus à base d‟inférence temporelle permettra d‟évaluer les recherches futures dans ce Domaine.\nL‟étude du corpus nous a permis de classifier différents types d‟inférence temporelle et de développer différentes règles d‟inférences temporelles.\nAussi l‟évaluation de notre système a permis de voir concrètement quel est l‟apport de l‟aspect temporel dans le RTE.\nPerspectives et travaux futurs\nNous envisageons de poursuivre nos recherches futures dans trois directions principales.\nNotre système ne permet pas de détecter les entités nommées et de gérer les anaphores. Pour cela, nous envisageons d‟introduire un module permettant de détecter et de dater les entités nommées automatiquement. Aussi nous pensons à intégrer un module pour gérer les anaphores et étudier l‟impacte de celui-ci sur la performance de notre système.\nLa seconde direction scientifique est d‟évaluer le système prédicat argument comme prétraitement au lieu d‟une simple analyse syntaxique.\nEnfin, nous envisageons également de développer un système pouvant tester l‟inférence textuelle dans des segments de textes plus grandes et utiliser un système qui utilise comme réponse trois sorties possibles (inférence vrai, inférence Fausse ou on ne c‟est pas s‟il y a une inférence) et nous associons chaque inférence vraie à une application du TALN (QR, RI, IE, PP…).\nRéférences\n(Baker, Fillmore et Lowe, 1998) Baker, Charles J. Fillmore, and John B. Lowe. 1998. The berkeley framenet project. In Proceedings of the COLING-ACL, Montreal.\n(Bras, 1990) Myriam Bras. Calcul des Structures Temporelles du Discours. PhD thesis, IRIT, 1990. (Benveniste, 1974) Benveniste Emile Problèmes de linguistique générale. Paris, Gallimard, vol. II.\n(Bourigault, 2000) BOURIGAULT D. Recent Advances in Computational Terminology, 2000.\n(Bourigault et al., 2004) BOURIGAULT D. AUSSENAC-GILLES N. et CHARLET J. (2004). Construction de ressources terminologiques ou ontologiques à partir de textes : un cadre unificateur pour trois études de cas, Revue d'Intelligence Artificielle, 18(4), 24 pp.\n(Charolles, 1997) Charolles M. « L‟encadrement du discours – univers, champs, domaines et espaces », Cahier derecherche linguistique, 6, p. 1-73. 1997.\n(Chaumartin, 2007) Francois-Regis chaumartin, wordnet et son ecosysteme, BDL-CA,2007, montreal.\n(Cohen, 1960) Cohen J. : “A coefficient of agreement for nominal scales”, Educ. Psychol. Meas.: 20, 27-46. 1960\n(Dagan et al, 2005) Textual inference problems from the PASCAL RTE. Challenge, 2005.\n(Len Schubert, 2002) Len Schubert. Can we derive general Word Knowledge from Texts ?. 2002.\n(Helmut Schmid, 1994) Part-of-Speech Tagging with Neural Networks. Proceedings of the 15th International Conference on Computational Linguistics (COLING-94). August 1994.\n(Joachims, 2003) T. Joachims, Information Retrieval and Language Technology (pdf), 2003, Cornell University.\n(Kosseim., 2005). Leila Kosseim, Extraction d'information bilingue, 2005.\n(Ligauzat , 1994) Gérard Ligauzat. Représentation des connaissances et linguistique. Armand Colin, Paris, 1994.\n(Lin et Pantel, 2001) DeKang Lin and Patrick Pantel. 2001. Discovery of inference rules for Question Answering. Natural Language Engineering.\n(Laurain et Marie, 2006) La traduction automatique. France. Septentrion Presses Universitaire, 1996. p. 15-16.\n(Macleod et al., 1998) C.Macleod, R.Grishman, A.Meyers, L.Barrett and R. Reeves. 1998. Nomex : A lexicom of normalisations.in Proceedings of 8 the International Congress of the European association for lexicography.1998. liege, begium : EURALEX.\n(Mani et Wilson, 2000) Mani and George Wilson. 2000. Processingof News. In Proceedings of the 38th Annual Meetingof the Association for Computational Linguistics(ACL2000), pages 69–76.\n(Moldovan et Rus, 2001) Dan I. Moldovan and Vasile Rus. 2001. Logic form transformation of wordnet and its applicability to question answering. In Meeting of the Association for Computational Linguistics, pages 394-401.\n(Moldovan and Rus, 2001). Moldovan and Rus Logic Forms can be utilized by a wide variety.2001.\n(Miller, 1995) P. Miller. 1995. \"Notes on phonology and orthography in several Katuic MonKhmer groups in Northeast Thailand.\" Mon-Khmer Studies 24: 27-51.\n(Nugues, 2006) Pierre Nugues. An Introduction to Language Processing with Perl and Prolog. Springer Verlag, 2006.\n(Nyberg et al, 2002) E. Nyberg, T.Mitamura, J. Carbonnell, J. Callan, K. Cllins-Thompson, K Czuba, M. Duggan, L. Hiyakumoto, N. Hu, Y. huang, J. Ko, L.V. Lita, S.Muratagh et V. Pedro. The JAVELIN Question-Ansewering System at TREC 2002. In Proceding of the 11 th Text Retrieval conference (TREC-11), 2002.\n(Pustejovsky et al., 2003) Paul Kiparsky and Carol Kiparsky. InManfred Bierwisch and Karl Erich Heidolph, editors, Progress in Linguistics. A collection of Papers, pages143–173. Mouton, Paris.\n(Rodrigo et al., 2007) A. Rodrigo, A. Pe˜nas, J. Herrera and F. Verdejo..The Effect of Entity Recognition on Answer Validation.In Lecture Notes in Computer Science. In press 2007.\n(Sleator et Temperley, 1991) Daniel Sleator and Davy Temperley. 1991. Parsing English with a Link Grammar. Carnegie Mellon University Computer Science technical report CMU-CS91-196, October 1991.\n(Swinnen, 2005) Gérard Swinnen Apprendre à programmer avec Python, Copyright 2005.\n(Tatu et Moldovan,2007) Marta Tatu and Dan Moldovan. 2007 COGEX at the third recognising of textual entailement challenge. In proceeding of the wokshop on textual entailment, prague, June 2007.\n(Tatu et al., 2006) Marta Tatu, B Iles, J. Slavick, A. Novischi, and D. Moldovan. 2006, COGEX at the third recognising of textual entailement challenge. In proceeding of the wokshop on textual entailment,Venice, Italy.\n(vanderwende et al., 2005) Lucy vanderwende, deborah coughlin and bill dolan. 2005.what syntax contribute in entailment task. In proccedings of pascalchallange workshop on recogning texual entailment,2005 .\n(Venhagen et al., 2005) M. Venhagen, I. Mani , R. Sauri, R. Knippen, J .Littman and J. Pustejovsky. 2005. Automating Tenporal Annotation With TARSQI. In Proceedings of ACL 2005. demo session.\n(WOS, 1998) L. WOS. Automated Reasoning -33 Basic Research Problems. Prentice-Hall. (Yvon, 2007) François Yvon . Une petite introduction au Traitement Automatique des Langues Naturelles, 2007."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2009,
    "abstractText" : null,
    "creator" : "Microsoft® Office Word 2007"
  }
}