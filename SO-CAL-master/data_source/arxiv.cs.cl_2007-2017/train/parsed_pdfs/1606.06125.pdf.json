{
  "name" : "1606.06125.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "maxime.amblard}@loria.fr" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 6.\n06 12\n5v 1\n[ cs\n.C L\n] 2\n0 Ju\nKeywords: compositionality, side effects, monads, handlers, deixis, conventional implicature"
    }, {
      "heading" : "1 Introduction",
      "text" : "The prevailing methodology of formal semantics is compositionality in the sense of Frege: denotations of complex phrases are functions of the denotations of their immediate constituents. However, several phenomena have been identified that challenge this notion of compositionality. Examples include anaphora, presupposition, quantification, deixis and conventional implicature. In all of these examples, simple models of denotation (i.e. noun phrases are individuals, sentences are truth-values) run into complications as the denotations can depend on external values (anaphora, deixis) or on something which is not an immediate constituent (presupposition, quantification, conventional implicature).\nAmong the solutions to these challenges, we find (at least) two types of solutions. First, we have those that relax the condition of compositionality. Notably, the denotation of a complex phrase is no longer a function per se of the denotations of its immediate subconstituents. Rather, it is some other formally defined process.1 Examples of this approach include:\n1 This kind of distinction is the same distinction as the one between a mathematical function and a function in a programming language, which might have all kinds of side effects and therefore not be an actual function.\n– the incremental algorithm used to build discourse representation structures in DRT, as presented in [12] – the λµ calculus, used in [5] to analyze quantification, since, due to the lack of confluence, function terms do not denote functions over simple denotations – the use of exceptions and exception handlers in [18] to model presuppositions in an otherwise compositional framework – the parsetree interpretation step in the logic of conventional implicatures of [23] that builds the denotation of a sentence by extracting implicatures from the denotations of its subparts (including the non-immediate ones)\nThe other approach is to enrich the denotations so that they are parameterized by the external information they need to obtain and contain whatever internal information they need to provide to their superconstituents. Here are some examples of this style:\n– any kind of semantic indices (e.g. the speaker and addressee for deixis, the current world for modality), since they amount to saying that a phrase denotes an indexed set of simpler meanings – the continuized semantics for quantification [1] in which denotations are functions of their own continuations • and more generally, any semantics using type raising or generalized quantifiers for noun phrase denotations – the dynamic denotations of [7] that are functions of the common ground and their continuation – compositional event semantics, such as the one in [25], that shift the denotations of sentences from truth-values to predicates on events\nWe want to find a common language in which we could express the above techniques. Our inspiration comes from computer science. There, a concept known as monad has been used:\n– in denotational semantics to give the domain of interpretation for programming languages that involve side effects [21]. – in functional programming to emulate programming with side effects via term-level encodings of effectful programs [29].\nThese two principal applications of monads align with the two approaches we have seen above. The one where we change our calculus so it no longer defines pure functions (e.g. is non-deterministic, stateful or throws exceptions) and the one where we use a pure calculus to manipulate terms (denotations) that encode some interaction (e.g. dynamicity, continuations or event predication).\nMonad is a term from category-theory. Its meaning is relative to a category. For us, this will always be the category whose objects are types and whose arrows are functions between different types. A monad is formed by a functor and a pair of natural transformations that satisfy certain laws. In our case, this means that a monad is some type constructor (the functor part) and some combinators (the natural transformations) that follow some basic laws. To give an example of this,\nwe can think of the functor T (α) = (α → o) → o together with combinators such as the type raising η(x) = λP. P x as a monad of quantification.\nThe relationship between side effects in functional programming and computational semantics has been developed in several works [27,28],2 stretching as far back as 1977 [10]. The usefulness of monads in particular has been discovered by Shan in 2002 [26]. Since then, the problem that remained was how to compose several different monads in a single solution. Charlow used the popular method of monad morphisms3 to combine several monads in his dissertation [4]. Giorgolo and Asudeh have used distributive laws to combine monads [8], while Kiselyov has eschewed monads altogether in favor of applicative functors which enjoy easy composability [13].\nOur approach follows the recent trend in adopting effects and handlers to combine side effects [2,11] and to encode effectful programs in pure functional programming languages [14,3].\nThe idea is that we can represent each of the relevant monads using an algebra. We can then combine the signatures of the algebras by taking a disjoint union. The free algebra of the resulting signature will serve as a universal representation format for the set of all terms built from any of the source algebras and closed under substitution. Then, we will build modular interpreters that will give meanings to the operators of the algebras in terms of individuals, truth-values and functions.\nIn Sect. 2, we will introduce a formal calculus for working with the algebraic terms that we will use in our linguistic denotations. In Sect. 3, we will incrementally build up a fragment involving several of the linguistic phenomena and see the calculus in action. Before we conclude in Sect. 5, we will also discuss some of the formal properties of the calculus in Sect. 4."
    }, {
      "heading" : "2 Definition of the Calculus",
      "text" : "Our calculus is an extension of the simply-typed lambda calculus (STLC). We add terms of a free algebra into our language and a notation for writing handlers, composable interpreters of these terms. An operator of the free algebra corresponds to a particular interaction that a piece of natural language can have with its context (e.g. a deictic expression might request the speaker’s identity using some operator speaker in order to find its denotation). A handler gives an interpretation to every occurrence of an operator within a term (e.g. direct speech introduces a handler for the operator speaker that essentially rebinds the current speaker to some other entity).\n2 Side effects are to programming languages what pragmatics are to natural languages: they both study how expressions interact with the worlds of their users. It might then come as no surprise that phenomena such as anaphora, presupposition, deixis and conventional implicature yield a monadic description. 3 Also known as monad transformers in functional programming.\nHaving sketched the general idea behind our calculus, we will now turn our attention to the specifics. We start by defining the syntactic constructions used to build the terms of our language."
    }, {
      "heading" : "2.1 Terms",
      "text" : "First off, let X be a set of variables, Σ a typed signature and E a set of operation symbols. In the definition below, we will let M , N . . . range over terms, x, y, z. . . range over variables from X , c, d. . . range over the names of constants from Σ and op, opi. . . range over the operation symbols in E .\nThe terms of our language are composed of the following:\nM,N ::= λx.M [abstraction]\n| M N [application]\n| x [variable]\n| c [constant]\n| opMp (λx.Mc) [operation]\n| ηM [injection]\n| L op1:M1, . . . , opn:Mn, η:Mη MN [handler] | − ◦ M [extraction]\n| CM [exchange]\nThe first four constructions — abstraction, application, variables and constants — come directly from STLC with constants.\nThe next four deal with the algebraic expressions used to encode computations. Let us sketch the behaviors of these four kinds of expressions.\nThe operation (op) and injection (η) expressions will serve as the constructors for our algebraic expressions. Algebraic expressions are usually formed by operation symbols and then variables as atoms. Instead of variables, our algebraic expressions use terms from our calculus for atoms. The η constructor can thus take an ordinary term from our calculus and make it an atomic algebraic expression. The operation symbols op are then the operations of the algebra.\nThe other three expression types correspond to functions over algebraic expressions.\n– The most useful is the handler L M.4 It is an iterator for the type of algebraic expressions. The termsM1,. . . ,Mn andMη in L op1:M1, . . . , opn:Mn, η:Mη M are the clauses for the constructors op1,. . . ,opn and η, respectively. We will use handlers to define interpretations of operation symbols in algebraic expressions. – The cherry − ◦ operator allows us to extract terms out of algebraic expressions.\nIf an algebraic expression is of the form ηM , applying − ◦ to it will yield M .\n4 Pronounced “banana”. See [20] for the introduction of banana brackets.\n– The exchange operator C permits a kind of commutation between the λbinder and the operation symbols. We will see its use later."
    }, {
      "heading" : "2.2 Types",
      "text" : "We now give a syntax for the types of our calculus along with a typing relation. In the grammar below, α, β, γ. . . range over types, ν ranges over atomic types from some set T and E, E′. . . range over effect signatures (introduced below).\nThe types of our language consist of:\nα, β, γ ::= α → β [function]\n| ν [atom]\n| FE(α) [computation]\nThe only novelty here is the FE(α) computation type. This is the type of algebraic expressions whose atoms are terms of type α and whose operation symbols come from the effect signature E. We call them computation types and we call terms of these types computations because our algebraic expressions will always represent some kind of program with effects.\nEffect signatures are similar to typing contexts. They are partial mappings from the set of operation symbols E to pairs of types. We will write the elements of effect signatures the following way — op : α  β ∈ E means that E maps op to the pair of types α and β.5 When dealing with effect signatures, we will often make use of the disjoint union operator ⊎. The term E1 ⊎ E2 serves as a constraint demanding that the domains of E1 and E2 be disjoint and at the same time it denotes the effect signature that is the union of E1 and E2.\nThe typing rules are presented in Figure 1. The typing rules mirror the syntax of terms. Again, the first four rules come\nfrom STLC. The [η] and [ − ◦ ] rules are self-explanatory and so we will focus on the [op], [L M] and [C] rules.\n[op] To use an operation op : α  β, we provide the input parameter Mp : α and a continuation λx.Mc : β → FE(γ), which expects the output of type β. The resulting term has the same type as the body of the continuation, FE(γ).\nBefore, we have spoken of terms of type FE(γ) as of algebraic expressions generated by the terms of type γ and the operators in the effect signature E. However, having seen the typing rule for operation terms, it might not be obvious how such a term represents an algebraic expression. Traditionally, algebraic signatures map operation symbols to arities, which are natural numbers. Our effect signatures map each operation symbol to a pair of types α  β.\n– We can explain α by analogy to the single-sorted algebra of vector spaces. In a single-sorted vector space algebra, scalar multiplication is viewed as\n5 The two types α and β are to be seen as the operation’s input and output types, respectively.\na unary operation parameterized by some scalar. So technically, there is a different unary operation for each scalar. All of our operations are similarly parameterized and α is the type of that parameter. – The type β expresses the arity of the operator. When we say that an operator has arity β, where β is a type, we mean that it takes one operand for every value of β [24]. We can also think of the operator as taking one operand containing x : β as a free variable.\nWe can look at the algebraic expression opMp (λx.Mc) as a description of a program that:\n– interacts with its context by some operator called op – to which it provides the input Mp – and from which it expects to receive an output of type β – which it will then bind as the variable x and continue as the program de-\nscribed by Mc.\n[L M] The banana brackets describe iterators/catamorphisms.6 In the typing rule, E is the input’s signature, E′ is the output’s signature, γ is the input’s atom type and δ is the output’s atom type. E is decomposed into the operations that our\n6 These are similar to recursors/paramorphisms. See [20] for the difference. Catamorphisms are also known as folds and the common higher-order function fold found in functional programming languages is actually the iterator/catamorphism for lists.\niterator will actually interpret, the other operations form a residual signature Ef . The output signature will then still contain the uninterpreted operations Ef combined with any operations E′′ that our interpretation might introduce.\n[C] We said before that the C function will let us commute λ and operations. Here we see that, on the type level, this corresponds to commuting the FE( ) and the α → type constructors."
    }, {
      "heading" : "2.3 Reduction Rules",
      "text" : "We will now finally give a semantics to our calculus. The semantics will be given in the form of a reduction relation on terms. Even though the point of the calculus is to talk about effects, the reduction semantics will not be based on any fixed evaluation order; any subterm that is a redex can be reduced in any context. The reduction rules are given in Fig. 2."
    }, {
      "heading" : "L (opi:Mi)i∈I , η:Mη M (η N) → rule L η M",
      "text" : "We have the β and η rules, which, by no coincidence, are the same rules as the ones found in STLC. The rest are function definitions for L M, − ◦ and C.\nBy looking at the definition of L M, we see that it is an iterator. It replaces every occurrence of the constructors opj and η with Mj and Mη, respectively.\nThe C function recursively swaps C (λx. ) with opMp (λy. ) using the Cop rule. When C finally meets the η constructor, it swaps (λx. ) with η and terminates. Note that the constraint x /∈ FV(Mp) in rule Cop cannot be dismissed by renaming of bound variables. If the parameter Mp contains a free occurrence of x, the evaluation of C will get stuck. C is thus a partial function: it is only applicable when none of the operations being commuted with the λ-binder actually depend on the bound variable."
    }, {
      "heading" : "2.4 Common Combinators",
      "text" : "When demonstrating the calculus in the next section, the following combinators will be helpful. First, we define a sequencing operator. The operator ≫=, called bind, replaces all the α-typed atoms of a FE(α)-typed expression with FE(β)typed expressions. More intuitively, M ≫=N is the program that first runs M to get its result x and then continues as the program N x.\n≫= : FE(α) → (α → FE(β)) → FE(β)\nM ≫=N = L η:N MM\nThe type constructor FE along with the operators η and ≫= form a free monad. Using this monadic structure, we can define the following combinators (variations on application) which we will make heavy use of in Section 3.\n≪· : FE(α → β) → α → FE(β)\nF ≪· x = F ≫= (λf. η (f x))\n·≫ : (α → β) → FE(α) → FE(β)\nf ·≫X = X ≫= (λx. η (f x))\n≪·≫ : FE(α → β) → FE(α) → FE(β)\nF ≪·≫X = F ≫= (λf.X ≫= (λx. η (f x)))\nAll of these operators associate to the left, so f ·≫X ≪·≫ Y should be read as (f ·≫X)≪·≫ Y .\nLet ◦ : o → o → o be a binary operator on propositions. We define the following syntax for the same operator lifted to computations of propositions.\n◦ : FE(o) → FE(o) → FE(o)\nM ◦N = (λmn.m ◦ n) ·≫M ≪·≫N"
    }, {
      "heading" : "3 Linguistic Phenomena as Effects",
      "text" : ""
    }, {
      "heading" : "3.1 Deixis",
      "text" : "We will now try to use this calculus to do some semantics. Here is our tectogrammar in an abstract categorial grammar presentation [6].\nJohn,Mary,me : NP\nloves : NP −◦NP −◦ S\nAnd here is our semantics.\nJJohnK := η j\nJMaryK := ηm\nJmeK := speaker ⋆ (λx. η x)\nJlovesK := λOS. love ·≫ S ≪·≫ O\nIn the semantics for JmeK, we use the speaker operation to retrieve the current speaker and make it available as the value of the variable x. The star (⋆) passed to speaker is a dummy value of the unit type 1.\nThis, and all the semantics we will see in this paper, satisfies a homomorphism condition that whenever M : τ , then JMK : JτK. In our case, JNP K = FE(ι) and JSK = FE(o), where ι and o are the types of individuals and propositions, respectively. Of E, we assume that speaker : 1  ι ∈ E, since that is the type of speaker used in our semantics.7\nWith this fragment, we can give meanings to trivial sentences like:\n(1) John loves Mary.\n(2) Mary loves me.\nwhose meanings we can calculate as:\nJlovesMary JohnK ։ η (love jm) (1)\nJlovesmeMaryK ։ speaker ⋆ (λx. η (lovem x)) (2)\nThe meaning of (1) is a proposition of type o wrapped in η, i.e. something that we can interpret in a model. As for the meaning of (2), the speaker operator has propagated from the me lexical entry up to the meaning of the whole sentence. We now have an algebraic expression having as operands the propositions lovemx for all possible x : ι. In order to get a single proposition which is to be seen as the truth-conditional meaning of the sentence and which can be evaluated in a model, we will need to fix the speaker. We will do so by defining an interpreting handler.\nwithSpeaker : ι → F{speaker:1ι}⊎E(α) → FE(α)\nwithSpeaker = λsM. L speaker: (λxk. k s) MM\nNote that we omitted the η clause in the banana brackets above. In such cases, we say there is a default clause η: (λx. η x).\n7 1 is the unit type whose only element is written as ⋆.\nwithSpeaker s JlovesmeMaryK ։ η (lovem s)\nSo far, we could have done the same by introducing a constant named me to stand in for the speaker. However, since handlers are part of our object language, we can include them in lexical entries. With this, we can handle phenomena such as direct (quoted) speech, that rebinds the current speaker in a certain scope.\nsaidis : S −◦NP −◦ S\nsaidds : S −◦NP −◦ S\nThose are our new syntactic constructors: one for the indirect speech use of said and the other for the direct speech use (their surface realizations would differ typographically or phonologically). Let us give them some semantics.\nJsaidisK = λCS. say ·≫ S ≪·≫ C\n= λCS. S ≫= (λs. say s ·≫ C)\nJsaiddsK = λCS. S ≫= (λs. say s ·≫ (withSpeaker sC))\nHere we elaborated the entry for indirect speech so it is easier to compare with the one for direct speech, which just adds a use of the withSpeaker operator.\n(3) John said Mary loves me.\n(4) John said, “Mary loves me”.\nJsaidis (lovesmeMary)JohnK ։ speaker ⋆ (λx. η (say j (lovem x))) (3)\nJsaidds (lovesmeMary)JohnK ։ η (say j (lovemj)) (4)\nThe meaning of sentence (3) depends on the speaker (as testified by the use of the speaker operator) whereas in (4), this dependence has been eliminated due to the use of direct speech."
    }, {
      "heading" : "3.2 Quantification",
      "text" : "Now we turn our attention to quantificational noun phrases.\nevery,a : N −◦NP\nman,woman : N\nJeveryK := λN. scope (λc. ∀ ·≫ (C (λx. (N ≪· x)→ (c x)))) (λx. η x)\nJaK := λN. scope (λc. ∃ ·≫ (C (λx. (N ≪· x) ∧ (c x)))) (λx. η x)\nJmanK := ηman\nJwomanK := ηwoman\nThe entries for every and a might seem intimidating. However, if we ignore the ·≫, the C, the ≪· and the overline on the logical operator, we get the familiar\ngeneralized quantifiers. These decorations are the plumbing that takes care of the proper sequencing of effects.\nNote that we make use of the C operator here. In the denotation of JaK, the term (λx. (N ≪· x) ∧ (c x)) describes the property to which we want to apply the quantifier ∃. However, this term is of type ι → FE(o). In order to apply ∃, we need something of type ι → o. Intuitively, the effects of E correspond to the process of interpretation, the process of arriving at some logical form of the sentence. They should thus be independent of the particular individual that we use as a witness for x when we try to model-check the resulting logical form. This independence allows us use the C operator without fear of getting stuck. Once we arrive at the type FE(ι → o), it is a simple case of using ∃ ·≫ to apply the quantifier within the computation type.89\nWhile the terms that use the scope operator might be complex, the handler that interprets them is as simple as can be.\nSI = λM. L scope: (λck. c k) MM\nSame as with withSpeaker, SI will also be used in lexical items. By interpreting the scope operation in a particular place, we effectively determine the scope of the quantifier. Hence the name of SI, short for Scope Island. If we want to model clause boundaries as scope islands, we can do so by inserting SI in the lexical entries of clause constructors (in our case, the verbs).\nJlovesK := λOS. SI (JlovesKOS)\nJsaidisK := λCS. SI (JsaidisKC S)\nJsaiddsK := λCS. SI (JsaiddsKC S)\nWhenever we use the semantic brackets on the right-hand side of these revised definitions, they stand for the denotations we have assigned previously.\n(5) Every man loves a woman.\n(6) John said every woman loves me.\n(7) John said, “Every woman loves me”.\nJloves (awoman) (everyman)K\n։ η (∀x.man x → (∃y.woman y ∧ love x y)) (5)\nwithSpeaker s Jsaidis (lovesme (everywoman))JohnK\n։ η (say j (∀x.woman x → love x s)) (6)\nJsaidds (lovesme (everywoman))JohnK\n։ η (say j (∀x.woman x → love x j)) (7)\n8 Other solutions to this problem include separating the language of logical forms and the metalanguage used in the semantic lexical entries to manipulate logical forms as objects [13]. 9 Our C has been inspired by an operator of the same name proposed in [9]: de Groote introduces a structure that specializes applicative functors in a similar direction as monads by introducing the C operator and equipping it with certain laws; our C operator makes the FE type constructor an instance of this structure.\nThe calculus offers us flexibility when modelling the semantics. We might choose to relax the constraint that clauses are scope islands by keeping the old entries for verbs that do not use the SI handler. We might then want to add the SI handler to the lexical entry of saidds, next to the withSpeaker handler, so that quantifiers cannot escape quoted expressions. We might also allow for inverse scope readings by, e.g., providing entries for transitive verbs that evaluate their arguments right-to-left (though then we would have to watch out for crossover effects if we were to add anaphora)."
    }, {
      "heading" : "3.3 Conventional Implicature",
      "text" : "Our goal is to show the modularity of this approach and so we will continue and plug in one more phenomenon into our growing fragment: conventional implicatures, as analyzed by Potts [23]. Specifically, we will focus on nominal appositives.\nappos : NP −◦NP −◦NP\nbest-friend : NP −◦NP\nJapposK := λXY.X ≫= (λx. SI (η x= Y )≫= (λi. implicate i (λz. η x)))\nJbest-friendK := λX.best-friend ·≫X\nIn the denotation of the nominal appositive construction, appos, we first evaluate the head noun phrase X : JNP K to find its referent x : ι. We then want to implicate that x is equal to the referent of Y . The term η x = Y (note the line over =) is the term that computes that referent and gives us the proposition we want. We also want to state that no quantifier from within the appositive Y should escape into the matrix clause and so we wrap this computation in the SI handler to establish a scope island. Finally, we pass this proposition as an argument to implicate and we return x as the referent of the noun phrase.\nThe point of the implicate operation is to smuggle non-at-issue content outside the scope of logical operators. The contribution of an appositive should survive, e.g., logical negation.10 The place where we will accommodate the implicated truth-conditions will be determined by the use of the following handler:\naccommodate : F{implicate:o1}⊎E(o) → FE(o)\naccommodate = λM. L implicate: (λik. η i ∧ k ⋆) MM\nWe want conventional implicatures to project out of the common logical operators. However, when we consider direct quotes, we would not like to attribute the implicature made by the quotee to the quoter. We can implement this by inserting the accommodate handler into the lexical entry for direct speech.\nJsaiddsK := λCS. SI (S ≫= (λs. say s ·≫ (withSpeaker s (accommodate C))))\nConsider the following three examples.\n10 In our limited fragment, we will only see it sneak out of a quantifier.\n(8) John, my best friend, loves every woman.\n(9) Mary, everyone’s best friend, loves John.\n(10) A man said, “My best friend, Mary, loves me”.\nIn (8), the conventional implicature that John is the speaker’s best friend projects from the scope of the quantifier. On the other hand, in (10), the implicature does not project from the quoted clause and so it is not misattributed.\nwithSpeaker s (accommodate Jloves (everywoman) (appos John (best-friendme))K)\n։ η ((j = best-friend s) ∧ (∀x.woman x → love jx)) (8)\naccommodate Jloves John (apposMary (best-friend everyone))K\n։ η ((∀x.m = best-friendx) ∧ (lovemj)) (9)\nJsaidds (lovesme (appos (best-friendme)Mary)) (aman)K\n։ η (∃x.man x ∧ sayx ((best-friendx = m) ∧ (love (best-friendx)x))) (10)"
    }, {
      "heading" : "3.4 Summary",
      "text" : "Let us look back at the modularity of our approach and count how often during the incremental development of our fragment we either had to modify existing denotations or explicitly mention previous effects in new denotations.\nWhen adding quantification:\n– in the old denotations of verbs, we added the new SI handler so that clauses form scope islands\nWhen adding appositives and their conventional implicatures:\n– in the old denotations JsaiddsK, we added the new accommodate handler to state that conventional implicatures should not project out of quoted speech – in the new denotation JapposK, we used the old SI handler to state that appositives should form scope islands\nOtherwise, none of the denotations prescribed in our semantic lexicon had to be changed. We did not have to type-raise non-quantificational NP constructors like JJohnK, JmeK or Jbest-friendK. With the exception of direct speech, we did not have to modify any existing denotations to enable us to collect conventional implicatures from different subconstituents.\nFurthermore, all of the modifications we have performed to existing denotations are additions of handlers for new effects. This gives us a strong guarantee that all of the old results are conserved, since applying a handler to a computation which does not use the operations being handled changes nothing.\nThe goal of our calculus is to enable the creation of semantic lexicons with a high degree of separation of concerns. In this section, we have seen how it can be done for one particular fragment."
    }, {
      "heading" : "4 Properties of the Calculus",
      "text" : "The calculus defined in Sect. 2 and to which we will refer as Lλ M, has some satisfying properties.\nFirst of all, the reduction rules preserve types of terms (subject reduction). The reduction relation itself is confluent and, for well-typed terms, it is also terminating. This means that typed Lλ M is strongly normalizing.\nThe proof of subject reduction is a mechanical proof by induction. For confluence and termination, we employ very similar strategies: we make use of general results and show how they apply to our calculus. Due to space limitations, we will pursue in detail only the proof of confluence.\nOur reduction relation is given as a set of rules which map redexes matching some pattern into contracta built up out of the redexes’ free variables. However, our language also features binding, and so some of the rules are conditioned on whether or not certain variables occur freely in parts of the redex. Fortunately, such rewriting systems have been thoroughly studied. Klop’s Combinatory Reduction Systems (CRSs) [16] is one class of such rewriting systems.\nWe will make use of the result that orthogonal CRSs are confluent [16]. A CRS is orthogonal if it is left-linear and non-ambiguous. We will need to adapt our formulation of the reduction rules so that they form a CRS and we will need to check whether we satisfy left-linearity and non-ambiguity (we will see what these two properties mean when we get to them).\nWe refer the reader to [16] for the definition of CRSs. The key point is that in a CRS, the free variables which appear in the left-hand side of a rewrite rule, called metavariables, are explicitly annotated with the set of all free variables that are allowed to occur within a term which would instantiate them. This allows us to encode all of our x /∈ FV (M) constraints.\nOne detail which must be taken care of is the set notation (opi:Mi)i∈I and the indices I used in the L M rules. We do away with this notation by adding a separate rule for every possible instantiation of the schema. This means that for each sequence of distinct operation symbols op1,. . . ,opn, we end up with:\n– a special rewriting rule L op1:M1, . . . , opn:Mn, η:Mη M (η N) → Mη N – for every 1 ≤ i ≤ n, a special rewriting rule L op1:M1, . . . , opn:Mn, η:Mη M (opiNp (λx.Nc(x))) → MiNp (λx. L op1:M1, . . . , opn:Mn, η:Mη MNc(x)) – for every op′ ∈ E \\ {opi|1 ≤ i ≤ n}, a special rewriting rule L op1:M1, . . . , opn:Mn, η:Mη M (op\n′ Np (λx.Nc(x))) → op′ Np (λx. L op1:M1, . . . , opn:Mn, η:Mη MNc(x))\nSo now we have a CRS which defines the same reduction relation as the rules we have shown in 2.3. Next, we verify the two conditions. Left-linearity states that no left-hand side of any rule contains multiple occurrences of the same metavariable. By examining our rules, we find that this is indeed the case.11\n11 Multiple occurrences of the same opi are alright, since those are not metavariables.\nNon-ambiguity demands that there is no non-trivial overlap between any of the left-hand sides.12 In our CRS, we have overlaps between the β and the η rules. We split our CRS into one with just the η rule (→η) and one with all the other rules (→Lλ M). Now, there is no overlap in either of these CRSs, so they are both orthogonal and therefore confluent.\nWe then use the Lemma of Hindley-Rosen [17, p. 7] to show that the union of →Lλ M and →η is confluent when →Lλ M and →η are both confluent and commute together. For that, all that is left to prove is that →L λ M and →η commute. Thanks to another result due to Hindley [17, p. 8], it is enough to prove that for all a, b and c such that a →Lλ M b and a →η c, we have a d such that b ։η d and c →=Lλ M d. The proof of this is a straightforward induction on the structure of a."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In our contribution, we have introduced a new calculus motivated by modelling detailed semantics and inspired by current work in programming language theory. Our calculus is an extension of the simply-typed lambda calculus which is the de facto lingua franca of semanticists. Its purpose is to facilitate the communication of semantic ideas without depending on complex programming languages [19,15] and to do so with a well-defined formal semantics.\nWe have demonstrated the features of our calculus on several examples exhibiting phenomena such as deixis, quantification and conventional implicature. While our calculus still requires us to do some uninteresting plumbing to be able to correctly connect all the denotations together, we have seen that the resulting denotations are very generic. We were able to add new phenomena without having to change much of what we have done before and the changes we have made arguably corresponded to places where the different phenomena interact.\nFinally, we have also shown that the calculus shares some of the useful properties of the simply-typed lambda calculus, namely strong normalization.\nIn future work, it would be useful to automate some of the routine plumbing that we have to do in our terms. It will also be important to test the methodology on larger and more diverse fragments (besides this fragment, we have also created one combining anaphora, quantification and presupposition [19]). Last but not least, it would be interesting to delve deeper into the foundational differences between the approach used here, the monad transformers used by Charlow [4] and the applicative functors used by Kiselyov [13]."
    } ],
    "references" : [ {
      "title" : "Continuations and the nature of quantification",
      "author" : [ "C. Barker" ],
      "venue" : "Natural language semantics 10(3), 211–242",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Programming with algebraic effects and handlers",
      "author" : [ "A. Bauer", "M. Pretnar" ],
      "venue" : "arXiv preprint arXiv:1203.1539",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Programming and reasoning with algebraic effects and dependent types",
      "author" : [ "E. Brady" ],
      "venue" : null,
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2013
    }, {
      "title" : "On the semantics of exceptional scope",
      "author" : [ "S. Charlow" ],
      "venue" : "Ph.D. thesis, New York University",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Towards abstract categorial grammars",
      "author" : [ "P. de Groote" ],
      "venue" : "Proceedings of the 39th Annual Meeting on Association for Computational Linguistics. pp. 252–259. Association for Computational Linguistics",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Towards a montagovian account of dynamics",
      "author" : [ "P. de Groote" ],
      "venue" : "Proceedings of SALT. vol. 16",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Natural language semantics with enriched meanings",
      "author" : [ "G. Giorgolo", "A. Asudeh" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2015
    }, {
      "title" : "On Logical Relations and Conservativity",
      "author" : [ "P. de Groote" ],
      "venue" : "NLCS’15. Third Workshop on Natural Language and Computer Science",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Making computational sense of montague’s intensional logic",
      "author" : [ "J. Hobbs", "S. Rosenschein" ],
      "venue" : "Artificial Intelligence 9(3), 287–306",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1977
    }, {
      "title" : "Handlers in action",
      "author" : [ "O. Kammar", "S. Lindley", "N. Oury" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2013
    }, {
      "title" : "From discourse to logic: Introduction to modeltheoretic semantics of natural language, formal logic and discourse representation theory",
      "author" : [ "H. Kamp", "U. Reyle" ],
      "venue" : "No. 42, Kluwer Academic Pub",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Applicative abstract categorial grammars",
      "author" : [ "O. Kiselyov" ],
      "venue" : "Proceedings of the Third Workshop on Natural Language and Computer Science",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2015
    }, {
      "title" : "Extensible effects: an alternative to monad transformers",
      "author" : [ "O. Kiselyov", "A. Sabry", "C. Swords" ],
      "venue" : null,
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2013
    }, {
      "title" : "C.c.: Lambda: the ultimate syntax-semantics interface",
      "author" : [ "O. Kiselyov", "Shan" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2010
    }, {
      "title" : "Combinatory reduction systems: introduction and survey",
      "author" : [ "J.W. Klop", "V. Van Oostrom", "F. Van Raamsdonk" ],
      "venue" : null,
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1993
    }, {
      "title" : "Term rewriting systems",
      "author" : [ "Klop", "J.W" ],
      "venue" : "Handbook of logic in computer science 2, 1–116",
      "citeRegEx" : "17",
      "shortCiteRegEx" : null,
      "year" : 1992
    }, {
      "title" : "Expression de la dynamique du discours à l’aide de continuations",
      "author" : [ "E. Lebedeva" ],
      "venue" : "Ph.D. thesis, Université de Lorraine",
      "citeRegEx" : "18",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "Algebraic Effects and Handlers in Natural Language Interpretation",
      "author" : [ "J. Marš́ık", "M. Amblard" ],
      "venue" : "Natural Language and Computer Science",
      "citeRegEx" : "19",
      "shortCiteRegEx" : null,
      "year" : 2014
    }, {
      "title" : "Functional programming with bananas, lenses, envelopes and barbed wire",
      "author" : [ "E. Meijer", "M. Fokkinga", "R. Paterson" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1991
    }, {
      "title" : "Notions of computation and monads",
      "author" : [ "E. Moggi" ],
      "venue" : "Information and computation 93(1), 55–92",
      "citeRegEx" : "21",
      "shortCiteRegEx" : null,
      "year" : 1991
    }, {
      "title" : "Handlers of algebraic effects",
      "author" : [ "G. Plotkin", "M. Pretnar" ],
      "venue" : "Programming Languages and Systems, pp. 80–94. Springer",
      "citeRegEx" : "22",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "The logic of conventional implicatures",
      "author" : [ "C. Potts" ],
      "venue" : "Oxford University Press",
      "citeRegEx" : "23",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Logic and handling of algebraic effects",
      "author" : [ "M. Pretnar" ],
      "venue" : null,
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2010
    }, {
      "title" : "Event in compositional dynamic semantics",
      "author" : [ "S. Qian", "M. Amblard" ],
      "venue" : "Logical Aspects of Computational Linguistics",
      "citeRegEx" : "25",
      "shortCiteRegEx" : null,
      "year" : 2011
    }, {
      "title" : "Monads for natural language semantics",
      "author" : [ "C. Shan" ],
      "venue" : "arXiv cs/0205026",
      "citeRegEx" : "26",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Linguistic side effects",
      "author" : [ "Shan", "C.c." ],
      "venue" : "Ph.D. thesis, Harvard University Cambridge, Massachusetts",
      "citeRegEx" : "27",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Computational semantics with functional programming",
      "author" : [ "J. Van Eijck", "C. Unger" ],
      "venue" : "Cambridge University Press",
      "citeRegEx" : "28",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "The essence of functional programming",
      "author" : [ "P. Wadler" ],
      "venue" : "Proceedings of the 19th ACM SIGPLAN-SIGACT symposium on Principles of programming languages. pp. 1–14. ACM",
      "citeRegEx" : "29",
      "shortCiteRegEx" : null,
      "year" : 1992
    } ],
    "referenceMentions" : [ {
      "referenceID" : 24,
      "context" : "It was previously observed [26] that the lambda terms and/or the denotations studied tend to follow the same pattern: they are instances of a monad.",
      "startOffset" : 27,
      "endOffset" : 31
    }, {
      "referenceID" : 20,
      "context" : "In this paper, we present an extension of the simplytyped lambda calculus that exploits this uniformity using the recently discovered technique of effect handlers [22].",
      "startOffset" : 163,
      "endOffset" : 167
    }, {
      "referenceID" : 10,
      "context" : "– the incremental algorithm used to build discourse representation structures in DRT, as presented in [12] – the λμ calculus, used in [5] to analyze quantification, since, due to the lack of confluence, function terms do not denote functions over simple denotations – the use of exceptions and exception handlers in [18] to model presuppositions in an otherwise compositional framework – the parsetree interpretation step in the logic of conventional implicatures of [23] that builds the denotation of a sentence by extracting implicatures from the denotations of its subparts (including the non-immediate ones)",
      "startOffset" : 102,
      "endOffset" : 106
    }, {
      "referenceID" : 16,
      "context" : "– the incremental algorithm used to build discourse representation structures in DRT, as presented in [12] – the λμ calculus, used in [5] to analyze quantification, since, due to the lack of confluence, function terms do not denote functions over simple denotations – the use of exceptions and exception handlers in [18] to model presuppositions in an otherwise compositional framework – the parsetree interpretation step in the logic of conventional implicatures of [23] that builds the denotation of a sentence by extracting implicatures from the denotations of its subparts (including the non-immediate ones)",
      "startOffset" : 316,
      "endOffset" : 320
    }, {
      "referenceID" : 21,
      "context" : "– the incremental algorithm used to build discourse representation structures in DRT, as presented in [12] – the λμ calculus, used in [5] to analyze quantification, since, due to the lack of confluence, function terms do not denote functions over simple denotations – the use of exceptions and exception handlers in [18] to model presuppositions in an otherwise compositional framework – the parsetree interpretation step in the logic of conventional implicatures of [23] that builds the denotation of a sentence by extracting implicatures from the denotations of its subparts (including the non-immediate ones)",
      "startOffset" : 467,
      "endOffset" : 471
    }, {
      "referenceID" : 0,
      "context" : "the speaker and addressee for deixis, the current world for modality), since they amount to saying that a phrase denotes an indexed set of simpler meanings – the continuized semantics for quantification [1] in which denotations are functions of their own continuations • and more generally, any semantics using type raising or generalized quantifiers for noun phrase denotations – the dynamic denotations of [7] that are functions of the common ground and their continuation – compositional event semantics, such as the one in [25], that shift the denotations of sentences from truth-values to predicates on events",
      "startOffset" : 203,
      "endOffset" : 206
    }, {
      "referenceID" : 5,
      "context" : "the speaker and addressee for deixis, the current world for modality), since they amount to saying that a phrase denotes an indexed set of simpler meanings – the continuized semantics for quantification [1] in which denotations are functions of their own continuations • and more generally, any semantics using type raising or generalized quantifiers for noun phrase denotations – the dynamic denotations of [7] that are functions of the common ground and their continuation – compositional event semantics, such as the one in [25], that shift the denotations of sentences from truth-values to predicates on events",
      "startOffset" : 408,
      "endOffset" : 411
    }, {
      "referenceID" : 23,
      "context" : "the speaker and addressee for deixis, the current world for modality), since they amount to saying that a phrase denotes an indexed set of simpler meanings – the continuized semantics for quantification [1] in which denotations are functions of their own continuations • and more generally, any semantics using type raising or generalized quantifiers for noun phrase denotations – the dynamic denotations of [7] that are functions of the common ground and their continuation – compositional event semantics, such as the one in [25], that shift the denotations of sentences from truth-values to predicates on events",
      "startOffset" : 527,
      "endOffset" : 531
    }, {
      "referenceID" : 19,
      "context" : "– in denotational semantics to give the domain of interpretation for programming languages that involve side effects [21].",
      "startOffset" : 117,
      "endOffset" : 121
    }, {
      "referenceID" : 27,
      "context" : "– in functional programming to emulate programming with side effects via term-level encodings of effectful programs [29].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 25,
      "context" : "The relationship between side effects in functional programming and computational semantics has been developed in several works [27,28], stretching as far back as 1977 [10].",
      "startOffset" : 128,
      "endOffset" : 135
    }, {
      "referenceID" : 26,
      "context" : "The relationship between side effects in functional programming and computational semantics has been developed in several works [27,28], stretching as far back as 1977 [10].",
      "startOffset" : 128,
      "endOffset" : 135
    }, {
      "referenceID" : 8,
      "context" : "The relationship between side effects in functional programming and computational semantics has been developed in several works [27,28], stretching as far back as 1977 [10].",
      "startOffset" : 168,
      "endOffset" : 172
    }, {
      "referenceID" : 24,
      "context" : "The usefulness of monads in particular has been discovered by Shan in 2002 [26].",
      "startOffset" : 75,
      "endOffset" : 79
    }, {
      "referenceID" : 3,
      "context" : "Charlow used the popular method of monad morphisms to combine several monads in his dissertation [4].",
      "startOffset" : 97,
      "endOffset" : 100
    }, {
      "referenceID" : 6,
      "context" : "Giorgolo and Asudeh have used distributive laws to combine monads [8], while Kiselyov has eschewed monads altogether in favor of applicative functors which enjoy easy composability [13].",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 11,
      "context" : "Giorgolo and Asudeh have used distributive laws to combine monads [8], while Kiselyov has eschewed monads altogether in favor of applicative functors which enjoy easy composability [13].",
      "startOffset" : 181,
      "endOffset" : 185
    }, {
      "referenceID" : 1,
      "context" : "Our approach follows the recent trend in adopting effects and handlers to combine side effects [2,11] and to encode effectful programs in pure functional programming languages [14,3].",
      "startOffset" : 95,
      "endOffset" : 101
    }, {
      "referenceID" : 9,
      "context" : "Our approach follows the recent trend in adopting effects and handlers to combine side effects [2,11] and to encode effectful programs in pure functional programming languages [14,3].",
      "startOffset" : 95,
      "endOffset" : 101
    }, {
      "referenceID" : 12,
      "context" : "Our approach follows the recent trend in adopting effects and handlers to combine side effects [2,11] and to encode effectful programs in pure functional programming languages [14,3].",
      "startOffset" : 176,
      "endOffset" : 182
    }, {
      "referenceID" : 2,
      "context" : "Our approach follows the recent trend in adopting effects and handlers to combine side effects [2,11] and to encode effectful programs in pure functional programming languages [14,3].",
      "startOffset" : 176,
      "endOffset" : 182
    }, {
      "referenceID" : 18,
      "context" : "See [20] for the introduction of banana brackets.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 22,
      "context" : "When we say that an operator has arity β, where β is a type, we mean that it takes one operand for every value of β [24].",
      "startOffset" : 116,
      "endOffset" : 120
    }, {
      "referenceID" : 18,
      "context" : "See [20] for the difference.",
      "startOffset" : 4,
      "endOffset" : 8
    }, {
      "referenceID" : 4,
      "context" : "Here is our tectogrammar in an abstract categorial grammar presentation [6].",
      "startOffset" : 72,
      "endOffset" : 75
    }, {
      "referenceID" : 11,
      "context" : "8 Other solutions to this problem include separating the language of logical forms and the metalanguage used in the semantic lexical entries to manipulate logical forms as objects [13].",
      "startOffset" : 180,
      "endOffset" : 184
    }, {
      "referenceID" : 7,
      "context" : "9 Our C has been inspired by an operator of the same name proposed in [9]: de Groote introduces a structure that specializes applicative functors in a similar direction as monads by introducing the C operator and equipping it with certain laws; our C operator makes the FE type constructor an instance of this structure.",
      "startOffset" : 70,
      "endOffset" : 73
    }, {
      "referenceID" : 21,
      "context" : "Our goal is to show the modularity of this approach and so we will continue and plug in one more phenomenon into our growing fragment: conventional implicatures, as analyzed by Potts [23].",
      "startOffset" : 183,
      "endOffset" : 187
    }, {
      "referenceID" : 14,
      "context" : "Klop’s Combinatory Reduction Systems (CRSs) [16] is one class of such rewriting systems.",
      "startOffset" : 44,
      "endOffset" : 48
    }, {
      "referenceID" : 14,
      "context" : "We will make use of the result that orthogonal CRSs are confluent [16].",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 14,
      "context" : "We refer the reader to [16] for the definition of CRSs.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 17,
      "context" : "Its purpose is to facilitate the communication of semantic ideas without depending on complex programming languages [19,15] and to do so with a well-defined formal semantics.",
      "startOffset" : 116,
      "endOffset" : 123
    }, {
      "referenceID" : 13,
      "context" : "Its purpose is to facilitate the communication of semantic ideas without depending on complex programming languages [19,15] and to do so with a well-defined formal semantics.",
      "startOffset" : 116,
      "endOffset" : 123
    }, {
      "referenceID" : 17,
      "context" : "It will also be important to test the methodology on larger and more diverse fragments (besides this fragment, we have also created one combining anaphora, quantification and presupposition [19]).",
      "startOffset" : 190,
      "endOffset" : 194
    }, {
      "referenceID" : 3,
      "context" : "Last but not least, it would be interesting to delve deeper into the foundational differences between the approach used here, the monad transformers used by Charlow [4] and the applicative functors used by Kiselyov [13].",
      "startOffset" : 165,
      "endOffset" : 168
    }, {
      "referenceID" : 11,
      "context" : "Last but not least, it would be interesting to delve deeper into the foundational differences between the approach used here, the monad transformers used by Charlow [4] and the applicative functors used by Kiselyov [13].",
      "startOffset" : 215,
      "endOffset" : 219
    } ],
    "year" : 2017,
    "abstractText" : "In compositional model-theoretic semantics, researchers assemble truth-conditions or other kinds of denotations using the lambda calculus. It was previously observed [26] that the lambda terms and/or the denotations studied tend to follow the same pattern: they are instances of a monad. In this paper, we present an extension of the simplytyped lambda calculus that exploits this uniformity using the recently discovered technique of effect handlers [22]. We prove that our calculus exhibits some of the key formal properties of the lambda calculus and we use it to construct a modular semantics for a small fragment that involves multiple distinct semantic phenomena.",
    "creator" : "LaTeX with hyperref package"
  }
}