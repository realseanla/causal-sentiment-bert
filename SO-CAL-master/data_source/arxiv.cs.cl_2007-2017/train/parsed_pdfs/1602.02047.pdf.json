{
  "name" : "1602.02047.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Elvys Linhares Pontes UTILIZAÇÃO DE GRAFOS E MATRIZ DE SIMILARIDADE NA SUMARIZAÇÃO AUTOMÁTICA DE DOCUMENTOS BASEADA EM EXTRAÇÃO DE FRASES",
    "authors" : [ "Elvys Linhares Pontes" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n60 2.\n02 04\n7v 1\n[ cs\n.C L\n] 5\nF eb\n2 01\n6\nUniversidade Federal do Ceará\nCampus de Sobral\nPrograma de Pós-Graduação em Engenharia Elétrica e de Computação\nElvys Linhares Pontes\nUTILIZAÇÃO DE GRAFOS E MATRIZ DE\nSIMILARIDADE NA SUMARIZAÇÃO AUTOMÁTICA DE\nDOCUMENTOS BASEADA EM EXTRAÇÃO DE FRASES\nSobral\n2015\nElvys Linhares Pontes\nUTILIZAÇÃO DE GRAFOS E MATRIZ DE SIMILARIDADE NA SUMARIZAÇÃO AUTOMÁTICA DE DOCUMENTOS BASEADA EM EXTRAÇÃO DE FRASES\nDissertação submetida à coordenação do programa de Pós-Graduação em Engenharia Elétrica e de Computação da Universidade Federal do Ceará, como requisito parcial para obtenção do grau de mestre em Engenheiro Elétrico e de Computação.\nOrientadora: Profa. Dra. Andréa Carneiro Linhares Co-orientador: Prof. Dr. Juan-Manuel Torres-Moreno\nSobral\n2015\nAGRADECIMENTOS\nAgradeço primeiramente a Deus. A minha orientadora Andréa e meu co-orientadorJuan-Manuel pela ajuda e paciência no trabalho. À FUNCAP pelo fomento e à Universidade Federal do Ceará. A todos os meus professores, amigos e a minha querida família. Em especial, eu quero agradecer a minha namorada Polyanna por sempre me apoiar e incentivar a enfrentar os obstáculos e aventuras da vida e superá-los.\nElvys Linhares.\nRESUMO\nA internet possibilitou o aumento da quantidade de informação disponível. Entretanto,as práticas de ler e compreender essas informações são tarefas dispendiosas. Nesse cenário, as aplicações de Processamento de Linguagem Natural (PLN) possibilitam soluções muito importantes, destacando-se a Sumarização Automática de Textos (SAT), que produz um resumo a partir de um ou mais textos-fontes. Resumir um ou mais textos de forma automática, contudo, é uma tarefa complexa devido às dificuldades inerentes à análise e geração desse resumo. Esta dissertação descreve as principais técnicas e metodologias (PLN e heurísticas) para a geração de sumários. São igualmente abordados e propostos alguns métodos heurísticos baseados em Grafos e em Matriz de Similaridade para mensurar a relevância das sentenças e gerar resumos por extração de sentenças. Foram utilizados os corpus multi-idioma (Espanhol, Francês e Inglês), CSTNews (Português do Brasil), RPM (Francês) e DECODA (Francês) para avaliar os sistemas desenvolvidos e os resultados assim obtidos foram bastante interessantes.\nPalavras-chave: Processamento da Linguagem Natural, Sumarização Automática de Textos, Grafos, Matriz de Similaridade.\nABSTRACT\nThe internet increased the amount of information available. However, the readingand understanding of this information are costly tasks. In this scenario, the Natural Language Processing (NLP) applications enable very important solutions, highlighting the Automatic Text Summarization (ATS), which produce a summary from one or more source texts. Automatically summarizing one or more texts, however, is a complex task because of the difficulties inherent to the analysis and generation of this summary. This master’s thesis describes the main techniques and methodologies (NLP and heuristics) to generate summaries. We have also addressed and proposed some heuristics based on graphs and similarity matrix to measure the relevance of judgments and to generate summaries by extracting sentences. We used the multiple languages (English, French and Spanish), CSTNews (Brazilian Portuguese), RPM (French) and DECODA (French) corpus to evaluate the developped systems. The results obtained were quite interesting.\nKeywords: Natural Language Processing, Automatic Text Summarization, Graph, Similarity Matrix.\nLISTA DE FIGURAS\n1 Exemplo de compressão de sentenças utilizando grafos [Filippova 2010]. . . 25 2 Estrutura para fusão de sentenças similares. . . . . . . . . . . . . . . . . . 28 3 Arquitetura do sistema CSTSumm [Jorge, Pardo e Salgueiro 2010]. . . . . 29 4 Estrutura Multi-document Rhetorical Structure (MRS) [Xu et al. 2013]. . . 29 5 Exemplo de um grafo G (a) e seu complemento Ḡ (b). . . . . . . . . . . . . 36 6 Exemplos de grafo conexo (a) e desconexo (b). . . . . . . . . . . . . . . . . 36 7 Exemplo de Clique. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 8 Exemplo de Subconjunto Independente de Vértices (SIV) (a) e Subconjunto\nIndependente Máximo (SIM) (b). . . . . . . . . . . . . . . . . . . . . . . . 37\n9 Modelo Espaço Vetorial (MEV) do tema global. . . . . . . . . . . . . . . . 39 10 MEV do peso lexical. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 11 Funcionamento do sistema Cortex. . . . . . . . . . . . . . . . . . . . . . . 40 12 Funcionamento do sistema SASI. . . . . . . . . . . . . . . . . . . . . . . . 48 13 Sistema RAG. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 14 Sistema LIA-RAG. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 15 Funcionamento do sistema SUMMatrix. . . . . . . . . . . . . . . . . . . . . 53 16 Sistema SUMMatrix. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\nLISTA DE GRÁFICOS\n7.1 Desempenho do sistema SASI para o corpus multi-idioma. . . . . . . . . . 67 7.2 Avaliação FRESA dos sistemas usando CSTNews. . . . . . . . . . . . . . . 69 7.3 Avaliação ROUGE dos sistemas usando CSTNews. . . . . . . . . . . . . . . 69 7.4 Avaliação ROUGE dos sistemas usando o corpus RPM. . . . . . . . . . . . 71\nLISTA DE TABELAS\n5.1 Texto integrando o cluster do corpus CSTNews [Dias et al. 2014]. . . . . 56 5.2 Relevância das sentenças segundo o sistema RAG. . . . . . . . . . . . . . . 57 5.3 Divergência entre as frases dos textos T1 e T2. . . . . . . . . . . . . . . . . 57 5.4 Divergência entre as sentenças selecionadas e o cluster. . . . . . . . . . . . 57 5.5 Divergência entre as frases do Resumo Parcial e o texto T3. . . . . . . . . 57 5.6 Divergência entre as sentenças selecionadas e o cluster. . . . . . . . . . . . 58 5.7 Cluster com 3 textos de diferentes jornais relatando um mesmo acidente\nno Congo (corpus CSTNews [Dias et al. 2014]). . . . . . . . . . . . . . . . 59\n6.1 Estatística do corpus DECODA. . . . . . . . . . . . . . . . . . . . . . . . . 61 7.1 Nível de similaridade relacionado à divergência JS . . . . . . . . . . . . . . 66 7.2 Tamanho dos resumos obtidos para um conjunto de valores da DJS. . . . . 66 7.3 Análise da precisão dos resumos gerados automaticamente. . . . . . . . . . 67 7.4 Experimentos com o CSTNews para resumos sem referências. . . . . . . . . 68 7.5 Experimentos com o CSTNews usando resumos de profissionais. . . . . . . 68 7.6 Tempo de execução dos sistemas usando o corpus CSTNews. . . . . . . . . 70 7.7 Avaliação ROUGE dos sistemas utilizando um único cluster do RPM. . . . 70 7.8 Avaliação ROUGE dos sistemas utilizando dois clusters do RPM. . . . . . 71 7.9 Avaliação dos sistemas usando o corpus de treinamento DECODA. . . . . . 72 7.10 Avaliação dos sistemas usando o corpus de teste DECODA. . . . . . . . . . 72\nLISTA DE SIGLAS E ACRÔNIMOS\nArtex Autre Resumeur TEXtuel\nCAS Chemical Abstracts Service\nCST Cross-document Structure Theory DVS Decomposição de Valores Singulares FMN Fatorização de Matrizes Não-negativas\nFRESA FRamework for Evaluating Summaries Automatically JS Jensen-Shannon\nISF Inverse Sentence Frequency KL Kullback-Leibler\nLSA Latent Semantic Analysis MEV Modelo Espaço Vetorial\nMRS Multi-document Rhetorical Structure PCM Problema do Caminho Mínimo PLI Programação Linear Inteira PLN Processamento da Linguagem Natural\nRAG Résumeur Avec de Graphes\nROUGE Recall-Oriented Understudy for Gisting Evaluation SASI Sumarizador Automático baseado em Subconjunto Independente SAT Sumarização Automática de Textos SIM Subconjunto Independente Máximo SIV Subconjunto Independente de Vértices\nSUMMatrix SUMmarizer based on Matrix model\nSVR Support Vector Regression\nTF Term Frequency\nTF-IDF Term Frequency - Inverse Document Frequency\nTF-ISF Term Frequency - Inverse Sentence Frequency\nVSM Vector Space Model\nSÍMBOLOS E NOTAÇÕES\nNesta seção são apresentados os símbolos e as notações utilizadas nesta dissertação.De forma geral, os escalares e os vetores serão representados por letras em itálico e as matrizes por letras romanas maiúsculas em negrito. Outras convenções são listadas a seguir:\nConjuntos e Espaços Vetoriais R Conjunto dos números reais Vetores e Matrizes S Matriz de saco de palavras M Matriz de palavras Funções e outros operadores logb (·) Função logarítmica de base b\nSUMÁRIO\n1 Introdução 14\n1.1 Processamento da Linguagem Natural . . . . . . . . . . . . . . . . . . . . . 16\n1.2 Justificativa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n1.3 Objetivos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n1.4 Estrutura . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19"
    }, {
      "heading" : "2 Estado da arte 21",
      "text" : "2.1 Fatoração de Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.2 Grafos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.3 Métodos Heurísticos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.4 Programação Linear Inteira . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.5 Submodular . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n2.6 Sumarização por abstração . . . . . . . . . . . . . . . . . . . . . . . . . . . 27"
    }, {
      "heading" : "3 Modelagem do Problema 31",
      "text" : "3.1 Saco de palavras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n3.2 Relevância das palavras e frases . . . . . . . . . . . . . . . . . . . . . . . . 32\n3.3 Similaridade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n3.3.1 Similaridade do cosseno . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.3.2 Similaridade de Jaccard . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.4 Divergência . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n3.4.1 Divergência de Kullback-Leibler . . . . . . . . . . . . . . . . . . . . 34\n3.4.2 Divergência de Jensen-Shannon . . . . . . . . . . . . . . . . . . . . 34\n3.5 Grafos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n3.5.1 Conceitos gerais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n3.5.2 Problema da Clique e do Subconjunto Independente . . . . . . . . . 36"
    }, {
      "heading" : "4 Sistemas de Sumarização Automática de Textos na Literatura 38",
      "text" : "4.1 Artex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n4.2 Cortex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n4.3 Enertex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n4.4 GistSumm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n4.5 KLSumm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n4.6 LexRank . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n4.7 Programação Linear Inteira . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n4.8 Submodular . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n4.9 TextRank . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45"
    }, {
      "heading" : "5 Sistemas propostos 46",
      "text" : "5.1 Sumarizador Automático baseado em Subconjunto Independente (SASI) . 46\n5.1.1 Funcionamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n5.1.2 Exemplo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n5.2 Résumeur Avec de Graphes (RAG) . . . . . . . . . . . . . . . . . . . . . . 49\n5.2.1 Funcionamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n5.2.2 Exemplo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n5.3 LIA-RAG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n5.3.1 Funcionamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n5.4 SUMmarizer based on Matrix model (SUMMatrix) . . . . . . . . . . . . . . 52\n5.4.1 Funcionamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n5.4.2 Exemplo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54"
    }, {
      "heading" : "6 Corpus e métodos de avaliação 60",
      "text" : "6.1 Corpus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n6.1.1 Corpus multi-idioma . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n6.1.2 CSTNews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n6.1.3 RPM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n6.1.4 DECODA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n6.2 Métodos de avaliação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n6.2.1 Métricas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n6.2.2 ROUGE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n6.2.3 FRESA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64"
    }, {
      "heading" : "7 Avaliação Experimental 65",
      "text" : "7.1 Avaliação do sistema SASI (Corpus multi-idioma) . . . . . . . . . . . . . . 65\n7.2 Avaliação do sistema SUMMatrix (Corpus CSTNews) . . . . . . . . . . . . 68\n7.3 Avaliação do sistema RAG (Corpus RPM) . . . . . . . . . . . . . . . . . . 70\n7.4 Avaliação dos sistemas LIA-RAG e RAG (Corpus DECODA) . . . . . . . . 70\n7.5 Análise geral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72"
    }, {
      "heading" : "8 Conclusão e Trabalhos Futuros 75",
      "text" : "8.1 Trabalhos futuros . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\nReferências Bibliográficas 77\n14\nCAPÍTULO 1\nINTRODUÇÃO\nO avanço tecnológico possibilitou melhorar e aumentar a velocidade de comunicação mundial através da transmissão de vídeos, imagens e sons. Atualmente, grande parte dos livros possui uma versão digital ou áudio e a popularização das redes sociais (como Facebook, Twitter, Youtube, entre outros) e sítios de notícias possibilitaram um grande aumento da quantidade de informações trafegadas pela internet acerca dos mais diversos assuntos. Todos os dias, uma quantidade considerável de informações é adicionada em vários sítios com comentários, fotos, vídeos e áudio. Dessa forma, um acontecimento é rapidamente divulgado na Web por diferentes fontes de notícias e formatos (áudio, imagem, texto e vídeo).\nO leitor, além de não possuir tempo hábil para ler essa quantidade de informações, não se interessa por todos os assuntos propostos e, geralmente, seleciona o conteúdo do seu interesse. Vale destacar que grande parte da informação criada a todo momento é pessoal como, por exemplo, comentários da vida cotidiana, fotos e vídeos pessoais divulgados em redes sociais e blogs. Assim, parte dessas informações não é importante para o público em geral. Por isso, os jornais, filmes, livros, revistas, sites e blogs possuem manchetes, sumários ou sinopses dos assuntos abordados. O leitor, ao ler as manchetes de um jornal, identifica o assunto de cada notícia e, então, pode escolher qual delas ler na íntegra. O processo é similar para livros e filmes com suas sinopses e os destaques nos sítios e blogs. Dessa forma, o leitor identifica rapidamente o assunto de seu interesse para em seguida dar sequência à leitura.\nAs manchetes e sinopses de livros e filmes (entre outros) são tipos de resumos. De forma geral, o “resumo” é composto pela ideia principal apresentada no documento original de forma curta e objetiva. Para uma melhor compreensão dessa palavra seguem algumas\n1 Introdução 15\ndefinições existentes na literatura e em dicionários:\n◮ Condensação em poucas palavras do que foi dito ou escrito mais extensamente1;\n◮ É a abreviação, representação precisa do conteúdo do documento original,\npreferencialmente feita pelo autor do documento;\n◮ É um produzido de um ou mais textos, que contém as informações importantes do\ntexto original, e não pode ser maior que a metade do texto original.\nO resumo deve conter as principais informações do texto original de forma clara e concisa possibilitando a compreensão do mesmo. Ele pode ser criado utilizando diferentes estratégias. Entretanto, cada uma delas cria um resumo diferente com características específicas (boas ou ruins). O homem geralmente segue uma metodologia para criar um resumo. Inicialmente, ele lê o texto e seleciona as principais informações. Com esses dados e seu conhecimento, ele constrói novas frases de tamanho menor contendo as informações relevantes e a ideia geral contida no texto original.\nOutra característica fundamental do resumo é o seu tamanho. O resumo pode ser produzido em diferentes tamanhos dependendo do fim almejado. Por exemplo, as manchetes de notícias de jornais e sítios possuem poucas palavras para chamar a atenção do leitor e transmitir a ideia chave da notícia. Entretanto, os textos mais longos necessitam um resumo mais extenso para o leitor compreender o assunto do texto, como é o caso de livros, que necessitam resumos maiores que uma notícia do cotidiano para ter sua ideia geral transmitida. Uma forma de mensurar o tamanho do resumo é analisar sua quantidade de palavras ou caracteres. Outra forma possível é a taxa de compressão tc, que é responsável por definir o tamanho do resumo em relação ao seu texto original. Ela é definida pela equação 1.1.\ntc = |resumo|\n|texto| (1.1)\nO resumo é um processo de compressão que remove o conteúdo não relevante e mantém as informações fundamentais do texto. Quanto menor o valor da tc, menor será o tamanho do resumo do texto analisado. Essa redução, até um certo nível, melhora a qualidade do resumo pois ressalta as principais informações do mesmo. Entretanto, a redução exagerada do texto ocasiona a perda de informações relevantes e de sua compreensibilidade. Vários trabalhos analisaram a melhor taxa de compressão do documento fonte para manter um\n1Dicionário Michaelis online: http://michaelis.uol.com.br"
    }, {
      "heading" : "1.1 Processamento da Linguagem Natural 16",
      "text" : "resumo pequeno com ideias claras e concisas. Segundo [Lin 1999], a taxa de compressão variando entre 0, 15 e 0, 30 possibilita criar bons resumos sem perder as principais informações do texto.\nAlguns resumos possuem estrutura e tamanho específicos, como é caso dos Twitter e SMS [Inouye e Kalita 2011], que contêm um limite de caracteres pré-determinado e diferentes gírias e abreviações. Nesses casos, é necessário uma filtragem de expressões (hashtags, smilefaces, links, entre outros) e um novo vocabulário contendo-as para analisar as mensagens e criar os resumos utilizando-as.\nO resumo facilita e acelera a obtenção de informações relevantes para o leitor. Entretanto, a grande quantidade de textos e o custo elevado de resumidores profissionais tornam impossível resumir muitos documentos em tempo hábil e com custo acessível. Uma solução para esse problema apresenta-se através da análise e da criação automática de resumos de textos."
    }, {
      "heading" : "1.1 Processamento da Linguagem Natural",
      "text" : "O Processamento da Linguagem Natural (PLN) é uma área de pesquisa envolvendo Linguística, Inteligência Artificial e Ciências da Computação, com o propósito de fazer a interação entre a linguagem natural humana e das máquinas. É necessário um grande conhecimento dos idiomas e expressões corporais, orais e escritas para realizar a análise correta de um texto, imagem ou video. Os computadores ainda não conseguem realizar esse processo perfeitamente, pois a complexidade para representar e identificar completamente a estrutura sintática e semântica de um documento é elevada. O PLN necessita da [Dyer 1995]:\n◮ Representação de conhecimentos abstratos;\n◮ Aprendizagem de módulos de processamento e troca de informações entre eles;\n◮ Criação e propagação de ligações dinâmicas;\n◮ Manipulação de estruturas;\n◮ Aquisição e acesso a memórias lexicais, semânticas e episódicas.\nO PLN possui diversos campos de estudo: análise do discurso, separação morfológica, tradução automática, geração e compreensão da linguagem natural (mensagem escrita e"
    }, {
      "heading" : "1.1 Processamento da Linguagem Natural 17",
      "text" : "oral), reconhecimento de caracteres, reconhecimento de discurso e análise de sentimentos, etc. As principais aplicações do PLN são: Sumarização Automática de Textos (SAT), tradução automática, reconhecimento de discurso, compressão textual, corretor automático e pergunta resposta.\nA SAT consiste em resumir um ou mais textos de forma automática. Esses textos podem estar presentes em um banco de dados, repositório local ou remoto. O sistema sumarizador analisa os textos identificando os dados relevantes e cria um novo texto baseado nessas informações. Para isso, é necessário reconhecer as palavras, a estrutura das sentenças e analisar a estrutura sintática das frases, verificando as palavras e seus significados em cada sentença. Dessa forma, o sistema identifica os dados relevantes e cria um novo texto através de paráfrases (ou extração de frases) com o conteúdo dessas informações.\nA tradução automática consiste no processo de traduzir um texto de qualquer idioma para outro. Essa tarefa é bem complexa, pois é necessário saber a semântica e a gramática de cada idioma para compreender o texto com suas variâncias linguísticas regionais e traduzir as sentenças para outro idioma. Dessa forma, é possível traduzir um texto mantendo a sua coesão e coerência.\nA extração de dados obtém as informações específicas de um ou mais textos. Elas podem ser obtidas de forma simples ou através de sinônimos, da reordenação de expressões ou da análise de expressões similares para identificar os dados desejados.\nO reconhecimento do discurso realiza o reconhecimento textual de uma mensagem por meio de uma conversa entre pessoas ou de um áudio. Já a compressão textual analisa um texto e reduz o seu conteúdo mantendo sua informatividade e gramaticalidade. Uma problemática dessa tarefa consiste em como definir mecanismos para avaliar as informações mais importantes de um documento e reduzir o texto mantendo-o claro e conciso.\nO corretor automático analisa o texto e verifica a gramática, concordância verbal e nominal das sentenças identificando erros e sugerindo possíveis correções. O sistema pergunta resposta analisa automaticamente os textos com o intuito de encontrar informações sobre um determinado tema de uma pergunta e retorna uma resposta (com base nos textos analisados).\nDentre as aplicações de PLN citadas anteriormente, a SAT foi escolhida como problemática base desta dissertação. Atualmente, existem diversos sistemas sumarizadores automáticos de textos que analisam diferentes tipos de documentos e estruturas, e criam resumos em formatos distintos. [ARCHANA AB e SUNITHA C 2013]"
    }, {
      "heading" : "1.2 Justificativa 18",
      "text" : "classificam os sistemas sumarizadores como:\n◮ Os resumos são criados pelos processos de abstração ou extração de sentenças.\nA abstração gera um resumo a partir da criação de novas frases com base no texto original. Ela requer um conhecimento mais avançado da estrutura do idioma incluindo suas regras gramaticais e de construção de sentenças. Ela possibilita ainda uma melhor análise do texto e da mensagem. A extração geralmente utiliza menos recursos das linguagens e se concentra em criar resumos a partir das estruturas já existentes no texto. Usualmente, são utilizadas regras estatísticas para avaliar a relevância das sentenças e o resumo é criado a partir daquelas consideradas mais relevantes.\n◮ Há sumários genéricos ou voltados a um tema específico. Os resumos genéricos\nnão diferenciam o conteúdo abordado nos documentos e realizam o mesmo tipo de análise em todos os textos. Os direcionados a um tema possuem regras e conceitos mais avançados para uma área de análise. Por exemplo, os resumos voltados para a área da saúde necessitam e consideram conceitos e regras mais específicos dos termos encontrados nesses documentos.\n◮ A criação de resumos pode ser mono ou multidocumento. A sumarização\nmonodocumento analisa um texto e cria o resumo com as principais informações do mesmo. A multidocumento analisa geralmente um cluster de documentos. Esse cluster pode conter informações similares (ou não) de uma mesma época (ou não).\n◮ Os resumos podem ser indicativos ou informativos. Os indicativos fornecem a\ninformação geral do texto sem conter informações específicas. Os informativos fornecem a informação geral do texto juntamente com dados específicos do documento original.\n◮ O sumário pode conter somente as informações-chave sem descrever dados básicos,\ncomo também pode conter dados básicos para auxiliar o leitor a compreender melhor o assunto descrito."
    }, {
      "heading" : "1.2 Justificativa",
      "text" : "Como mencionado anteriormente, a grande quantidade de informação existente e o tempo limitado para ler os textos por uma pessoa se tornou um problema na sociedade moderna. A SAT é uma ferramenta bastante útil a fim de propor soluções para esse"
    }, {
      "heading" : "1.3 Objetivos 19",
      "text" : "problema e agilizar o processo de identificação e leitura de textos. Algumas facilidades e/ou vantagens em utilizar a sumarização são [ARCHANA AB e SUNITHA C 2013]:\n◮ O resumo economiza o tempo de leitura possibilitando ao leitor identificar\nrapidamente o assunto principal do texto.\n◮ O resumo facilita a busca e a seleção de textos na literatura.\n◮ Melhora a qualidade de indexação dos documentos.\n◮ Os algoritmos de sumarização automática não têm preferências sobre assuntos ou\ncoisas possibilitando a criação de um resumo sem uma possível análise tendenciosa da opinião de um resumidor profissional."
    }, {
      "heading" : "1.3 Objetivos",
      "text" : "Os principais objetivos desta dissertação são pesquisar e desenvolver sistemas de SAT por extração de sentenças nos idiomas Francês e Português. Inicialmente, serão analisadas diferentes metodologias para criar resumos como, por exemplo, matriz de similaridade, conjunto estável e algoritmos em grafos. Serão explorados e analisados diversos sistemas sumarizadores na literatura a fim de estudar seus funcionamentos e utilizá-los como referência para a avaliação qualitativa dos sistemas aqui propostos.\nSerão desenvolvidos quatro sistemas sumarizadores independentes de idioma: RAG, LIA-RAG, SASI e SUMMatrix para sumarizar (multi)documentos em Francês e Português. O RAG, LIA-RAG e SASI utiliza a Teoria de Grafos e o SUMMatrix integra o uso de matrizes de similaridade. Outra parte do trabalho analisará os sistemas responsáveis pela análise qualitativa automática de resumos. Serão estudados e utilizados os sistemas FRamework for Evaluating Summaries Automatically (FRESA) e Recall-Oriented Understudy for Gisting Evaluation (ROUGE) para avaliar a qualidade dos resumos através das métricas precisão, cobertura e medida-f ."
    }, {
      "heading" : "1.4 Estrutura",
      "text" : "O restante desta dissertação está estruturado da seguinte forma:\n◮ O capítulo 2 aborda o estado da arte envolvendo os trabalhos em SAT. São descritas\ndiferentes metodologias para analisar os textos e produzir seus respectivos resumos."
    }, {
      "heading" : "1.4 Estrutura 20",
      "text" : "◮ O capítulo 3 descreve a modelagem matemática e as fórmulas utilizadas para calcular\na relevância, similaridade, divergência e identificar as sentenças principais dos textos.\n◮ O capítulo 4 descreve o funcionamento dos principais tipos de sistemas de SAT na\nliteratura.\n◮ O capítulo 5 analisa a estrutura e a metodologia dos sistemas propostos nesta\ndissertação (LIA-RAG, RAG, SASI e SUMMatrix).\n◮ O capítulo 6 detalha a estrutura e as características de cada corpus2 utilizado na\navaliação dos sistemas.\n◮ O capítulo 7 descreve os resultados obtidos para cada corpus e a análise geral dos\nsistemas.\n◮ O capítulo 8 conclui esta dissertação destacando os pontos positivos e negativos dos\nresultados obtidos e os possíveis trabalhos futuros.\n2O corpus é um conjunto estruturado de documentos com determinadas características.\n21\nCAPÍTULO 2\nESTADO DA ARTE\nOs primeiros trabalhos acerca da sumarização automática de documentos abordavam somente textos jornalísticos através de técnicas simples baseadas na frequência das palavras para avaliar a relevância das frases [Luhn 1958]. Os resumos de profissionais possuem ótima qualidade em termos de informatividade e legibilidade. Entretanto, sua produção é mais lenta, cara e sujeita à subjetividade do profissional. Em contrapartida, os resumos produzidos de modo automático têm custo de produção bem reduzido, inexistência de problemas de subjetividade e de variabilidade observados nas proposições dos resumidores profissionais, dentre outros. Verificou-se, assim, a necessidade de gerar resumos automáticos visando essas facilidades e a fim de lidar com o crescimento da quantidade de informações.\n[Edmundson 1969] deu continuidade aos trabalhos de Luhn, adicionando ao processo\nde produção de resumos considerações sobre posição das frases e presença de palavras provenientes da estrutura do documento (por exemplo, títulos, sub-títulos, etc.). As pesquisas desenvolvidas em Chemical Abstracts Service (CAS) [Pollock e Zamora 1975], concernentes à produção de sumários a partir de artigos científicos de Química, permitiram validar a viabilidade das abordagens de extração automática de frases. Uma “limpeza” das frases através de operações de eliminação foi introduzida pela primeira vez. No intuito de adequar os resumos aos padrões impostos pela CAS, uma normalização do vocabulário era efetuada. A normalização incluiu a substituição de palavras/frases por suas abreviações e uma padronização das variantes ortográficas. Os estudos sobre SAT podem ser divididos em dois grupos, extração e abstração de texto. No primeiro grupo, há a identificação das partes mais relevantes de um ou mais textos, através de técnicas de recuperação de informação estatística para mensurar a relevância das frases e gerar o resumo através"
    }, {
      "heading" : "2 Estado da arte 22",
      "text" : "da concatenação das mesmas. O trabalho de [Wu, Hsu e Tan 1992] descreve vários métodos estatísticos utilizados no processo de sumarização de textos. A abstração analisa o texto original de uma forma linguística profunda, interpreta o texto semanticamente em uma representação formal, encontra novos conceitos mais concisos para descrevê-lo e, em seguida, gera um novo texto mais curto com o mesmo sentido do texto original com as informações relevantes apresentadas de forma concisa (fusão, paráfrase, etc) [Hovy e Lin 1998].\nExistem diversos métodos para analisar a relevância das sentenças e construir um resumo. [SARANYAMOL CS e SINDHU L 2014] classificaram esses métodos em: Term Frequency - Inverse Document Frequency (TF-IDF), Cluster, Teoria dos Grafos, Aprendizado de Máquina, Latent Semantic Analysis (LSA), Redes Neurais e Lógica Fuzzy. Normalmente, esses métodos baseiam-se em cálculos estatísticos para verificar a relevância das sentenças. Por isso eles não analisam corretamente a estrutura e a semântica do texto, ocasionando erros gramaticais e sintáticos e reduzindo a coesão e coerência do resumo.\nDe forma geral, os trabalhos voltados à extração de frases utilizam a seguinte\nmetodologia de produção de sumários:\n◮ Pré-processamento do texto;\n◮ Identificação das frases em destaque no documento;\n◮ Construção do sumário por concatenação das frases extraídas.\nO pré-processamento do texto ou do cluster geralmente se inicia com o processo de segmentação do texto para identificar frases, palavras e pontuações. Em seguida, identifica-se qual é o idioma do texto e realiza-se o processo de filtragem, em que são removidos os stopwords (palavras sem relevância para o texto e para o conteúdo), e o processo de stemming, em que as palavras são reduzidas a seus radicais, evitando-se suas flexões (singular e plural, masculino e feminino, derivações de palavras e verbos).\nA identificação das frases relevantes no texto é normalmente feita através de uma ponderação que faz uso de métodos estatísticos: análise da frequência das palavras nas sentenças e no texto em geral, determinação da energia textual das sentenças [FernÁndez, SanJuan e Torres-Moreno 2007], modelagem das sentenças como vetores [Torres-Moreno 2012], grupos de vértices num grafo [Pontes, Linhares e Torres-Moreno 2014], entre outros.\nA parte final do processo de sumarização é a geração de textos, que pode ser realizada através de diversas técnicas. Os métodos de sumarização por extração geralmente utilizam"
    }, {
      "heading" : "2.1 Fatoração de Matrizes 23",
      "text" : "a abordagem de concatenar as sentenças relevantes [Torres-Moreno 2012,Pontes, Linhares e Torres-Moreno 2014]. Esse método é simples e rápido, mas pode criar vários problemas de coesão e coerência devido à possibilidade das frases selecionadas não apresentarem conexão entre si e assim, incorrer na perda do fluxo e da compreensão do texto.\nA abordagem por abstração utiliza métodos mais complexos e elaborados para gerar\nsentenças (fusão de sentenças, geração de paráfrases, etc) [Filippova 2010,Seno 2010].\nAnalisamos os trabalhos relacionados às principais metodologias utilizadas na literatura para a sumarização de textos com o intuito de analisar diferentes metodologias e compará-las com os sistemas propostos nesta dissertação. As seções seguintes discorrem sobre: Fatoração de Matrizes (seção 2.1), Grafos (seção 2.2), Métodos Heurísticos (seção 2.3), Programação Linear Inteira (PLI) (seção 2.4) e Submodular (seção 2.5). A seção 2.6 mostra alguns trabalhos de sumarização por abstração de sentenças voltados ao Português Brasileiro e Inglês."
    }, {
      "heading" : "2.1 Fatoração de Matrizes",
      "text" : "A Decomposição de Valores Singulares (DVS) é um dos métodos de fatorização de matrizes bem estudado na literatura. A DVS é usada em álgebra linear para minimizar erros computacionais em operações com matrizes de grande porte [Lay 2011]. A decomposição fatoriza a matriz M em três matrizes, I, A e X, de tal forma que M = I ×A×XT . A matriz I é uma matriz unitária de dimensão m×n cujas colunas são vetores ortonormais. A matriz A é uma matriz diagonal n×n, cujos elementos diagonais são valores singulares não negativos, ordenados de forma decrescente. Finalmente, a matriz transposta de X (XT ) é uma matriz ortogonal de dimensão n × n, cujas colunas são chamadas de vetores singulares à direita.\nA LSA é um método não supervisionado de obtenção de espaço vetorial representando a semântica de um grande corpus de textos. Esse método representa uma coleção de documentos através da distribuição dos termos do documento em uma matriz M. A LSA utiliza a DVS para decompor a matriz M e obter as matrizes I, A e X.\nOs primeiros (maiores) valores na diagonal da matriz A são postos a zero, resultando em uma espécie de análise de componentes principais. Esse processo reduz eficazmente a dimensionalidade das palavras para cada vetor [Landauer et al. 2007].\nNo contexto da aplicação em sumarização automática, o documento é modelado como uma matriz M representando a ocorrência dos termos por sentença (i.e., uma matriz com"
    }, {
      "heading" : "2.2 Grafos 24",
      "text" : "m linhas, que representam os termos únicos, e com n colunas, que representam cada frase). A DVS é utilizada para reduzir o número de linhas (i.e., os termos correlacionados são agrupados em conceitos, capturando fenômenos como a sinonímia entre termos), preservando a estrutura de similaridade entre as colunas (i.e., entre as frases).\nUm algoritmo simples pode ser usado para selecionar a(s) melhor(es) frase(s), com base na decomposição DVS e no uso da matriz de valores singulares à direita XT . Cada sentença i é representada pelo vetor coluna [xj1, xj2, . . . , xjn]T da matriz XT . Uma abordagem simples é selecionar o primeiro vetor singular direito da matriz XT e em seguida a(s) frase(s) que têm o maior valor índice no vetor. Após isso, se necessário, efetua-se o mesmo processo para o segundo vetor singular direito da matriz, até se chegar ao número desejado de frases a serem selecionadas para a construção do sumário [Gong e Liu 2001].\nNa proposta original de [Lee e Seung 1999], a Fatorização de Matrizes Não-negativas (FMN) decompunha uma matriz M em duas matrizes não-negativas Y e Z, de forma que M = Y×Z, onde Y é uma matriz não-negativa de características semânticas (i.e., a matriz dos termos) e Z é uma matriz não negativa de variáveis semânticas (i.e., a matriz das frases). Um dos algoritmos mais populares para encontrar decomposições FMN é baseado numa regra de atualização multiplicativa que atualiza iterativamente as matrizes Y e Z até obter a convergência de uma função objetiva ou até o algoritmo exceder um determinado número de passos."
    }, {
      "heading" : "2.2 Grafos",
      "text" : "Os métodos relacionados à Teoria dos Grafos consideram um grafo não-direcionado G = (V,E) composto por um conjunto de vértices V e um conjunto de arestas E. Existem diversas formas de modelizar o texto utilizando grafos. Filippova [Filippova 2010] utilizou cada palavra como um nó no grafo e o fluxo das sentenças para determinar a existência de arcos entre os vértices. [Pontes, Linhares e Torres-Moreno 2014] consideram cada vértice representando uma sentença no texto e as arestas representam a existência de similaridade entre dois vértices (sentenças). [Baralis et al. 2013] modelizam o texto utilizando grafos para representar os termos dos textos.\nMihalcea desenvolveu algoritmos de classificação baseados em grafos, tais como PageRank [Mihalcea 2004]. Esses algoritmos foram utilizados com sucesso nas redes sociais, na análise do número de citações ou no estudo da estrutura da Web. Eles permitem"
    }, {
      "heading" : "2.2 Grafos 25",
      "text" : "tomar decisões acerca da importância de um vértice, baseando-se na informação global advinda da análise recursiva do grafo completo e não na análise local do vértice. No âmbito da sumarização automática, observa-se que o documento é representado por um grafo de unidades textuais (frases) conectadas entre si através de relações oriundas de cálculos de similaridade. As frases são em seguida selecionadas segundo critérios de centralidade ou de prestígio no grafo, e agrupadas a fim de produzir os extratos do texto [Ferreira et al. 2014].\nBaralis et al. também utilizaram a modelagem de grafos para sumarizar textos [Baralis et al. 2013]. Entretanto, sua metodologia é composta por: processamento do texto, correlação do grafo, indexação do grafo e seleção de sentenças. O processamento realiza a stemming e a remoção dos stopwords. A correlação do grafo é feita a partir dos conjuntos de itens frequentes no texto. A indexação do grafo dá-se através de um algoritmo baseado no PageRank para ponderar os nós do grafo. A geração do resumo seleciona as sentenças com melhor ponderação baseada na indexação dos nós.\nFilippova descreve outro método através da fusão multissentença, apoiado em uma estrutura de grafo para representar palavras e frases [Filippova 2010]. Os arcos do grafo são ponderados com a frequência de palavras e a posição nas frases. A fusão é realizada através do cálculo do menor caminho no grafo de palavras. A figura 1 exemplifica a fusão utilizando várias sentenças similares para criar uma nova sentença com o conteúdo que as representa.\nFigura 1 – Exemplo de compressão de sentenças utilizando grafos [Filippova 2010].\nO trabalho de Pontes et al usa a Teoria dos Grafos concomitante com a divergência Jensen-Shannon (JS) para criar resumos multi-documentos por extração [Pontes, Linhares"
    }, {
      "heading" : "2.3 Métodos Heurísticos 26",
      "text" : "e Torres-Moreno 2014]. O sistema representa o texto através de um grafo onde as frases correspondem aos vértices e as arestas representam a similaridade entre duas sentenças (vértices). Portanto, o grupo de vértices interligados no grafo representa sentenças com conteúdo similar. O sistema calcula o conjunto estável máximo do grafo visando criar o resumo com frases contendo informações gerais do cluster e sem redundância. Por isso, o sistema seleciona geralmente uma frase de cada grupo, reduzindo a quantidade de sentenças muito similares."
    }, {
      "heading" : "2.3 Métodos Heurísticos",
      "text" : "Torres desenvolveu vários métodos heurísticos para sumarização por extração. Em [Torres-Moreno 2012], o texto é representado como um Vector Space Model (VSM) e cada sentença possui um vetor que descreve o tema do texto. A partir desse vetor, calcula-se a relevância de cada frase para construir o resumo. O trabalho de [Boudin e Torres-Moreno 2007] utiliza diferentes cálculos numéricos para determinar a relevância das sentenças. [FernÁndez, SanJuan e Torres-Moreno 2007] calculam a energia textual das sentenças que representa a relevância de cada uma delas com relação ao texto. Esses métodos serão melhores descritos no capítulo 4."
    }, {
      "heading" : "2.4 Programação Linear Inteira",
      "text" : "Uma forma de melhorar a qualidade do resumo é maximizar a seleção das sentenças mais relevantes. A Programação Linear Inteira (PLI) modela a sumarização de textos de forma a maximizar a qualidade da extração de sentenças por meio de análises do texto.\nA PLI consiste em maximizar ou minimizar uma função sujeita a um conjunto de restrições3. Mcdonald [Mcdonald 2006] considerou a informatividade e a redundância das sentenças como pontos fundamentais para a SAT. Ele avalia a qualidade do resumo a partir da relevância das frases com a inserção de uma penalidade para as sentenças redundantes do resumo.\n[Gillick e Favre 2009] basearam-se no modelo de Mcdonald para abordar o modelo de\nescalas de forma. Os autores tratam a redundância das sentenças sem necessitar de um número quadrático de variáveis, facilitando a modelagem e resolução do problema. Eles também modelam esse problema na formulação PLI realizando a compressão e a seleção de sentenças simultaneamente.\n3A seção 4.7 descreverá melhor a modelagem da PLI para a sumarização de textos"
    }, {
      "heading" : "2.5 Submodular 27",
      "text" : "Já [Galanis, Lampouras e Androutsopoulos 2012] adicionaram o modelo Support Vector Regression (SVR) para mensurar a relevância das sentenças a partir do treinamento dos sistemas com resumos produzidos por humanos. Esse modelo avalia a relevância das sentenças baseando-se em sua diversidade."
    }, {
      "heading" : "2.5 Submodular",
      "text" : "Seja B um conjunto finito e seja f uma função de partes de B em R. A função f é submodular se, para quaisquer partes C e D de B, observa-se a relação exposta na equação 2.1.\nf(C ∪D) + f(C ∩D) ≤ f(C) + f(D) (2.1)\nSeja um conjunto de objetos B e uma função f que retorna um valor real para qualquer subconjunto C ⊆ B. O objetivo é escolher um subconjunto com tamanho limitado a um certo valor que maximize a função [Krause et al. 2008]. A SAT por extração seleciona um subconjunto (conjunto de sentenças) C ⊆ B para representar o documento de tal forma que o resumo tenha o tamanho máximo de L palavras.\n[Lin e Bilmes 2011] projetaram uma classe de funções submodulares voltadas à\ncompactação de sentenças objetivando a diversidade e a representatividade do corpus. As funções são não-decrescentes, monótonas e submodulares, possibilitando um desempenho ideal de fator constante. Outra possibilidade é a aprendizagem supervisionada de funções submodulares para a extração de sentenças. [Sipos, Shivaswamy e Joachims 2012] aplicam esse método de aprendizagem a diversos métodos de compactação submodulares e demonstram sua eficácia com base na análise de vários conjuntos de dados."
    }, {
      "heading" : "2.6 Sumarização por abstração",
      "text" : "A sumarização por abstração geralmente usa métodos mais complexos de análise, pois eles permitem verificar o conteúdo do documento e possibilitam que o sistema sumarizador possa “saber” quais informações estão presentes no mesmo. Possui uma abordagem baseada na estrutura e na semântica. A abordagem estruturada codifica a informação mais importante do documento por meio de esquemas cognitivos tais como modelos, regras de extração, e estruturais, tais como conhecimento base e estrutura da frase. O método semântico, por sua vez, concentra-se na identificação de frases nominais e verbais"
    }, {
      "heading" : "2.6 Sumarização por abstração 28",
      "text" : "por meio de dados linguísticos para que o sistema de geração da linguagem natural possa criar o resumo do texto analisado.\nA sumarização por abstração geralmente usa a fusão de frases ou geração de paráfrases\npara revisar as informações e evitar redundâncias em um texto [Seno 2010].\nA fusão por união preserva a mensagem geral do cluster, enquanto a fusão por interseção analisa as informações redundantes presentes no mesmo. Seno propôs um método de fusão de sentenças similares em Português utilizando uma abordagem simbólica e independente de domínio (figura 2) [Seno 2010]. Esse método permite mesclar as sumarizações por união e interseção de um cluster de documentos. Já no trabalho de [Seno e Nunes 2008] é descrita uma metodologia para identificar informações comuns entre frases em Português usando o conhecimento lexical, sintático e regras semânticas de paráfrase.\nFigura 2 – Estrutura para fusão de sentenças similares.\nEm [Jorge, Pardo e Salgueiro 2010] é desenvolvido um método de compactação multi-documento baseado no modelo Cross-document Structure Theory (CST). Esse método analisa a redundância, a complementaridade e a contradição entre as diferentes fontes de informação para calcular a relevância das sentenças. Em seguida, os operadores são utilizados no auxílio do processo de reponderação das sentenças a fim de criar um resumo com algumas características escolhidas pelo usuário. Por fim, o resumo é gerado a partir das sentenças de maior ponderação (figura 3).\nO trabalho de [Xu et al. 2013] usa os conceitos de árvore tópica hierárquica, retórica e relação temporal para calcular as inter-relações entre as unidades do texto. Ele utiliza ainda a estrutura Multi-document Rhetorical Structure (MRS) (figura 4) para representar o texto em diferentes níveis de granularidade (incluindo frases, parágrafos, seções e documentos). Seu algoritmo de extração realiza etapas de ponderação e remoção de nós a fim de selecionar as sentenças mais importantes. Primeiramente, ele executa o algoritmo de ponderação dos nós para, em seguida, utilizar um algoritmo de clustering no intuito"
    }, {
      "heading" : "2.6 Sumarização por abstração 29",
      "text" : "Figura 3 – Arquitetura do sistema CSTSumm [Jorge, Pardo e Salgueiro 2010].\nde identificar sentenças similares e remover as que são redundantes.\nFigura 4 – Estrutura MRS [Xu et al. 2013].\nBarzilay et al. desenvolveram um método de geração automática de resumos através da identificação e sintetização de elementos semelhantes em um conjunto de documentos [Barzilay, McKeown e Elhadad 1999]. Esse método seleciona o conteúdo dos textos a partir da similaridade das frases relacionadas com o tema discutido a fim de criar um novo texto. No trabalho de [Barzilay e McKeown 2005] é descrita uma abordagem para fusionar frases por meio da técnica de geração text-to-text4 de modo a sintetizar informações repetidas de vários documentos. Esse método utiliza um alinhamento sintático nas frases para identificar informações comuns às mesmas. Após a etapa de identificação, as sentenças são processadas e um novo texto é gerado mantendo a mesma ideia original.\nUma maneira de calcular a similaridade entre frases é através da co-ocorrência de 4A geração text-to-text é reconfiguração de um texto através da: reformulação, reorganização,\ncombinação ou divisão das sentenças e eliminação do conteúdo."
    }, {
      "heading" : "2.6 Sumarização por abstração 30",
      "text" : "palavras. Em [He et al. 2008] é proposto um método de fusão usando métricas de similaridade, co-ocorrência Skip-bigrama5 e densidade de informação para calcular o valor das sentenças e selecionar os conteúdos mais relevantes. Hennig e Albayrak desenvolveram um modelo multi-documento para resumir um texto analisando a co-ocorrência de termos e bigramas6 usando a divergência JS [Hennig e Albayrak 2010].\nHovy e Lin desenvolveram o sistema sumarizador SUMMARIST, que combina conhecimentos de conceitos do mundo (dicionários, ontologias e recursos similares) com PLN [Hovy e Lin 1998]. O SUMMARIST é baseado na identificação da temática do documento e em sua interpretação. Através de técnicas de recuperação de informação e de dicionários, o sistema identifica os principais tópicos abordados no texto e faz a interpretação dos dados através de técnicas estatísticas, psicologia cognitiva, léxicos e dicionários. Por fim, o sumário é criado através de métodos de geração de frases.\n5Skip-bigramas são quaisquer pares de palavras na ordem da frase. 6Bigramas são pares de palavras sequenciais em uma frase.\n31\nCAPÍTULO 3\nMODELAGEM DO PROBLEMA\nEste capítulo aborda a modelagem matemática utilizada nesta dissertação. A seção 3.1 descreve o modelo de saco de palavras para identificar as palavras e suas distribuições nos documentos analisados. A seção 3.2 descreve formas de avaliação da relevância inicial de palavras e sentenças. A seção 3.3 e 3.4 discorrem sobre formas de calcular a similaridade e a divergência entre sentenças, respectivamente. Por fim, a seção 3.5 descreve os conceitos gerais e os problemas (abordados neste trabalho) envolvendo a Teoria de Grafos."
    }, {
      "heading" : "3.1 Saco de palavras",
      "text" : "Os métodos propostos nesta dissertação são baseados em um pré-tratamento específico de palavras e um modelo de saco de palavras para representar o texto. A modelagem de saco de palavras organiza e representa o modo como as palavras estão distribuídas nas sentenças. Utiliza-se uma matriz representada por S[NS×NP ] construída a partir do texto, onde NS é o número de sentenças e NP é o número de palavras distintas no documento. A célula Sij representa a frequência da palavra j na frase i (FPij).\nS =   S11 S12 . . . S1NP S21 S22 . . . S2NP ... ... ...\nSNS1 SNS2 . . . SNSNP\n  , Sij = { FPij, se ∃ a palavra j na frase i 0, caso contrário (3.1)"
    }, {
      "heading" : "3.2 Relevância das palavras e frases 32",
      "text" : ""
    }, {
      "heading" : "3.2 Relevância das palavras e frases",
      "text" : "Uma forma de verificar a relevância de uma palavra ou de uma frase em relação ao texto é através do Term Frequency - Inverse Sentence Frequency (TF-ISF) [Vodolazova et al. 2012], que é uma variação do TF-IDF7. Normalmente, as palavras mais frequentes representam ideias relevantes no texto. Entretanto, uma boa parte das mesmas são artigos, preposições ou conjunções, e assim serão referenciadas como stopwords. Os stopwords não são relevantes para a compreensão do texto e sua remoção auxilia sua análise. As palavras menos frequentes também podem ser relevantes. Então, uma melhor forma de analisar as palavras é através da TF-ISF. Essa métrica analisa a frequência das palavras e sua distribuição nas sentenças. A relevância de uma palavra w no texto, tfisf(w), é dada pela equação 3.2.\ntfisf(w) = tf(w)× log NS\nnw , (3.2)\nonde tf(w) corresponde a frequência da palavra w, NS é a quantidade de sentenças e nw é a quantidade de sentenças que possuem a palavra w. Consequentemente, a relevância de uma sentença s, rel(s), é determinada pela equação 3.3.\nrel(s) = ∑\nw∈s\ntfisf(w) (3.3)"
    }, {
      "heading" : "3.3 Similaridade",
      "text" : "A métrica de similaridade de sentenças verifica a semelhança entre as mensagens transmitidas por cada sentença. O processo de análise de similaridade verifica o significado semântico das sentenças e analisa a semelhança das mensagens transmitidas. Entretanto, o processo de análise das sentenças exige uma verificação complexa da estrutura sintática e semântica das palavras.\nUma alternativa para avaliar a similaridade entre duas sentenças é analisar as palavras em comum entre elas. A subseção 3.3.1 descreve o cálculo da similaridade baseado na determinação do cosseno e a subseção 3.3.2 baseia-se nas palavras em comum para avaliar o nível de similaridade. 7Term Frequency - Inverse Document Frequency (TF-IDF)"
    }, {
      "heading" : "3.3 Similaridade 33",
      "text" : ""
    }, {
      "heading" : "3.3.1 Similaridade do cosseno",
      "text" : "O método da similaridade do cosseno baseia-se no cálculo do cosseno do ângulo entre dois vetores. Essa métrica avalia duas sentenças e calcula o ângulo entre dois vetores representados por elas. Sejam as sentenças P e Q com as palavras p1, p2, . . . , pn e q1, q2, . . . , qn, respectivamente. O produto escalar PQ é dado pela equação 3.4, em que pk é 1 quando a palavra pk existe na sentença P , e, caso contrário, pk é 0. O mesmo ocorre para qk em relação à sentença Q.\nP.Q = p1 × q1 + p2 × q2 + · · ·+ pn × qn (3.4)\nA norma da frase é definida pela equação 3.5.\n||P || = 2 √\np21 + p 2 2 + · · ·+ p 2 n (3.5)\nA similaridade do cosseno é calculada segundo a equação 3.6. Seu valor varia entre\n[0, 1]. Quanto maior for o valor do cosseno maior é a semelhança entre as sentenças.\ncos(P,Q) = P.Q\n||P || × ||Q|| (3.6)"
    }, {
      "heading" : "3.3.2 Similaridade de Jaccard",
      "text" : "O coeficiente de similaridade de Jaccard calcula a similaridade entre conjuntos de forma estatística. Essa métrica é baseada na quantidade de elementos em comum entre dois conjuntos. Sejam duas sentenças P e Q cujos elementos são as palavras de cada uma delas. O coeficiente de similaridade de Jaccard, Jac(.), é dado pela equação 3.7 e o mesmo varia entre [0, 1], sendo 1 quando duas sentenças são iguais.\nJac(P,Q) = |P ∩Q|\n|P ∪Q| (3.7)\nOutra medida possível é a distância de Jaccard, disJ(.), que calcula a dissimilaridade\nentre dois conjuntos através do complemento de Jaccard (equação 3.8).\ndisJ(P,Q) = 1− Jac(P,Q) = |P ∪Q| − |P ∩Q|\n|P ∪Q| (3.8)"
    }, {
      "heading" : "3.4 Divergência 34",
      "text" : ""
    }, {
      "heading" : "3.4 Divergência",
      "text" : "A métrica de divergência também necessita da análise semântica para avaliar corretamente o significado e a diferença entre duas sentenças. Por isso, foram analisados alguns métodos estatísticos ( [Sogaard 2013, Torres-Moreno et al. 2010]) para avaliar a divergência entre conjuntos de probabilidades. As subseções 3.4.1 e 3.4.2 descrevem um método assimétrico e outro simétrico, respectivamente, para mensurar a divergência entre duas sentenças."
    }, {
      "heading" : "3.4.1 Divergência de Kullback-Leibler",
      "text" : "Sejam P , Q e W conjuntos de palavras, onde P e Q representam as palavras de duas sentenças de um documento e W é formado por sua união. Pr(P,w) representa a probabilidade da palavra w na sentença P em relação ao conjunto W . Respectivamente, Pr(Q,w) será a probabilidade da palavra w na frase Q em relação ao conjunto W .\nA divergência Kullback-Leibler (KL) determina a informação perdida ao aproximar um conjunto de probabilidades do conjunto P em relação ao conjunto de probabilidades do conjunto Q (equação 3.9) [Sogaard 2013]. Ela permite calcular a diferença entre dois conjuntos de palavras distintas.\nDKL(P ||Q) = 1\n2\n∑\nw∈W\n( Pr(P,w) log Pr(P,w)\nPr(Q,w)\n) (3.9)\nEssa divergência é assimétrica (DKL(P ||Q) 6= DKL(Q||P )), assumindo valores diferentes dependendo da análise realizada. Seu valor varia entre [0,∞) e suas probabilidades são semelhantes quando seus valores são próximos a zero."
    }, {
      "heading" : "3.4.2 Divergência de Jensen-Shannon",
      "text" : "A divergência Jensen-Shannon (JS) é uma versão simétrica e suavizada da KL, fornecendo uma maneira mais estável para mensurar a diferença entre dois conjuntos de probabilidades (equação 3.10) [Torres-Moreno et al. 2010, Saggion et al. 2010]. A divergência JS pode assumir a mesma variação de valores que a KL."
    }, {
      "heading" : "3.5 Grafos 35",
      "text" : "DJS(P ||Q) = 1\n2\n∑\nw∈W\n( Pr(P,w) log\n2× Pr(P,w)\nPr(P,w) + Pr(Q,w) + Pr(Q,w) log\n2× Pr(Q,w)\nPr(P,w) + Pr(Q,w)\n)\n(3.10)\nNo caso de haver somente uma palavra em uma das frases analisadas, utiliza-se uma suavização para evitar valores nulos [Hiemstra 2009]. Se uma palavra w não está presente na frase Q, então Pr(Q,w) é calculada pela equação 3.11, onde β = 1.5 ∗ voc, voc é o número de palavras distintas em W , γ controla a relevância da palavra ausente na frase e NP é a quantidade de palavras em W . Caso a palavra w esteja presente somente na frase Q, o cálculo da probabilidade Pr(P,w) é simétrico a equação 3.11.\nPr(Q,w) =\n( Pr(P,w) + γ\nNP + γ × β\n) (3.11)"
    }, {
      "heading" : "3.5 Grafos",
      "text" : "Esta seção descreve uma breve introdução sobre a Teoria dos Grafos (subseção 3.5.1) e os problemas da clique e do subconjunto independente de vértices (subseção 3.5.2) abordados em alguns algoritmos utilizados nos sistemas desenvolvidos."
    }, {
      "heading" : "3.5.1 Conceitos gerais",
      "text" : "Considere um grafo G = (V,E), onde V é o conjunto de vértices e E o conjunto de arestas não orientadas de G (ver figura 5.a). A cardinalidade (n) de um grafo é definida pela quantidade de vértices e o complemento do grafo Ḡ é o grafo (V, {u, v} ∈ (V ×V )\\E : u 6= v) (figura 5.b8).\nO grafo G pode ser denso ou esparso. Ele é denso quando o número de arestas é próximo a n(n−1 2 ) (quando existe uma aresta entre todo par de vértices). Quando há poucas arestas, o grafo é denominado esparso. A vizinhança de um conjunto de vértices U é o conjunto de todos os vértices que possui em algum vizinho em U . O grau de um vértice v é definido pela quantidade de arestas que ele possui.\nUm subgrafo de um grafoG é qualquer grafoH tal que V (H) ⊆ V (G) e E(H) ⊆ E(G). O subgrafo de G induzido por um subconjunto U de V (G) é o grafo (U, J), em que J é o conjunto de todas as arestas de G que têm ambas as extremidades em U .\n8https://it.wikipedia.org/wiki/Grafo_complemento"
    }, {
      "heading" : "3.5 Grafos 36",
      "text" : "Figura 5 – Exemplo de um grafo G (a) e seu complemento Ḡ (b).\n(a) (b)\nUm caminho (para o caso de um grafo simples9) com a origem no vértice vi e o fim no vértice vf é definido por um conjunto finito de arestas consecutivas partindo do vértice vi e chegando ao vértice vf . Portanto, há um caminho entre os vértices v1 e v2 se existir um conjunto de arestas que interligue esses dois vértices diretamente ou indiretamente. Um grafo é conexo se para qualquer par de vértices {v1, v2}, existe um caminho com início em v1 e término em v2. A figura 6 exemplifica um grafo conexo e outro desconexo.\nFigura 6 – Exemplos de grafo conexo (a) e desconexo (b).\n(a) Conexo (b) Desconexo"
    }, {
      "heading" : "3.5.2 Problema da Clique e do Subconjunto Independente",
      "text" : "Seja um grafo G = (V,E). A clique (ou subconjunto completo) é qualquer conjunto de vértices dois a dois adjacentes. Um subconjunto U de vértices é uma clique se o grafo induzido G[U ] é completo (figura 7). O tamanho da clique é definido pela sua cardinalidade e um dos problemas mais conhecidos é o de identificar a maior clique existente em um grafo, denominado problema da Clique Máxima. Esse problema é NP-Difícil. 91-grafo, multiplicidade de arestas entre dois vértices igual a 1."
    }, {
      "heading" : "3.5 Grafos 37",
      "text" : "Figura 7 – Exemplo de Clique.\nUm Subconjunto Independente de Vértices (SIV) (denotado dessa forma nesta dissertação) é formado por um subconjunto dos vértices do grafo que não são adjacentes [Garey e Johnson 1990], ou seja, vértices que não possuem aresta interligando-os (figura 8). A Clique e o SIV são problemas complementares. Portanto, um conjunto U de vértices é uma clique em um grafo G se e somente se U é SIV no grafo complementar Ḡ.\nO Subconjunto Independente Máximo (SIM) é o subconjunto independente de vértices com maior cardinalidade no grafo. O SIM está presente em várias aplicações como coloração de grafos, agendamento de tarefas, atribuição de canais de rádio, entre outras.\nFigura 8 – Exemplo de SIV (a) e SIM (b).\n(a) SIV (b) SIM\n[Butenko 2003] abordou a complexidade algorítmica e possíveis soluções para o SIM\nadaptadas às características do grafo. [Rossi e Smriglio 2001] desenvolveram um algoritmo branch-and-cut [Wolsey 1998] para solucionar o problema do SIM. Eles criaram restrições de estrutura geral a partir da execução de algoritmos de separação de clique sobre um grafo modificado obtido a partir da projeção das arestas.\n38\nCAPÍTULO 4\nSISTEMAS DE SUMARIZAÇÃO AUTOMÁTICA DE TEXTOS NA LITERATURA\nEste capítulo aborda alguns sistemas baseline10 e da literatura para a sumarização automática de textos. Serão apresentados os sistemas Artex, Cortex, Enertex, GistSumm, KLSumm, baseados em PLI, LexRank e TextRank. Alguns deles serão comparados com os sistemas desenvolvidos nesta dissertação."
    }, {
      "heading" : "4.1 Artex",
      "text" : "Autre Resumeur TEXtuel (Artex) é um sistema de sumarização por extração [Torres-Moreno 2012]. O pré-tratamento é o mesmo descrito no sistema SASI (seção 5.1). O sistema recebe a matriz de saco de palavras e cria o Modelo Espaço Vetorial (MEV) que possibilita a construção do vetor médio do documento (o “tópico global”) de todos os vetores das sentenças. Ao mesmo tempo, obtém-se o “peso lexical” de cada sentença, que é o número de palavras na sentença. Analisa-se a similaridade entre as sentenças em relação ao “peso lexical\"e o “tópico global\", a figura 9 descreve a MEV de um documento em que as sentenças vetoriais ~si e o vetor do tópico global ~b são representados em um espaço de palavras de dimensão NP .\nA figura 10 descreve o peso lexical ~a em um MEV de sentenças com dimensionalidade de NS, sendo ~wi o vetor da frequência da palavra i nas NS sentenças. A relevância das sentenças é calculada baseada na proximidade do vetor de cada sentença em relação ao vetor de “tópico global\"e ao vetor de “peso lexical\". A relevância ou o peso da sentença\n10Sistemas baseline são sistemas simples que servem de comparação de desempenho em relação a outros sistemas."
    }, {
      "heading" : "4.2 Cortex 39",
      "text" : "Figura 9 – MEV do tema global.\nsi, denominado score(si), é calculada pela equação 4.1.\nscore(si) = 1\nNS ×NP\n( NP∑\nj=1\nnos(i, j)× nod(j) ) × ai; i = 1, 2, ..., NS; (4.1)\nsendo nos(i, j) é o número médio de ocorrências da palavra j na sentença i, nod(j) é o número médio de ocorrências da palavra j nas NS sentenças e ai é o número médio de ocorrências das NP palavras na sentença i.\nFigura 10 – MEV do peso lexical.\nPor fim, o sistema gera o resumo composto pelas sentenças com os maiores scores."
    }, {
      "heading" : "4.2 Cortex",
      "text" : "O sistema Cortex é um sistema de sumarização automática independente do idioma [Boudin e Torres-Moreno 2007]. O sistema aplica cálculos numéricos para ponderar frases e criar um resumo. Inicialmente, realiza-se o processo de pré-tratamento descrito no sistema SASI (seção 5.1). O Cortex possui um sistema de decisão que utiliza as métricas de similaridade, de overlap e score normalizadas (entre [0, 1]), combinadas a fim de calcular"
    }, {
      "heading" : "4.2 Cortex 40",
      "text" : "a pontuação de cada sentença (figura 11).\nFigura 11 – Funcionamento do sistema Cortex.\nO algoritmo de decisão avalia todas as métricas permitindo uma melhor avaliação da importância das sentenças. Utiliza-se o cosseno de similaridade para medir o grau de similaridade entre dois vetores representando os documentos e os tópicos abordados.\nO overlap calcula a quantidade de informação compartilhada de uma sentença (conjunto de palavras P ) em relação a um determinado tópico (conjunto de palavras Q) a partir da quantidade de palavras comuns entre eles (equação 4.2).\noverlap(P,Q) = |P ∩Q|\n|Q| (4.2)\nAs métricas de similaridade e overlap são usadas para refinar o cálculo do Cortex descrito no trabalho de Torres-Moreno et al [Torres-Moreno, Velázquez-Morales e Meunier 2002]. Assim, a ponderação final (score) de uma frase P com relação a um documento (conjunto de palavras W ) e um tópico Q é definida pela equação 4.3.\nscore(P ) = α0 × CORTEX(P,W ) + α1 × overlap(P,Q) + α2 × Sim(W,Q); ∑\ni\nαi = 1\n(4.3)\nO resumo é criado a partir das sentenças com maiores pontuações e sem redundâncias.\nA redundância das sentenças é calculada a partir da similaridade de Dice [Dice 1945]."
    }, {
      "heading" : "4.3 Enertex 41",
      "text" : ""
    }, {
      "heading" : "4.3 Enertex",
      "text" : "O sistema Enertex avalia a energia textual das sentenças, que representa a relevância das mesmas em relação ao texto [FernÁndez, SanJuan e Torres-Moreno 2007]. O sistema modela um texto como uma rede neural baseada no modelo de Hopfield e de Ising para calcular a energia textual das sentenças. O pré-tratamento do texto é o mesmo descrito no SASI (seção 5.1), com a criação da matriz de palavras S[NS×NP ]. Em seguida, o Enertex utiliza a matriz S para analisar a interação entre os termos do vocabulário do texto a partir da regra de Hebb (equação 4.4).\nK = ST × S, (4.4)\nonde ST é a matriz transposta de S. Baseada nessa interação, a energia textual (Energia) é calculada através da equação 4.5.\nEnergia = − 1\n2 S×K× ST ;Energiaij ∈ EnergiaNS×NS (4.5)\nem que Energiaij representa a energia da interação entre as sentenças i e j. A relevância das sentenças é calculada considerando sua energia textual e, por fim, cria-se o resumo (sem redundâncias) a partir das frases consideradas mais relevantes pelo sistema."
    }, {
      "heading" : "4.4 GistSumm",
      "text" : "O sistema GistSumm [Pardo, Rino e Nunes 2003] baseia-se em encontrar a mensagem principal do documento para a criação de seu resumo. O sistema segmenta o texto e calcula a relevância das sentenças através das palavras-chaves e do TF-ISF das sentenças. Dessa forma, as sentenças com maior score são consideradas as mais relevantes para o documento. O sistema avalia a pontuação das sentenças determinando seus limiares e seleciona as sentenças que possuam palavras com radicais correspondentes às palavras na sentença principal e com um score acima do limiar."
    }, {
      "heading" : "4.5 KLSumm",
      "text" : "O algoritmo KLSumm baseia-se no cálculo da divergência KL (seção 3.4.1) para analisar a divergência entre um sumário e seu texto original [Haghighi e Vanderwende"
    }, {
      "heading" : "4.6 LexRank 42",
      "text" : "2009]. O objetivo desse algoritmo é tornar o sumário (conjuntos de palavras R) o mais similar possível do texto (conjunto de palavras O) respeitando o limite de caracteres do sumário (equação 4.6). Dessa forma, o sistema seleciona as sentenças menos divergentes em relação ao texto, conforme a equação 4.6.\nResumo = min DKL(R||O) (4.6)"
    }, {
      "heading" : "4.6 LexRank",
      "text" : "O LexRank avalia estocasticamente a relevância das sentenças [Erkan e Radev 2004]. O sistema utiliza um grafo de palavras construído a partir do texto e o modela como um grafo de sentenças. O sistema é dividido em duas partes: similaridade das sentenças e centralidade de uma sentença com relação às demais.\nO cálculo da similaridade é baseado no TF-ISF e no cosseno de similaridade (equação 4.7), sendo tf(w, P ) a frequência da palavra w na sentença P e idf(w) o valor inverse document frequency (inverso da frequência nos documentos) da palavra w.\nlexranksim(P,Q) =\n∑ w∈P,Q tf(w, P )× tf(w,Q)× [idf(w)] 2\n√∑ pi∈P [tf(pi, P )× idf(pi)]2 × √∑ qi∈Q [tf(qi, Q)× idf(qi)]2\n(4.7)\nA partir da similaridade (lexranksim), calcula-se a relevância (score) de cada sentença baseada na centralidade das sentenças (equação 4.8). A variável d considera a ponderação inicial dos vértices.\np(u) = d\nNS + (1− d)\n∑\nv∈viz(u)\nlexranksim(u, v)∑ z∈viz(v) lexranksim(z, v) p(v) (4.8)\nonde p(u) é a centralidade do vértice e viz(u) são os vértices vizinhos de u.\nO sistema criará um resumo com as sentenças de maior score e sem redundância."
    }, {
      "heading" : "4.7 Programação Linear Inteira",
      "text" : "[Mcdonald 2006] propôs um modelo matemático para avaliar a qualidade do resumo\nbaseado na relevância e similaridade das sentenças. Seja um conjunto de sentenças de um"
    }, {
      "heading" : "4.8 Submodular 43",
      "text" : "texto bfi indicará a existência da sentença i no resumo do texto, Doc será o conjunto de sentenças do documento, Redudij representará a redundância entre as sentenças i e j e por sua vez Relevi representará a relevância da sentença i. Dessa forma, um resumo pode ser avaliado pela fórmula descrita na equação 4.9.\nResumo = ∑\ni∈Doc\nRelevi × bfi − ∑\ni,j∈Doc\nRedudij × bfi × bfj (4.9)\nMcdonald modela o problema usando Programação Linear, considerando L como o limite máximo de caracteres do resumo e li o tamanho da sentença i. A análise da redundância é uma função quadrática, portanto é necessário linearizar a ocorrência simultânea das frases i e j (rij = bfi × bfj). Assim, a modelagem PLI utilizada por Mcdonald é expressa pelas equações 4.10, 4.11, 4.12, 4.13 e 4.14.\nMaximizar: ∑\ni∈Doc\nRelevi × bfi − ∑\ni,j∈Doc\nRedudij × rij (4.10)\nRestrições: ∑\nj∈Doc\nlj × bfj ≤ L (4.11)\nrij ≤ bfi rij ≤ bfj ∀i, j (4.12)\nbfi + bfj − rij ≤ 1 ∀i, j (4.13)\nbfi ∈ {0, 1} ∀i (4.14)"
    }, {
      "heading" : "4.8 Submodular",
      "text" : "Seja B um conjunto finito e seja f uma função de partes de B em R. A função f é submodular se para quaisquer partes C e D de B, observa-se a relação expressa na equação 4.15.\nf(C ∪D) + f(C ∩D) ≤ f(C) + f(D) (4.15)\nCorrelacionando a função submodular com a extração automática, definiu-se B como o conjunto com todas as sentenças do documento, C é resumo do texto e f é a função de avaliação de qualidade do resumo. A sumarização objetiva encontrar o conjunto de sentenças (conjunto C), que melhor represente o texto (conjunto B) e tenha um tamanho"
    }, {
      "heading" : "4.8 Submodular 44",
      "text" : "|C| ≤ L (tamanho máximo do resumo) (equação 4.16). Esse problema é NP-Difícil. Entretanto, é possível determinar uma solução aproximada através de um algoritmo guloso se a função f for submodular [Lin, Bilmes e Xie 2009].\nmax C⊆B {f(C) : |C| ≤ L} (4.16)\nO trabalho [Lin, Bilmes e Xie 2009] descreve quatro funções submodulares para avaliar a qualidade de resumos automáticos. A primeira calcula a representatividade de um resumo com relação ao texto (equação 4.17) analisando a similaridade do resumo C com relação ao texto B, sendo simij a similaridade entre as sentenças i e j.\nffac(C) = ∑\ni∈B\nmax j∈C simij (4.17)\nA segunda métrica utilizada, fcorte, avalia a similaridade das sentenças do resumo em relação as demais sentenças do texto (equação 4.18). A terceira métrica, fpior, considera o caso de uma sentença relevante não ser similar às demais. Uma forma de avaliar esse caso é através da maximização da similaridade da sentença menos similar do resumo (equação 4.19).\nfcorte(C) = ∑\ni∈B\\C\n∑\nj∈C\nsimij (4.18)\nfpior(C) = min i∈B max j∈C simij (4.19)\nA última métrica, fpen, avalia a redundância das sentenças do resumo. Um resumo deve ser conciso e pequeno. Desse modo, a presença de sentenças similares não adiciona um conteúdo interessante ao resumo. Portanto, pode-se evitar essa redundância com a adição de penalidades às sentenças similares do resumo (equação 4.20), em que λ é a taxa de penalidade caso haja redundância de sentenças.\nfpen(C) = ∑\ni∈B\\C\n∑\nj∈C\nsimij − λ ∑\ni,j∈C:i 6=j\nsimij , λ ≥ 0 (4.20)"
    }, {
      "heading" : "4.9 TextRank 45",
      "text" : ""
    }, {
      "heading" : "4.9 TextRank",
      "text" : "O TextRank é um algoritmo baseado em grafos para mensurar a relevância das sentenças [Mihalcea e Tarau 2004]. O algoritmo baseia-se na recomendação (ou relevância) de cada vértice baseada nas ligações entre os mesmos. Portanto, quanto maior a quantidade de ligações associadas a um vértice, mais relevante ele será para o texto.\nO algoritmo modela o texto como um grafo de sentenças e cria as arestas baseadas na\nsimilaridade entre as sentenças P e Q (equação 4.21).\nsim(P,Q) = |{w|w ∈ P & w ∈ Q}|\nlog(|P |) + log(|Q|) (4.21)\nO TextRank mensura o score de cada vértice de forma recursiva utilizando a\nvizinhança dos vértices até seus valores se tornarem estáveis (equação 4.22).\nRec(vi) = (1− p) + p× ∑\nvj∈viz(vi)\nsim(vj , vi)∑ vk∈viz(vj) sim(vj , vk) Rec(vj), (4.22)\nem que a variável p é um amortecimento ajustado entre 0 e 1, sim(vj , vi) é a similaridade entre os vértices vj e vi, e viz(vi) representa o conjunto de vértices da vizinhança do vértice vi.\nFinalmente, o sistema cria o resumo com as sentenças de maior score.\n46\nCAPÍTULO 5\nSISTEMAS PROPOSTOS\nEste capítulo aborda os sistemas sumarizadores LIA-RAG, RAG, SASI e SUMMatrix. Os sistemas utilizam a Teoria de Grafos (LIA-RAG, RAG e SASI) e matrizes de similaridade (SUMMatrix) juntamente com métricas de similaridade para avaliar a divergência entre as sentenças e selecionar as principais informações de um texto. Os sistemas desenvolvidos são sumarizadores genéricos, monodocumento e multidocumento, indicativos com as informações-chaves e geram os resumos através da extração de sentenças. Os sistemas nesta dissertação possuem características particulares e assim, requereram o uso de corpus específicos ao problema configurado. A seção 5.1 descreve a motivação e o funcionamento geral dos sistemas SASI. As seções 5.2 e 5.3 descrevem o funcionamento dos sistemas RAG e LIA-RAG. Por fim, a seção 5.4 descreve o sistema SUMMatrix e suas características."
    }, {
      "heading" : "5.1 Sumarizador Automático baseado em Subconjunto Independente (SASI)",
      "text" : "Um texto é composto por diversas sentenças, que podem ser agrupadas de acordo com o grau de similaridade entre elas. Cada grupo aborda uma etapa/ideia do texto. Considera-se neste trabalho que uma sentença similar a todas (ou à maioria) pertencentes ao seu grupo possui conteúdo “relevante” com relação ao grupo. Dessa forma, é possível criar um resumo com a ideia geral do texto utilizando as sentenças com maior similaridade identificadas em cada grupo. Uma outra abordagem possível consiste em obter resumos contendo apenas as informações mais importantes, ou seja, analisar somente os maiores grupos de sentenças similares visto que suas informações são constantemente discutidas no texto."
    }, {
      "heading" : "5.1 Sumarizador Automático baseado em Subconjunto Independente (SASI) 47",
      "text" : "O sistema SASI analisa e cria grupos de sentenças similares do texto para identificar\ne gerar um resumo com as principais sentenças de cada grupo."
    }, {
      "heading" : "5.1.1 Funcionamento",
      "text" : "Inicialmente, executa-se o pré-tratamento do documento realizando o processo de leitura e o reconhecimento de caracteres do texto. Em seguida, realiza-se a segmentação das sentenças e palavras, a filtragem de stopwords e o processo de stemming a fim de remover palavras irrelevantes e reduzir as palavras às suas raízes. Por fim, cria-se uma matriz de palavras correlacionando sua frequência em cada sentença. De posse dessa matriz de palavras, o SASI calcula a divergência das sentenças.\nRealiza-se, igualmente, uma filtragem das sentenças sem relevância para o texto e verifica-se a divergência entre elas. Para isso, foi utilizada a abordagem descrita na seção 3.4. Então, sempre dois conjuntos de palavras P e Q são analisados concomitantemente. Inicialmente, P e Q referenciam, respectivamente, o texto completo e cada frase isolada do mesmo. Dessa forma, calcula-se a divergência entre os conjuntos P e Q, DJS(P ||Q), para verificar se uma frase é importante para o documento por meio da análise das palavras existentes:\n◮ Se a divergência da frase for grande em relação ao texto completo, a frase será\ndescartada;\n◮ Se o documento possuir um título: analisa-se a similaridade entre o título e a\nfrase descartada, caso a divergência entre eles seja pequena, a frase fará parte do documento novamente.\nEm seguida, o SASI cria um grafo G em que os vértices representam as sentenças inicialmente relevantes. Nesse caso, os conjuntos P e Q correspondem a pares de sentenças e sua divergência será igualmente utilizada para a criação e para a ponderação das arestas. Caso a divergência entre duas sentenças seja “pequena” (parâmetro do algoritmo), uma aresta interligando-as será inserida.\nA sumarização objetiva a produção de um resumo de tamanho pequeno e com as principais informações do texto. Desse modo, o SASI deverá escolher somente as sentenças com mais informações adicionais para construir o resumo. Portanto, a escolha de vértices adjacentes implica na seleção de frases com conteúdo redundante, o que não é interessante para esse tipo de resumo. O sistema deverá selecionar as frases com conteúdo distinto"
    }, {
      "heading" : "5.1 Sumarizador Automático baseado em Subconjunto Independente (SASI) 48",
      "text" : "entre si, descartando as sentenças repetitivas ou que trazem pouca informação adicional ao resumo. A determinação de um Subconjunto Independente de Vértices (SIV) do grafo fornece uma possível solução para o problema devido suas características de selecionar vértices não conectados entre si. Os vértices com maior grau tem preferência no resumo pois, teoricamente, são similares a um número maior de sentenças e, portanto, são mais relevantes. Dessa forma, o sistema ordena os vértices de acordo com o grau deles em ordem decrescente. Em seguida, o SASI avalia os vértices nessa ordem e seleciona aqueles que mantenham as características do SIV. O resumo é composto pelas frases que compõem o SIV excluindo as frases que são redundantes com base no coeficiente de Dice [Dice 1945] (figura 12).\nFigura 12 – Funcionamento do sistema SASI."
    }, {
      "heading" : "5.1.2 Exemplo",
      "text" : "O texto da tabela 5.1 retrata uma notícia sobre a política brasileira. Inicialmente realiza-se os processos de segmentação, filtragem, stemming e criação da matriz de palavras. Os textos não possuem títulos, então todas as sentenças são consideradas"
    }, {
      "heading" : "5.2 Résumeur Avec de Graphes (RAG) 49",
      "text" : "relevantes. O sistema recebe a matriz e cria um grafo de sentenças. O SASI calcula a divergência entre as sentenças e caso a divergência entre elas seja abaixo de 0, 20 (valor obtido de forma empírica), adiciona-se uma aresta interligando os dois vértices, i.e., as duas sentenças. Em seguida, o sistema calcula o SIV privilegiando os vértices de maior grau. Por fim, o resumo do texto é composto pela concatenação das sentenças selecionadas no SIV, sem redundâncias. Nesse exemplo, o resumo com 100 palavras é composto pelas frases: S − 9, S − 13, S − 18, S − 19 e S − 21.\n5.2 Résumeur Avec de Graphes (RAG)\nAs principais ideias de um texto são geralmente analisadas e discutidas várias vezes. No entanto, não é necessário dispor de uma grande quantidade de sentenças similares para que elas tenham importância. O RAG, que é um sistema sumarizador automático por extração de sentenças, seleciona as principais sentenças de um texto baseado na similaridade entre as sentenças e na importância das palavras."
    }, {
      "heading" : "5.2.1 Funcionamento",
      "text" : "Efetua-se o pré-processamento dos textos e obtém-se a matriz de saco de palavras, assim como descrito no funcionamento do sistema SASI (seção 5.1). O RAG calcula a relevância de cada sentença com base na métrica TF-ISF (equação 3.2) e seleciona as sentenças com maior score.\nO RAG cria um grafo G em que cada vértice representa uma sentença selecionada anteriormente. O texto é analisado e modelado como um grafo de sentenças (vértices). Com base na equação 3.10, o RAG calcula a similaridade entre as sentenças. Se a divergência entre elas é menor do que limiar (obtido por testes empíricos), então o sistema criará uma aresta entre elas. Portanto, os vértices com maior grau terão o conteúdo mais analisado no texto. No entanto, algumas sentenças podem ter um grau pequeno e mesmo assim podem conter informações importantes. O RAG combina o valor do TF-ISF e do grau das sentenças para analisar sua relevância. A relevância da sentença i é definida pela equação 5.1, onde grau(i) é o grau de vértice i e rel(i) é a relevância da sentença i (equação 3.3). Em seguida, o sistema cria um resumo de sentenças de pontuação mais elevada, excluindo frases similares (ou redundantes) com base no coeficiente de Dice [Dice 1945]. A figura 13 descreve o sistema RAG."
    }, {
      "heading" : "5.2 Résumeur Avec de Graphes (RAG) 50",
      "text" : "score(i) = grau(i)× rel(i) (5.1)\nFigura 13 – Sistema RAG."
    }, {
      "heading" : "5.2.2 Exemplo",
      "text" : "O exemplo aqui descrito considera o mesmo texto da tabela 5.1. Inicialmente realiza-se os processos de segmentação, filtragem e stemming. Em seguida, uma matriz de saco de palavras é criada a partir do texto. O RAG recebe essa matriz, calcula o TF-ISF das sentenças para remover as sentenças menos relevantes e modela o texto como um grafo de sentenças. Em seguida, o sistema calcula o score das sentenças (tabela 5.2) e são selecionadas as de maior pontuação. No exemplo considerado, o resumo contendo 100 palavras é composto pelas sentenças: S-3, S-11, S-13, S-14 e S-18."
    }, {
      "heading" : "5.3 LIA-RAG 51",
      "text" : ""
    }, {
      "heading" : "5.3 LIA-RAG",
      "text" : "O áudio é amplamente utilizado nas transmissões dos rádios e na internet (em notícias, histórias, entrevistas ou conversas). Existem várias ferramentas para reconhecimento de voz (áudio sobre um assunto ou uma conversa entre duas ou mais pessoas).\nA tarefa de sumarização de textos orais é mais complexa e envolve a transcrição de áudios em textos. As reuniões e conversas envolvem discussões entre várias pessoas e frequentemente suas vozes se sobrepõem. Essas transcrições possuem diversas problemáticas associadas pois é mais difícil identificar os limites de uma sentença, visto que a mesma pode ser fragmentada, conter rupturas e introduzir erros de reconhecimento de fala. A linguagem utilizada pode ser informal e as declarações podem ser parciais, fragmentárias, não gramaticais, além de possivelmente incluírem muitas reticências e pronomes. No entanto, a fala pode fornecer informações adicionais que evidenciam uma parte específica do texto como, por exemplo, a prosódia [Murray, Renals e Carletta 2005].\n[Mckeown et al. 2005] descreveram aplicações de técnicas de sumarização automática\nde um texto para a produção de resumos de conversas orais. Eles analisaram alguns trabalhos sobre a produção de resumos de notícias e reuniões. [Murray, Renals e Carletta 2005] analisaram a sumarização extrativa de reuniões multipartidárias. Eles descreveram a relevância marginal máxima e a análise semântica latente para criar um resumo com base em características prosódicas e lexicais.\nO sistema LIA-RAG foi desenvolvido a fim de sumarizar textos de conversas através da extração de sentenças. Esse sistema seleciona as principais sentenças da conversa transcrita baseado no sistema RAG e usa um pós-processamento para remover os erros contidos em diálogos e tornar o texto mais conciso e compacto."
    }, {
      "heading" : "5.3.1 Funcionamento",
      "text" : "O LIA-RAG recebe um texto transcrito de uma conversa e realiza o pré-processamento do mesmo, pois estas possuem diversas expressões para associar o pensamento e o modo de falar dos personagens. O sistema remove essas expressões e características relacionadas aos participantes da conversa. Em seguida, ele analisa a relevância das sentenças utilizando o sistema RAG, que fornece o resumo automático da conversa.\nO processo de reconhecimento da voz produz um texto com vários problemas gramaticais (gírias, linguagens cotidianas, expressões e erros de reconhecimento da fala)."
    }, {
      "heading" : "5.4 SUMmarizer based on Matrix model (SUMMatrix) 52",
      "text" : "Um algoritmo de resumo por extração seleciona as frases relevantes. No entanto, as sentenças podem ter alguns problemas gramaticais. Assim, é necessário realizar um tratamento desse resumo. Os principais aspectos analisados nesse processo são:\n◮ coloquialismos;\n◮ expressões da fala;\n◮ datas.\nAlgumas expressões da fala são usadas para conectar ideias ou conceitos em conversas orais. O sistema LIA-RAG realiza o pós-processamento com o resumo gerado pelo RAG. O sistema remove essas expressões da fala porque muitas vezes elas são transcritas incorretamente (ruído na conversação). Além disso, o sistema elimina vários coloquialismos e palavras duplicadas, substitui algumas palavras erradas por sua forma correta e transforma as datas por extenso na forma “dia/mês/ano”. A figura 14 mostra a arquitetura do sistema LIA-RAG.\nFigura 14 – Sistema LIA-RAG.\n5.4 SUMmarizer based on Matrix model (SUMMatrix)\nAtualmente, há diferentes jornais e sites de notícias disponibilizando informações sobre diferentes acontecimentos a todo momento. Entretanto, a análise de uma notícia a partir de uma única fonte pode fornecer informações imprecisas, duvidosas ou desnecessárias. A diversidade dos meios de comunicação possibilita a identificação de informações tendenciosas (desnecessárias ou erradas) e compreender corretamente um acontecimento a partir de diferentes perspectivas.\nA utilização de várias fontes de informação nos auxilia na compreensão de um evento. Entretanto, a enorme quantidade de notícias torna impossível sua leitura de maneira integral. Uma maneira de resolver esse problema é selecionar as principais informações"
    }, {
      "heading" : "5.4 SUMmarizer based on Matrix model (SUMMatrix) 53",
      "text" : "contidas em todos os documentos e criar um resumo com as mesmas [Barzilay e McKeown 2005].\nO sistema SUMMatrix foi desenvolvido no intuito de analisar as sentenças de conjuntos de textos de conteúdo similar. O sistema cria um resumo por extração independente do idioma do cluster, analisa as sentenças dos textos e calcula a divergência entre as mesmas a fim de mensurar sua relevância. Em seguida, o resumo é gerado através da concatenação das sentenças com maior pontuação. A figura 15 descreve resumidamente o funcionamento do SUMMatrix.\nFigura 15 – Funcionamento do sistema SUMMatrix."
    }, {
      "heading" : "5.4.1 Funcionamento",
      "text" : "O SUMMatrix analisa um cluster composto de textos relacionados a uma mesma notícia. Esses textos são similares e transmitem a mesma mensagem ou uma informação similar. O cálculo da similaridade utiliza unigramas e bigramas. O SUMMatrix é iterativo pois analisa qualquer quantidade de documentos em um cluster. Ele analisa os textos em pares com o intuito de identificar as sentenças similares.\nO sistema SUMMatrix calcula a divergência a partir da divergência JS ou KL bem como a similaridade do cosseno. Para calcular a divergência, considera-se os conjuntos P e Q que referem-se, respectivamente, ao conjunto de palavras da sentença do primeiro texto e da sentença do segundo texto. Pr(P,w) é a probabilidade da palavra w na sentença P e Pr(Q,w) da sentença Q. Além da divergência JS ou KL, o sistema avalia a similaridade do cosseno entre duas sentenças. Assim, a divergência entre duas sentenças F1 e F2, Div(F1, F2), é calculada pela equação 5.2 e seu valor varia entre 0 e ∞. Portanto, quanto menor for o valor da divergência maior será a similaridade entre as sentenças."
    }, {
      "heading" : "5.4 SUMmarizer based on Matrix model (SUMMatrix) 54",
      "text" : "Div(F1, F2) = [1− cos(F1, F2)] +DJS(F1||F2) (5.2)\nO SUMMatrix analisa os dois primeiros textos, denominados T1 e T2, e verifica quais sentenças (em pares) são mais similares através do cálculo da divergência descrito na equação 5.2. O sistema cria uma matriz de divergência onde as linhas representam as sentenças do T1 e as colunas representam as sentenças do T2. O sistema seleciona, em seguida, o par de sentenças (sT1, sT2) com menor divergência e calcula a divergência entre ele e o cluster. As sentenças selecionadas de cada par são consideradas mais relevantes e adicionadas ao Resumo Parcial, o qual contém as principais sentenças dos textos considerados. Nesse momento, o sistema analisa o conjunto Resumo Parcial e o texto seguinte, denominado T3. O sistema cria uma nova matriz de divergência entre as sentenças dos mesmos. O SUMMatrix seleciona os pares de sentenças mais similares, calcula a divergência das sentenças em relação ao cluster e acrescenta a sentença mais similar em cada par de sentenças no novo conjunto Resumo Parcial. O sistema repete esse processo até que todos os textos tenham sido analisados. O conjunto Resumo Final será composto pelas sentenças da última versão do conjunto Resumo Parcial.\nO sistema analisa o conjunto Resumo Final e cria o resumo sem sentenças redundantes a partir da similaridade de Dice [Dice 1945] e da taxa de compressão definida pelo usuário. A figura 16 apresenta a arquitetura desse sistema de maneira estruturada."
    }, {
      "heading" : "5.4.2 Exemplo",
      "text" : "O conjunto de textos descrito na tabela 5.7 discorre sobre um mesmo acidente de avião ocorrido no Congo. O processo de sumarização inicia com o pré-tratamento do texto e com a criação da matriz de palavras. O SUMMatrix calcula a divergência entre pares de sentenças dos textos T1 e T2 e identifica aquelas com menor divergência (tabela 5.3).\nAs sentenças identificadas são comparadas com o cluster completo para analisar a divergência entre elas. A sentença de cada par de frases mais similar ao cluster é selecionada para constituir o Resumo Parcial dos textos T1 e T2. A tabela 5.4 mostra a divergência entre as frases selecionadas e o cluster. Assim, o resumo parcial da análise dos textos T1 e T2 é composto pelas frases: T1− 2, T1− 4, T1− 7, T2− 1 e T2− 3.\nEm seguida, inicia-se a análise do Resumo Parcial e o texto T3. É criada uma nova matriz de divergência entre eles (tabela 5.5). O sistema calcula a divergência entre as frases e seleciona os pares de menor divergência. Novamente, analisa-se os pares de sentenças"
    }, {
      "heading" : "5.4 SUMmarizer based on Matrix model (SUMMatrix) 55",
      "text" : "Figura 16 – Sistema SUMMatrix.\ncom menor divergência em relação ao cluster. Verifica-se a divergência entre as frases e o cluster completo e seleciona-se as frases de cada par que forem mais similares ao cluster para compor o Resumo Final do grupo de textos (tabela 5.6). Finalmente, o Resumo Final é composto pelas frases: T1− 4, T2− 1, T2− 3, T3− 2 e T3− 3."
    }, {
      "heading" : "5.4 SUMmarizer based on Matrix model (SUMMatrix) 56",
      "text" : "Tabela 5.1 – Texto integrando o cluster do corpus CSTNews [Dias et al. 2014].\nTexto S-1 Termina hoje, às 20 horas, o prazo para que os deputados acusados de participar do esquema dos sanguessugas renunciem para escapar da abertura de processo por quebra de decoro parlamentar. S-2 A expectativa de lideranças da Câmara e do Conselho de Ética é que pouco mais de 10% dos 69 deputados denunciados no relatório parcial da CPI dos Sanguessugas abrirão mão de seus mandatos. S-3 Integrante da cúpula da Câmara que, nos últimos dias, conversou com ao menos 30 parlamentares acusados no caso calcula que sete podem renunciar - Nilton Capixaba (PTB-RO), Marcelino Fraga (PMDB-ES), César Bandeira (PFL-MA), Benedito Dias (PP-AP), Carlos Nader (PL-RJ), João Caldas (PL-AL) e Reginaldo Germano (PP-BA). S-4 Ex-líder do PP, Pedro Henry (MT) cogitou sair da função, mas teria desistido da ideia. S-5 Até ontem, só Coriolano Sales (PFL-BA) havia apresentado renúncia. S-6 Ele não quis arriscar a chance de assumir a prefeitura de Vitória da Conquista. S-7 Segundo colocado em 2004, Sales processou seu adversário por abuso do poder econômico e aguarda resultado. S-8 “Não dá para avaliar quantos vão renunciar”, disse ontem o presidente do Conselho de Ética, Ricardo Izar (PTB-SP). S-9 Ele vai instaurar o processo contra os deputados envolvidos com a máfia dos sanguessugas amanhã, às 10h30. S-10 Formalizada antes da abertura, a renúncia cessa o procedimento. S-11 Izar pretende que os casos dos 15 parlamentares que receberam depósito na própria conta bancária ou na de parentes sejam os primeiros julgados pelo Conselho. S-12 “Vou instaurar todos os processos juntos, mas a ideia é que os 15 casos mais graves, que têm provas contundentes, sejam julgados na frente”, afirmou Izar. S-13 O horário-limite para que o parlamentar renuncie - 20 horas - foi estabelecido pela direção da Câmara a fim de que o ato seja oficializado com a sua publicação já no Diário Oficial do Congresso de amanhã. S-14 A maioria dos 69 deputados acusados de envolvimento com a máfia dos sanguessugas é candidato à reeleição e, com a renúncia, tentará escapar do risco de cassação e da perda dos direitos políticos por oito anos. S-15 Outros parlamentares resistem à renúncia por considerarem ter chance de não sofrer punição. S-16 Segundo investigações iniciadas pela Polícia Federal, o esquema consistia no desvio de recursos públicos por meio da apresentação de emendas parlamentares para a compra superfaturada de ambulâncias. S-17 Dois dos 69 deputados acusados são da Mesa Diretora, mas se afastaram das funções. S-18 Contra João Caldas, por exemplo, pesam 12 pagamentos no total de R$ 136 mil, alguns dos quais em sua própria conta. S-19 Ele, porém, resiste à ideia de abrir mão do mandato. S-20 Já Capixaba, acusado de ter recebido R$ 646 mil, considera seriamente a hipótese de renunciar. S-21 No caso dos integrantes da Igreja Universal, a possibilidade de saída do cargo está afastada, pois os envolvidos, entre eles Edna Macedo (PTB-SP), foram proibidos pela direção da instituição de concorrer à reeleição. S-22 Eleitos na esteira do deputado Enéas Carneiro (Prona-SP), ex-integrantes do partido suspeitos, como Irapuan Teixeira (PTB-PR) e Ildeu Araújo (PP-SP), tiveram votação insignificante em 2002 e não têm chance de reeleição. S-23 Devem preferir manter o resto do mandato."
    }, {
      "heading" : "5.4 SUMmarizer based on Matrix model (SUMMatrix) 57",
      "text" : "Tabela 5.2 – Relevância das sentenças segundo o sistema RAG.\nSentenças Relevância Sentenças Relevância Sentenças Relevância S-1 93,7 S-9 89,1 S-17 26,5 S-2 84,4 S-10 71,6 S-18 134,0 S-3 113,4 S-11 127,9 S-19 92,9 S-4 78,0 S-12 83,4 S-20 63,2 S-5 47,8 S-13 157,8 S-21 65,0 S-6 86,1 S-14 115,1 S-22 53,7 S-7 0 S-15 28,9 S-23 31 S-8 99,1 S-16 104,5 —– —-\nTabela 5.3 – Divergência entre as frases dos textos T1 e T2.\nT2− 1 T2− 2 T2− 3 T2− 4 T2− 5 T2− 6 T2− 7 T1− 1 0,44 0,55 0,56 0,65 0,65 0,63 0,48 T1− 2 0,51 0,66 0,51 0,52 0,43 0,64 0,40 T1− 3 0,67 0,65 0,35 0,64 0,65 0,63 0,66 T1− 4 0,55 0,44 0,62 0,60 0,68 0,67 0,43 T1− 5 0,59 0,64 0,44 0,63 0,63 0,60 0,65 T1− 6 0,38 0,66 0,69 0,65 0,65 0,63 0,57 T1− 7 0,49 0,65 0,68 0,64 0,64 0,63 0,47 T1− 8 0,54 0,65 0,61 0,63 0,64 0,61 0,55\nTabela 5.4 – Divergência entre as sentenças selecionadas e o cluster.\nT1− 1 T2− 1 T1− 5 T2− 3 Cluster 0,55 0,39 Cluster 0,60 0,43 T1− 2 T2− 7 T1− 6 T2− 1 Cluster 0,53 0,55 Cluster 0,55 0,39 T1− 3 T2− 3 T1− 7 T2− 7 Cluster 0,57 0,43 Cluster 0,54 0,55 T1− 4 T2− 7 T1− 8 T2− 1 Cluster 0,34 0,55 Cluster 0,58 0,39\nTabela 5.5 – Divergência entre as frases do Resumo Parcial e o texto T3.\nT3− 1 T3− 2 T3− 3 T3− 4 T3− 5 T1− 2 0,52 0,50 0,55 0,68 0,64 T1− 4 0,63 0,55 0,15 0,27 0,67 T1− 7 0,50 0,68 0,27 0,58 0,63 T2− 1 0,01 0,64 0,51 0,68 0,66 T2− 3 0,65 0,02 0,69 0,64 0,68"
    }, {
      "heading" : "5.4 SUMmarizer based on Matrix model (SUMMatrix) 58",
      "text" : "Tabela 5.6 – Divergência entre as sentenças selecionadas e o cluster.\nT1− 2 T3− 2 Cluster 0,53 0,44 T1− 4 T3− 3 Cluster 0,34 0,44 T1− 7 T3− 3 Cluster 0,54 0,44 T2− 1 T3− 1 Cluster 0,39 0,40 T2− 3 T3− 2 Cluster 0,43 0,44"
    }, {
      "heading" : "5.4 SUMmarizer based on Matrix model (SUMMatrix) 59",
      "text" : "Tabela 5.7 – Cluster com 3 textos de diferentes jornais relatando um mesmo acidente no Congo (corpus CSTNews [Dias et al. 2014]).\nTexto T1: T1-1 Ao menos 17 pessoas morreram após a queda de um avião de passageiros na República Democrática do Congo. T1-2 Segundo uma porta-voz da ONU, o avião, de fabricação russa, estava tentando aterrissar no aeroporto de Bukavu em meio a uma tempestade. T1-3 A aeronave se chocou com uma montanha e caiu, em chamas, sobre uma floresta a 15 quilômetros de distância da pista do aeroporto. T1-4 Acidentes aéreos são frequentes no Congo, onde 51 companhias privadas operam com aviões antigos principalmente fabricados na antiga União Soviética. T1-5 O avião acidentado, operado pela Air Traset, levava 14 passageiros e três tripulantes. T1-6 Ele havia saído da cidade mineira de Lugushwa em direção a Bukavu, numa distância de 130 quilômetros. T1-7 Aviões são usados extensivamente para transporte na República Democrática do Congo, um vasto país no qual há poucas estradas pavimentadas. T1-8 Apenas uma manteve a permissão. Texto T2: T2-1 Um acidente aéreo na localidade de Bukavu, no leste da República Democrática do Congo (RDC), matou 17 pessoas na quinta-feira à tarde, informou nesta sexta-feira um porta-voz das Nações Unidas. T2-2 As vítimas do acidente foram 14 passageiros e três membros da tripulação. T2-3 Todos morreram quando o avião, prejudicado pelo mau tempo, não conseguiu chegar à pista de aterrissagem e caiu numa floresta a 15 quilômetros do aeroporto de Bukavu. T2-4 Segundo fontes aeroportuárias, os membros da tripulação eram de nacionalidade russa. T2-5 O avião explodiu e se incendiou, acrescentou o porta-voz da ONU em Kinshasa, Jean-Tobias Okala. T2-6 “Não houve sobreviventes”, disse Okala. T2-7 O porta-voz informou que o avião, um Soviet Antonov-28 de fabricação ucraniana e propriedade de uma companhia congolesa, a Trasept Congo, também levava uma carga de minerais. Texto T3: T3-1 Um acidente aéreo na localidade de Bukavu, no leste da República Democrática do Congo, matou 17 pessoas na quinta-feira à tarde, informou hoje um porta-voz das Nações Unidas. T3-2 As vítimas do acidente foram 14 passageiros e três membros da tripulação. T3-3 Todos morreram quando o avião, prejudicado pelo mau tempo, não conseguiu chegar à pista de aterrissagem e caiu numa floresta a 15 Km do aeroporto de Bukavu. T3-4 O avião explodiu e se incendiou, acrescentou o porta-voz da ONU em Kinshasa, Jean-Tobias Okala. T3-5 “Não houve sobreviventes”, disse Okala.\n60\nCAPÍTULO 6\nCORPUS E MÉTODOS DE AVALIAÇÃO\nEste capítulo descreve os corpus utilizados nos testes descritos no capítulo 7. Serão apresentadas suas características e os métodos utilizados para avaliar a qualidade dos sistemas desenvolvidos e dos referenciados na literatura. A seção 6.1 descreve os corpus e a seção 6.2 descreve as métricas para avaliar a qualidade dos resumos."
    }, {
      "heading" : "6.1 Corpus",
      "text" : "O corpus é um conjunto de textos com características específicas. As subseções\nseguintes descrevem os corpus utilizados e suas características."
    }, {
      "heading" : "6.1.1 Corpus multi-idioma",
      "text" : "O corpus multi-idioma é composto por textos de jornais e revistas científicas em inglês, francês e espanhol. Além dessas características, os resumos dos textos selecionados estão disponíveis na literatura para outros sistemas sumarizadores [Torres-Moreno, Velázquez-Morales e Meunier 2002,FernÁndez, SanJuan e Torres-Moreno 2008]. O corpus utilizado é composto por 13 textos de diferentes tamanhos e assuntos."
    }, {
      "heading" : "6.1.2 CSTNews",
      "text" : "O corpus CSTNews11 é composto por textos jornalísticos em Português. Esse corpus possui notícias sobre política, esportes, acidentes, mundo, entre outros. Ele contém 50\n11Corpus CSTNews: http://www.icmc.usp.br/∼taspardo/sucinto/cstnews.html"
    }, {
      "heading" : "6.1 Corpus 61",
      "text" : "clusters, cada qual possuindo 2 ou 3 textos relacionados ao mesmo acontecimento. Os textos são provenientes de diferentes agências de notícias online populares no país: Folha de São Paulo, Estadão, O Globo, Jornal do Brasil e Gazeta do Povo. Os textos foram selecionados durante os meses de agosto e setembro de 2007 [Dias et al. 2014]. O CSTNews possui 40.839 palavras e 258.818 caracteres."
    }, {
      "heading" : "6.1.3 RPM",
      "text" : "O corpus RPM12 é composto por 40 clusters em Francês. O corpus possui 20 temáticas e cada uma delas possui 2 clusters. Ele é composto por textos de assuntos similares que foram coletados em momentos distintos. Esse corpus possui resumos elaborados por profissionais em cada cluster. O RPM possui 143.881 palavras e 905.348 caracteres."
    }, {
      "heading" : "6.1.4 DECODA",
      "text" : "O corpus DECODA é composto de conversas em francês entre clientes e agentes que foram registradas em 2009 em um call center da autoridade de transporte público de Paris (tabela 6.1) [Bechet et al. 2012]. Os tópicos das conversas consistem em pedidos de itinerários, cronogramas, perdidos e achados e reclamações. Os diálogos foram gravados em condições espontâneas e focados no objetivo do autor da chamada. Essas gravações são um grande desafio para o reconhecimento automático da fala devido às condições acústicas difíceis, tais como ligações de telefones celulares diretamente do metrô.\nTabela 6.1 – Estatística do corpus DECODA.\nEstatísticas FR Conversas 100 Falas 7.905 Palavras 42.130 Tamanho médio 421,3 Tamanho léxico 2.995 Número de resumos 212 Tamanho médio do resumo 23\nO corpus é composto por 1.513 conversas (cerca de 70 horas de conversação). 1.000 conversas foram distribuídas sem sinopses para a formação do sistema sem supervisão e 50 outras foram distribuídas com várias sinopses para formar até cinco anotadores. O conjunto de testes consiste de 47 conversas traduzidas manualmente e\n12Corpus RPM: http://lia.univ-avignon.fr/fileadmin/documents/rpm2/rpm2_resumes_fr.html"
    }, {
      "heading" : "6.2 Métodos de avaliação 62",
      "text" : "suas correspondentes sinopses, e 53 conversas traduzidas automaticamente assim como suas correspondentes sinopses [Gillick e Favre 2009]."
    }, {
      "heading" : "6.2 Métodos de avaliação",
      "text" : "Os capítulos anteriores descreveram diferentes metodologias para criar resumos, seja por resumidores profissionais ou por algum tipo de sumarizador automático. No entanto, é fundamental analisar a qualidade desses resumos. As subseções seguintes descrevem as principais métricas e sistemas encontrados na literatura para avaliar a informatividade dos resumos produzidos."
    }, {
      "heading" : "6.2.1 Métricas",
      "text" : "Uma forma de verificar a qualidade do resumo é viabilizada através da análise de 3 métricas (precisão, cobertura e medida-f), que representam a informatividade do resumo criado. Essas métricas possibilitam identificar o conteúdo do resumo e verificar se o assunto do mesmo refere-se ao conteúdo geral do texto original ou se ele aborda somente alguns dados aleatórios.\nA avaliação manual considera diferentes características no texto para a compreensão e para a avaliação do resumo como gramaticalidade, informatividade e coerência. A gramaticalidade é a qualidade gramatical de um texto, ou seja, ela identifica se uma frase esta construída corretamente. A informatividade representa a porcentagem das informações principais transmitidas no texto. A coerência é a ligação ou conexão entre os fatos e/ou as ideias de uma história. Entretanto, algumas dessas avaliações dependem do conhecimento e da opinião, entre outros fatores, dos resumidores profissionais. Por isso, a avaliação de resumos pode variar entre diferentes profissionais. Geralmente pode-se obtê-la através da análise fornecida por diferentes avaliadores, o que requer tempo e dinheiro. O avaliador lê o texto e seleciona suas principais informações. Após a leitura dos resumos fornecidos, ele verifica se o texto é coerente e conciso com relação ao tema discutido no texto original. Outro ponto analisado é a informatividade do texto.\nOutra forma de avaliação possível feita pelos avaliadores consiste na criação de seus próprios resumos e comparação com os resumos candidatos (produzidos automaticamente). Geralmente, utiliza-se as métricas precisão e cobertura para avaliar a qualidade dos resumos assim produzidos. A primeira calcula a fração de sentenças do resumo que são relevantes para o texto. A cobertura avalia a fração de sentenças relevantes"
    }, {
      "heading" : "6.2 Métodos de avaliação 63",
      "text" : "do texto que estão presentes no resumo. Uma forma de unir essas duas métricas é dada pela medida-f (equação 6.1).\nmedida-f = 2× precisão× cobertura\nprecisão+ cobertura (6.1)"
    }, {
      "heading" : "6.2.2 ROUGE",
      "text" : "O sistema ROUGE é um avaliador automático de resumos desenvolvido por [Lin 2004] baseado no sistema BLUE [Papineni et al. 2002]. O ROUGE utiliza resumos de profissionais como referência para avaliar os demais resumos. Ele faz uso de diferentes métricas para determinar a similaridade entre os resumos dos profissionais e os resumos candidatos. Serão consideradas apenas as métricas ROUGE-N e ROUGE-SU nesta dissertação. A ROUGE-N avalia a co-ocorrência de n-gramas. Em outras palavras, ela é a recuperação de n-gramas entre um sumário candidato e um conjunto de resumos de referências (SumRef). Ela é calculada através da equação 6.2.\nROUGE-N =\n∑ S∈SumRef ∑ n-gramas∈S Countmatch(n-gramas)∑\nS∈SumRef\n∑ n-gramas∈S Count(n-gramas)\n(6.2)\nA ROUGE-N será utilizada para avaliar unigramas (ROUGE-1) e bigramas (ROUGE-2). A ROUGE-SU é uma extensão da ROUGE-S, que avalia também quaisquer pares de palavras na ordem das sentenças entre os resumos (skip-bigrama ou skip2). Dessa forma, a ROUGE-S calcula a precisão (Pr), a cobertura (Cb) e a medida-f , conforme as equações 6.3, 6.4 e 6.5, respectivamente.\nPrskip2 = SKIP2(P,Q)\nComb(m, 2) (6.3)\nCbskip2 = SKIP2(P,Q)\nComb(n, 2) (6.4)\nFskip2 = (1 + β2)× Cbskip2 × Prskip2\nCbskip2 + β2 × Prskip2 (6.5)\nSKIP2(P,Q) é a quantidade de skip-gramas iguais entre P e Q, β controla a relevância do Pskip2 e Rskip2, e Comb é a função de combinações possíveis.\nEntretanto, a ROUGE-S não valoriza as sentenças dos resumos em que não há uma"
    }, {
      "heading" : "6.2 Métodos de avaliação 64",
      "text" : "co-ocorrência das palavras do resumo candidato com relação aos sumários de referência. Nesse caso, a ROUGE-SU adiciona a contagem de unigramas permitindo às palavras isoladas uma certa relevância no processo de avaliação."
    }, {
      "heading" : "6.2.3 FRESA",
      "text" : "Nem sempre tem-se recursos financeiros e tempo para a obtenção de resumos de referência para os textos considerados. Nesse caso, o sistema FRESA apresenta-se como uma boa opção. FRESA é um avaliador de resumos que analisa a qualidade dos mesmos sem necessitar de resumos de referência [Torres-Moreno et al. 2010]. Ele avalia a qualidade do texto a partir das distribuições de probabilidades P e Q, que representam a distribuição do resumo Res e o documento Doc, respectivamente. Ele calcula a DJS para unigramas, bigramas, bigramas-SU4 e suas combinações para P e Q (equação 3.10). O FRESA utiliza as atribuições explicitas na equação 6.6, onde FDocw é a frequência da palavra w no documento, FResw é a frequência da palavra w no resumo, NP é o número de palavras do resumo e do documento, β é 1, 5× voc, voc é o vocabulário do resumo e do documento e γ é parâmetro de suavização. Dessa forma, o FRESA avalia a precisão, a cobertura e a medida-f para cada resumo de acordo com o texto original.\nPw = FDocw |Doc| ;Qw =\n{ FResw |Res|\n, se w ∈ Res FDocw +γ NP+γ×β , caso contrário\n} (6.6)\n65\nCAPÍTULO 7\nAVALIAÇÃO EXPERIMENTAL\nOs testes foram realizados em um computador com processador i5@2.6 GHz e 4 GB de memória RAM no sistema operacional GNU/Linux Ubuntu 15.04 64-bits. Os algoritmos que compõem os sistemas LIA-RAG, RAG, SASI e SUMMatrix foram implementados na linguagem de programação Perl. Foram desenvolvidos igualmente dois sistemas baselines (resumos produzidos aleatoriamente, base-rand, e contendo as primeiras sentenças, base-first, dos textos) para auxiliar na avaliação dos sistemas. As seções a seguir descrevem os resultados obtidos dos sistemas propostos nesta dissertação para cada corpus analisado, sendo que alguns sistemas foram testados com um corpus específico tendo em vista as particularidades do problema considerado (áudio ou texto, mono ou multi-documento, etc)."
    }, {
      "heading" : "7.1 Avaliação do sistema SASI (Corpus multi-idioma)",
      "text" : "O corpus multi-idioma foi utilizado para avaliar o desempenho do sistema SASI. Foram considerados na comparação dos resultados os valores fornecidos pelos sistemas sumarizadores Cortex, Enertex e REG. O REG modela o documento como um grafo e atribui uma ponderação às arestas para gerar o resumo do texto [Torres-Moreno e Ramírez 2010].\nAs similaridades foram analisadas entre: duas frases (DFrase); uma frase e o título (DT itulo); e uma frase e o documento (DTexto). A tabela 7.1 descreve o nível de similaridade relacionado ao valor da divergência JS e aos valores selecionados (parametrização) nos experimentos aqui descritos. Analisou-se o γ variando entre 0, 01 e 0, 20 e, a partir dos resultados obtidos, selecionou-se γ = 0, 1."
    }, {
      "heading" : "7.1 Avaliação do sistema SASI (Corpus multi-idioma) 66",
      "text" : "Tabela 7.1 – Nível de similaridade relacionado à divergência JS\nParâmetros Nível de similaridade\nFraca Média Forte Selecionado DFrase JS > 0, 75 0, 25 < JS < 0, 75 JS < 0, 25 0,32 DT itulo JS > 0, 8 0, 4 < JS < 0, 8 JS < 0, 4 0,6 DTexto JS > 0, 95 0, 65 < JS < 0, 95 JS < 0, 65 0,9\nA tabela 7.2 mostra 4 textos13 extraídos do corpus multi-idioma e os resumos produzidos pelo SASI, ressaltando a quantidade de frases presentes nos resumos construídos automaticamente para textos de diferentes tamanhos e valores do parâmetro DFrase. Pode-se observar, a partir dos dados dessa tabela, que quanto maior o valor da DJS entre frases menor será o resumo (número de frases) fornecido pelo sistema. Portanto, esse valor dependerá do tamanho do resumo que se deseja obter. Deve-se considerar que quanto menor o resumo mais informações serão omitidas e a informatividade poderá ser reduzida.\nTabela 7.2 – Tamanho dos resumos obtidos para um conjunto de valores da DJS .\nTextos\nQuantidade de Frases\nTexto Original (frases) Resumos\nValor da DFrase 0,30 0,32 0,33 0,35 0,40\nMars 12 6 4 4 4 2 Puces 31 14 9 8 5 3 Lewinsky 32 13 7 7 5 3 Quebec 45 18 15 14 12 6\nO gráfico 7.1 descreve o desempenho obtido em segundos pelo sistema SASI na produção de resumos a partir dos textos da tabela 7.2, com a quantidade de palavras variando entre 11 e 214. Os sistemas obtiveram os seguintes tempos de execução total para o corpus analisado: Cortex, 58,27 segundos; Enertex, 56,80 segundos; REG, 55,70 segundos; e SASI, 38,78 segundos.\nAnalisou-se, ainda, a qualidade dos resumos através da informatividade (tabela 7.3) calculada através da taxa de acerto das frases fornecidas pelos sistemas sumarizadores em relação aos resumos dos profissionais. O SASI obteve o melhor resultado ao resumir o texto Quebec e um desempenho semelhante aos outros sistemas com relação ao texto Puces. No caso dos textos Lewinsky e Mars, o SASI teve uma taxa de acerto inferior aos demais sistemas pois os SIV calculados não corresponderam aos SIM dos grafos analisados, o que\n13Textos disponíveis em: http://www.lia.univ-avignon.fr/chercheurs/torres/recherche/cortex e http://en.wikipedia.org/wiki/Quebec_sovereignty_movement;Monica_Lewinsky;Nazca_lines"
    }, {
      "heading" : "7.1 Avaliação do sistema SASI (Corpus multi-idioma) 67",
      "text" : "Gráfico 7.1 – Desempenho do sistema SASI para o corpus multi-idioma.\n0 5 10 15 20 25 30 35 40 45 0\n0.5\n1\n1.5\nQuantidade de frases\nT em\npo (\nse gu\nnd os\n)\nimplica que a ponderação das frases não foi suficientemente significativa para selecionar outros elementos importantes dos textos. Nos demais textos do corpus, os resumos tiveram uma taxa de informatividade semelhante aos resultados obtidos com a sumarização de Puces. Assim, apesar do SASI ter obtido um desempenho inferior em 69% com relação aos textos analisados, a informatividade dos documentos foi preservada, o que é extremamente importante na construção de um resumo de forma automática.\nTabela 7.3 – Análise da precisão dos resumos gerados automaticamente.\nTextos Sistemas SASI Cortex Enertex REG Mars 67% 100% 100% 100% Puces 63% 75% 63% 63%\nLewinsky 43% 57% 57% 57% Quebec 73% 55% 46% 55%\nO SASI é uma ferramenta que tem por base uma heurística simples e que se apoia em cálculos estatísticos menos complexos do que outros sistemas utilizados no domínio do PLN no âmbito da sumarização automática de documentos. A integração de novas regras sintáticas e semânticas para pré-tratamento dos textos proverá melhorias no desempenho do SASI. Além disso, com base nos testes realizados, o desenvolvimento de um método mais refinado para cálculo do SIV que assegure resultados mais próximos de um SIM priorizando sempre um dos vértices de maior grau em cada grupo, impactará de maneira positiva na qualidade dos sumários produzidos, visto que será escolhido um numero maior de “frases importantes” do texto e com conteúdo distinto, o que evitará que frases relevantes sejam descartadas no processo."
    }, {
      "heading" : "7.2 Avaliação do sistema SUMMatrix (Corpus CSTNews) 68",
      "text" : ""
    }, {
      "heading" : "7.2 Avaliação do sistema SUMMatrix (Corpus CSTNews)",
      "text" : "Os resumos dos profissionais produzidos para os textos do corpus CSTNews foram usados como referência para avaliar a qualidade dos sistemas Artex, Cortex, Enertex, GistSumm, LexRank, SUMMatrix e base-rand.\nOs sistemas avaliadores FRESA e ROUGE foram utilizados para analisar a qualidade dos resumos produzidos automaticamente. Os resumos produzidos foram de qualidade média e permitiram a compreensão do texto. A tabela 7.4 mostra os resultados dos sistemas com a avaliação do FRESA usando o processo de stemming e uma taxa de compressão de 20%. O sistema Cortex obteve os melhores resultados em todas as características. O SUMMatrix obteve bons resultados e foi melhor que os sistemas baseline (base-rand), GistSumm e LexRank (gráfico 7.2, os melhores sistemas estão posicionados à direita e no topo do gráfico.).\nTabela 7.4 – Experimentos com o CSTNews para resumos sem referências.\nSistemas FRESA-1 FRESA-2 FRESA-4 Artex 0,70258 0,64898 0,64193 baseline 0,66725 0,60514 0,59671 Cortex 0,71277 0,65648 0,64892 Enertex 0,69969 0,64833 0,64121\nGistSumm 0,63873 0,59095 0,58714 LexRank 0,66545 0,60799 0,60106 SUMMatrix 0,68707 0,63087 0,62464\nA tabela 7.5 mostra a avaliação do sistema ROUGE usando as mesmas características usadas na avaliação FRESA. Nessa avaliação, o SUMMatrix obteve os melhores resultados para todos os parâmetros do ROUGE. O gráfico 7.3 mostra a qualidade dos resumos descritos na tabela 7.5, baseado nas métricas ROUGE-2 e ROUGE-SU. Nesse caso, SUMMatrix foi o melhor sistema seguido por GistSumm e LexRank. Os sistemas Artex, Cortex e Enertex tiveram desempenho similares.\nTabela 7.5 – Experimentos com o CSTNews usando resumos de profissionais.\nSistemas ROUGE-1 ROUGE-2 ROUGE-SU Artex 0,43871 0,23515 0,16102 base-rand 0,42877 0,17859 0,15773 Cortex 0,44270 0,23586 0,16279 Enertex 0,43688 0,23853 0,16099\nGistSumm 0,44629 0,22395 0,19043 LexRank 0,46765 0,21586 0,18396 SUMMatrix 0,47749 0,25011 0,19141"
    }, {
      "heading" : "7.2 Avaliação do sistema SUMMatrix (Corpus CSTNews) 69",
      "text" : "Gráfico 7.2 – Avaliação FRESA dos sistemas usando CSTNews.\nO tempo de execução do SUMMatrix foi maior que o dos outros sistemas (tabela 7.6). Entretanto, ele obteve um excelente resultado quando avaliado com o ROUGE (teste mais relevante pois utiliza os resumos de referência) e bons resultados com o FRESA.\nGráfico 7.3 – Avaliação ROUGE dos sistemas usando CSTNews.\nForam realizados, ainda, os mesmos testes com uma taxa de compressão de 30%.\nNesse cenário, os resultados obtidos foram similares para o FRESA e para o ROUGE."
    }, {
      "heading" : "7.3 Avaliação do sistema RAG (Corpus RPM) 70",
      "text" : "Tabela 7.6 – Tempo de execução dos sistemas usando o corpus CSTNews.\nArtex base-rand Cortex Enertex\n11,7s 10,5s 13,1s 12,4s GistSumm LexRank SUMMatrix\n50,765s 25,0s 242,4s"
    }, {
      "heading" : "7.3 Avaliação do sistema RAG (Corpus RPM)",
      "text" : "O sistema RAG foi utilizado para avaliar todos os clusters do corpus RPM e produzir automaticamente resumos com as principais informações do grupo analisado. Para esse corpus, analisou-se os resultados (resumos) produzidos pelos sistemas Artex, Cortex, Enertex, LexRank, RAG, base-first e base-rand.\nPara avaliar a qualidade dos resumos, fez-se uso do sistema ROUGE (seção 6.2.2). A tabela 7.5 mostra os resultados dos sistemas com a avaliação ROUGE em que os resumos são compostos por 100 palavras para um cluster (tabela 7.7) e para dois clusters (tabela 7.8) de cada temática. Considerando os dois casos, o sistema Enertex obteve os melhores resultados para os parâmetros ROUGE-2 e ROUGE-SU. O sistema RAG obteve bons resultados e foi melhor que os sistemas Artex, base-first, base-rand, Cortex e LexRank.\nTabela 7.7 – Avaliação ROUGE dos sistemas utilizando um único cluster do RPM.\nSistemas ROUGE-1 ROUGE-2 ROUGE-SU Artex 0,36406 0,10953 0,13532 base-first 0,33915 0,08126 0,11443 base-rand 0,31885 0,05697 0,09917 Cortex 0,36810 0,10605 0,13407 Enertex 0,37697 0,12057 0,14778 LexRank 0,38965 0,12201 0,14424 RAG 0,37852 0,11795 0,14490\nO gráfico 7.4 sumariza os dados com relação à qualidade de cada resumo baseado nas métricas ROUGE-2 e ROUGE-SU com relação aos resultados obtidos utilizando os dois clusters do corpus RPM."
    }, {
      "heading" : "7.4 Avaliação dos sistemas LIA-RAG e RAG (Corpus DECODA)",
      "text" : "“Multiling é uma iniciativa dirigida para sistemas de sumarização multi-lingue\nbenchmarking, para incentivar a pesquisa e alavancar o estado da arte na área”14. A iniciativa MultiLing 2015 possuiu as seguintes tarefas: Multilingual\n14http://multiling.iit.demokritos.gr/pages/view/1517/multiling-2015-call-for-participation"
    }, {
      "heading" : "7.4 Avaliação dos sistemas LIA-RAG e RAG (Corpus DECODA) 71",
      "text" : "Tabela 7.8 – Avaliação ROUGE dos sistemas utilizando dois clusters do RPM.\nSistemas ROUGE-1 ROUGE-2 ROUGE-SU Artex 0,36205 0,10420 0,13280 base-first 0,33805 0,08098 0,11592 base-rand 0,32138 0,06353 0,10082 Cortex 0,36432 0,10342 0,13279 Enertex 0,36867 0,11255 0,14112 LexRank 0,37139 0,11107 0,13654 RAG 0,36607 0,11119 0,13864\nMulti-document Summarization, Multilingual Single-document Summarization, Online Forum Summarization e Call Centre Conversation Summarization (CCCS). A tarefa piloto CCCS consiste em “criar sistemas que analisem conversas de call centers e gerem\nresumos textuais refletindo o motivo do cliente estar ligando, como o agente responde às\nquestões, os passos para solucionar os problemas e o estado de resolução do problema\" [Gillick e Favre 2009].\nGráfico 7.4 – Avaliação ROUGE dos sistemas usando o corpus RPM.\nFoi utilizado o corpus Francês DECODA [Bechet et al. 2012]. Os sistemas devem produzir resumos com a ideia principal das conversas. “Os tópicos das conversas variam entre itinerário e pedidos de horários, perdidos e achados e reclamações ” [Gillick e Favre 2009]. Cada resumo tem 7% do número de palavras de cada conversa transcrita. Comparou-se os sistemas LIA-RAG e RAG com os sistemas base-first, base-rand e os demais sistemas da competição (NTNU:1, NTNU:2 e NTNU:3)."
    }, {
      "heading" : "7.5 Análise geral 72",
      "text" : "O Multiling CCCS utilizou o sistema ROUGE15 para avaliar a qualidade dos sistemas. A tabela 7.9 exibe os resultados obtidos usando os sistemas citados anteriormente e o corpus de treinamento16. Ambas as versões do RAG foram melhores que os demais sistemas da competição. O pós-processamento do LIA-RAG permitiu melhorar os resultados do RAG por meio da redução dos erros e produzir um resumo mais informativo e conciso.\nTabela 7.9 – Avaliação dos sistemas usando o corpus de treinamento DECODA.\nSistemas ROUGE-1 ROUGE-2 ROUGE-4 LIA-RAG:1 0,1893 0,0628 0,0683\nRAG 0,1833 0,0614 0,0654 base-first 0,1578 0,0556 0,0583 base-rand 0,1170 0,0310 0,0371\nO corpus Francês de teste tem 100 conversas transcritas com 42.130 palavras e 212 resumos. A performance oficial ROUGE-2 para os sistemas participantes do CCCS é exibida na tabela 7.10 [Gillick e Favre 2009]. O sistema LIA-RAG obteve os melhores resultados.\nTabela 7.10 – Avaliação dos sistemas usando o corpus de teste DECODA.\nSistemas ROUGE-2 LIA-RAG:1 0,037\nNTNU:1 0,035 NTNU:3 0,034 NTNU:2 0,027"
    }, {
      "heading" : "7.5 Análise geral",
      "text" : "Os 4 sistemas (LIA-RAG, RAG, SASI e SUMMatrix) desenvolvidos nesta dissertação possuem diferentes abordagens e são mais indicados para certos tipos de corpus e aplicações. Cada corpus possui características específicas e, portanto, a metodologia de um sistema pode ser melhor que a de um outro para um dado corpus.\nO corpus multi-idioma é muito variável pois aborda diferentes temas em diversos idiomas. Essa característica dificulta a identificação da relevância das sentenças. Os sistemas Cortex, Enertex e REG tiveram um desempenho melhor para os documentos de pequeno tamanho. Entretanto, o SASI obteve os melhores resultados à medida em que\n15Os parâmetros de execução: ROUGE 1.5.5 -a -l 10000 -n 4 -x -2 4 -u -c 95 -r 1000 -f A -p 0.5 -t 0 16O corpus de treinamento é utilizado para configurar e testar o sistema para as características\nespecíficas do corpus de avaliação."
    }, {
      "heading" : "7.5 Análise geral 73",
      "text" : "o tamanho dos documentos a serem resumidos aumentou. Portanto, o SASI conseguiu mensurar com eficiência e eficácia a relevância das sentenças em documentos de diferentes temáticas.\nO corpus CSTNews é composto por grupos de notícias jornalísticas similares sobre um mesmo acontecimento. Textos jornalísticos normalmente possuem as principais informações descritas nas primeiras sentenças e, frequentemente, as principais informações estão presentes em todas notícias. A característica do SUMMatrix de identificar e priorizar as informações que estão presentes na maioria dos documentos permite produzir resumos com as informações de destaque das notícias. O SUMMatrix não obteve os melhores resultados na avaliação FRESA. Entretanto, essa avaliação analisa o resumo com relação ao texto integral de uma notícia, que não é o mais importante para textos jornalísticos pois os mesmos podem conter informações irrelevantes ou desnecessárias sobre um acontecimento. A análise de textos jornalísticos foca-se na produção de resumos com os dados mais relevantes. Assim, o sumário não precisa ser o melhor na análise do FRESA, mas deve ser o melhor na análise do sistema ROUGE, que compara o resumo candidato com os produzidos por humanos. Nesse cenário, o SUMMatrix obteve os melhores resultados no sistema ROUGE para o corpus CSTNews.\nO corpus RPM é dividido em dois clusters por temática. Os textos de cada cluster foram selecionados em diferentes períodos podendo envolver diferentes acontecimentos. O sistema RAG baseia-se na análise das palavras e na quantidade de sentenças similares entre si para avaliar a relevância das mesmas no texto. Apesar das sentenças poderem referenciar acontecimentos diferentes, a temática das sentenças pode ser similar e juntamente com a análise das palavras, é possível identificar a importância das sentenças com relação ao cluster. Baseando-se nessa metodologia, o sistema RAG obteve o segundo melhor desempenho na maioria das métricas quando avaliado pelos sistemas FRESA e ROUGE.\nO corpus DECODA trata de conversas sobre um assunto específico em centrais de atendimento ao cliente. Os textos contém a narração do problema ocorrido e uma possível solução proposta (se foi disponibilizada durante a conversa). As expressões vocais e outros erros de conversas transcritas (por exemplo, “bah”, “hein”, “ah”, expressões sem relevância para o texto, abreviações erradas, falhas no reconhecimento de algumas palavras, entre outros erros) ocupam espaço no resumo e não possuem importância. Essas expressões reduzem a informatividade e seu tratamento propicia uma melhoria da qualidade dos resumos produzidos. Por isso, o sistema LIA-RAG gerou sumários legíveis e com as informações mais pertinentes do texto. Os resultados do LIA-RAG foram melhores que"
    }, {
      "heading" : "7.5 Análise geral 74",
      "text" : "os resultados dos sistemas NTNU da competição Multiling CCCS.\n75\nCAPÍTULO 8\nCONCLUSÃO E TRABALHOS FUTUROS\nO Processamento da Linguagem Natural (PLN) se tornou fundamental para a sociedade devido à quantidade de informações presentes no cotidiano. Atualmente, há um grande investimento em todas os campos de estudo do PLN, com destaque para a área de Sumarização Automática de Textos (SAT). Empresas como a Google estão investindo nesse domínio e nas facilidades obtidas com sua utilização.\nOs sistemas desenvolvidos neste trabalho (LIA-RAG, RAG, SASI e SUMMatrix) conseguiram produzir resumos compreensíveis com as principais sentenças dos documentos originais e em diferentes idiomas. Com relação aos demais sistemas sumarizadores referenciados na literatura, os sistemas desenvolvidos tiveram excelente desempenho, posicionando-se entre os melhores (que fornecem resumos mais informativos).\nMesmo produzindo resumos com boa informatividade, os resumos por extração são compostos por sentenças isoladas e nem sempre é possível obter uma construção sintática e semântica coerente entre as sentenças. Os resumos por abstração possuem uma melhor estrutura sintática e semântica, mas sua dificuldade reside em construir resumos para um cenário multi-idioma."
    }, {
      "heading" : "8.1 Trabalhos futuros",
      "text" : "Os próximos trabalhos visam desenvolver um sumarizador cross-lingue envolvendo os idiomas Espanhol, Francês, Inglês e Português em contexto multicultural. A relevância multicultural é fundamental para analisar documentos de diferentes regiões, pois palavras similares podem apresentar diferentes significados em regiões distintas. Assim, pretende-se"
    }, {
      "heading" : "8.1 Trabalhos futuros 76",
      "text" : "analisar o idioma do utilizador do sistema de forma a produzir automaticamente um resumo adaptado à sua língua e cultura.\nCogita-se a utilização da representação Word Embedding17 para analisar e representar um Big Data18 de documentos a fim de mensurar a relevância das sentenças e seu significado em diferentes idiomas. Serão utilizados, igualmente, técnicas de sumarização por abstração no idioma do utilizador do sistema. As sentenças serão produzidas por meio dos processos de compressão e fusão multi-frases objetivando-se uma melhora na sua concisão e informatividade. Concomitante a essas técnicas, pretende-se desenvolver alguns métodos heurísticos/meta-heurísticos e híbridos buscando maximizar a informatividade e a legibilidade do resumo.\n17Word Embedding é o conjunto de modelagens de um idioma e suas técnicas de aprendizagem em PLN, em que as palavras e as frases são mapeadas para vetores reais em um espaço contínuo de baixa dimensionalidade.\n18Big Data é um conjunto de dados muito grande e/ou complexo.\n77\nREFERÊNCIAS BIBLIOGRÁFICAS\nARCHANA AB; SUNITHA C. An overview of document summarization techniques. International Journal on Advanced Computer Theory and Engineering, p. 113–118, 2013.\nBARALIS, E.; CAGLIERO, L.; MAHOTO, N. A.; FIORI, A. Graphsum: Discovering correlations among multiple terms for graph-based summarization. Inf. Sci., v. 249, p. 96–109, 2013.\nBARZILAY, R.; MCKEOWN, K. R. Sentence fusion for multidocument news summarization. Comput. Linguist., MIT Press, v. 31, n. 3, p. 297–328, 2005.\nBARZILAY, R.; MCKEOWN, K. R.; ELHADAD, M. Information fusion in the context of multi-document summarization. In: Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics. [S.l.]: Association for Computational Linguistics, 1999. (ACL ’99), p. 550–557.\nBECHET, F.; MAZA, B.; BIGOUROUX, N.; BAZILLON, T.; EL-BEZE, M.; MORI, R. D.; ARBILLOT, E. Decoda: a call-centre human-human spoken conversation corpus. In: CHAIR), N. C. C.; CHOUKRI, K.; DECLERCK, T.; DOğAN, M. U.; MAEGAARD, B.; MARIANI, J.; MORENO, A.; ODIJK, J.; PIPERIDIS, S. (Ed.). Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12). Istanbul, Turkey: European Language Resources Association (ELRA), 2012. ISBN 978-2-9517408-7-7.\nBOUDIN, F.; TORRES-MORENO, J.-M. Neo-cortex: A performant user-oriented multi-document summarization system. In: GELBUKH, A. (Ed.). Computational Linguistics and Intelligent Text Processing. [S.l.]: Springer Berlin Heidelberg, 2007, (Lecture Notes in Computer Science, v. 4394). p. 551–562. ISBN 978-3-540-70938-1.\nBUTENKO, S. Maximum Independent Set and Related Problems, with Applications. Tese (Doutorado), Gainesville, FL, USA, 2003. AAI3120100.\nDIAS, M. S.; GARAY, A. Y. B.; CHUMAN, C.; BARROS, C. D. de; MAZIERO, E. G.; NOBREGA, F. A. A.; SOUZA, J. W. d. C.; CABEZUDO, M. A. S.; DELEGE, M.; JORGE, M. L. D. R. C.; SILVA, N. L.; CARDOSO, P. C. F.; FILHO, P. P. B.; CONDORI, R. E. L.; FELIPPO, A. D.; NUNES, M. d. G. V.; PARDO, T. A. S. Enriquecendo o córpus cstnews - a criação de novos sumários multidocumento. In: Proceedings of the I\nREFERÊNCIAS BIBLIOGRÁFICAS 78\nWorkshop on Tools and Resources for Automatically Processing Portuguese and Spanish - ToRPorEsp. São Carlos-SP, Brazil: [s.n.], 2014. p. 1–8.\nDICE, L. R. Measures of the amount of ecologic association between species. Ecology, v. 26, n. 3, p. 297–302, 1945.\nDYER, M. G. Connectionist natural language processing: A status report. In: SUN, R.; BOOKMAN, L. (Ed.). Computational Architectures Integrating Neural And Symbolic Processes. [S.l.]: Springer US, 1995, (The Springer International Series In Engineering and Computer Science, v. 292). p. 389–429. ISBN 978-0-7923-9517-1.\nEDMUNDSON, H. P. New methods in automatic extracting. Journal of the ACM (JACM), p. 264–285, 1969.\nERKAN, G.; RADEV, D. R. Lexrank: Graph-based lexical centrality as salience in text summarization. J. Artif. Int. Res., AI Access Foundation, USA, v. 22, n. 1, p. 457–479, dez. 2004. ISSN 1076-9757. Disponível em: <http://dl.acm.org/citation.cfm?id=1622487.1622501>.\nFERNÁNDEZ, S.; SANJUAN, E.; TORRES-MORENO, J.-M. Textual energy of associative memories: Performant applications of enertex algorithm in text summarization and topic segmentation. In: GELBUKH, A.; MORALES, A. K. (Ed.). MICAI 2007: Advances in Artificial Intelligence. [S.l.]: Springer Berlin Heidelberg, 2007, (Lecture Notes in Computer Science, v. 4827). p. 861–871. ISBN 978-3-540-76630-8.\nFERNÁNDEZ, S.; SANJUAN, E.; TORRES-MORENO, J. M. Enertex: un système basé sur l’énergie textuelle. Traitement Automatique des Langues Naturelles, p. 99–108, 2008.\nFERREIRA, R.; CABRAL, L. de S.; FREITAS, F. L. G. de; LINS, R. D.; SILVA, G. de Franca Pereira e; SIMSKE, S. J.; FAVARO, L. A multi-document summarization system based on statistics and linguistic treatment. Expert Syst. Appl., v. 41, n. 13, p. 5780–5787, 2014. Disponível em: <http://dx.doi.org/10.1016/j.eswa.2014.03.023>.\nFILIPPOVA, K. Multi-sentence compression: Finding shortest paths in word graphs. In: Proceedings of the 23rd International Conference on Computational Linguistics. Stroudsburg, PA, USA: Association for Computational Linguistics, 2010. (COLING’10), p. 322–330. Disponível em: <http://dl.acm.org/citation.cfm?id=1873781.1873818>.\nGALANIS, D.; LAMPOURAS, G.; ANDROUTSOPOULOS, I. Extractive multi-document summarization with integer linear programming and support vector regression. In: COLING 2012. [S.l.: s.n.], 2012.\nGAREY, M. R.; JOHNSON, D. S. Computers and Intractability; A Guide to the Theory of NP-Completeness. New York, NY, USA: W. H. Freeman & Co., 1990.\nGILLICK, D.; FAVRE, B. A scalable global model for summarization. In: NAACL/HLT 2009 Workshop on Integer Linear Programming for Natural Language Processing. [S.l.: s.n.], 2009.\nGONG, Y.; LIU, X. Generic text summarization using relevance measure and latent semantic analysis. In: Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. New York, NY,\nREFERÊNCIAS BIBLIOGRÁFICAS 79\nUSA: ACM, 2001. (SIGIR ’01), p. 19–25. ISBN 1-58113-331-6. Disponível em: <http://doi.acm.org/10.1145/383952.383955>.\nHAGHIGHI, A.; VANDERWENDE, L. Exploring content models for multi-document summarization. In: Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Stroudsburg, PA, USA: Association for Computational Linguistics, 2009. (NAACL ’09), p. 362–370. ISBN 978-1-932432-41-1. Disponível em: <http://dl.acm.org/citation.cfm?id=1620754.1620807>.\nHE, T.; LI, F.; SHAO, W.; CHEN, J.; MA, L. A new feature-fusion sentence selecting strategy for query-focused multi-document summarization. In: Advanced Language Processing and Web Information Technology, 2008. ALPIT ’08. International Conference on. [S.l.: s.n.], 2008. p. 81–86.\nHENNIG, L.; ALBAYRAK, S. Personalized multi-document summarization using n-gram topic model fusion. In: Proceedings of LREC’10, 1st Workshop on Semantic Personalized Information Management (SPIM 2010). Valletta, Malta: European Language Resources Association (ELRA), 2010. p. 28–34. ISBN 2-9517408-6-7. Disponível em: <http://www.lrec-conf.org/proceedings/lrec2010/workshops/W7.pdf>.\nHIEMSTRA, D. Probability smoothing. In: Encyclopedia of Database Systems, pp. 2169-2170, Springer. [S.l.: s.n.], 2009.\nHOVY, E.; LIN, C.-Y. Automated text summarization and the summarist system. In: Proceedings of a Workshop on Held at Baltimore, Maryland: October 13-15, 1998. Stroudsburg, PA, USA: Association for Computational Linguistics, 1998. (TIPSTER ’98), p. 197–214. Disponível em: <http://dx.doi.org/10.3115/1119089.1119121>.\nINOUYE, D.; KALITA, J. Comparing twitter summarization algorithms for multiple post summaries. In: Privacy, Security, Risk and Trust (PASSAT) and 2011 IEEE Third Inernational Conference on Social Computing (SocialCom), 2011 IEEE Third International Conference on. [S.l.: s.n.], 2011. p. 298–306.\nJORGE, C.; PARDO, M. L. del R.; SALGUEIRO, T. A. Experiments with cst-based multidocument summarization. In: Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing. Stroudsburg, PA, USA: Association for Computational Linguistics, 2010. p. 74–82.\nKRAUSE, A.; MCMAHAN, B.; GUESTRIN, C.; GUPTA, A. Robust submodular observation selection. Journal of Machine Learning Research (JMLR), v. 9, p. 2761–2801, December 2008.\nLANDAUER, T.; MCNAMARA, D.; DENNIS, S.; KINTSCH, W. Handbook of Latent Semantix Analysis. [S.l.]: NJ & London, 2007.\nLAY, D. C. Linear Algebra and Its Applications. [S.l.]: Pearson, 2011.\nLEE, D. D.; SEUNG, H. S. Learning the parts of objects by non-negative matrix factorization. Nature, Nature Publishing Group, v. 401, n. 6755, p. 788–791, out. 1999. ISSN 0028-0836. Disponível em: <http://dx.doi.org/10.1038/44565>.\nREFERÊNCIAS BIBLIOGRÁFICAS 80\nLIN, C.-Y. Training a selection function for extraction. In: Proceedings of the Eighth International Conference on Information and Knowledge Management. New York, NY, USA: ACM, 1999. (CIKM ’99), p. 55–62. ISBN 1-58113-146-1. Disponível em: <http://doi.acm.org/10.1145/319950.319957>.\nLIN, C. Y. Rouge: A package for automatic evaluation of summaries. In: Proc. ACL workshop on Text Summarization Branches Out. [s.n.], 2004. p. 10. Disponível em: <http://research.microsoft.com/ cyl/download/papers/WAS2004.pdf>.\nLIN, H.; BILMES, J. A class of submodular functions for document summarization. In: IN THE 49TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (ACL-HLT. [S.l.: s.n.], 2011.\nLIN, H.; BILMES, J.; XIE, S. Graph-based Submodular Selection for Extractive Summarization. 2009.\nLUHN, H. P. The automatic creation of literature abstracts. IBM Journal of Research and Development, p. 159, 1958.\nMCDONALD, R. Discriminative sentence compression with soft syntactic constraints. In: In Proc. EACL. [S.l.: s.n.], 2006.\nMCKEOWN, K.; HIRSCHBERG, J.; GALLEY, M.; MASKEY, S. From text to speech summarization. In: ICASSP. 2005. Philadelphia, PA. [S.l.: s.n.], 2005.\nMIHALCEA, R. Graph-based ranking algorithms for sentence extraction, applied to text summarization. ACL 2004 on Interactive poster and demonstration sessions, p. 181–184, 2004.\nMIHALCEA, R.; TARAU, P. TextRank: Bringing Order into Texts. In: Conference on Empirical Methods in Natural Language Processing. Barcelona, Spain: [s.n.], 2004. Disponível em: <http://acl.ldc.upenn.edu/acl2004/emnlp/pdf/Mihalcea.pdf>.\nMURRAY, G.; RENALS, S.; CARLETTA, J. Extractive summarization of meeting recordings. In: in Proceedings of the 9th European Conference on Speech Communication and Technology. [S.l.: s.n.], 2005. p. 593–596.\nPAPINENI, K.; ROUKOS, S.; WARD, T.; ZHU, W.-J. Bleu: A method for automatic evaluation of machine translation. In: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics. Stroudsburg, PA, USA: Association for Computational Linguistics, 2002. (ACL ’02), p. 311–318. Disponível em: <http://dx.doi.org/10.3115/1073083.1073135>.\nPARDO, T. A. S.; RINO, L. H. M.; NUNES, M. das G. V. Gistsumm: A summarization tool based on a new extractive method. In: MAMEDE, N. J.; BAPTISTA, J.; TRANCOSO, I.; NUNES, M. das G. V. (Ed.). PROPOR. [S.l.]: Springer, 2003. (Lecture Notes in Computer Science, v. 2721), p. 210–218.\nPOLLOCK, J. J.; ZAMORA, A. Automatic abstracting research at chemical abstracts service. J. of Chemical Information and C. Sciences, p. 226–232, 1975.\nREFERÊNCIAS BIBLIOGRÁFICAS 81\nPONTES, E. L.; LINHARES, A. C.; TORRES-MORENO, J.-M. Sasi: sumarizador automático de documentos baseado no problema do subconjunto independente de vértices. In: Proceedings of the XLVI Simpósio Brasileiro de Pesquisa Operacional. [S.l.: s.n.], 2014.\nROSSI, F.; SMRIGLIO, S. A branch-and-cut algorithm for the maximum cardinality stable set problem. Operations Research Letters, v. 28, n. 2, p. 63 – 74, 2001. ISSN 0167-6377. Disponível em: <http://www.sciencedirect.com/science/article/pii/S0167637700000602>.\nSAGGION, H.; TORRES-MORENO, J.-M.; CUNHA, I. da; SANJUAN, E. Multilingual summarization evaluation without human models. In: Proceedings of the 23rd International Conference on Computational Linguistics: Posters. Stroudsburg, PA, USA: Association for Computational Linguistics, 2010. (COLING ’10), p. 1059–1067. Disponível em: <http://dl.acm.org/citation.cfm?id=1944566.1944688>.\nSARANYAMOL CS; SINDHU L. A survey on automatic text summarization. International Journal of Computer Science and Information Technologies, v. 5, p. 7889–7893, 2014.\nSENO, E. R. M. Um método para a fusão automática de sentenças similares em português. Tese (Doutorado) — Instituto de Ciências Matemáticas e de Computação, Universidade de São Paulo, São Carlos, 2010.\nSENO, E. R. M.; NUNES, M. das G. V. Some experiments on clustering similar sentences of texts in portuguese. In: Computational Processing of the Portuguese Language, 8th International Conference, PROPOR 2008, Aveiro, Portugal, September 8-10, 2008, Proceedings. [S.l.: s.n.], 2008. p. 133–142.\nSIPOS, R.; SHIVASWAMY, P.; JOACHIMS, T. Large-margin learning of submodular summarization models. In: Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics. Stroudsburg, PA, USA: Association for Computational Linguistics, 2012. (EACL ’12), p. 224–233. ISBN 978-1-937284-19-0. Disponível em: <http://dl.acm.org/citation.cfm?id=2380816.2380846>.\nSOGAARD, A. Semi-supervised learning and domain adaptation in natural language processing. San Rafael: Morgan & Claypool, 2013. ISBN 1-608-45985-3. Disponível em: <http://opac.inria.fr/record=b1134947>.\nTORRES-MORENO, J. Artex is another text summarizer. CoRR, abs/1210.3312, 2012. Disponível em: <http://arxiv.org/abs/1210.3312>.\nTORRES-MORENO, J.-M.; RAMíREZ, J. Reg : un algorithme glouton appliqué au résumé automatique de texte. In: JADT. JADT. [S.l.], 2010.\nTORRES-MORENO, J.-M.; SAGGION, H.; CUNHA, I. da; VELÁZQUEZ-MORALES, P.; SANJUAN, E. Evaluation automatique de résumés avec et sans référence. Traitement Automatique des Langues Naturelles, 2010.\nTORRES-MORENO, J.-M.; SAGGION, H.; CUNHA, I. da; SANJUAN, E.; VELÁZQUEZ-MORALES, P. Summary evaluation with and without references. Polibits, n. 42, p. 13–19, 2010.\nREFERÊNCIAS BIBLIOGRÁFICAS 82\nTORRES-MORENO, J.-M.; VELáZQUEZ-MORALES, P.; MEUNIER, J.-G. Condensés de textes par des méthodes numériques. In: JADT. JADT. [S.l.], 2002. v. 2, p. 723–734.\nVODOLAZOVA, T.; LLORET, E.; MUñOZ, R.; PALOMAR, M. A comparative study of the impact of statistical and semantic features in the framework of extractive text summarization. In: TSD. [S.l.]: Springer, 2012. (Lecture Notes in Computer Science, v. 7499), p. 306–313.\nWOLSEY, L. A. Integer Programming. [S.l.]: Wiley-Interscience, 1998.\nWU, Z. B.; HSU, L. S.; TAN, C. L. A survey on statistical approaches to natural language processing. 1992.\nXU, Y.-D.; ZHANG, X.-D.; QUAN, G.-R.; WANG, Y.-D. Mrs for multi-document summarization by sentence extraction. Telecommunication Systems, Springer US, v. 53, n. 1, p. 91–98, 2013."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2016,
    "abstractText" : "The internet increased the amount of information available. However, the reading and understanding of this information are costly tasks. In this scenario, the Natural Language Processing (NLP) applications enable very important solutions, highlighting the Automatic Text Summarization (ATS), which produce a summary from one or more source texts. Automatically summarizing one or more texts, however, is a complex task because of the difficulties inherent to the analysis and generation of this summary. This master’s thesis describes the main techniques and methodologies (NLP and heuristics) to generate summaries. We have also addressed and proposed some heuristics based on graphs and similarity matrix to measure the relevance of judgments and to generate summaries by extracting sentences. We used the multiple languages (English, French and Spanish), CSTNews (Brazilian Portuguese), RPM (French) and DECODA (French) corpus to evaluate the developped systems. The results obtained were quite interesting.",
    "creator" : "dvips(k) 5.991 Copyright 2011 Radical Eye Software"
  }
}