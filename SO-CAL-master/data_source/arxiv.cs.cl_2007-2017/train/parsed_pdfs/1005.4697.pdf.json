{
  "name" : "1005.4697.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Jeroen Bransen" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n00 5.\n46 97\nv3 [\ncs .C\nL ]\n2 5\nA ug\n2 01"
    }, {
      "heading" : "1 Introduction",
      "text" : "In his 1958 and 1961 papers, Lambek formulated two versions of the Syntactic Calculus : in (Lambek, 1958), types are assigned to strings, which are then combined by an associative operation; in (Lambek, 1961), types are assigned to phrases (bracketed strings), and the composition operation is non-associative. We refer to these two versions as L and NL respectively.\nAs for generative power, Kandulski (1988) proved thatNL defines exactly the context-free languages. Pentus (1993) showed that this also holds for associative L. As for the complexity of the derivability problem, de Groote (1999) showed that for NL this belongs to PTIME; for L, Pentus (2003) proves that the problem is NP-complete and Savateev (2009) shows that NP-completeness also holds for the product-free fragment of L.\nIt is well known that some natural language phenomena require generative capacity beyond context-free. Several extensions of the Syntactic Calculus have been proposed to deal with such phenomena. In this paper we look at the Lambek-Grishin calculus LG (Moortgat, 2007, 2009). LG is a symmetric extension of the nonassociative Lambek calculus NL. In addition to ⊗, \\, / (product, left and right division), LG has dual operations ⊕,;,⊘ (coproduct, left and right difference). These two families are related by linear distributivity principles. Melissen (2009) shows that all languages which are the intersection of a context-free language and the permutation closure of a context-free language are recognizable in LG. This places the lower bound for LG recognition beyond LTAG. The upper bound is still open.\nThe key result of the present paper is a proof that the derivability problem for LG is NP-complete. This will be shown by means of a reduction from SAT.1"
    }, {
      "heading" : "2 Lambek-Grishin calculus",
      "text" : "We define the formula language of LG as follows.\n1 This paper has been written as a result of my Master thesis supervised by Michael Moortgat. I would like to thank him, Rosalie Iemhoff and Arno Bastenhof for comments and I acknowledge that any errors are my own.\nLet V ar be a set of primitive types, we use lowercase letters to refer to an element of V ar. Let formulas be constructed using primitive types and the binary connectives ⊗, /, \\, ⊕, ⊘ and ; as follows:\nA,B ::= p | A⊗B | A/B | B\\A | A⊕B | A⊘B | B ; A\nThe sets of input and output structures are constructed using formulas and the binary structural connectives · ⊗ ·, ·/·, ·\\·, · ⊕ ·, · ⊘ · and · ; · as follows:\n(input) X,Y ::= A | X · ⊗ · Y | X · ⊘ · P | P · ; ·X\n(output) P,Q ::= A | P · ⊕ ·Q | P · / ·X | X · \\ · P\nThe sequents of the calculus are of the form X → P , and as usual we write ⊢LG X → P to indicate that the sequent X → P is derivable in LG. The axioms and inference rules are presented in Figure 1, where we use the display logic from (Goré, 1998), but with different symbols for the structural connectives.\nIt has been proven by Moortgat (2007) that we have Cut admissibility for LG. This means that for every derivation using the Cut -rule, there exists a corresponding derivation that is Cut-free. Therefore we will assume that the Cut-rule is not needed anywhere in a derivation."
    }, {
      "heading" : "3 Preliminaries",
      "text" : ""
    }, {
      "heading" : "3.1 Derivation length",
      "text" : "We will first show that for every derivable sequent there exists a Cut-free derivation that is polynomial in the length of the sequent. The length of a sequent ϕ, denoted as |ϕ|, is defined as the number of (formula and structural) connectives used to construct this sequent. A subscript will be used to indicate that we count only certain connectives, for example |ϕ|⊗.\nLemma 1. If ⊢LG ϕ there exists a derivation with exactly |ϕ| logical rules.\nProof. If ⊢LG ϕ then there exists a Cut-free derivation for ϕ. Because every logical rule removes one logical connective and there are no rules that introduce logical connectives, this derivation contains |ϕ| logical rules. ⊓⊔\nLemma 2. If ⊢LG ϕ there exists a derivation with at most 1 4 |ϕ|2 Grishin interactions.\nProof. Let us take a closer look at the Grishin interaction principles. First of all, it is not hard to see that the interactions are irreversible. Also note that the interactions happen between the families of input connectives {⊗, /, \\} and output connectives {⊕,⊘,;} and that the Grishin interaction principles are the only rules of inference that apply on both families. So, on any pair of one input and one output connective, at most one Grishin interaction principle can be applied.\nIf ⊢LG ϕ there exists a Cut-free derivation of ϕ. The maximum number of possible Grishin interactions in 1 Cut-free derivation is reached when a Grishin interaction is applied on every pair of one input and one output connective. Thus, the maximum number of Grishin interactions in one Cut-free derivation is |ϕ|{⊗,/,\\} · |ϕ|{⊕,⊘,;}.\nBy definition, |ϕ|{⊗,/,\\}+|ϕ|{⊕,⊘,;} = |ϕ|, so the maximum value of |ϕ|{⊗,/,\\}· |ϕ|{⊕,⊘,;} is reached when |ϕ|{⊗,/,\\} = |ϕ|{⊕,⊘,;} = |ϕ| 2 . Then the total number of Grishin interactions in 1 derivation is |ϕ| 2 · |ϕ| 2 = 1 4 |ϕ|2, so any Cut-free derivation of ϕ will contain at most 1 4 |ϕ|2 Grishin interactions. ⊓⊔\nLemma 3. In a derivation of sequent ϕ at most 2|ϕ| display rules are needed to display any of the structural parts.\nProof. A structural part in sequent ϕ is nested under at most |ϕ| structural connectives. For each of these connectives, one or two r or dr rules can display the desired part, after which the next connective is visible. Thus, at most 2|ϕ| display rules are needed to display any of the structural parts.\nLemma 4. If ⊢LG ϕ there exists a Cut-free derivation of length O(|ϕ| 3).\nProof. From Lemma 1 and Lemma 2 we know that there exists a derivation with at most |ϕ| logical rules and 1\n4 |ϕ|2 Grishin interactions. Thus, the derivation\nconsists of |ϕ| + 1 4 |ϕ|2 rules, with between each pair of consecutive rules the display rules. From Lemma 3 we know that at most 2|ϕ| display rules are needed to display any of the structural parts. So, at most 2|ϕ|·(|ϕ|+ 1\n4 |ϕ|2) = 2|ϕ|2+ 1 2 |ϕ|3\nderivation steps are needed in the shortest possible Cut-free derivation for this sequent, and this is in O(|ϕ|3). ⊓⊔"
    }, {
      "heading" : "3.2 Additional notations",
      "text" : "Let us first introduce some additional notations to make the proofs shorter and easier readable.\nLet us call an input structure X which does not contain any structural operators except for ·⊗ · a ⊗-structure. A ⊗-structure can be seen as a binary tree with · ⊗ · in the internal nodes and formulas in the leafs. Formally we define ⊗-structures U and V as:\nU, V ::= A | U · ⊗ · V\nWe define X [] and P [] as the input and output structures X and P with a hole in one of their leafs. Formally:"
    }, {
      "heading" : "X [] ::= [] | X [] · ⊗ · Y | Y · ⊗ ·X [] | X [] · ⊘ ·Q | Y · ⊘ ·P [] | Q ·; ·X [] | P [] ·; ·Y",
      "text" : ""
    }, {
      "heading" : "P [] ::= [] | P [] · ⊕ ·Q | Q · ⊕ · P [] | P [] · / · Y | Q · / ·X [] | Y · \\ · P [] | X [] · \\ ·Q",
      "text" : "This notation is similar to the one of de Groote (1999) but with structures. If X [] is a structure with a hole, we write X [Y ] for X [] with its hole filled with structure Y . We will write X⊗[] for a ⊗-structure with a hole.\nFurthermore, we extend the definition of hole to formulas, and define A[] as a formula A with a hole in it, in a similar manner as for structures. Hence, by A[B] we mean the formula A[] with its hole filled by formula B.\nIn order to distinguish between input and output polarity formulas, we write A• for a formula with input polarity and A◦ for a formula with output polarity. Note that for structures this is already defined by using X and Y for input polarity and P and Q for output polarity. This can be extended to formulas in a similar way, and we will use this notation only in cases where the polarity is not clear from the context."
    }, {
      "heading" : "3.3 Derived rules of inference",
      "text" : "Now we will show and prove some derived rules of inference of LG.\nLemma 5. If ⊢LG A → B and we want to derive X ⊗[A] → P , we can replace A by B in X⊗[]. We have the inference rule below:\nA → B X⊗[B] → P\nX⊗[A] → P Repl\nProof. We consider three cases:\n1. If X⊗[A] = A, it is simply the cut-rule:\nA → B B → P A → P Cut\n2. If X⊗[A] = Y ⊗[A] · ⊗ · V , we can move V to the righthand-side and use induction to prove the sequent:\nA → B\nY ⊗[B] · ⊗ · V → P Y ⊗[B] → P · / · V r\nY ⊗[A] → P · / · V Repl Y ⊗[A] · ⊗ · V → P r\n3. If X⊗[A] = U · ⊗ · Y ⊗[A], we can move U to the righthand-side and use induction to prove the sequent:\nA → B\nU · ⊗ · Y ⊗[B] → P Y ⊗[B] → U · \\ · P r\nY ⊗[A] → U · \\ · P Repl U · ⊗ · Y ⊗[A] → P r\n⊓⊔\nLemma 6. If we want to derive X⊗[A ⊘ B] → P , then we can move the expression ⊘B out of the ⊗-structure. We have the inference rule below:\nX⊗[A] · ⊘ ·B → P\nX⊗[A⊘B] → P Move\nProof. We consider three cases:\n1. If X⊗[A⊘B] = A⊘B, then this is simply the ⊘L-rule:\nA · ⊘ · B → Y A⊘B → Y ⊘L\n2. If X⊗[A⊘B] = Y ⊗[A⊘B] ·⊗ ·V , we can move V to the righthand-side and use induction together with the Grishin interaction principles to prove the sequent:\n(Y ⊗[A] · ⊗ · V ) · ⊘ · B → P\nY ⊗[A] · ⊗ · V → P · ⊕ ·B dr Y ⊗[A] · ⊘ · B → P · / · V d⊘ /\nY ⊗[A⊘B] → P · / · V Move Y ⊗[A⊘B] · ⊗ · V → P r\n3. If X⊗[A⊘B] = U ·⊗ ·Y ⊗[A⊘B], we can move U to the righthand-side and use induction together with the Grishin interaction principles to prove the sequent:\n(U · ⊗ · Y ⊗[A]) · ⊘ · B → P\nU · ⊗ · Y ⊗[A] → P · ⊕ ·B dr Y ⊗[A] · ⊘ · B → U · \\ · P d⊘ \\\nY ⊗[A⊘B] → U · \\ · P Move U · ⊗ · Y ⊗[A⊘B] → P r\n⊓⊔\nLemma 7. ⊢LG A1 ⊗ (A2 ⊗ . . . (An−1 ⊗ An)) → P iff ⊢LG A1 · ⊗ · (A2 · ⊗ · . . . (An−1 · ⊗ · An)) → P\nProof. The if -part can be derived by the application of n− 1 times the ⊗L rule together with the r rule:\nA1 · ⊗ · (A2 · ⊗ · . . . (An−1 · ⊗ · An)) → P\nAn−1 · ⊗ · An → . . . · \\ · (A2 · \\ · (A1 · \\ · P )) r∗\nAn−1 ⊗An → . . . · \\ · (A2 · \\ · (A1 · \\ · P )) ⊗L\n. . . (An−1 ⊗An) → A2 · \\ · (A1 · \\ · P ) . . .\nA2 · ⊗ · . . . (An−1 ⊗An) → A1 · \\ · P r\nA2 ⊗ . . . (An−1 ⊗An) → A1 · \\ · P ⊗L\nA1 · ⊗ · (A2 ⊗ . . . (An−1 ⊗An)) → P r\nA1 ⊗ (A2 ⊗ . . . (An−1 ⊗An)) → P ⊗L\nThe only-if -part can be derived by application of n − 1 times the ⊗R rule followed by a Cut:\nA1 → A1\nA2 → A2\nAn−1 → An−1 An → An An−1 · ⊗ · An → An−1 ⊗An ⊗R\n. . . (An−1 · ⊗ ·An) → . . . (An−1 ⊗An) . . .\nA2 · ⊗ · . . . (An−1 · ⊗ ·An) → A2 ⊗ . . . (An−1 ⊗An) ⊗R\nA1 · ⊗ · (A2 · ⊗ · . . . (An−1 · ⊗ · An)) → A1 ⊗ (A2 ⊗ . . . (An−1 ⊗An)) ⊗R A1 ⊗ (A2 ⊗ . . . (An−1 ⊗An)) → P\nA1 · ⊗ · (A2 · ⊗ · . . . (An−1 · ⊗ · An)) → P Cut\nNote that because of the Cut elimination theorem, there exists a cut-free derivation for this sequent.\n⊓⊔"
    }, {
      "heading" : "3.4 Type similarity",
      "text" : "The type simililarity relation ∼, introduced by Lambek (1958), is the reflexive transitive symmetric closure of the derivability relation. Formally we define this as:\nDefinition 1. A ∼ B iff there exists a sequence C1 . . . Cn(1 ≤ i ≤ n) such that C1 = A, Cn = B and Ci → Ci+1 or Ci+1 → Ci for all 1 ≤ i < n.\nIt was proved by Lambek that A ∼ B iff one of the following equivalent statements holds (the so-called diamond property):\n∃C such that A → C and B → C (join)\n∃D such that D → A and D → B (meet)\nThis diamond property will be used in the reduction from SAT to create a choice for a truthvalue of a variable.\nDefinition 2. If A ∼ B and C is the join type of A and B so that A → C and B → C, we define A C ⊓ B = (A/((C/C)\\C)) ⊗ ((C/C)\\B) as the meet type of"
    }, {
      "heading" : "A and B.",
      "text" : "This is also the solution given by Lambek (1958) for the associative system L, but in fact this is the shortest solution for the non-associative system NL (Foret, 2003).\nLemma 8. If A ∼ B with join-type C and ⊢LG A → P or ⊢LG B → P , then we also have ⊢LG A C ⊓ B → P . We can write this as a derived rule of inference:\nA → P or B → P\nA C ⊓ B → P\nMeet\nProof.\n1. If A → P :\nC → C C → C C/C → C · / · C /L\nC/C → C/C /R B → C\n(C/C)\\B → (C/C) · \\ · C \\L\n(C/C)\\B → (C/C)\\C \\R A → P\nA/((C/C)\\C) → P · / · ((C/C)\\B) /L\n(A/((C/C)\\C)) · ⊗ · ((C/C)\\B) → P r\n(A/((C/C)\\C)) ⊗ ((C/C)\\B) → P ⊗L\n2. If B → P :\nA → C\nC → C C → C C/C → C · / · C /L\n(C/C) · ⊗ · C → C r C → (C/C) · \\ · C r\nC → (C/C)\\C \\R\nA/((C/C)\\C) → C · / · C /L\nA/((C/C)\\C) → C/C /R\nB → P\n(C/C)\\B → (A/((C/C)\\C)) · \\ · P \\L\n(A/((C/C)\\C)) · ⊗ · ((C/C)\\B) → P r\n(A/((C/C)\\C))⊗ ((C/C)\\B) → P ⊗L\n⊓⊔\nThe following lemma is the key lemma of this paper, and its use will become clear to the reader in the construction of Section 4.\nLemma 9. If ⊢LG A C ⊓ B → P then ⊢LG A → P or ⊢LG B → P , if it is not the case that:\n– P = P ′[A′[(A1 ⊗A2) ◦]] – ⊢LG A/((C/C)\\C) → A1 – ⊢LG (C/C)\\B → A2\nProof. We have that ⊢LG (A/((C/C)\\C))⊗ ((C/C)\\B) → P , so from Lemma 7 we know that ⊢LG (A/((C/C)\\C)) · ⊗ · ((C/C)\\B) → P . Remark that this also means that there exists a cut-free derivation for this sequent. By induction on the length of the derivation we will show that if ⊢LG (A/((C/C)\\C)) · ⊗ · ((C/ C)\\B) → P , then ⊢LG A → P or ⊢LG B → P , under the assumption that P is not of the form that is explicitly excluded in this lemma. We will look at the derivations in a top-down way.\nThe induction base is the case where a logical rule is applied on the lefthandside of the sequent. At a certain point in the derivation, possibly when P is an atom, one of the following three rules must be applied:\n1. The ⊗R rule, but then P = A1 ⊗A2 and in order to come to a derivation it must be the case that ⊢LG A/((C/C)\\C) → A1 and ⊢LG (C/C)\\B → A2. However, this is explicitly excluded in this lemma so this can never be the case. 2. The /L rule, in this case first the r rule is applied so that we have ⊢LG A/((C/C)\\C) → P · / · ((C/C)\\B). Now if the /L rule is applied, we must have that ⊢LG A → P . 3. The \\L rule, in this case first the r rule is applied so that we have ⊢LG (C/C)\\B → (A/((C/C)\\C)) · \\ · P . Now if the \\L rule is applied, we must have that ⊢LG B → P .\nThe induction step is the case where a logical rule is applied on the righthandside of the sequent. Let δ = {r, dr, d ⊘ /, d⊘ \\, d ; /, d ; \\} and let δ∗ indicate a (possibly empty) sequence of structural residuation steps and Grishin interactions. For example for the ⊘R rule there are two possibilities:\n– The lefthand-side ends up in the first premisse of the ⊘R rule:\n(A/((C/C)\\C)) · ⊗ · ((C/C)\\B) → P ′′[A′] P ′[(A/((C/C)\\C)) · ⊗ · ((C/C)\\B)] → A′ δ∗ B′ → Q\nP ′[(A/((C/C)\\C)) · ⊗ · ((C/C)\\B)] · ⊘ ·Q → A′ ⊘B′ ⊘R\n(A/((C/C)\\C)) · ⊗ · ((C/C)\\B) → P [A′ ⊘B′] δ∗\nIn order to be able to apply the ⊘R rule, we need to have a formula of the form A′ ⊘ B′ on the righthand-side. In the first step all structural rules are applied to display this formula in the righthand-side, and we assume that in the lefthand-side the meet-type ends up in the first structural part (inside a structure with the remaining parts from P that we call P ′). After the ⊘R rule has been applied, we can again display our meet-type in the lefthandside of the formula by moving all other structural parts from P ′ back to the righthand-side (P ′′). In this case it must be that ⊢LG (A/((C/C)\\C)) · ⊗ · ((C/C)\\B) → P\n′′[A′], and by induction we know that in this case also ⊢LG A → P\n′′[A′] or ⊢LG B → P ′′[A′]. In the case that ⊢LG A → P\n′′[A′], we can show that ⊢LG A → P [A′ ⊘B′] as follows:\nA → P ′′[A′] P ′[A] → A′ δ∗ B′ → Q\nP ′[A] · ⊘ ·Q → A′ ⊘B′ ⊘R\nA → P [A′ ⊘B′] δ∗\nThe case for B is similar. – The lefthand-side ends up in the second premisse of the ⊘R rule:\nQ → A′ (A/((C/C)\\C)) · ⊗ · ((C/C)\\B) → P ′′[B′] B′ → P ′[(A/((C/C)\\C)) · ⊗ · ((C/C)\\B)] δ∗\nQ · ⊘ · P ′[(A/((C/C)\\C)) · ⊗ · ((C/C)\\B)] → A′ ⊘B′ ⊘R\n(A/((C/C)\\C)) · ⊗ · ((C/C)\\B) → P [A′ ⊘B′] δ∗\nThis case is similar to the other case, except that the meet-type ends up in the other premisse. Note that, although in this case it is temporarily moved to the righthand-side, the meet-type will still be in an input polarity position and can therefore be displayed in the lefthand-side again. In this case it must be that ⊢LG (A/((C/C)\\C)) · ⊗ · ((C/C)\\B) → P\n′′[B′], and by induction we know that in this case also ⊢LG A → P\n′′[B′] or ⊢LG B → P ′′[B′]. In the case that ⊢LG A → P\n′′[B′], we can show that ⊢LG A → P [A′ ⊘B′] as follows:\nQ → A′ A → P ′′[B′] B′ → P ′[A] δ∗\nQ · ⊘ · P ′[A] → A′ ⊘B′ ⊘R\nA → P [A′ ⊘B′] δ∗\nThe case for B is similar.\nThe cases for the other logical rules are similar. ⊓⊔"
    }, {
      "heading" : "4 Reduction from SAT to LG",
      "text" : "In this section we will show that we can reduce a Boolean formula in conjunctive normal form to a sequent of the Lambek-Grishin calculus, so that the corresponding LG sequent is provable if and only if the CNF formula is satisfiable. This has already been done for the associative system L by Pentus (2003) with a similar construction.\nLet ϕ = c1 ∧ . . . ∧ cn be a Boolean formula in conjunctive normal form with clauses c1 . . . cn and variables x1 . . . xm. For all 1 ≤ j ≤ m let ¬0xj stand for the literal ¬xj and ¬1xj stand for the literal xj . Now 〈t1, . . . , tm〉 ∈ {0, 1}\nm is a satisfying assignment for ϕ if and only if for every 1 ≤ i ≤ n there exists a 1 ≤ j ≤ m such that the literal ¬tjxj appears in clause ci.\nLet pi (for 1 ≤ i ≤ n) be distinct primitive types from V ar. We now define the following families of types:\nEij(t) ⇌\n{\npi ⊘ (pi ; pi) if ¬txj appears in clause ci pi otherwise if 1 ≤ i ≤ n, 1 ≤ j ≤ m and t ∈ {0, 1}\nEj(t) ⇌ E 1 j (t)⊗ (E 2 j (t)⊗ (. . . (E n−1 j (t)⊗ E n j (t)))) if 1 ≤ j ≤ m and t ∈ {0, 1}\nHj ⇌ p1 ⊗ (p2 ⊗ (. . . (pn−1 ⊗ pn))) if 1 ≤ j ≤ m\nFj ⇌ Ej(1) Hj ⊓ Ej(0) if 1 ≤ j ≤ m\nG0 ⇌ H1 ⊗ (H2 ⊗ (. . . (Hm−1 ⊗Hm)))\nGi ⇌ Gi−1 ⊘ (pi ; pi) if 1 ≤ i ≤ n\nLet ϕ̄ = F1 ⊗ (F2 ⊗ (. . . (Fm−1 ⊗Fm))) → Gn be the LG sequent corresponding to the Boolean formula ϕ. We now claim that the ϕ if and only if ⊢LG ϕ̄."
    }, {
      "heading" : "4.1 Example",
      "text" : "Let us take the Boolean formula (x1∨¬x2)∧(¬x1∨¬x2) as an example. We have the primitive types {p1, p2} and the types as shown in Figure 2. The formula is satisfiable (for example with the assignment 〈1, 0〉), thus ⊢LG F1 ⊗ F2 → G2. A sketch of the derivation is given in Figure 2, some parts are proved in lemma’s later on."
    }, {
      "heading" : "4.2 Intuition",
      "text" : "Let us give some intuitions for the different parts of the construction, and a brief idea of why this would work. The basic idea is that on the lefthand-side we create a type for each literal (Fj is the formula for literal j), which will in the end result in the base type Hj , so F1 ⊗ (F2 ⊗ (. . . (Fm−1 ⊗ Fm))) will result in G0. However, on the righthand-side we have an occurence of the expression ⊘(pi;pi) for each clause i, so in order to come to a derivation, we need to apply the ⊘R rule for every clause i.\nEach literal on the lefthand-side will result in either Ej(1) (xj is true) or Ej(0) (xj is false). This choice is created using a join type Hj such that ⊢LG Ej(1) → Hj and ⊢LG Ej(0) → Hj , which we use to construct the meet type Fj . It can be shown that in this case ⊢LG Fj → Ej(1) and ⊢LG Fj → Ej(0), i.e. in the original formula we can replace Fj by either Ej(1) or Ej(0), giving us a choice for the truthvalue of xj .\nLet us assume that we need x1 = true to satisfy the formula, so on the lefthand-side we need to replace Fj by E1(1). E1(1) will be the product of exactly n parts, one for each clause (E11 (1) . . . E n 1 (1)). Here E i 1(1) is pi ⊘ (pi ; pi) iff x1 does appear in clause i, and pi otherwise. The first thing that should be noticed is that ⊢LG pi⊘ (pi ; pi) → pi, so we can rewrite all pi⊘ (pi ; pi) into pi so that ⊢LG E1(1) → H1.\nHowever, we can also use the type pi⊘(pi;pi) to facilitate the application of the ⊘R rule on the occurrence of the expression ⊘(pi;pi) in the righthand-side. From Lemma 6 we know that ⊢LG X ⊗[pi ⊘ (pi ; pi)] → Gi if ⊢LG X ⊗[pi] · ⊘ · (pi ; pi) → Gi, so if the expression ⊘Y occurs somewhere in a ⊗-structure we can move it to the outside. Hence, from the occurrence of pi ⊘ (pi ; pi) on the lefthand-side we can move ⊘(pi ; pi) to the outside of the ⊗-structure and pi will be left behind within the original structure (just as if we rewrote it to pi). However, the sequent is now of the form X⊗[pi] ·⊘ · (pi ; pi) → Gi−1 ⊘ (pi ; pi), so after applying the ⊘R rule we have X⊗[pi] → Gi−1.\nNow if the original CNF formula is satisfiable, we can use the meet types on the lefthand-side to derive the correct value of Ej(1) or Ej(0) for all j. If this assignment indeed satisfies the formula, then for each i the formula pi⊘ (pi ;pi) will appear at least once. Hence, for all occurrences of the expression ⊘(pi ; pi) on the righthand-side we can apply the ⊘R rule, after which the rest of the pi ⊘ (pi ; pi) can be rewritten to pi in order to derive the base type.\nIf the formula is not satisfiable, then there will be no way to have the pi ⊘ (pi;pi) types on the lefthand-side for all i, so there will be at least one occurence\nof ⊘(pi ;pi) on the righthand-side where we cannot apply the ⊘R rule. Because the ⊘ will be the main connective we cannot apply any other rule, and we will never come to a valid derivation.\nNote that the meet type Fj provides an explicit switch, so we first have to replace it by either Ej(1) or Ej(0) before we can do anything else with it. This guarantees that if ⊢LG ϕ̄, there also must be some assignment 〈t1, . . . , tm〉 ∈ {0, 1}m such that ⊢LG E1(t1)⊗ (E2(t2)⊗ (. . . (Em−1(tm−1)⊗Em(tm)))) → Gn, which means that 〈t1, . . . , tm〉 is a satisfying assigment for ϕ."
    }, {
      "heading" : "5 Proof",
      "text" : "We will now prove the main claim that ϕ if and only if ⊢LG ϕ̄. First we will prove that if ϕ, then ⊢LG ϕ̄."
    }, {
      "heading" : "5.1 If-part",
      "text" : "Let us assume that ϕ, so there is an assignment 〈t1, . . . , tm〉 ∈ {0, 1} m that satisfies ϕ.\nLemma 10. If 1 ≤ i ≤ n, 1 ≤ j ≤ m and t ∈ {0, 1} then ⊢LG E i j(t) → pi.\nProof. We consider two cases:\n1. If Eij(t) = pi this is simply the axiom rule. 2. If Eij(t) = pi ⊘ (pi ; pi) we can prove it as follows:\npi → pi pi → pi pi · ; · pi → pi ; pi ;R pi → pi · ⊕ · (pi ; pi) dr pi · ⊘ · (pi ; pi) → pi dr\npi ⊘ (pi ; pi) → pi ⊘L\n⊓⊔\nLemma 11. If 1 ≤ j ≤ m and t ∈ {0, 1}, then ⊢LG Ej(t) → Hj.\nProof. From Lemma 7 we know that we can turn Ej(t) into a ⊗-structure. From Lemma 10 we know that ⊢LG E i j(t) → pi, so using Lemma 5 we can replace all Eij(t) by pi in Ej(t) after which we can apply the ⊗R rule n− 1 times to prove the lemma. ⊓⊔\nLemma 12. If 1 ≤ j ≤ m, then ⊢LG Fj → Ej(tj)\nProof. From Lemma 11 we know that ⊢LG Ej(1) → Hj and ⊢LG Ej(0) → Hj , so Ej(1) ∼ Ej(0) with join-type Hj . Now from Lemma 8 we know that ⊢LG Ej(1) Hj ⊓ Ej(0) → Ej(1) and ⊢LG Ej(1) Hj ⊓ Ej(0) → Ej(0). ⊓⊔\nLemma 13. We can replace each Fj in ϕ̄ by Ej(tj), so:\nE1(t1) · ⊗ · (E2(t2) · ⊗ · (. . . (Em−1(tm−1) · ⊗ · Em(tm)))) → Gn\nF1 ⊗ (F2 ⊗ (. . . (Fm−1 ⊗ Fm))) → Gn\nProof. This can be proven by using Lemma 7 to turn it into a ⊗-structure, and then apply Lemma 12 in combination with Lemma 5 m times. ⊓⊔\nLemma 14. In E1(t1) · ⊗ · (E2(t2) · ⊗ · (. . . (Em−1(tm−1) · ⊗ ·Em(tm)))) → Gn, there is at least one occurrence of pi ⊘ (pi ; pi) in the lefthand-side for every 1 ≤ i ≤ n.\nProof. This sequence of E1(t1), . . . , Em(tm) represents the truthvalue of all variables, and because this is a satisfying assignment, for all i there is at least one index k such that ¬tkxk appears in clause i. By definition we have that Eik(tk) = pi ⊘ (pi ; pi). ⊓⊔\nDefinition 3. Y ij ⇌ Ej(tj) with every occurrence of pk ⊘ (pk ; pk) replaced by pk for all i < k ≤ n\nLemma 15. ⊢LG Y 0 1 · ⊗ · (Y 0 2 · ⊗ · (. . . (Y 0 m−1 · ⊗ · Y 0 m))) → G0\nProof. Because Y 0j = Hj by definition for all 1 ≤ j ≤ m and G0 = H1 ⊗ (H2 ⊗ (. . . (Hm−1⊗Hm))), this can be proven by applying the ⊗R rule m−1 times. ⊓⊔\nLemma 16. If ⊢LG Y i−1 1 · ⊗ · (Y i−1 2 · ⊗ · (. . . (Y i−1 m−1 · ⊗ · Y i−1 m ))) → Gi−1, then ⊢LG Y i 1 · ⊗ · (Y i 2 · ⊗ · (. . . (Y i m−1 · ⊗ · Y i m))) → Gi\nProof. From Lemma 14 we know that pi ⊘ (pi ; pi) occurs in Y i 1 · ⊗ · (Y i 2 · ⊗ · (. . . (Y im−1 · ⊗ · Y i m))) (because the Y i j parts are Ej(tj) but with pk ⊘ (pk ; pk) replaced by pk only for k > i). Using Lemma 6 we can move the expression ⊘(pi ; pi) to the outside of the lefthand-side of the sequent, after which we can apply the ⊘R-rule. After this we can replace all other occurrences of pi⊘(pi;pi) by pi using Lemma 10 and Lemma 5. This process can be summarized as:\nY i−11 · ⊗ · (Y i−1 2 · ⊗ · (. . . (Y i−1 m−1 · ⊗ · Y i−1 m ))) → Gi−1 pi ; pi → pi ; pi\n(Y i−11 · ⊗ · (Y i−1 2 · ⊗ · (. . . (Y i−1 m−1 · ⊗ · Y i−1 m )))) · ⊘ · (pi ; pi) → Gi−1 ⊘ (pi ; pi)\n⊘R\nY i−11 · ⊗ · (Y i−1 2 · ⊗ · (. . . (Y i−1 m−1 · ⊗ · Y i−1 m ))) · ⊘ · (pi ; pi) → Gi\nDef\nY i1 · ⊗ · (Y i 2 · ⊗ · (. . . (Y i m−1 · ⊗ · Y i m))) → Gi\n14, 6, 10, 5\n⊓⊔\nLemma 17. ⊢LG Y n 1 · ⊗ · (Y n 2 · ⊗ · (. . . (Y n m−1 · ⊗ · Y n m))) → Gn\nProof. We can prove this using induction with Lemma 15 as base and Lemma 16 as induction step. ⊓⊔\nLemma 18. If ϕ, then ⊢LG ϕ̄,\nProof. From Lemma 17 we know that ⊢LG Y n 1 ·⊗·(Y n 2 ·⊗·(. . . (Y n m−1 ·⊗·Y n m))) → Gn, and because by definition Y n j = Ej(tj), we also have that ⊢LG E1(t1) · ⊗ · (E2(t2) ·⊗ · (. . . (Em−1(tm−1) ·⊗ ·Em(tm)))) → Gn. Finally combining this with Lemma 13 we have that ⊢LG ϕ̄ = F1 ⊗ (F2 ⊗ (. . . (Fm−1 ⊗ Fm))) → Gn, using the assumption that ϕ. ⊓⊔"
    }, {
      "heading" : "5.2 Only-if part",
      "text" : "For the only if part we will need to prove that if ⊢LG ϕ̄, then ϕ. Let us now assume that ⊢LG ϕ̄.\nLemma 19. If ⊢LG X → P ′[(P ⊘Y )◦], then there exist a Q such that Q is part of X or P ′ (possibly inside a formula in X or P ′) and ⊢LG Y → Q.\nProof. The only rule that matches a ⊘ in the righthand-side is the ⊘R rule, so somewhere in the derivation this rule must be applied on the occurrence of P ⊘ Y . Because this rule needs a · ⊘ · connective in the lefthand-side, we know that if ⊢LG X → P\n′[(P ⊘ Y )◦] it must be the case that we can turn this into X ′ · ⊘ ·Q → P ⊘ Y such that ⊢LG Y → Q. ⊓⊔\nLemma 20. If ⊢LG E1(t1)·⊗·(E2(t2)·⊗·(. . . (Em−1(tm−1)·⊗·Em(tm))) → Gn, then there is an occurrence pi ⊘ (pi ; pi) on the lefthand-side at least once for all 1 ≤ i ≤ n.\nProof. Gn by definition contains an occurrence of the expression ⊘(pi ; pi) for all 1 ≤ i ≤ n. From Lemma 19 we know that somewhere in the sequent we need an occurrence of a structure Q such that ⊢LG pi;pi → Q. From the construction it is obvious that the only possible type for Q is in this case pi ; pi, and it came from the occurrence of pi ⊘ (pi ; pi) on the lefthand-side. ⊓⊔\nLemma 21. If ⊢LG E1(t1)·⊗·(E2(t2)·⊗·(. . . (Em−1(tm−1)·⊗·Em(tm))) → Gn, then 〈t1, t2, . . . , tm−1, tm〉 is a satisfying assignment for the CNF formula.\nProof. From Lemma 20 we know that there is a pi⊘(pi;pi) in the lefthand-side of the formula for all 1 ≤ i ≤ n. From the definition we know that for each i there is an index j such that Eij(tj) = pi ⊘ (pi ; pi), and this means that ¬tjxj appears in clause i, so all clauses are satisfied. Hence, this choice of t1 . . . tm is a satisfying assignment. ⊓⊔\nLemma 22. If 1 ≤ j ≤ m and ⊢LG X ⊗[Fj ] → Gn, then ⊢LG X ⊗[Ej(0)] → Gn or ⊢LG X ⊗[Ej(1)] → Gn.\nProof. We know that X⊗[Fj ] is a ⊗-structure, so we can apply the r rule several times to move all but the Fj -part to the righthand-side. We then have that ⊢LG Fj → . . . · \\ · Gn · / · . . . . From Lemma 9 we know that we now have that ⊢LG Ej(0) → . . . · \\ ·Gn · / · . . . or ⊢LG Ej(1) → . . . · \\ ·Gn · / · . . . . Finally we can apply the r rule again to move all parts back to the lefthand-side, to show that ⊢LG X ⊗[Ej(0)] → Gn or ⊢LG X ⊗[Ej(1)] → Gn.\nNote that, in order for Lemma 9 to apply, we have to show that this sequent satisfies the constraints. Gn does contain A1 ⊗A2 with output polarity, however the only connectives in A1 and A2 are ⊗. Because no rules apply on A/((C/ C)\\C) → A′1 ⊗ A ′′ 1 , we have that 6⊢LG A/((C/C)\\C) → A1. In X\n⊗[], the only ⊗ connectives are within other Fk, however these have an input polarity and do not break the constraints either.\nSo, in all cases Fj provides an explicit switch, which means that the truthvalue of a variable can only be changed in all clauses simultanously. ⊓⊔\nLemma 23. If ⊢LG ϕ̄, then ϕ.\nProof. From Lemma 22 we know that all derivations will first need to replace each Fj by either Ej(1) or Ej(0). This means that if ⊢LG F1⊗(F2⊗(. . . (Fm−1⊗ Fm))) → Gn, then also ⊢LG E1(t1) · ⊗ · (E2(t2) · ⊗ · (. . . (Em−1(tm−1) · ⊗ · Em(tm))) → Gn for some 〈t1, t2, . . . , tm−1, tm〉 ∈ {0, 1}\nm. From Lemma 21 we know that this is a satisfying assignment for ϕ, so if we assume that ⊢LG ϕ̄, then ϕ. ⊓⊔"
    }, {
      "heading" : "5.3 Conclusion",
      "text" : "Theorem 1. LG is NP-complete.\nProof. From Lemma 4 we know that for every derivable sequent there exists a proof that is of polynomial length, so the derivability problem for LG is in NP . From Lemma 18 and Lemma 23 we can conclude that we can reduce SAT to LG. Because SAT is a known NP-hard problem (Garey and Johnson, 1979), and our reduction is polynomial, we can conclude that derivability for LG is also NP-hard.\nCombining these two facts we conclude that the derivability problem for LG is NP-complete. ⊓⊔"
    } ],
    "references" : [ {
      "title" : "The Non-associative Lambek Calculus with Product in Polynomial Time",
      "author" : [ "P. de Groote" ],
      "venue" : null,
      "citeRegEx" : "Groote,? \\Q1999\\E",
      "shortCiteRegEx" : "Groote",
      "year" : 1999
    }, {
      "title" : "On the computation of joins for non associative Lambek categorial grammars",
      "author" : [ "A. Foret" ],
      "venue" : "In Proceedings of the 17th International Workshop on Unification,",
      "citeRegEx" : "Foret,? \\Q2003\\E",
      "shortCiteRegEx" : "Foret",
      "year" : 2003
    }, {
      "title" : "Computers and Intractability: A Guide to the Theory of NP-Completeness",
      "author" : [ "M.R. Garey", "D.S. Johnson" ],
      "venue" : null,
      "citeRegEx" : "Garey and Johnson,? \\Q1979\\E",
      "shortCiteRegEx" : "Garey and Johnson",
      "year" : 1979
    }, {
      "title" : "Substructural logics on display",
      "author" : [ "R. Goré" ],
      "venue" : "Logic Jnl IGPL,",
      "citeRegEx" : "Goré,? \\Q1998\\E",
      "shortCiteRegEx" : "Goré",
      "year" : 1998
    }, {
      "title" : "The non-associative Lambek calculus. Categorial Grammar, Linguistic and Literary Studies in Eastern Europe (LLSEE), 25:141–151",
      "author" : [ "M. Kandulski" ],
      "venue" : null,
      "citeRegEx" : "Kandulski,? \\Q1988\\E",
      "shortCiteRegEx" : "Kandulski",
      "year" : 1988
    }, {
      "title" : "The Mathematics of Sentence Structure",
      "author" : [ "J. Lambek" ],
      "venue" : "American Mathematical Monthly,",
      "citeRegEx" : "Lambek,? \\Q1958\\E",
      "shortCiteRegEx" : "Lambek",
      "year" : 1958
    }, {
      "title" : "On the calculus of syntactic types",
      "author" : [ "J. Lambek" ],
      "venue" : "Structure of Language and Its Mathematical Aspects,",
      "citeRegEx" : "Lambek,? \\Q1961\\E",
      "shortCiteRegEx" : "Lambek",
      "year" : 1961
    }, {
      "title" : "The generative capacity of the Lambek-Grishin calculus: A new lower bound",
      "author" : [ "M. Melissen" ],
      "venue" : "Proceedings 14th conference on Formal Grammar,",
      "citeRegEx" : "Melissen,? \\Q2009\\E",
      "shortCiteRegEx" : "Melissen",
      "year" : 2009
    }, {
      "title" : "Symmetries in Natural Language Syntax and Semantics: The Lambek-Grishin Calculus. In Logic, Language, Information and Computation, volume 4576 of Lecture Notes in Computer Science, pages 264–284",
      "author" : [ "M. Moortgat" ],
      "venue" : null,
      "citeRegEx" : "Moortgat,? \\Q2007\\E",
      "shortCiteRegEx" : "Moortgat",
      "year" : 2007
    }, {
      "title" : "Symmetric categorial grammar",
      "author" : [ "M. Moortgat" ],
      "venue" : "Journal of Philosophical Logic,",
      "citeRegEx" : "Moortgat,? \\Q2009\\E",
      "shortCiteRegEx" : "Moortgat",
      "year" : 2009
    }, {
      "title" : "Lambek grammars are context free",
      "author" : [ "M. Pentus" ],
      "venue" : "In Proceedings of the 8th Annual IEEE Symposium on Logic in Computer Science,",
      "citeRegEx" : "Pentus,? \\Q1993\\E",
      "shortCiteRegEx" : "Pentus",
      "year" : 1993
    }, {
      "title" : "Lambek calculus is NP-complete",
      "author" : [ "M. Pentus" ],
      "venue" : "CUNY Ph.D. Program in Computer Science Technical Report TR–2003005,",
      "citeRegEx" : "Pentus,? \\Q2003\\E",
      "shortCiteRegEx" : "Pentus",
      "year" : 2003
    }, {
      "title" : "Product-Free Lambek Calculus Is NP-Complete",
      "author" : [ "Y. Savateev" ],
      "venue" : "Proceedings of the 2009 International Symposium on Logical Foundations of Computer Science,",
      "citeRegEx" : "Savateev,? \\Q2009\\E",
      "shortCiteRegEx" : "Savateev",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "In his 1958 and 1961 papers, Lambek formulated two versions of the Syntactic Calculus : in (Lambek, 1958), types are assigned to strings, which are then combined by an associative operation; in (Lambek, 1961), types are assigned to phrases (bracketed strings), and the composition operation is non-associative.",
      "startOffset" : 91,
      "endOffset" : 105
    }, {
      "referenceID" : 6,
      "context" : "In his 1958 and 1961 papers, Lambek formulated two versions of the Syntactic Calculus : in (Lambek, 1958), types are assigned to strings, which are then combined by an associative operation; in (Lambek, 1961), types are assigned to phrases (bracketed strings), and the composition operation is non-associative.",
      "startOffset" : 194,
      "endOffset" : 208
    }, {
      "referenceID" : 3,
      "context" : "As for generative power, Kandulski (1988) proved thatNL defines exactly the context-free languages.",
      "startOffset" : 25,
      "endOffset" : 42
    }, {
      "referenceID" : 3,
      "context" : "As for generative power, Kandulski (1988) proved thatNL defines exactly the context-free languages. Pentus (1993) showed that this also holds for associative L.",
      "startOffset" : 25,
      "endOffset" : 114
    }, {
      "referenceID" : 0,
      "context" : "As for the complexity of the derivability problem, de Groote (1999) showed that for NL this belongs to PTIME; for L, Pentus (2003) proves that the problem is NP-complete and Savateev (2009) shows that NP-completeness also holds for the product-free fragment of L.",
      "startOffset" : 54,
      "endOffset" : 68
    }, {
      "referenceID" : 0,
      "context" : "As for the complexity of the derivability problem, de Groote (1999) showed that for NL this belongs to PTIME; for L, Pentus (2003) proves that the problem is NP-complete and Savateev (2009) shows that NP-completeness also holds for the product-free fragment of L.",
      "startOffset" : 54,
      "endOffset" : 131
    }, {
      "referenceID" : 0,
      "context" : "As for the complexity of the derivability problem, de Groote (1999) showed that for NL this belongs to PTIME; for L, Pentus (2003) proves that the problem is NP-complete and Savateev (2009) shows that NP-completeness also holds for the product-free fragment of L.",
      "startOffset" : 54,
      "endOffset" : 190
    }, {
      "referenceID" : 0,
      "context" : "As for the complexity of the derivability problem, de Groote (1999) showed that for NL this belongs to PTIME; for L, Pentus (2003) proves that the problem is NP-complete and Savateev (2009) shows that NP-completeness also holds for the product-free fragment of L. It is well known that some natural language phenomena require generative capacity beyond context-free. Several extensions of the Syntactic Calculus have been proposed to deal with such phenomena. In this paper we look at the Lambek-Grishin calculus LG (Moortgat, 2007, 2009). LG is a symmetric extension of the nonassociative Lambek calculus NL. In addition to ⊗, \\, / (product, left and right division), LG has dual operations ⊕,;,⊘ (coproduct, left and right difference). These two families are related by linear distributivity principles. Melissen (2009) shows that all languages which are the intersection of a context-free language and the permutation closure of a context-free language are recognizable in LG.",
      "startOffset" : 54,
      "endOffset" : 822
    }, {
      "referenceID" : 3,
      "context" : "The axioms and inference rules are presented in Figure 1, where we use the display logic from (Goré, 1998), but with different symbols for the structural connectives.",
      "startOffset" : 94,
      "endOffset" : 106
    }, {
      "referenceID" : 3,
      "context" : "The axioms and inference rules are presented in Figure 1, where we use the display logic from (Goré, 1998), but with different symbols for the structural connectives. It has been proven by Moortgat (2007) that we have Cut admissibility for LG.",
      "startOffset" : 95,
      "endOffset" : 205
    }, {
      "referenceID" : 0,
      "context" : "P [] ::= [] | P [] · ⊕ ·Q | Q · ⊕ · P [] | P [] · / · Y | Q · / ·X [] | Y · \\ · P [] | X [] · \\ ·Q This notation is similar to the one of de Groote (1999) but with structures.",
      "startOffset" : 141,
      "endOffset" : 155
    }, {
      "referenceID" : 5,
      "context" : "The type simililarity relation ∼, introduced by Lambek (1958), is the reflexive transitive symmetric closure of the derivability relation.",
      "startOffset" : 48,
      "endOffset" : 62
    }, {
      "referenceID" : 1,
      "context" : "This is also the solution given by Lambek (1958) for the associative system L, but in fact this is the shortest solution for the non-associative system NL (Foret, 2003).",
      "startOffset" : 155,
      "endOffset" : 168
    }, {
      "referenceID" : 4,
      "context" : "This is also the solution given by Lambek (1958) for the associative system L, but in fact this is the shortest solution for the non-associative system NL (Foret, 2003).",
      "startOffset" : 35,
      "endOffset" : 49
    }, {
      "referenceID" : 5,
      "context" : "In this section we will show that we can reduce a Boolean formula in conjunctive normal form to a sequent of the Lambek-Grishin calculus, so that the corresponding LG sequent is provable if and only if the CNF formula is satisfiable. This has already been done for the associative system L by Pentus (2003) with a similar construction.",
      "startOffset" : 113,
      "endOffset" : 307
    }, {
      "referenceID" : 2,
      "context" : "Because SAT is a known NP-hard problem (Garey and Johnson, 1979), and our reduction is polynomial, we can conclude that derivability for LG is also NP-hard.",
      "startOffset" : 39,
      "endOffset" : 64
    } ],
    "year" : 2017,
    "abstractText" : "The Lambek-Grishin calculus LG is the symmetric extension of the non-associative Lambek calculus NL. In this paper we prove that the derivability problem for LG is NP-complete.",
    "creator" : "LaTeX with hyperref package"
  }
}