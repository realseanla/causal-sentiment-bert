{
  "name" : "1609.02809.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "edward.dixon@intel.com " ],
    "sections" : [ {
      "heading" : null,
      "text" : "Harassment detection: a benchmark on the #HackHarassment dataset \nAlexei Bastidas, Edward Dixon, Chris Loo, John Ryan   Intel  \nemail:  edward.dixon@intel.com \nKeywords:e.g.Machine Learning, Natural Language Processing, Cyberbullying \nIntroduction \nOnline harassment has been a problem to a greater or lesser extent since the early days of the                                    internet. Previous work has applied antispam techniques like machinelearning based text                      classification (Reynolds, 2011) to detecting harassing messages. However, existing public datasets                      are limited in size, with labels of varying quality. The #HackHarassment initiative (an alliance of                             1 tech companies and NGOs devoted to fighting bullying on the internet) has begun to address this                                issue by creating a new dataset superior to its predecssors in terms of both size and quality. As we                                      (#HackHarassment) complete further rounds of labelling, later iterations of this dataset will                        increase the available samples by at least an order of magnitude, enabling corresponding                          improvements in the quality of machine learning models for harassment detection. In this paper, we                              introduce the first models built on the #HackHarassment dataset v1.0 (a new open dataset, which                              we are delighted to share with any interested researcherss) as a benchmark for future research. \nRelated Work \nPrevious work in the area by Bayzik 2011 showed that machine learing and natural language                              processing could be successfully applied to detect bullying messages on an online forum. However,                            the same work also made clear that the limiting factor on such models was the availability of a                                    suitable quantity of labeled examples. For example, the Bayzick work relied of a dataset of 2,696                                samples, only 196 of which were found to be examples of bullying behaviour. Additionally, this                              work relied on model types like J48 and JRIP (types of decision tree), and knearest neighbours                                classifiers like IBk, as opposed to popular modern ensemble methods or deep neuralnetworkbased                          approaches. \nMethodology \nOur work was carried out using the #HackHarassment Verison 1 dataset, the first iteration of which  consists exclusively of Reddit posts.  An initially random selection of posts, in which harassing  content occured at a rate of between 5% and 7% was culled of benign content using models training  on a combination of existing cyberbullying datasets (Reynolds 2001, also “Improved cyberbullying  detection through personal profiles). Each post is labelled independently by at least five Intel  Security Web Analysts.   (a post is considered “bullying” if it labelled as such by 20% or more of  the human labelers  as shown in the following histogram, a perfect consensus is relatively rare, and  so we rate a post as “harassing” if 20%  2 of our 5 raters  consider it to be harassing).  This is a  relatively balanced dataset, with 1,280 nonbullying/harassing posts,, and 1,118 bullying/harassing  examples. \n1 \"Hack Harassment.\" 2016. 26 Jul. 2016 <http://www.hackharassment.com/> \n  All preprocessing, training and evaluation was carried out in Python, using the popular                          SciKitLearn library (for feature engineering and linear models) in combination with Numpy (for                         2 3 matrix operations), Keras  and TensorFlow  (for models based on deep neural networks  DNNs).   4 5\nFor the linear models, features were generated by tokenizing the text (breaking it aparting into                              words), hashing the resulting unigrams, bigrams and trigrams (collectiojns of one, two, or three                            adjacent words) and computing at TF/IDF for each hashed value. The resulting feature vectors                            were used to train and test Logistic Regressioin, Support Vector Machine and Gradient Boosted                            Tree models, with 80% of data used for training and 20% held out for testing (results given are                                    based on the heldout 20%). \nFor the DNNbased approach, a similar approach was taken to tokenization, both bigram and                            trigram hashes were computed; these were onehot encoded, and dense representations of these                          features were learned during training, as per Joulin 2016. \n2 \"scikitlearn: machine learning in Python — scikitlearn 0.17.1 ...\" 2011. 29 Jul. 2016 <http://scikitlearn.org/>  3 \"NumPy — Numpy.\" 2002. 29 Jul. 2016 <http://www.numpy.org/>  4 \"Keras Documentation.\" 2015. 29 Jul. 2016 <http://keras.io/>  5 \"TensorFlow — an Open Source Software Library for Machine ...\" 2015. 29 Jul. 2016  <https://www.tensorflow.org/> \nThe FastText model used is a python implenmentation of the model described in \"Bag of Tricks for                                  Efficient Text Classification.” . For the text encoding, bigrams and trigrams are used. 20% of the                               6 data was held out for testing. \nThe Recurrent Character Level Neural Network model consists of 2 GRU layers of width 100                              followed by a Dense Layer of size 2 with softmax on the output, Between each of the layers batch                                      normailization is performed. The optimiser used was rmsprop. For data preperation each of                          characters was onehot encoded and each sample was truncated/padded to 500 charcters in length.                            20% of the data was held out for testing. \nResults \nModel  Precision (Harassing)  Recall (Harassing) \nGradient Boosted Trees  (ScikitLearn) \n0.80  0.71 \nBernoulli Naive Bayes  0.54  0.30 \nFastText  0.60  0.78 \nRecurrent Character Level  Neural Network \n0.71  0.73 \n \nConclusions \nWe have presented the first results on a new open cyberbullying/harassment dataset.  While our  models clearly demonstrate a degree of ability to discriminate between the content classes, the  achieved precision in particular falls far short of our ambitions for #HackHarassment.    Over the coming months, we’ll massively expand the size of our labelled dataset, and review our  labelling methodology, anticipating that a larger dataset will facilitate more accurate models.  We  look forward both to the availability of a larger dataset, and to seeing the development of classifiers  that improvement on our work, and welcome partners able to contribute either in terms of  expanding the dataset or improving the modelling. \nReferences  Reynolds, Kelly, April Kontostathis, and Lynne Edwards. \"Using machine learning to detect cyberbullying.\" Machine Learning and  Applications and Workshops (ICMLA), 2011 10th International Conference on  18 Dec. 2011: 241244. \nBayzick, Jennifer, April Kontostathis, and Lynne Edwards. \"Detecting the presence of cyberbullying using computer software.\"  (2011): 12. \nJoulin, Armand et al. \"Bag of Tricks for Efficient Text Classification.\" arXiv preprint arXiv:1607.01759  (2016). \nImproved Cyberbullying Detection Through Personal Profiles \n6 \"fastText\" 2015. 22 Jul. 2016 <https://github.com/sjhddh/fastText> "
    } ],
    "references" : [ {
      "title" : "Using machine learning to detect cyberbullying.\" ​Machine",
      "author" : [ "Reynolds", "Kelly", "April Kontostathis", "Lynne Edwards" ],
      "venue" : "Learning and Applications and Workshops (ICMLA),",
      "citeRegEx" : "Reynolds et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Reynolds et al\\.",
      "year" : 2011
    }, {
      "title" : "Detecting the presence of cyberbullying using computer software.",
      "author" : [ "241­244. Bayzick", "Jennifer", "April Kontostathis", "Lynne Edwards" ],
      "venue" : null,
      "citeRegEx" : "Bayzick et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bayzick et al\\.",
      "year" : 2011
    } ],
    "referenceMentions" : [ ],
    "year" : 0,
    "abstractText" : "tech companies and NGOs devoted to fighting bullying on the internet) has begun to address this  issue by creating a new dataset superior to its predecssors in terms of both size and quality. As we  (#HackHarassment) complete further rounds of labelling, later iterations of this dataset will  increase the available samples by at least an order of magnitude, enabling corresponding   improvements in the quality of machine learning models for harassment detection. In this paper, we  introduce the first models built on the #HackHarassment dataset v1.0 (a new open dataset, which   we are delighted to share with any interested researcherss) as a benchmark for future research.",
    "creator" : null
  }
}