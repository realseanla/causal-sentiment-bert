{
  "name" : "1705.07318.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Formalized Lambek Calculus in Higher Order Logic (HOL4)",
    "authors" : [ "Chun Tian" ],
    "emails" : [ "chun.tian@studio.unibo.it" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 5.\n07 31\n8v 1\n[ cs\n.C L\n] 2\n0 M\nay 2\n01 7\nThree deduction systems (Syntactic Calculus, Natural Deduction and Sequent Calculus) of Lambek Calculus are defined with many related theorems proved. The equivalance between these systems are formally proved. Finally, a formalization of Sequent Calculus proofs (where Coq has built-in supports) has been designed and implemented in HOL4. Some basic results including the subformula properties of the so-called “cut-free” proofs are formally proved. This work can be considered as the preliminary work towards a language parser based on category grammars which is not multimodal but still has ability to support context-sensitive languages through customized extensions."
    }, {
      "heading" : "1 Introduction",
      "text" : ""
    }, {
      "heading" : "1.1 Phrase structure grammars and Chomsky Hierarchy",
      "text" : "Roughly speaking, sentences in formal and natural languages are constructed by sequences of smaller units, i.e. phrases and words. And determining if any given sequence of phrases or words (coming from a finite lexicon of certain language) forms a grammatically correct sentence in that language, and when it’s correct, finding out the “structure” (and even the “meaning”) of that sentence, are the central goals in both linguistics and Natural Language Processing in computer science.\nSince the year when Noam Chomsky published his famous “Hierarchy” [1] and his work on phrase structures of English and Spanish [2] in 1950s, the concepts of context-free and context-sensitive languages (and the intemediate areas between them) with the uses of rewriting rules to represent the phrase structure grammar of any given language, has dominated the parsing theory until today.\nThe rule-based grammar for context-free languages and certain more restricted languages, together with the related parsing theory and algorithms, worked so well in handing artificial languages (formal languages and programming languages). But parsing natural languages has always been a complex and difficult area.\nThe first clue is that, natural languages are NOT context-free, although the precise statement only says: there exist some natural languages which are not context-free, and the proof is totally based on some rare phenomenons in certain languages, e.g. the so-called cross-serial dependencies in Swiss German and Dutch. For most of other natural languages, e.g. English and Italian, a proof that these languages are not context-free, doesn’t exist yet. Therefore, it’s quite fair to say, after ignoring some rarely used part, all natural languages can indeed be defined by context-free grammars.\nWhile it’s quite common for any programming langauge compiler to use a complete, hand-written or program-generated grammar to describe their targeting language, the task of writing down all the grammar rules for a natural language, e.g. English and Italian, is incredibly hard. (Nevertherless they do exist for English). Efficiency is not a big problem (given the fact that each sentence as parsing unit is relative small, e. g.. almost always less than 100 words), ambiguities are indeed problems, but it’s now generally accepted for any grammar parsing tool to output more than one possible interpretations for any given sentences (then there’re higher level linguistic theories to help disambiguiting them).\nThe real problem is, the grammar rules for each languages are so different, none of rewriting rules can be considered as universal to all human languages. For example, one may think that all sentences have a Noun Phrase (NP) followed by a Verb Phrase (VP) at top level, e.g. in the Italian sentence “molti esperti arriveranno”, NP is “molti esperti” and VP is “arriverranno”. But in Italian one can also put the subject after the verb and say “arriveranno esperti” instead. If we have to maintain the order between NP and VP, then this new sentence must be interpreted in a different way (see p. 33 of [3]) with an\nS NP\n(Molti esperti)\nVP\narriveranno\nS\nNP\nǫ\nVP\nV\nArriveranno\nNP\n(molti esperti)\nempty NP at the beginning (see Fig 1.1). 1 . Here the main argument is, phrase structures of the two sentences shouldn’t be such different when Italian speakers simply wanted to emphasize the action (Verb) by speaking that word first. But within the framework of Chomksy, such complexity is inevitable.\nChomsky further developped his phrase structure theory into a more complex theory called “Government and Binding” (GB) in 1990s, and by distinguishing the so-called surface structure and deep structure, different speaking ways of the same sentence now can be finally turned into the same structure. This new GB theory is dedicated for parsing only natural languages, but the attepmts to find evidences for the existence of universal grammars failed again.\nSeveral years later, Chomsky almost completely abandoned GB theory and turned into the “Minimalist Program”, which this new grammar theory is much simplier than GB theory while is still capable to analyze the phrase structure of context-sensitive languages."
    }, {
      "heading" : "1.2 Categorial Grammars and Lambek Calculus",
      "text" : "On the other side, different grammar theories have been introduced in parallel. One of them is the so-called Categorial Grammar.\nCategorial Grammar was firstly introduced by Polish philosopher and logician Kazimierz Ajdukiewicz in 1935 [4], which is based on ideas from precedent Polish logicians. In this whole new grammar system, Ajdukiewicz assigned each word (or lexical entry) a “category” which is defined inductively:\n1. Basic categories. The two primitive types n (for entities or individuals or first order terms) and s (for propositions or truth values) are categories. 2. Functor categorites. Whenever N is a category and D1, . . . , Dn is a sequence or multiset of categories,\nthen N\nD1 · · ·Dn is itself a category.\nTo decide the category of syntactically connected expressions, the following rules are used:\n1. a word or lexical entry is syntactically connected, and its category is the basic their assigned category, 2. given n syntactically connected expressions d1, . . . , dn of respective categoriesD1, . . . , Dn, and an ex-\npression f of category N\nD1 · · ·Dn , the expression fd1 · · · dn (or any permutation of it!) is syntactically\nconnected and has category N .\nThere’re two notable observations about Ajdukiewicz’s categorial grammar:\n1. The calculus of categorites works just like elementary arithmetics: functor categorites are divisions of categories, and syntactic connections are multiplications of categories. Thus if one word has category A\nB , the other has category B, their connecion has category\nA B · B = A.\n2. Although the original purpose of the grammar is to check logical formulae in Polish notation, in which the word order is not really a problem, but we can imagine that, for highly inflected languages like Latin and Sanskrit, which has rather flexible word orders, this category grammar may result into quite compat while still correct grammars (for at least a small portion). Nevertheless it’s impossible to handle English.\nIn 1953, just two years before Chomsky published his phrase structure grammar theory and the famous hierarchy, Israeli philosopher, mathematician, and linguist Yehoshua Bar-Hillel made an important enhancement [5] to Ajdukiewicz’s categorial grammar. The resulting new categorial grammar is now called Ajdukiewicz-Bar grammar or AB grammar.\n1 Relaxing the order of NP and VP in the grammar is not an option, because it will be illegal in English\nIn AB grammar, word orders are now respected, and the single “division” operator in categories are\nnot divided into two different directions, i.e. A\nB now becomes A/B (read as “A over B”) and A\\B (read\nas “B under A”, and the syntactic connections cannot be permutated with changing the overall category, i.e. in general, AB 6= BA. In formal languages, the so-called category is defined as follows:\nC ::= P | (C/C) | (C \\ C)\nwhere P is a basic category usually containing S (for sentences) and np (for noun phrases) and n (for nouns). And the only rules in this grammar systems are, ∀u, v ∈ C,\nu(u \\ v) −→ v (\\e)\n(v/u)u −→ v (/e)\nAlthough AB grammar system looks quite simple, it’s proved that AB grammar is weakly equivalent to a corresponding context-free grammar, and there’re algorithms to learn AB grammars from parsing results. [6]. However, having only elimination rules, it’s impossible to derive fomulae like (x/y)(y/z) −→ (x/z), because the only purposes of the rules is to reduce two categories into a small one, which is part of the two categories. AB grammar is just a rule-based system but formal system.\nFinally, in 1958, Joachim Lambek [7] succesfully defined a formal system for syntactic calculus in which all category formulae can be derived from a basic set of rules (as axioms) and basic logic formulae. It’s later called (Associative) Lambek Calculus, or L. In Lambek Calculus, now the syntactic connections are representated explicitly by a new connective “dot” (·) and the associativity (A ·B) · C = A · (B · C) is assumed as axiom (or rule). Thus, the category in Lambek calculus is defined as follows:\nL ::= P | (L/L) | (L \\ L) | L · L\nwhere P is a basic category. Lambek introduced a relation → and use x → y to indicate that any expression (string of words) of type (or category) x also has type y, and the following rules were used as axioms of the formal system:\n(a) x → x; (b) (x · y) · z → x · (y · z); (b’) x · (y · z) → (x · y) · z; (c) if x · y → z, then x → z/y; (c’) if x · y → z, then y → x \\ z; (d) if x → z/y, then x · y → z; (d’) if y → x \\ z, then x · y → z; (e) if x → y and y → z, then x → z.\nHere are a few observations about Lambek Calculus:\n1. Although Lambek calculues has more rules then AB grammar, but they’re actually equivalent: “a set of strings of words forms a categorial language of one type if and only if it forms a categorial language of the other type” [8]; 2. The → relation is reflexisive (by (a)) and transitive (by (e)), but it’s not symmetric, i.e. in general x → y ; y → x, thus it’s not an equivalence relation at all. 3. The dot (·) connective usually doesn’t appears in the lexion, in which each word is associated with one or more categories which is made by only basic categories and two connectives slash (/) and backslash (\\). 4. Lambek calculus can only be used to decide if a given string of words has a specific category (e. g. the category of a legal sentence, S), the phrase structure, however, is not immediately known. 5. Lambek calculus has a decision procedure through Gentzen’s Sequent Calculus and the corresponding Cut-elimination theorem. This was proved by Lambek (1958) [7]. 6. Lambek calculus is NP-complete [9], L-complete [10], and Lambek grammars are context-free [11].\nAmong other issues, to resolve the key limitation that Lambek calculus cannot be used as a language parser, in 1961, Lambek introduced the so-called Non-associative Lambek Calculus [12], or NL. There’re two major modifications comparing to previous associative Lambek Calculus:\n1. The associative rule (b) and (b’) have been removed from axiom rules, and all theorems derivated from them are not derivable any more. It’s found that such changes also removed some strange non-language sentences which are acceptable before.\n2. To decide the category of a sentence, now the first step is to put all the words into a binary tree with the original order respected, i. e. the bracketing process, then applications of inference rules are limited at each tree node.\nUsing as a language parser, non-associative Lambek Calculus works in this way: for any given string of words, if there exists a bracketing such that the resulting category is the target category (e. g. S), then it’s grammatically correct and the corresponding binary tree represent the phrase structures, with the category of each node representing the phrase structure at different levels. It’s proven that nonassociative Lambek Calculus also has a decision procedure, which surprisingly is polynomial. And for product-free NL (there’s no dots in lexicon), the parsing process is also polynomial. (see Chapter 4.6 of [6] for detailed discussions and links tooriginal papers)\nBeside L and NL, there’s also NLP in which the commutativity of products is respect based on NL, i. e. x ·y = y ·x. With such assumption, the resulting grammar is quite similar to the original Ajdukiewicz grammar. When both commutativity and associativity are respected, the resulting Lambek calculus is called LP."
    }, {
      "heading" : "1.3 Categorial grammars and universal grammar",
      "text" : "Chomsky believes that there’s an innate universal grammar in human mind, and when children start learning languages from very limited vocabulary and extremely incomplete corpus (where machine learning is impossible to converge), what they actually do is to adapt this universal grammar to their mother languages. However, from Chomsky’s phrase structure theory and the related grammars based on rewriting rules, terminals and non-terminals, we can’t see any evidence for the existence of Universal gammars.\nOn the other side, in Categorial grammars we see two separated parts:\n1. Language independent part: the inference rules for categories; 2. Language dependent part: the lexicon.\nTherefore, if we treat the first part at “unversal grammar”, what remains to be learn by children (and machine learning program), is just the lexion which associates words to their syntactic categories (which then indicate how a word gets used in this language) and their meanings. This connection (to universal grammars) has made Category Grammars quite attractive. Maybe the language parsing process based on categorial grammars are more natural and close to the natural language processing in human mind."
    }, {
      "heading" : "1.4 Categorial Type Logics",
      "text" : "Since natural language is not context-free, while either L and NL can only handle context-free languages, people seek ways to extend Lambek Calculus to support context-sensitive languages. On the other side, none of L, NL and NLP is perfect for all languages, thus people seek ways to combine different Lambek calculus and use them for different portions of the target language.\nOne such attempts is the so-called Multimodal Lambek Calculus. In this calculus system, there’re many copies of category connectives, each associated with a mode index i:\nL ::= P | (L/iL) | (L \\i L) | L ·i L\nDifferent versions of Lambek Calculus were identified with different mode identifiers, and properties like commutativity and associativity are respected for only connectives of certain modes. Then there’s structure rules to bring different modes together. (see Chapter 5 of [6]).\nEven further extension includes the unary connectives from linear logics: ♦ and . With all such things, the resulting calculus system has so many rules and operators, and goes far beyond Lambek Calculus, has a new name called Categorial Type Logics (CTL).\nCategorial Type Logics has the folloing characteristics:\n1. From the view of proof theory, there’re still decision procedures, and the cut-elimination theorem can still be proved. However, to find the proofs for category derivations, more complex algorithms must be used (e.g. proof nets) and the time complexity is at least NP-complete. 2. From the view of model theory, CTL were proved to be sound and complete. 3. Learning CTL grammars from corpus has no known results. Given the fact that the structure of\ncategories now contains more connectives in different modes, the learning process is much harder than the normal uni-modal Lambek calculus.\nThus CTL is not quite practical so far, as one of the main authors said in his book: “So the big open question for multimodal categorial grammars is to find the ‘right’ combination of structural rules both from the point of view of being able to make the relevant linguistic generalizations and from the point of view of computational complexity.”. (page. 184 of [6])\nIn this paper, we have tried another possibility to extend Lambek Calculus. We think NL is good enough as a basis, because it’s as simple as rewriting rules in context-free grammars, and it has known polinomial parsing alghrithm and reasonable learning algorithms. To handle certain context-sentive portions of the target language, we use restrictive extensions to extend the NL inference rules. These extensions, when satisfying certain restrictions, won’t break the validity of existing parsing and learning algorithms while it’s possible to handle context-sensitive languages."
    }, {
      "heading" : "1.5 Trusted software and theorem provers",
      "text" : "Software cannot be trusted in general, their outputs may be wrong due to either issues in their program code, or issues in the development platform in which they were written. On the other side, either operating systems or development platform (including programming languages) evolve quickly. Any program, once being written, must be maintained continuously, otherwise it soon becomes unusable.\nTherefore, we try to convince the audiences the following principles:\n1. For any research task in computer science, the last solution is to write a whole new software. Because once the research is done (or paper is published), the software may not be well maintained any more, and in a few years it’s dead. 2. Choose programming languages which has long history (at least 10 years), with more than one stable implemenations. 3. Whenever possible, generate program code from higher level tools instead of writing them directly.\nOn the other side, to gurantee the correctness of algorithms or their implementations, it’s preferred to use theorem provers. Many theorem proving software have the ability to generte program code from proved theorems. Coq 2 and Isabelle 3 are such examples.\nSometimes, the theorem prover itself is written as an extension to the development platform, and in this case user can continue extending the theorem prover to make the whole platform into any application software. ACL2 4 and HOL4 5 are two notable examples written in this way."
    }, {
      "heading" : "1.6 Why Higher Order Logic?",
      "text" : "Comparing to other theorem provers, the Higher Order Logic (HOL) family of theorem provers (HOL4, HOL light, Isabelle) has relatively simple logic foundation: just simple typed lambda calculus with type variables. Comparing to the logic foundation of Coq (Calculus of Inductive Construction, CIC), higier order logic is easier to understand and use, because it has few primitive derivation rules, and students who has just finished studying λ-calculus (typed and untyped) could easily get started with HOL.\nHOL has also a small and verified kernel. And when HOL is implemented in Standard ML language, which is the case of HOL4 and Isabelle, the programming platform itself could be also formally verified 6\nTherefore, we choose HOL4 for several reasons:\n1. It’s a theorem prover well maintained and with long history (30 years). Wigh high chances it will continue living for next 30 years, so is the proof scripts we wrote in it today. 2. The logical foundation of HOL4 is easy to understand, and the primitive inference rule set is small and clear. 3. HOL4 has a rich builtin theory library and a very large set of example code library for reference purposes. 4. The software is written as a natural extension to Standard ML programming language. The theorem prover, the proof scripts, and the tacticals, they’re all written in Standard ML. In theory, user can build any customized software upon the theorem prover. Besides, the CakeML project has demonstrated how to write a formally verified programming language compiler and interpreter in HOL4.\n2 https://coq.inria.fr 3 http://isabelle.in.tum.de 4 http://www.cs.utexas.edu/users/moore/acl2/ 5 https://hol-theorem-prover.org 6 The CakeML project (https://cakeml.org) represents one such efforts.\n5. The type variable in HOL4 types are especially suited for expresing syntactic categories in Categorial Grammars. (this will be explained in next section).\nSome more differences between HOL and Coq will be discussed later, in section 6."
    }, {
      "heading" : "2 Lambek Calculus in HOL4",
      "text" : "In this project, we have implemented Lambek Calculus in HOL4. The exact variant of Lambek Calculus is NL (non-associative) with arbitrary extensions. Three deduction systems are implemented: (Axiomatic) Syntactic Calculus, Natural Deduction, and Gentzen’s Sequent Calculus. 7\nThis work is based on an implementation of Lambek Calculus 8 in Coq proof assistant. In fact, our work so far can be considered as a partial porting of the Coq-based proof scripts: most definitions and theorems are from previous work, with necessary modifications. Here are some major differences:\n1. Whenever a relation can be defined as a reflexitive transivive closure (RTC) of another relation, instead of define it manuall as in Coq, now we use HOL’s builtin relationTheory to define it and get the related theorems. 2. Coq’s built-in support on proofs are not directly portable to HOL, therefore we defined whole new data structures and fill the gaps."
    }, {
      "heading" : "2.1 Syntactic Categories",
      "text" : "In HOL, syntactic categories are defined by an algebraic datatype Form with a type variable α:\nDatatype ‘Form = At ’a | Slash Form Form | Backslash Form Form | Dot Form Form ‘\nIn this way, all theorems we proved are actually theorem schemas in which there’s always a type variable. In practice, user can either define another data structure with enumerated categories (S, n, np, . . .), or directly use strings. For example, in later mode, the basic category “S” can be simply represented as At “S”, and category “S/np” will be Slash (At \"S\") (At \"np\") or At “S” / At “np” when grammar supports are enabled."
    }, {
      "heading" : "2.2 Syntactic Calculus",
      "text" : "(Axiomatic) Syntactic Calculus is a theory about the arrow relation which indicates that a string of words having the first category will also have the seoncd category, it’s reflexitive and transitive. In HOL4, such a inductive relation can be easily defined by Hol_reln [13] command:\nval (arrow_rules , arrow_ind , arrow_cases ) = Hol_reln ‘\n(!X A. arrow X A A) /\\ (!X A B C. arrow X (Dot A B) C ==> arrow X A (Slash C B)) /\\ (!X A B C. arrow X A (Slash C B) ==> arrow X (Dot A B) C) /\\ (!X A B C. arrow X (Dot A B) C ==> arrow X B (Backslash A C)) /\\ (!X A B C. arrow X B (Backslash A C) ==> arrow X (Dot A B) C) /\\ (!X A B C. arrow X A B /\\ arrow X B C ==> arrow X A C) /\\ (!(X :’a arrow_extension ) A B. X A B ==> arrow X A B) ‘;\nwhich is then broken into the following separated rules:\none:\n⊢ arrow X A A beta:\n⊢ arrow X (A · B) C ⇒ arrow X A (C / B) beta’:\n⊢ arrow X A (C / B) ⇒ arrow X (A · B) C gamma:\n⊢ arrow X (A · B) C ⇒ arrow X B (A \\ C) gamma’:\n⊢ arrow X B (A \\ C) ⇒ arrow X (A · B) C\n7 Project code can be found at https://github.com/binghe/informatica-public/tree/master/lambek 8 https://github.com/coq-contribs/lambek\ncomp:\n⊢ arrow X A B ∧ arrow X B C ⇒ arrow X A C arrow_plus:\n⊢ X A B ⇒ arrow X A B\nNoticed that, the relation arrow is a 3-ary relation with the type “α arrow_extension -> α arrow_extension”, in which the type abbreviation “arrow extension” is defined as\ntype_abbrev (\"arrow_extension \", ‘‘:’a Form -> ’a Form -> bool ‘‘);\nAn arrow extension defined some extra properties beyond the basic rules. This connection was made by the arrow_plus theorem. Thus for any arrow extension X , arrow X can be considered as a normal 2-ary relation between two categories with the type “α Form”.\nSince arrow extensions are nothing but normal relations, the union of two such relations can be considered as the “sum” of two arrow extensions, and the subset/superset of relations can be considered as restrictions (or further extensions) to an arrow extension. Then, the arrow extensions of the four different Lambek Calculus, NL, L, NLP and LP are defined respectively:\n⊢ NL = ⊢ (∀A B C. L (A · (B · C)) (A · B · C)) ∧\n∀A B C. L (A · B · C) (A · (B · C)) ⊢ NLP (A · B) (B · A) ⊢ LP = add_extension NLP L\nin which EMPTY_REL represents an empty relation, and add_extension equals to the union of relations. Thus LP is nothing but a sum of NLP and L.\nThen we have proved some common theorems for all Lambek Calculus (i. e. for whatever arrow extensions):\nDot_mono_right:\n⊢ arrow X B ′ B ⇒ arrow X (A · B ′) (A · B) Dot_mono_left:\n⊢ arrow X A′ A ⇒ arrow X (A′ · B) (A · B) Dot_mono:\n⊢ arrow X A C ∧ arrow X B D ⇒ arrow X (A · B) (C · D) Slash_mono_left:\n⊢ arrow X C ′ C ⇒ arrow X (C ′ / B) (C / B) Slash_antimono_right:\n⊢ arrow X B ′ B ⇒ arrow X (C / B) (C / B ′) Backslash_antimono_left:\n⊢ arrow X A A′ ⇒ arrow X (A′ \\ C) (A \\ C) Backslash_mono_right:\n⊢ arrow X C ′ C ⇒ arrow X (A \\ C ′) (A \\ C)\nThe monotonity of arrow relation with respect to arrow extensions is proved too (by induction on all basic arrow rules):\nmono_X:\n⊢ arrow X A B ⇒ extends X X ′ ⇒ arrow X ′ A B\nFor Lambek extensions supporting permutations, the following theorems are proved:\npi:\n⊢ extends NLP X ⇒ ∀A B. arrow X (A · B) (B · A) pi_NLP:\n⊢ arrow NLP (A · B) (B · A) pi_LP:\n⊢ arrow LP (A · B) (B · A)\nFor Lambek extensions supporting associativity, the following theorems are proved:\nalfa:\n⊢ extends L X ⇒ ∀A B C. arrow X (A · (B · C)) (A · B · C)\nalfa’:\n⊢ extends L X ⇒ ∀A B C. arrow X (A · B · C) (A · (B · C)) alfa_L:\n⊢ arrow L (A · (B · C)) (A · B · C) alfa’_L:\n⊢ arrow L (A · B · C) (A · (B · C)) alfa_LP:\n⊢ arrow LP (A · (B · C)) (A · B · C) alfa’_LP:\n⊢ arrow LP (A · B · C) (A · (B · C))"
    }, {
      "heading" : "2.3 Associative Lambek Calculus",
      "text" : "For the original associative Lambek Calculus, we have proved all arrow theorems mentioned in Lambek (1958) [7]. All these theorems are named as L_ plus single letters (with optional prim). The first five are L axioms (but actually they’re proved from previous definition on the arrow relation:\nL_a: ⊢ arrow L x x L_b: ⊢ arrow L (x · y · z) (x · (y · z)) L_b’: ⊢ arrow L (x · (y · z)) (x · y · z) L_c: ⊢ arrow L (x · y) z ⇒ arrow L x (z / y) L_c’: ⊢ arrow L (x · y) z ⇒ arrow L y (x \\ z) L_d: ⊢ arrow L x (z / y) ⇒ arrow L (x · y) z L_d’: ⊢ arrow L y (x \\ z) ⇒ arrow L (x · y) z L_e: ⊢ arrow L x y ∧ arrow L y z ⇒ arrow L x z\nBased on these axioms, the rest L theorems about arrow relations can easily be proved by automatic first-order proof searching:\nL_f: ⊢ arrow L x (x · y / y) L_g: ⊢ arrow L (z / y · y) z L_h: ⊢ arrow L y ((z / y) \\ z) L_i: ⊢ arrow L (z / y · (y / x)) (z / x) L_j: ⊢ arrow L (z / y) (z / x / (y / x)) L_k: ⊢ arrow L (x \\ y / z) (x \\ (y / z)) L_k’: ⊢ arrow L (x \\ (y / z)) (x \\ y / z) L_l: ⊢ arrow L (x / y / z) (x / (z · y)) L_l’: ⊢ arrow L (x / (z · y)) (x / y / z) L_m: ⊢ arrow L x x ′ ∧ arrow L y y ′ ⇒ arrow L (x · y) (x ′ · y ′) L_n: ⊢ arrow L x x ′ ∧ arrow L y y ′ ⇒ arrow L (x / y ′) (x ′ / y)\nFinally, the monotone theorems specific to L are proved:\nL_dot_mono_r:\n⊢ arrow L B B ′ ⇒ arrow L (A · B) (A · B ′) L_dot_mono_l:\n⊢ arrow L A A′ ⇒ arrow L (A · B) (A′ · B) L_slash_mono_l:\n⊢ arrow L C C ′ ⇒ arrow L (C / B) (C ′ / B) L_slash_antimono_r:\n⊢ arrow L B B ′ ⇒ arrow L (C / B ′) (C / B) L_backslash_antimono_l:\n⊢ arrow L A A′ ⇒ arrow L (A′ \\ C) (A \\ C) L_backslash_mono_r:\n⊢ arrow L C C ′ ⇒ arrow L (A \\ C) (A \\ C ′)\nThe main problem of axiomatic syntactic calculus is that, for complicated categories, it’s not easy to “find” the proofs. Automatic proof searching also doesn’t work here, because the searching space is infinite. Further more, the arrow relation is not a reduction, because there’s no congruence here: if a sub-formula is known to have another category, we can’t just replace that sub-formula and expect the whole formula still has the same category. Thus in practice, we have to use other deduction systems which is more convinence for manual proofs or automatic proofs. But for what ever other deduction systems, to be useful they must be proved to be equivalent with Syntactic calculus."
    }, {
      "heading" : "2.4 Natural Deduction for Lambek Calculus",
      "text" : "Natural deduction was first invented by Dag Prawitz [14] as a non-semantic approach to derive propositional logic formulae.9 From a structure view, Natural deduction is nothing but a group of inference rules, each concerns about the introduction or eliminatiob of a logic connective. Natural deduction is indeed natural: it’s successfully adopted in hand-proofs and also the primitive deduction systems of many theorem provers.\nNatural deduction has two styles, the original Prawitz style and the Gentzen style (which is borrowed from Genzen’s Sequent Calculus, we’ll talk about this in next section). The two styles are not totally equivalent in expressive power, sometimes the Prawitz style is unnatural to express certain logic extensions. Thus, in Lambek Calculus, most of time, only the Gentzen style of Natural Deduction is used, and when we’re talking “Natural deduction” in this paper, we always refer to its Gentzen style.\nThe basic unit in Natural Deduction (in Gentzen style) is based on the concept of Sequent which represents a statement of the calculus in the following form:\nA1, A2, . . . , An ⊢ C\nIf we think the whole statement as a theorem, then C is the conclusion, and A1, A2, . . . , An is a list of hypotheses or assumptions in which their orders are irrelevant. In terminalogy of sequents, such a list is called the antecedent, or the hypotheses of the statement. The purpose of inference rules is to derive new statements from existing statements.\nTo adopt Natural Deduction for Lambek Calculus, especially the non-associative version, two steps are done here:\n1. The arrow relation between two categories, i.e. A −→ B, is now represented by logic theorem A ⇒ B, and then a sequent A ⊢ B, which means by assuming A we can prove B. 2. A sentence as a string of categories of each words, is now represented as the antecedentsA1, A2, . . . , An of a sequent. However, now the order is essential (for Lambek calculus without P). And for Lambek calculus based on NL, the binary bracketing is also necessary.\nTo represent sentence structures as binary trees, a new data structure called Term is now defined in HOL4:\nDatatype ‘Term = OneForm (’a Form ) | Comma Term Term ‘;\nNotice the similarity between the Comma connective between two Terms and the Dot connective between two Forms. In fact, most of times they’re convertable from each others, but it’s Comma representing the boundary of categories of words. To translate a Term into Form, a recursive function called deltaTranslation is defined as follows10:\n⊢ (∀ f . deltaTranslation (OneForm f ) = f ) ∧ ∀ t1 t2. deltaTranslation (Comma t1 t2) = deltaTranslation t1 · deltaTranslation t2\nSimiar to arrow extensions, which is a 2-ary relation between Terms, now we have another kind of extensions, called Sequent extensions or gentzen_extension, which is again abbreviated type as 2-ary relation between Terms:\ntype_abbrev (\"gentzen_extension \", ‘‘:’a Term -> ’a Term -> bool ‘‘);\nSequent extensions for L, NL, NLP and LP are defined as follows:\n⊢ NL_Sequent = ⊢ NLP_Sequent (Comma A B) (Comma B A) ⊢ (∀A B C.\nL_Sequent (Comma A (Comma B C)) (Comma (Comma A B) C)) ∧ ∀A B C. L_Sequent (Comma (Comma A B) C) (Comma A (Comma B C))\n⊢ LP_Sequent = add_extension NLP_Sequent L_Sequent\n9 the semantic approach is to build a truth table to explicitly check if the given formula is true for all possible combinations of boolean values for each variables\n10 The reverse translation is not unique, and it’s not needed to have such translations.\nTo define the inference rules for Natural Deduction, we still need one more device: the ability to replace the sub-formula of a Term into another Term:\n⊢ (∀F1 F2. replace F1 F2 F1 F2) ∧ (∀Gamma1 Gamma2 Delta F1 F2.\nreplace Gamma1 Gamma2 F1 F2 ⇒ replace (Comma Gamma1 Delta) (Comma Gamma2 Delta) F1\nF2) ∧ ∀Gamma1 Gamma2 Delta F1 F2. replace Gamma1 Gamma2 F1 F2 ⇒ replace (Comma Delta Gamma1) (Comma Delta Gamma2) F1 F2\nTherefore when replace A B C D is true, it means in Term A, there’s a sub-formula C, and by replacing it with D, we obtain B. In many papers, the Term A is actually A[C], and B is written as A[D].\nRelated to replace, if the goal is to just replace some Commas into Dots, there’s a simplified relation called replaceCommaDot. To define it, we first define its one-step version is called replaceCommaDot1:\n⊢ replace T1 T2 (Comma (OneForm A) (OneForm B)) (OneForm (A · B)) ⇒\nreplaceCommaDot1 T1 T2\nThen replaceCommaDot is nothing but the RTC of replaceCommaDot1:\n⊢ replaceCommaDot = replaceCommaDot1∗\nTo make these replace operators actually useful, we have proved many theorems about them (some have complicated proofs):\nreplaceTransitive’:\n⊢ replaceCommaDot T1 T2 ∧ replaceCommaDot T2 T3 ⇒ replaceCommaDot T1 T3\nreplaceCommaDot_rules:\n⊢ (∀T. replaceCommaDot T T) ∧ (∀T1 T2 A B.\nreplace T1 T2 (Comma (OneForm A) (OneForm B)) (OneForm (A · B)) ⇒\nreplaceCommaDot T1 T2) ∧ (∀T1 T2 T3 A B.\nreplaceCommaDot T1 T2 ∧ replace T2 T3 (Comma (OneForm A) (OneForm B)) (OneForm (A · B)) ⇒\nreplaceCommaDot T1 T3) ∧ ∀T1 T2 T3 A B. replace T1 T2 (Comma (OneForm A) (OneForm B)) (OneForm (A · B)) ∧ replaceCommaDot T2 T3 ⇒\nreplaceCommaDot T1 T3 replaceMonoRight:\n⊢ replaceCommaDot T1 T2 ⇒ replaceCommaDot (Comma T1 T3) (Comma T2 T3)\nreplaceMonoLeft:\n⊢ replaceCommaDot T1 T2 ⇒ replaceCommaDot (Comma T3 T1) (Comma T3 T2)\nreplaceMono:\n⊢ replaceCommaDot T1 T2 ∧ replaceCommaDot T3 T4 ⇒ replaceCommaDot (Comma T1 T3) (Comma T2 T4)\nreplaceTranslation:\n⊢ replaceCommaDot T (OneForm (deltaTranslation T)) replace_inv1:\n⊢ replace (OneForm C) Gamma′ (OneForm X ) Delta ⇒ (Gamma′ = Delta) ∧ (X = C)\nreplace_inv2:\n⊢ replace (Comma Gamma1 Gamma2) Gamma ′ (OneForm X ) Delta ⇒\n(∃G. (Gamma′ = Comma G Gamma2) ∧ replace Gamma1 G (OneForm X ) Delta) ∨ ∃G. (Gamma′ = Comma Gamma1 G) ∧ replace Gamma2 G (OneForm X ) Delta\ndoubleReplace:\n⊢ replace Gamma Gamma′ T1 T2 ⇒ ∀Gamma2 A T3. replace Gamma′ Gamma2 (OneForm A) T3 ⇒ (∃G.\nreplace Gamma G (OneForm A) T3 ∧ replace G Gamma2 T1 T2) ∨\n∃G. replace T2 G (OneForm A) T3 ∧ replace Gamma Gamma2 T1 G\nreplaceSameP:\n⊢ replace T1 T2 T3 T4 ⇒ ∀G. ∃G ′. replace T1 G ′ T3 G ∧ replace G ′ T2 G T4\nreplaceTrans:\n⊢ replace T1 T2 T3 T4 ⇒ replace T3 T4 T5 T6 ⇒ replace T1 T2 T5 T6\nThe replace theorems about three deduction systems are more difficult to prove:\nreplace_arrow:\n⊢ replace Gamma Gamma′ T1 T2 ⇒ arrow X (deltaTranslation T2) (deltaTranslation T1) ⇒ arrow X (deltaTranslation Gamma′) (deltaTranslation Gamma)\nreplace_arrow’:\n⊢ replace Gamma Gamma′ T1 T2 ⇒ arrow X (deltaTranslation T2) (deltaTranslation T1) ⇒ arrow X (deltaTranslation Gamma) C ⇒ arrow X (deltaTranslation Gamma′) C\nreplaceGentzen:\n⊢ replace Gamma Gamma′ Delta Delta′ ⇒ gentzenSequent E Delta′ (deltaTranslation Delta) ⇒ gentzenSequent E Gamma′ (deltaTranslation Gamma)\nreplaceGentzen’:\n⊢ replace Gamma Gamma′ Delta Delta′ ∧ gentzenSequent E Delta′ (deltaTranslation Delta) ∧ gentzenSequent E Gamma C ⇒ gentzenSequent E Gamma′ C\nreplaceNatDed:\n⊢ replace Gamma Gamma′ Delta Delta′ ⇒ natDed E Delta′ (deltaTranslation Delta) ⇒ natDed E Gamma′ (deltaTranslation Gamma)\nNow we use natDed E Gamma A to represent Gamma ⊢ A under extension E. The type of natDed is “α gentzen_extension -> α Term -> α Form -> bool”. And the inference rules about Natural Deduction on Lambek Calculus are defined by an inductive relation and then broken into the following separated rules:\nNatAxiom:\n⊢ natDed E (OneForm A) A SlashIntro:\n⊢ natDed E (Comma Gamma (OneForm B)) A ⇒ natDed E Gamma (A / B)\nBackslashIntro:\n⊢ natDed E (Comma (OneForm B) Gamma) A ⇒ natDed E Gamma (B \\ A)\nDotIntro:\n⊢ natDed E Gamma A ∧ natDed E Delta B ⇒ natDed E (Comma Gamma Delta) (A · B)\nSlashElim:\n⊢ natDed E Gamma (A / B) ∧ natDed E Delta B ⇒ natDed E (Comma Gamma Delta) A\nBackslashElim:\n⊢ natDed E Gamma B ∧ natDed E Delta (B \\ A) ⇒ natDed E (Comma Gamma Delta) A\nDotElim:\n⊢ replace Gamma Gamma′ (Comma (OneForm A) (OneForm B)) Delta ∧ natDed E Delta (A · B) ∧ natDed E Gamma C ⇒ natDed E Gamma′ C\nNatExt:\n⊢ replace Gamma Gamma′ Delta Delta′ ∧ E Delta Delta′ ∧ natDed E Gamma C ⇒ natDed E Gamma′ C\nThese natural deduction rules are quite similar with those arrow rules of Syntactic Calculus. And the elimination rules SlashElim and BackslashElim are even more close to AB grammar rules. Besides, replace operations only appear in DotElim and NatExt rules. All these characteristics made natural deduction easier to use for proving facts about Lambek Calculus.\nWe have proved a few theorems as simplified version of above primitive rules, sometimes it’s easier to use them instead of the primitive rules:\nNatAxiomGeneralized:\n⊢ natDed E Gamma (deltaTranslation Gamma) DotElimGeneralized:\n⊢ replaceCommaDot Gamma Gamma′ ⇒ natDed E Gamma C ⇒ natDed E Gamma′ C\nNatTermToForm:\n⊢ natDed E Gamma C ⇒ natDed E (OneForm (deltaTranslation Gamma)) C\nNatExtSimpl:\n⊢ E Gamma Gamma′ ∧ natDed E Gamma C ⇒ natDed E Gamma′ C\nThe main problem for Natural Deduction is the lacking of decision procedures. When proving any theorem in backward way, one has to “guess” many unknown variables to correctly apply those elimination rules. To see this, let’s take a look at one elimination rules, e. g. SlashElim:\n⊢ natDed E Gamma (A / B) ∧ natDed E Delta B ⇒ natDed E (Comma Gamma Delta) A\nIn this rule, variable B only appears in the antecedents but the conclusion, and when applying this rule from backwards, we have to guess out the value of B, and different values of B may completely change the rest proofs (only the correct guess can lead to a success proof). Thus, automatic proof searching based on these Natural deduction rules are impossible. But if our final goal is to get a langauge parser, we have to have a more reasonable set of rules in which there’s essential no guess (this is the so-called “sub-formula property” in sequent calculus, we’ll get to this property later).\nThus, to make both manual proving and automatic proof searching possible, now we represent the final solution for the inference system of Lambek Calculus: the Gentzen’s Sequent Calculus."
    }, {
      "heading" : "2.5 Gentzen’s Sequent Calculus for Lambek Calculus",
      "text" : "Sequent Calculus was original introduced by Gerhard Gentzen in two German papers [15] [16] written in 1935. It’s a great achievements in the proof theory of classical and intuitionistic logic. To understnad its\ndifference with Natural Deduction, it’s better to watch directly the inference rules for Lambek Calculus. In our implementation, the Sequent Calculus is defined through an inductive definition of the relation gentzenSequent which has the same type as previous natDed relation. Here are its inference rules:\nSeqAxiom:\n⊢ gentzenSequent E (OneForm A) A RightSlash:\n⊢ gentzenSequent E (Comma Gamma (OneForm B)) A ⇒ gentzenSequent E Gamma (A / B)\nRightBackslash:\n⊢ gentzenSequent E (Comma (OneForm B) Gamma) A ⇒ gentzenSequent E Gamma (B \\ A)\nRightDot:\n⊢ gentzenSequent E Gamma A ∧ gentzenSequent E Delta B ⇒ gentzenSequent E (Comma Gamma Delta) (A · B)\nLeftSlash:\n⊢ replace Gamma Gamma′ (OneForm A) (Comma (OneForm (A / B)) Delta) ∧\ngentzenSequent E Delta B ∧ gentzenSequent E Gamma C ⇒ gentzenSequent E Gamma′ C\nLeftBackslash:\n⊢ replace Gamma Gamma′ (OneForm A) (Comma Delta (OneForm (B \\ A))) ∧\ngentzenSequent E Delta B ∧ gentzenSequent E Gamma C ⇒ gentzenSequent E Gamma′ C\nLeftDot:\n⊢ replace Gamma Gamma′ (Comma (OneForm A) (OneForm B)) (OneForm (A · B)) ∧ gentzenSequent E Gamma C ⇒\ngentzenSequent E Gamma′ C CutRule:\n⊢ replace Gamma Gamma′ (OneForm A) Delta ∧ gentzenSequent E Delta A ∧ gentzenSequent E Gamma C ⇒ gentzenSequent E Gamma′ C\nSeqExt:\n⊢ replace Gamma Gamma′ Delta Delta′ ∧ E Delta Delta′ ∧ gentzenSequent E Gamma C ⇒ gentzenSequent E Gamma′ C\nComparing with Natural Deduction rules, the following differences are notable:\n1. For each of the three connectives (·, / and \\), there’re Left and Right rules for them; For Natural deduction, instead they’re Introduction and Elimination rules. 2. Except for the different relation name, the rule SeqAxiom is the same as NatAxiom, RightSlash is the same as SlashIntro, RightBackslash is the same as BackslashIntro, RightDot is the same as DotIntro, and finally the rule SeqExt is the same as NatExt. 3. All Left rules are new, and they all make use of the replace predicates. And the result of these rules is to introduce one of the three connectives in the antecedents without changing the conclusion. 4. The rule CutRule is new in Sequent Calculus, it’s not present in Natural Deduction, nor can be proved in Natural Deduction.\nBeside above observations, there’s one more important fact:\n– All rules except for CutRule satisfy the so-called “sub-formula property”, that is, all variables in the antecedents are sub-formulae of the conclusion.\nTo see why this is true, let’s take a deeper look at LeftSlash:\n⊢ replace Gamma Gamma′ (OneForm A) (Comma (OneForm (A / B)) Delta) ∧\ngentzenSequent E Delta B ∧ gentzenSequent E Gamma C ⇒ gentzenSequent E Gamma′ C\nIf we consider the meaning of replace, we may rewrite this rule into the following form:\nDelta ⊢ B Gamma[A] ⊢ C (LeftSlash)\nGamma[(A/B,Delta)] ⊢ C\nTo some extents, this rule is just saying A/B · B → A as in AB grammar. What’s more important is the fact that, all variables appearing in the conclusion, i.e. Gamma, A, B, Delta and C, are variables borrowing from antecedents. The same fact is true for all other gentzenSequent rules, except for CutRule:\nDelta ⊢ A Gamma[A] ⊢ C (CutRule)\nGamma[Delta] ⊢ C\nin which the variable A appears only in antecedents but conclusion. The sub-formula property is extremely useful for automatic proof searching, because there’s nothing to guess when applying these rules from backwards. Based on above primitive inference rules, we have proved a large amount of derived theorems which is true for all Lambek calculus (i. e. extended from NL):\nSeqAxiomGeneralized:\n⊢ gentzenSequent E Gamma (deltaTranslation Gamma) LeftDotSimpl:\n⊢ gentzenSequent E (Comma (OneForm A) (OneForm B)) C ⇒ gentzenSequent E (OneForm (A · B)) C\nLeftDotGeneralized:\n⊢ replaceCommaDot T1 T2 ⇒ gentzenSequent E T1 C ⇒ gentzenSequent E T2 C\nSeqTermToForm:\n⊢ gentzenSequent E Gamma C ⇒ gentzenSequent E (OneForm (deltaTranslation Gamma)) C\nLeftSlashSimpl:\n⊢ gentzenSequent E Gamma B ∧ gentzenSequent E (OneForm A) C ⇒ gentzenSequent E (Comma (OneForm (A / B)) Gamma) C\nLeftBackslashSimpl:\n⊢ gentzenSequent E Gamma B ∧ gentzenSequent E (OneForm A) C ⇒ gentzenSequent E (Comma Gamma (OneForm (B \\ A))) C\nCutRuleSimpl:\n⊢ gentzenSequent E Gamma A ∧ gentzenSequent E (OneForm A) C ⇒ gentzenSequent E Gamma C\nDotRightSlash’:\n⊢ gentzenSequent E (OneForm A) (C / B) ⇒ gentzenSequent E (OneForm (A · B)) C\nDotRightBackslash’:\n⊢ gentzenSequent E (OneForm B) (A \\ C) ⇒ gentzenSequent E (OneForm (A · B)) C\nSeqExtSimpl:\n⊢ E Gamma Gamma′ ∧ gentzenSequent E Gamma C ⇒ gentzenSequent E Gamma′ C\napplication:\n⊢ gentzenSequent E (OneForm (A / B · B)) A application’:\n⊢ gentzenSequent E (OneForm (B · B \\ A)) A RightSlashDot:\n⊢ gentzenSequent E (OneForm (A · C)) B ⇒ gentzenSequent E (OneForm A) (B / C)\nRightBackslashDot:\n⊢ gentzenSequent E (OneForm (B · A)) C ⇒ gentzenSequent E (OneForm A) (B \\ C)\ncoApplication:\n⊢ gentzenSequent E (OneForm A) (A · B / B)\ncoApplication’:\n⊢ gentzenSequent E (OneForm A) (B \\ (B · A)) mono_E:\n⊢ gentzenSequent E Gamma A ⇒ extends E E ′ ⇒ gentzenSequent E ′ Gamma A\nmonotonicity:\n⊢ gentzenSequent E (OneForm A) B ∧ gentzenSequent E (OneForm C) D ⇒ gentzenSequent E (OneForm (A · C)) (B · D)\nisotonicity:\n⊢ gentzenSequent E (OneForm A) B ⇒ gentzenSequent E (OneForm (A / C)) (B / C)\nisotonicity’:\n⊢ gentzenSequent E (OneForm A) B ⇒ gentzenSequent E (OneForm (C \\ A)) (C \\ B)\nantitonicity:\n⊢ gentzenSequent E (OneForm A) B ⇒ gentzenSequent E (OneForm (C / B)) (C / A)\nantitonicity’:\n⊢ gentzenSequent E (OneForm A) B ⇒ gentzenSequent E (OneForm (B \\ C)) (A \\ C)\nlifting:\n⊢ gentzenSequent E (OneForm A) (B / A \\ B) lifting’:\n⊢ gentzenSequent E (OneForm A) ((B / A) \\ B)\nFor Lambek Calculus extended from L,which supports associativity, we have proved some extra theorems:\nLextensionSimpl:\n⊢ extends L_Sequent E ∧ gentzenSequent E (Comma T1 (Comma T2 T3)) C ⇒ gentzenSequent E (Comma (Comma T1 T2) T3) C\nLextensionSimpl’:\n⊢ extends L_Sequent E ∧ gentzenSequent E (Comma (Comma T1 T2) T3) C ⇒ gentzenSequent E (Comma T1 (Comma T2 T3)) C\nLextensionSimplDot:\n⊢ extends L_Sequent E ∧ gentzenSequent E (OneForm (A · (B · C))) D ⇒ gentzenSequent E (OneForm (A · B · C)) D\nLextensionSimplDot’:\n⊢ extends L_Sequent E ∧ gentzenSequent E (OneForm (A · B · C)) D ⇒ gentzenSequent E (OneForm (A · (B · C))) D\nmainGeach:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm (A / B)) (A / C / (B / C))\nmainGeach’:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm (B \\ A)) ((C \\ B) \\ C \\ A)\nsecondaryGeach:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm (B / C)) ((A / B) \\ (A / C))\nsecondaryGeach’:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm (C \\ B)) (C \\ A / B \\ A)\ncomposition:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm (A / B · (B / C))) (A / C)\ncomposition’:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm (C \\ B · B \\ A)) (C \\ A)\nrestructuring:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm (A \\ B / C)) (A \\ (B / C))\nrestructuring’:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm (A \\ (B / C))) (A \\ B / C)\ncurrying:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm (A / (B · C))) (A / C / B)\ncurrying’:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm (A / C / B)) (A / (B · C))\ndecurrying:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm ((A · B) \\ C)) (B \\ A \\ C)\ndecurrying’:\n⊢ extends L_Sequent E ⇒ gentzenSequent E (OneForm (B \\ A \\ C)) ((A · B) \\ C)\nFor Lambek Calculus extended from NLP, which supports both commutativity we have proved the following extra theorems:\nNLPextensionSimpl:\n⊢ extends NLP_Sequent E ∧ gentzenSequent E (Comma T1 T2) C ⇒ gentzenSequent E (Comma T2 T1) C\nNLPextensionSimplDot:\n⊢ extends NLP_Sequent E ∧ gentzenSequent E (OneForm (A · B)) C ⇒ gentzenSequent E (OneForm (B · A)) C\npermutation:\n⊢ extends NLP_Sequent E ⇒ gentzenSequent E (OneForm A) (B \\ C) ⇒ gentzenSequent E (OneForm B) (A \\ C)\nexchange:\n⊢ extends NLP_Sequent E ⇒ gentzenSequent E (OneForm (A / B)) (B \\ A)\nexchange’:\n⊢ extends NLP_Sequent E ⇒ gentzenSequent E (OneForm (B \\ A)) (A / B)\npreposing:\n⊢ extends NLP_Sequent E ⇒ gentzenSequent E (OneForm A) (B / (B / A))\npostposing:\n⊢ extends NLP_Sequent E ⇒ gentzenSequent E (OneForm A) ((A \\ B) \\ B)\nFor Lambek Calculus extended from LP, which supports both commutativity and associativity, we have proved the following theorems:\nmixedComposition:\n⊢ extends LP_Sequent E ⇒ gentzenSequent E (OneForm (A / B · C \\ B)) (C \\ A)\nmixedComposition’:\n⊢ extends LP_Sequent E ⇒ gentzenSequent E (OneForm (B / C · B \\ A)) (A / C)"
    }, {
      "heading" : "3 Equivalences between three deduction systems",
      "text" : "So far we have introduced three deduction systems for Lambek Calculus: (axiomatic) syntactic calculus, natural deduction and gentzen’s sequent calculus. The convincing of syntactic calculus comes from intuition and the fact that all axiom rules are extremely simple, while the correctness of natural deduction rules and sequent calculus rules is not that clear. Before fully switching to use natural deduction or sequent calculus as the alternative deduction system, we have to prove the equivalences between them and the original syntactic calculus."
    }, {
      "heading" : "3.1 Equivalence between Syntactic Calculus and Sequent Calculus",
      "text" : "By equivalence, basically we want to know if any theorem about categories in arrow relation has also a proof in natural deduction and sequent calculus, and conversely if any theorems in latter systems has also a proof in syntactac calculus. In another words, the set of theorems about syntactic categories proven in these three deduction systems are exactly the same. However, there’re two difficulties we must resolve first:\n1. the corresponce between arrow extensions (from Form to Form) and gentzen extensions (from Term to Term) must be defined and proved. 2. There’s unique translation from Term to Form, but the other direction is not unique.\nThe first problem are handled in two directions: from arrow to gentzen extensions, then from genzen to arrow extensions. In the first direction we have the following definition:\n⊢ arrowToGentzenExt X E ⇐⇒ ∀A B. X A B ⇒ gentzenSequent E (OneForm A) B\nNoticed that, this is not a function mapping any arrow extension to a gentzen extension, instead we need to use gentzenSequent relation to handle the OneForm quoting of the first parameter of arrow extension. Based on this definition, we have proved the correspondences between arrow and gentzen extensions for NL, L, NLP, LP:\nNLToNL_Sequent:\n⊢ arrowToGentzenExt NL NL_Sequent NLPToNLP_Sequent:\n⊢ arrowToGentzenExt NLP NLP_Sequent LToL_Sequent:\n⊢ arrowToGentzenExt L L_Sequent LPToLP_Sequent:\n⊢ arrowToGentzenExt LP LP_Sequent\nThe other direction is more subtle. From gentzen extension to arrow extension, since the translation from Term to Form is unique, the relationship between two kind of extensions can be defined just by characteristics of themselves:\n⊢ gentzenToArrowExt E X ⇐⇒ ∀T1 T2.\nE T1 T2 ⇒ X (deltaTranslation T2) (deltaTranslation T1)\nHowever, noticed the interesting part: instead of saying E T1 T2 ⇒ X (deltaTranslation T1) (deltaTranslation T we must use swap the order of deltaTranslation T1 and deltaTranslation T2. The reason seems connected with the CutRule, and without defing like this we can’t prove the equivalece between the three deduction systems. However, we do can prove correspondences between arrow and gentzen extensions for NL, L, NLP, LP and other general results using this definition:\nNL_SequentToNL:\n⊢ gentzenToArrowExt NL_Sequent NL NLP_SequentToNLP:\n⊢ gentzenToArrowExt NLP_Sequent NLP L_SequentToL:\n⊢ gentzenToArrowExt L_Sequent L LP_SequentToLP:\n⊢ gentzenToArrowExt LP_Sequent LP\nAlso noticed that, in the definition of gentzenToArrowExt, when the gentzen extension contains more contents (i.e. more pairs of Terms satisfy the relation) then what’s required by arrow extension, the whole definition is still satisfied. To actually define a function which precisely translate a gentzen extension into unique arrow extension and make sure the resulting arrow extension satisfy the definition of gentzenToArrowExt, we can define this function like this:\n⊢ ToArrowExt E = CURRY\n{(deltaTranslation y,deltaTranslation x) | (x,y) ∈ UNCURRY E }\nHere we used HOL4’s set theory package, and the use of CURRY and UNCURRY is to converse between standard mathemics definition of relations (with type “α Form · α Form -> bool”) and relations in higher order logics (with type “α arrow_extension”. We can prove that, the output of this function indeed satisfy the definition of gentzenToArrowExt:\ngentzenToArrowExt_thm:\n⊢ gentzenToArrowExt E (ToArrowExt E)\nWith all above devices, now the equivalences between (axiomatic) syntactic calculus and gentzen’s Sequent calculus and their common extensions have been proved by the following theorems:\narrowToGentzen:\n⊢ arrow X A B ⇒ arrowToGentzenExt X E ⇒ gentzenSequent E (OneForm A) B\narrowToGentzenNL:\n⊢ arrow NL A B ⇒ gentzenSequent NL_Sequent (OneForm A) B arrowToGentzenNLP:\n⊢ arrow NLP A B ⇒ gentzenSequent NLP_Sequent (OneForm A) B arrowToGentzenL:\n⊢ arrow L A B ⇒ gentzenSequent L_Sequent (OneForm A) B arrowToGentzenLP:\n⊢ arrow LP A B ⇒ gentzenSequent LP_Sequent (OneForm A) B\ngentzenToArrow:\n⊢ gentzenToArrowExt E X ∧ gentzenSequent E Gamma A ⇒ arrow X (deltaTranslation Gamma) A\nNLGentzenToArrow:\n⊢ gentzenSequent NL_Sequent Gamma A ⇒ arrow NL (deltaTranslation Gamma) A\nNLPGentzenToArrow:\n⊢ gentzenSequent NLP_Sequent Gamma A ⇒ arrow NLP (deltaTranslation Gamma) A\nLGentzenToArrow:\n⊢ gentzenSequent L_Sequent Gamma A ⇒ arrow L (deltaTranslation Gamma) A\nLPGentzenToArrow:\n⊢ gentzenSequent LP_Sequent Gamma A ⇒ arrow LP (deltaTranslation Gamma) A\nThis means, if we translated all Comma into Dots, gentzen’s Sequent Calculus actually doesn’t prove anything new beyond the Syntactic Calculus, although it has more rules, especially the CutRule."
    }, {
      "heading" : "3.2 Equivalence between Natural Deduction and Sequent Calculus",
      "text" : "Surprisely, the equivalance between Natural Deduction and Sequent Calculus requires extra assumptions about properties on gentzen extensions. Generally speaking, without any restriction on gentzen extension, Gentzen’s sequent calculus has a larger theorem set, therefore is stronger than Natural Deduction.\nFrom Natural Deduction to Sequence Calculus, i.e. the easy direction, we can prove the following theorem by induction on the structure of gentzenSequent relation:\nnatDedToGentzen:\n⊢ natDed E Gamma C ⇒ gentzenSequent E Gamma C\nThe other direction is more difficult to prove, and it contains an extra property called condCutExt about the extensions. First we present directly the following important result:\ngentzenToNatDed:\n⊢ gentzenSequent E Gamma C ⇒ condCutExt E ⇒ natDed E Gamma C\nits the formal proof of this theorem is the longest proof in our LambekTheory, and to successfully prove it, many lemmas are needed.\nThe definition of condCutExt used in above theorem is defined as follows:\n⊢ condCutExt E ⇐⇒ ∀Gamma T1 T2 A Delta.\nE T1 T2 ⇒ replace T2 Gamma (OneForm A) Delta ⇒ ∃Gamma′.\nE Gamma′ Gamma ∧ replace T1 Gamma ′ (OneForm A) Delta\nto understand the precise meaning of this definition, we may consider the meaning of the replace operator and rewrite above definition into the following mathematic definition:\nE T1[A] T2[A] =⇒ ∃T1[Delta]. E T1[Delta] T2[Delta]\nThis seems like a kind of completeness of the arrow extension: whenever we replace any OneForm term into another Term in the pairs satisfying the gentzen extension, the resulting pairs must also satisfy this extension. However, whenever the definition of extension concerns only about Commas, like in L_Sequent_def and others, this condition is naturally satisfied: (although the formal proofs are quite long for some of them)\nconditionOKNL:\n⊢ condCutExt NL_Sequent conditionOKNLP:\n⊢ condCutExt NLP_Sequent conditionOKL:\n⊢ condCutExt L_Sequent\nBesides, we have proved that, if two gentzen extensions both satisfy above condCutExt property, so is their sum relation:\ncondAddExt:\n⊢ condCutExt E ∧ condCutExt E ′ ⇒ condCutExt (add_extension E E ′)\nThe formal proofs of gentzenToNatDed also depends on the following lemmas which themselves have long proofs:\nCutNatDed:\n⊢ natDed E Gamma C ⇒ condCutExt E ⇒ natDed E Delta A ⇒ ∀Gamma′. replace Gamma Gamma′ (OneForm A) Delta ⇒ natDed E Gamma′ C\nnatDedComposition:\n⊢ condCutExt E ∧ natDed E Gamma F1 ∧ natDed E (OneForm F1) F2 ⇒ natDed E Gamma F2\nFinally, we can merge the two direction together and get the following equivalence theorems about natural deduction and gentzen’s sequent calculus for Lambek Calculus (both general and special cases), although they’re not used anywhere so far:\ngentzenEqNatDed:\n⊢ condCutExt E ⇒ (gentzenSequent E Gamma C ⇐⇒ natDed E Gamma C)\nNLgentzenEqNatDed:\n⊢ gentzenSequent NL_Sequent Gamma C ⇐⇒ natDed NL_Sequent Gamma C\nLgentzenEqNatDed:\n⊢ gentzenSequent L_Sequent Gamma C ⇐⇒ natDed L_Sequent Gamma C NLPgentzenEqNatDed:\n⊢ gentzenSequent NLP_Sequent Gamma C ⇐⇒ natDed NLP_Sequent Gamma C"
    }, {
      "heading" : "3.3 Equivalence between Syntactic Calculus and Natural Deduction",
      "text" : "Combining results from previous two sections, the equivalence between Syntactic Calculus and Natural Deduction can be easily proved with gentzen’s Sequent Calculus as intermediate steps:\nnatDedToArrow:\n⊢ gentzenToArrowExt E X ⇒ natDed E Gamma A ⇒ arrow X (deltaTranslation Gamma) A\nnatDedToArrow_E:\n⊢ natDed E Gamma A ⇒ arrow (ToArrowExt E) (deltaTranslation Gamma) A\narrowToNatDed:\n⊢ condCutExt E ∧ arrowToGentzenExt X E ∧ arrow X A B ⇒ natDed E (OneForm A) B\nThere seems no way to get equivalence theorems between Syntactic Calculus and Natural Deduction/Sequent Calculus, because of the translations between Terms and Forms."
    }, {
      "heading" : "4 A proof-theoretic formalization of Sequent Calculus",
      "text" : "Above formalizations for Lambek Calculus may have provided a good basis for proving theorems about categories using any of the three deduction systems, but one can only do this manually. For the following two purposes, the current work is not enough:\n1. Proving theorems about Sequent Calculus proofs, e. g. the cut-elimination theorem (for any Sequent Calculus proof, there exists a corresponding proof without using the CutRule). 2. Finding and generating Sequent Calculus proofs programmatically.\nFor any of above purpose, we need a data structure to represent a whole proof. HOL theorem prover has already provided data structures to represent terms and theorems, but there’s no built-in facility to represent a whole proof. In another word, a “proof” is not a first-class object in HOL.\nHowever, Coq has built-in support for first-class proof object. In Coq, it’s possible to define the “degree” of a gentzenSequent proof like this:\nFixpoint degreeProof (Atoms : Set) (Gamma : Term Atoms)\n(B : Form Atoms) (E : gentzen_extension ) (p : gentzenSequent E Gamma B) {struct p} : nat :=\nmatch p with | Ax _ => 0 | RightSlash _ _ _ H => degreeProof H | RightBackSlash _ _ _ H => degreeProof H | RightDot _ _ _ _ H1 H2 => max ( degreeProof H1) (degreeProof H2) | LeftSlash _ _ _ _ _ _ R H1 H2 => max (degreeProof H1) ( degreeProof H2) | LeftBackSlash _ _ _ _ _ _ R H1 H2 =>\nmax (degreeProof H1) (degreeProof H2)\n| LeftDot _ _ _ _ _ R H => degreeProof H | CutRule _ _ _ A _ R H1 H2 =>\nmax (max (degreeFormula A) ( degreeProof H1)) (degreeProof H2)\n| SequentExtension _ _ _ _ _ E R H => degreeProof H end.\nIn HOL, it’s impossible to defined the same thing directly, because gentzenSequent E Gamma B has the type bool. To fill the gaps, we have to model a proof by a proof tree ”object” by using a datatype definition. Our datatype definition is based on similar modelling work in Isabelle/HOL for Display Logic [17], then all other related inductive relation definitions and theorems are new. (But once the gaps are filled, those theorems in Coq has also the same internal structure in HOL."
    }, {
      "heading" : "4.1 Proof objects",
      "text" : "A proof object in Sequent Calculus is represented as a datatype called Dertree. A Dertree has at least a sequent as its head, and by applying a rule it’s derived from one or more other sequents. Thus Dertree is nothing but a tree of sequent with each node identified by a rule name. A Dertree as a proof can also be “unfinished”, and in this case it contains only a (unproved) sequent, nothing else:\nDatatype ‘Sequent = Sequent (’a gentzen_extension ) (’a Term ) (’a Form )‘; Datatype ‘Rule = SeqAxiom\n| RightSlash | RightBackslash | RightDot | LeftSlash | LeftBackslash | LeftDot | CutRule | SeqExt ‘;\nDatatype ‘Dertree = Der (’a Sequent) Rule (Dertree list )\n| Unf (’a Sequent )‘;\nHere the datatype Sequent is just a simple container of three inner objects: a gentzen extension, a Term and a Form. The datatype Rule is just an atomic symbol, which takes values from 9 possible rule names as primitive Sequent Calculus rules. So in our formal system, a sequent gentzenSequent E Gamma B has the type bool, there’s no way to access its internat structure, and when it can appears along as a theorem. On the other side a sequent Sequent E Gamma B has the type α Sequent, it’s just a container with accessors and its correctness has to be proved separately.\nWith above data structures, the following accessors are defined to access their internal structures:\n⊢ (∀ seq v0 v1. head (Der seq v0 v1) = seq) ∧ ∀ seq. head (Unf seq) = seq ⊢ (concl (Unf (Sequent E Delta A)) = A) ∧ (concl (Der (Sequent E Delta A) v0 v1) = A) ⊢ (prems (Unf (Sequent E Delta A)) = Delta) ∧ (prems (Der (Sequent E Delta A) v0 v1) = Delta) ⊢ (exten (Unf (Sequent E Delta A)) = E) ∧ (exten (Der (Sequent E Delta A) v0 v1) = E)\nAnd now we can define degreeProof as follows:\n⊢ (∀S. degreeProof (Der S SeqAxiom []) = 0) ∧ (∀S H . degreeProof (Der S RightSlash [H ]) = degreeProof H ) ∧ (∀S H .\ndegreeProof (Der S RightBackslash [H ]) = degreeProof H ) ∧ (∀S H2 H1.\ndegreeProof (Der S RightDot [H1; H2]) = MAX (degreeProof H1) (degreeProof H2)) ∧ (∀S H2 H1. degreeProof (Der S LeftSlash [H1; H2]) = MAX (degreeProof H1) (degreeProof H2)) ∧ (∀S H2 H1. degreeProof (Der S LeftBackslash [H1; H2]) = MAX (degreeProof H1) (degreeProof H2)) ∧ (∀S H . degreeProof (Der S LeftDot [H ]) = degreeProof H ) ∧ (∀S H . degreeProof (Der S SeqExt [H ]) = degreeProof H ) ∧ ∀S H2 H1. degreeProof (Der S CutRule [H1; H2]) = MAX (degreeFormula (concl H1)) (MAX (degreeProof H1) (degreeProof H2))\nAnother closely related concept is the degreeFormulawhich assign each Form as integer as its degree:\n⊢ (∀C. degreeFormula (At C) = 1) ∧ (∀F1 F2.\ndegreeFormula (F1 / F2) = SUC (MAX (degreeFormula F1) (degreeFormula F2))) ∧ (∀F1 F2. degreeFormula (F1 \\ F2) = SUC (MAX (degreeFormula F1) (degreeFormula F2))) ∧ ∀F1 F2. degreeFormula (F1 · F2) = SUC (MAX (degreeFormula F1) (degreeFormula F2))\nThe concept of sub-formula between two Forms that we mentioned several times in previous sections, is now formally defined as an inductive relation:\n⊢ (∀A. subFormula A A) ∧ (∀A B C. subFormula A B ⇒ subFormula A (B / C)) ∧ (∀A B C. subFormula A B ⇒ subFormula A (C / B)) ∧ (∀A B C. subFormula A B ⇒ subFormula A (B \\ C)) ∧ (∀A B C. subFormula A B ⇒ subFormula A (C \\ B)) ∧ (∀A B C. subFormula A B ⇒ subFormula A (B · C)) ∧ ∀A B C. subFormula A B ⇒ subFormula A (C · B)\nAnd we have also proved many theorems about subFormula:\nsubAt:\n⊢ subFormula A (At a) ⇒ (A = At a) subSlash:\n⊢ subFormula A (B / C) ⇒ (A = B / C) ∨ subFormula A B ∨ subFormula A C\nsubBackslash:\n⊢ subFormula A (B \\ C) ⇒ (A = B \\ C) ∨ subFormula A B ∨ subFormula A C\nsubDot:\n⊢ subFormula A (B · C) ⇒ (A = B · C) ∨ subFormula A B ∨ subFormula A C\nsubFormulaTrans:\n⊢ subFormula A B ⇒ subFormula B C ⇒ subFormula A C\nThe sub-formula between a Form and a Term is called subFormTerm, which is defined inductively upon subFormula:\n⊢ (∀A B. subFormula A B ⇒ subFormTerm A (OneForm B)) ∧ (∀A T1 T2. subFormTerm A T1 ⇒ subFormTerm A (Comma T1 T2)) ∧ ∀A T1 T2. subFormTerm A T1 ⇒ subFormTerm A (Comma T2 T1)\nThen we have proved several important theorems about subFormTerm, most concering about the replace operator:\noneFormSubEQ:\n⊢ subFormTerm A (OneForm B) ⇐⇒ subFormula A B comSub:\n⊢ subFormTerm f (Comma T1 T2) ⇒ subFormTerm f T1 ∨ subFormTerm f T2\nsubReplace1:\n⊢ replace T1 T2 T3 T4 ⇒ subFormTerm f T3 ⇒ subFormTerm f T1 subReplace2:\n⊢ replace T1 T2 T3 T4 ⇒ subFormTerm f T4 ⇒ subFormTerm f T2 subReplace3:\n⊢ replace T1 T2 T3 T4 ⇒ subFormTerm X T1 ⇒ subFormTerm X T2 ∨ subFormTerm X T3"
    }, {
      "heading" : "4.2 Derivations of proof tree",
      "text" : "So how can we (manually) construct a proof for any theorem in Sequent calculus of Lambek Calculus and prove the resulting Dertree object is indeed a valid proof for this theorem? Unfortunately previous Coq proof scripts didn’t give any hint, for this part the author has built everything needed from the ground.\nThe idea comes from beta-reduction in λ-Calculus. First we define the one-step derivation from any unfinished Dertree by applying one rule which is equivalent with one of gentzenSequent rules:\n⊢ (∀E A. derivOne (Unf (Sequent E (OneForm A) A)) (Der (Sequent E (OneForm A) A) SeqAxiom [])) ∧\n(∀E Gamma A B. derivOne (Unf (Sequent E Gamma (A / B))) (Der (Sequent E Gamma (A / B)) RightSlash [Unf (Sequent E (Comma Gamma (OneForm B)) A)])) ∧ (∀E Gamma A B.\nderivOne (Unf (Sequent E Gamma (B \\ A))) (Der (Sequent E Gamma (B \\ A)) RightBackslash\n[Unf (Sequent E (Comma (OneForm B) Gamma) A)])) ∧ (∀E Gamma Delta A B.\nderivOne (Unf (Sequent E (Comma Gamma Delta) (A · B))) (Der (Sequent E (Comma Gamma Delta) (A · B)) RightDot\n[Unf (Sequent E Gamma A); Unf (Sequent E Delta B)])) ∧\n(∀E Gamma Gamma′ Delta A B C. replace Gamma Gamma′ (OneForm A) (Comma (OneForm (A / B)) Delta) ⇒\nderivOne (Unf (Sequent E Gamma′ C)) (Der (Sequent E Gamma′ C) LeftSlash\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta B)])) ∧\n(∀E Gamma Gamma′ Delta A B C. replace Gamma Gamma′ (OneForm A) (Comma Delta (OneForm (B \\ A))) ⇒\nderivOne (Unf (Sequent E Gamma′ C)) (Der (Sequent E Gamma′ C) LeftBackslash\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta B)])) ∧\n(∀E Gamma Gamma′ A B C. replace Gamma Gamma′ (Comma (OneForm A) (OneForm B)) (OneForm (A · B)) ⇒\nderivOne (Unf (Sequent E Gamma′ C)) (Der (Sequent E Gamma′ C) LeftDot\n[Unf (Sequent E Gamma C)])) ∧ (∀E Delta Gamma Gamma′ A C.\nreplace Gamma Gamma′ (OneForm A) Delta ⇒ derivOne (Unf (Sequent E Gamma′ C)) (Der (Sequent E Gamma′ C) CutRule\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta A)])) ∧\n∀E Gamma Gamma′ Delta Delta′ C. replace Gamma Gamma′ Delta Delta′ ∧ E Delta Delta′ ⇒ derivOne (Unf (Sequent E Gamma′ C)) (Der (Sequent E Gamma′ C) SeqExt\n[Unf (Sequent E Gamma C)])\nThe second step is to define “structure rules” as a new inductive relation deriv based on derivOne. With this relation, one can repeatly apply one-step derivation for all the unfinished sub-proofs in the derivation tree, until all leaves are finished:\n⊢ (∀D1 D2. derivOne D1 D2 ⇒ deriv D1 D2) ∧ (∀S R D1 D ′ 1.\nderiv D1 D ′ 1 ⇒ deriv (Der S R [D1]) (Der S R [D ′ 1 ])) ∧\n(∀S R D1 D ′ 1 D.\nderiv D1 D ′ 1 ⇒ deriv (Der S R [D1; D]) (Der S R [D ′ 1 ; D])) ∧\n(∀S R D2 D ′ 2 D. deriv D2 D ′ 2 ⇒\nderiv (Der S R [D; D2]) (Der S R [D; D ′ 2 ])) ∧\n∀S R D1 D ′ 1 D2 D ′ 2.\nderiv D1 D ′ 1 ∧ deriv D2 D ′ 2 ⇒ deriv (Der S R [D1; D2]) (Der S R [D ′ 1 ; D ′ 2 ])\nThe last step is to define the chain of derivations as a reduction, so that any two derivation trees are related with each other. This is done by defining a new relation Deriv as the reflexitive transitive closure (RTC) of deriv:\n⊢ Deriv = deriv∗\nMerging all above definitions together, we have proved all needed theorems for contructing a whole new proof tree, either manually or automatically:\n(One step rules) DerivSeqAxiom:\n⊢ Deriv (Unf (Sequent E (OneForm A) A)) (Der (Sequent E (OneForm A) A) SeqAxiom [])\nDerivRightSlash:\n⊢ Deriv (Unf (Sequent E Gamma (A / B))) (Der (Sequent E Gamma (A / B)) RightSlash\n[Unf (Sequent E (Comma Gamma (OneForm B)) A)]) DerivRightBackslash:\n⊢ Deriv (Unf (Sequent E Gamma (B \\ A))) (Der (Sequent E Gamma (B \\ A)) RightBackslash\n[Unf (Sequent E (Comma (OneForm B) Gamma) A)]) DerivRightDot:\n⊢ Deriv (Unf (Sequent E (Comma Gamma Delta) (A · B))) (Der (Sequent E (Comma Gamma Delta) (A · B)) RightDot\n[Unf (Sequent E Gamma A); Unf (Sequent E Delta B)]) DerivLeftSlash:\n⊢ replace Gamma Gamma′ (OneForm A) (Comma (OneForm (A / B)) Delta) ⇒\nDeriv (Unf (Sequent E Gamma′ C)) (Der (Sequent E Gamma′ C) LeftSlash\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta B)]) DerivLeftBackslash:\n⊢ replace Gamma Gamma′ (OneForm A) (Comma Delta (OneForm (B \\ A))) ⇒\nDeriv (Unf (Sequent E Gamma′ C)) (Der (Sequent E Gamma′ C) LeftBackslash\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta B)]) DerivLeftDot:\n⊢ replace Gamma Gamma′ (Comma (OneForm A) (OneForm B)) (OneForm (A · B)) ⇒\nDeriv (Unf (Sequent E Gamma′ C)) (Der (Sequent E Gamma′ C) LeftDot\n[Unf (Sequent E Gamma C)]) DerivCutRule:\n⊢ replace Gamma Gamma′ (OneForm A) Delta ⇒ Deriv (Unf (Sequent E Gamma′ C)) (Der (Sequent E Gamma′ C) CutRule\n[Unf (Sequent E Gamma C); Unf (Sequent E Delta A)]) DerivSeqExt:\n⊢ replace Gamma Gamma′ Delta Delta′ ∧ E Delta Delta′ ⇒ Deriv (Unf (Sequent E Gamma′ C)) (Der (Sequent E Gamma′ C) SeqExt\n[Unf (Sequent E Gamma C)])\n(Structure rules) DerivOne:\n⊢ Deriv D1 D ′ 1 ⇒ Deriv (Der S R [D1]) (Der S R [D ′ 1])\nDerivLeft:\n⊢ Deriv D1 D ′ 1 ⇒ Deriv (Der S R [D1; D]) (Der S R [D ′ 1 ; D])\nDerivRight:\n⊢ Deriv D2 D ′ 2 ⇒ Deriv (Der S R [D; D2]) (Der S R [D; D ′ 2 ])\nDerivBoth:\n⊢ Deriv D1 D ′ 1 ⇒\nDeriv D2 D ′ 2 ⇒ Deriv (Der S R [D1; D2]) (Der S R [D ′ 1; D ′ 2])\n(RTC rules) Deriv_refl:\n⊢ Deriv x x Deriv_trans:\n⊢ Deriv x y ∧ Deriv y z ⇒ Deriv x z\nA Dertree is a proof if all its leaves are finished sub-proofs. It has to be defined as another inductive unary relation:\n⊢ (∀S R. Proof (Der S R [])) ∧ (∀S R D. Proof D ⇒ Proof (Der S R [D])) ∧ ∀S R D1 D2. Proof D1 ∧ Proof D2 ⇒ Proof (Der S R [D1; D2])\nFinally we have proved the following theorem which partially guaranteed the correctness of Deriv rules. It says for each true sequent, there’s a finished proof tree which is derivable from a unfinished Dertree having that sequent as head:11\ngentzenToDeriv:\n⊢ gentzenSequent E Gamma A ⇒ ∃D. Deriv (Unf (Sequent E Gamma A)) D ∧ Proof D"
    }, {
      "heading" : "4.3 Cut-free proofs",
      "text" : "In Gentzen’s original Sequent Calculus for intuitionistic propositional logic, the so-called cut-elimination theorem (Hauptsatz) stands at the central position. Cut-elimination theorem for Lambek Calculus was proved by Lambek for L [7] and NL [12].\nRoughly speaking, this important theorem said that the Cut rule is admissible. In other words, the Cut rule doesn’t increase the set of theorems provable from other rules. It’s this theorem which guaranteed the existence of decision procedures, because all other rules has the sub-formula property, which is essential for automatic proof searching.\nIn our project, due to the complexity and large amount of preparation before reaching the Cutelimination theorem, it’s not formally proved yet. Nor the original Coq work has done this proof.12\nA cut-free proof is a proof (Dertree) without using the CutRule of gentzen’s Sequent Calculus. One way to define cut-free proofs is simply through the degreeProof property:\n⊢ CutFreeProof p ⇐⇒ (degreeProof p = 0)\n11 The other direction remains unproved: for any sequent, if it leads to a finished Dertree, then it must be a true sequent. We leave this difficult theorem to future work."
    }, {
      "heading" : "12 to our knowledge, the Cut-elimination theorem for Lambek calculus is never formally verified. This topic along",
      "text" : "may become another paper after this project, since it’s big enough.\nThis is because, in the definition of degreeProof, only the CutRule has a non-zero degree, while all other rules has zero degrees. So if the entire Dertree has zero degree, it must not contain any CutRule. Saying the same thing in another way, that’s the following theorem:\nnotCutFree:\n⊢ replace T1 T2 (OneForm A) D ∧ (p1 = Sequent E D A) ∧ (p2 = Sequent E T1 C) ⇒ ¬CutFreeProof (Der _ CutRule [Der p1 _ _; Der p2 _ _])\nThe next important concept is sub-proof. A proof q is a sub-proof of another proof p if and only if p can be found in one leave of the Dertree of p. The one-step version of this relation is defined as another inductive relation subProofOne. Here we omitted its long definition but only show one example, the two LeftSlash cases:\nls1:\n⊢ (p0 = Sequent E Gamma ′ C) ∧\n(p1 = Der (Sequent E Delta B) R D) ∧ (p2 = Der (Sequent E Gamma C) R D) ∧ replace Gamma Gamma′ (OneForm A) (Comma (OneForm (A / B)) Delta) ⇒\nsubProofOne p1 (Der p0 LeftSlash [p1; p2]) ls2:\n⊢ (p0 = Sequent E Gamma ′ C) ∧\n(p1 = Der (Sequent E Delta B) R D) ∧ (p2 = Der (Sequent E Gamma C) R D) ∧ replace Gamma Gamma′ (OneForm A) (Comma (OneForm (A / B)) Delta) ⇒ subProofOne p2 (Der p0 LeftSlash [p1; p2])\nBased on subProofOne, now the full version subProof is just a RTC of subProofOne: (there’s no structure rules here)\n⊢ subProof = subProofOne∗\nFinally we have proved an important sub-formula property if we already have a Cut-free proof. The one-step version (subFormulaPropertyOne) is the longest proofs we met in the whole project, the full version is then provable by doing induction on the one-step version.\nsubFormulaPropertyOne:\n⊢ subProofOne q p ⇒ extensionSub (exten p) ⇒ CutFreeProof p ⇒ ∀ x. subFormTerm x (prems q) ∨ subFormula x (concl q) ⇒ subFormTerm x (prems p) ∨ subFormula x (concl p)\nsubFormulaPropertyOne’:\n⊢ (p = Der (Sequent E Gamma1 B) _ _) ⇒ (q = Der (Sequent E Gamma2 C) _ _) ⇒ extensionSub E ⇒ subProofOne q p ⇒ CutFreeProof p ⇒ subFormTerm x Gamma2 ∨ subFormula x C ⇒ subFormTerm x Gamma1 ∨ subFormula x B\nsubFormulaProperty:\n⊢ subProof q p ⇒ extensionSub (exten p) ⇒ CutFreeProof p ⇒ ∀ x. subFormTerm x (prems q) ∨ subFormula x (concl q) ⇒ subFormTerm x (prems p) ∨ subFormula x (concl p)\nsubFormulaProperty’:\n⊢ (p = Der (Sequent E Gamma1 B) _ _) ⇒ (q = Der (Sequent E Gamma2 C) _ _) ⇒ extensionSub E ⇒ subProof q p ⇒ CutFreeProof p ⇒ subFormTerm x Gamma2 ∨ subFormula x C ⇒ subFormTerm x Gamma1 ∨ subFormula x B\nBasically these theorems said, if we have a cut-free proof, then any sub-formula in its sub-proofs (either in antecedents or conclusion of the sequent) is also a sub-formula of the sequent for whole proof. In another word, NO new formula appears during the proof searching process, or NO need to guess anything! So, if the cut-free proof indeed exists for every sequent proof using CutRule, then we do have the decision procedure!\nThe last thing to explain, is the meaning of extensionSub appearing in above theorems. The purpose is to make sure the gentzen extension in the related Lambek Calculus has also the sub-formula property:\n⊢ extensionSub E ⇐⇒ ∀Form T1 T2.\nE T1 T2 ⇒ subFormTerm Form T1 ⇒ subFormTerm Form T2"
    }, {
      "heading" : "5 Examples",
      "text" : "Our first example demonstrates how to use the Lambek Calculus formulization as a toolkit for manual proving derivations about categories of sentences. Suppose we have the following minimal Italian lexicon:\nword category\ncosa S/(S/np) guarda S/inf passare inf/np\nAnd the goal is to check if “cosa guarda passare” is an Italian sentance (and then parse it). There’re only two ways to bracketing the three words “cosa”, “guarda” and “passare”:\n1. ((“cosa”, “guarda”), “passare”); 2. (“cosa”, (“guarda”, “passare”)).\nThe first way leads to nothing, while the second way (as also a parsing tree) can be proved to have the category S in either Natural Deduction or Sequent Calculus:\n⊢ natDed L_Sequent (Comma (OneForm (At “S” / (At “S” / At “np”)))\n(Comma (OneForm (At “S” / At “inf”)) (OneForm (At “inf” / At “np”)))) (At “S”)\n⊢ gentzenSequent L_Sequent (Comma (OneForm (At “S” / (At “S” / At “np”)))\n(Comma (OneForm (At “S” / At “inf”)) (OneForm (At “inf” / At “np”)))) (At “S”)\nHere is the proof tree in Natural Deduction with L extension:\nS/(S/np) ⊢ S/(S/np)\nS/inf ⊢ S/inf\ninf/np ⊢ inf/np np ⊢ np /e\ninf/np, np ⊢ inf /e\nS/inf, (inf/np, np) ⊢ S L Sequent (S/inf, inf/np), np ⊢ S /i\nS/inf, inf/np ⊢ S/np /e\nS/(S/np), (S/inf, inf/np) ⊢ S Lex\n(“cosa”, (“guarda”, “passare”)) ⊢ S\nAnd the proof tree in Sequent Calculus with L extension:\nS ⊢ S\nS ⊢ S inf ⊢ inf /L\nS/inf, inf ⊢ S np ⊢ np /L\nS/inf, (inf/np, np) ⊢ S L Sequent (S/inf, inf/np), np ⊢ S /R\nS/inf, inf/np ⊢ S/np /L\nS/(S/np), (S/inf, inf/np) ⊢ S Lex\n(“cosa”, (“guarda”, “passare”)) ⊢ S\nIf we compare the two proof trees, we can see that, the Sequent Calculus proof is “smaller” in the sense that, all applications of SeqAxiom are based on sub-formulae of lower level formulae in the proof tree (in this case they’re all basic categories, but it’s not always like this). To see the advantages of Sequent Calculus more clearly, for the first time we give the formal proof scripts in HOL4 for above two theorems:\nval cosa_guarda_passare_natDed = store_thm (\n\" cosa_guarda_passare_natDed\",\n‘‘natDed L_Sequent (Comma (OneForm ^cosa )\n(Comma ( OneForm ^guarda) (OneForm ^passare )))\n(At \"S\")‘‘,\nMATCH_MP_TAC SlashElim\n>> EXISTS_TAC ‘‘(At \"S\") / (At \"np\")‘‘ (* guess 1 *) >> CONJ_TAC (* 2 sub -goals here *) >| [ (* goal 1 *)\nREWRITE_TAC [NatAxiom ], (* goal 2 *) MATCH_MP_TAC SlashIntro \\\\ MATCH_MP_TAC NatExtSimpl \\\\ EXISTS_TAC ‘‘(Comma (OneForm (At \"S\" / At \"inf\"))\n(Comma (OneForm (At \"inf\" / At \"np\"))\n(OneForm (At \"np\"))))‘‘ \\\\\nCONJ_TAC >- REWRITE_TAC [ L_Sequent_rules ] \\\\ MATCH_MP_TAC SlashElim \\\\ EXISTS_TAC ‘‘At \"inf\"‘‘ \\\\ (* guess 2 *) CONJ_TAC >| (* 2 sub -goals here *) [ (* goal 2.1 *)\nREWRITE_TAC [ NatAxiom ], (* goal 2.2 *) MATCH_MP_TAC SlashElim \\\\ EXISTS_TAC ‘‘At \"np\"‘‘ \\\\ (* guess 3 *) REWRITE_TAC [ NatAxiom ] ] ]);\nval cosa_guarda_passare_gentzenSequent = store_thm (\n\" cosa_guarda_passare_gentzenSequent\",\n‘‘ gentzenSequent L_Sequent (Comma (OneForm ^cosa )\n(Comma (OneForm ^guarda) (OneForm ^passare )))\n(At \"S\")‘‘,\nMATCH_MP_TAC LeftSlashSimpl\n>> CONJ_TAC (* 2 sub -goals here *) >| [ (* goal 1 *)\nMATCH_MP_TAC RightSlash \\\\ MATCH_MP_TAC SeqExtSimpl \\\\ EXISTS_TAC ‘‘(Comma (OneForm (At \"S\" / At \"inf\"))\n(Comma (OneForm (At \"inf\" / At \"np\"))\n(OneForm (At \"np\"))))‘‘ \\\\\nCONJ_TAC >- REWRITE_TAC [ L_Sequent_rules ] \\\\ MATCH_MP_TAC LeftSlashSimpl \\\\ CONJ_TAC >| (* 2 sub -goals here *) [ (* goal 1.1 *)\nMATCH_MP_TAC LeftSlashSimpl \\\\ REWRITE_TAC [ SeqAxiom ], (* goal 1.2 *) REWRITE_TAC [ SeqAxiom ] ],\n(* goal 2 *) REWRITE_TAC [SeqAxiom ] ]);\nIn the first proof based on Natural Deduction, after rule applications of SlashElim, SlashElim and the second SlashElim, the parameter of EXISTS_TAC tactical must be correctly guessed. Since there’re infinite possibilities, automatica proof searching will fail with Natural Deduction rules. But in the second proof based on Sequent Calculus, there’s no such guess at all. Automatic proof searching algorithm could just try each possible rules (the number is finite) and then does the same strategy for each searching branches, since the formulae at next levels always become smaller, the proof searching process will definitely terminate. (And there’re even better algorithms with polinomial time complexity)\nThe next example is to demonstrates how to manually construct a proof tree object for above sentence and prove that the Dertree is indeed a valid proof.\nAt the beginning we have the following unfinished Dertree:\nval r0 =\n‘‘(Unf (Sequent L_Sequent (Comma ( OneForm (At \"S\" / (At \"S\" / At \"np\")))\n(Comma (OneForm (At \"S\" / At \"inf\"))\n(OneForm (At \"inf\" / At \"np\"))))\n(At \"S\")))‘‘;\nIf we try to manually expand this Dertree into the final proof tree according to above manual proof, at the next step we could have a new Dertree like this:\nval r1 =\n‘‘(Der (Sequent L_Sequent (Comma ( OneForm (At \"S\" / (At \"S\" / At \"np\")))\n(Comma (OneForm (At \"S\" / At \"inf\"))\n(OneForm (At \"inf\" / At \"np\"))))\n(At \"S\"))\nLeftSlash\n[ (Unf (Sequent L_Sequent (OneForm (At \"S\")) (At \"S\"))) ;\n(Unf (Sequent L_Sequent (Comma (OneForm (At \"S\" / At \"inf\"))\n(OneForm (At \"inf\" / At \"np\")))\n(At \"S\" / At \"np\"))) ])‘‘;\nAnd we can prove this new Dertree is derived from the last one:\n⊢ Deriv (Unf\n(Sequent L_Sequent\n(Comma (OneForm (At “S” / (At “S” / At “np”))) (Comma (OneForm (At “S” / At “inf”))\n(OneForm (At “inf” / At “np”)))) (At “S”))) (Der\n(Sequent L_Sequent\n(Comma (OneForm (At “S” / (At “S” / At “np”))) (Comma (OneForm (At “S” / At “inf”))\n(OneForm (At “inf” / At “np”)))) (At “S”)) LeftSlash [Unf (Sequent L_Sequent (OneForm (At “S”)) (At “S”)); Unf\n(Sequent L_Sequent\n(Comma (OneForm (At “S” / At “inf”)) (OneForm (At “inf” / At “np”))) (At “S” / At “np”))])\nIf we repeat this process and manually expand the Dertree while prove the new Dertree is derived from the last Dertree, finally the transitivity of Deriv relation will let us prove that, the final finished Dertree is indeed a valid proof for the original unfinished Dertree, and thus it’s indeed a valid proof for the original Sequent theorem. We omited the intermediate steps and show only the proof script of the final step:\nval r0_to_final = store_thm (\n\"r0_to_final \", ‘‘Deriv ^r0 ^r_final ‘‘,\nASSUME_TAC r0_to_r1 ’’\n>> ASSUME_TAC (derivToDeriv r1_to_r2 ) >> ASSUME_TAC (derivToDeriv r2_to_r3 ) >> ASSUME_TAC (derivToDeriv r3_to_r4 ) >> ASSUME_TAC (derivToDeriv r4_to_r5 ) >> ASSUME_TAC (derivToDeriv r5_to_r6 ) >> ASSUME_TAC (derivToDeriv r6_to_final ) >> REPEAT (IMP_RES_TAC Deriv_trans ));\nAnd the actual proved theorem:\n⊢ Deriv (Unf\n(Sequent L_Sequent\n(Comma (OneForm (At “S” / (At “S” / At “np”))) (Comma (OneForm (At “S” / At “inf”))\n(OneForm (At “inf” / At “np”)))) (At “S”))) (Der\n(Sequent L_Sequent\n(Comma (OneForm (At “S” / (At “S” / At “np”))) (Comma (OneForm (At “S” / At “inf”))\n(OneForm (At “inf” / At “np”)))) (At “S”)) LeftSlash [Der (Sequent L_Sequent (OneForm (At “S”)) (At “S”)) SeqAxiom [];\nDer\n(Sequent L_Sequent\n(Comma (OneForm (At “S” / At “inf”)) (OneForm (At “inf” / At “np”)))\n(At “S” / At “np”)) RightSlash [Der\n(Sequent L_Sequent\n(Comma\n(Comma (OneForm (At “S” / At “inf”)) (OneForm (At “inf” / At “np”)))\n(OneForm (At “np”))) (At “S”)) SeqExt [Der\n(Sequent L_Sequent\n(Comma (OneForm (At “S” / At “inf”)) (Comma (OneForm (At “inf” / At “np”))\n(OneForm (At “np”)))) (At “S”)) LeftSlash [Der\n(Sequent L_Sequent\n(Comma (OneForm (At “S” / At “inf”)) (OneForm (At “inf”))) (At “S”))\nLeftSlash [Der\n(Sequent L_Sequent (OneForm (At “S”)) (At “S”)) SeqAxiom [];\nDer\n(Sequent L_Sequent (OneForm (At “inf”)) (At “inf”)) SeqAxiom []];\nDer\n(Sequent L_Sequent (OneForm (At “np”)) (At “np”)) SeqAxiom []]]]])\nThe final Dertree is quite long and hard to read, but it does contain all necessary information about the details of the proof. If there’s an automatic proof searching algorithm, in theory we can implement it either as a special tactical for proving theorems about relation gentzenSequent, or as a program taking an initial Dertree and produce a finished Dertree with a related theorem as above one. If we\nneed a language parser instead, then the useful output will be the bracketed binary tree, together with categories at each node of the tree."
    }, {
      "heading" : "6 Differences between HOL and Coq",
      "text" : "There’re essential differences between HOL and Coq for many logical definitions that we have ported from Coq, although they looks similiar."
    }, {
      "heading" : "6.1 Inductive datatypes and relations",
      "text" : "In Coq, both inductive data types and relations are defined as Inductive sets. For instance, the definition of type Form and the arrow relation for Syntactic Calculus:\nInductive Form (Atoms : Set) : Set :=\n| At : Atoms -> Form Atoms | Slash : Form Atoms -> Form Atoms -> Form Atoms | Dot : Form Atoms -> Form Atoms -> Form Atoms | Backslash : Form Atoms -> Form Atoms -> Form Atoms.\nInductive arrow (Atoms : Set) : Form Atoms -> Form Atoms -> Set :=\n| one : forall A : Form Atoms , arrow A A | comp : forall A B C : Form Atoms , arrow A B -> arrow B C -> arrow A C | beta :\nforall A B C : Form Atoms , arrow (Dot A B) C -> arrow A (Slash C B)\n| beta ’ :\nforall A B C : Form Atoms , arrow A (Slash C B) -> arrow (Dot A B) C\n| gamma :\nforall A B C : Form Atoms , arrow (Dot A B) C -> arrow B (Backslash A C)\n| gamma ’ :\nforall A B C : Form Atoms , arrow B (Backslash A C) -> arrow (Dot A B) C\n| arrow_plus : forall A B : Form Atoms , X A B -> arrow A B.\nwhile in HOL, although they’re still inductive defintions, but they’re handled differently: the former is defined by Define, and latter is defined by Hol_reln:\nval _ = Datatype ‘Form = At ’a | Slash Form Form | Backslash Form Form | Dot Form Form ‘;\nval (arrow_rules , arrow_ind , arrow_cases ) = Hol_reln ‘\n(!X A. arrow X A A) /\\ (* one *) (!X A B C. arrow X (Dot A B) C ==> arrow X A (Slash C B)) /\\ (* beta *) (!X A B C. arrow X A (Slash C B) ==> arrow X (Dot A B) C) /\\ (* beta ’ *) (!X A B C. arrow X (Dot A B) C ==> arrow X B (Backslash A C)) /\\ (* gamma *) (!X A B C. arrow X B (Backslash A C) ==> arrow X (Dot A B) C) /\\ (* gamma ’ *) (!X A B C. arrow X A B /\\ arrow X B C ==> arrow X A C) /\\ (* comp *) (!(X :’a arrow_extension ) A B. X A B ==> arrow X A B) ‘; (* arrow_plus *)\nThere’s no magic behind HOL’s datatype definition, because what the Datatype does is to prove a series of theorems which completely characteries the type Form:\nForm_TY_DEF:\n⊢ ∃ rep. TYPE_DEFINITION\n(λ a′0. ∀ ′Form ′ . (∀ a′\n0 . (∃ a. a′ 0 =\n(λ a. ind_type$CONSTR 0 a (λn. ind_type$BOTTOM))\na) ∨ (∃ a0 a1.\n(a′ 0 =\n(λ a0 a1. ind_type$CONSTR (SUC 0) ARB (ind_type$FCONS a0\n(ind_type$FCONS a1 (λn. ind_type$BOTTOM)))) a0 a1) ∧\n′Form ′ a0 ∧ ′Form ′ a1) ∨\n(∃ a0 a1. (a′\n0 =\n(λ a0 a1. ind_type$CONSTR (SUC (SUC 0)) ARB (ind_type$FCONS a0\n(ind_type$FCONS a1 (λn. ind_type$BOTTOM)))) a0 a1) ∧\n′Form ′ a0 ∧ ′Form ′ a1) ∨\n(∃ a0 a1. (a′\n0 =\n(λ a0 a1. ind_type$CONSTR (SUC (SUC (SUC 0))) ARB (ind_type$FCONS a0\n(ind_type$FCONS a1 (λn. ind_type$BOTTOM)))) a0 a1) ∧\n′Form ′ a0 ∧ ′Form ′ a1) ⇒\n′Form ′ a′ 0 ) ⇒\n′Form ′ a′ 0 ) rep\nForm_case_def:\n⊢ (∀ a f f1 f2 f3. Form_CASE (At a) f f1 f2 f3 = f a) ∧ (∀ a0 a1 f f1 f2 f3.\nForm_CASE (a0 / a1) f f1 f2 f3 = f1 a0 a1) ∧ (∀ a0 a1 f f1 f2 f3.\nForm_CASE (a0 \\ a1) f f1 f2 f3 = f2 a0 a1) ∧ ∀ a0 a1 f f1 f2 f3. Form_CASE (a0 · a1) f f1 f2 f3 = f3 a0 a1\nForm_size_def:\n⊢ (∀ f a. Form_size f (At a) = 1 + f a) ∧ (∀ f a0 a1.\nForm_size f (a0 / a1) = 1 + (Form_size f a0 + Form_size f a1)) ∧ (∀ f a0 a1. Form_size f (a0 \\ a1) = 1 + (Form_size f a0 + Form_size f a1)) ∧ ∀ f a0 a1. Form_size f (a0 · a1) = 1 + (Form_size f a0 + Form_size f a1)\nForm_11:\n⊢ (∀ a a′. (At a = At a′) ⇐⇒ (a = a′)) ∧ (∀ a0 a1 a ′ 0 a′ 1 .\n(a0 / a1 = a ′ 0 / a ′ 1) ⇐⇒ (a0 = a ′ 0) ∧ (a1 = a ′ 1)) ∧ (∀ a0 a1 a ′ 0 a′ 1 .\n(a0 \\ a1 = a ′ 0 \\ a′ 1 ) ⇐⇒ (a0 = a ′ 0 ) ∧ (a1 = a ′ 1 )) ∧\n∀ a0 a1 a ′ 0 a ′ 1.\n(a0 · a1 = a ′ 0 · a′ 1 ) ⇐⇒ (a0 = a ′ 0 ) ∧ (a1 = a ′ 1 )\nForm_Axiom:\n⊢ ∃ fn. (∀ a. fn (At a) = f0 a) ∧ (∀ a0 a1. fn (a0 / a1) = f1 a0 a1 (fn a0) (fn a1)) ∧ (∀ a0 a1. fn (a0 \\ a1) = f2 a0 a1 (fn a0) (fn a1)) ∧ ∀ a0 a1. fn (a0 · a1) = f3 a0 a1 (fn a0) (fn a1)\nForm_case_cong:\n⊢ (M = M ′) ∧ (∀ a. (M ′ = At a) ⇒ (f a = f ′ a)) ∧ (∀ a0 a1. (M ′ = a0 / a1) ⇒ (f1 a0 a1 = f ′\n1 a0 a1)) ∧ (∀ a0 a1. (M ′ = a0 \\ a1) ⇒ (f2 a0 a1 = f ′ 2 a0 a1)) ∧ (∀ a0 a1. (M ′ = a0 · a1) ⇒ (f3 a0 a1 = f ′ 3 a0 a1)) ⇒ (Form_CASE M f f1 f2 f3 = Form_CASE M ′ f ′ f ′1 f ′ 2 f ′ 3)\nForm_distinct:\n⊢ (∀ a1 a0 a. At a 6= a0 / a1) ∧ (∀ a1 a0 a. At a 6= a0 \\ a1) ∧ (∀ a1 a0 a. At a 6= a0 · a1) ∧ (∀ a′\n1 a1 a\n′ 0 a0. a0 / a1 6= a ′ 0 \\ a′ 1 ) ∧\n(∀ a′1 a1 a ′ 0 a0. a0 / a1 6= a ′ 0 · a ′ 1) ∧ ∀ a′\n1 a1 a\n′ 0 a0. a0 \\ a1 6= a ′ 0 · a′ 1\nForm_induction:\n⊢ (∀ a. P (At a)) ∧ (∀F ′ F0. P F ′ ∧ P F0 ⇒ P (F ′ / F0)) ∧ (∀F ′ F0. P F ′ ∧ P F0 ⇒ P (F ′ \\ F0)) ∧\n(∀F ′ F0. P F ′ ∧ P F0 ⇒ P (F ′ · F0)) ⇒ ∀F ′. P F ′\nForm_nchotomy:\n⊢ (∃ a. F ′F ′ = At a) ∨ (∃F ′ F0. F ′F ′ = F ′ / F0) ∨\n(∃F ′ F0. F ′F ′ = F ′ \\ F0) ∨ ∃F ′ F0. F ′F ′ = F ′ · F0\nwhere the constant TYPE_DEFINITION is defined in the theory bool by:\n⊢ TYPE_DEFINITION = (λP rep.\n(∀ x ′ x ′′. (rep x ′ = rep x ′′) ⇒ (x ′ = x ′′)) ∧ ∀ x. P x ⇐⇒ ∃ x ′. x = rep x ′)\nWith all above theorems, any theorem in which the type Form is used, can be handled by combining above theorems with other related theorems, although most of time, some HOL’s tacticals can benefit from these generated theorems implicitly. In Coq, datatypes are handled in black-box like ways: user has no direct access to any theorem related to datatype themselves.\nSimilarily, an induction relation arrow in HOL is just defined by some generated theorems:\narrow_def:\n⊢ arrow = (λ a0 a1 a2.\n∀ arrow ′. (∀ a0 a1 a2.\n(a2 = a1) ∨ (∃B C. (a2 = C / B) ∧ arrow\n′ a0 (a1 · B) C) ∨ (∃A B. (a1 = A · B) ∧ arrow\n′ a0 A (a2 / B)) ∨ (∃A C. (a2 = A \\ C) ∧ arrow\n′ a0 (A · a1) C) ∨ (∃A B. (a1 = A · B) ∧ arrow\n′ a0 B (A \\ a2)) ∨ (∃B. arrow ′ a0 a1 B ∧ arrow\n′ a0 B a2) ∨ a0 a1 a2 ⇒ arrow ′ a0 a1 a2) ⇒\narrow ′ a0 a1 a2) arrow_rules:\n⊢ (∀X A. arrow X A A) ∧ (∀X A B C. arrow X (A · B) C ⇒ arrow X A (C / B)) ∧ (∀X A B C. arrow X A (C / B) ⇒ arrow X (A · B) C) ∧ (∀X A B C. arrow X (A · B) C ⇒ arrow X B (A \\ C)) ∧ (∀X A B C. arrow X B (A \\ C) ⇒ arrow X (A · B) C) ∧ (∀X A B C. arrow X A B ∧ arrow X B C ⇒ arrow X A C) ∧ ∀X A B. X A B ⇒ arrow X A B\narrow_strongind:\n⊢ (∀X A. arrow ′ X A A) ∧ (∀X A B C.\narrow X (A · B) C ∧ arrow ′ X (A · B) C ⇒ arrow ′ X A (C / B)) ∧\n(∀X A B C.\narrow X A (C / B) ∧ arrow ′ X A (C / B) ⇒ arrow ′ X (A · B) C) ∧\n(∀X A B C. arrow X (A · B) C ∧ arrow ′ X (A · B) C ⇒ arrow ′ X B (A \\ C)) ∧ (∀X A B C. arrow X B (A \\ C) ∧ arrow ′ X B (A \\ C) ⇒ arrow ′ X (A · B) C) ∧ (∀X A B C. arrow X A B ∧ arrow ′ X A B ∧ arrow X B C ∧ arrow ′ X B C ⇒ arrow ′ X A C) ∧ (∀X A B. X A B ⇒ arrow ′ X A B) ⇒ ∀ a0 a1 a2. arrow a0 a1 a2 ⇒ arrow ′ a0 a1 a2\narrow_ind:\n⊢ (∀X A. arrow ′ X A A) ∧ (∀X A B C. arrow ′ X (A · B) C ⇒ arrow ′ X A (C / B)) ∧ (∀X A B C. arrow ′ X A (C / B) ⇒ arrow ′ X (A · B) C) ∧ (∀X A B C. arrow ′ X (A · B) C ⇒ arrow ′ X B (A \\ C)) ∧ (∀X A B C. arrow ′ X B (A \\ C) ⇒ arrow ′ X (A · B) C) ∧ (∀X A B C. arrow ′ X A B ∧ arrow ′ X B C ⇒ arrow ′ X A C) ∧ (∀X A B. X A B ⇒ arrow ′ X A B) ⇒ ∀ a0 a1 a2. arrow a0 a1 a2 ⇒ arrow\n′ a0 a1 a2 arrow_cases:\n⊢ arrow a0 a1 a2 ⇐⇒ (a2 = a1) ∨ (∃B C. (a2 = C / B) ∧ arrow a0 (a1 · B) C) ∨ (∃A B. (a1 = A · B) ∧ arrow a0 A (a2 / B)) ∨ (∃A C. (a2 = A \\ C) ∧ arrow a0 (A · a1) C) ∨ (∃A B. (a1 = A · B) ∧ arrow a0 B (A \\ a2)) ∨ (∃B. arrow a0 a1 B ∧ arrow a0 B a2) ∨ a0 a1 a2\nWith all above theorems, any theorem in which the relation arrow is used, can be handled by combining above theorems with other related theorems.\nHere is the essential differences between Coq and HOL that we have observed on inductive relations: In HOL, terms like arrow X A B has type bool; while in Coq, its type is Set.\nHere is the consequence: in HOL, in terms like arrow X A B ∧ arrow X B C or arrow X A B ⇒ arrow X A C they’re normal logical connectives between boolean values (first is “and”, second is “implies”). But in Coq, logical connectives never appears between two Sets. Instead, theorems like A / B ==> C were always represented as A -> B -> C in which -> serves as logical implication but actually has more complex meanings."
    }, {
      "heading" : "6.2 Further on logical connectives",
      "text" : "In HOL, basic Boolean connectives and first-order logic quantifiers like “forall”, “exists”, “and”, “or”, “not” and even “true”, “false”, are all defined as λ terms:\n⊢ T ⇐⇒ ((λ x. x) = (λ x. x)) ⊢ (∀ ) = (λP. P = (λ x. T)) ⊢ (∃ ) = (λP. P ((ε) P)) ⊢ (∧) = (λ t1 t2. ∀ t. (t1 ⇒ t2 ⇒ t) ⇒ t) ⊢ (∨) = (λ t1 t2. ∀ t. (t1 ⇒ t) ⇒ (t2 ⇒ t) ⇒ t) ⊢ F ⇐⇒ ∀ t. t ⊢ (¬) = (λ t. t ⇒ F) ⊢ (∃!) = (λP. (∃ ) P ∧ ∀ x y. P x ∧ P y ⇒ (x = y))\nSince they’re all λ terms, any facts about their relationship can be proved within the framework of λ-calculus, using β-reductions and other basic deduction rules. That’s so clear!\nWhile in Coq, it’s surprised to notice that, the quantifier forall is something quite primitive: it’s a keyword in Coq. While there’s no exists keyword at all. And to express the existence of something in any theorem, user must write it as a lambda function. For instance, our replace_inv2 theorem in HOL contains two existence quantifier variables:\n⊢ replace (Comma Gamma1 Gamma2) Gamma ′ (OneForm X ) Delta ⇒\n(∃G. (Gamma′ = Comma G Gamma2) ∧ replace Gamma1 G (OneForm X ) Delta) ∨ ∃G. (Gamma′ = Comma Gamma1 G) ∧ replace Gamma2 G (OneForm X ) Delta\nThe meaning of above theorem is quite clear just by reading it. While in Coq, the same theorem must be expressed in this strange way:\nLemma replace_inv2 :\nforall (Gamma1 Gamma2 Gamma ’ Delta : Term Atoms) (X : Form Atoms), replace (Comma Gamma1 Gamma2) Gamma ’ (OneForm X) Delta -> sigS\n(fun Gamma ’1 : Term Atoms =>\n{x_ : replace Gamma1 Gamma ’1 (OneForm X) Delta | Gamma ’ = Comma Gamma ’1 Gamma2 }) +\nsigS\n(fun Gamma ’2 : Term Atoms =>\n{x_ : replace Gamma2 Gamma ’2 (OneForm X) Delta | Gamma ’ = Comma Gamma1 Gamma ’2}).\nplease notice that, how logical “and” and “or” must be expressed as | and + between Sets in Coq. The author hope these examples could convince the readers that, Coq is very unnatural for representing logical theorems."
    }, {
      "heading" : "6.3 On Coq’s built-in supports of proofs",
      "text" : "In previous section, we have mentioned that, Coq has built-in supports on “proofs”. This fact seems coming from the fact that, in Coq, each logical theorems has essentially the type Set which is indeed a mathematical set, and each element in such sets is one possible “proof” for that theorem! This is really a convenient feature when people need to prove results about proof themselves, but the drawback is, most of such theorems has large amount of variables.\nFor instance, our last theorem in CutFreeTheory is subFormulaProperty, which has the following representation in HOL:\n⊢ subProof q p ⇒ extensionSub (exten p) ⇒ CutFreeProof p ⇒ ∀ x. subFormTerm x (prems q) ∨ subFormula x (concl q) ⇒ subFormTerm x (prems p) ∨ subFormula x (concl p)\nThis theorem was actually ported from Coq, from the following theorem:\nLemma subFormulaProperty :\nforall (Atoms : Set) (Gamma1 Gamma2 : Term Atoms)\n(B C x : Form Atoms) (E : gentzen_extension ) (p : gentzenSequent E Gamma1 B) (q : gentzenSequent E Gamma2 C),\nextensionSub Atoms E -> subProof q p -> CutFreeProof p -> subFormTerm x Gamma2 \\/ subFormula x C -> subFormTerm x Gamma1 \\/ subFormula x B.\nNow let’s count how many variables are used in above theorem in Coq: Atoms, Gamma1, Gamma2, B, C, x, E, p, q, 9 variables totally. While in the HOL version, 3 variables are just enough (two “proofs” plus one Term).\nOnce we have proved above HOL theorem, we can also easily prove the following theorem which has the same amount of variables as Coq:\n⊢ (p = Der (Sequent E Gamma1 B) _ _) ⇒ (q = Der (Sequent E Gamma2 C) _ _) ⇒ extensionSub E ⇒ subProof q p ⇒ CutFreeProof p ⇒ subFormTerm x Gamma2 ∨ subFormula x C ⇒ subFormTerm x Gamma1 ∨ subFormula x B\nbut the other direction is not easy (maybe just impossible): if we have already this last theorem in HOL, no way to get the previous theorem with only 3 variables.\nNevertheless, for Coq’s built-in supports of proof, HOL users can prove the same theorems, although they have to invent the concept and structure of “proofs” from almost ground, and case by case. But the author thinks, it’s quite fair to say that, all theorems provers have exactly the same set of theorems that they’re capable to prove. So the remain question is how to choose between them. Most of time, it’s just a matter of personal preferences, experiences and environment requirements (e.g. when you were doing formalization studies in France, you have to use Coq and OCaml, which are both invented by Franch people)."
    }, {
      "heading" : "7 Future directions",
      "text" : "From the view of theorem proving, the following theorems are worth to prove in the future:\n1. Cut-elimination theorem for Lambek Calculus with arbitrary sequent extensions. 2. Lambek calculus L is context-free. [11]\nThe cut-elimination theorem can be proved directly using the existing framework in our CutFreeTheory, while for the second goal, a full treatment of Lambek Calculus in model-theoretic approach with many new foundamental definitions and theorems must be done first.\nFrom the view of language parsing, the following goals remain to be finished:\n1. Implement an automatic proof searching algorithm for Sequent Calculus as a HOL tactical. 2. Implement the same algorithm for generating first-class proof trees (Dertree). 3. Implement a language parser as ML functions which generates both parsing trees and validation\ntheorems. 4. Design a lexicon data structure for holding large amount of words, each with more than one categories. 5. Design and implement machine learning algorithms to build a large enough lexicon for Italian lan-\nguage."
    }, {
      "heading" : "8 Conclusions",
      "text" : "In this project, we have implemented a rather complete proof-theoretical formalization of Lambek Calculus (non-associative, with arbitrary extensions).\nThe current status is enough as a tool kit for manually proving category theorems in three deduction systems of Lambek Calculus: Axiomatic Syntactic Calculus, Natural Deduction (in Gentzen style) and Gentzen’s Sequent Calculus. It can also be considered as a base framework for further formalization of more deep theorems of Lambek Calculus, e.g. the cut-elimination theorem of Gentzen’s Sequent Calculus of Lambek Calculus.\nThis work is based on the Lambek Calculus formalization in Coq, by Houda ANOUN and Pierre Casteran in 2002-2003. For the modules that we have migrated from Coq, we improved definitions and proved many new theorems. For the proof-theoretic formalization of Sequent Calculus proofs, our work (first-class proof trees in HOL, including related derivation definitions and theorems) is completely new.\nThanks to Prof. Fabio Tambrini, who has introduced Lambek Calculus to the author in his NLP course at University of Bologna."
    }, {
      "heading" : "1. Chomsky, N.: On certain formal properties of grammars. Information and Computation 2 (1959) 137–167",
      "text" : "2. Chomsky, N.: Syntactic Structures. Walter de Gruyter (January 2002)\n3. Napoli, D.J., Burzio, L.: Italian Syntax: A Government-Binding Approach. Language 64(1) (1988) 130 4. Ajdukiewicz, K.: Syntactic Connexion (1936). In: The Scientific World-Perspective and Other Essays,\n1931–1963. Springer Netherlands, Dordrecht (1978) 118–139 5. Bar-Hillel, Y.: A quasi-arithmetical notation for syntactic description. Language 29(1) (1953) 47 6. Moot, R., Retore, C.: The Logic of Categorial Grammars. Volume 6850 of Lecture Notes in Computer Science.\nSpringer Berlin Heidelberg, Berlin, Heidelberg (2012) 7. Lambek, J.: The mathematics of sentence structure. The American Mathematical Monthly 65(3) (1958)\n154–170 8. Cohen, J.M.: The equivalence of two concepts of categorial grammar. Information and Control 10(5) (1967)\n475–484 9. Pentus, M.: Lambek calculus is NP-complete. Theoretical Computer Science 357(1-3) (July 2006) 186–201 10. Pentus, M.: Lambek calculus is L-complete. Institute for Logic (1993) 11. Pentus, M.: Lambek grammars are context free. In: Eighth Annual IEEE Symposium on Logic in Computer\nScience (Montreal, PQ, 1993). IEEE Comput. Soc. Press, Los Alamitos, CA (1993) 429–433 12. Lambek, J.: On the calculus of syntactic types. Proceedings of Symposia in Applied Mathematics 12 (1961)\n166–178 13. Melham, T.F.: A Package for Inductive Relation Definitions in HOL. (January 2017) 1–10 14. Prawitz, D.: Natural deduction. A proof-theoretical study. Acta Universitatis Stockholmiensis. Stockholm\nStudies in Philosophy, No. 3. Almqvist & Wiksell, Stockholm (1965) 15. Gentzen, G.: Untersuchungen über das logische Schlie en. I. Mathematische Zeitschrift 39(1) (1935) 176–210 16. Gentzen, G.: Untersuchungen über das logische Schlie en. II. Mathematische Zeitschrift 39(1) (1935) 405–431 17. Dawson, J.E., Goré, R.: Machine-checked Cut-elimination for Display Logic. (2006)"
    } ],
    "references" : [ {
      "title" : "On certain formal properties of grammars",
      "author" : [ "N. Chomsky" ],
      "venue" : "Information and Computation 2",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 1959
    }, {
      "title" : "Syntactic Structures",
      "author" : [ "N. Chomsky" ],
      "venue" : "Walter de Gruyter",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2002
    }, {
      "title" : "Italian Syntax: A Government-Binding Approach",
      "author" : [ "D.J. Napoli", "L. Burzio" ],
      "venue" : "Language 64(1)",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 1988
    }, {
      "title" : "Syntactic Connexion (1936)",
      "author" : [ "K. Ajdukiewicz" ],
      "venue" : "The Scientific World-Perspective and Other Essays, 1931–1963. Springer Netherlands, Dordrecht",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 1978
    }, {
      "title" : "A quasi-arithmetical notation for syntactic description",
      "author" : [ "Y. Bar-Hillel" ],
      "venue" : "Language 29(1)",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 1953
    }, {
      "title" : "The Logic of Categorial Grammars",
      "author" : [ "R. Moot", "C. Retore" ],
      "venue" : "Volume 6850 of Lecture Notes in Computer Science. Springer Berlin Heidelberg, Berlin, Heidelberg",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2012
    }, {
      "title" : "The mathematics of sentence structure",
      "author" : [ "J. Lambek" ],
      "venue" : "The American Mathematical Monthly 65(3)",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 1958
    }, {
      "title" : "The equivalence of two concepts of categorial grammar",
      "author" : [ "J.M. Cohen" ],
      "venue" : "Information and Control 10(5)",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1967
    }, {
      "title" : "Lambek calculus is NP-complete",
      "author" : [ "M. Pentus" ],
      "venue" : "Theoretical Computer Science 357(1-3)",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Lambek calculus is L-complete",
      "author" : [ "M. Pentus" ],
      "venue" : "Institute for Logic",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "Lambek grammars are context free",
      "author" : [ "M. Pentus" ],
      "venue" : "Eighth Annual IEEE Symposium on Logic in Computer Science (Montreal, PQ, 1993). IEEE Comput. Soc. Press, Los Alamitos, CA",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 1993
    }, {
      "title" : "On the calculus of syntactic types",
      "author" : [ "J. Lambek" ],
      "venue" : "Proceedings of Symposia in Applied Mathematics 12",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 1961
    }, {
      "title" : "A Package for Inductive Relation Definitions in HOL",
      "author" : [ "T.F. Melham" ],
      "venue" : null,
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2017
    }, {
      "title" : "Natural deduction",
      "author" : [ "D. Prawitz" ],
      "venue" : "A proof-theoretical study. Acta Universitatis Stockholmiensis. Stockholm Studies in Philosophy, No. 3. Almqvist & Wiksell, Stockholm",
      "citeRegEx" : "14",
      "shortCiteRegEx" : null,
      "year" : 1965
    }, {
      "title" : "Untersuchungen über das logische Schlie en",
      "author" : [ "G. Gentzen" ],
      "venue" : "I. Mathematische Zeitschrift 39(1)",
      "citeRegEx" : "15",
      "shortCiteRegEx" : null,
      "year" : 1935
    }, {
      "title" : "Untersuchungen über das logische Schlie en",
      "author" : [ "G. Gentzen" ],
      "venue" : "II. Mathematische Zeitschrift 39(1)",
      "citeRegEx" : "16",
      "shortCiteRegEx" : null,
      "year" : 1935
    }, {
      "title" : "Machine-checked Cut-elimination for Display Logic",
      "author" : [ "J.E. Dawson", "R. Goré" ],
      "venue" : null,
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Since the year when Noam Chomsky published his famous “Hierarchy” [1] and his work on phrase structures of English and Spanish [2] in 1950s, the concepts of context-free and context-sensitive languages (and the intemediate areas between them) with the uses of rewriting rules to represent the phrase structure grammar of any given language, has dominated the parsing theory until today.",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 1,
      "context" : "Since the year when Noam Chomsky published his famous “Hierarchy” [1] and his work on phrase structures of English and Spanish [2] in 1950s, the concepts of context-free and context-sensitive languages (and the intemediate areas between them) with the uses of rewriting rules to represent the phrase structure grammar of any given language, has dominated the parsing theory until today.",
      "startOffset" : 127,
      "endOffset" : 130
    }, {
      "referenceID" : 2,
      "context" : "33 of [3]) with an",
      "startOffset" : 6,
      "endOffset" : 9
    }, {
      "referenceID" : 3,
      "context" : "Categorial Grammar was firstly introduced by Polish philosopher and logician Kazimierz Ajdukiewicz in 1935 [4], which is based on ideas from precedent Polish logicians.",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 4,
      "context" : "In 1953, just two years before Chomsky published his phrase structure grammar theory and the famous hierarchy, Israeli philosopher, mathematician, and linguist Yehoshua Bar-Hillel made an important enhancement [5] to Ajdukiewicz’s categorial grammar.",
      "startOffset" : 210,
      "endOffset" : 213
    }, {
      "referenceID" : 5,
      "context" : "[6].",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "Finally, in 1958, Joachim Lambek [7] succesfully defined a formal system for syntactic calculus in which all category formulae can be derived from a basic set of rules (as axioms) and basic logic formulae.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 7,
      "context" : "Although Lambek calculues has more rules then AB grammar, but they’re actually equivalent: “a set of strings of words forms a categorial language of one type if and only if it forms a categorial language of the other type” [8]; 2.",
      "startOffset" : 223,
      "endOffset" : 226
    }, {
      "referenceID" : 6,
      "context" : "This was proved by Lambek (1958) [7].",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 8,
      "context" : "Lambek calculus is NP-complete [9], L-complete [10], and Lambek grammars are context-free [11].",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 9,
      "context" : "Lambek calculus is NP-complete [9], L-complete [10], and Lambek grammars are context-free [11].",
      "startOffset" : 47,
      "endOffset" : 51
    }, {
      "referenceID" : 10,
      "context" : "Lambek calculus is NP-complete [9], L-complete [10], and Lambek grammars are context-free [11].",
      "startOffset" : 90,
      "endOffset" : 94
    }, {
      "referenceID" : 11,
      "context" : "Among other issues, to resolve the key limitation that Lambek calculus cannot be used as a language parser, in 1961, Lambek introduced the so-called Non-associative Lambek Calculus [12], or NL.",
      "startOffset" : 181,
      "endOffset" : 185
    }, {
      "referenceID" : 5,
      "context" : "6 of [6] for detailed discussions and links tooriginal papers) Beside L and NL, there’s also NLP in which the commutativity of products is respect based on NL, i.",
      "startOffset" : 5,
      "endOffset" : 8
    }, {
      "referenceID" : 5,
      "context" : "(see Chapter 5 of [6]).",
      "startOffset" : 18,
      "endOffset" : 21
    }, {
      "referenceID" : 5,
      "context" : "184 of [6]) In this paper, we have tried another possibility to extend Lambek Calculus.",
      "startOffset" : 7,
      "endOffset" : 10
    }, {
      "referenceID" : 12,
      "context" : "In HOL4, such a inductive relation can be easily defined by Hol_reln [13] command:",
      "startOffset" : 69,
      "endOffset" : 73
    }, {
      "referenceID" : 6,
      "context" : "For the original associative Lambek Calculus, we have proved all arrow theorems mentioned in Lambek (1958) [7].",
      "startOffset" : 107,
      "endOffset" : 110
    }, {
      "referenceID" : 13,
      "context" : "Natural deduction was first invented by Dag Prawitz [14] as a non-semantic approach to derive propositional logic formulae.",
      "startOffset" : 52,
      "endOffset" : 56
    }, {
      "referenceID" : 14,
      "context" : "Sequent Calculus was original introduced by Gerhard Gentzen in two German papers [15] [16] written in 1935.",
      "startOffset" : 81,
      "endOffset" : 85
    }, {
      "referenceID" : 15,
      "context" : "Sequent Calculus was original introduced by Gerhard Gentzen in two German papers [15] [16] written in 1935.",
      "startOffset" : 86,
      "endOffset" : 90
    }, {
      "referenceID" : 16,
      "context" : "Our datatype definition is based on similar modelling work in Isabelle/HOL for Display Logic [17], then all other related inductive relation definitions and theorems are new.",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 6,
      "context" : "Cut-elimination theorem for Lambek Calculus was proved by Lambek for L [7] and NL [12].",
      "startOffset" : 71,
      "endOffset" : 74
    }, {
      "referenceID" : 11,
      "context" : "Cut-elimination theorem for Lambek Calculus was proved by Lambek for L [7] and NL [12].",
      "startOffset" : 82,
      "endOffset" : 86
    }, {
      "referenceID" : 10,
      "context" : "[11]",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2017,
    "abstractText" : "In this project, a rather complete proof-theoretical formalization of Lambek Calculus (non-associative with arbitrary extensions) has been ported from Coq proof assistent to HOL4 theorem prover, with some improvements and new theorems. Three deduction systems (Syntactic Calculus, Natural Deduction and Sequent Calculus) of Lambek Calculus are defined with many related theorems proved. The equivalance between these systems are formally proved. Finally, a formalization of Sequent Calculus proofs (where Coq has built-in supports) has been designed and implemented in HOL4. Some basic results including the subformula properties of the so-called “cut-free” proofs are formally proved. This work can be considered as the preliminary work towards a language parser based on category grammars which is not multimodal but still has ability to support context-sensitive languages through customized extensions.",
    "creator" : "LaTeX with hyperref package"
  }
}