{
  "name" : "1704.01938.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "oavraham1@gmail.com", "yoav.goldberg@gmail.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n70 4.\n01 93\n8v 1\n[ cs\n.C L\n] 6\nA pr\n2 01\n7\ndings to capture both semantic and morphological similarity, as affected by the different types of linguistic properties (surface form, lemma, morphological tag) used to compose the representation of each word. We train several models, where each uses a different subset of these properties to compose its representations. By evaluating the models on semantic and morphological measures, we reveal some useful insights on the relationship between semantics and morphology."
    }, {
      "heading" : "1 Introduction",
      "text" : "Word embedding models learn a space of continuous word representations, in which similar words are expected to be close to each other. Traditionally, the term similar refers to semantic similarity (e.g. walking should be close to hiking, and happiness to joy), hence the model performance is usually evaluated using semantic similarity datasets. Recently, several works introduced morphology-driven models motivated by the poor performance of traditional models on morphologically complex words. Such words are often rare, and there is not enough evidence to model them correctly. The morphology-driven models allow pooling evidence from different words which have the same base form. These models work by learning per-morpheme representations rather than just per-word ones, and compose the representing vector of each word from those of its morphemes – as derived from a supervised or unsupervised morphological analysis – and (optionally) its surface form (e.g. walking = f(vwalk, ving, vwalking)). The works differ in the way they acquire morphological knowledge (from using linguistically\nderived morphological analyzers on one end, to approximating morphology using substrings while relying on the concatenative nature of morphology, on the other) and in the model form (cDSMs (Lazaridou et al., 2013), RNN (Luong et al., 2013), LBL (Botha and Blunsom, 2014), CBOW (Qiu et al., 2014), SkipGram (Soricut and Och, 2015; Bojanowski et al., 2016), GGM (Cotterell et al., 2016)). But essentially, they all show that breaking a word into morphological components (base form, affixes and potentially also the complete surface form), learning a vector for each component, and representing a word as a composition of these vectors improves the models semantic performance, especially on rare words.\nIn this work we argue that these models capture two distinct aspects of word similarity, semantic (e.g. sim(walking, hiking) > sim(walking, eating)) and morphological (e.g. sim(walking, hiking) > sim(walking, hiked)), and that these two aspects are at odds with each other (should sim(walking, hiking) be lower or higher than sim(walking, walked)?). The base form component of the compositional models is mostly responsible for semantic aspects of the similarity, while the affixes are mostly responsible for morphological similarity.\nThis analysis brings about several natural questions: is the combination of semantic and morphological components used in previous work ideal for every purpose? For example, if we exclude the morphological component from the representations, wouldn’t it improve the semantic performance? What is the contribution of using the surface form? And do the models behave differently on common and rare words? We explore these questions in order to help the users of morphology-driven models choose the right configuration for their needs: semantic or morphological performance, on common or rare words.\nWe compare different configurations of morphology-driven models, while controlling for the components composing the representation. We then separately evaluate the semantic and morphological performance of each model, on rare and on common words. We focus on inflectional (rather than derivational) morphology. This is due to the fact that derivations (e.g. affected → unaffected) often drastically change the meaning of the word, and therefore the benefit of having similar representations for words with the same derivational base is questionable, as discussed by Lazaridou et al (2013) and Luong et al (2013). Inflections (e.g. walked → walking), in contrast, preserve the word lexical meaning, and only change its grammatical categories values.\nOur experiments are performed on Modern Hebrew, a language with rich inflectional morphological system. We build on a recently introduced evaluation dataset for semantic similarity in Modern Hebrew (Avraham and Goldberg, 2016), which we further extend with a collection of rare words. We also create datasets for morphological similarity, for common and rare words. Hebrew’s morphology is not concatenative, so unlike most previous work we do not break the words into base and affixes, but instead rely on a morphological analyzer and represent words using their lemmas (corresponding to the base form) and their morphological tags (from which the morphological forms are derived, corresponding to affixes). This allow us to have a finer grained control over the composition, separating inflectional from derivational processes. We also compare to a strong character ngram based model, that mixes the different components and does not allow finergrained distinctions.\nWe observe a clear trade-off between the morphological and semantic performance – models that excel on one metric perform badly on the other. We present the strengths and weaknesses of the different configurations, to help the users choose the one that best fits their needs.\nWe believe that this work is the first to make a comprehensive comparison between various configurations of morphology-driven models: among the previous work mentioned above, only few explored configurations other than (base + affixes) or (surface + base + affixes). Lazaridou et al (2013) and Luong et al (2013) trained models which represent a word by its base only, and showed that\nthese models performs worse than the compositional ones (base + affixes). However, the poor results for the base-only models were mainly attributed to undesirable capturing of derivational similarity, e.g. (affected, unaffected). Working with a more linguistically informed morphological analyzer allows us to tease apart inflectional from derivational processes, leading to different results.\nMost of the works on morphology-driven models evaluate the semantic performance of the models, while others perform morphological evaluation. To the best of our knowledge, this work is the first to evaluate both aspects. While our experiments focus on Modern Hebrew due to the availability of a reliable semantic similarity dataset, we believe our conclusions hold more generally."
    }, {
      "heading" : "2 Models",
      "text" : "Our model form is a generalization of the fastText model (Bojanowski et al., 2016), which in turn extends the skip-gram model of Mikolov et al (2013). The skip-gram model takes a sequence of words w1, ..., wT and a function s assigning scores to (word, context) pairs, and maximizes\nT ∑\nt=1\n\n\n∑\nwc∈Ct\nℓ(s(wt, wc)) + ∑\nw′c∈Nt\nℓ(−s(wt, w ′ c))\n\n\nwhere ℓ is the log-sigmoid loss function, Ct is a set of context words, and Nt is a set of negative examples sampled from the vocabulary. s(wt, wc) is defined as s(wt, wc) = v ⊤ wt uwc (where vwt and uwc are the embeddings of the focus and the context words).\nBojanowski et al (2016) replace the word representation vwt with the set of character ngrams appearing in it: vwt = ∑\ng∈G(wt) vg where G(wt) is the set of n-grams appearing in wt. The n-grams are used to approximate the morphemes in the target word.\nWe generalize Bojanowski et al (2016) by replacing the set of ngrams G(w) with a set P(w) of explicit linguistic properties. Each word wt is then composed as the sum of the vectors of its linguistic properties: vwt = ∑ p∈P(wt) vp. The linguistic properties we consider are the surface form of the word (W), it’s lemma (L) and its morphological tag (M)1. The lemma corre-\n1The lemma and morphological tag for a word in context are obtained using a morphological analyzer and disambiguator. Then, each value of lemma/tag/surface from is associated with a trainable embedding vector.\nsponds to the base-form, and the morphological tag encodes the grammatical properties of the word, from which its inflectional affixes are derived (a similar approach was taken by Cotterell and Schütze (2015)). Moving from a set of ngrams to a set of explicit linguistic properties, allows finer control of the kinds of information in the word representation. We train models with different subsets of {W,L,M}."
    }, {
      "heading" : "3 Experiments and Results",
      "text" : "Our implementation is based on the fastText2 library (Bojanowski et al., 2016), which we modify as described above. We train the models on the Hebrew Wikipedia (∼4M sentences), using a window size of 2 to each side of the focus word, and dimensionality of 200. We use the morphological disambiguator of Adler (2007) to assign words with their morphological tags, and the inflection dictionary of MILA (Itai and Wintner, 2008) to find their lemmas. For example, for the words lkzqp ([we will] look [at]), dlkzqd ([she] looked [at]) and lkzqd ([he] looked [at]) are assigned the tags VB.MF.P.1.FUTURE, VB.F.S.3.PAST and VB.M.S.3.PAST respectively, and share the lemma lkzqd. We train the models for the subsets {W}, {L}, {W,L}, {W,M} and {W,L,M}, as well as the original fastText (n-grams) model. Finally, we evaluate each model on several datasets, using both semantic and morphological performance measures.3\nSemantic Evaluation Measure The common datasets for semantic similarity4 have some notable shortcomings as noted in (Avraham and Goldberg, 2016; Faruqui et al., 2016; Batchkarov et al., 2016; Linzen, 2016). We use the evaluation method (and corresponding Hebrew similarity dataset) that we have introduced in a previous work (Avraham and Goldberg, 2016) (AG). The AG method defines an annotation task which is more natural for human judges, resulting in datasets with improved annotator-agreement scores. Furthermore, the AG’s evaluation metric takes annotator agreement into account, by putting less weight on similarities that have lower annotator agreement.\n2https://github.com/facebookresearch/fastText 3Our code is available on https://github.com/ oavraham1/prop2vec, our datasets on https:// github.com/oavraham1/ag-evaluation\n4E.g., WordSim353 (Finkelstein et al., 2001), RW (Luong et al., 2013) and SimLex999 (Hill et al., 2015)\nAn AG dataset is a collection of target-groups, where each group contains a target word (e.g. singer) and three types of candidate words: positives which are words “similar” to the target (e.g. musician), distractors which are words “related but dissimilar” to the target (e.g. microphone), and randoms which are not related to the target at all (e.g laptop). The human annotators are asked to rank the positive words by their similarity to the target word (distractor and random words are not annotated by humans and are automatically ranked below the positive words). This results in a set of triples of a target word w and two candidate words c1, c2, coupled with a value indicating the confidence of ranking sim(w, c1) > sim(w, c2) by the annotators. A model is then scored based on its ability to correctly rank each triple, giving more weight to highly-confident triples. The scores range between 0 (all wrong answers) to 1 (perfect match with human annotators).\nWe use this method on two datasets: the AG dataset from (Avraham and Goldberg, 2016) (SemanticSim, containing 1819 triples), and a new dataset we created in order to evaluate the models on rare words (similar to RW (Luong et al., 2013)). The rare-words dataset (SemanticSimRare) follows the structure of SemanticSim, but includes only target words that occur less than 100 times in the corpus. It contains a total of 163 triples, all of the type positive vs. random (we find that for rare words, distinguishing similar words from random ones is a hard enough task for the models).\nMorphological Evaluation Measure Cotterrel and Schütze (2015) introduced the MorphoDistk measure, which quantifies the amount of morphological difference between a target word and a list of its k most similar words. We modify MorphoDistk measure to derive MorphoSimk , a measure that ranges between 0 and 1, where 1 indicates total morphological compatibility. The MorphoDist measure is defined as: MorphoDistk(w) = ∑\nw′∈Kw minmw,mw′ dh(mw,mw′) where Kw is the set of top-k similarities of w, mw and mw′ are possible morphological tags of w and w′ respectively (there may be more than one possible morphological interpretation per word), and dh is the Hamming distance between the morphological tags. MorphoDist counts the total number of incompatible morphological components.\nEach entry is of the form [word:lexical meaning:morphological tag]. Green-colored items share the semantic/inflection of the target word, while red-colored indicate a divergence. In the morphological tags: M/F/MF indicate masculine/feminine/both,\nP/S indicate plural/singular, 1/2/3 indicate 1st/2nd/3rd person.\nMorphoSim calculates the average rate of compatible morphological values. More formally, MorphoSimk(w) = 1 − MorphoDistk(w)\nk·|mw| , where\n|mw| is the number of grammatical components specified in w’s morphological tag.\nWe use k=10 and calculate the average MorphoSim score over 100 randomly chosen words. To evaluate the morphological performance on rare words, we run another benchmark (MorphoSimRare) in which we calculate the average MorphoSim score over the 35 target words of the SemanticSimRare dataset.\nQualitative Results To get an impression of the differences in behavior between the models, we queried each model for the top similarities of several words (calculated by cosine similarity between words vectors), focusing on rare words. Table 1 presents the top-3 similarities for the word dlkzqd ([she] looked [at]), which occurs 17 times in the corpus, under the different models. Unsurprisingly, the lemma component has a positive effect on semantics, while the tag component improves the morphological performance. It also shows a clear trade-off between the two aspects – as models which perform the best on semantics are the worst on morphology. This behavior is representative of the dozens of words we examined.\nQuantitative Results We compare the different models on the different measures, and also compare to the state-of-the-art n-gram based fastText model of Bojanowski et al (2016) that does not require morphological analysis. The results (Table 2) highlight the following:\n1. There is a trade-off between semantic and morphological performance – improving one aspect comes at the expense of the other: the lemma component improves semantics but hurts morphology,\nwhile the opposite is true for the tag component. The common practice of using both components together is a kind of compromise: the LM, WLM and n-grams models are not the best nor the worst on any measure.\n2. The impacts of the lemma and the tag components are much larger when dealing with rare words: comparing toW,WL is only 1.7% better on SS and 3.8% worse onMS, while it’s 16.3% better and 11.9% worse on SSR and MSR (respectively). Similarly, WM is only 2.8% worse than W on SS and 44.9% better on MS, while it’s 21.8% worse and 75.7% better on SSR andMSR (respectively).\n3. Simply lemmatizing the words is very effective for capturing semantic similarity. This is especially true for the rare words, in which the L model clearly outperform all others. For the common words, we see a small drop compared to including the surface form as well (WL,WLM). This is attributed to cases in which some of the semantics lies within the word’s morphological template, for example: in W model, most similar words for the masculine verb ltp (fell) are associated with a soldier (which is a masculine noun): bxdp (was killed), rbtp (was injured), while the similarities of the feminine form dltp are associated with a land or a state (both are feminine nouns): dgteq (was annexed), dyakp (was occupied). In Lmodel – dltp and ltp share a single, less accurate representation (somewhat similarly to representations of ambiguous words). This suggests using different compositions for common and rare words."
    }, {
      "heading" : "4 Conclusions",
      "text" : "Our key message is that users of morphologydriven models should consider the trade-off between the different components of their representations. Since the goal of most works on"
    }, {
      "heading" : "WM 0.687 0.528 0.907 1",
      "text" : "morphology-driven models was to improve semantic similarity, the configurations they used (which combine both semantic and morphological components) were probably not the best choices: we show that using the lemma component (either alone or together with the surface form) is better. Indeed, excluding the morphological component will make the morphological similarity drop, but it’s not necessarily a problem for every task. One should include the morphological component in the embeddings only for tasks in which morphological similarity is required and cannot be handled by other means. A future work can be to perform an extrinsic evaluation of the different models in various downstream applications. This may reveal which kinds of tasks benefit from morphological information, and which can be done better by a pure semantic model."
    }, {
      "heading" : "Acknowledgements",
      "text" : "The work was supported by the Israeli Science Foundation (grant number 1555/15)."
    } ],
    "references" : [ {
      "title" : "Hebrew morphological disambiguation: An unsupervised stochastic wordbased approach",
      "author" : [ "Menahem Meni Adler." ],
      "venue" : "Ph.D. thesis, Ben-Gurion University of the Negev.",
      "citeRegEx" : "Adler.,? 2007",
      "shortCiteRegEx" : "Adler.",
      "year" : 2007
    }, {
      "title" : "Improving reliability of word similarity evaluation by redesigning annotation task and performancemeasure",
      "author" : [ "Oded Avraham", "Yoav Goldberg." ],
      "venue" : "Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP, pages",
      "citeRegEx" : "Avraham and Goldberg.,? 2016",
      "shortCiteRegEx" : "Avraham and Goldberg.",
      "year" : 2016
    }, {
      "title" : "A critique of word similarity as a method for evaluating distributional semantic models",
      "author" : [ "Miroslav Batchkarov", "Thomas Kober", "Jeremy Reffin", "Julie Weeds", "David Weir." ],
      "venue" : "Proceedings of the 1st",
      "citeRegEx" : "Batchkarov et al\\.,? 2016",
      "shortCiteRegEx" : "Batchkarov et al\\.",
      "year" : 2016
    }, {
      "title" : "Enriching word vectors with subword information",
      "author" : [ "Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov." ],
      "venue" : "arXiv preprint arXiv:1607.04606.",
      "citeRegEx" : "Bojanowski et al\\.,? 2016",
      "shortCiteRegEx" : "Bojanowski et al\\.",
      "year" : 2016
    }, {
      "title" : "Compositional morphology for word representations and language modelling",
      "author" : [ "Jan A. Botha", "Phil Blunsom." ],
      "venue" : "ICML, pages 1899–1907.",
      "citeRegEx" : "Botha and Blunsom.,? 2014",
      "shortCiteRegEx" : "Botha and Blunsom.",
      "year" : 2014
    }, {
      "title" : "Morphological word-embeddings",
      "author" : [ "Ryan Cotterell", "Hinrich Schütze." ],
      "venue" : "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1287–1292,",
      "citeRegEx" : "Cotterell and Schütze.,? 2015",
      "shortCiteRegEx" : "Cotterell and Schütze.",
      "year" : 2015
    }, {
      "title" : "Morphological smoothing and extrapolation of word embeddings",
      "author" : [ "Ryan Cotterell", "Hinrich Schütze", "Jason Eisner." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages",
      "citeRegEx" : "Cotterell et al\\.,? 2016",
      "shortCiteRegEx" : "Cotterell et al\\.",
      "year" : 2016
    }, {
      "title" : "Problems with evaluation of word embeddings using word similarity tasks",
      "author" : [ "Manaal Faruqui", "Yulia Tsvetkov", "Pushpendre Rastogi", "Chris Dyer." ],
      "venue" : "Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP, pages 30–",
      "citeRegEx" : "Faruqui et al\\.,? 2016",
      "shortCiteRegEx" : "Faruqui et al\\.",
      "year" : 2016
    }, {
      "title" : "Placing search in context: The concept revisited",
      "author" : [ "Lev Finkelstein", "Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin." ],
      "venue" : "Proceedings of the 10th international conference on World Wide Web, pages 406–",
      "citeRegEx" : "Finkelstein et al\\.,? 2001",
      "shortCiteRegEx" : "Finkelstein et al\\.",
      "year" : 2001
    }, {
      "title" : "Simlex-999: Evaluating semantic models with (genuine) similarity estimation",
      "author" : [ "Felix Hill", "Roi Reichart", "Anna Korhonen." ],
      "venue" : "Computational Linguistics, 41(4).",
      "citeRegEx" : "Hill et al\\.,? 2015",
      "shortCiteRegEx" : "Hill et al\\.",
      "year" : 2015
    }, {
      "title" : "Language resources for Hebrew",
      "author" : [ "Alon Itai", "Shuly Wintner." ],
      "venue" : "Language Resources and Evaluation, 42(1):75–98, March.",
      "citeRegEx" : "Itai and Wintner.,? 2008",
      "shortCiteRegEx" : "Itai and Wintner.",
      "year" : 2008
    }, {
      "title" : "Compositionally derived representations of morphologically complex words in distributional semantics",
      "author" : [ "Angeliki Lazaridou", "Marco Marelli", "Roberto Zamparelli", "Marco Baroni." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association",
      "citeRegEx" : "Lazaridou et al\\.,? 2013",
      "shortCiteRegEx" : "Lazaridou et al\\.",
      "year" : 2013
    }, {
      "title" : "Issues in evaluating semantic spaces using word analogies",
      "author" : [ "Tal Linzen." ],
      "venue" : "Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP, pages 13–18, Berlin, Germany, August. Association for Computational Linguistics.",
      "citeRegEx" : "Linzen.,? 2016",
      "shortCiteRegEx" : "Linzen.",
      "year" : 2016
    }, {
      "title" : "Better word representations with recursive neural networks for morphology",
      "author" : [ "Thang Luong", "Richard Socher", "Christopher Manning." ],
      "venue" : "Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 104–113,",
      "citeRegEx" : "Luong et al\\.,? 2013",
      "shortCiteRegEx" : "Luong et al\\.",
      "year" : 2013
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "arXiv preprint arXiv:1301.3781.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Co-learning of word representations and morpheme representations",
      "author" : [ "Siyu Qiu", "Qing Cui", "Jiang Bian", "Bin Gao", "Tie-Yan Liu." ],
      "venue" : "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages",
      "citeRegEx" : "Qiu et al\\.,? 2014",
      "shortCiteRegEx" : "Qiu et al\\.",
      "year" : 2014
    }, {
      "title" : "Unsupervised morphology induction using word embeddings",
      "author" : [ "Radu Soricut", "Franz Och." ],
      "venue" : "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technolo-",
      "citeRegEx" : "Soricut and Och.,? 2015",
      "shortCiteRegEx" : "Soricut and Och.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "The works differ in the way they acquire morphological knowledge (from using linguistically derived morphological analyzers on one end, to approximating morphology using substrings while relying on the concatenative nature of morphology, on the other) and in the model form (cDSMs (Lazaridou et al., 2013), RNN (Luong et al.",
      "startOffset" : 281,
      "endOffset" : 305
    }, {
      "referenceID" : 13,
      "context" : ", 2013), RNN (Luong et al., 2013), LBL (Botha and Blunsom, 2014), CBOW (Qiu et al.",
      "startOffset" : 13,
      "endOffset" : 33
    }, {
      "referenceID" : 4,
      "context" : ", 2013), LBL (Botha and Blunsom, 2014), CBOW (Qiu et al.",
      "startOffset" : 13,
      "endOffset" : 38
    }, {
      "referenceID" : 15,
      "context" : ", 2013), LBL (Botha and Blunsom, 2014), CBOW (Qiu et al., 2014), SkipGram (Soricut and Och, 2015; Bojanowski et al.",
      "startOffset" : 45,
      "endOffset" : 63
    }, {
      "referenceID" : 16,
      "context" : ", 2014), SkipGram (Soricut and Och, 2015; Bojanowski et al., 2016), GGM (Cotterell et al.",
      "startOffset" : 18,
      "endOffset" : 66
    }, {
      "referenceID" : 3,
      "context" : ", 2014), SkipGram (Soricut and Och, 2015; Bojanowski et al., 2016), GGM (Cotterell et al.",
      "startOffset" : 18,
      "endOffset" : 66
    }, {
      "referenceID" : 6,
      "context" : ", 2016), GGM (Cotterell et al., 2016)).",
      "startOffset" : 13,
      "endOffset" : 37
    }, {
      "referenceID" : 1,
      "context" : "We build on a recently introduced evaluation dataset for semantic similarity in Modern Hebrew (Avraham and Goldberg, 2016), which we further extend with a collection of rare words.",
      "startOffset" : 94,
      "endOffset" : 122
    }, {
      "referenceID" : 3,
      "context" : "Our model form is a generalization of the fastText model (Bojanowski et al., 2016), which in turn extends the skip-gram model of Mikolov et al (2013).",
      "startOffset" : 57,
      "endOffset" : 82
    }, {
      "referenceID" : 3,
      "context" : "Our model form is a generalization of the fastText model (Bojanowski et al., 2016), which in turn extends the skip-gram model of Mikolov et al (2013). The skip-gram model takes a sequence of words w1, .",
      "startOffset" : 58,
      "endOffset" : 150
    }, {
      "referenceID" : 5,
      "context" : "word, from which its inflectional affixes are derived (a similar approach was taken by Cotterell and Schütze (2015)).",
      "startOffset" : 87,
      "endOffset" : 116
    }, {
      "referenceID" : 3,
      "context" : "brary (Bojanowski et al., 2016), which we modify as described above.",
      "startOffset" : 6,
      "endOffset" : 31
    }, {
      "referenceID" : 10,
      "context" : "We use the morphological disambiguator of Adler (2007) to assign words with their morphological tags, and the inflection dictionary of MILA (Itai and Wintner, 2008) to find their lemmas.",
      "startOffset" : 140,
      "endOffset" : 164
    }, {
      "referenceID" : 0,
      "context" : "We use the morphological disambiguator of Adler (2007) to assign words with their morphological tags, and the inflection dictionary of MILA (Itai and Wintner, 2008) to find their lemmas.",
      "startOffset" : 42,
      "endOffset" : 55
    }, {
      "referenceID" : 1,
      "context" : "previous work (Avraham and Goldberg, 2016) (AG).",
      "startOffset" : 14,
      "endOffset" : 42
    }, {
      "referenceID" : 8,
      "context" : ", WordSim353 (Finkelstein et al., 2001), RW (Luong et al.",
      "startOffset" : 13,
      "endOffset" : 39
    }, {
      "referenceID" : 13,
      "context" : ", 2001), RW (Luong et al., 2013) and SimLex999 (Hill et al.",
      "startOffset" : 12,
      "endOffset" : 32
    }, {
      "referenceID" : 9,
      "context" : ", 2013) and SimLex999 (Hill et al., 2015) An AG dataset is a collection of target-groups,",
      "startOffset" : 22,
      "endOffset" : 41
    }, {
      "referenceID" : 1,
      "context" : "We use this method on two datasets: the AG dataset from (Avraham and Goldberg, 2016) (SemanticSim, containing 1819 triples), and a new dataset we created in order to evaluate the models on rare words (similar to RW (Luong et al.",
      "startOffset" : 56,
      "endOffset" : 84
    }, {
      "referenceID" : 13,
      "context" : "We use this method on two datasets: the AG dataset from (Avraham and Goldberg, 2016) (SemanticSim, containing 1819 triples), and a new dataset we created in order to evaluate the models on rare words (similar to RW (Luong et al., 2013)).",
      "startOffset" : 215,
      "endOffset" : 235
    } ],
    "year" : 2017,
    "abstractText" : "We explore the ability of word embeddings to capture both semantic and morphological similarity, as affected by the different types of linguistic properties (surface form, lemma, morphological tag) used to compose the representation of each word. We train several models, where each uses a different subset of these properties to compose its representations. By evaluating the models on semantic and morphological measures, we reveal some useful insights on the relationship between semantics and morphology.",
    "creator" : "dvips(k) 5.996 Copyright 2016 Radical Eye Software"
  }
}