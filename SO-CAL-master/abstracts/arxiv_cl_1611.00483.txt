While automatic response generation for building chatbot systems has drawn a lot of attention recently, there is limited understanding on when we need to consider the linguistic context of an input text in the generation process.
The task is challenging, as messages in a conversational environment are short and informal, and evidence that can indicate a message is context dependent is scarce.
After a study of social conversation data crawled from the web, we observed that some characteristics estimated from the responses of messages are discriminative for identifying context dependent messages.
With the characteristics as weak supervision, we propose using a Long Short Term Memory (LSTM) network to learn a classifier.
Our method carries out text representation and classifier learning in a unified framework.
Experimental results show that the proposed method can significantly outperform baseline methods on accuracy of classification.
