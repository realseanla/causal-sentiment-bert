Recent works have been shown effective in using neural networks for Chinese word segmentation.
However, these models rely on large-scale data and are less effective for low-resource datasets because of insufficient training data.
Thus, we propose a transfer learning method to improve low-resource word segmentation by leveraging high-resource corpora.
First, we train a teacher model on high-resource corpora and then use the learned knowledge to initialize a student model.
Second, a weighted data similarity method is proposed to train the student model on low-resource data with the help of high-resource corpora.
Finally, given that insufficient data puts forward higher requirements for feature extraction, we propose a novel neural network which improves feature learning.
Experiment results show that our work significantly improves the performance on low-resource datasets: 2.3 percent and 1.5 percent F-score on PKU and CTB datasets.
Furthermore, this paper achieves state-of-the-art results: 96.1 percent, and 96.2 percent F-score on PKU and CTB datasets.
Besides, we explore an asynchronous parallel method on neural word segmentation to speed up training.
The parallel method accelerates training substantially and is almost five times faster than a serial mode.
