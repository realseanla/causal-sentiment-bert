With the development of community based question answering (Q\&amp;A) services, a large scale of Q\&amp;A archives have been accumulated and are an important information and knowledge resource on the web.
Question and answer matching has been attached much importance to for its ability to reuse knowledge stored in these systems: it can be useful in enhancing user experience with recurrent questions.
In this paper, we try to improve the matching accuracy by overcoming the lexical gap between question and answer pairs.
A Word Embedding based Correlation (WEC) model is proposed by integrating advantages of both the translation model and word embedding, given a random pair of words, WEC can score their co-occurrence probability in Q\&amp;A pairs and it can also leverage the continuity and smoothness of continuous space word representation to deal with new pairs of words that are rare in the training parallel text.
An experimental study on Yahoo!
Answers dataset and Baidu Zhidao dataset shows this new method's promising potential.
