The identification and quantification of markers in medical images is critical for diagnosis, prognosis and management of patients in clinical practice.
Supervised- or weakly supervised training enables the detection of findings that are known a priori.
It does not scale well, and a priori definition limits the vocabulary of markers to known entities reducing the accuracy of diagnosis and prognosis.
Here, we propose the identification of anomalies in large-scale medical imaging data using healthy examples as a reference.
We detect and categorize candidates for anomaly findings untypical for the observed data.
A deep convolutional autoencoder is trained on healthy retinal images.
The learned model generates a new feature representation, and the distribution of healthy retinal patches is estimated by a one-class support vector machine.
Results demonstrate that we can identify pathologic regions in images without using expert annotations.
A subsequent clustering categorizes findings into clinically meaningful classes.
In addition the learned features outperform standard embedding approaches in a classification task.
