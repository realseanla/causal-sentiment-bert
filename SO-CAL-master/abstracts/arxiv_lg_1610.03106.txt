Term weighting metrics assign weights to terms in order to discriminate the important terms from the less crucial ones.
Due to this characteristic, these metrics have attracted growing attention in text classification and recently in sentiment analysis.
Using the weights given by such metrics could lead to more accurate document representation which may improve the performance of the classification.
While previous studies have focused on proposing or comparing different weighting metrics at two-classes document level sentiment analysis, this study propose to analyse the results given by each metric in order to find out the characteristics of good and bad weighting metrics.
Therefore we present an empirical study of fifteen global supervised weighting metrics with four local weighting metrics adopted from information retrieval, we also give an analysis to understand the behavior of each metric by observing and analysing how each metric distributes the terms and deduce some characteristics which may distinguish the good and bad metrics.
The evaluation has been done using Support Vector Machine on three different datasets: Twitter, restaurant and laptop reviews.
