In video games, virtual characters' decision systems often use a simplified representation of the world.
To increase both their autonomy and believability we want those characters to be able to learn this representation from human players.
We propose to use a model called growing neural gas to learn by imitation the topology of the environment.
The implementation of the model, the modifications and the parameters we used are detailed.
Then, the quality of the learned representations and their evolution during the learning are studied using different measures.
Improvements for the growing neural gas to give more information to the character's model are given in the conclusion.
