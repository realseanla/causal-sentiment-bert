The speech signal conveys information on different time scales from short (20-40 ms) time scale or segmental, associated to phonological and phonetic information to long (150-250 ms) time scale or supra segmental, associated to syllabic and prosodic information.
Linguistic and neurocognitive studies recognize the phonological classes at segmental level as the essential and invariant representations used in speech temporal organization.
In the context of speech processing, a deep neural network (DNN) is an effective computational method to infer the probability of individual phonological classes from a short segment of speech signal.
A vector of all phonological class probabilities is referred to as phonological posterior.
There are only very few classes comprising a short term speech signal; hence, the phonological posterior is a sparse vector.
Although the phonological posteriors are estimated at segmental level, we claim that they convey supra-segmental information.
Namely, we demonstrate that phonological posteriors are indicative of syllabic and prosodic events.
Building on findings from converging linguistic evidence on the gestural model of Articulatory Phonology as well as neural basis of speech perception, we hypothesize that phonological posteriors convey properties of linguistic classes at multiple time scales, and this information is embedded in their support (index) of active coefficients.
To verify this hypothesis, we obtain a binary representation of phonological posteriors at segmental level which is referred to as first-order sparsity structure; the high-order structures are obtained by concatenation of first-order binary vectors.
It is then confirmed that classification of supra-segmental linguistic events, the problem known as linguistic parsing, can be achieved with high accuracy using a simple binary pattern matching of first-order or high-order structures.
