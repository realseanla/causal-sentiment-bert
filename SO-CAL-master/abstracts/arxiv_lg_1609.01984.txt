Personal robots are expected to interact with the user by recognizing the user's face.
However, in most of the service robot applications, the user needs to move himself/herself to allow the robot to see him/her face to face.
To overcome such limitations, a method for estimating human body orientation is required.
Previous studies used various components such as feature extractors and classification models to classify the orientation which resulted in low performance.
For a more robust and accurate approach, we propose the light weight convolutional neural networks, an end to end system, for estimating human body orientation.
Our body orientation estimation model achieved 81.58 percent and 94 percent accuracy with the benchmark dataset and our own dataset respectively.
The proposed method can be used in a wide range of service robot applications which depend on the ability to estimate human body orientation.
To show its usefulness in service robot applications, we designed a simple robot application which allows the robot to move towards the user's frontal plane.
With this, we demonstrated an improved face detection rate.
