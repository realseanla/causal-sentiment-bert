As datasets become larger and more distributed, algorithms for distributed clustering have become more and more important.
In this work, we present a general framework for designing distributed clustering algorithms that are robust to outliers.
Using our framework, we give a distributed approximation algorithm for k-means, k-median, or generally any L_p objective, with z outliers and/or balance constraints, using O(m(k+z)(d+log n)) bits of communication, where m is the number of machines, n is the size of the point set, and d is the dimension.
This generalizes and improves over previous work of Bateni et al.
and Malkomes et al.
As a special case, we achieve the first distributed algorithm for k-median with outliers, answering an open question posed by Malkomes et al.
For distributed k-means clustering, we provide the first dimension-dependent communication complexity lower bound for finding the optimal clustering.
This improves over the lower bound from Chen et al.
which is dimension-agnostic.
