In this paper the task of emotion recognition from speech is considered.
Proposed approach uses deep recurrent neural network trained on a sequence of acoustic features calculated over small speech intervals.
At the same time special probabilistic-nature CTC loss function allows to consider long utterances containing both emotional and unemotional parts.
The effectiveness of such an approach is shown in two ways.
First one is the comparison with recent advances in this field.
While second way implies measuring human performance on the same task, which also was done by authors.
