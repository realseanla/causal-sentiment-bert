The agent program, called Samu, is an experiment to build a disembodied DevRob (Developmental Robotics) chatter bot that can talk in a natural language like humans do.
One of the main design feature is that Samu can be interacted with using only a character terminal.
This is important not only for practical aspects of Turing test or Loebner prize, but also for the study of basic principles of Developmental Robotics.
Our purpose is to create a rapid prototype of Q-learning with neural network approximators for Samu.
We sketch out the early stages of the development process of this prototype, where Samu's task is to predict the next sentence of tales or conversations.
The basic objective of this paper is to reach the same results using reinforcement learning with general function approximators that can be achieved by using the classical Q lookup table on small input samples.
The paper is closed by an experiment that shows a significant improvement in Samu's learning when using LZW tree to narrow the number of possible Q-actions.
