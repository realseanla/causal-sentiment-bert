In this paper we investigate the computational complexity of learning the graph structure underlying a discrete undirected graphical model from i.i.d.
samples.
We first observe that the notoriously difficult problem of learning parities with noise can be captured as a special case of learning graphical models.
This leads to an unconditional computational lower bound of $\Omega (p^{d/2})$ for learning general graphical models on $p$ nodes of maximum degree $d$, for the class of so-called statistical algorithms recently introduced by Feldman et al (2013).
The lower bound suggests that the $O(p^d)$ runtime required to exhaustively search over neighborhoods cannot be significantly improved without restricting the class of models.
