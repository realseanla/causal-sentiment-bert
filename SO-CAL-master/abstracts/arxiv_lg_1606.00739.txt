Stochastic structured prediction under bandit feedback follows a learning protocol where on each of a sequence of iterations, the learner receives an input, predicts an output structure, and receives partial feedback in form of a task loss evaluation of the predicted structure.
We introduce stochastic approximation algorithms that apply this learning scenario to probabilistic structured prediction, with a focus on asymptotic convergence and ease of elicitability of feedback.
We present simulation experiments for complex natural language processing tasks, showing fastest empirical convergence and smallest empirical variance for stochastic optimization of a non-convex pairwise preference learning objective compared to stochastic optimization of related non-convex and convex objectives.
