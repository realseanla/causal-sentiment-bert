Deep Reinforcement Learning has been successful in various virtual tasks, but it is still rarely used in real world applications especially for continuous control of mobile robots navigation.
In this paper, we present a learning-based mapless motion planner by taking the 10-dimensional range findings and the target position as input and the continuous steering commands as output.
Traditional motion planners for mobile ground robots with a laser range sensor mostly depend on the map of the navigation environment where both the highly precise laser sensor and the map building work of the environment are indispensable.
We show that, through an asynchronous deep reinforcement learning method, a mapless motion planner can be trained end-to-end without any manually designed features and prior demonstrations.
The trained planner can be directly applied in unseen virtual and real environments.
We also evaluated this learning-based motion planner and compared it with the traditional motion planning method, both in virtual and real environments.
The experiments show that the proposed mapless motion planner can navigate the nonholonomic mobile robot to the desired targets without colliding with any obstacles.
