Feature-based format is the main data representation format used by machine learning algorithms.
When the features do not properly describe the initial data, performance starts to degrade.
Some algorithms address this problem by internally changing the representation space, but the newly-constructed features are rarely comprehensible.
We seek to construct, in an unsupervised way, new features that are more appropriate for describing a given dataset and, at the same time, comprehensible for a human user.
We propose two algorithms that construct the new features as conjunctions of the initial primitive features or their negations.
The generated feature sets have reduced correlations between features and succeed in catching some of the hidden relations between individuals in a dataset.
For example, a feature like $sky \wedge \neg building \wedge panorama$ would be true for non-urban images and is more informative than simple features expressing the presence or the absence of an object.
The notion of Pareto optimality is used to evaluate feature sets and to obtain a balance between total correlation and the complexity of the resulted feature set.
Statistical hypothesis testing is used in order to automatically determine the values of the parameters used for constructing a data-dependent feature set.
We experimentally show that our approaches achieve the construction of informative feature sets for multiple datasets.
