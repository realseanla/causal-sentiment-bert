Applying end-to-end learning to solve complex, interactive, pixel-driven control tasks on a robot is an unsolved problem.
Deep Reinforcement Learning algorithms are too slow to achieve performance on a real robot, but their potential has been demonstrated in simulated environments.
We propose using progressive networks to bridge the reality gap and transfer learned policies from simulation to the real world.
The progressive net approach is a general framework that enables reuse of everything from low-level visual features to high-level policies for transfer to new tasks, enabling a compositional, yet simple, approach to building complex skills.
We present an early demonstration of this approach with a number of experiments in the domain of robot manipulation that focus on bridging the reality gap.
Unlike other proposed approaches, our real-world experiments demonstrate successful task learning from raw visual input on a fully actuated robot manipulator.
Moreover, rather than relying on model-based trajectory optimisation, the task learning is accomplished using only deep reinforcement learning and sparse rewards.
