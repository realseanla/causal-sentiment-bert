This paper presents early experiments extending the work of Ba et al.
(2014) on recurrent neural models for attention into less constrained visual environments, beginning with fine-grained categorization on the Stanford Dogs data set.
In this work we use an RNN of the same structure but substitute a more powerful visual network and perform large-scale pre-training of the visual network outside of the attention RNN.
Most work in attention models to date focuses on tasks with toy or more constrained visual environments.
We present results comparing our model to state-of-the-art in fine-grained categorization as well as state-of-the-art deep visual models.
