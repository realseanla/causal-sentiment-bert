Game tree search algorithms, such as Monte Carlo Tree Search (MCTS), require access to a forward model (or "simulator") of the game at hand.
However, in some games such forward model is not readily available.
This paper presents three forward models for two-player attrition games, which we call "combat models", and show how they can be used to simulate combat in RTS games.
We also show how these combat models can be learned from replay data.
We use StarCraft as our application domain.
We report experiments comparing our combat models predicting a combat output and their impact when used for tactical decisions during a real game.
