Image/video data is usually represented by multiple visual features.
Fusion of multi-sources information for establishing the identity has been widely recognized.
Multi-feature visual recognition has recently received attention in multimedia applications.
This paper studies visual understanding via a newly proposed l_2-norm based multi-feature jointly sharing learning framework, which can simultaneously learn the global label matrix and explicit classifiers from the labeled visual data represented by multiple feature modalities.
Additionally, a multi-modal group graph manifold regularizer formed by mixed Laplacian and Hessian graph is proposed for better preserving the manifold structure of different features on the labeled data, while preserving the label consistency and improving the label prediction power via semi-supervised learning.
The merits of the proposed multi-feature learning framework lie in jointly sharing the structural information from multiple features in global classifier learning phase based on a mixed graph regularizer on one hand, and an efficient alternating optimization method for fast classifier training on the other hand.
Experiments on several benchmark visual datasets, such as 17-category Oxford Flower dataset, the challenging 101-category Caltech dataset, YouTube &amp; Consumer Videos dataset and large-scale NUS-WIDE dataset for multimedia understanding all demonstrate that the proposed approach compares favorably with state-of-the-art algorithms.
