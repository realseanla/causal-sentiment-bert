Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks.
While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties.
In this paper we report two such properties.
