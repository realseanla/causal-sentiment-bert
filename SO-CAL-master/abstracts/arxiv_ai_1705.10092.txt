In this paper, we present the Role Playing Learning (RPL) scheme for a mobile robot to navigate socially with its human companion in populated environments.
Neural networks (NN) are constructed to parameterize a stochastic policy that directly maps sensory data collected by the robot to its velocity outputs, while respecting a set of social norms.
An efficient simulative learning environment is built with maps and pedestrians trajectories collected from a number of real-world crowd data sets.
In each learning iteration, a robot equipped with the NN policy is created virtually in the learning environment to play itself as a companied pedestrian and navigate towards a goal in a socially concomitant manner.
Thus, we call this process Role Playing Learning, which is formulated under a reinforcement learning (RL) framework.
The NN policy is optimized end-to-end using Trust Region Policy Optimization (TRPO), with consideration of the imperfectness of robot's sensor measurements.
Simulative and experimental results are provided to demonstrate the efficacy and superiority of our method.
