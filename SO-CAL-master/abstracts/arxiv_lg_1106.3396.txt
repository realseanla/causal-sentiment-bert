Signal Sequence Labeling consists in predicting a sequence of labels given an observed sequence of samples.
A naive way is to filter the signal in order to reduce the noise and to apply a classification algorithm on the filtered samples.
We propose in this paper to jointly learn the filter with the classifier leading to a large margin filtering for classification.
This method allows to learn the optimal cutoff frequency and phase of the filter that may be different from zero.
Two methods are proposed and tested on a toy dataset and on a real life BCI dataset from BCI Competition III.
