One of the most important fields in robotics is the optimization of controllers.
Currently, robots are treated as a black box in this optimization process, which is the reason why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are omnipresent.
We propose an implementation of a modern physics engine, which has the ability to differentiate control parameters.
This has been implemented on both CPU and GPU.
We show how this speeds up the optimization process, even for small problems, and why it will scale to bigger problems.
We explain why this is an alternative approach to deep Q-learning, for using deep learning in robotics.
Lastly, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots, both in hardware and software.
