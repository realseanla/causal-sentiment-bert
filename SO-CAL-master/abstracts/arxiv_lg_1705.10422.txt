Sensor fusion is indispensable to improve accuracy and robustness in an autonomous navigation setting.
However, in the space of end-to-end sensorimotor control, this multimodal outlook has received limited attention.
In this work, we propose a novel stochastic regularization technique, called Sensor Dropout, to robustify multimodal sensor policy learning outcomes.
We also introduce an auxiliary loss on policy network along with the standard DRL loss that help reduce the action variations of the multimodal sensor policy.
Through empirical testing we demonstrate that our proposed policy can 1) operate with minimal performance drop in noisy environments, 2) remain functional even in the face of a sensor subset failure.
Finally, through the visualization of gradients, we show that the learned policies are conditioned on the same latent input distribution despite having multiple sensory observations spaces - a hallmark of true sensor-fusion.
This efficacy of a multimodal policy is shown through simulations on TORCS, a popular open-source racing car game.
A demo video can be seen here:
