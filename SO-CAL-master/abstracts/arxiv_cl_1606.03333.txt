Huge amounts of digital videos are being produced and broadcast every day, leading to giant media archives.
Effective techniques are needed to make such data accessible further.
Automatic meta-data labelling of broadcast media is an essential task for multimedia indexing, where it is standard to use multi-modal input for such purposes.
This paper describes a novel method for automatic detection of media genre and show identities using acoustic features, textual features or a combination thereof.
Furthermore the inclusion of available meta-data, such as time of broadcast, is shown to lead to very high performance.
Latent Dirichlet Allocation is used to model both acoustics and text, yielding fixed dimensional representations of media recordings that can then be used in Support Vector Machines based classification.
Experiments are conducted on more than 1200 hours of TV broadcasts from the British Broadcasting Corporation (BBC), where the task is to categorise the broadcasts into 8 genres or 133 show identities.
On a 200-hour test set, accuracies of 98.6 percent and 85.7 percent were achieved for genre and show identification respectively, using a combination of acoustic and textual features with meta-data.
