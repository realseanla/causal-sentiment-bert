One of the critical issues when adopting Bayesian networks (BNs) to model dependencies among random variables is to "learn" their structure, given the huge search space of possible solutions, i.e., all the possible direct acyclic graphs.
This is a well-known NP-hard problem, which is also complicated by known pitfalls such as the issue of I-equivalence among different structures.
In this work we restrict the investigations on BN structure learning to a specific class of networks, i.e., those representing the dynamics of phenomena characterized by the monotonic accumulation of events.
Such phenomena allow to set specific structural constraints based on Suppes' theory of probabilistic causation and, accordingly, to define constrained BNs, named Suppes-Bayes Causal Networks (SBCNs).
We here investigate the structure learning of SBCNs via extensive simulations with various state-of-the-art search strategies, such as canonical local search techniques and Genetic Algorithms.
Among the main results we show that Suppes' constraints deeply simplify the learning task, by reducing the solution search space and providing a temporal ordering on the variables.
