There are two common approaches for optimizing the performance of a machine: genetic algorithms and machine learning.
A genetic algorithm is applied over many generations whereas machine learning works by applying feedback until the system meets a performance threshold.
Though these are methods that typically operate separately, we combine evolutionary adaptation and machine learning into one approach.
Our focus is on machines that can learn during their lifetime, but instead of equipping them with a machine learning algorithm we aim to let them evolve their ability to learn by themselves.
We use evolvable networks of probabilistic and deterministic logic gates, known as Markov Brains, as our computational model organism.
The ability of Markov Brains to learn is augmented by a novel adaptive component that can change its computational behavior based on feedback.
We show that Markov Brains can indeed evolve to incorporate these feedback gates to improve their adaptability to variable environments.
By combining these two methods, we now also implemented a computational model that can be used to study the evolution of learning.
