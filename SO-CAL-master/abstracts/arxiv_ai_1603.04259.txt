Many Collaborative Filtering (CF) algorithms are item-based in the sense that they analyze item-item relations in order to produce item similarities.
Recently, several works in the field of Natural Language Processing suggested to learn a latent representation of words using neural embedding algorithms.
Among them, the Skip-gram with Negative Sampling (SGNS), also known as Word2Vec, was shown to provide state-of-the-art results on various linguistics tasks.
In this paper, we show that item-based CF can be cast in the same framework of neural word embedding.
Inspired by SGNS, we describe a method we name Item2Vec for item-based CF that produces embedding for items in a latent space.
The method is capable of inferring item-to-item relations even when user information is not available.
We present experimental results on large scale datasets that demonstrate the effectiveness of the proposed method and show it provides a similarity measure that is competitive with SVD.
