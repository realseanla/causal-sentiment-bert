Reservoir computing is a recently introduced machine learning paradigm that has been shown to be well-suited for the processing of spatiotemporal data.
Rather than training the network node connections and weights via backpropagation in traditional recurrent neural networks, reservoirs instead have fixed connections and weights among the `hidden layer' nodes, and traditionally only the weights to the output layer of neurons are trained using linear regression.
We claim that for signal classification tasks, one may forgo the weight training step entirely and instead use a simple supervised clustering method.
The proposed method is analyzed theoretically and explored through numerical experiments on real-world data.
The examples demonstrate that the proposed clustering method outperforms the traditional trained output weight approach in terms of speed, accuracy, and sensitivity to reservoir parameters.
