Machine-learning techniques have been recently used with spectacular results to generate artefacts such as music or text.
However, these techniques are still unable to capture and generate artefacts that are convincingly structured.
In this paper we present an approach to generate structured musical sequences.
We introduce a mechanism for sampling efficiently variations of musical sequences.
Given a input sequence and a statistical model, this mechanism samples a set of sequences whose distance to the input sequence is approximately within specified bounds.
This mechanism is implemented as an extension of belief propagation, and uses local fields to bias the generation.
We show experimentally that sampled sequences are indeed closely correlated to the standard musical similarity measure defined by Mongeau and Sankoff.
We then show how this mechanism can used to implement composition strategies that enforce arbitrary structure on a musical lead sheet generation problem.
