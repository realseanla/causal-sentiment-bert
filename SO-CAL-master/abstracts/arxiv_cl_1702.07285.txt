Emojis are ideograms which are naturally combined with plain text to visually complement or condense the meaning of a message.
Despite being widely used in social media, their underlying semantics have received little attention from a Natural Language Processing standpoint.
In this paper, we investigate the relation between words and emojis, studying the novel task of predicting which emojis are evoked by text-based tweet messages.
We train several models based on Long Short-Term Memory networks (LSTMs) in this task.
Our experimental results show that our neural model outperforms two baselines as well as humans solving the same task, suggesting that computational models are able to better capture the underlying semantics of emojis.
