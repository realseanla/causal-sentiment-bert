In this paper we propose introspective classifier learning (ICL) that emphasizes the importance of having a discriminative classifier empowered with generative capabilities.
We develop a reclassification-by-synthesis algorithm to perform training using a formulation stemmed from the Bayes theory.
Our classifier is able to iteratively: (1) synthesize pseudo-negative samples in the synthesis step; and (2) enhance itself by improving the classification in the reclassification step.
The single classifier learned is at the same time generative --- being able to directly synthesize new samples within its own discriminative model.
We conduct experiments on standard benchmark datasets including MNIST, CIFAR, and SVHN using state-of-the-art CNN architectures, and observe improved classification results.
