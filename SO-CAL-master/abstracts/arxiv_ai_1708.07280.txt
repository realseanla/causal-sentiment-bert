We consider the problem of learning for planning, where knowledge acquired while planning is reused to plan faster in new problem instances.
For robotic tasks, among others, plan execution can be captured as a sequence of visual images.
For such domains, we propose to use deep neural networks in learning for planning, based on learning a reactive policy that imitates execution traces produced by a planner.
We investigate architectural properties of deep networks that are suitable for learning long-horizon planning behavior, and explore how to learn, in addition to the policy, a heuristic function that can be used with classical planners or search algorithms such as A*.
Our results on the challenging Sokoban domain show that, with a suitable network design, complex decision making policies and powerful heuristic functions can be learned through imitation.
