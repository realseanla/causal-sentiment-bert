We propose an efficient technique for multilabel classification based on calibration, a term we use to mean learning a link function that maps independent predictions to joint predictions.
Though a naive implementation of our proposal would require training individual classifiers for each label, we show that for natural datasets and linear classifiers we can sidestep this by leveraging techniques from randomized linear algebra.
Moreover, our algorithm applies equally well to multiclass classification.
The end result is an algorithm that scales to very large multilabel and multiclass problems, and offers state of the art accuracy on many datasets.
