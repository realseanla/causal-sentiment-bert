Image clustering is one of the most important computer vision applications, which has been extensively studied in literature.
However, current clustering methods mostly suffer from lack of efficiency and scalability when dealing with large-scale and high-dimensional data.
In this paper, we propose a new clustering model, called DEeP Embedded RegularIzed ClusTering (DEPICT), which efficiently maps data into a discriminative embedding subspace and precisely predicts cluster assignments.
DEPICT generally consists of a multinomial logistic regression function stacked on top of a multi-layer convolutional autoencoder.
We define a clustering objective function using relative entropy (KL divergence) minimization, regularized by a prior for the frequency of clusters.
An alternating strategy is then derived to optimize the objective by updating parameters and estimating cluster assignments.
Furthermore, we employ the reconstruction loss functions in our autoencoder, as a data-dependent regularization term, to prevent the deep embedding function from overfitting.
In order to benefit from end-to-end optimization and eliminate the necessity for layer-wise pretraining, we introduce a joint learning framework to minimize the unified clustering and reconstruction loss functions together and train all network layers simultaneously.
Experimental results indicate the superiority and speed of DEPICT and our joint learning approach in real-world clustering tasks, in which no labeled data is available for hyper-parameter tuning.
