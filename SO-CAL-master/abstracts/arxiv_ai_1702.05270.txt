People can refer to quantities in a visual scene by using either exact cardinals (e.g.
one, two, three) or natural language quantifiers (e.g.
few, most, all).
In humans, these two processes underlie fairly different cognitive and neural mechanisms.
Inspired by this evidence, the present study proposes two models for learning the objective meaning of cardinals and quantifiers from visual scenes containing multiple objects.
We show that a model capitalizing on a 'fuzzy' measure of similarity is effective for learning quantifiers, whereas the learning of exact cardinals is better accomplished when information about number is provided.
