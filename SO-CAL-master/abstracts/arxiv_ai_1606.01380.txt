Real-world multi-agent planning problems cannot be solved using decision-theoretic planning methods due to the exponential complexity.
We approximate firefighting in rescue simulation as a spatially distributed task and model with multi-agent Markov decision process.
We use recent approximation methods for spatial task problems to reduce the model complexity.
Our approximations are single-agent, static task, shortest path pruning, dynamic planning horizon, and task clustering.
We create scenarios from RoboCup Rescue Simulation maps and evaluate our methods on these graph worlds.
The results show that our approach is faster and better than comparable methods and has negligible performance loss compared to the optimal policy.
We also show that our method has a similar performance as DCOP methods on example RCRS scenarios.
