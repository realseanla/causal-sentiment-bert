Conditional Random Field (CRF) and recurrent neural models have achieved success in structured prediction.
More recently, there is a marriage of CRF and recurrent neural models, so that we can gain from both non-linear dense features and globally normalized CRF objective.
These recurrent neural CRF models mainly focus on encode node features in CRF undirected graphs.
However, edge features prove important to CRF in structured prediction.
In this work, we introduce a new recurrent neural CRF model, which learns non-linear edge features, and thus makes non-linear features encoded completely.
We compare our model with different neural models in well-known structured prediction tasks.
Experiments show that our model outperforms state-of-the-art methods in NP chunking, shallow parsing, Chinese word segmentation and POS tagging.
