Canonical correlation analysis (CCA) is a method for reducing the dimension of data represented using two views.
It has been previously used to derive word embeddings, where one view indicates a word, and the other view indicates its context.
We describe a way to incorporate prior knowledge into CCA, give a theoretical justification for it, and test it by deriving word embeddings and evaluating them on a myriad of datasets.
