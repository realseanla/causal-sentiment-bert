Recently there has been substantial interest in predictive state methods for learning dynamical systems: these algorithms are popular since they often offer a good tradeoff between computational speed and statistical efficiency.
Despite their desirable properties, though, predictive state methods can sometimes be difficult to use in practice.
E.g., in contrast to the rich literature on supervised learning methods, which allows us to choose from an extensive menu of models and algorithms to suit the prior beliefs we have about properties of the function to be learned, predictive state dynamical system learning methods are comparatively inflexible: it is as if we were restricted to use only linear regression instead of being allowed to choose decision trees, nonparametric regression, or the lasso.
To address this problem, we propose a new view of predictive state methods in terms of instrumental variable regression.
This view allows us to construct a wide variety of dynamical system learners simply by swapping in different supervised learning methods.
We demonstrate the effectiveness of our proposed methods by experimenting with non-linear regression to learn a hidden Markov model, showing that the resulting algorithm outperforms the correctness of this algorithm follows directly from our general analysis.
