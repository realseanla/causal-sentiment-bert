We propose a new approach to value-directed belief state approximation for POMDPs.
The value-directed model allows one to choose approximation methods for belief state monitoring that have a small impact on decision quality.
Using a vector space analysis of the problem, we devise two new search procedures for selecting an approximation scheme that have much better computational properties than existing methods.
Though these provide looser error bounds, we show empirically that they have a similar impact on decision quality in practice, and run up to two orders of magnitude more quickly.
