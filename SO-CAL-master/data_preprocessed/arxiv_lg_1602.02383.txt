Representation/NN learning/NN is/VBZ the/DT foundation/NN for/IN the/DT recent/JJ success/NN of/IN neural/JJ network/NN models/NNS ./.
However/RB ,/, the/DT distributed/VBN representations/NNS generated/VBN by/IN neural/JJ networks/NNS are/VBP far/RB from/IN ideal/NN ./.
Due/IN to/IN their/PRP$ highly/RB entangled/JJ nature/NN ,/, they/PRP are/VBP di/NNP cult/NN to/TO reuse/VB and/CC interpret/VB ,/, and/CC they/PRP do/VBP a/DT poor/JJ job/NN of/IN capturing/VBG the/DT sparsity/NN which/WDT is/VBZ present/JJ in/IN real/JJ -/HYPH world/NN transformations/NNS ./.
In/IN this/DT paper/NN ,/, I/PRP describe/VBP methods/NNS for/IN learning/VBG disentangled/JJ representations/NNS in/IN the/DT two/CD domains/NNS of/IN graphics/NNS and/CC computation/NN ./.
These/DT methods/NNS allow/VBP neural/JJ methods/NNS to/TO learn/VB representations/NNS which/WDT are/VBP easy/JJ to/TO interpret/VB and/CC reuse/VB ,/, yet/CC they/PRP incur/VBP little/JJ or/CC no/DT penalty/NN to/IN performance/NN ./.
In/IN the/DT Graphics/NNP section/NN ,/, I/PRP demonstrate/VBP the/DT ability/NN of/IN these/DT methods/NNS to/TO infer/VB the/DT generating/VBG parameters/NNS of/IN images/NNS and/CC rerender/VB those/DT images/NNS under/IN novel/JJ conditions/NNS ./.
In/IN the/DT Computation/NN section/NN ,/, I/PRP describe/VBP a/DT model/NN which/WDT is/VBZ able/JJ to/TO factorize/VB a/DT multitask/JJ learning/NN problem/NN into/IN subtasks/NNS and/CC which/WDT experiences/NNS no/DT catastrophic/JJ forgetting/VBG ./.
Together/RB these/DT techniques/NNS provide/VBP the/DT tools/NNS to/TO design/VB a/DT wide/JJ range/NN of/IN models/NNS that/WDT learn/VBP disentangled/JJ representations/NNS and/CC better/JJR model/NN the/DT factors/NNS of/IN variation/NN in/IN the/DT real/JJ world/NN ./.
