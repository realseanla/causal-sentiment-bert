We/PRP formulate/VBP sequence/NN to/IN sequence/NN transduction/NN as/IN a/DT noisy/JJ channel/NN decoding/NN problem/NN and/CC use/VB recurrent/JJ neural/JJ networks/NNS to/TO parameterise/VB the/DT source/NN and/CC channel/NN models/NNS ./.
Unlike/IN direct/JJ models/NNS which/WDT can/MD suffer/VB from/IN explaining/VBG -/HYPH away/RB effects/NNS during/IN training/NN ,/, noisy/JJ channel/NN models/NNS must/MD produce/VB outputs/NNS that/WDT explain/VBP their/PRP$ inputs/NNS ,/, and/CC their/PRP$ component/NN models/NNS can/MD be/VB trained/VBN with/IN not/RB only/RB paired/JJ training/NN samples/NNS but/CC also/RB unpaired/JJ samples/NNS from/IN the/DT marginal/JJ output/NN distribution/NN ./.
Using/VBG a/DT latent/JJ variable/NN to/TO control/VB how/WRB much/JJ of/IN the/DT conditioning/NN sequence/NN the/DT channel/NN model/NN needs/VBZ to/TO read/VB in/IN order/NN to/TO generate/VB a/DT subsequent/JJ symbol/NN ,/, we/PRP obtain/VBP a/DT tractable/JJ and/CC effective/JJ beam/NN search/NN decoder/NN ./.
Experimental/JJ results/NNS on/IN abstractive/JJ sentence/NN summarisation/NN ,/, morphological/JJ inflection/NN ,/, and/CC machine/NN translation/NN show/NN that/WDT noisy/JJ channel/NN models/NNS outperform/VBP direct/JJ models/NNS ,/, and/CC that/IN they/PRP significantly/RB benefit/VBP from/IN increased/VBN amounts/NNS of/IN unpaired/JJ output/NN data/NNS that/WDT direct/JJ models/NNS can/MD not/RB easily/RB use/VB ./.
