We/PRP improve/VBP the/DT computational/JJ complexity/NN of/IN online/JJ learning/NN algorithms/NNS that/WDT require/VBP to/TO often/RB recompute/VB least/JJS squares/NNS regression/NN estimates/NNS of/IN parameters/NNS ./.
We/PRP propose/VBP two/CD stochastic/JJ gradient/NN descent/NN schemes/NNS with/IN randomisation/NN in/IN order/NN to/TO efficiently/RB track/VB the/DT true/JJ solutions/NNS of/IN the/DT regression/NN problems/NNS achieving/VBG an/DT O/NN (/-LRB- d/NN )/-RRB- improvement/NN in/IN complexity/NN ,/, where/WRB d/NN is/VBZ the/DT dimension/NN of/IN the/DT data/NNS ./.
The/DT first/JJ algorithm/NN assumes/VBZ strong/JJ convexity/NN in/IN the/DT regression/NN problem/NN ,/, and/CC we/PRP provide/VBP bounds/NNS on/IN the/DT error/NN both/CC in/IN expectation/NN and/CC high/JJ probability/NN (/-LRB- the/DT latter/JJ is/VBZ often/RB needed/VBN to/TO provide/VB theoretical/JJ guarantees/NNS for/IN higher/JJR level/NN algorithms/NNS )/-RRB- ./.
The/DT second/JJ algorithm/NN deals/NNS with/IN cases/NNS where/WRB strong/JJ convexity/NN of/IN the/DT regression/NN problem/NN can/MD not/RB be/VB guaranteed/VBN and/CC uses/VBZ adaptive/JJ regularisation/NN ./.
We/PRP again/RB give/VBP error/NN bounds/NNS in/IN both/DT expectation/NN and/CC high/JJ probability/NN ./.
We/PRP apply/VBP our/PRP$ approaches/NNS to/IN the/DT linear/JJ bandit/NN algorithms/NNS PEGE/NN and/CC ConfidenceBall/NN and/CC demonstrate/VBP significant/JJ gains/NNS in/IN complexity/NN in/IN both/DT cases/NNS ./.
Since/IN strong/JJ convexity/NN is/VBZ guaranteed/VBN by/IN the/DT PEGE/NN algorithm/NN ,/, we/PRP lose/VBP only/RB logarithmic/JJ factors/NNS in/IN the/DT regret/NN performance/NN of/IN the/DT algorithm/NN ./.
On/IN the/DT other/JJ hand/NN ,/, in/IN the/DT ConfidenceBall/NNP algorithm/NN we/PRP adaptively/RB regularise/VB to/TO ensure/VB strong/JJ convexity/NN ,/, and/CC this/DT results/VBZ in/IN an/DT O/NN (/-LRB- n/NN ^/SYM {/-LRB- 1/5/CD }/-RRB- )/-RRB- deterioration/NN of/IN the/DT regret/NN ./.
