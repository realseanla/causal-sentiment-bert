We/PRP study/VBP the/DT multi-armed/JJ bandit/NN (/-LRB- MAB/NN )/-RRB- problem/NN where/WRB the/DT agent/NN receives/VBZ a/DT vectorial/JJ feedback/NN that/WDT encodes/VBZ many/JJ possibly/RB competing/VBG objectives/NNS to/TO be/VB optimized/VBN ./.
The/DT goal/NN of/IN the/DT agent/NN is/VBZ to/TO find/VB a/DT policy/NN ,/, which/WDT can/MD optimize/VB these/DT objectives/NNS simultaneously/RB in/IN a/DT fair/JJ way/NN ./.
This/DT multi-objective/JJ online/JJ optimization/NN problem/NN is/VBZ formalized/VBN by/IN using/VBG the/DT Generalized/VBN Gini/NNP Index/NNP (/-LRB- GGI/NN )/-RRB- aggregation/NN function/NN ./.
We/PRP propose/VBP an/DT online/JJ gradient/NN descent/NN algorithm/NN which/WDT exploits/VBZ the/DT convexity/NN of/IN the/DT GGI/NN aggregation/NN function/NN ,/, and/CC controls/VBZ the/DT exploration/NN in/IN a/DT careful/JJ way/NN achieving/VBG a/DT distribution/NN -/HYPH free/JJ regret/NN $/$ \/SYM tilde/NN {/-LRB- \/SYM bigO/NN }/-RRB- (/-LRB- T/NN ^/SYM {/-LRB- -/HYPH 1/2/CD }/-RRB- )/-RRB- $/$ with/IN high/JJ probability/NN ./.
We/PRP test/VBP our/PRP$ algorithm/NN on/IN synthetic/JJ data/NNS as/RB well/RB as/IN on/IN an/DT electric/JJ battery/NN control/NN problem/NN where/WRB the/DT goal/NN is/VBZ to/TO trade/VB off/RP the/DT use/NN of/IN the/DT different/JJ cells/NNS of/IN a/DT battery/NN in/IN order/NN to/TO balance/VB their/PRP$ respective/JJ degradation/NN rates/NNS ./.
