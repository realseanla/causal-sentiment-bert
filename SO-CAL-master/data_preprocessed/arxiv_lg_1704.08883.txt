Recent/JJ advances/NNS in/IN combining/VBG deep/JJ neural/JJ network/NN architectures/NNS with/IN reinforcement/NN learning/VBG techniques/NNS have/VBP shown/VBN promising/JJ potential/JJ results/NNS in/IN solving/VBG complex/JJ control/NN problems/NNS with/IN high/JJ dimensional/JJ state/NN and/CC action/NN spaces/NNS ./.
Inspired/VBN by/IN these/DT successes/NNS ,/, in/IN this/DT paper/NN ,/, we/PRP build/VBP two/CD kinds/NNS of/IN reinforcement/NN learning/VBG algorithms/NNS :/: deep/JJ policy/NN -/HYPH gradient/NN and/CC value/NN -/HYPH function/NN based/VBN agents/NNS which/WDT can/MD predict/VB the/DT best/JJS possible/JJ traffic/NN signal/NN for/IN a/DT traffic/NN intersection/NN ./.
At/IN each/DT time/NN step/NN ,/, these/DT adaptive/JJ traffic/NN light/NN control/NN agents/NNS receive/VBP a/DT snapshot/NN of/IN the/DT current/JJ state/NN of/IN a/DT graphical/JJ traffic/NN simulator/NN and/CC produce/VB control/NN signals/NNS ./.
The/DT policy/NN -/HYPH gradient/NN based/VBN agent/NN maps/VBZ its/PRP$ observation/NN directly/RB to/IN the/DT control/NN signal/NN ,/, however/RB the/DT value/NN -/HYPH function/NN based/VBN agent/NN first/JJ estimates/NNS values/NNS for/IN all/DT legal/JJ control/NN signals/NNS ./.
The/DT agent/NN then/RB selects/VBZ the/DT optimal/JJ control/NN action/NN with/IN the/DT highest/JJS value/NN ./.
Our/PRP$ methods/NNS show/VBP promising/JJ results/NNS in/IN a/DT traffic/NN network/NN simulated/VBN in/IN the/DT SUMO/NN traffic/NN simulator/NN ,/, without/IN suffering/VBG from/IN instability/NN issues/NNS during/IN the/DT training/NN process/NN ./.
