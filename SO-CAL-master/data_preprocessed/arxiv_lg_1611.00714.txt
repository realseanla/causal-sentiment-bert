We/PRP propose/VBP a/DT scalable/JJ method/NN for/IN semi-supervised/JJ (/-LRB- transductive/JJ )/-RRB- learning/VBG from/IN massive/JJ network/NN -/HYPH structured/VBN datasets/NNS ./.
Our/PRP$ approach/NN to/IN semi-supervised/VBN learning/NN is/VBZ based/VBN on/IN representing/VBG the/DT underlying/VBG hypothesis/NN as/IN a/DT graph/NN signal/NN with/IN small/JJ total/JJ variation/NN ./.
Requiring/VBG a/DT small/JJ total/JJ variation/NN of/IN the/DT graph/NN signal/NN representing/VBG the/DT underlying/VBG hypothesis/NN corresponds/VBZ to/IN the/DT central/JJ smoothness/NN assumption/NN that/WDT forms/VBZ the/DT basis/NN for/IN semi-supervised/JJ learning/NN ,/, i.e./FW ,/, input/NN points/NNS forming/VBG clusters/NNS have/VBP similar/JJ output/NN values/NNS or/CC labels/NNS ./.
We/PRP formulate/VBP the/DT learning/NN problem/NN as/IN a/DT nonsmooth/JJ convex/NN optimization/NN problem/NN which/WDT we/PRP solve/VB by/IN appealing/VBG to/IN Nesterovs/NNP optimal/JJ first/JJ -/HYPH order/NN method/NN for/IN nonsmooth/JJ optimization/NN ./.
We/PRP also/RB provide/VBP a/DT message/NN passing/VBG formulation/NN of/IN the/DT learning/NN method/NN which/WDT allows/VBZ for/IN a/DT highly/RB scalable/JJ implementation/NN in/IN big/JJ data/NNS frameworks/NNS ./.
