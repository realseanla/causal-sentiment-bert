We/PRP propose/VBP a/DT new/JJ fast/JJ word/NN embedding/NN technique/NN using/VBG hash/NN functions/NNS ./.
The/DT method/NN is/VBZ a/DT derandomization/NN of/IN a/DT new/JJ type/NN of/IN random/JJ projections/NNS :/: By/IN disregarding/VBG the/DT classic/JJ constraint/NN used/VBN in/IN designing/VBG random/JJ projections/NNS (/-LRB- i.e./FW ,/, preserving/VBG pairwise/JJ distances/NNS in/IN a/DT particular/JJ normed/JJ space/NN )/-RRB- ,/, our/PRP$ solution/NN exploits/NNS extremely/RB sparse/JJ non-negative/JJ random/JJ projections/NNS ./.
Our/PRP$ experiments/NNS show/VBP that/IN the/DT proposed/JJ method/NN can/MD achieve/VB competitive/JJ results/NNS ,/, comparable/JJ to/IN neural/JJ embedding/NN learning/NN techniques/NNS ,/, however/RB ,/, with/IN only/RB a/DT fraction/NN of/IN the/DT computational/JJ complexity/NN of/IN these/DT methods/NNS ./.
While/IN the/DT proposed/VBN derandomization/NN enhances/VBZ the/DT computational/JJ and/CC space/NN complexity/NN of/IN our/PRP$ method/NN ,/, the/DT possibility/NN of/IN applying/VBG weighting/NN methods/NNS such/JJ as/IN positive/JJ pointwise/NN mutual/JJ information/NN (/-LRB- PPMI/NNP )/-RRB- to/IN our/PRP$ models/NNS after/IN their/PRP$ construction/NN (/-LRB- and/CC at/IN a/DT reduced/VBN dimensionality/NN )/-RRB- imparts/VBZ a/DT high/JJ discriminatory/JJ power/NN to/IN the/DT resulting/VBG embeddings/NNS ./.
Obviously/RB ,/, this/DT method/NN comes/VBZ with/IN other/JJ known/JJ benefits/NNS of/IN random/JJ projection/NN -/HYPH based/VBN techniques/NNS such/JJ as/IN ease/NN of/IN update/NN ./.
