We/PRP introduce/VBP a/DT novel/JJ type/NN of/IN artificial/JJ neural/JJ network/NN structure/NN and/CC training/NN procedure/NN that/WDT results/VBZ in/IN networks/NNS that/WDT are/VBP provably/RB ,/, quantitatively/RB more/RBR robust/JJ to/IN adversarial/JJ samples/NNS than/IN classical/JJ ,/, end/NN -/HYPH to/IN -/HYPH end/NN trained/VBN classifiers/NNS ./.
The/DT main/JJ idea/NN of/IN our/PRP$ approach/NN is/VBZ to/TO force/VB the/DT network/NN to/TO make/VB predictions/NNS on/IN what/WP the/DT given/VBN instance/NN of/IN the/DT class/NN under/IN consideration/NN would/MD look/VB like/IN and/CC subsequently/RB test/VB those/DT predictions/NNS ./.
By/IN forcing/VBG the/DT network/NN to/TO redraw/VB the/DT relevant/JJ parts/NNS of/IN the/DT image/NN and/CC subsequently/RB comparing/VBG this/DT new/JJ image/NN to/IN the/DT original/JJ ,/, we/PRP are/VBP having/VBG the/DT network/NN give/VB a/DT '/`` proof/NN '/'' of/IN the/DT presence/NN of/IN the/DT object/NN ./.
