Support/NN Vector/NNP Machine/NNP is/VBZ one/CD of/IN the/DT most/RBS classical/JJ approaches/NNS for/IN classification/NN and/CC regression/NN ./.
Despite/IN being/VBG studied/VBN for/IN decades/NNS ,/, obtaining/VBG practical/JJ algorithms/NNS for/IN SVM/NNP is/VBZ still/RB an/DT active/JJ research/NN problem/NN in/IN machine/NN learning/NN ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT new/JJ perspective/NN for/IN SVM/NNP via/IN saddle/NN point/NN optimization/NN ./.
We/PRP provide/VBP an/DT algorithm/NN which/WDT achieves/VBZ $/$ (/-LRB- 1/CD -/SYM \/SYM epsilon/SYM )/-RRB- $/$ -/HYPH approximations/NNS with/IN running/VBG time/NN $/$ \/SYM tilde/NN {/-LRB- O/NN }/-RRB- (/-LRB- nd/NN n/NN \/SYM sqrt/NN {/-LRB- d/NN //HYPH \/SYM epsilon/NN }/-RRB- )/-RRB- $/$ for/IN both/DT separable/JJ (/-LRB- hard/JJ margin/NN SVM/NN )/-RRB- and/CC non-separable/JJ cases/NNS (/-LRB- $/$ \/CD nu/CD $/$ -/HYPH SVM/NN )/-RRB- ,/, where/WRB $/$ n/NN $/$ is/VBZ the/DT number/NN of/IN points/NNS and/CC $/$ d/LS $/$ is/VBZ the/DT dimensionality/NN ./.
To/IN the/DT best/JJS of/IN our/PRP$ knowledge/NN ,/, the/DT current/JJ best/JJS algorithm/NN for/IN hard/JJ margin/NN SVM/NNP achieved/VBN by/IN Gilbert/NNP algorithm/NN ~/SYM requires/VBZ $/$ O/UH (/-LRB- nd/NN //HYPH \/SYM epsilon/NN )/-RRB- $/$ time/NN ./.
Our/PRP$ algorithm/NN improves/VBZ the/DT running/NN time/NN by/IN a/DT factor/NN of/IN $/$ \/CD sqrt/NN {/-LRB- d/NN }/-RRB- //HYPH \/SYM sqrt/NN {/-LRB- \/SYM epsilon/NN }/-RRB- $/$ ./.
For/IN $/$ \/CD nu/CD $/$ -/HYPH SVM/NN ,/, besides/IN the/DT well/RB known/VBN quadratic/JJ programming/NN approach/NN which/WDT requires/VBZ $/$ \/SYM Omega/NN (/-LRB- n/NN ^/SYM 2/CD d/NN )/-RRB- $/$ time/NN ~/SYM ,/, no/DT better/JJR algorithm/NN is/VBZ known/VBN ./.
In/IN the/DT paper/NN ,/, we/PRP provide/VBP the/DT first/JJ nearly/RB linear/JJ time/NN algorithm/NN for/IN $/$ \/CD nu/CD $/$ -/HYPH SVM/NN ./.
We/PRP also/RB consider/VBP the/DT distributed/VBN settings/NNS and/CC provide/VB distributed/VBN algorithms/NNS with/IN low/JJ communication/NN cost/NN via/IN saddle/NN point/NN optimization/NN ./.
Our/PRP$ algorithms/NNS require/VBP $/$ \/SYM tilde/NN {/-LRB- O/NN }/-RRB- (/-LRB- k/CD (/-LRB- d/NN \/SYM sqrt/NN {/-LRB- d/NN //HYPH \/SYM epsilon/NN }/-RRB- )/-RRB- )/-RRB- $/$ communication/NN cost/NN where/WRB $/$ k/CD $/$ is/VBZ the/DT number/NN of/IN clients/NNS ,/, almost/RB matching/VBG the/DT theoretical/JJ lower/JJR bound/JJ ./.
