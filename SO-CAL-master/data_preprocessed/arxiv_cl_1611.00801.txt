In/IN this/DT paper/NN ,/, we/PRP study/VBP a/DT novel/JJ approach/NN for/IN named/VBN entity/NN recognition/NN (/-LRB- NER/NN )/-RRB- and/CC mention/VB detection/NN in/IN natural/JJ language/NN processing/NN ./.
Instead/RB of/IN treating/VBG NER/NN as/IN a/DT sequence/NN labelling/NN problem/NN ,/, we/PRP propose/VBP a/DT new/JJ local/JJ detection/NN approach/NN ,/, which/WDT rely/VBP on/IN the/DT recent/JJ fixed/VBN -/HYPH size/NN ordinally/RB forgetting/VBG encoding/VBG (/-LRB- FOFE/NN )/-RRB- method/NN to/TO fully/RB encode/VB each/DT sentence/NN fragment/NN and/CC its/PRP$ left/JJ //SYM right/JJ contexts/NNS into/IN a/DT fixed/VBN -/HYPH size/NN representation/NN ./.
Afterwards/RB ,/, a/DT simple/JJ feedforward/JJ neural/JJ network/NN is/VBZ used/VBN to/TO reject/VB or/CC predict/VB entity/NN label/NN for/IN each/DT individual/JJ fragment/NN ./.
The/DT proposed/JJ method/NN has/VBZ been/VBN evaluated/VBN in/IN several/JJ popular/JJ NER/NN and/CC mention/VB detection/NN tasks/NNS ,/, including/VBG the/DT CoNLL/NN 2003/CD NER/NN task/NN and/CC TAC/NN -/HYPH KBP2015/NN and/CC TAC/NN -/HYPH KBP2016/NN Tri-lingual/JJ Entity/NNP Discovery/NNP and/CC Linking/VBG (/-LRB- EDL/NN )/-RRB- tasks/NNS ./.
Our/PRP$ methods/NNS have/VBP yielded/VBN pretty/RB strong/JJ performance/NN in/IN all/DT of/IN these/DT examined/VBN tasks/NNS ./.
This/DT local/JJ detection/NN approach/NN has/VBZ shown/VBN many/JJ advantages/NNS over/IN the/DT traditional/JJ sequence/NN labelling/NN methods/NNS ./.
