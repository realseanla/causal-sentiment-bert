Matrix/NN factorization/NN is/VBZ a/DT popular/JJ approach/NN for/IN large/JJ -/HYPH scale/NN matrix/NN completion/NN and/CC constitutes/VBZ a/DT basic/JJ component/NN of/IN many/JJ solutions/NNS for/IN Netflix/NNP Prize/NNP competition/NN ./.
In/IN this/DT approach/NN ,/, the/DT unknown/JJ low/JJ -/HYPH rank/NN matrix/NN is/VBZ expressed/VBN as/IN the/DT product/NN of/IN two/CD much/RB smaller/JJR matrices/NNS so/IN that/IN the/DT low/JJ -/HYPH rank/NN property/NN is/VBZ automatically/RB fulfilled/VBN ./.
The/DT resulting/VBG optimization/NN problem/NN ,/, even/RB with/IN huge/JJ size/NN ,/, can/MD be/VB solved/VBN (/-LRB- to/IN stationary/JJ points/NNS )/-RRB- very/RB efficiently/RB through/IN standard/JJ optimization/NN algorithms/NNS such/JJ as/IN alternating/VBG minimization/NN and/CC stochastic/JJ gradient/NN descent/NN (/-LRB- SGD/NNP )/-RRB- ./.
However/RB ,/, due/IN to/IN the/DT non-convexity/NN caused/VBN by/IN the/DT factorization/NN model/NN ,/, there/EX is/VBZ a/DT limited/JJ theoretical/JJ understanding/NN of/IN whether/IN these/DT algorithms/NNS will/MD generate/VB a/DT good/JJ solution/NN ./.
In/IN this/DT paper/NN ,/, we/PRP establish/VBP a/DT theoretical/JJ guarantee/NN for/IN the/DT factorization/NN based/VBN formulation/NN to/TO correctly/RB recover/VB the/DT underlying/VBG low/JJ -/HYPH rank/NN matrix/NN ./.
In/IN particular/JJ ,/, we/PRP show/VBP that/IN under/IN similar/JJ conditions/NNS to/IN those/DT in/IN previous/JJ works/NNS ,/, many/JJ standard/JJ optimization/NN algorithms/NNS converge/VBP to/IN the/DT global/JJ optima/NN of/IN the/DT factorization/NN based/VBN formulation/NN ,/, thus/RB recovering/VBG the/DT true/JJ low/JJ -/HYPH rank/NN matrix/NN ./.
To/IN the/DT best/JJS of/IN our/PRP$ knowledge/NN ,/, our/PRP$ result/NN is/VBZ the/DT first/JJ one/NN that/WDT provides/VBZ recovery/NN guarantee/NN for/IN many/JJ standard/JJ algorithms/NNS such/JJ as/IN gradient/NN descent/NN ,/, SGD/NNP and/CC block/NN coordinate/VBP gradient/NN descent/NN ./.
Our/PRP$ result/NN also/RB applies/VBZ to/IN alternating/VBG minimization/NN ,/, and/CC a/DT notable/JJ difference/NN from/IN previous/JJ studies/NNS on/IN alternating/VBG minimization/NN is/VBZ that/IN we/PRP do/VBP not/RB need/VB the/DT resampling/VBG scheme/NN (/-LRB- i.e./FW using/VBG independent/JJ samples/NNS in/IN each/DT iteration/NN )/-RRB- ./.
