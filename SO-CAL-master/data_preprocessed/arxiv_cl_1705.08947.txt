We/PRP introduce/VBP a/DT technique/NN for/IN augmenting/VBG neural/JJ text/NN -/HYPH to/IN -/HYPH speech/NN (/-LRB- TTS/NN )/-RRB- with/IN lowdimensional/NN trainable/JJ speaker/NN embeddings/NNS to/TO generate/VB different/JJ voices/NNS from/IN a/DT single/JJ model/NN ./.
As/IN a/DT starting/NN point/NN ,/, we/PRP show/VBP improvements/NNS over/IN the/DT two/CD state/NN -/HYPH ofthe/NN -/HYPH art/NN approaches/NNS for/IN single/JJ -/HYPH speaker/NN neural/JJ TTS/NN :/: Deep/JJ Voice/NNP 1/CD and/CC Tacotron/NNP ./.
We/PRP introduce/VBP Deep/JJ Voice/NNP 2/CD ,/, which/WDT is/VBZ based/VBN on/IN a/DT similar/JJ pipeline/NN with/IN Deep/JJ Voice/NNP 1/CD ,/, but/CC constructed/VBN with/IN higher/JJR performance/NN building/NN blocks/NNS and/CC demonstrates/VBZ a/DT significant/JJ audio/JJ quality/NN improvement/NN over/IN Deep/NNP Voice/NNP 1/CD ./.
We/PRP improve/VBP Tacotron/NNP by/IN introducing/VBG a/DT post-processing/JJ neural/JJ vocoder/NN ,/, and/CC demonstrate/VBP a/DT significant/JJ audio/JJ quality/NN improvement/NN ./.
We/PRP then/RB demonstrate/VBP our/PRP$ technique/NN for/IN multi-speaker/JJ speech/NN synthesis/NN for/IN both/DT Deep/JJ Voice/NNP 2/CD and/CC Tacotron/NNP on/IN two/CD multi-speaker/JJ TTS/NN datasets/NNS ./.
We/PRP show/VBP that/IN a/DT single/JJ neural/JJ TTS/NN system/NN can/MD learn/VB hundreds/NNS of/IN unique/JJ voices/NNS from/IN less/JJR than/IN half/PDT an/DT hour/NN of/IN data/NNS per/IN speaker/NN ,/, while/IN achieving/VBG high/JJ audio/JJ quality/NN synthesis/NN and/CC preserving/VBG the/DT speaker/NN identities/NNS almost/RB perfectly/RB ./.
