Information/NN projections/NNS are/VBP the/DT key/JJ building/NN block/NN of/IN variational/JJ inference/NN algorithms/NNS and/CC are/VBP used/VBN to/TO approximate/VB a/DT target/NN probabilistic/JJ model/NN by/IN projecting/VBG it/PRP onto/IN a/DT family/NN of/IN tractable/JJ distributions/NNS ./.
In/IN general/JJ ,/, there/EX is/VBZ no/DT guarantee/NN on/IN the/DT quality/NN of/IN the/DT approximation/NN obtained/VBN ./.
To/TO overcome/VB this/DT issue/NN ,/, we/PRP introduce/VBP a/DT new/JJ class/NN of/IN random/JJ projections/NNS to/TO reduce/VB the/DT dimensionality/NN and/CC hence/RB the/DT complexity/NN of/IN the/DT original/JJ model/NN ./.
In/IN the/DT spirit/NN of/IN random/JJ projections/NNS ,/, the/DT projection/NN preserves/VBZ (/-LRB- with/IN high/JJ probability/NN )/-RRB- key/JJ properties/NNS of/IN the/DT target/NN distribution/NN ./.
We/PRP show/VBP that/IN information/NN projections/NNS can/MD be/VB combined/VBN with/IN random/JJ projections/NNS to/TO obtain/VB provable/JJ guarantees/NNS on/IN the/DT quality/NN of/IN the/DT approximation/NN obtained/VBN ,/, regardless/RB of/IN the/DT complexity/NN of/IN the/DT original/JJ model/NN ./.
We/PRP demonstrate/VBP empirically/RB that/IN augmenting/VBG mean/JJ field/NN with/IN a/DT random/JJ projection/NN step/NN dramatically/RB improves/VBZ partition/NN function/NN and/CC marginal/JJ probability/NN estimates/NNS ,/, both/DT on/IN synthetic/JJ and/CC real/JJ world/NN data/NNS ./.
