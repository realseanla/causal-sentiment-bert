We/PRP present/VBP a/DT novel/JJ end/NN -/HYPH to/IN -/HYPH end/NN neural/JJ model/NN to/TO extract/VB entities/NNS and/CC relations/NNS between/IN them/PRP ./.
Our/PRP$ recurrent/JJ neural/JJ network/NN based/VBN model/NN stacks/NNS bidirectional/JJ sequential/JJ LSTM/NN -/HYPH RNNs/NNS and/CC bidirectional/JJ tree/NN -/HYPH structured/VBN LSTM/NN -/HYPH RNNs/NNS to/TO capture/VB both/DT word/NN sequence/NN and/CC dependency/NN tree/NN substructure/NN information/NN ./.
This/DT allows/VBZ our/PRP$ model/NN to/TO jointly/RB represent/VB both/DT entities/NNS and/CC relations/NNS with/IN shared/VBN parameters/NNS ./.
We/PRP further/RB encourage/VBP detection/NN of/IN entities/NNS during/IN training/NN and/CC use/NN of/IN entity/NN information/NN in/IN relation/NN extraction/NN via/IN curriculum/NN learning/NN and/CC scheduled/VBN sampling/NN ./.
Our/PRP$ model/NN improves/VBZ over/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN feature/NN -/HYPH based/VBN model/NN on/IN end/NN -/HYPH to/IN -/HYPH end/NN relation/NN extraction/NN ,/, achieving/VBG 3.5/CD percent/NN and/CC 4.8/CD percent/NN relative/JJ error/NN reductions/NNS in/IN F/NN -/HYPH score/NN on/IN ACE2004/NN and/CC ACE2005/NN ,/, respectively/RB ./.
We/PRP also/RB show/VBP improvements/NNS over/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN convolutional/JJ neural/JJ network/NN based/VBN model/NN on/IN nominal/JJ relation/NN classification/NN (/-LRB- SemEval/NNP -/HYPH 2010/CD Task/NNP 8/CD )/-RRB- ,/, with/IN 2.5/CD percent/NN relative/JJ error/NN reduction/NN in/IN F/NN -/HYPH score/NN ./.
