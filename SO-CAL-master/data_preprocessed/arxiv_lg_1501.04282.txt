In/IN this/DT paper/NN we/PRP investigate/VBP the/DT usage/NN of/IN regularized/VBN correntropy/NN framework/NN for/IN learning/NN of/IN classifiers/NNS from/IN noisy/JJ labels/NNS ./.
The/DT class/NN label/NN predictors/NNS learned/VBN by/IN minimizing/VBG transitional/JJ loss/NN functions/NNS are/VBP sensitive/JJ to/IN the/DT noisy/JJ and/CC outlying/JJ labels/NNS of/IN training/NN samples/NNS ,/, because/IN the/DT transitional/JJ loss/NN functions/NNS are/VBP equally/RB applied/VBN to/IN all/PDT the/DT samples/NNS ./.
To/TO solve/VB this/DT problem/NN ,/, we/PRP propose/VBP to/TO learn/VB the/DT class/NN label/NN predictors/NNS by/IN maximizing/VBG the/DT correntropy/NN between/IN the/DT predicted/VBN labels/NNS and/CC the/DT true/JJ labels/NNS of/IN the/DT training/NN samples/NNS ,/, under/IN the/DT regularized/VBN Maximum/NNP Correntropy/NNP Criteria/NNP (/-LRB- MCC/NNP )/-RRB- framework/NN ./.
Moreover/RB ,/, we/PRP regularize/VBP the/DT predictor/NN parameter/NN to/TO control/VB the/DT complexity/NN of/IN the/DT predictor/NN ./.
The/DT learning/NN problem/NN is/VBZ formulated/VBN by/IN an/DT objective/JJ function/NN considering/VBG the/DT parameter/NN regularization/NN and/CC MCC/NNP simultaneously/RB ./.
By/IN optimizing/VBG the/DT objective/JJ function/NN alternately/RB ,/, we/PRP develop/VBP a/DT novel/JJ predictor/NN learning/VBG algorithm/NN ./.
The/DT experiments/NNS on/IN two/CD chal/JJ -/HYPH lenging/NN pattern/NN classification/NN tasks/NNS show/VBP that/IN it/PRP significantly/RB outperforms/VBZ the/DT machines/NNS with/IN transitional/JJ loss/NN functions/NNS ./.
