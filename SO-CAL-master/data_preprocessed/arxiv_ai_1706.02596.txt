Despite/IN the/DT recent/JJ success/NN of/IN neural/JJ networks/NNS in/IN tasks/NNS involving/VBG natural/JJ language/NN understanding/NN (/-LRB- NLU/NN )/-RRB- there/EX has/VBZ only/RB been/VBN limited/VBN progress/NN in/IN some/DT of/IN the/DT fundamental/JJ challenges/NNS of/IN NLU/NNP ,/, such/JJ as/IN the/DT disambiguation/NN of/IN the/DT meaning/NN and/CC function/NN of/IN words/NNS in/IN context/NN ./.
This/DT work/NN approaches/VBZ this/DT problem/NN by/IN incorporating/VBG contextual/JJ information/NN into/IN word/NN representations/NNS prior/JJ to/IN processing/VBG the/DT task/NN at/IN hand/NN ./.
To/IN this/DT end/NN we/PRP propose/VBP a/DT general/JJ -/HYPH purpose/NN reading/NN architecture/NN that/WDT is/VBZ employed/VBN prior/JJ to/IN a/DT task/NN -/HYPH specific/JJ NLU/NN model/NN ./.
It/PRP is/VBZ responsible/JJ for/IN refining/NN context/NN -/HYPH agnostic/JJ word/NN representations/NNS with/IN contextual/JJ information/NN and/CC lends/VBZ itself/PRP to/IN the/DT introduction/NN of/IN additional/JJ ,/, context/NN -/HYPH relevant/JJ information/NN from/IN external/JJ knowledge/NN sources/NNS ./.
We/PRP demonstrate/VBP that/IN previously/RB non-competitive/JJ models/NNS benefit/VBP dramatically/RB from/IN employing/VBG contextual/JJ representations/NNS ,/, closing/VBG the/DT gap/NN between/IN general/JJ -/HYPH purpose/NN reading/NN architectures/NNS and/CC the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN obtained/VBN with/IN fine/JJ -/HYPH tuned/VBN ,/, task/NN -/HYPH specific/JJ architectures/NNS ./.
Apart/RB from/IN our/PRP$ empirical/JJ results/NNS we/PRP present/VBP a/DT comprehensive/JJ analysis/NN of/IN the/DT computed/VBN representations/NNS which/WDT gives/VBZ insights/NNS into/IN the/DT kind/NN of/IN information/NN added/VBN during/IN the/DT refinement/NN process/NN ./.
