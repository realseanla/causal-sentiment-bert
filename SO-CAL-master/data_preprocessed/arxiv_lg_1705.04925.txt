In/IN many/JJ modern/JJ machine/NN learning/NN applications/NNS ,/, structures/NNS of/IN underlying/VBG mathematical/JJ models/NNS often/RB yield/VBP nonconvex/JJ optimization/NN problems/NNS ./.
Due/IN to/IN the/DT intractability/NN of/IN nonconvexity/NN ,/, there/EX is/VBZ a/DT rising/VBG need/NN to/TO develop/VB efficient/JJ methods/NNS for/IN solving/VBG general/JJ nonconvex/NN problems/NNS with/IN certain/JJ performance/NN guarantee/NN ./.
In/IN this/DT work/NN ,/, we/PRP investigate/VBP the/DT accelerated/VBN proximal/JJ gradient/NN method/NN for/IN nonconvex/JJ programming/NN (/-LRB- APGnc/NN )/-RRB- ./.
The/DT method/NN compares/VBZ between/IN a/DT usual/JJ proximal/JJ gradient/NN step/NN and/CC a/DT linear/JJ extrapolation/NN step/NN ,/, and/CC accepts/VBZ the/DT one/NN that/WDT has/VBZ a/DT lower/JJR function/NN value/NN to/TO achieve/VB a/DT monotonic/JJ decrease/NN ./.
In/IN specific/JJ ,/, under/IN a/DT general/JJ nonsmooth/JJ and/CC nonconvex/JJ setting/NN ,/, we/PRP provide/VBP a/DT rigorous/JJ argument/NN to/TO show/VB that/IN the/DT limit/NN points/NNS of/IN the/DT sequence/NN generated/VBN by/IN APGnc/NNP are/VBP critical/JJ points/NNS of/IN the/DT objective/JJ function/NN ./.
Then/RB ,/, by/IN exploiting/VBG the/DT Kurdyka/NNP -/HYPH {/-LRB- \/SYM L/NN }/-RRB- ojasiewicz/NN (/-LRB- \/SYM KL/NN )/-RRB- property/NN for/IN a/DT broad/JJ class/NN of/IN functions/NNS ,/, we/PRP establish/VBP the/DT linear/JJ and/CC sub-linear/JJ convergence/NN rates/NNS of/IN the/DT function/NN value/NN sequence/NN generated/VBN by/IN APGnc/NNP ./.
We/PRP further/RB propose/VB a/DT stochastic/JJ variance/NN reduced/VBN APGnc/NNP (/-LRB- SVRG/NNP -/HYPH APGnc/NNP )/-RRB- ,/, and/CC establish/VB its/PRP$ linear/JJ convergence/NN under/IN a/DT special/JJ case/NN of/IN the/DT \/NN KL/NN property/NN ./.
We/PRP also/RB extend/VBP the/DT analysis/NN to/IN the/DT inexact/JJ version/NN of/IN these/DT methods/NNS and/CC develop/VB an/DT adaptive/JJ momentum/NN strategy/NN that/WDT improves/VBZ the/DT numerical/JJ performance/NN ./.
