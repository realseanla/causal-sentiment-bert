Many/JJ machine/NN learning/VBG approaches/NNS are/VBP characterized/VBN by/IN information/NN constraints/NNS on/IN how/WRB they/PRP interact/VBP with/IN the/DT training/NN data/NNS ./.
These/DT include/VBP memory/NN and/CC sequential/JJ access/NN constraints/NNS (/-LRB- e.g./FW fast/RB first/RB -/HYPH order/NN methods/NNS to/TO solve/VB stochastic/JJ optimization/NN problems/NNS )/-RRB- ;/: communication/NN constraints/NNS (/-LRB- e.g./FW distributed/VBN learning/NN )/-RRB- ;/: partial/JJ access/NN to/IN the/DT underlying/VBG data/NNS (/-LRB- e.g./FW missing/VBG features/NNS and/CC multi-armed/JJ bandits/NNS )/-RRB- and/CC more/JJR ./.
However/RB ,/, currently/RB we/PRP have/VBP little/JJ understanding/NN how/WRB such/JJ information/NN constraints/NNS fundamentally/RB affect/VBP our/PRP$ performance/NN ,/, independent/JJ of/IN the/DT learning/NN problem/NN semantics/NNS ./.
For/IN example/NN ,/, are/VBP there/EX learning/VBG problems/NNS where/WRB \/SYM emph/NN {/-LRB- any/DT }/-RRB- algorithm/NN which/WDT has/VBZ small/JJ memory/NN footprint/NN (/-LRB- or/CC can/MD use/VB any/DT bounded/VBN number/NN of/IN bits/NNS from/IN each/DT example/NN ,/, or/CC has/VBZ certain/JJ communication/NN constraints/NNS )/-RRB- will/MD perform/VB worse/JJR than/IN what/WP is/VBZ possible/JJ without/IN such/JJ constraints/NNS ?/.
In/IN this/DT paper/NN ,/, we/PRP describe/VBP how/WRB a/DT single/JJ set/NN of/IN results/NNS implies/VBZ positive/JJ answers/NNS to/IN the/DT above/JJ ,/, for/IN a/DT variety/NN of/IN settings/NNS ./.
