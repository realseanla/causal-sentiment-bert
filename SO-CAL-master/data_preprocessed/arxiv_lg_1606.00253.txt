Probabilistic/JJ topic/NN models/NNS are/VBP generative/JJ models/NNS that/WDT describe/VBP the/DT content/NN of/IN documents/NNS by/IN discovering/VBG the/DT latent/JJ topics/NNS underlying/VBG them/PRP ./.
However/RB ,/, the/DT structure/NN of/IN the/DT textual/JJ input/NN ,/, and/CC for/IN instance/NN the/DT grouping/NN of/IN words/NNS in/IN coherent/JJ text/NN spans/NNS such/JJ as/IN sentences/NNS ,/, contains/VBZ much/JJ information/NN which/WDT is/VBZ generally/RB lost/VBN with/IN these/DT models/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP sentenceLDA/NNP ,/, an/DT extension/NN of/IN LDA/NNP whose/WP$ goal/NN is/VBZ to/TO overcome/VB this/DT limitation/NN by/IN incorporating/VBG the/DT structure/NN of/IN the/DT text/NN in/IN the/DT generative/JJ and/CC inference/NN processes/NNS ./.
We/PRP illustrate/VBP the/DT advantages/NNS of/IN sentenceLDA/NN by/IN comparing/VBG it/PRP with/IN LDA/NN using/VBG both/CC intrinsic/JJ (/-LRB- perplexity/NN )/-RRB- and/CC extrinsic/JJ (/-LRB- text/NN classification/NN )/-RRB- evaluation/NN tasks/NNS on/IN different/JJ text/NN collections/NNS ./.
