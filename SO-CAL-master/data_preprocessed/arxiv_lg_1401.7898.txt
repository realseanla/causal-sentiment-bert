We/PRP develop/VBP a/DT general/JJ framework/NN for/IN margin/NN -/HYPH based/VBN multicategory/JJ classification/NN in/IN metric/JJ spaces/NNS ./.
The/DT basic/JJ work/NN -/HYPH horse/NN is/VBZ a/DT margin/NN -/HYPH regularized/VBN version/NN of/IN the/DT nearest/JJS -/HYPH neighbor/NN classifier/NN ./.
We/PRP prove/VBP generalization/NN bounds/NNS that/WDT match/VBP the/DT state/NN of/IN the/DT art/NN in/IN sample/NN size/NN $/$ n/NN $/$ and/CC significantly/RB improve/VB the/DT dependence/NN on/IN the/DT number/NN of/IN classes/NNS $/$ k/CD $/$ ./.
Our/PRP$ point/NN of/IN departure/NN is/VBZ a/DT nearly/RB Bayes/NNPS -/HYPH optimal/JJ finite/NN -/HYPH sample/NN risk/NN bound/VBN independent/JJ of/IN $/$ k/CD $/$ ./.
Although/IN $/$ k/CD $/$ -/HYPH free/JJ ,/, this/DT bound/VBN is/VBZ unregularized/JJ and/CC non-adaptive/JJ ,/, which/WDT motivates/VBZ our/PRP$ main/JJ result/NN :/: Rademacher/NNP and/CC scale/NN -/HYPH sensitive/JJ margin/NN bounds/NNS with/IN a/DT logarithmic/JJ dependence/NN on/IN $/$ k/CD $/$ ./.
As/IN the/DT best/JJS previous/JJ risk/NN estimates/NNS in/IN this/DT setting/NN were/VBD of/IN order/NN $/$ \/CD sqrt/NN k/CD $/$ ,/, our/PRP$ bound/VBN is/VBZ exponentially/RB sharper/JJR ./.
From/IN the/DT algorithmic/JJ standpoint/NN ,/, in/IN doubling/VBG metric/JJ spaces/NNS our/PRP$ classifier/NN may/MD be/VB trained/VBN on/IN $/$ n/NN $/$ examples/NNS in/IN $/$ O/UH (/-LRB- n/NN ^/SYM 2/CD \/SYM log/NN n/NN )/-RRB- $/$ time/NN and/CC evaluated/VBN on/IN new/JJ points/NNS in/IN $/$ O/UH (/-LRB- \/SYM log/NN n/NN )/-RRB- $/$ time/NN ./.
