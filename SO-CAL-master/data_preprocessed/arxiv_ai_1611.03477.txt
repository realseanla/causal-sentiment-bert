We/PRP present/VBP a/DT novel/JJ framework/NN for/IN generating/VBG pop/NN music/NN ./.
Our/PRP$ model/NN is/VBZ a/DT hierarchical/JJ Recurrent/JJ Neural/JJ Network/NN ,/, where/WRB the/DT layers/NNS and/CC the/DT structure/NN of/IN the/DT hierarchy/NN encode/VBP our/PRP$ prior/JJ knowledge/NN about/IN how/WRB pop/JJ music/NN is/VBZ composed/VBN ./.
In/IN particular/JJ ,/, the/DT bottom/JJ layers/NNS generate/VBP the/DT melody/NN ,/, while/IN the/DT higher/JJR levels/NNS produce/VBP the/DT drums/NNS and/CC chords/NNS ./.
We/PRP conduct/VBP several/JJ human/JJ studies/NNS that/WDT show/VBP strong/JJ preference/NN of/IN our/PRP$ generated/VBN music/NN over/IN that/DT produced/VBN by/IN the/DT recent/JJ method/NN by/IN Google/NNP ./.
We/PRP additionally/RB show/VBP two/CD applications/NNS of/IN our/PRP$ framework/NN :/: neural/JJ dancing/NN and/CC karaoke/NN ,/, as/RB well/RB as/IN neural/JJ story/NN singing/NN ./.
