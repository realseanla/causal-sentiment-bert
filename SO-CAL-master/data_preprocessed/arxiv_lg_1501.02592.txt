Nonlinear/JJ photonic/JJ delay/NN systems/NNS present/JJ interesting/JJ implementation/NN platforms/NNS for/IN machine/NN learning/NN models/NNS ./.
They/PRP can/MD be/VB extremely/RB fast/RB ,/, offer/VBP great/JJ degrees/NNS of/IN parallelism/NN and/CC potentially/RB consume/VBP far/RB less/JJR power/NN than/IN digital/JJ processors/NNS ./.
So/RB far/RB they/PRP have/VBP been/VBN successfully/RB employed/VBN for/IN signal/NN processing/NN using/VBG the/DT Reservoir/NNP Computing/NNP paradigm/NN ./.
In/IN this/DT paper/NN we/PRP show/VBP that/IN their/PRP$ range/NN of/IN applicability/NN can/MD be/VB greatly/RB extended/VBN if/IN we/PRP use/VBP gradient/NN descent/NN with/IN backpropagation/NN through/IN time/NN on/IN a/DT model/NN of/IN the/DT system/NN to/TO optimize/VB the/DT input/NN encoding/NN of/IN such/JJ systems/NNS ./.
We/PRP perform/VBP physical/JJ experiments/NNS that/WDT demonstrate/VBP that/IN the/DT obtained/VBN input/NN encodings/NNS work/VBP well/RB in/IN reality/NN ,/, and/CC we/PRP show/VBP that/IN optimized/VBN systems/NNS perform/VBP significantly/RB better/JJR than/IN the/DT common/JJ Reservoir/NNP Computing/NNP approach/NN ./.
The/DT results/NNS presented/VBN here/RB demonstrate/VBP that/IN common/JJ gradient/NN descent/NN techniques/NNS from/IN machine/NN learning/NN may/MD well/RB be/VB applicable/JJ on/IN physical/JJ neuro/NN -/HYPH inspired/VBN analog/NN computers/NNS ./.
