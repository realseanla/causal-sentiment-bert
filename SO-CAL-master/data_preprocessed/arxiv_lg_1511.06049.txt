Self/NN -/HYPH paced/VBN learning/NN (/-LRB- SPL/NN )/-RRB- has/VBZ been/VBN attracting/VBG increasing/VBG attention/NN in/IN machine/NN learning/NN and/CC computer/NN vision/NN ./.
Albeit/IN empirically/RB substantiated/VBN to/TO be/VB effective/JJ ,/, the/DT investigation/NN on/IN its/PRP$ theoretical/JJ insight/NN is/VBZ still/RB a/DT blank/JJ ./.
It/PRP is/VBZ even/RB unknown/JJ that/IN what/WP objective/NN a/DT general/JJ SPL/NN regime/NN converges/VBZ to/IN ./.
To/IN this/DT issue/NN ,/, this/DT study/NN attempts/VBZ to/TO initially/RB provide/VB some/DT new/JJ insights/NNS under/IN this/DT "/`` heuristic/NN "/'' learning/VBG scheme/NN ./.
Specifically/RB ,/, we/PRP prove/VBP that/IN the/DT solving/VBG strategy/NN on/IN SPL/NN exactly/RB accords/VBZ with/IN a/DT majorization/NN minimization/NN algorithm/NN ,/, a/DT well/RB known/VBN technique/NN in/IN optimization/NN and/CC machine/NN learning/NN ,/, implemented/VBN on/IN a/DT latent/JJ objective/NN ./.
A/DT more/RBR interesting/JJ finding/NN is/VBZ that/IN ,/, the/DT loss/NN function/NN contained/VBD in/IN this/DT latent/JJ objective/NN has/VBZ a/DT similar/JJ configuration/NN with/IN non-convex/JJ regularized/VBN penalty/NN ,/, an/DT attractive/JJ topic/NN in/IN statistics/NNS and/CC machine/NN learning/NN ./.
In/IN particular/JJ ,/, we/PRP show/VBP that/IN the/DT previous/JJ hard/JJ and/CC linear/JJ self/NN -/HYPH paced/VBN regularizers/NNS are/VBP equivalent/JJ to/IN the/DT capped/VBN norm/NN and/CC minimax/NN concave/NN plus/CC penalties/NNS ,/, respectively/RB ,/, both/DT being/VBG widely/RB investigated/VBN in/IN statistics/NNS ./.
Such/JJ connections/NNS between/IN SPL/NN and/CC previous/JJ known/VBN researches/NNS enhance/VB new/JJ insightful/JJ comprehension/NN on/IN SPL/NN ,/, like/IN convergence/NN and/CC parameter/NN setting/VBG rationality/NN ./.
The/DT correctness/NN of/IN the/DT proposed/VBN theory/NN is/VBZ substantiated/VBN by/IN experimental/JJ results/NNS on/IN synthetic/JJ and/CC UCI/NNP data/NNS sets/NNS ./.
