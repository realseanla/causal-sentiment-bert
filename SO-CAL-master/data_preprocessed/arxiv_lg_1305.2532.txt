Many/JJ prediction/NN domains/NNS ,/, such/JJ as/IN ad/NN placement/NN ,/, recommendation/NN ,/, trajectory/NN prediction/NN ,/, and/CC document/NN summarization/NN ,/, require/VBP predicting/VBG a/DT set/NN or/CC list/NN of/IN options/NNS ./.
Such/JJ lists/NNS are/VBP often/RB evaluated/VBN using/VBG submodular/JJ reward/NN functions/VBZ that/IN measure/NN both/CC quality/NN and/CC diversity/NN ./.
We/PRP propose/VBP a/DT simple/JJ ,/, efficient/JJ ,/, and/CC provably/RB near/RB -/HYPH optimal/JJ approach/NN to/IN optimizing/VBG such/JJ prediction/NN problems/NNS based/VBN on/IN no/DT -/HYPH regret/NN learning/NN ./.
Our/PRP$ method/NN leverages/VBZ a/DT surprising/JJ result/NN from/IN online/JJ submodular/JJ optimization/NN :/: a/DT single/JJ no/NN -/HYPH regret/NN online/JJ learner/NN can/MD compete/VB with/IN an/DT optimal/JJ sequence/NN of/IN predictions/NNS ./.
Compared/VBN to/IN previous/JJ work/NN ,/, which/WDT either/CC learn/VB a/DT sequence/NN of/IN classifiers/NNS or/CC rely/VBP on/IN stronger/JJR assumptions/NNS such/JJ as/IN realizability/NN ,/, we/PRP ensure/VBP both/DT data/NNS -/HYPH efficiency/NN as/RB well/RB as/IN performance/NN guarantees/NNS in/IN the/DT fully/RB agnostic/JJ setting/NN ./.
Experiments/NNS validate/VBP the/DT efficiency/NN and/CC applicability/NN of/IN the/DT approach/NN on/IN a/DT wide/JJ range/NN of/IN problems/NNS including/VBG manipulator/NN trajectory/NN optimization/NN ,/, news/NN recommendation/NN and/CC document/NN summarization/NN ./.
