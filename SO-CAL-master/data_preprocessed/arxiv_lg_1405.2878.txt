We/PRP consider/VBP the/DT infinite/JJ -/HYPH horizon/NN discounted/VBN optimal/JJ control/NN problem/NN formalized/VBN by/IN Markov/NNP Decision/NN Processes/NNS ./.
We/PRP focus/VBP on/IN several/JJ approximate/JJ variations/NNS of/IN the/DT Policy/NN Iteration/NN algorithm/NN :/: Approximate/JJ Policy/NN Iteration/NN ,/, Conservative/JJ Policy/NN Iteration/NN (/-LRB- CPI/NN )/-RRB- ,/, a/DT natural/JJ adaptation/NN of/IN the/DT Policy/NN Search/NN by/IN Dynamic/JJ Programming/NN algorithm/NN to/IN the/DT infinite/JJ -/HYPH horizon/NN case/NN (/-LRB- PSDP$/NNP _/NFP \/SYM infty/JJ $/$ )/-RRB- ,/, and/CC the/DT recently/RB proposed/VBN Non-Stationary/NNP Policy/NNP iteration/NN (/-LRB- NSPI/NN (/-LRB- m/NN )/-RRB- )/-RRB- ./.
For/IN all/DT algorithms/NNS ,/, we/PRP describe/VBP performance/NN bounds/NNS ,/, and/CC make/VB a/DT comparison/NN by/IN paying/VBG a/DT particular/JJ attention/NN to/IN the/DT concentrability/NN constants/NNS involved/VBN ,/, the/DT number/NN of/IN iterations/NNS and/CC the/DT memory/NN required/VBN ./.
Our/PRP$ analysis/NN highlights/VBZ the/DT following/VBG points/NNS :/: 1/LS )/-RRB- The/DT performance/NN guarantee/NN of/IN CPI/NN can/MD be/VB arbitrarily/RB better/JJR than/IN that/DT of/IN API/NN //HYPH API/NN (/-LRB- $/$ \/SYM alpha/NN $/$ )/-RRB- ,/, but/CC this/DT comes/VBZ at/IN the/DT cost/NN of/IN a/DT relative/JJ ---/, exponential/JJ in/IN $/$ \/CD frac/NN {/-LRB- 1/CD }/-RRB- {/-LRB- \/SYM epsilon/NN }/-RRB- $/$ ---/NFP increase/NN of/IN the/DT number/NN of/IN iterations/NNS ./.
2/LS )/-RRB- PSDP$/NNP _/NFP \/SYM infty/JJ $/$ enjoys/VBZ the/DT best/JJS of/IN both/DT worlds/NNS :/: its/PRP$ performance/NN guarantee/NN is/VBZ similar/JJ to/IN that/DT of/IN CPI/NN ,/, but/CC within/IN a/DT number/NN of/IN iterations/NNS similar/JJ to/IN that/DT of/IN API/NN ./.
3/LS )/-RRB- Contrary/JJ to/IN API/NN that/WDT requires/VBZ a/DT constant/JJ memory/NN ,/, the/DT memory/NN needed/VBN by/IN CPI/NNP and/CC PSDP$/NNP _/NFP \/SYM infty/JJ $/$ is/VBZ proportional/JJ to/IN their/PRP$ number/NN of/IN iterations/NNS ,/, which/WDT may/MD be/VB problematic/JJ when/WRB the/DT discount/NN factor/NN $/$ \/SYM gamma/NN $/$ is/VBZ close/JJ to/IN 1/CD or/CC the/DT approximation/NN error/NN $/$ \/CD epsilon/CD $/$ is/VBZ close/JJ to/IN $/$ 0/CD $/$ ;/: we/PRP show/VBP that/IN the/DT NSPI/NN (/-LRB- m/NN )/-RRB- algorithm/NN allows/VBZ to/TO make/VB an/DT overall/JJ trade/NN -/HYPH off/NN between/IN memory/NN and/CC performance/NN ./.
Simulations/NNS with/IN these/DT schemes/NNS confirm/VBP our/PRP$ analysis/NN ./.
