Learning/VBG from/IN a/DT few/JJ examples/NNS remains/VBZ a/DT key/JJ challenge/NN in/IN machine/NN learning/NN ./.
Despite/IN recent/JJ advances/NNS in/IN important/JJ domains/NNS such/JJ as/IN vision/NN and/CC language/NN ,/, the/DT standard/JJ supervised/JJ deep/JJ learning/NN paradigm/NN does/VBZ not/RB offer/VB a/DT satisfactory/JJ solution/NN for/IN learning/VBG new/JJ concepts/NNS rapidly/RB from/IN little/JJ data/NNS ./.
In/IN this/DT work/NN ,/, we/PRP employ/VBP ideas/NNS from/IN metric/JJ learning/NN based/VBN on/IN deep/JJ neural/JJ features/NNS and/CC from/IN recent/JJ advances/NNS that/WDT augment/VBP neural/JJ networks/NNS with/IN external/JJ memories/NNS ./.
Our/PRP$ framework/NN learns/VBZ a/DT network/NN that/WDT maps/VBZ a/DT small/JJ labelled/JJ support/NN set/NN and/CC an/DT unlabelled/JJ example/NN to/IN its/PRP$ label/NN ,/, obviating/VBG the/DT need/NN for/IN fine/JJ -/HYPH tuning/NN to/TO adapt/VB to/IN new/JJ class/NN types/NNS ./.
We/PRP then/RB define/VB one/CD -/HYPH shot/NN learning/NN problems/NNS on/IN vision/NN (/-LRB- using/VBG Omniglot/NNP ,/, ImageNet/NNP )/-RRB- and/CC language/NN tasks/NNS ./.
Our/PRP$ algorithm/NN improves/VBZ one/CD -/HYPH shot/NN accuracy/NN on/IN ImageNet/NNP from/IN 87.6/CD percent/NN to/IN 93.2/CD percent/NN and/CC from/IN 88.0/CD percent/NN to/IN 93.8/CD percent/NN on/IN Omniglot/NN compared/VBN to/IN competing/VBG approaches/NNS ./.
We/PRP also/RB demonstrate/VBP the/DT usefulness/NN of/IN the/DT same/JJ model/NN on/IN language/NN modeling/NN by/IN introducing/VBG a/DT one/CD -/HYPH shot/NN task/NN on/IN the/DT Penn/NNP Treebank/NNP ./.
