Recent/JJ advances/NNS in/IN convolutional/JJ neural/JJ networks/NNS have/VBP considered/VBN model/NN complexity/NN and/CC hardware/NN efficiency/NN to/TO enable/VB deployment/NN onto/IN embedded/VBN systems/NNS and/CC mobile/JJ devices/NNS ./.
For/IN example/NN ,/, it/PRP is/VBZ now/RB well/RB -/HYPH known/VBN that/IN the/DT arithmetic/NN operations/NNS of/IN deep/JJ networks/NNS can/MD be/VB encoded/VBN down/RP to/IN 8/CD -/HYPH bit/NN fixed/JJ -/HYPH point/NN without/IN significant/JJ deterioration/NN in/IN performance/NN ./.
However/RB ,/, further/JJ reduction/NN in/IN precision/NN down/IN to/IN as/RB low/JJ as/IN 3/CD -/HYPH bit/NN fixed/JJ -/HYPH point/NN results/NNS in/IN significant/JJ losses/NNS in/IN performance/NN ./.
In/IN this/DT paper/NN we/PRP propose/VBP a/DT new/JJ data/NNS representation/NN that/WDT enables/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN networks/NNS to/TO be/VB encoded/VBN to/IN 3/CD bits/NNS with/IN negligible/JJ loss/NN in/IN classification/NN performance/NN ./.
To/TO perform/VB this/DT ,/, we/PRP take/VBP advantage/NN of/IN the/DT fact/NN that/IN the/DT weights/NNS and/CC activations/NNS in/IN a/DT trained/VBN network/NN naturally/RB have/VBP non-uniform/JJ distributions/NNS ./.
Using/VBG non-uniform/NN ,/, base/NN -/HYPH 2/CD logarithmic/JJ representation/NN to/TO encode/VB weights/NNS ,/, communicate/VBP activations/NNS ,/, and/CC perform/VB dot/NN -/HYPH products/NNS enables/VBZ networks/NNS to/IN 1/CD )/-RRB- achieve/VBP higher/JJR classification/NN accuracies/NNS than/IN fixed/VBN -/HYPH point/NN at/IN the/DT same/JJ resolution/NN and/CC 2/LS )/-RRB- eliminate/VB bulky/JJ digital/JJ multipliers/NNS ./.
Finally/RB ,/, we/PRP propose/VBP an/DT end/NN -/HYPH to/IN -/HYPH end/NN training/NN procedure/NN that/WDT uses/VBZ log/NN representation/NN at/IN 5/CD -/HYPH bits/NNS ,/, which/WDT achieves/VBZ higher/JJR final/JJ test/NN accuracy/NN than/IN linear/JJ at/IN 5/CD -/HYPH bits/NNS ./.
