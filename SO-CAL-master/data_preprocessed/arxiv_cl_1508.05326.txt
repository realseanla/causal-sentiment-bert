Understanding/VBG entailment/NN and/CC contradiction/NN is/VBZ fundamental/JJ to/IN understanding/VBG natural/JJ language/NN ,/, and/CC inference/NN about/IN entailment/NN and/CC contradiction/NN is/VBZ a/DT valuable/JJ testing/NN ground/NN for/IN the/DT development/NN of/IN semantic/JJ representations/NNS ./.
However/RB ,/, machine/NN learning/NN research/NN in/IN this/DT area/NN has/VBZ been/VBN dramatically/RB limited/VBN by/IN the/DT lack/NN of/IN large/JJ -/HYPH scale/NN resources/NNS ./.
To/TO address/VB this/DT ,/, we/PRP introduce/VBP the/DT Stanford/NNP Natural/NNP Language/NNP Inference/NN corpus/NN ,/, a/DT new/JJ ,/, freely/RB available/JJ collection/NN of/IN labeled/VBN sentence/NN pairs/NNS ,/, written/VBN by/IN humans/NNS doing/VBG a/DT novel/JJ grounded/VBN task/NN based/VBN on/IN image/NN captioning/NN ./.
At/IN 570K/NN pairs/NNS ,/, it/PRP is/VBZ two/CD orders/NNS of/IN magnitude/NN larger/JJR than/IN all/DT other/JJ resources/NNS of/IN its/PRP$ type/NN ./.
This/DT increase/NN in/IN scale/NN allows/VBZ lexicalized/VBN classifiers/NNS to/TO outperform/VB some/DT sophisticated/JJ existing/VBG entailment/NN models/NNS ,/, and/CC it/PRP allows/VBZ a/DT neural/JJ network/NN -/HYPH based/VBN model/NN to/TO perform/VB competitively/RB on/IN natural/JJ language/NN inference/NN benchmarks/NNS for/IN the/DT first/JJ time/NN ./.
