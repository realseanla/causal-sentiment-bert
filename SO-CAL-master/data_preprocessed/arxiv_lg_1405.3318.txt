We/PRP consider/VBP the/DT problem/NN of/IN sequentially/RB choosing/VBG between/IN a/DT set/NN of/IN unbiased/JJ Monte/NNP Carlo/NNP estimators/NNS to/TO minimize/VB the/DT mean/NN -/HYPH squared/VBN -/HYPH error/NN (/-LRB- MSE/NN )/-RRB- of/IN a/DT final/JJ combined/VBN estimate/NN ./.
By/IN reducing/VBG this/DT task/NN to/IN a/DT stochastic/JJ multi-armed/JJ bandit/NN problem/NN ,/, we/PRP show/VBP that/RB well/RB developed/JJ allocation/NN strategies/NNS can/MD be/VB used/VBN to/TO achieve/VB an/DT MSE/NN that/WDT approaches/VBZ that/IN of/IN the/DT best/JJS estimator/NN chosen/VBN in/IN retrospect/NN ./.
We/PRP then/RB extend/VBP these/DT developments/NNS to/IN a/DT scenario/NN where/WRB alternative/JJ estimators/NNS have/VBP different/JJ ,/, possibly/RB stochastic/JJ costs/NNS ./.
The/DT outcome/NN is/VBZ a/DT new/JJ set/NN of/IN adaptive/JJ Monte/NNP Carlo/NNP strategies/NNS that/WDT provide/VBP stronger/JJR guarantees/NNS than/IN previous/JJ approaches/NNS while/IN offering/VBG practical/JJ advantages/NNS ./.
