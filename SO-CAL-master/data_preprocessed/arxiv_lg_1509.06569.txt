Deep/JJ neural/JJ networks/NNS currently/RB demonstrate/VBP state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN in/IN several/JJ domains/NNS ./.
At/IN the/DT same/JJ time/NN ,/, models/NNS of/IN this/DT class/NN are/VBP very/RB demanding/JJ in/IN terms/NNS of/IN computational/JJ resources/NNS ./.
In/IN particular/JJ ,/, a/DT large/JJ amount/NN of/IN memory/NN is/VBZ required/VBN by/IN commonly/RB used/VBN fully/RB -/HYPH connected/VBN layers/NNS ,/, making/VBG it/PRP hard/RB to/TO use/VB the/DT models/NNS on/IN low/JJ -/HYPH end/NN devices/NNS and/CC stopping/VBG the/DT further/JJ increase/NN of/IN the/DT model/NN size/NN ./.
In/IN this/DT paper/NN we/PRP convert/VBP the/DT dense/JJ weight/NN matrices/NNS of/IN the/DT fully/RB -/HYPH connected/VBN layers/NNS to/IN the/DT Tensor/NNP Train/NNP format/NN such/JJ that/IN the/DT number/NN of/IN parameters/NNS is/VBZ reduced/VBN by/IN a/DT huge/JJ factor/NN and/CC at/IN the/DT same/JJ time/NN the/DT expressive/JJ power/NN of/IN the/DT layer/NN is/VBZ preserved/VBN ./.
In/IN particular/JJ ,/, for/IN the/DT Very/JJ Deep/JJ VGG/NN networks/NNS we/PRP report/VBP the/DT compression/NN factor/NN of/IN the/DT dense/JJ weight/NN matrix/NN of/IN a/DT fully/RB -/HYPH connected/VBN layer/NN up/IN to/IN 200000/CD times/NNS leading/VBG to/IN the/DT compression/NN factor/NN of/IN the/DT whole/JJ network/NN up/IN to/IN 7/CD times/NNS ./.
