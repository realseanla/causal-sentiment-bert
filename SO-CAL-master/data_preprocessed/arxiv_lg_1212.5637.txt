We/PRP investigate/VBP the/DT problem/NN of/IN sequentially/RB predicting/VBG the/DT binary/JJ labels/NNS on/IN the/DT nodes/NNS of/IN an/DT arbitrary/JJ weighted/JJ graph/NN ./.
We/PRP show/VBP that/IN ,/, under/IN a/DT suitable/JJ parametrization/NN of/IN the/DT problem/NN ,/, the/DT optimal/JJ number/NN of/IN prediction/NN mistakes/NNS can/MD be/VB characterized/VBN (/-LRB- up/IN to/IN logarithmic/JJ factors/NNS )/-RRB- by/IN the/DT cutsize/NN of/IN a/DT random/JJ spanning/VBG tree/NN of/IN the/DT graph/NN ./.
The/DT cutsize/NN is/VBZ induced/VBN by/IN the/DT unknown/JJ adversarial/JJ labeling/NN of/IN the/DT graph/NN nodes/NNS ./.
In/IN deriving/VBG our/PRP$ characterization/NN ,/, we/PRP obtain/VBP a/DT simple/JJ randomized/JJ algorithm/NN achieving/VBG in/IN expectation/NN the/DT optimal/JJ mistake/NN bound/VBN on/IN any/DT polynomially/RB connected/VBN weighted/JJ graph/NN ./.
Our/PRP$ algorithm/NN draws/VBZ a/DT random/JJ spanning/VBG tree/NN of/IN the/DT original/JJ graph/NN and/CC then/RB predicts/VBZ the/DT nodes/NNS of/IN this/DT tree/NN in/IN constant/JJ expected/VBN amortized/VBN time/NN and/CC linear/JJ space/NN ./.
Experiments/NNS on/IN real/JJ -/HYPH world/NN datasets/NNS show/VBP that/IN our/PRP$ method/NN compares/VBZ well/RB to/IN both/DT global/JJ (/-LRB- Perceptron/NNP )/-RRB- and/CC local/JJ (/-LRB- label/NN propagation/NN )/-RRB- methods/NNS ,/, while/IN being/VBG generally/RB faster/RBR in/IN practice/NN ./.
