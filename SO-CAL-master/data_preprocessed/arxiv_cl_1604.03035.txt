There/EX is/VBZ compelling/JJ evidence/NN that/IN coreference/NN prediction/NN would/MD benefit/VB from/IN modeling/VBG global/JJ information/NN about/IN entity/NN -/HYPH clusters/NNS ./.
Yet/RB ,/, state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN can/MD be/VB achieved/VBN with/IN systems/NNS treating/VBG each/DT mention/NN prediction/NN independently/RB ,/, which/WDT we/PRP attribute/VBP to/IN the/DT inherent/JJ difficulty/NN of/IN crafting/VBG informative/JJ cluster/NN -/HYPH level/NN features/NNS ./.
We/PRP instead/RB propose/VBP to/TO use/VB recurrent/JJ neural/JJ networks/NNS (/-LRB- RNNs/NNS )/-RRB- to/TO learn/VB latent/NN ,/, global/JJ representations/NNS of/IN entity/NN clusters/NNS directly/RB from/IN their/PRP$ mentions/VBZ ./.
We/PRP show/VBP that/IN such/JJ representations/NNS are/VBP especially/RB useful/JJ for/IN the/DT prediction/NN of/IN pronominal/NN mentions/VBZ ,/, and/CC can/MD be/VB incorporated/VBN into/IN an/DT end/NN -/HYPH to/IN -/HYPH end/NN coreference/NN system/NN that/WDT outperforms/VBZ the/DT state/NN of/IN the/DT art/NN without/IN requiring/VBG any/DT additional/JJ search/NN ./.
