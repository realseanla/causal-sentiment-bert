We/PRP consider/VBP the/DT visual/JJ sentiment/NN task/NN of/IN mapping/VBG an/DT image/NN to/IN an/DT adjective/NN noun/NN pair/NN (/-LRB- ANP/NN )/-RRB- such/JJ as/IN "/`` cute/JJ baby/NN "/'' ./.
To/TO capture/VB the/DT two/CD -/HYPH factor/NN structure/NN of/IN our/PRP$ ANP/NN semantics/NNS as/RB well/RB as/IN to/TO overcome/VB annotation/NN noise/NN and/CC ambiguity/NN ,/, we/PRP propose/VBP a/DT novel/JJ factorized/JJ CNN/NNP model/NN which/WDT learns/VBZ separate/JJ representations/NNS for/IN adjectives/NNS and/CC nouns/NNS but/CC optimizes/VBZ the/DT classification/NN performance/NN over/IN their/PRP$ product/NN ./.
Our/PRP$ experiments/NNS on/IN the/DT publicly/RB available/JJ SentiBank/NNP dataset/NN show/VBP that/IN our/PRP$ model/NN significantly/RB outperforms/VBZ not/RB only/RB independent/JJ ANP/NN classifiers/NNS on/IN unseen/JJ ANPs/NNS and/CC on/IN retrieving/VBG images/NNS of/IN novel/JJ ANPs/NNS ,/, but/CC also/RB image/NN captioning/NN models/NNS which/WDT capture/VBP word/NN semantics/NNS from/IN co-occurrence/NN of/IN natural/JJ text/NN ;/: the/DT latter/JJ turn/NN out/RP to/TO be/VB surprisingly/RB poor/JJ at/IN capturing/VBG the/DT sentiment/NN evoked/VBN by/IN pure/JJ visual/JJ experience/NN ./.
That/DT is/VBZ ,/, our/PRP$ factorized/JJ ANP/NN CNN/NNP not/RB only/RB trains/VBZ better/JJR from/IN noisy/JJ labels/NNS ,/, generalizes/VBZ better/JJR to/IN new/JJ images/NNS ,/, but/CC can/MD also/RB expands/VBZ the/DT ANP/NN vocabulary/NN on/IN its/PRP$ own/JJ ./.
