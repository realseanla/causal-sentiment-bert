The/DT ability/NN to/TO train/VB large/JJ -/HYPH scale/NN neural/JJ networks/NNS has/VBZ resulted/VBN in/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN in/IN many/JJ areas/NNS of/IN computer/NN vision/NN ./.
These/DT results/NNS have/VBP largely/RB come/VBN from/IN computational/JJ break/NN throughs/NNS of/IN two/CD forms/NNS :/: model/NN parallelism/NN ,/, e.g./FW GPU/NN accelerated/VBD training/NN ,/, which/WDT has/VBZ seen/VBN quick/JJ adoption/NN in/IN computer/NN vision/NN circles/NNS ,/, and/CC data/NNS parallelism/NN ,/, e.g./FW A-SGD/NN ,/, whose/WP$ large/JJ scale/NN has/VBZ been/VBN used/VBN mostly/RB in/IN industry/NN ./.
We/PRP report/VBP early/JJ experiments/NNS with/IN a/DT system/NN that/WDT makes/VBZ use/NN of/IN both/DT model/NN parallelism/NN and/CC data/NNS parallelism/NN ,/, we/PRP call/VBP GPU/NNP A-SGD/NNP ./.
We/PRP show/VBP using/VBG GPU/NNP A-SGD/VBD it/PRP is/VBZ possible/JJ to/TO speed/VB up/RP training/NN of/IN large/JJ convolutional/JJ neural/JJ networks/NNS useful/JJ for/IN computer/NN vision/NN ./.
We/PRP believe/VBP GPU/NNP A-SGD/NNP will/MD make/VB it/PRP possible/JJ to/TO train/VB larger/JJR networks/NNS on/IN larger/JJR training/NN sets/NNS in/IN a/DT reasonable/JJ amount/NN of/IN time/NN ./.
