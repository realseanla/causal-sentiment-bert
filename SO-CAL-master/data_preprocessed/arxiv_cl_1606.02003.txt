We/PRP propose/VBP to/TO enhance/VB the/DT RNN/NNP decoder/NN in/IN a/DT neural/JJ machine/NN translator/NN (/-LRB- NMT/NN )/-RRB- with/IN external/JJ memory/NN ,/, as/IN a/DT natural/JJ but/CC powerful/JJ extension/NN to/IN the/DT state/NN in/IN the/DT decoding/NN RNN/NN ./.
This/DT memory/NN -/HYPH enhanced/VBN RNN/NN decoder/NN is/VBZ called/VBN \/SYM textsc/NN {/-LRB- MemDec/NNP }/-RRB- ./.
At/IN each/DT time/NN during/IN decoding/NN ,/, \/SYM textsc/NN {/-LRB- MemDec/NNP }/-RRB- will/MD read/VB from/IN this/DT memory/NN and/CC write/VB to/IN this/DT memory/NN once/RB ,/, both/CC with/IN content/NN -/HYPH based/VBN addressing/VBG ./.
Unlike/IN the/DT unbounded/JJ memory/NN in/IN previous/JJ work/NN to/TO store/VB the/DT representation/NN of/IN source/NN sentence/NN ,/, the/DT memory/NN in/IN \/NN textsc/NN {/-LRB- MemDec/NNP }/-RRB- is/VBZ a/DT matrix/NN with/IN pre-determined/JJ size/NN designed/VBN to/TO better/RBR capture/VB the/DT information/NN important/JJ for/IN the/DT decoding/NN process/NN at/IN each/DT time/NN step/NN ./.
Our/PRP$ empirical/JJ study/NN on/IN Chinese/JJ -/HYPH English/JJ translation/NN shows/VBZ that/IN it/PRP can/MD improve/VB by/IN $/$ 4.8/CD $/$ BLEU/CD upon/IN Groundhog/NNP and/CC $/$ 5.3/CD $/$ BLEU/CD upon/IN on/IN Moses/NNP ,/, yielding/VBG the/DT best/JJS performance/NN achieved/VBN with/IN the/DT same/JJ training/NN set/NN ./.
