This/DT paper/NN focuses/VBZ on/IN the/DT development/NN of/IN randomized/JJ approaches/NNS for/IN building/VBG deep/JJ neural/JJ networks/NNS ./.
A/DT supervisory/JJ mechanism/NN is/VBZ proposed/VBN to/TO constrain/VB the/DT random/JJ assignment/NN of/IN the/DT hidden/JJ parameters/NNS (/-LRB- i.e./FW ,/, all/DT biases/NNS and/CC weights/NNS within/IN the/DT hidden/JJ layers/NNS )/-RRB- ./.
Full/JJ -/HYPH rank/NN oriented/VBN criterion/NN is/VBZ suggested/VBN and/CC utilized/VBN as/IN a/DT termination/NN condition/NN to/TO determine/VB the/DT number/NN of/IN nodes/NNS for/IN each/DT hidden/JJ layer/NN ,/, and/CC a/DT pre-defined/JJ error/NN tolerance/NN is/VBZ used/VBN as/IN a/DT global/JJ indicator/NN to/TO decide/VB the/DT depth/NN of/IN the/DT learner/NN model/NN ./.
The/DT read/VBN -/HYPH out/RP weights/NNS attached/VBN with/IN all/DT direct/JJ links/NNS from/IN each/DT hidden/JJ layer/NN to/IN the/DT output/NN layer/NN are/VBP incrementally/RB evaluated/VBN by/IN the/DT least/JJS squares/NNS method/NN ./.
Such/PDT a/DT class/NN of/IN randomized/JJ leaner/JJR models/NNS with/IN deep/JJ architecture/NN is/VBZ termed/VBN as/IN deep/JJ stochastic/JJ configuration/NN networks/NNS (/-LRB- DeepSCNs/NNS )/-RRB- ,/, of/IN which/WDT the/DT universal/JJ approximation/NN property/NN is/VBZ verified/VBN with/IN rigorous/JJ proof/NN ./.
Given/VBN abundant/JJ samples/NNS from/IN a/DT continuous/JJ distribution/NN ,/, DeepSCNs/NNS can/MD speedily/RB produce/VB a/DT learning/NN representation/NN ,/, that/DT is/VBZ ,/, a/DT collection/NN of/IN random/JJ basis/NN functions/VBZ with/IN the/DT cascaded/VBN inputs/NNS together/RB with/IN the/DT read/VBN -/HYPH out/RP weights/NNS ./.
Simulation/NNP results/VBZ with/IN comparisons/NNS on/IN function/NN approximation/NN align/VB with/IN the/DT theoretical/JJ findings/NNS ./.
