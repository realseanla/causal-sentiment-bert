An/DT efficient/JJ policy/NN search/NN algorithm/NN should/MD estimate/VB the/DT local/JJ gradient/NN of/IN the/DT objective/JJ function/NN ,/, with/IN respect/NN to/IN the/DT policy/NN parameters/NNS ,/, from/IN as/IN few/JJ trials/NNS as/IN possible/JJ ./.
Whereas/IN most/JJS policy/NN search/NN methods/NNS estimate/VBP this/DT gradient/NN by/IN observing/VBG the/DT rewards/NNS obtained/VBN during/IN policy/NN trials/NNS ,/, we/PRP show/VBP ,/, both/CC theoretically/RB and/CC empirically/RB ,/, that/IN taking/VBG into/IN account/NN the/DT sensor/NN data/NNS as/RB well/RB gives/VBZ better/JJR gradient/NN estimates/NNS and/CC hence/RB faster/RBR learning/VBG ./.
The/DT reason/NN is/VBZ that/IN rewards/NNS obtained/VBN during/IN policy/NN execution/NN vary/VBP from/IN trial/NN to/IN trial/NN due/IN to/IN noise/NN in/IN the/DT environment/NN ;/: sensor/NN data/NNS ,/, which/WDT correlates/VBZ with/IN the/DT noise/NN ,/, can/MD be/VB used/VBN to/TO partially/RB correct/VB for/IN this/DT variation/NN ,/, resulting/VBG in/IN an/DT estimatorwith/NN lower/JJR variance/NN ./.
