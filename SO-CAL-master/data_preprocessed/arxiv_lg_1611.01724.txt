Previous/JJ work/NN combines/VBZ word/NN -/HYPH level/NN and/CC character/NN -/HYPH level/NN representations/NNS using/VBG concatenation/NN or/CC scalar/JJ weighting/NN ,/, which/WDT is/VBZ suboptimal/JJ for/IN high/JJ -/HYPH level/NN tasks/NNS like/IN reading/NN comprehension/NN ./.
We/PRP present/VBP a/DT fine/JJ -/HYPH grained/JJ gating/NN mechanism/NN to/TO dynamically/RB combine/VB word/NN -/HYPH level/NN and/CC character/NN -/HYPH level/NN representations/NNS based/VBN on/IN properties/NNS of/IN the/DT words/NNS ./.
We/PRP also/RB extend/VBP the/DT idea/NN of/IN fine/JJ -/HYPH grained/JJ gating/NN to/IN modeling/VBG the/DT interaction/NN between/IN questions/NNS and/CC paragraphs/NNS for/IN reading/NN comprehension/NN ./.
Experiments/NNS show/VBP that/IN our/PRP$ approach/NN can/MD improve/VB the/DT performance/NN on/IN reading/NN comprehension/NN tasks/NNS ,/, achieving/VBG new/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS on/IN the/DT Children/NNP 's/POS Book/NNP Test/NNP dataset/NN ./.
To/TO demonstrate/VB the/DT generality/NN of/IN our/PRP$ gating/NN mechanism/NN ,/, we/PRP also/RB show/VBP improved/VBN results/NNS on/IN a/DT social/JJ media/NN tag/NN prediction/NN task/NN ./.
