This/DT work/NN presents/VBZ a/DT multiscale/JJ framework/NN to/TO solve/VB an/DT inverse/JJ reinforcement/NN learning/NN (/-LRB- IRL/NN )/-RRB- problem/NN for/IN continuous/JJ -/HYPH time/NN //HYPH state/NN stochastic/JJ systems/NNS ./.
We/PRP take/VBP advantage/NN of/IN a/DT diffusion/NN wavelet/NN representation/NN of/IN the/DT associated/VBN Markov/NNP chain/NN to/IN abstract/JJ the/DT state/NN space/NN ./.
This/DT not/RB only/RB allows/VBZ for/IN effectively/RB handling/VBG the/DT large/JJ (/-LRB- and/CC geometrically/RB complex/JJ )/-RRB- decision/NN space/NN but/CC also/RB provides/VBZ more/JJR interpretable/JJ representations/NNS of/IN the/DT demonstrated/VBN state/NN trajectories/NNS and/CC also/RB of/IN the/DT resulting/VBG policy/NN of/IN IRL/NN ./.
In/IN the/DT proposed/VBN framework/NN ,/, the/DT problem/NN is/VBZ divided/VBN into/IN the/DT global/JJ and/CC local/JJ IRL/NN ,/, where/WRB the/DT global/JJ approximation/NN of/IN the/DT optimal/JJ value/NN functions/NNS are/VBP obtained/VBN using/VBG coarse/JJ features/NNS and/CC the/DT local/JJ details/NNS are/VBP quantified/VBN using/VBG fine/JJ local/JJ features/NNS ./.
An/DT illustrative/JJ numerical/JJ example/NN on/IN robot/NN path/NN control/NN in/IN a/DT complex/JJ environment/NN is/VBZ presented/VBN to/TO verify/VB the/DT proposed/JJ method/NN ./.
