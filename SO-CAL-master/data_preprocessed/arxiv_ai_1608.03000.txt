This/DT paper/NN explores/VBZ the/DT task/NN of/IN translating/VBG natural/JJ language/NN queries/NNS into/IN regular/JJ expressions/NNS which/WDT embody/VBP their/PRP$ meaning/NN ./.
In/IN contrast/NN to/IN prior/JJ work/NN ,/, the/DT proposed/VBN neural/JJ model/NN does/VBZ not/RB utilize/VB domain/NN -/HYPH specific/JJ crafting/VBG ,/, learning/VBG to/IN translate/VB directly/RB from/IN a/DT parallel/JJ corpus/NN ./.
To/TO fully/RB explore/VB the/DT potential/NN of/IN neural/JJ models/NNS ,/, we/PRP propose/VBP a/DT methodology/NN for/IN collecting/VBG a/DT large/JJ corpus/NN of/IN regular/JJ expression/NN ,/, natural/JJ language/NN pairs/NNS ./.
Our/PRP$ resulting/VBG model/NN achieves/VBZ a/DT performance/NN gain/NN of/IN 19.6/CD percent/NN over/IN previous/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN models/NNS ./.
