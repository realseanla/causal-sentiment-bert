Recognizing/VBG implicit/JJ discourse/NN relations/NNS is/VBZ a/DT challenging/JJ but/CC important/JJ task/NN in/IN the/DT field/NN of/IN Natural/NNP Language/NNP Processing/NNP ./.
For/IN such/PDT a/DT complex/JJ text/NN processing/NN task/NN ,/, different/JJ from/IN previous/JJ studies/NNS ,/, we/PRP argue/VBP that/IN it/PRP is/VBZ necessary/JJ to/TO repeatedly/RB read/VB the/DT arguments/NNS and/CC dynamically/RB exploit/VB the/DT efficient/JJ features/NNS useful/JJ for/IN recognizing/VBG discourse/NN relations/NNS ./.
To/TO mimic/VB the/DT repeated/VBN reading/NN strategy/NN ,/, we/PRP propose/VBP the/DT neural/JJ networks/NNS with/IN multi-level/JJ attention/NN (/-LRB- NNMA/NN )/-RRB- ,/, combining/VBG the/DT attention/NN mechanism/NN and/CC external/JJ memories/NNS to/TO gradually/RB fix/VB the/DT attention/NN on/IN some/DT specific/JJ words/NNS helpful/JJ to/IN judging/VBG the/DT discourse/NN relations/NNS ./.
Experiments/NNS on/IN the/DT PDTB/NN dataset/NN show/VBP that/IN our/PRP$ proposed/JJ method/NN achieves/VBZ the/DT state/NN -/HYPH of/IN -/HYPH art/NN results/NNS ./.
The/DT visualization/NN of/IN the/DT attention/NN weights/NNS also/RB illustrates/VBZ the/DT progress/NN that/IN our/PRP$ model/NN observes/VBZ the/DT arguments/NNS on/IN each/DT level/NN and/CC progressively/RB locates/VBZ the/DT important/JJ words/NNS ./.
