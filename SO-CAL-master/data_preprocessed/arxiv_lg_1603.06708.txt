In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT novel/JJ multi-label/JJ learning/NN framework/NN ,/, called/VBN Multi-Label/NNP Self/NNP -/HYPH Paced/NNP Learning/NNP (/-LRB- MLSPL/NNP )/-RRB- ,/, in/IN an/DT attempt/NN to/TO incorporate/VB the/DT self/NN -/HYPH paced/VBN learning/NN strategy/NN into/IN multi-label/JJ learning/NN regime/NN ./.
In/IN light/NN of/IN the/DT benefits/NNS of/IN adopting/VBG the/DT easy/JJ -/HYPH to/IN -/HYPH hard/JJ strategy/NN proposed/VBN by/IN self/NN -/HYPH paced/VBN learning/NN ,/, the/DT devised/VBN MLSPL/NNP aims/VBZ to/TO learn/VB multiple/JJ labels/NNS jointly/RB by/IN gradually/RB including/VBG label/NN learning/NN tasks/NNS and/CC instances/NNS into/IN model/NN training/NN from/IN the/DT easy/JJ to/IN the/DT hard/JJ ./.
We/PRP first/RB introduce/VB a/DT self/NN -/HYPH paced/VBN function/NN as/IN a/DT regularizer/NN in/IN the/DT multi-label/JJ learning/NN formulation/NN ,/, so/RB as/IN to/TO simultaneously/RB rank/VB priorities/NNS of/IN the/DT label/NN learning/NN tasks/NNS and/CC the/DT instances/NNS in/IN each/DT learning/NN iteration/NN ./.
Considering/VBG that/IN different/JJ multi-label/JJ learning/NN scenarios/NNS often/RB need/VBP different/JJ self/NN -/HYPH paced/VBN schemes/NNS during/IN optimization/NN ,/, we/PRP thus/RB propose/VBP a/DT general/JJ way/NN to/TO find/VB the/DT desired/VBN self/NN -/HYPH paced/VBN functions/NNS ./.
Experimental/JJ results/NNS on/IN three/CD benchmark/NN datasets/NNS suggest/VBP the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN of/IN our/PRP$ approach/NN ./.
