We/PRP propose/VBP a/DT simple/JJ ,/, scalable/JJ ,/, and/CC fast/JJ gradient/NN descent/NN algorithm/NN to/TO optimize/VB a/DT nonconvex/JJ objective/NN for/IN the/DT rank/NN minimization/NN problem/NN and/CC a/DT closely/RB related/JJ family/NN of/IN semidefinite/JJ programs/NNS ./.
With/IN $/$ O/UH (/-LRB- r/NN ^/SYM 2/CD \/SYM kappa/NN ^/SYM 2/CD n/NN \/SYM log/NN n/NN )/-RRB- $/$ random/JJ measurements/NNS of/IN a/DT positive/JJ semidefinite/JJ $/NN n/NN \/NN times/NNS n/NN $/$ matrix/NN of/IN rank/NN $/$ r/VBP $/$ and/CC condition/NN number/NN $/$ \/SYM kappa/FW $/$ ,/, our/PRP$ method/NN is/VBZ guaranteed/VBN to/TO converge/VB linearly/RB to/IN the/DT global/JJ optimum/JJ ./.
