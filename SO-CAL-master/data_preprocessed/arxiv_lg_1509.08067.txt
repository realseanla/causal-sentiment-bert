This/DT paper/NN presents/VBZ a/DT method/NN ,/, called/VBN \/SYM textit/FW {/-LRB- AOGTracker/NN }/-RRB- ,/, for/IN simultaneously/RB tracking/VBG ,/, learning/VBG and/CC parsing/VBG (/-LRB- TLP/NN )/-RRB- objects/NNS in/IN video/NN sequences/NNS with/IN a/DT hierarchical/JJ and/CC compositional/JJ And/CC -/HYPH Or/CC graph/NN (/-LRB- AOG/NN )/-RRB- representation/NN ./.
In/IN our/PRP$ TLP/NN framework/NN ,/, the/DT AOG/NNP explores/VBZ latent/JJ part/NN configurations/NNS to/TO represent/VB a/DT target/NN object/NN ./.
The/DT TLP/NN is/VBZ formulated/VBN in/IN the/DT Bayesian/JJ framework/NN and/CC a/DT spatial/JJ -/HYPH temporal/JJ dynamic/JJ programming/NN (/-LRB- DP/NN )/-RRB- algorithm/NN is/VBZ derived/VBN to/TO infer/VB object/NN bounding/VBG boxes/NNS on/IN the/DT fly/NN ./.
During/IN online/JJ learning/NN ,/, the/DT AOG/NNP is/VBZ discriminatively/RB trained/VBN in/IN the/DT latent/JJ structural/JJ SVM/NN framework/NN to/TO account/VB for/IN the/DT appearance/NN (/-LRB- e.g./FW ,/, lighting/NN and/CC partial/JJ occlusion/NN )/-RRB- and/CC structural/JJ (/-LRB- e.g./FW ,/, different/JJ poses/NNS and/CC viewpoints/NNS )/-RRB- variations/NNS of/IN the/DT object/NN ,/, as/RB well/RB as/IN the/DT distractors/NNS (/-LRB- e.g./FW ,/, similar/JJ objects/NNS )/-RRB- in/IN the/DT background/NN scene/NN ./.
Three/CD key/JJ issues/NNS in/IN online/JJ learning/NN are/VBP addressed/VBN :/: (/-LRB- i/LS )/-RRB- maintaining/VBG the/DT purity/NN of/IN positive/JJ and/CC negative/JJ datasets/NNS collected/VBN online/RB with/IN the/DT help/NN from/IN the/DT spatial/JJ -/HYPH temporal/JJ DP/NNP algorithm/NN ,/, (/-LRB- ii/LS )/-RRB- controling/VBG the/DT model/NN complexity/NN in/IN latent/JJ structure/NN learning/NN ,/, and/CC (/-LRB- iii/LS )/-RRB- identifying/VBG the/DT critical/JJ moments/NNS to/IN re-learn/VB the/DT structure/NN of/IN AOG/NNP based/VBN on/IN its/PRP$ intrackability/NN ./.
The/DT intrackability/NN measures/VBZ the/DT uncertainty/NN of/IN the/DT AOG/NNP based/VBN on/IN its/PRP$ score/NN maps/NNS ./.
In/IN experiments/NNS ,/, our/PRP$ AOGTracker/NN is/VBZ tested/VBN in/IN two/CD main/JJ tracking/NN benchmarks/NNS with/IN the/DT same/JJ parameter/NN setting/NN :/: the/DT TB/NN -/HYPH 100/CD //HYPH 50/CD //HYPH CVPR2013/NN benchmarks/NNS ,/, and/CC the/DT VOT/NN benchmarks/NNS ---/, VOT/NNP 2013/CD ,/, 2014/CD ,/, 2015/CD and/CC TIR2015/NN (/-LRB- thermal/JJ imagery/NN tracking/NN )/-RRB- ./.
In/IN the/DT former/JJ ,/, our/PRP$ AOGTracker/NN outperforms/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN tracking/NN algorithms/NNS including/VBG two/CD trackers/NNS based/VBN on/IN deep/JJ convolutional/JJ network/NN ./.
In/IN the/DT latter/JJ ,/, our/PRP$ AOGTracker/NN outperforms/VBZ all/DT other/JJ trackers/NNS in/IN VOT2013/NN and/CC is/VBZ comparable/JJ to/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS in/IN VOT2014/NN (/-LRB- comparison/NN results/NNS of/IN VOT2015/NN and/CC VOT/NN -/HYPH TIR2015/NN will/MD be/VB released/VBN by/IN the/DT benchmark/NN authors/NNS at/IN the/DT VOT2015/NN workshop/NN in/IN conjunction/NN with/IN ICCV2015/NN )/-RRB- ./.
