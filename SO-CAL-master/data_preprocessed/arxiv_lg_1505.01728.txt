Several/JJ data/NNS mining/NN problems/NNS are/VBP characterized/VBN by/IN data/NNS in/IN high/JJ dimensions/NNS ./.
One/CD of/IN the/DT popular/JJ ways/NNS to/TO reduce/VB the/DT dimensionality/NN of/IN the/DT data/NNS is/VBZ to/TO perform/VB feature/NN selection/NN ,/, i.e/FW ,/, select/VB a/DT subset/NN of/IN relevant/JJ and/CC non-redundant/JJ features/NNS ./.
Recently/RB ,/, Quadratic/JJ Programming/NN Feature/NN Selection/NN (/-LRB- QPFS/NN )/-RRB- has/VBZ been/VBN proposed/VBN which/WDT formulates/VBZ the/DT feature/NN selection/NN problem/NN as/IN a/DT quadratic/JJ program/NN ./.
It/PRP has/VBZ been/VBN shown/VBN to/TO outperform/VB many/JJ of/IN the/DT existing/VBG feature/NN selection/NN methods/NNS for/IN a/DT variety/NN of/IN applications/NNS ./.
Though/IN ,/, better/JJR than/IN many/JJ existing/JJ approaches/NNS ,/, the/DT running/NN time/NN complexity/NN of/IN QPFS/NNP is/VBZ cubic/JJ in/IN the/DT number/NN of/IN features/NNS ,/, which/WDT can/MD be/VB quite/RB computationally/RB expensive/JJ even/RB for/IN moderately/RB sized/JJ datasets/NNS ./.
In/IN this/DT paper/NN we/PRP propose/VBP a/DT novel/JJ method/NN for/IN feature/NN selection/NN by/IN integrating/VBG k/CD -/HYPH means/NN clustering/NN with/IN QPFS/NN ./.
The/DT basic/JJ variant/NN of/IN our/PRP$ approach/NN runs/VBZ k/CD -/HYPH means/NNS to/TO bring/VB down/RP the/DT number/NN of/IN features/NNS which/WDT need/VBP to/TO be/VB passed/VBN on/IN to/IN QPFS/NNP ./.
We/PRP then/RB enhance/VB this/DT idea/NN ,/, wherein/WRB we/PRP gradually/RB refine/VBP the/DT feature/NN space/NN from/IN a/DT very/RB coarse/JJ clustering/NN to/IN a/DT fine/JJ -/HYPH grained/JJ one/CD ,/, by/IN interleaving/VBG steps/NNS of/IN QPFS/NN with/IN k/CD -/HYPH means/NN clustering/NN ./.
Every/DT step/NN of/IN QPFS/NN helps/VBZ in/IN identifying/VBG the/DT clusters/NNS of/IN irrelevant/JJ features/NNS (/-LRB- which/WDT can/MD then/RB be/VB thrown/VBN away/RB )/-RRB- ,/, whereas/IN every/DT step/NN of/IN k/CD -/HYPH means/NNS further/RBR refines/VBZ the/DT clusters/NNS which/WDT are/VBP potentially/RB relevant/JJ ./.
We/PRP show/VBP that/IN our/PRP$ iterative/JJ refinement/NN of/IN clusters/NNS is/VBZ guaranteed/VBN to/TO converge/VB ./.
We/PRP provide/VBP bounds/NNS on/IN the/DT number/NN of/IN distance/NN computations/NNS involved/VBN in/IN the/DT k/NN -/HYPH means/NN algorithm/NN ./.
Further/RB ,/, each/DT QPFS/NNP run/NN is/VBZ now/RB cubic/JJ in/IN number/NN of/IN clusters/NNS ,/, which/WDT can/MD be/VB much/RB smaller/JJR than/IN actual/JJ number/NN of/IN features/NNS ./.
Experiments/NNS on/IN eight/CD publicly/RB available/JJ datasets/NNS show/VBP that/IN our/PRP$ approach/NN gives/VBZ significant/JJ computational/JJ gains/NNS (/-LRB- both/CC in/IN time/NN and/CC memory/NN )/-RRB- ,/, over/IN standard/JJ QPFS/NNP as/RB well/RB as/IN other/JJ state/NN of/IN the/DT art/NN feature/NN selection/NN methods/NNS ,/, even/RB while/IN improving/VBG the/DT overall/JJ accuracy/NN ./.
