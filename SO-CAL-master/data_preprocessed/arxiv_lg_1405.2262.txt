We/PRP present/VBP a/DT method/NN for/IN training/VBG a/DT deep/JJ neural/JJ network/NN containing/VBG sinusoidal/NN activation/NN functions/VBZ to/TO fit/VB to/IN time/NN -/HYPH series/NN data/NNS ./.
Weights/NNS are/VBP initialized/VBN using/VBG a/DT fast/JJ Fourier/NN transform/VB ,/, then/RB trained/VBN with/IN regularization/NN to/TO improve/VB generalization/NN ./.
A/DT simple/JJ dynamic/JJ parameter/NN tuning/NN method/NN is/VBZ employed/VBN to/TO adjust/VB both/CC the/DT learning/NN rate/NN and/CC regularization/NN term/NN ,/, such/JJ that/IN stability/NN and/CC efficient/JJ training/NN are/VBP both/DT achieved/VBN ./.
We/PRP show/VBP how/WRB deeper/JJR layers/NNS can/MD be/VB utilized/VBN to/IN model/NN the/DT observed/VBN sequence/NN using/VBG a/DT sparser/JJR set/NN of/IN sinusoid/JJ units/NNS ,/, and/CC how/WRB non-uniform/JJ regularization/NN can/MD improve/VB generalization/NN by/IN promoting/VBG the/DT shifting/NN of/IN weight/NN toward/IN simpler/JJR units/NNS ./.
The/DT method/NN is/VBZ demonstrated/VBN with/IN time/NN -/HYPH series/NN problems/NNS to/TO show/VB that/IN it/PRP leads/VBZ to/IN effective/JJ extrapolation/NN of/IN nonlinear/JJ trends/NNS ./.
