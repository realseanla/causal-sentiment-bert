Deep/JJ convolutional/JJ neural/JJ networks/NNS (/-LRB- CNN/NNP )/-RRB- has/VBZ become/VBN the/DT most/RBS promising/JJ method/NN for/IN object/NN recognition/NN ,/, repeatedly/RB demonstrating/VBG record/NN breaking/NN results/VBZ for/IN image/NN classification/NN and/CC object/NN detection/NN in/IN recent/JJ years/NNS ./.
However/RB ,/, a/DT very/RB deep/JJ CNN/NNP generally/RB involves/VBZ many/JJ layers/NNS with/IN millions/NNS of/IN parameters/NNS ,/, making/VBG the/DT storage/NN of/IN the/DT network/NN model/NN to/TO be/VB extremely/RB large/JJ ./.
This/DT prohibits/VBZ the/DT usage/NN of/IN deep/JJ CNNs/NNS on/IN resource/NN limited/VBN hardware/NN ,/, especially/RB cell/NN phones/NNS or/CC other/JJ embedded/VBN devices/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP tackle/VBP this/DT model/NN storage/NN issue/NN by/IN investigating/VBG information/NN theoretical/JJ vector/NN quantization/NN methods/NNS for/IN compressing/VBG the/DT parameters/NNS of/IN CNNs/NNS ./.
In/IN particular/JJ ,/, we/PRP have/VBP found/VBN in/IN terms/NNS of/IN compressing/VBG the/DT most/RBS storage/NN demanding/VBG dense/JJ connected/JJ layers/NNS ,/, vector/NN quantization/NN methods/NNS have/VBP a/DT clear/JJ gain/NN over/IN existing/VBG matrix/NN factorization/NN methods/NNS ./.
Simply/RB applying/VBG k/CD -/HYPH means/NN clustering/NN to/IN the/DT weights/NNS or/CC conducting/VBG product/NN quantization/NN can/MD lead/VB to/IN a/DT very/RB good/JJ balance/NN between/IN model/NN size/NN and/CC recognition/NN accuracy/NN ./.
For/IN the/DT 1000/CD -/HYPH category/NN classification/NN task/NN in/IN the/DT ImageNet/NNP challenge/NN ,/, we/PRP are/VBP able/JJ to/TO achieve/VB 16/CD -/HYPH 24/CD times/NNS compression/NN of/IN the/DT network/NN with/IN only/RB 1/CD percent/NN loss/NN of/IN classification/NN accuracy/NN using/VBG the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN CNN/NNP ./.
