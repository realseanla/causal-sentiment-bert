Guided/VBN policy/NN search/NN algorithms/NNS can/MD be/VB used/VBN to/TO optimize/VB complex/JJ nonlinear/JJ policies/NNS ,/, such/JJ as/IN deep/JJ neural/JJ networks/NNS ,/, without/IN directly/RB computing/VBG policy/NN gradients/NNS in/IN the/DT high/JJ -/HYPH dimensional/JJ parameter/NN space/NN ./.
Instead/RB ,/, these/DT methods/NNS use/VBP supervised/JJ learning/NN to/TO train/VB the/DT policy/NN to/TO mimic/VB a/DT "/`` teacher/NN "/'' algorithm/NN ,/, such/JJ as/IN a/DT trajectory/NN optimizer/NN or/CC a/DT trajectory/NN -/HYPH centric/JJ reinforcement/NN learning/NN method/NN ./.
Guided/VBN policy/NN search/NN methods/NNS provide/VBP asymptotic/JJ local/JJ convergence/NN guarantees/NNS by/IN construction/NN ,/, but/CC it/PRP is/VBZ not/RB clear/JJ how/WRB much/RB the/DT policy/NN improves/VBZ within/IN a/DT small/JJ ,/, finite/JJ number/NN of/IN iterations/NNS ./.
We/PRP show/VBP that/IN guided/VBN policy/NN search/NN algorithms/NNS can/MD be/VB interpreted/VBN as/IN an/DT approximate/JJ variant/NN of/IN mirror/NN descent/NN ,/, where/WRB the/DT projection/NN onto/IN the/DT constraint/NN manifold/NN is/VBZ not/RB exact/JJ ./.
We/PRP derive/VBP a/DT new/JJ guided/VBN policy/NN search/NN algorithm/NN that/WDT is/VBZ simpler/JJR and/CC provides/VBZ appealing/JJ improvement/NN and/CC convergence/NN guarantees/NNS in/IN simplified/JJ convex/NN and/CC linear/JJ settings/NNS ,/, and/CC show/VBP that/IN in/IN the/DT more/RBR general/JJ nonlinear/JJ setting/NN ,/, the/DT error/NN in/IN the/DT projection/NN step/NN can/MD be/VB bounded/VBN ./.
We/PRP provide/VBP empirical/JJ results/NNS on/IN several/JJ simulated/VBN robotic/JJ navigation/NN and/CC manipulation/NN tasks/NNS that/WDT show/VBP that/IN our/PRP$ method/NN is/VBZ stable/JJ and/CC achieves/VBZ similar/JJ or/CC better/JJR performance/NN when/WRB compared/VBN to/IN prior/JJ guided/VBN policy/NN search/NN methods/NNS ,/, with/IN a/DT simpler/JJR formulation/NN and/CC fewer/JJR hyperparameters/NNS ./.
