With/IN the/DT impressive/JJ capability/NN to/TO capture/VB visual/JJ content/NN ,/, deep/JJ convolutional/JJ neural/JJ networks/NNS (/-LRB- CNN/NNP )/-RRB- have/VBP demon/NN -/HYPH strated/VBN promising/JJ performance/NN in/IN various/JJ vision/NN -/HYPH based/VBN ap/NN -/HYPH plications/NNS ,/, such/JJ as/IN classification/NN ,/, recognition/NN ,/, and/CC objec/NN -/HYPH t/NN detection/NN ./.
However/RB ,/, due/IN to/IN the/DT intrinsic/JJ structure/NN design/NN of/IN CNN/NNP ,/, for/IN images/NNS with/IN complex/JJ content/NN ,/, it/PRP achieves/VBZ lim/NN -/HYPH ited/VBN capability/NN on/IN invariance/NN to/IN translation/NN ,/, rotation/NN ,/, and/CC re-sizing/VBG changes/NNS ,/, which/WDT is/VBZ strongly/RB emphasized/VBN in/IN the/DT s/NN -/HYPH cenario/NN of/IN content/NN -/HYPH based/VBN image/NN retrieval/NN ./.
In/IN this/DT paper/NN ,/, to/TO address/VB this/DT problem/NN ,/, we/PRP proposed/VBD a/DT new/JJ kernelized/VBN deep/JJ convolutional/JJ neural/JJ network/NN ./.
We/PRP first/RB discuss/VBP our/PRP$ motiva/NN -/HYPH tion/NN by/IN an/DT experimental/JJ study/NN to/TO demonstrate/VB the/DT sensitivi/NN -/, ty/UH of/IN the/DT global/JJ CNN/NNP feature/NN to/IN the/DT basic/JJ geometric/JJ trans/NN -/HYPH formations/NNS ./.
Then/RB ,/, we/PRP propose/VBP to/TO represent/VB visual/JJ content/NN with/IN approximate/JJ invariance/NN to/IN the/DT above/JJ geometric/JJ trans/NN -/HYPH formations/NNS from/IN a/DT kernelized/VBN perspective/NN ./.
We/PRP extract/VBP CNN/NNP features/NNS on/IN the/DT detected/VBN object/NN -/HYPH like/JJ patches/NNS and/CC aggregate/NN these/DT patch/NN -/HYPH level/NN CNN/NNP features/VBZ to/TO form/VB a/DT vectorial/JJ repre/NN -/HYPH sentation/NN with/IN the/DT Fisher/NNP vector/NN model/NN ./.
The/DT effectiveness/NN of/IN our/PRP$ proposed/VBN algorithm/NN is/VBZ demonstrated/VBN on/IN image/NN search/NN application/NN with/IN three/CD benchmark/NN datasets/NNS ./.
