In/IN this/DT work/NN ,/, we/PRP address/VBP the/DT problem/NN to/TO model/VB all/PDT the/DT nodes/NNS (/-LRB- words/NNS or/CC phrases/NNS )/-RRB- in/IN a/DT dependency/NN tree/NN with/IN the/DT dense/JJ representations/NNS ./.
We/PRP propose/VBP a/DT recursive/JJ convolutional/JJ neural/JJ network/NN (/-LRB- RCNN/NN )/-RRB- architecture/NN to/TO capture/VB syntactic/JJ and/CC compositional/JJ -/HYPH semantic/JJ representations/NNS of/IN phrases/NNS and/CC words/NNS in/IN a/DT dependency/NN tree/NN ./.
Different/JJ with/IN the/DT original/JJ recursive/JJ neural/JJ network/NN ,/, we/PRP introduce/VBP the/DT convolution/NN and/CC pooling/VBG layers/NNS ,/, which/WDT can/MD model/VB a/DT variety/NN of/IN compositions/NNS by/IN the/DT feature/NN maps/VBZ and/CC choose/VB the/DT most/RBS informative/JJ compositions/NNS by/IN the/DT pooling/VBG layers/NNS ./.
Based/VBN on/IN RCNN/NNP ,/, we/PRP use/VBP a/DT discriminative/JJ model/NN to/TO re-rank/VB a/DT $/$ k/CD $/$ -/HYPH best/JJS list/NN of/IN candidate/NN dependency/NN parsing/VBG trees/NNS ./.
The/DT experiments/NNS show/VBP that/IN RCNN/NNP is/VBZ very/RB effective/JJ to/TO improve/VB the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN dependency/NN parsing/VBG on/IN both/DT English/NNP and/CC Chinese/NNP datasets/NNS ./.
