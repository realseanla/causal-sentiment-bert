Representing/VBG symbolic/JJ knowledge/NN into/IN a/DT connectionist/JJ network/NN is/VBZ the/DT key/JJ element/NN for/IN the/DT integration/NN of/IN scalable/JJ learning/NN and/CC sound/NN reasoning/NN ./.
Most/JJS of/IN the/DT previous/JJ studies/NNS focus/VBP on/IN discriminative/JJ neural/JJ networks/NNS which/WDT unnecessarily/RB require/VBP a/DT separation/NN of/IN input/NN //HYPH output/NN variables/NNS ./.
Recent/JJ development/NN of/IN generative/JJ neural/JJ networks/NNS such/JJ as/IN restricted/VBN Boltzmann/NNP machines/NNS (/-LRB- RBMs/NNS )/-RRB- has/VBZ shown/VBN a/DT capability/NN of/IN learning/VBG semantic/JJ abstractions/NNS directly/RB from/IN data/NNS ,/, posing/VBG a/DT promise/NN for/IN general/JJ symbolic/JJ learning/NN and/CC reasoning/NN ./.
Previous/JJ work/NN on/IN Penalty/NNP logic/NN show/VBP a/DT link/NN between/IN propositional/JJ logic/NN and/CC symmetric/JJ connectionist/JJ networks/NNS ,/, however/RB it/PRP is/VBZ not/RB applicable/JJ to/IN RBMs/NNS ./.
This/DT paper/NN proposes/VBZ a/DT novel/JJ method/NN to/TO represent/VB propositional/JJ formulas/NNS into/IN RBMs/NNS //SYM stack/NN of/IN RBMs/NNS where/WRB Gibbs/NNP sampling/NN can/MD be/VB seen/VBN as/IN MaxSAT/NNP ./.
It/PRP also/RB shows/VBZ a/DT promising/JJ use/NN of/IN RBMs/NNS to/TO learn/VB symbolic/JJ knowledge/NN through/IN maximum/JJ likelihood/NN estimation/NN ./.
