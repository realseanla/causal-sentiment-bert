We/PRP show/VBP an/DT alternative/JJ way/NN of/IN representing/VBG a/DT Bayesian/JJ belief/NN network/NN by/IN sensitivities/NNS and/CC probability/NN distributions/NNS ./.
This/DT representation/NN is/VBZ equivalent/JJ to/IN the/DT traditional/JJ representation/NN by/IN conditional/JJ probabilities/NNS ,/, but/CC makes/VBZ dependencies/NNS between/IN nodes/NNS apparent/JJ and/CC intuitively/RB easy/JJ to/TO understand/VB ./.
We/PRP also/RB propose/VBP a/DT QR/NN matrix/NN representation/NN for/IN the/DT sensitivities/NNS and/CC //HYPH or/CC conditional/JJ probabilities/NNS which/WDT is/VBZ more/RBR efficient/JJ ,/, in/IN both/DT memory/NN requirements/NNS and/CC computational/JJ speed/NN ,/, than/IN the/DT traditional/JJ representation/NN for/IN computer/NN -/HYPH based/VBN implementations/NNS of/IN probabilistic/JJ inference/NN ./.
We/PRP use/VBP sensitivities/NNS to/TO show/VB that/IN for/IN a/DT certain/JJ class/NN of/IN binary/JJ networks/NNS ,/, the/DT computation/NN time/NN for/IN approximate/JJ probabilistic/JJ inference/NN with/IN any/DT positive/JJ upper/JJ bound/VBN on/IN the/DT error/NN of/IN the/DT result/NN is/VBZ independent/JJ of/IN the/DT size/NN of/IN the/DT network/NN ./.
Finally/RB ,/, as/IN an/DT alternative/NN to/IN traditional/JJ algorithms/NNS that/WDT use/VBP conditional/JJ probabilities/NNS ,/, we/PRP describe/VBP an/DT exact/JJ algorithm/NN for/IN probabilistic/JJ inference/NN that/WDT uses/VBZ the/DT QR/NN -/HYPH representation/NN for/IN sensitivities/NNS and/CC updates/NNS probability/NN distributions/NNS of/IN nodes/NNS in/IN a/DT network/NN according/VBG to/IN messages/NNS from/IN the/DT neighbors/NNS ./.
