It/PRP 's/VBZ useful/JJ to/TO automatically/RB transform/VB an/DT image/NN from/IN its/PRP$ original/JJ form/NN to/IN some/DT synthetic/JJ form/NN (/-LRB- style/NN ,/, partial/JJ contents/NNS ,/, etc./FW )/-RRB- ,/, while/IN keeping/VBG the/DT original/JJ structure/NN or/CC semantics/NNS ./.
We/PRP define/VBP this/DT requirement/NN as/IN the/DT "/`` image/NN -/HYPH to/IN -/HYPH image/NN translation/NN "/'' problem/NN ,/, and/CC propose/VB a/DT general/JJ approach/NN to/TO achieve/VB it/PRP ,/, based/VBN on/IN deep/JJ convolutional/JJ and/CC conditional/JJ generative/JJ adversarial/JJ networks/NNS (/-LRB- GANs/NNS )/-RRB- ,/, which/WDT has/VBZ gained/VBN a/DT phenomenal/JJ success/NN to/TO learn/VB mapping/NN images/NNS from/IN noise/NN input/NN since/IN 2014/CD ./.
In/IN this/DT work/NN ,/, we/PRP develop/VBP a/DT two/CD step/NN (/-LRB- unsupervised/JJ )/-RRB- learning/NN method/NN to/TO translate/VB images/NNS between/IN different/JJ domains/NNS by/IN using/VBG unlabeled/JJ images/NNS without/IN specifying/VBG any/DT correspondence/NN between/IN them/PRP ,/, so/IN that/IN to/TO avoid/VB the/DT cost/NN of/IN acquiring/VBG labeled/VBN data/NNS ./.
Compared/VBN with/IN prior/JJ works/NNS ,/, we/PRP demonstrated/VBD the/DT capacity/NN of/IN generality/NN in/IN our/PRP$ model/NN ,/, by/IN which/WDT variance/NN of/IN translations/NNS can/MD be/VB conduct/NN by/IN a/DT single/JJ type/NN of/IN model/NN ./.
Such/JJ capability/NN is/VBZ desirable/JJ in/IN applications/NNS like/IN bidirectional/JJ translation/NN
