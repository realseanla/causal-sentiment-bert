The/DT minimization/NN of/IN the/DT logistic/JJ loss/NN is/VBZ a/DT popular/JJ approach/NN to/IN batch/NN supervised/VBD learning/NN ./.
Our/PRP$ paper/NN starts/VBZ from/IN the/DT surprising/JJ observation/NN that/IN ,/, when/WRB fitting/VBG linear/JJ (/-LRB- or/CC kernelized/VBN )/-RRB- classifiers/NNS ,/, the/DT minimization/NN of/IN the/DT logistic/JJ loss/NN is/VBZ \/SYM textit/FW {/-LRB- equivalent/JJ }/-RRB- to/IN the/DT minimization/NN of/IN an/DT exponential/JJ \/NN textit/NN {/-LRB- rado/NN }/-RRB- -/HYPH loss/NN computed/VBN (/-LRB- i/LS )/-RRB- over/IN transformed/VBN data/NNS that/WDT we/PRP call/VBP Rademacher/NNP observations/NNS (/-LRB- rados/NNS )/-RRB- ,/, and/CC (/-LRB- ii/LS )/-RRB- over/IN the/DT \/SYM textit/FW {/-LRB- same/JJ }/-RRB- classifier/NN as/IN the/DT one/CD of/IN the/DT logistic/JJ loss/NN ./.
Thus/RB ,/, a/DT classifier/NN learnt/VBD from/IN rados/NNS can/MD be/VB \/SYM textit/FW {/-LRB- directly/RB }/-RRB- used/VBN to/TO classify/VB \/SYM textit/FW {/-LRB- observations/NNS }/-RRB- ./.
We/PRP provide/VBP a/DT learning/NN algorithm/NN over/IN rados/NNS with/IN boosting/VBG -/HYPH compliant/JJ convergence/NN rates/NNS on/IN the/DT \/SYM textit/FW {/-LRB- logistic/JJ loss/NN }/-RRB- (/-LRB- computed/VBN over/IN examples/NNS )/-RRB- ./.
Experiments/NNS on/IN domains/NNS with/IN up/RB to/IN millions/NNS of/IN examples/NNS ,/, backed/VBD up/RP by/IN theoretical/JJ arguments/NNS ,/, display/VBP that/DT learning/NN over/IN a/DT small/JJ set/NN of/IN random/JJ rados/NNS can/MD challenge/VB the/DT state/NN of/IN the/DT art/NN that/WDT learns/VBZ over/IN the/DT \/SYM textit/FW {/-LRB- complete/JJ }/-RRB- set/NN of/IN examples/NNS ./.
We/PRP show/VBP that/IN rados/NNS comply/VBP with/IN various/JJ privacy/NN requirements/NNS that/WDT make/VBP them/PRP good/JJ candidates/NNS for/IN machine/NN learning/NN in/IN a/DT privacy/NN framework/NN ./.
We/PRP give/VBP several/JJ algebraic/JJ ,/, geometric/JJ and/CC computational/JJ hardness/NN results/NNS on/IN reconstructing/VBG examples/NNS from/IN rados/NNS ./.
We/PRP also/RB show/VBP how/WRB it/PRP is/VBZ possible/JJ to/TO craft/VB ,/, and/CC efficiently/RB learn/VB from/IN ,/, rados/NNS in/IN a/DT differential/JJ privacy/NN framework/NN ./.
Tests/NNS reveal/VBP that/IN learning/VBG from/IN differentially/RB private/JJ rados/NNS can/MD compete/VB with/IN learning/NN from/IN random/JJ rados/NNS ,/, and/CC hence/RB with/IN batch/NN learning/NN from/IN examples/NNS ,/, achieving/VBG non-trivial/JJ privacy/NN vs/IN accuracy/NN tradeoffs/NNS ./.
