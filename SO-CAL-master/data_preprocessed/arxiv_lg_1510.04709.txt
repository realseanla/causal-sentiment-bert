In/IN this/DT paper/NN we/PRP present/VBP an/DT approach/NN to/IN multi-language/JJ image/NN description/NN bringing/VBG together/RB insights/NNS from/IN neural/JJ machine/NN translation/NN and/CC neural/JJ image/NN description/NN ./.
To/TO create/VB a/DT description/NN of/IN an/DT image/NN for/IN a/DT given/VBN target/NN language/NN ,/, our/PRP$ sequence/NN generation/NN models/NNS condition/NN on/IN feature/NN vectors/NNS from/IN the/DT image/NN ,/, the/DT description/NN from/IN the/DT source/NN language/NN ,/, and/CC //HYPH or/CC a/DT multimodal/JJ vector/NN computed/VBN over/IN the/DT image/NN and/CC a/DT description/NN in/IN the/DT source/NN language/NN ./.
In/IN image/NN description/NN experiments/NNS on/IN the/DT IAPR/NN -/HYPH TC12/NN dataset/NN of/IN images/NNS aligned/VBN with/IN English/NNP and/CC German/JJ sentences/NNS ,/, we/PRP find/VBP significant/JJ and/CC substantial/JJ improvements/NNS in/IN BLEU4/NN and/CC Meteor/NN scores/NNS for/IN models/NNS trained/VBN over/IN multiple/JJ languages/NNS ,/, compared/VBN to/IN a/DT monolingual/JJ baseline/NN ./.
