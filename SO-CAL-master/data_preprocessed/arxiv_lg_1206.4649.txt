We/PRP present/VBP a/DT comprehensive/JJ framework/NN for/IN structured/JJ sparse/JJ coding/NN and/CC modeling/NN extending/VBG the/DT recent/JJ ideas/NNS of/IN using/VBG learnable/JJ fast/JJ regressors/NNS to/TO approximate/VB exact/JJ sparse/JJ codes/NNS ./.
For/IN this/DT purpose/NN ,/, we/PRP develop/VBP a/DT novel/JJ block/NN -/HYPH coordinate/NN proximal/JJ splitting/NN method/NN for/IN the/DT iterative/JJ solution/NN of/IN hierarchical/JJ sparse/JJ coding/NN problems/NNS ,/, and/CC show/VB an/DT efficient/JJ feed/NN forward/JJ architecture/NN derived/VBN from/IN its/PRP$ iteration/NN ./.
This/DT architecture/NN faithfully/RB approximates/VBZ the/DT exact/JJ structured/JJ sparse/JJ codes/NNS with/IN a/DT fraction/NN of/IN the/DT complexity/NN of/IN the/DT standard/JJ optimization/NN methods/NNS ./.
We/PRP also/RB show/VBP that/IN by/IN using/VBG different/JJ training/NN objective/JJ functions/NNS ,/, learnable/JJ sparse/JJ encoders/NNS are/VBP no/RB longer/RBR restricted/VBN to/TO be/VB mere/JJ approximants/NNS of/IN the/DT exact/JJ sparse/JJ code/NN for/IN a/DT pre-given/JJ dictionary/NN ,/, as/IN in/IN earlier/JJR formulations/NNS ,/, but/CC can/MD be/VB rather/RB used/VBN as/IN full/JJ -/HYPH featured/VBN sparse/JJ encoders/NNS or/CC even/RB modelers/NNS ./.
A/DT simple/JJ implementation/NN shows/VBZ several/JJ orders/NNS of/IN magnitude/NN speedup/NN compared/VBN to/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN at/IN minimal/JJ performance/NN degradation/NN ,/, making/VBG the/DT proposed/VBN framework/NN suitable/JJ for/IN real/JJ time/NN and/CC large/JJ -/HYPH scale/NN applications/NNS ./.
