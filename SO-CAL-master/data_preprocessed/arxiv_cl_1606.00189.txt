Phrase/NN -/HYPH based/VBN statistical/JJ machine/NN translation/NN (/-LRB- SMT/NN )/-RRB- systems/NNS have/VBP previously/RB been/VBN used/VBN for/IN the/DT task/NN of/IN grammatical/JJ error/NN correction/NN (/-LRB- GEC/NNP )/-RRB- to/TO achieve/VB state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN accuracy/NN ./.
The/DT superiority/NN of/IN SMT/NN systems/NNS comes/VBZ from/IN their/PRP$ ability/NN to/TO learn/VB text/NN transformations/NNS from/IN erroneous/JJ to/IN corrected/VBN text/NN ,/, without/IN explicitly/RB modeling/VBG error/NN types/NNS ./.
However/RB ,/, phrase/NN -/HYPH based/VBN SMT/NNP systems/NNS suffer/VBP from/IN limitations/NNS of/IN discrete/JJ word/NN representation/NN ,/, linear/JJ mapping/NN ,/, and/CC lack/NN of/IN global/JJ context/NN ./.
In/IN this/DT paper/NN ,/, we/PRP address/VBP these/DT limitations/NNS by/IN using/VBG two/CD different/JJ yet/CC complementary/JJ neural/JJ network/NN models/NNS ,/, namely/RB a/DT neural/JJ network/NN global/JJ lexicon/NN model/NN and/CC a/DT neural/JJ network/NN joint/JJ model/NN ./.
These/DT neural/JJ networks/NNS can/MD generalize/VB better/JJR by/IN using/VBG continuous/JJ space/NN representation/NN of/IN words/NNS and/CC learn/VB non-linear/JJ mappings/NNS ./.
Moreover/RB ,/, they/PRP can/MD leverage/VB contextual/JJ information/NN from/IN the/DT source/NN sentence/NN more/RBR effectively/RB ./.
By/IN adding/VBG these/DT two/CD components/NNS ,/, we/PRP achieve/VBP statistically/RB significant/JJ improvement/NN in/IN accuracy/NN for/IN grammatical/JJ error/NN correction/NN over/IN a/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN GEC/NNP system/NN ./.
