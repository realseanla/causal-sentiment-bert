We/PRP present/VBP a/DT neural/JJ network/NN architecture/NN and/CC training/NN method/NN designed/VBN to/TO enable/VB very/RB rapid/JJ training/NN and/CC low/JJ implementation/NN complexity/NN ./.
Due/IN to/IN its/PRP$ training/NN speed/NN and/CC very/RB few/JJ tunable/JJ parameters/NNS ,/, the/DT method/NN has/VBZ strong/JJ potential/NN for/IN embedded/VBN hardware/NN applications/NNS requiring/VBG frequent/JJ retraining/VBG or/CC online/JJ training/NN ./.
The/DT approach/NN is/VBZ characterized/VBN by/IN (/-LRB- a/DT )/-RRB- convolutional/JJ filters/NNS based/VBN on/IN biologically/RB inspired/VBN visual/JJ processing/NN filters/NNS ,/, (/-LRB- b/LS )/-RRB- randomly/RB -/HYPH valued/VBN classifier/NN -/HYPH stage/NN input/NN weights/NNS ,/, (/-LRB- c/LS )/-RRB- use/NN of/IN least/JJS squares/NNS regression/NN to/TO train/VB the/DT classifier/NN output/NN weights/NNS in/IN a/DT single/JJ batch/NN ,/, and/CC (/-LRB- d/LS )/-RRB- linear/JJ classifier/NN -/HYPH stage/NN output/NN units/NNS ./.
We/PRP demonstrate/VBP the/DT efficacy/NN of/IN the/DT method/NN as/IN an/DT image/NN classifier/NN ,/, obtaining/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS on/IN the/DT MNIST/NN (/-LRB- 0.37/CD percent/NN error/NN )/-RRB- and/CC NORB/NNP -/HYPH small/JJ (/-LRB- 2.2/CD percent/NN )/-RRB- image/NN classification/NN databases/NNS ,/, with/IN very/RB fast/JJ training/NN times/NNS compared/VBN to/IN standard/JJ deep/JJ network/NN approaches/NNS ./.
The/DT network/NN 's/POS performance/NN on/IN the/DT Google/NNP Street/NNP View/NNP House/NNP Number/NN (/-LRB- SVHN/NN )/-RRB- (/-LRB- 4/CD percent/NN )/-RRB- database/NN is/VBZ also/RB competitive/JJ with/IN state/NN -/HYPH of/IN -/HYPH the/DT art/NN methods/NNS ./.
