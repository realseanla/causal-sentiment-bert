Many/JJ natural/JJ language/NN understanding/NN (/-LRB- NLU/NN )/-RRB- tasks/NNS ,/, such/JJ as/IN shallow/JJ parsing/VBG (/-LRB- i.e./FW ,/, text/NN chunking/NN )/-RRB- and/CC semantic/JJ slot/NN filling/NN ,/, require/VBP the/DT assignment/NN of/IN representative/JJ labels/NNS to/IN the/DT meaningful/JJ chunks/NNS in/IN a/DT sentence/NN ./.
Most/JJS of/IN the/DT current/JJ deep/JJ neural/JJ network/NN (/-LRB- DNN/NN )/-RRB- based/VBN methods/NNS consider/VBP these/DT tasks/NNS as/IN a/DT sequence/NN labeling/NN problem/NN ,/, in/IN which/WDT a/DT word/NN ,/, rather/RB than/IN a/DT chunk/NN ,/, is/VBZ treated/VBN as/IN the/DT basic/JJ unit/NN for/IN labeling/NN ./.
These/DT chunks/NNS are/VBP then/RB inferred/VBN by/IN the/DT standard/JJ IOB/NNP (/-LRB- Inside/IN -/HYPH Outside/JJ -/HYPH Beginning/NN )/-RRB- labels/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP an/DT alternative/JJ approach/NN by/IN investigating/VBG the/DT use/NN of/IN DNN/NNP for/IN sequence/NN chunking/NN ,/, and/CC propose/VB three/CD neural/JJ models/NNS so/IN that/IN each/DT chunk/NN can/MD be/VB treated/VBN as/IN a/DT complete/JJ unit/NN for/IN labeling/NN ./.
Experimental/JJ results/NNS show/VBP that/IN the/DT proposed/VBN neural/JJ sequence/NN chunking/VBG models/NNS can/MD achieve/VB start/VB -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN on/IN both/CC the/DT text/NN chunking/NN and/CC slot/NN filling/VBG tasks/NNS ./.
