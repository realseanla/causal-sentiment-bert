In/IN this/DT work/NN we/PRP present/VBP a/DT deep/JJ learning/NN framework/NN for/IN video/NN compressive/JJ sensing/VBG ./.
The/DT proposed/VBN formulation/NN enables/VBZ recovery/NN of/IN video/NN frames/NNS in/IN a/DT few/JJ seconds/NNS at/IN significantly/RB improved/VBN reconstruction/NN quality/NN compared/VBN to/IN previous/JJ approaches/NNS ./.
Our/PRP$ investigation/NN starts/VBZ by/IN learning/VBG a/DT linear/JJ mapping/NN between/IN video/NN sequences/NNS and/CC corresponding/VBG measured/VBN frames/NNS which/WDT turns/VBZ out/RP to/TO provide/VB promising/JJ results/NNS ./.
We/PRP then/RB extend/VBP the/DT linear/JJ formulation/NN to/IN deep/JJ fully/RB -/HYPH connected/VBN networks/NNS and/CC explore/VB the/DT performance/NN gains/NNS using/VBG deeper/JJR architectures/NNS ./.
Our/PRP$ analysis/NN is/VBZ always/RB driven/VBN by/IN the/DT applicability/NN of/IN the/DT proposed/VBN framework/NN on/IN existing/VBG compressive/JJ video/NN architectures/NNS ./.
Extensive/JJ simulations/NNS on/IN several/JJ video/NN sequences/NNS document/VBP the/DT superiority/NN of/IN our/PRP$ approach/NN both/CC quantitatively/RB and/CC qualitatively/RB ./.
Finally/RB ,/, our/PRP$ analysis/NN offers/VBZ insights/NNS into/IN understanding/VBG how/WRB dataset/NN sizes/VBZ and/CC number/NN of/IN layers/NNS affect/VBP reconstruction/NN performance/NN while/IN raising/VBG a/DT few/JJ points/NNS for/IN future/JJ investigation/NN ./.
