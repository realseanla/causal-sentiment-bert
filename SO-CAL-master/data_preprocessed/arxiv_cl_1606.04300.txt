Most/JJS previous/JJ approaches/NNS to/IN Chinese/JJ word/NN segmentation/NN formalize/VB this/DT problem/NN as/IN a/DT character/NN -/HYPH based/VBN sequence/NN labeling/NN task/NN so/IN that/IN only/RB contextual/JJ information/NN within/IN fixed/VBN sized/JJ local/JJ windows/NNS and/CC simple/JJ interactions/NNS between/IN adjacent/JJ tags/NNS can/MD be/VB captured/VBN ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT novel/JJ neural/JJ framework/NN which/WDT thoroughly/RB eliminates/VBZ context/NN windows/NNS and/CC can/MD utilize/VB complete/JJ segmentation/NN history/NN ./.
Our/PRP$ model/NN employs/VBZ a/DT gated/VBN combination/NN neural/JJ network/NN over/IN characters/NNS to/TO produce/VB distributed/VBN representations/NNS of/IN word/NN candidates/NNS ,/, which/WDT are/VBP then/RB given/VBN to/IN a/DT long/JJ short/JJ -/HYPH term/NN memory/NN (/-LRB- LSTM/NN )/-RRB- language/NN scoring/VBG model/NN ./.
Experiments/NNS on/IN the/DT benchmark/NN datasets/NNS show/VBP that/IN without/IN the/DT help/NN of/IN feature/NN engineering/NN as/IN most/JJS existing/VBG approaches/NNS ,/, our/PRP$ models/NNS achieve/VBP competitive/JJ or/CC better/JJR performances/NNS with/IN previous/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS ./.
