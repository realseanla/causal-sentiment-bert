We/PRP introduce/VBP openXBOW/NNP ,/, an/DT open/JJ -/HYPH source/NN toolkit/NN for/IN the/DT generation/NN of/IN bag/NN -/HYPH of/IN -/HYPH words/NNS (/-LRB- BoW/NN )/-RRB- representations/NNS from/IN multimodal/JJ input/NN ./.
In/IN the/DT BoW/NNP principle/NN ,/, word/NN histograms/NNS were/VBD first/RB used/VBN as/IN features/NNS in/IN document/NN classification/NN ,/, but/CC the/DT idea/NN was/VBD and/CC can/MD easily/RB be/VB adapted/VBN to/IN ,/, e.g./FW ,/, acoustic/JJ or/CC visual/JJ low/JJ -/HYPH level/NN descriptors/NNS ,/, introducing/VBG a/DT prior/JJ step/NN of/IN vector/NN quantisation/NN ./.
The/DT openXBOW/NNP toolkit/NN supports/VBZ arbitrary/JJ numeric/JJ input/NN features/NNS and/CC text/NN input/NN and/CC concatenates/NNS computed/VBN subbags/NNS to/IN a/DT final/JJ bag/NN ./.
It/PRP provides/VBZ a/DT variety/NN of/IN extensions/NNS and/CC options/NNS ./.
To/IN our/PRP$ knowledge/NN ,/, openXBOW/NN is/VBZ the/DT first/JJ publicly/RB available/JJ toolkit/NN for/IN the/DT generation/NN of/IN crossmodal/JJ bags/NNS -/HYPH of/IN -/HYPH words/NNS ./.
The/DT capabilities/NNS of/IN the/DT tool/NN are/VBP exemplified/VBN in/IN two/CD sample/NN scenarios/NNS :/: time/NN -/HYPH continuous/JJ speech/NN -/HYPH based/VBN emotion/NN recognition/NN and/CC sentiment/NN analysis/NN in/IN tweets/NNS where/WRB improved/VBN results/NNS over/IN other/JJ feature/NN representation/NN forms/NNS were/VBD observed/VBN ./.
