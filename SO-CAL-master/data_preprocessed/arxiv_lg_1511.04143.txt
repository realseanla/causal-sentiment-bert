Recent/JJ work/NN has/VBZ shown/VBN that/IN deep/JJ neural/JJ networks/NNS are/VBP capable/JJ of/IN approximating/VBG both/DT value/NN functions/VBZ and/CC policies/NNS in/IN reinforcement/NN learning/VBG domains/NNS featuring/VBG continuous/JJ state/NN and/CC action/NN spaces/NNS ./.
However/RB ,/, to/IN the/DT best/JJS of/IN our/PRP$ knowledge/NN no/DT previous/JJ work/NN has/VBZ succeeded/VBN at/IN using/VBG deep/JJ neural/JJ networks/NNS in/IN structured/JJ (/-LRB- parameterized/JJ )/-RRB- continuous/JJ action/NN spaces/NNS ./.
To/TO fill/VB this/DT gap/NN ,/, this/DT paper/NN focuses/VBZ on/IN learning/VBG within/IN the/DT domain/NN of/IN simulated/JJ RoboCup/NNP soccer/NN ,/, which/WDT features/VBZ a/DT small/JJ set/NN of/IN discrete/JJ action/NN types/NNS ,/, each/DT of/IN which/WDT is/VBZ parameterized/VBN with/IN continuous/JJ variables/NNS ./.
The/DT best/JJS learned/VBN agent/NN can/MD score/VB goals/NNS more/RBR reliably/RB than/IN the/DT 2012/CD RoboCup/NNP champion/NN agent/NN ./.
As/IN such/JJ ,/, this/DT paper/NN represents/VBZ a/DT successful/JJ extension/NN of/IN deep/JJ reinforcement/NN learning/VBG to/IN the/DT class/NN of/IN parameterized/JJ action/NN space/NN MDPs/NNS ./.
