Recently/RB there/EX has/VBZ been/VBN significant/JJ activity/NN in/IN developing/VBG algorithms/NNS with/IN provable/JJ guarantees/NNS for/IN topic/NN modeling/NN ./.
In/IN standard/JJ topic/NN models/NNS ,/, a/DT topic/NN (/-LRB- such/JJ as/IN sports/NNS ,/, business/NN ,/, or/CC politics/NNS )/-RRB- is/VBZ viewed/VBN as/IN a/DT probability/NN distribution/NN $/$ \/CD vec/CD a_i/IN $/$ over/IN words/NNS ,/, and/CC a/DT document/NN is/VBZ generated/VBN by/IN first/JJ selecting/VBG a/DT mixture/NN $/$ \/SYM vec/NN w/IN $/$ over/IN topics/NNS ,/, and/CC then/RB generating/VBG words/NNS i.i.d./VBN from/IN the/DT associated/VBN mixture/NN $/$ A/DT {/-LRB- \/SYM vec/NN w/IN }/-RRB- $/$ ./.
Given/VBN a/DT large/JJ collection/NN of/IN such/JJ documents/NNS ,/, the/DT goal/NN is/VBZ to/TO recover/VB the/DT topic/NN vectors/NNS and/CC then/RB to/TO correctly/RB classify/VB new/JJ documents/NNS according/VBG to/IN their/PRP$ topic/NN mixture/NN ./.
