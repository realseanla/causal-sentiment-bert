We/PRP propose/VBP a/DT cluster/NN -/HYPH based/VBN quantization/NN method/NN to/TO convert/VB pre-trained/JJ full/JJ precision/NN weights/NNS into/IN ternary/JJ weights/NNS with/IN minimal/JJ impact/NN on/IN the/DT accuracy/NN ./.
In/IN addition/NN ,/, we/PRP also/RB constrain/VBP the/DT activations/NNS to/TO 8/CD -/HYPH bits/NNS thus/RB enabling/VBG sub/NN 8/CD -/HYPH bit/NN full/JJ integer/NN inference/NN pipeline/NN ./.
Our/PRP$ method/NN uses/VBZ smaller/JJR clusters/NNS of/IN N/NN filters/NNS with/IN a/DT common/JJ scaling/NN factor/NN to/TO minimize/VB the/DT quantization/NN loss/NN ,/, while/IN also/RB maximizing/VBG the/DT number/NN of/IN ternary/JJ operations/NNS ./.
We/PRP show/VBP that/IN with/IN a/DT cluster/NN size/NN of/IN N/NN =/SYM 4/CD on/IN Resnet/NNP -/HYPH 101/CD ,/, can/MD achieve/VB 71.8/CD percent/NN TOP/NN -/HYPH 1/CD accuracy/NN ,/, within/IN 6/CD percent/NN of/IN the/DT best/JJS full/JJ precision/NN results/NNS while/IN replacing/VBG \/SYM approx/NN 85/CD percent/NN of/IN all/DT multiplications/NNS with/IN 8/CD -/HYPH bit/NN accumulations/NNS ./.
Using/VBG the/DT same/JJ method/NN with/IN 4/CD -/HYPH bit/NN weights/NNS achieves/VBZ 76.3/CD percent/NN TOP/NN -/HYPH 1/CD accuracy/NN which/WDT within/IN 2/CD percent/NN of/IN the/DT full/JJ precision/NN result/NN ./.
We/PRP also/RB study/VB the/DT impact/NN of/IN the/DT size/NN of/IN the/DT cluster/NN on/IN both/DT performance/NN and/CC accuracy/NN ,/, larger/JJR cluster/NN sizes/NNS N/NN =/SYM 64/CD can/MD replace/VB \/SYM approx/NN 98/CD percent/NN of/IN the/DT multiplications/NNS with/IN ternary/JJ operations/NNS but/CC introduces/VBZ significant/JJ drop/NN in/IN accuracy/NN which/WDT necessitates/VBZ fine/JJ tuning/NN the/DT parameters/NNS with/IN retraining/VBG the/DT network/NN at/IN lower/JJR precision/NN ./.
To/TO address/VB this/DT we/PRP have/VBP also/RB trained/VBN low/JJ -/HYPH precision/NN Resnet/NNP -/HYPH 50/CD with/IN 8/CD -/HYPH bit/NN activations/NNS and/CC ternary/JJ weights/NNS by/IN pre-initializing/VBG the/DT network/NN with/IN full/JJ precision/NN weights/NNS and/CC achieve/VB 68.9/CD percent/NN TOP/NN -/HYPH 1/CD accuracy/NN within/IN 4/CD additional/JJ epochs/NNS ./.
Our/PRP$ final/JJ quantized/JJ model/NN can/MD run/VB on/IN a/DT full/JJ 8/CD -/HYPH bit/NN compute/VB pipeline/NN ,/, with/IN a/DT potential/JJ 16x/NN improvement/NN in/IN performance/NN compared/VBN to/IN baseline/NN full/JJ -/HYPH precision/NN models/NNS ./.
