In/IN this/DT paper/NN ,/, we/PRP present/VBP a/DT novel/JJ approach/NN for/IN Human/NNP Computer/NNP Interaction/NNP (/-LRB- HCI/NNP )/-RRB- where/WRB ,/, we/PRP control/VBP cursor/NN movement/NN using/VBG a/DT real/JJ -/HYPH time/NN camera/NN ./.
Current/JJ methods/NNS involve/VBP changing/VBG mouse/NN parts/NNS such/JJ as/IN adding/VBG more/JJR buttons/NNS or/CC changing/VBG the/DT position/NN of/IN the/DT tracking/NN ball/NN ./.
Instead/RB ,/, our/PRP$ method/NN is/VBZ to/TO use/VB a/DT camera/NN and/CC computer/NN vision/NN technology/NN ,/, such/JJ as/IN image/NN segmentation/NN and/CC gesture/NN recognition/NN ,/, to/TO control/VB mouse/NN tasks/NNS (/-LRB- left/VBN and/CC right/RB clicking/VBG ,/, double/RB -/HYPH clicking/VBG ,/, and/CC scrolling/VBG )/-RRB- and/CC we/PRP show/VBP how/WRB it/PRP can/MD perform/VB everything/NN as/IN current/JJ mouse/NN devices/NNS can/MD ./.
The/DT software/NN will/MD be/VB developed/VBN in/IN JAVA/NNP language/NN ./.
Recognition/NNP and/CC pose/VBP estimation/NN in/IN this/DT system/NN are/VBP user/NN independent/JJ and/CC robust/JJ as/IN we/PRP will/MD be/VB using/VBG colour/NN tapes/NNS on/IN our/PRP$ finger/NN to/TO perform/VB actions/NNS ./.
The/DT software/NN can/MD be/VB used/VBN as/IN an/DT intuitive/JJ input/NN interface/NN to/IN applications/NNS that/WDT require/VBP multi-dimensional/JJ control/NN e.g./FW computer/NN games/NNS etc/FW ./.
