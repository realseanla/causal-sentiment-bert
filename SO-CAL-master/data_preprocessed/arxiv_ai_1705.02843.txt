We/PRP investigate/VBP GPU/NNP -/HYPH based/VBN parallelization/NN of/IN Iterative/JJ -/HYPH Deepening/VBG A/DT */SYM (/-LRB- IDA/NNP */SYM )/-RRB- ./.
We/PRP show/VBP that/IN straightforward/JJ thread/NN -/HYPH based/VBN parallelization/NN techniques/NNS which/WDT were/VBD previously/RB proposed/VBN for/IN massively/RB parallel/JJ SIMD/NNP processors/NNS perform/VBP poorly/RB due/JJ to/IN warp/NN divergence/NN and/CC load/NN imbalance/NN ./.
We/PRP propose/VBP Block/NN -/HYPH Parallel/JJ IDA/NN */NFP (/-LRB- BPIDA/NNP */SYM )/-RRB- ,/, which/WDT assigns/VBZ the/DT search/NN of/IN a/DT subtree/NN to/IN a/DT block/NN (/-LRB- a/DT group/NN of/IN threads/NNS with/IN access/NN to/IN fast/JJ shared/VBN memory/NN )/-RRB- rather/RB than/IN a/DT thread/NN ./.
On/IN the/DT 15/CD -/HYPH puzzle/NN ,/, BPIDA/NNP */NFP on/IN a/DT NVIDIA/NNP GRID/NNP K520/NN with/IN 1536/CD CUDA/NNP cores/NNS achieves/VBZ a/DT speedup/NN of/IN 4.98/CD compared/VBN to/IN a/DT highly/RB optimized/VBN sequential/JJ IDA/NNP */NFP implementation/NN on/IN a/DT Xeon/NNP E5/NN -/HYPH 2670/CD core/NN ./.
