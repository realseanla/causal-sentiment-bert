A/DT standard/JJ objective/NN in/IN partially/RB -/HYPH observable/JJ Markov/NNP decision/NN processes/NNS (/-LRB- POMDPs/NNS )/-RRB- is/VBZ to/TO find/VB a/DT policy/NN that/WDT maximizes/VBZ the/DT expected/VBN discounted/VBN -/HYPH sum/NN payoff/NN ./.
However/RB ,/, such/JJ policies/NNS may/MD still/RB permit/VB unlikely/JJ but/CC highly/RB undesirable/JJ outcomes/NNS ,/, which/WDT is/VBZ problematic/JJ especially/RB in/IN safety/NN -/HYPH critical/JJ applications/NNS ./.
Recently/RB ,/, there/EX has/VBZ been/VBN a/DT surge/NN of/IN interest/NN in/IN POMDPs/NNS where/WRB the/DT goal/NN is/VBZ to/TO maximize/VB the/DT probability/NN to/TO ensure/VB that/IN the/DT payoff/NN is/VBZ at/IN least/JJS a/DT given/VBN threshold/NN ,/, but/CC these/DT approaches/NNS do/VBP not/RB consider/VB any/DT optimization/NN beyond/IN satisfying/VBG this/DT threshold/NN constraint/NN ./.
In/IN this/DT work/NN we/PRP go/VBP beyond/IN both/CC the/DT "/`` expectation/NN "/'' and/CC "/`` threshold/NN "/'' approaches/NNS and/CC consider/VB a/DT "/`` guaranteed/VBN payoff/NN optimization/NN (/-LRB- GPO/NN )/-RRB- "/`` problem/NN for/IN POMDPs/NNS ,/, where/WRB we/PRP are/VBP given/VBN a/DT threshold/NN $/$ t/CD $/$ and/CC the/DT objective/NN is/VBZ to/TO find/VB a/DT policy/NN $/$ \/CD sigma/CD $/$ such/PDT that/IN a/DT )/-RRB- each/DT possible/JJ outcome/NN of/IN $/$ \/CD sigma/CD $/$ yields/VBZ a/DT discounted/VBN -/HYPH sum/NN payoff/NN of/IN at/RB least/RBS $/$ t/CD $/$ ,/, and/CC b/LS )/-RRB- the/DT expected/VBN discounted/VBN -/HYPH sum/NN payoff/NN of/IN $/$ \/CD sigma/CD $/$ is/VBZ optimal/JJ (/-LRB- or/CC near/IN -/HYPH optimal/JJ )/-RRB- among/IN all/DT policies/NNS satisfying/VBG a/LS )/-RRB- ./.
We/PRP present/VBP a/DT practical/JJ approach/NN to/TO tackle/VB the/DT GPO/NN problem/NN and/CC evaluate/VB it/PRP on/IN standard/JJ POMDP/NN benchmarks/NNS ./.
