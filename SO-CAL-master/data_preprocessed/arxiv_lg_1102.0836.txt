It/PRP is/VBZ a/DT challenging/JJ task/NN to/TO select/VB correlated/VBN variables/NNS in/IN a/DT high/JJ dimensional/JJ space/NN ./.
To/TO address/VB this/DT challenge/NN ,/, the/DT elastic/JJ net/NN has/VBZ been/VBN developed/VBN and/CC successfully/RB applied/VBD to/IN many/JJ applications/NNS ./.
Despite/IN its/PRP$ great/JJ success/NN ,/, the/DT elastic/JJ net/NN does/VBZ not/RB explicitly/RB use/VB correlation/NN information/NN embedded/VBN in/IN data/NNS to/TO select/VB correlated/VBN variables/NNS ./.
To/TO overcome/VB this/DT limitation/NN ,/, we/PRP present/VBP a/DT novel/JJ Bayesian/JJ hybrid/NN model/NN ,/, the/DT \/NNP eig/NNP ,/, that/DT uses/VBZ the/DT eigenstructures/NNS of/IN data/NNS to/TO guide/VB variable/JJ selection/NN ./.
Specifically/RB ,/, it/PRP integrates/VBZ a/DT sparse/JJ conditional/JJ classification/NN model/NN with/IN a/DT generative/JJ model/NN capturing/VBG variable/JJ correlations/NNS in/IN a/DT principled/JJ Bayesian/JJ framework/NN ./.
We/PRP reparameterize/VBP the/DT hybrid/NN model/NN in/IN the/DT eigenspace/NN to/TO avoid/VB overfiting/VBG and/CC to/TO increase/VB the/DT computational/JJ efficiency/NN of/IN its/PRP$ MCMC/NNP sampler/NN ./.
Furthermore/RB ,/, we/PRP provide/VBP an/DT alternative/JJ view/NN to/IN the/DT \/NNP eig/NNP from/IN a/DT regularization/NN perspective/NN :/: the/DT \/NNP eig/NNP has/VBZ an/DT adaptive/JJ eigenspace/NN -/HYPH based/VBN composite/JJ regularizer/NN ,/, which/WDT naturally/RB generalizes/VBZ the/DT $/NN l/NN _/NFP {/-LRB- 1/2/CD }/-RRB- $/$ regularizer/CD used/VBN by/IN the/DT elastic/JJ net/NN ./.
Experiments/NNS on/IN synthetic/JJ and/CC real/JJ data/NNS show/VBP that/IN the/DT \/NNP eig/NNP significantly/RB outperforms/VBZ the/DT lasso/NN ,/, the/DT elastic/JJ net/NN ,/, and/CC the/DT Bayesian/JJ lasso/NN in/IN terms/NNS of/IN prediction/NN accuracy/NN ,/, especially/RB when/WRB the/DT number/NN of/IN training/NN samples/NNS is/VBZ smaller/JJR than/IN the/DT number/NN of/IN variables/NNS ./.
