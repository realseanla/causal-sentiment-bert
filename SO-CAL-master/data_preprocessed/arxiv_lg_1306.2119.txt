We/PRP consider/VBP the/DT stochastic/JJ approximation/NN problem/NN where/WRB a/DT convex/NN function/NN has/VBZ to/TO be/VB minimized/VBN ,/, given/VBN only/RB the/DT knowledge/NN of/IN unbiased/JJ estimates/NNS of/IN its/PRP$ gradients/NNS at/IN certain/JJ points/NNS ,/, a/DT framework/NN which/WDT includes/VBZ machine/NN learning/NN methods/NNS based/VBN on/IN the/DT minimization/NN of/IN the/DT empirical/JJ risk/NN ./.
We/PRP focus/VBP on/IN problems/NNS without/IN strong/JJ convexity/NN ,/, for/IN which/WDT all/DT previously/RB known/VBN algorithms/NNS achieve/VBP a/DT convergence/NN rate/NN for/IN function/NN values/NNS of/IN O/NN (/-LRB- 1/CD //SYM n/NN ^/SYM {/-LRB- 1/2/CD }/-RRB- )/-RRB- ./.
We/PRP consider/VBP and/CC analyze/VBP two/CD algorithms/NNS that/WDT achieve/VBP a/DT rate/NN of/IN O/NN (/-LRB- 1/CD //SYM n/NN )/-RRB- for/IN classical/JJ supervised/JJ learning/NN problems/NNS ./.
For/IN least/JJS -/HYPH squares/NNS regression/NN ,/, we/PRP show/VBP that/IN averaged/VBD stochastic/JJ gradient/NN descent/NN with/IN constant/JJ step/NN -/HYPH size/NN achieves/VBZ the/DT desired/VBN rate/NN ./.
For/IN logistic/JJ regression/NN ,/, this/DT is/VBZ achieved/VBN by/IN a/DT simple/JJ novel/JJ stochastic/JJ gradient/NN algorithm/NN that/WDT (/-LRB- a/DT )/-RRB- constructs/NNS successive/JJ local/JJ quadratic/JJ approximations/NNS of/IN the/DT loss/NN functions/NNS ,/, while/IN (/-LRB- b/NN )/-RRB- preserving/VBG the/DT same/JJ running/NN time/NN complexity/NN as/IN stochastic/JJ gradient/NN descent/NN ./.
For/IN these/DT algorithms/NNS ,/, we/PRP provide/VBP a/DT non-asymptotic/JJ analysis/NN of/IN the/DT generalization/NN error/NN (/-LRB- in/IN expectation/NN ,/, and/CC also/RB in/IN high/JJ probability/NN for/IN least/JJS -/HYPH squares/NNS )/-RRB- ,/, and/CC run/VB extensive/JJ experiments/NNS on/IN standard/JJ machine/NN learning/VBG benchmarks/NNS showing/VBG that/IN they/PRP often/RB outperform/VBP existing/VBG approaches/NNS ./.
