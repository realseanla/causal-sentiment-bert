Building/NN on/IN recent/JJ advances/NNS in/IN image/NN caption/NN generation/NN and/CC optical/JJ character/NN recognition/NN (/-LRB- OCR/NN )/-RRB- ,/, we/PRP present/VBP a/DT general/JJ -/HYPH purpose/NN ,/, deep/JJ learning/NN -/HYPH based/VBN system/NN to/TO decompile/VB an/DT image/NN into/IN presentational/JJ markup/NN ./.
While/IN this/DT task/NN is/VBZ a/DT well/RB -/HYPH studied/VBN problem/NN in/IN OCR/NNP ,/, our/PRP$ method/NN takes/VBZ an/DT inherently/RB different/JJ ,/, data/NN -/HYPH driven/VBN approach/NN ./.
Our/PRP$ model/NN does/VBZ not/RB require/VB any/DT knowledge/NN of/IN the/DT underlying/VBG markup/NN language/NN ,/, and/CC is/VBZ simply/RB trained/VBN end/NN -/HYPH to/IN -/HYPH end/NN on/IN real/JJ -/HYPH world/NN example/NN data/NNS ./.
The/DT model/NN employs/VBZ a/DT convolutional/JJ network/NN for/IN text/NN and/CC layout/NN recognition/NN in/IN tandem/NN with/IN an/DT attention/NN -/HYPH based/VBN neural/JJ machine/NN translation/NN system/NN ./.
To/TO train/VB and/CC evaluate/VB the/DT model/NN ,/, we/PRP introduce/VBP a/DT new/JJ dataset/NN of/IN real/JJ -/HYPH world/NN rendered/VBN mathematical/JJ expressions/NNS paired/VBN with/IN LaTeX/NN markup/NN ,/, as/RB well/RB as/IN a/DT synthetic/JJ dataset/NN of/IN web/NN pages/NNS paired/VBN with/IN HTML/NN snippets/NNS ./.
Experimental/JJ results/NNS show/VBP that/IN the/DT system/NN is/VBZ surprisingly/RB effective/JJ at/IN generating/VBG accurate/JJ markup/NN for/IN both/DT datasets/NNS ./.
While/IN a/DT standard/JJ domain/NN -/HYPH specific/JJ LaTeX/NN OCR/NN system/NN achieves/VBZ around/RB 25/CD percent/NN accuracy/NN ,/, our/PRP$ model/NN reproduces/VBZ the/DT exact/JJ rendered/VBN image/NN on/IN 75/CD percent/NN of/IN examples/NNS ./.
