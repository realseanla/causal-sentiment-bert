Modified/VBN policy/NN iteration/NN (/-LRB- MPI/NNP )/-RRB- is/VBZ a/DT dynamic/JJ programming/NN (/-LRB- DP/NN )/-RRB- algorithm/NN that/WDT contains/VBZ the/DT two/CD celebrated/JJ policy/NN and/CC value/NN iteration/NN methods/NNS ./.
Despite/IN its/PRP$ generality/NN ,/, MPI/NNP has/VBZ not/RB been/VBN thoroughly/RB studied/VBN ,/, especially/RB its/PRP$ approximation/NN form/NN which/WDT is/VBZ used/VBN when/WRB the/DT state/NN and/CC //HYPH or/CC action/NN spaces/NNS are/VBP large/JJ or/CC infinite/JJ ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP three/CD approximate/JJ MPI/NNP (/-LRB- AMPI/NNP )/-RRB- algorithms/NNS that/WDT are/VBP extensions/NNS of/IN the/DT well/NN -/HYPH known/VBN approximate/JJ DP/NNP algorithms/NNS :/: fitted/VBN -/HYPH value/NN iteration/NN ,/, fitted/VBN -/HYPH Q/NN iteration/NN ,/, and/CC classification/NN -/HYPH based/VBN policy/NN iteration/NN ./.
We/PRP provide/VBP an/DT error/NN propagation/NN analysis/NN for/IN AMPI/NNP that/WDT unifies/VBZ those/DT for/IN approximate/JJ policy/NN and/CC value/NN iteration/NN ./.
We/PRP also/RB provide/VBP a/DT finite/NN -/HYPH sample/NN analysis/NN for/IN the/DT classification/NN -/HYPH based/VBN implementation/NN of/IN AMPI/NNP (/-LRB- CBMPI/NNP )/-RRB- ,/, which/WDT is/VBZ more/RBR general/JJ (/-LRB- and/CC somehow/RB contains/VBZ )/-RRB- than/IN the/DT analysis/NN of/IN the/DT other/JJ presented/VBN AMPI/NNP algorithms/NNS ./.
An/DT interesting/JJ observation/NN is/VBZ that/IN the/DT MPI/NNP 's/POS parameter/NN allows/VBZ us/PRP to/TO control/VB the/DT balance/NN of/IN errors/NNS (/-LRB- in/IN value/NN function/NN approximation/NN and/CC in/IN estimating/VBG the/DT greedy/JJ policy/NN )/-RRB- in/IN the/DT final/JJ performance/NN of/IN the/DT CBMPI/NNP algorithm/NN ./.
