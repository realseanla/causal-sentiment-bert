Recent/JJ progress/NN on/IN image/NN captioning/NN has/VBZ made/VBN it/PRP possible/JJ to/TO generate/VB novel/JJ sentences/NNS describing/VBG images/NNS in/IN natural/JJ language/NN ,/, but/CC compressing/VBG an/DT image/NN into/IN a/DT single/JJ sentence/NN can/MD describe/VB visual/JJ content/NN in/IN only/RB coarse/JJ detail/NN ./.
While/IN one/CD new/JJ captioning/NN approach/NN ,/, dense/JJ captioning/NN ,/, can/MD potentially/RB describe/VB images/NNS in/IN finer/JJR levels/NNS of/IN detail/NN by/IN captioning/VBG many/JJ regions/NNS within/IN an/DT image/NN ,/, it/PRP in/IN turn/NN is/VBZ unable/JJ to/TO produce/VB a/DT coherent/JJ story/NN for/IN an/DT image/NN ./.
In/IN this/DT paper/NN we/PRP overcome/VBP these/DT limitations/NNS by/IN generating/VBG entire/JJ paragraphs/NNS for/IN describing/VBG images/NNS ,/, which/WDT can/MD tell/VB detailed/JJ ,/, unified/JJ stories/NNS ./.
We/PRP develop/VBP a/DT model/NN that/WDT decomposes/VBZ both/CC images/NNS and/CC paragraphs/NNS into/IN their/PRP$ constituent/JJ parts/NNS ,/, detecting/VBG semantic/JJ regions/NNS in/IN images/NNS and/CC using/VBG a/DT hierarchical/JJ recurrent/JJ neural/JJ network/NN to/TO reason/VB about/RB language/NN ./.
Linguistic/JJ analysis/NN confirms/VBZ the/DT complexity/NN of/IN the/DT paragraph/NN generation/NN task/NN ,/, and/CC thorough/JJ experiments/NNS on/IN a/DT new/JJ dataset/NN of/IN image/NN and/CC paragraph/NN pairs/NNS demonstrate/VBP the/DT effectiveness/NN of/IN our/PRP$ approach/NN ./.
