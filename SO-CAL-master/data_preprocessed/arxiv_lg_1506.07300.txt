The/DT computational/JJ cost/NN of/IN many/JJ signal/NN processing/NN and/CC machine/NN learning/NN techniques/NNS is/VBZ often/RB dominated/VBN by/IN the/DT cost/NN of/IN applying/VBG certain/JJ linear/JJ operators/NNS to/IN high/JJ -/HYPH dimensional/JJ vectors/NNS ./.
This/DT paper/NN introduces/VBZ an/DT algorithm/NN aimed/VBN at/IN reducing/VBG the/DT complexity/NN of/IN applying/VBG linear/JJ operators/NNS in/IN high/JJ dimension/NN by/IN approximately/RB factorizing/VBG the/DT corresponding/VBG matrix/NN into/IN few/JJ sparse/JJ factors/NNS ./.
The/DT approach/NN relies/VBZ on/IN recent/JJ advances/NNS in/IN non-convex/JJ optimization/NN ./.
It/PRP is/VBZ first/JJ explained/VBD and/CC analyzed/VBD in/IN details/NNS and/CC then/RB demonstrated/VBD experimentally/RB on/IN various/JJ problems/NNS including/VBG dictionary/NN learning/NN for/IN image/NN denoising/NN ,/, and/CC the/DT approximation/NN of/IN large/JJ matrices/NNS arising/VBG in/IN inverse/JJ problems/NNS ./.
