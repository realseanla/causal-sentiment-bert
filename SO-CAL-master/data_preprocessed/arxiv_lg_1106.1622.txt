We/PRP address/VBP the/DT problem/NN of/IN minimizing/VBG a/DT convex/NN function/NN over/IN the/DT space/NN of/IN large/JJ matrices/NNS with/IN low/JJ rank/NN ./.
While/IN this/DT optimization/NN problem/NN is/VBZ hard/JJ in/IN general/JJ ,/, we/PRP propose/VBP an/DT efficient/JJ greedy/JJ algorithm/NN and/CC derive/VBP its/PRP$ formal/JJ approximation/NN guarantees/NNS ./.
Each/DT iteration/NN of/IN the/DT algorithm/NN involves/VBZ (/-LRB- approximately/RB )/-RRB- finding/VBG the/DT left/JJ and/CC right/JJ singular/JJ vectors/NNS corresponding/VBG to/IN the/DT largest/JJS singular/JJ value/NN of/IN a/DT certain/JJ matrix/NN ,/, which/WDT can/MD be/VB calculated/VBN in/IN linear/JJ time/NN ./.
This/DT leads/VBZ to/IN an/DT algorithm/NN which/WDT can/MD scale/VB to/IN large/JJ matrices/NNS arising/VBG in/IN several/JJ applications/NNS such/JJ as/IN matrix/NN completion/NN for/IN collaborative/JJ filtering/NN and/CC robust/JJ low/JJ rank/NN matrix/NN approximation/NN ./.
