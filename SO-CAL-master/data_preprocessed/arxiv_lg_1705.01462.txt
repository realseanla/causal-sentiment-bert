We/PRP propose/VBP a/DT novel/JJ fine/JJ -/HYPH grained/JJ quantization/NN method/NN for/IN ternarizing/VBG pre-trained/JJ full/JJ precision/NN models/NNS ,/, while/IN also/RB constraining/VBG activations/NNS to/TO 8/CD -/HYPH bits/NNS ./.
Using/VBG this/DT method/NN ,/, we/PRP demonstrate/VBP minimal/JJ loss/NN in/IN classification/NN accuracy/NN on/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN topologies/NNS without/IN additional/JJ training/NN ./.
This/DT enables/VBZ a/DT full/JJ 8/CD -/HYPH bit/NN inference/NN pipeline/NN ,/, with/IN best/JJS reported/VBN accuracy/NN using/VBG ternary/JJ weights/NNS on/IN ImageNet/NNP dataset/NN ./.
Further/RB ,/, we/PRP also/RB provide/VBP an/DT improved/VBN theoretical/JJ formulation/NN that/WDT forms/VBZ the/DT basis/NN for/IN a/DT higher/JJR quality/NN solution/NN with/IN this/DT approach/NN ./.
Our/PRP$ method/NN involves/VBZ ternarizing/VBG the/DT original/JJ weight/NN tensor/NN in/IN groups/NNS of/IN $/$ N$/CD weights/NNS ./.
Using/VBG $/$ N/CD =/SYM 4/CD $/$ ,/, we/PRP achieve/VBP Top/JJ -/HYPH 1/CD accuracy/NN within/IN $/$ 3.7/CD \/SYM percent/NN $/$ and/CC $/$ 5.8/CD \/SYM percent/NN $/$ of/IN the/DT baseline/NN full/JJ precision/NN result/NN for/IN Resnet/NNP -/HYPH 101/CD and/CC Resnet/NNP -/HYPH 50/CD respectively/RB ,/, while/IN eliminating/VBG $/$ 75/CD \/SYM percent/NN $/$ of/IN all/DT multiplications/NNS ./.
We/PRP also/RB study/VB the/DT impact/NN of/IN group/NN size/NN on/IN both/DT performance/NN and/CC accuracy/NN ./.
With/IN a/DT group/NN size/NN of/IN $/$ N/CD =/SYM 64/CD $/$ ,/, we/PRP eliminate/VBP $/$ \/CD approx99/CD \/SYM percent/NN $/$ of/IN the/DT multiplications/NNS ;/: however/RB ,/, this/DT introduces/VBZ a/DT significant/JJ drop/NN in/IN accuracy/NN ,/, which/WDT necessitates/VBZ fine/JJ tuning/NN the/DT parameters/NNS (/-LRB- re-training/NN )/-RRB- at/IN lower/JJR precision/NN ./.
To/TO address/VB this/DT ,/, we/PRP re-train/VBP Resnet/NNP -/HYPH 50/CD with/IN 8/CD -/HYPH bit/NN activations/NNS and/CC ternary/JJ weights/NNS ,/, improving/VBG the/DT Top/JJ -/HYPH 1/CD accuracy/NN to/IN within/IN $/$ 4/CD \/SYM percent/NN $/$ of/IN the/DT full/JJ precision/NN result/VBP with/IN $/$ &lt;/SYM 30/CD \/SYM percent/NN $/$ additional/JJ overhead/NN ./.
Our/PRP$ final/JJ quantized/JJ model/NN can/MD run/VB on/IN a/DT full/JJ 8/CD -/HYPH bit/NN compute/VB pipeline/NN using/VBG 2/CD -/HYPH bit/NN weights/NNS and/CC has/VBZ the/DT potential/NN of/IN up/RB to/IN $/$ 16/CD \/SYM times/NNS $/$ improvement/NN in/IN performance/NN compared/VBN to/IN baseline/NN full/JJ -/HYPH precision/NN models/NNS ./.
