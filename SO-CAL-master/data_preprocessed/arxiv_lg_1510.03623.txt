Restricted/VBN Boltzmann/JJ machines/NNS (/-LRB- RBMs/NNS )/-RRB- are/VBP endowed/VBN with/IN the/DT universal/JJ power/NN of/IN modeling/NN (/-LRB- binary/NN )/-RRB- joint/JJ distributions/NNS ./.
Meanwhile/RB ,/, as/IN a/DT result/NN of/IN their/PRP$ confining/VBG network/NN structure/NN ,/, training/NN RBMs/NNS confronts/VBZ less/JJR difficulties/NNS (/-LRB- compared/VBN with/IN more/RBR complicated/JJ models/NNS ,/, e.g./FW ,/, Boltzmann/NNP machines/NNS )/-RRB- when/WRB dealing/VBG with/IN approximation/NN and/CC inference/NN issues/NNS ./.
However/RB ,/, in/IN certain/JJ computational/JJ biology/NN scenarios/NNS ,/, such/JJ as/IN the/DT cancer/NN data/NNS analysis/NN ,/, employing/VBG RBMs/NNS to/TO model/VB data/NNS features/NNS may/MD lose/VB its/PRP$ efficacy/NN due/IN to/IN the/DT "/`` $/$ p/NN \/SYM gg/NNP N$/NNP "/'' problem/NN ,/, in/IN which/WDT the/DT number/NN of/IN features/NNS //, predictors/NNS is/VBZ much/RB larger/JJR than/IN the/DT sample/NN size/NN ./.
The/DT "/`` $/$ p/NN \/SYM gg/NNP N$/NNP "/'' problem/NN puts/VBZ the/DT bias/NN -/HYPH variance/NN trade/NN -/HYPH off/NN in/IN a/DT more/JJR crucial/JJ place/NN when/WRB designing/VBG statistical/JJ learning/NN methods/NNS ./.
In/IN this/DT manuscript/NN ,/, we/PRP try/VBP to/TO address/VB this/DT problem/NN by/IN proposing/VBG a/DT novel/JJ RBM/NNP model/NN ,/, called/VBN elastic/JJ restricted/JJ Boltzmann/JJ machine/NN (/-LRB- eRBM/NN )/-RRB- ,/, which/WDT incorporates/VBZ the/DT elastic/JJ regularization/NN term/NN into/IN the/DT likelihood/NN //HYPH cost/NN function/NN ./.
We/PRP provide/VBP several/JJ theoretical/JJ analysis/NN on/IN the/DT superiority/NN of/IN our/PRP$ model/NN ./.
Furthermore/RB ,/, attributed/VBN to/IN the/DT classic/JJ contrastive/JJ divergence/NN (/-LRB- CD/NN )/-RRB- algorithm/NN ,/, eRBMs/NNPS can/MD be/VB trained/VBN efficiently/RB ./.
Our/PRP$ novel/JJ model/NN is/VBZ a/DT promising/JJ method/NN for/IN future/JJ cancer/NN data/NNS analysis/NN ./.
