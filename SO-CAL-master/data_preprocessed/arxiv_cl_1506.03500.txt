We/PRP introduce/VBP language/NN -/HYPH driven/VBN image/NN generation/NN ,/, the/DT task/NN of/IN generating/VBG an/DT image/NN visualizing/VBG the/DT semantic/JJ contents/NNS of/IN a/DT word/NN embedding/NN ,/, e.g./FW ,/, given/VBN the/DT word/NN embedding/NN of/IN grasshopper/NN ,/, we/PRP generate/VBP a/DT natural/JJ image/NN of/IN a/DT grasshopper/NN ./.
We/PRP implement/VBP a/DT simple/JJ method/NN based/VBN on/IN two/CD mapping/VBG functions/NNS ./.
The/DT first/JJ takes/VBZ as/RB input/VB a/DT word/NN embedding/NN (/-LRB- as/IN produced/VBN ,/, e.g./FW ,/, by/IN the/DT word2vec/NN toolkit/NN )/-RRB- and/CC maps/VBZ it/PRP onto/IN a/DT high/JJ -/HYPH level/NN visual/JJ space/NN (/-LRB- e.g./FW ,/, the/DT space/NN defined/VBN by/IN one/CD of/IN the/DT top/JJ layers/NNS of/IN a/DT Convolutional/JJ Neural/JJ Network/NN )/-RRB- ./.
The/DT second/JJ function/NN maps/VBZ this/DT abstract/JJ visual/JJ representation/NN to/IN pixel/NN space/NN ,/, in/IN order/NN to/TO generate/VB the/DT target/NN image/NN ./.
Several/JJ user/NN studies/NNS suggest/VBP that/IN the/DT current/JJ system/NN produces/VBZ images/NNS that/WDT capture/VBP general/JJ visual/JJ properties/NNS of/IN the/DT concepts/NNS encoded/VBN in/IN the/DT word/NN embedding/NN ,/, such/JJ as/IN color/NN or/CC typical/JJ environment/NN ,/, and/CC are/VBP sufficient/JJ to/TO discriminate/VB between/IN general/JJ categories/NNS of/IN objects/NNS ./.
