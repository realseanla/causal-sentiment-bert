In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT novel/JJ method/NN for/IN fast/JJ face/NN recognition/NN called/VBN L1/NN //HYPH 2/CD Regularized/VBN Sparse/JJ Representation/NN using/VBG Hierarchical/JJ Feature/NN Selection/NN (/-LRB- HSR/NN )/-RRB- ./.
By/IN employing/VBG hierarchical/JJ feature/NN selection/NN ,/, we/PRP can/MD compress/VB the/DT scale/NN and/CC dimension/NN of/IN global/JJ dictionary/NN ,/, which/WDT directly/RB contributes/VBZ to/IN the/DT decrease/NN of/IN computational/JJ cost/NN in/IN sparse/JJ representation/NN that/WDT our/PRP$ approach/NN is/VBZ strongly/RB rooted/VBN in/IN ./.
It/PRP consists/VBZ of/IN Gabor/NNP wavelets/NNS and/CC Extreme/NNP Learning/NNP Machine/NNP Auto/NNP -/HYPH Encoder/NNP (/-LRB- ELM/NNP -/HYPH AE/NNP )/-RRB- hierarchically/RB ./.
For/IN Gabor/NNP wavelets/NNS part/NN ,/, local/JJ features/NNS can/MD be/VB extracted/VBN at/IN multiple/JJ scales/NNS and/CC orientations/NNS to/TO form/VB Gabor/NNP -/HYPH feature/NN based/VBN image/NN ,/, which/WDT in/IN turn/NN improves/VBZ the/DT recognition/NN rate/NN ./.
Besides/RB ,/, in/IN the/DT presence/NN of/IN occluded/VBN face/NN image/NN ,/, the/DT scale/NN of/IN Gabor/NNP -/HYPH feature/NN based/VBN global/JJ dictionary/NN can/MD be/VB compressed/VBN accordingly/RB because/IN redundancies/NNS exist/VBP in/IN Gabor/NNP -/HYPH feature/NN based/VBN occlusion/NN dictionary/NN ./.
For/IN ELM/NN -/HYPH AE/NN part/NN ,/, the/DT dimension/NN of/IN Gabor/NNP -/HYPH feature/NN based/VBN global/JJ dictionary/NN can/MD be/VB compressed/VBN because/IN high/JJ -/HYPH dimensional/JJ face/NN images/NNS can/MD be/VB rapidly/RB represented/VBN by/IN low/JJ -/HYPH dimensional/JJ feature/NN ./.
By/IN introducing/VBG L1/NN //HYPH 2/CD regularization/NN ,/, our/PRP$ approach/NN can/MD produce/VB sparser/JJR and/CC more/JJR robust/JJ representation/NN compared/VBN to/IN regularized/VBN Sparse/JJ Representation/NN based/VBN Classification/NN (/-LRB- SRC/NN )/-RRB- ,/, which/WDT also/RB contributes/VBZ to/IN the/DT decrease/NN of/IN the/DT computational/JJ cost/NN in/IN sparse/JJ representation/NN ./.
In/IN comparison/NN with/IN related/JJ work/NN such/JJ as/IN SRC/NNP and/CC Gabor/NNP -/HYPH feature/NN based/VBN SRC/NNP (/-LRB- GSRC/NNP )/-RRB- ,/, experimental/JJ results/NNS on/IN a/DT variety/NN of/IN face/NN databases/NNS demonstrate/VBP the/DT great/JJ advantage/NN of/IN our/PRP$ method/NN for/IN computational/JJ cost/NN ./.
Moreover/RB ,/, we/PRP also/RB achieve/VBP approximate/JJ or/CC even/RB better/JJR recognition/NN rate/NN ./.
