Convolutional/JJ Neural/JJ Networks/NNS are/VBP extremely/RB efficient/JJ architectures/NNS in/IN image/NN and/CC audio/JJ recognition/NN tasks/NNS ,/, thanks/NNS to/IN their/PRP$ ability/NN to/TO exploit/VB the/DT local/JJ translational/JJ invariance/NN of/IN signal/NN classes/NNS over/IN their/PRP$ domain/NN ./.
In/IN this/DT paper/NN we/PRP consider/VBP possible/JJ generalizations/NNS of/IN CNNs/NNS to/IN signals/NNS defined/VBN on/IN more/JJR general/JJ domains/NNS without/IN the/DT action/NN of/IN a/DT translation/NN group/NN ./.
In/IN particular/JJ ,/, we/PRP propose/VBP two/CD constructions/NNS ,/, one/CD based/VBN upon/IN a/DT hierarchical/JJ clustering/NN of/IN the/DT domain/NN ,/, and/CC another/DT based/VBN on/IN the/DT spectrum/NN of/IN the/DT graph/NN Laplacian/NNP ./.
We/PRP show/VBP through/IN experiments/NNS that/WDT for/IN low/JJ -/HYPH dimensional/JJ graphs/NNS it/PRP is/VBZ possible/JJ to/TO learn/VB convolutional/JJ layers/NNS with/IN $/$ O/UH (/-LRB- 1/CD )/-RRB- $/$ parameters/NNS ,/, resulting/VBG in/IN efficient/JJ deep/JJ architectures/NNS ./.
