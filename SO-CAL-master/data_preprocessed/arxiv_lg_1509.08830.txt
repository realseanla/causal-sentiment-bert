We/PRP formulate/VBP problems/NNS of/IN statistical/JJ recognition/NN and/CC learning/NN in/IN a/DT common/JJ framework/NN of/IN complex/JJ hypothesis/NN testing/NN ./.
Based/VBN on/IN arguments/NNS from/IN multi-criteria/JJ optimization/NN ,/, we/PRP identify/VBP strategies/NNS that/WDT are/VBP improper/JJ for/IN solving/VBG these/DT problems/NNS and/CC derive/VBP a/DT common/JJ form/NN of/IN the/DT remaining/VBG strategies/NNS ./.
We/PRP show/VBP that/IN some/DT widely/RB used/VBN approaches/NNS to/IN recognition/NN and/CC learning/NN are/VBP improper/JJ in/IN this/DT sense/NN ./.
We/PRP then/RB propose/VB a/DT generalized/VBN formulation/NN of/IN the/DT recognition/NN and/CC learning/NN problem/NN which/WDT embraces/VBZ the/DT whole/JJ range/NN of/IN sizes/NNS of/IN the/DT learning/NN sample/NN ,/, including/VBG the/DT zero/CD size/NN ./.
Learning/VBG becomes/VBZ a/DT special/JJ case/NN of/IN recognition/NN without/IN learning/NN ./.
We/PRP define/VBP the/DT concept/NN of/IN closest/JJS to/IN optimal/JJ strategy/NN ,/, being/VBG a/DT solution/NN to/IN the/DT formulated/VBN problem/NN ,/, and/CC describe/VB a/DT technique/NN for/IN finding/VBG such/PDT a/DT strategy/NN ./.
On/IN several/JJ illustrative/JJ cases/NNS ,/, the/DT strategy/NN is/VBZ shown/VBN to/TO be/VB superior/JJ to/IN the/DT widely/RB used/VBN learning/NN methods/NNS based/VBN on/IN maximal/JJ likelihood/NN estimation/NN ./.
