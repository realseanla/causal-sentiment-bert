Sequence/NN -/HYPH to/IN -/HYPH sequence/NN neural/JJ translation/NN models/NNS learn/VBP semantic/JJ and/CC syntactic/JJ relations/NNS between/IN sentence/NN pairs/NNS by/IN optimizing/VBG the/DT likelihood/NN of/IN the/DT target/NN given/VBN the/DT source/NN ,/, i.e./FW ,/, $/$ p/NN (/-LRB- y/NN |/HYPH x/NN )/-RRB- $/$ ,/, an/DT objective/NN that/WDT ignores/VBZ other/JJ potentially/RB useful/JJ sources/NNS of/IN information/NN ./.
We/PRP introduce/VBP an/DT alternative/JJ objective/JJ function/NN for/IN neural/JJ MT/NN that/WDT maximizes/VBZ the/DT mutual/JJ information/NN between/IN the/DT source/NN and/CC target/NN sentences/NNS ,/, modeling/VBG the/DT bi-directional/JJ dependency/NN of/IN sources/NNS and/CC targets/NNS ./.
We/PRP implement/VBP the/DT model/NN with/IN a/DT simple/JJ re-ranking/NN method/NN ,/, and/CC also/RB introduce/VB a/DT decoding/NN algorithm/NN that/WDT increases/VBZ diversity/NN in/IN the/DT N/NN -/HYPH best/JJS list/NN produced/VBN by/IN the/DT first/JJ pass/NN ./.
Applied/NNP to/IN the/DT WMT/JJ German/JJ //HYPH English/JJ and/CC French/JJ //HYPH English/JJ tasks/NNS ,/, both/CC mechanisms/NNS offer/VBP a/DT consistent/JJ performance/NN boost/NN on/IN both/DT standard/JJ LSTM/NNP and/CC attention/NN -/HYPH based/VBN neural/JJ MT/NN architectures/NNS ./.
The/DT result/NN is/VBZ the/DT best/JJS published/VBN performance/NN for/IN a/DT single/JJ (/-LRB- non-ensemble/JJ )/-RRB- neural/JJ MT/NN system/NN ,/, as/RB well/RB as/IN the/DT potential/JJ application/NN of/IN our/PRP$ diverse/JJ decoding/NN algorithm/NN to/IN other/JJ NLP/NNP re-ranking/NN tasks/NNS ./.
