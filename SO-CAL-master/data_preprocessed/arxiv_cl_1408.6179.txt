We/PRP provide/VBP a/DT comparative/JJ study/NN between/IN neural/JJ word/NN representations/NNS and/CC traditional/JJ vector/NN spaces/NNS based/VBN on/IN co-occurrence/NN counts/NNS ,/, in/IN a/DT number/NN of/IN compositional/JJ tasks/NNS ./.
We/PRP use/VBP three/CD different/JJ semantic/JJ spaces/NNS and/CC implement/VB seven/CD tensor/NN -/HYPH based/VBN compositional/JJ models/NNS ,/, which/WDT we/PRP then/RB test/NN (/-LRB- together/RB with/IN simpler/JJR additive/JJ and/CC multiplicative/JJ approaches/NNS )/-RRB- in/IN tasks/NNS involving/VBG verb/VB disambiguation/NN and/CC sentence/NN similarity/NN ./.
To/TO check/VB their/PRP$ scalability/NN ,/, we/PRP additionally/RB evaluate/VB the/DT spaces/NNS using/VBG simple/JJ compositional/JJ methods/NNS on/IN larger/JJR -/HYPH scale/NN tasks/NNS with/IN less/JJR constrained/JJ language/NN :/: paraphrase/NN detection/NN and/CC dialogue/NN act/VBP tagging/NN ./.
In/IN the/DT more/RBR constrained/JJ tasks/NNS ,/, co-occurrence/NN vectors/NNS are/VBP competitive/JJ ,/, although/IN choice/NN of/IN compositional/JJ method/NN is/VBZ important/JJ ;/, on/IN the/DT larger/JJR -/HYPH scale/NN tasks/NNS ,/, they/PRP are/VBP outperformed/VBN by/IN neural/JJ word/NN embeddings/NNS ,/, which/WDT show/VBP robust/JJ ,/, stable/JJ performance/NN across/IN the/DT tasks/NNS ./.
