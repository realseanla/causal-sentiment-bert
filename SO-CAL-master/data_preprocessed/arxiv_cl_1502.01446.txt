Language/NNP model/NN is/VBZ one/CD of/IN the/DT most/RBS important/JJ modules/NNS in/IN statistical/JJ machine/NN translation/NN and/CC currently/RB the/DT word/NN -/HYPH based/VBN language/NN model/NN dominants/NNS this/DT community/NN ./.
However/RB ,/, many/JJ translation/NN models/NNS (/-LRB- e.g./FW phrase/NN -/HYPH based/VBN models/NNS )/-RRB- generate/VBP the/DT target/NN language/NN sentences/NNS by/IN rendering/VBG and/CC compositing/VBG the/DT phrases/NNS rather/RB than/IN the/DT words/NNS ./.
Thus/RB ,/, it/PRP is/VBZ much/RB more/RBR reasonable/JJ to/IN model/NN dependency/NN between/IN phrases/NNS ,/, but/CC few/JJ research/NN work/NN succeed/VB in/IN solving/VBG this/DT problem/NN ./.
In/IN this/DT paper/NN ,/, we/PRP tackle/VBP this/DT problem/NN by/IN designing/VBG a/DT novel/JJ phrase/NN -/HYPH based/VBN language/NN model/NN which/WDT attempts/VBZ to/TO solve/VB three/CD key/JJ sub-problems/NNS :/: 1/CD ,/, how/WRB to/TO define/VB a/DT phrase/NN in/IN language/NN model/NN ;/: 2/CD ,/, how/WRB to/TO determine/VB the/DT phrase/NN boundary/NN in/IN the/DT large/JJ -/HYPH scale/NN monolingual/JJ data/NNS in/IN order/NN to/TO enlarge/VB the/DT training/NN set/NN ;/: 3/CD ,/, how/WRB to/TO alleviate/VB the/DT data/NNS sparsity/NN problem/NN due/IN to/IN the/DT huge/JJ vocabulary/NN size/NN of/IN phrases/NNS ./.
By/IN carefully/RB handling/VBG these/DT issues/NNS ,/, the/DT extensive/JJ experiments/NNS on/IN Chinese/JJ -/HYPH to/IN -/HYPH English/NNP translation/NN show/NN that/IN our/PRP$ phrase/NN -/HYPH based/VBN language/NN model/NN can/MD significantly/RB improve/VB the/DT translation/NN quality/NN by/IN up/RB to/IN 1.47/CD absolute/JJ BLEU/NN score/NN ./.
