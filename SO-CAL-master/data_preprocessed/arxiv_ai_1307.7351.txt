The/DT representation/NN of/IN the/DT knowledge/NN needed/VBN by/IN a/DT robot/NN to/TO perform/VB complex/JJ tasks/NNS is/VBZ restricted/VBN by/IN the/DT limitations/NNS of/IN perception/NN ./.
One/CD possible/JJ way/NN of/IN overcoming/VBG this/DT situation/NN and/CC designing/VBG "/`` knowledgeable/JJ "/'' robots/NNS is/VBZ to/TO rely/VB on/IN the/DT interaction/NN with/IN the/DT user/NN ./.
We/PRP propose/VBP a/DT multi-modal/JJ interaction/NN framework/NN that/WDT allows/VBZ to/TO effectively/RB acquire/VB knowledge/NN about/IN the/DT environment/NN where/WRB the/DT robot/NN operates/VBZ ./.
In/IN particular/JJ ,/, in/IN this/DT paper/NN we/PRP present/VBP a/DT rich/JJ representation/NN framework/NN that/WDT can/MD be/VB automatically/RB built/VBN from/IN the/DT metric/JJ map/NN annotated/VBN with/IN the/DT indications/NNS provided/VBN by/IN the/DT user/NN ./.
Such/PDT a/DT representation/NN ,/, allows/VBZ then/RB the/DT robot/NN to/TO ground/VB complex/JJ referential/JJ expressions/NNS for/IN motion/NN commands/NNS and/CC to/TO devise/VB topological/JJ navigation/NN plans/NNS to/TO achieve/VB the/DT target/NN locations/NNS ./.
