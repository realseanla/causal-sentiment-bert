We/PRP propose/VBP a/DT sequence/NN labeling/NN framework/NN with/IN a/DT secondary/JJ training/NN objective/NN ,/, learning/VBG to/TO predict/VB surrounding/VBG words/NNS for/IN every/DT word/NN in/IN the/DT dataset/NN ./.
This/DT language/NN modeling/NN objective/NN incentivises/VBZ the/DT system/NN to/TO learn/VB general/JJ -/HYPH purpose/NN patterns/NNS of/IN semantic/JJ and/CC syntactic/JJ composition/NN ,/, which/WDT are/VBP also/RB useful/JJ for/IN improving/VBG accuracy/NN on/IN different/JJ sequence/NN labeling/NN tasks/NNS ./.
The/DT architecture/NN was/VBD evaluated/VBN on/IN a/DT range/NN of/IN datasets/NNS ,/, covering/VBG the/DT tasks/NNS of/IN error/NN detection/NN in/IN learner/NN texts/NNS ,/, named/VBN entity/NN recognition/NN ,/, chunking/VBG and/CC POS/NN -/HYPH tagging/NN ./.
The/DT novel/JJ language/NN modeling/NN objective/NN provided/VBN consistent/JJ performance/NN improvements/NNS on/IN every/DT benchmark/NN ,/, without/IN requiring/VBG any/DT additional/JJ annotated/JJ or/CC unannotated/JJ data/NNS ./.
