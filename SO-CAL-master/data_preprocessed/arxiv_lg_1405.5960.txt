We/PRP consider/VBP the/DT problem/NN of/IN learning/VBG soft/JJ assignments/NNS of/IN $/$ N$/CD items/NNS to/IN $/$ K$/CD categories/NNS given/VBN two/CD sources/NNS of/IN information/NN :/: an/DT item/NN -/HYPH category/NN similarity/NN matrix/NN ,/, which/WDT encourages/VBZ items/NNS to/TO be/VB assigned/VBN to/IN categories/NNS they/PRP are/VBP similar/JJ to/IN (/-LRB- and/CC to/TO not/RB be/VB assigned/VBN to/IN categories/NNS they/PRP are/VBP dissimilar/JJ to/TO )/-RRB- ,/, and/CC an/DT item/NN -/HYPH item/NN similarity/NN matrix/NN ,/, which/WDT encourages/VBZ similar/JJ items/NNS to/TO have/VB similar/JJ assignments/NNS ./.
We/PRP propose/VBP a/DT simple/JJ quadratic/JJ programming/NN model/NN that/WDT captures/VBZ this/DT intuition/NN ./.
We/PRP give/VBP necessary/JJ conditions/NNS for/IN its/PRP$ solution/NN to/TO be/VB unique/JJ ,/, define/VB an/DT out/RB -/HYPH of/IN -/HYPH sample/NN mapping/NN ,/, and/CC derive/VBP a/DT simple/JJ ,/, effective/JJ training/NN algorithm/NN based/VBN on/IN the/DT alternating/VBG direction/NN method/NN of/IN multipliers/NNS ./.
The/DT model/NN predicts/VBZ reasonable/JJ assignments/NNS from/IN even/RB a/DT few/JJ similarity/NN values/NNS ,/, and/CC can/MD be/VB seen/VBN as/IN a/DT generalization/NN of/IN semisupervised/VBN learning/NN ./.
It/PRP is/VBZ particularly/RB useful/JJ when/WRB items/NNS naturally/RB belong/VBP to/IN multiple/JJ categories/NNS ,/, as/IN for/IN example/NN when/WRB annotating/VBG documents/NNS with/IN keywords/NNS or/CC pictures/NNS with/IN tags/NNS ,/, with/IN partially/RB tagged/VBN items/NNS ,/, or/CC when/WRB the/DT categories/NNS have/VBP complex/JJ interrelations/NNS (/-LRB- e.g./FW hierarchical/JJ )/-RRB- that/WDT are/VBP unknown/JJ ./.
