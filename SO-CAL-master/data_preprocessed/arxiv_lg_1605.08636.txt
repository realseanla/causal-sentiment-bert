We/PRP exhibit/VBP a/DT strong/JJ link/NN between/IN frequentist/JJ PAC/NN -/HYPH Bayesian/JJ bounds/NNS and/CC the/DT Bayesian/JJ marginal/JJ likelihood/NN ./.
That/DT is/VBZ ,/, for/IN the/DT negative/JJ log/NN -/HYPH likelihood/NN loss/NN function/NN ,/, we/PRP show/VBP that/IN the/DT minimization/NN of/IN PAC/NN -/HYPH Bayesian/JJ generalization/NN bounds/NNS maximizes/VBZ the/DT Bayesian/JJ marginal/JJ likelihood/NN ./.
This/DT provides/VBZ an/DT alternative/JJ explanation/NN to/IN the/DT Bayesian/JJ Occam/NNP 's/POS razor/NN criteria/NNS ,/, under/IN the/DT assumption/NN that/IN the/DT data/NNS is/VBZ generated/VBN by/IN a/DT i.i.d./NN distribution/NN ./.
Moreover/RB ,/, as/IN the/DT negative/JJ log/NN -/HYPH likelihood/NN is/VBZ an/DT unbounded/JJ loss/NN function/NN ,/, we/PRP motivate/VBP and/CC propose/VBP a/DT PAC/NN -/HYPH Bayesian/JJ theorem/NN tailored/VBN for/IN the/DT sub-Gamma/JJ loss/NN family/NN ,/, and/CC we/PRP show/VBP that/IN our/PRP$ approach/NN is/VBZ sound/JJ on/IN classical/JJ Bayesian/JJ linear/JJ regression/NN tasks/NNS ./.
