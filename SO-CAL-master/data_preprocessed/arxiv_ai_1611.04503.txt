We/PRP propose/VBP an/DT approach/NN to/TO build/VB a/DT neural/JJ machine/NN translation/NN system/NN with/IN no/DT supervised/JJ resources/NNS (/-LRB- i.e./FW ,/, no/DT parallel/JJ corpora/NN )/-RRB- using/VBG multimodal/JJ embedded/VBN representation/NN over/IN texts/NNS and/CC images/NNS ./.
Based/VBN on/IN the/DT assumption/NN that/IN text/NN documents/NNS are/VBP often/RB likely/JJ to/TO be/VB described/VBN with/IN other/JJ multimedia/NNS information/NN (/-LRB- e.g./FW ,/, images/NNS )/-RRB- somewhat/RB related/JJ to/IN the/DT content/NN ,/, we/PRP try/VBP to/TO indirectly/RB estimate/VB the/DT relevance/NN between/IN two/CD languages/NNS ./.
Using/VBG multimedia/NNS as/IN the/DT "/`` pivot/NN "/'' ,/, we/PRP project/VBP all/DT modalities/NNS into/IN one/CD common/JJ hidden/VBN space/NN where/WRB samples/NNS belonging/VBG to/IN similar/JJ semantic/JJ concepts/NNS should/MD come/VB close/RB to/IN each/DT other/JJ ,/, whatever/WDT the/DT observed/VBN space/NN of/IN each/DT sample/NN is/VBZ ./.
This/DT modality/NN -/HYPH agnostic/JJ representation/NN is/VBZ the/DT key/NN to/IN bridging/VBG the/DT gap/NN between/IN different/JJ modalities/NNS ./.
Putting/VBG a/DT decoder/NN on/IN top/NN of/IN it/PRP ,/, our/PRP$ network/NN can/MD flexibly/RB draw/VB the/DT outputs/NNS from/IN any/DT input/NN modality/NN ./.
Notably/RB ,/, in/IN the/DT testing/NN phase/NN ,/, we/PRP need/VBP only/RB source/NN language/NN texts/NNS as/IN the/DT input/NN for/IN translation/NN ./.
In/IN experiments/NNS ,/, we/PRP tested/VBD our/PRP$ method/NN on/IN two/CD benchmarks/NNS to/TO show/VB that/IN it/PRP can/MD achieve/VB reasonable/JJ translation/NN performance/NN ./.
We/PRP compared/VBD and/CC investigated/VBD several/JJ possible/JJ implementations/NNS and/CC found/VBD that/IN an/DT end/NN -/HYPH to/IN -/HYPH end/NN model/NN that/WDT simultaneously/RB optimized/VBN both/DT rank/NN loss/NN in/IN multimodal/JJ encoders/NNS and/CC cross-entropy/JJ loss/NN in/IN decoders/NNS performed/VBD the/DT best/JJS ./.
