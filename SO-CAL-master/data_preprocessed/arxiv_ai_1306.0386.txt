Given/VBN a/DT Markov/NNP Decision/NN Process/NN (/-LRB- MDP/NN )/-RRB- with/IN $/$ n/NN $/$ states/NNS and/CC $/$ m/CD $/$ actions/NNS per/IN state/NN ,/, we/PRP study/VBP the/DT number/NN of/IN iterations/NNS needed/VBN by/IN Policy/NNP Iteratio/NNP n/NN (/-LRB- PI/NN )/-RRB- algorithms/NNS to/TO converge/VB ./.
We/PRP consider/VBP two/CD variations/NNS of/IN PI/NN :/: Howard/NNP 's/POS PI/NNP that/WDT changes/VBZ all/PDT the/DT actions/NNS with/IN a/DT positive/JJ advantage/NN ,/, and/CC Sim/NNP plex/NN -/HYPH PI/NN that/WDT only/RB changes/VBZ one/CD action/NN with/IN maximal/JJ advantage/NN ./.
We/PRP show/VBP that/IN Howard/NNP 's/POS PI/NNP terminates/VBZ after/IN at/IN most/RBS $/$ n/NN (/-LRB- m/NN -/HYPH 1/CD )/-RRB- \/SYM lceil/NN \/SYM frac/NN {/-LRB- 1/CD }/-RRB- {/-LRB- 1/CD -/HYPH \/SYM gamma/NN }/-RRB- \/SYM log/NN (/-LRB- \/SYM frac/NN {/-LRB- 1/CD }/-RRB- {/-LRB- 1/CD -/HYPH \/SYM gamma/NN }/-RRB- )/-RRB- \/SYM rceil/NN $/$ iterations/NNS ,/, improving/VBG by/IN a/DT factor/NN $/$ O/UH (/-LRB- \/SYM log/NN n/NN )/-RRB- $/$ a/DT result/NN by/IN Hansen/NNP et/FW al./FW (/-LRB- 2013/CD )/-RRB- ,/, while/IN Simplex/NNP -/HYPH PI/NNP terminates/VBZ after/IN at/IN most/RBS $/$ n/NN (/-LRB- m/NN -/HYPH 1/CD )/-RRB- \/SYM lceil/NN \/SYM frac/NN {/-LRB- n/NN }/-RRB- {/-LRB- 1/CD -/HYPH \/SYM gamma/NN }/-RRB- \/SYM log/NN (/-LRB- \/SYM frac/NN {/-LRB- n/NN }/-RRB- {/-LRB- 1/CD -/HYPH \/SYM gamma/NN }/-RRB- )/-RRB- \/SYM rceil/NN $/$ iterations/NNS ,/, improving/VBG by/IN a/DT factor/NN 2/CD a/DT result/NN by/IN Ye/NNP (/-LRB- 2011/CD )/-RRB- ./.
We/PRP then/RB consider/VBP bounds/NNS that/WDT are/VBP independent/JJ of/IN the/DT discount/NN factor/NN $/$ \/SYM gamma/NN $/$ ./.
When/WRB the/DT MDP/NNP is/VBZ deterministic/JJ ,/, we/PRP show/VBP that/IN Simplex/NNP -/HYPH PI/NNP terminates/VBZ after/IN at/IN most/RBS $/$ 2/CD n/NN ^/SYM 2/CD m/NN (/-LRB- m/NN -/HYPH 1/CD )/-RRB- \/SYM lceil/NN 2/CD (/-LRB- n/NN -/HYPH 1/CD )/-RRB- \/SYM log/NN n/NN \/SYM rceil/NN \/SYM lceil/NN 2/CD n/NN \/SYM log/NN n/NN \/SYM rceil/NN =/SYM O/NN (/-LRB- n/NN ^/SYM 4/CD m/NN ^/SYM 2/CD \/SYM log/NN ^/SYM 2/CD n/NN )/-RRB- $/$ iterations/NNS ,/, improving/VBG by/IN a/DT factor/NN $/$ O/UH (/-LRB- n/NN )/-RRB- $/$ a/DT bound/JJ obtained/VBN by/IN Post/NNP and/CC Ye/NNP (/-LRB- 2012/CD )/-RRB- ./.
We/PRP generalize/VBP this/DT result/NN to/IN general/JJ MDPs/NNS under/IN some/DT structural/JJ assumptions/NNS :/: given/VBN a/DT measure/NN of/IN the/DT maximal/JJ transient/JJ time/NN $/$ \/CD tau_t/CD $/$ and/CC the/DT maximal/JJ time/NN $/$ \/CD tau_r/CD $/$ to/TO revisit/VB states/NNS in/IN recurrent/JJ classes/NNS under/IN all/DT policies/NNS ,/, we/PRP show/VBP that/IN Simplex/NNP -/HYPH PI/NNP terminates/VBZ after/IN at/IN most/RBS $/$ n/NN ^/SYM 2/CD m/NN (/-LRB- m/NN -/HYPH 1/CD )/-RRB- (/-LRB- \/SYM lceil/NN \/SYM tau_r/NN \/SYM log/NN (/-LRB- n/NN \/SYM tau_r/NN )/-RRB- \/SYM rceil/NN \/SYM lceil/NN \/SYM tau_r/NN \/SYM log/NN (/-LRB- n/NN \/SYM tau_t/NN )/-RRB- \/SYM rceil/NN )/-RRB- \/SYM lceil/NN {/-LRB- \/SYM tau_t/JJ }/-RRB- \/SYM log/NN (/-LRB- n/NN (/-LRB- \/SYM tau_t/NN 1/CD )/-RRB- )/-RRB- \/SYM rceil/NN =/SYM \/SYM tilde/NN O/NN (/-LRB- n/NN ^/SYM 2/CD \/SYM tau_t/CD \/SYM tau_r/CD m/NN ^/SYM 2/CD )/-RRB- $/$ iterations/NNS ./.
We/PRP explain/VBP why/WRB similar/JJ results/NNS seem/VBP hard/JJ to/TO derive/VB for/IN Howard/NNP 's/POS PI/NNP ./.
Finally/RB ,/, under/IN the/DT additional/JJ (/-LRB- restrictive/JJ )/-RRB- assumption/NN that/IN the/DT MDP/NNP is/VBZ weakly/RB -/HYPH communicating/VBG ,/, we/PRP show/VBP that/IN Simplex/NNP -/HYPH PI/NNP and/CC Howard/NNP 's/POS PI/NN terminate/VB after/IN at/IN most/RBS $/$ n/NN (/-LRB- m/NN -/HYPH 1/CD )/-RRB- (/-LRB- \/SYM lceil/NN \/SYM tau_t/NN \/SYM log/NN n/NN \/SYM tau_t/NN \/SYM rceil/NN \/SYM lceil/NN \/SYM tau_r/NN \/SYM log/NN n/NN \/SYM tau_r/NN \/SYM rceil/NN )/-RRB- =/SYM \/SYM tilde/NN O/NN (/-LRB- nm/NN (/-LRB- \/SYM tau_t/NN \/SYM tau_r/NN )/-RRB- )/-RRB- $/$ iterations/NNS ./.
