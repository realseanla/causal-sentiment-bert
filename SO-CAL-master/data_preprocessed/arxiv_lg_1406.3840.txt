We/PRP study/VBP a/DT sequential/JJ resource/NN allocation/NN problem/NN involving/VBG a/DT fixed/VBN number/NN of/IN recurring/VBG jobs/NNS ./.
At/IN each/DT time/NN -/HYPH step/NN the/DT manager/NN should/MD distribute/VB available/JJ resources/NNS among/IN the/DT jobs/NNS in/IN order/NN to/TO maximise/VB the/DT expected/VBN number/NN of/IN completed/VBN jobs/NNS ./.
Allocating/VBG more/JJR resources/NNS to/IN a/DT given/VBN job/NN increases/VBZ the/DT probability/NN that/IN it/PRP completes/VBZ ,/, but/CC with/IN a/DT cut/NN -/HYPH off/NN ./.
Specifically/RB ,/, we/PRP assume/VBP a/DT linear/JJ model/NN where/WRB the/DT probability/NN increases/VBZ linearly/RB until/IN it/PRP equals/VBZ one/CD ,/, after/IN which/WDT allocating/VBG additional/JJ resources/NNS is/VBZ wasteful/JJ ./.
We/PRP assume/VBP the/DT difficulty/NN of/IN each/DT job/NN is/VBZ unknown/JJ and/CC present/JJ the/DT first/JJ algorithm/NN for/IN this/DT problem/NN and/CC prove/VB upper/JJ and/CC lower/JJR bounds/NNS on/IN its/PRP$ regret/NN ./.
Despite/IN its/PRP$ apparent/JJ simplicity/NN ,/, the/DT problem/NN has/VBZ a/DT rich/JJ structure/NN :/: we/PRP show/VBP that/IN an/DT appropriate/JJ optimistic/JJ algorithm/NN can/MD improve/VB its/PRP$ learning/NN speed/NN dramatically/RB beyond/IN the/DT results/NNS one/CD normally/RB expects/VBZ for/IN similar/JJ problems/NNS as/IN the/DT problem/NN becomes/VBZ resource/NN -/HYPH laden/NN ./.
