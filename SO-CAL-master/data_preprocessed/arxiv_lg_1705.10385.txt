We/PRP show/VBP that/IN a/DT Modular/JJ Neural/JJ Network/NN (/-LRB- MNN/NN )/-RRB- can/MD combine/VB various/JJ speech/NN enhancement/NN modules/NNS ,/, each/DT of/IN which/WDT is/VBZ a/DT Deep/JJ Neural/JJ Network/NN (/-LRB- DNN/NN )/-RRB- specialized/VBN on/IN a/DT particular/JJ enhancement/NN job/NN ./.
Differently/RB from/IN an/DT ordinary/JJ ensemble/NN technique/NN that/WDT averages/NNS variations/NNS in/IN models/NNS ,/, the/DT propose/VB MNN/NNP selects/VBZ the/DT best/JJS module/NN for/IN the/DT unseen/JJ test/NN signal/NN to/TO produce/VB a/DT greedy/JJ ensemble/NN ./.
We/PRP see/VBP this/DT as/IN Collaborative/JJ Deep/JJ Learning/NN (/-LRB- CDL/NNP )/-RRB- ,/, because/IN it/PRP can/MD reuse/VB various/JJ already/RB -/HYPH trained/VBN DNN/NN models/NNS without/IN any/DT further/JJ refining/NN ./.
In/IN the/DT proposed/VBN MNN/NN selecting/VBG the/DT best/JJS module/NN during/IN run/NN time/NN is/VBZ challenging/JJ ./.
To/IN this/DT end/NN ,/, we/PRP employ/VBP a/DT speech/NN AutoEncoder/NNP (/-LRB- AE/NNP )/-RRB- as/IN an/DT arbitrator/NN ,/, whose/WP$ input/NN and/CC output/NN are/VBP trained/VBN to/TO be/VB as/IN similar/JJ as/IN possible/JJ if/IN its/PRP$ input/NN is/VBZ clean/JJ speech/NN ./.
Therefore/RB ,/, the/DT AE/NNP can/MD gauge/VB the/DT quality/NN of/IN the/DT module/NN -/HYPH specific/JJ denoised/VBN result/NN by/IN seeing/VBG its/PRP$ AE/NN reconstruction/NN error/NN ,/, e.g./FW low/JJ error/NN means/VBZ that/IN the/DT module/NN output/NN is/VBZ similar/JJ to/TO clean/VB speech/NN ./.
We/PRP propose/VBP an/DT MNN/NN structure/NN with/IN various/JJ modules/NNS that/WDT are/VBP specialized/VBN on/IN dealing/VBG with/IN a/DT specific/JJ noise/NN type/NN ,/, gender/NN ,/, and/CC input/NN Signal/NNP -/HYPH to/IN -/HYPH Noise/NN Ratio/NN (/-LRB- SNR/NN )/-RRB- value/NN ,/, and/CC empirically/RB prove/VB that/IN it/PRP almost/RB always/RB works/VBZ better/JJR than/IN an/DT arbitrarily/RB chosen/VBN DNN/NNP module/NN and/CC sometimes/RB as/RB good/JJ as/IN an/DT oracle/NN result/NN ./.
