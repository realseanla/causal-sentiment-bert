It/PRP is/VBZ commonly/RB accepted/VBN that/IN machine/NN translation/NN is/VBZ a/DT more/RBR complex/JJ task/NN than/IN part/NN of/IN speech/NN tagging/NN ./.
But/CC how/WRB much/RB more/RBR complex/JJ ?/.
In/IN this/DT paper/NN we/PRP make/VBP an/DT attempt/NN to/TO develop/VB a/DT general/JJ framework/NN and/CC methodology/NN for/IN computing/VBG the/DT informational/JJ and/CC //HYPH or/CC processing/NN complexity/NN of/IN NLP/NN applications/NNS and/CC tasks/NNS ./.
We/PRP define/VBP a/DT universal/JJ framework/NN akin/JJ to/IN a/DT Turning/VBG Machine/NN that/WDT attempts/VBZ to/TO fit/VB (/-LRB- most/RBS )/-RRB- NLP/NN tasks/NNS into/IN one/CD paradigm/NN ./.
We/PRP calculate/VBP the/DT complexities/NNS of/IN various/JJ NLP/NN tasks/NNS using/VBG measures/NNS of/IN Shannon/NNP Entropy/NNP ,/, and/CC compare/VB `/`` simple/JJ '/'' ones/NNS such/JJ as/IN part/NN of/IN speech/NN tagging/NN to/IN `/`` complex/NN '/'' ones/NNS such/JJ as/IN machine/NN translation/NN ./.
This/DT paper/NN provides/VBZ a/DT first/RB ,/, though/RB far/RB from/IN perfect/JJ ,/, attempt/NN to/TO quantify/VB NLP/NN tasks/NNS under/IN a/DT uniform/JJ paradigm/NN ./.
We/PRP point/VBP out/RP current/JJ deficiencies/NNS and/CC suggest/VBP some/DT avenues/NNS for/IN fruitful/JJ research/NN ./.
