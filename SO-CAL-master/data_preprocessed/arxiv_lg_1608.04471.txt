We/PRP propose/VBP a/DT general/JJ purpose/NN variational/JJ inference/NN algorithm/NN that/WDT forms/VBZ a/DT natural/JJ counterpart/NN of/IN gradient/NN descent/NN for/IN optimization/NN ./.
Our/PRP$ method/NN iteratively/RB transports/VBZ a/DT set/NN of/IN particles/NNS to/TO match/VB the/DT target/NN distribution/NN ,/, by/IN applying/VBG a/DT form/NN of/IN functional/JJ gradient/NN descent/NN that/WDT minimizes/VBZ the/DT KL/NN divergence/NN ./.
Empirical/JJ studies/NNS are/VBP performed/VBN on/IN various/JJ real/JJ world/NN models/NNS and/CC datasets/NNS ,/, on/IN which/WDT our/PRP$ method/NN is/VBZ competitive/JJ with/IN existing/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS ./.
The/DT derivation/NN of/IN our/PRP$ method/NN is/VBZ based/VBN on/IN a/DT new/JJ theoretical/JJ result/NN that/WDT connects/VBZ the/DT derivative/NN of/IN KL/NN divergence/NN under/IN smooth/JJ transforms/VBZ with/IN Stein/NNP 's/POS identity/NN and/CC a/DT recently/RB proposed/VBN kernelized/VBN Stein/NNP discrepancy/NN ,/, which/WDT is/VBZ of/IN independent/JJ interest/NN ./.
