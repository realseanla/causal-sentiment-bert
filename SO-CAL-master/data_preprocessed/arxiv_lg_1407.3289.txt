Dropout/NN training/NN ,/, originally/RB designed/VBN for/IN deep/JJ neural/JJ networks/NNS ,/, has/VBZ been/VBN successful/JJ on/IN high/JJ -/HYPH dimensional/JJ single/JJ -/HYPH layer/NN natural/JJ language/NN tasks/NNS ./.
This/DT paper/NN proposes/VBZ a/DT theoretical/JJ explanation/NN for/IN this/DT phenomenon/NN :/: we/PRP show/VBP that/IN ,/, under/IN a/DT generative/JJ Poisson/NNP topic/NN model/NN with/IN long/JJ documents/NNS ,/, dropout/NN training/NN improves/VBZ the/DT exponent/NN in/IN the/DT generalization/NN bound/VBN for/IN empirical/JJ risk/NN minimization/NN ./.
Dropout/NN achieves/VBZ this/DT gain/VB much/RB like/IN a/DT marathon/NN runner/NN who/WP practices/VBZ at/IN altitude/NN :/: once/IN a/DT classifier/NN learns/VBZ to/TO perform/VB reasonably/RB well/RB on/IN training/NN examples/NNS that/WDT have/VBP been/VBN artificially/RB corrupted/VBN by/IN dropout/NN ,/, it/PRP will/MD do/VB very/RB well/RB on/IN the/DT uncorrupted/JJ test/NN set/NN ./.
We/PRP also/RB show/VBP that/IN ,/, under/IN similar/JJ conditions/NNS ,/, dropout/NN preserves/VBZ the/DT Bayes/NNP decision/NN boundary/NN and/CC should/MD therefore/RB induce/VB minimal/JJ bias/NN in/IN high/JJ dimensions/NNS ./.
