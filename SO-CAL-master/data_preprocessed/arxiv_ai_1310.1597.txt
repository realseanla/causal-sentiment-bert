We/PRP consider/VBP a/DT multilingual/JJ weakly/RB supervised/VBD learning/VBG scenario/NN where/WRB knowledge/NN from/IN annotated/VBN corpora/NNS in/IN a/DT resource/NN -/HYPH rich/JJ language/NN is/VBZ transferred/VBN via/IN bitext/NN to/TO guide/VB the/DT learning/NN in/IN other/JJ languages/NNS ./.
Past/JJ approaches/NNS project/NN labels/NNS across/IN bitext/NN and/CC use/VB them/PRP as/IN features/NNS or/CC gold/NN labels/NNS for/IN training/NN ./.
We/PRP propose/VBP a/DT new/JJ method/NN that/WDT projects/VBZ model/NN expectations/NNS rather/RB than/IN labels/NNS ,/, which/WDT facilities/NNS transfer/NN of/IN model/NN uncertainty/NN across/IN language/NN boundaries/NNS ./.
We/PRP encode/VBP expectations/NNS as/IN constraints/NNS and/CC train/VB a/DT discriminative/JJ CRF/NNP model/NN using/VBG Generalized/VBN Expectation/NN Criteria/NNS (/-LRB- Mann/NNP and/CC McCallum/NNP ,/, 2010/CD )/-RRB- ./.
Evaluated/VBN on/IN standard/JJ Chinese/JJ -/HYPH English/JJ and/CC German/JJ -/HYPH English/JJ NER/NN datasets/NNS ,/, our/PRP$ method/NN demonstrates/VBZ F1/NN scores/NNS of/IN 64/CD percent/NN and/CC 60/CD percent/NN when/WRB no/DT labeled/VBN data/NNS is/VBZ used/VBN ./.
Attaining/VBG the/DT same/JJ accuracy/NN with/IN supervised/JJ CRFs/NN requires/VBZ 12k/NN and/CC 1.5/CD k/CD labeled/VBN sentences/NNS ./.
Furthermore/RB ,/, when/WRB combined/VBN with/IN labeled/VBN examples/NNS ,/, our/PRP$ method/NN yields/NNS significant/JJ improvements/NNS over/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN supervised/VBD methods/NNS ,/, achieving/VBG best/JJS reported/VBN numbers/NNS to/IN date/NN on/IN Chinese/JJ OntoNotes/NNPS and/CC German/JJ CoNLL/NN -/HYPH 03/CD datasets/NNS ./.
