In/IN this/DT paper/NN ,/, we/PRP address/VBP the/DT problem/NN of/IN learning/VBG compact/JJ similarity/NN -/HYPH preserving/VBG embeddings/NNS for/IN massive/JJ high/JJ -/HYPH dimensional/JJ streams/NNS of/IN data/NNS in/IN order/NN to/TO perform/VB efficient/JJ similarity/NN search/NN ./.
We/PRP present/VBP a/DT new/JJ method/NN for/IN computing/VBG binary/JJ compressed/JJ representations/NNS -/HYPH \/SYM textit/FW {/-LRB- sketches/NNS }/-RRB- -/HYPH of/IN high/JJ -/HYPH dimensional/JJ real/JJ feature/NN vectors/NNS ./.
Given/VBN an/DT expected/VBN code/NN length/NN $/$ c/LS $/$ and/CC high/JJ -/HYPH dimensional/JJ input/NN data/NNS points/NNS ,/, our/PRP$ algorithm/NN provides/VBZ a/DT binary/JJ code/NN of/IN $/$ c/LS $/$ bits/NNS aiming/VBG at/IN preserving/VBG the/DT distance/NN between/IN the/DT points/NNS from/IN the/DT original/JJ high/JJ -/HYPH dimensional/JJ space/NN ./.
Our/PRP$ offline/RB version/NN of/IN the/DT algorithm/NN outperforms/VBZ the/DT offline/RB state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS regarding/VBG their/PRP$ computation/NN time/NN complexity/NN and/CC have/VBP a/DT similar/JJ quality/NN of/IN the/DT sketches/NNS ./.
It/PRP also/RB provides/VBZ convergence/NN guarantees/NNS ./.
Moreover/RB ,/, our/PRP$ algorithm/NN can/MD be/VB straightforwardly/RB used/VBN in/IN the/DT streaming/NN context/NN by/IN not/RB requiring/VBG neither/CC the/DT storage/NN of/IN the/DT whole/JJ dataset/NN nor/CC a/DT chunk/NN ./.
We/PRP demonstrate/VBP the/DT quality/NN of/IN our/PRP$ binary/JJ sketches/NNS through/IN extensive/JJ experiments/NNS on/IN real/JJ data/NNS for/IN the/DT nearest/JJS neighbors/NNS search/VB task/NN in/IN the/DT offline/RB and/CC online/RB settings/NNS ./.
