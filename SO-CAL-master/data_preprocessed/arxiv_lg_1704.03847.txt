This/DT paper/NN presents/VBZ a/DT new/JJ 3D/NN point/NN cloud/NN classification/NN benchmark/NN data/NNS set/VBN with/IN over/IN four/CD billion/CD manually/RB labelled/VBN points/NNS ,/, meant/VBN as/IN input/NN for/IN data/NN -/HYPH hungry/JJ (/-LRB- deep/JJ )/-RRB- learning/NN methods/NNS ./.
We/PRP also/RB discuss/VBP first/JJ submissions/NNS to/IN the/DT benchmark/NN that/WDT use/VBP deep/JJ convolutional/JJ neural/JJ networks/NNS (/-LRB- CNNs/NNS )/-RRB- as/IN a/DT work/NN horse/NN ,/, which/WDT already/RB show/VBP remarkable/JJ performance/NN improvements/NNS over/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN ./.
CNNs/NNS have/VBP become/VBN the/DT de-facto/JJ standard/NN for/IN many/JJ tasks/NNS in/IN computer/NN vision/NN and/CC machine/NN learning/NN like/IN semantic/JJ segmentation/NN or/CC object/NN detection/NN in/IN images/NNS ,/, but/CC have/VBP no/DT yet/RB led/VBN to/IN a/DT true/JJ breakthrough/NN for/IN 3D/NN point/NN cloud/NN labelling/NN tasks/NNS due/IN to/IN lack/NN of/IN training/NN data/NNS ./.
With/IN the/DT massive/JJ data/NNS set/VBN presented/VBN in/IN this/DT paper/NN ,/, we/PRP aim/VBP at/IN closing/VBG this/DT data/NN gap/NN to/TO help/VB unleash/VB the/DT full/JJ potential/NN of/IN deep/JJ learning/NN methods/NNS for/IN 3D/NN labelling/NN tasks/NNS ./.
Our/PRP$ semantic3D.net/NN data/NNS set/VBN consists/VBZ of/IN dense/JJ point/NN clouds/NNS acquired/VBN with/IN static/NN terrestrial/JJ laser/NN scanners/NNS ./.
It/PRP contains/VBZ 8/CD semantic/JJ classes/NNS and/CC covers/VBZ a/DT wide/JJ range/NN of/IN urban/JJ outdoor/JJ scenes/NNS :/: churches/NNS ,/, streets/NNS ,/, railroad/NN tracks/NNS ,/, squares/NNS ,/, villages/NNS ,/, soccer/NN fields/NNS and/CC castles/NNS ./.
We/PRP describe/VBP our/PRP$ labelling/NN interface/NN and/CC show/VBP that/IN our/PRP$ data/NNS set/VBN provides/VBZ more/JJR dense/JJ and/CC complete/JJ point/NN clouds/NNS with/IN much/RB higher/JJR overall/JJ number/NN of/IN labelled/VBN points/NNS compared/VBN to/IN those/DT already/RB available/JJ to/IN the/DT research/NN community/NN ./.
We/PRP further/RB provide/VBP baseline/NN method/NN descriptions/NNS and/CC comparison/NN between/IN methods/NNS submitted/VBN to/IN our/PRP$ online/JJ system/NN ./.
We/PRP hope/VBP semantic3D.net/NN will/MD pave/VB the/DT way/NN for/IN deep/JJ learning/NN methods/NNS in/IN 3D/NN point/NN cloud/NN labelling/NN to/TO learn/VB richer/JJR ,/, more/RBR general/JJ 3D/NN representations/NNS ,/, and/CC first/JJ submissions/NNS after/IN only/RB a/DT few/JJ months/NNS indicate/VBP that/IN this/DT might/MD indeed/RB be/VB the/DT case/NN ./.
