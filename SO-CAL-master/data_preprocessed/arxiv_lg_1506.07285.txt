Most/JJS tasks/NNS in/IN natural/JJ language/NN processing/NN can/MD be/VB cast/VBN into/IN question/NN answering/NN (/-LRB- QA/NN )/-RRB- problems/NNS over/IN language/NN input/NN ./.
We/PRP introduce/VBP the/DT dynamic/JJ memory/NN network/NN (/-LRB- DMN/NN )/-RRB- ,/, a/DT unified/JJ neural/JJ network/NN framework/NN which/WDT processes/VBZ input/NN sequences/NNS and/CC questions/NNS ,/, forms/VBZ semantic/JJ and/CC episodic/JJ memories/NNS ,/, and/CC generates/VBZ relevant/JJ answers/NNS ./.
Questions/NNS trigger/VBP an/DT iterative/JJ attention/NN process/NN which/WDT allows/VBZ the/DT model/NN to/IN condition/NN its/PRP$ attention/NN on/IN the/DT result/NN of/IN previous/JJ iterations/NNS ./.
These/DT results/NNS are/VBP then/RB reasoned/VBN over/IN in/IN a/DT hierarchical/JJ recurrent/JJ sequence/NN model/NN to/TO generate/VB answers/NNS ./.
The/DT DMN/NNP can/MD be/VB trained/VBN end/NN -/HYPH to/IN -/HYPH end/NN and/CC obtains/VBZ state/NN of/IN the/DT art/NN results/NNS on/IN several/JJ types/NNS of/IN tasks/NNS and/CC datasets/NNS :/: question/NN answering/NN (/-LRB- Facebook/NNP 's/POS bAbI/NNP dataset/NN )/-RRB- ,/, sequence/NN modeling/NN for/IN part/NN of/IN speech/NN tagging/NN (/-LRB- WSJ/NNP -/HYPH PTB/NNP )/-RRB- ,/, and/CC text/NN classification/NN for/IN sentiment/NN analysis/NN (/-LRB- Stanford/NNP Sentiment/NN Treebank/NNP )/-RRB- ./.
The/DT model/NN relies/VBZ exclusively/RB on/IN trained/JJ word/NN vector/NN representations/NNS and/CC requires/VBZ no/DT string/NN matching/NN or/CC manually/RB engineered/VBN features/NNS ./.
