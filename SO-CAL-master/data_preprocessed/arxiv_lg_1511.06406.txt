Denoising/NNP autoencoders/NNS (/-LRB- DAE/NN )/-RRB- are/VBP trained/VBN to/TO reconstruct/VB their/PRP$ clean/JJ input/NN with/IN noise/NN injected/VBN at/IN the/DT input/NN level/NN ,/, while/IN variational/JJ autoencoders/NNS (/-LRB- VAE/NNP )/-RRB- are/VBP trained/VBN with/IN noise/NN injected/VBN in/IN their/PRP$ stochastic/JJ hidden/JJ layer/NN ,/, with/IN a/DT regularizer/NN that/WDT encourages/VBZ this/DT noise/NN injection/NN ./.
In/IN this/DT paper/NN ,/, we/PRP show/VBP that/IN injecting/VBG noise/NN both/CC in/IN input/NN and/CC in/IN the/DT stochastic/JJ hidden/JJ layer/NN can/MD be/VB advantageous/JJ and/CC we/PRP propose/VBP a/DT modified/VBN variational/JJ lower/JJR bound/VBN as/IN an/DT improved/VBN objective/JJ function/NN in/IN this/DT setup/NN ./.
If/IN noise/NN is/VBZ injected/VBN in/IN input/NN ,/, then/RB the/DT standard/JJ VAE/NNP lower/JJR bound/JJ involves/VBZ marginalizing/VBG the/DT encoder/NN conditional/JJ distribution/NN over/IN the/DT input/NN noise/NN ,/, which/WDT makes/VBZ the/DT training/NN criterion/NN intractable/JJ ./.
Instead/RB ,/, we/PRP propose/VBP a/DT modified/VBN training/NN criterion/NN which/WDT corresponds/VBZ to/IN a/DT tighter/JJR bound/VBN ,/, when/WRB noise/NN is/VBZ injected/VBN in/IN input/NN ./.
Experimentally/RB ,/, we/PRP find/VBP that/IN the/DT proposed/VBN denoising/NN variational/JJ autoencoder/NN (/-LRB- DVAE/NN )/-RRB- yields/VBZ better/JJR average/JJ log/NN -/HYPH likelihood/NN than/IN the/DT VAE/NNP and/CC the/DT importance/NN weighted/JJ auto/NN -/HYPH encoder/NN on/IN the/DT MNIST/NNP and/CC Frey/NNP Face/NNP datasets/NNS ./.
