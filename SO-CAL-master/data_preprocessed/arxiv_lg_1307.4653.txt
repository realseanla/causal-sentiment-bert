We/PRP study/VBP the/DT problem/NN of/IN learning/VBG a/DT tensor/NN from/IN a/DT set/NN of/IN linear/JJ measurements/NNS ./.
A/DT prominent/JJ methodology/NN for/IN this/DT problem/NN is/VBZ based/VBN on/IN a/DT generalization/NN of/IN trace/NN norm/NN regularization/NN ,/, which/WDT has/VBZ been/VBN used/VBN extensively/RB for/IN learning/VBG low/JJ rank/NN matrices/NNS ,/, to/IN the/DT tensor/NN setting/NN ./.
In/IN this/DT paper/NN ,/, we/PRP highlight/VBD some/DT limitations/NNS of/IN this/DT approach/NN and/CC propose/VB an/DT alternative/JJ convex/NN relaxation/NN on/IN the/DT Euclidean/NNP ball/NN ./.
We/PRP then/RB describe/VBP a/DT technique/NN to/TO solve/VB the/DT associated/VBN regularization/NN problem/NN ,/, which/WDT builds/VBZ upon/IN the/DT alternating/VBG direction/NN method/NN of/IN multipliers/NNS ./.
Experiments/NNS on/IN one/CD synthetic/JJ dataset/NN and/CC two/CD real/JJ datasets/NNS indicate/VBP that/IN the/DT proposed/JJ method/NN improves/VBZ significantly/RB over/IN tensor/NN trace/NN norm/NN regularization/NN in/IN terms/NNS of/IN estimation/NN error/NN ,/, while/IN remaining/VBG computationally/RB tractable/JJ ./.
