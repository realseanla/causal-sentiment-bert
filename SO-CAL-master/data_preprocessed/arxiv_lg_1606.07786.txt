There/EX is/VBZ an/DT urgent/JJ need/NN for/IN compact/JJ ,/, fast/RB ,/, and/CC power/NN -/HYPH efficient/JJ hardware/NN implementations/NNS of/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN artificial/JJ intelligence/NN ./.
Here/RB we/PRP propose/VBP a/DT power/NN -/HYPH efficient/JJ approach/NN for/IN real/JJ -/HYPH time/NN inference/NN ,/, in/IN which/WDT deep/JJ neural/JJ networks/NNS (/-LRB- DNNs/NNS )/-RRB- are/VBP implemented/VBN through/IN low/JJ -/HYPH power/NN analog/NN circuits/NNS ./.
Although/IN analog/NN implementations/NNS can/MD be/VB extremely/RB compact/JJ ,/, they/PRP have/VBP been/VBN largely/RB supplanted/VBN by/IN digital/JJ designs/NNS ,/, partly/RB because/IN of/IN device/NN mismatch/NN effects/NNS due/IN to/IN fabrication/NN ./.
We/PRP propose/VBP a/DT framework/NN that/WDT exploits/VBZ the/DT power/NN of/IN Deep/NNP Learning/NNP to/TO compensate/VB for/IN this/DT mismatch/NN by/IN incorporating/VBG the/DT measured/VBN variations/NNS of/IN the/DT devices/NNS as/IN constraints/NNS in/IN the/DT DNN/NN training/NN process/NN ./.
This/DT eliminates/VBZ the/DT use/NN of/IN mismatch/NN minimization/NN strategies/NNS such/JJ as/IN the/DT use/NN of/IN very/RB large/JJ transistors/NNS ,/, and/CC allows/VBZ circuit/NN complexity/NN and/CC power/NN -/HYPH consumption/NN to/TO be/VB reduced/VBN to/IN a/DT minimum/NN ./.
Our/PRP$ results/NNS ,/, based/VBN on/IN large/JJ -/HYPH scale/NN simulations/NNS as/RB well/RB as/IN a/DT prototype/NN VLSI/NNP chip/NN implementation/NN indicate/VBP at/IN least/JJS a/DT 3-fold/RB improvement/NN of/IN processing/VBG efficiency/NN over/IN current/JJ digital/JJ implementations/NNS ./.
