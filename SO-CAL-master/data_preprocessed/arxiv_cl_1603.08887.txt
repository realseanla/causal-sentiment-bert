We/PRP present/VBP a/DT discriminative/JJ model/NN for/IN single/JJ -/HYPH document/NN summarization/NN that/WDT integrally/RB combines/VBZ compression/NN and/CC anaphoricity/NN constraints/NNS ./.
Our/PRP$ model/NN selects/VBZ textual/JJ units/NNS to/TO include/VB in/IN the/DT summary/NN based/VBN on/IN a/DT rich/JJ set/NN of/IN sparse/JJ features/NNS whose/WP$ weights/NNS are/VBP learned/VBN on/IN a/DT large/JJ corpus/NN ./.
We/PRP allow/VBP for/IN the/DT deletion/NN of/IN content/NN within/IN a/DT sentence/NN when/WRB that/DT deletion/NN is/VBZ licensed/VBN by/IN compression/NN rules/NNS ;/: in/IN our/PRP$ framework/NN ,/, these/DT are/VBP implemented/VBN as/IN dependencies/NNS between/IN subsentential/JJ units/NNS of/IN text/NN ./.
Anaphoricity/NN constraints/NNS then/RB improve/VB cross-sentence/NN coherence/NN by/IN guaranteeing/VBG that/DT ,/, for/IN each/DT pronoun/NN included/VBD in/IN the/DT summary/NN ,/, the/DT pronoun/NN 's/POS antecedent/NN is/VBZ included/VBN as/RB well/RB or/CC the/DT pronoun/NN is/VBZ rewritten/VBN as/IN a/DT full/JJ mention/NN ./.
When/WRB trained/VBN end/NN -/HYPH to/IN -/HYPH end/NN ,/, our/PRP$ final/JJ system/NN outperforms/VBZ prior/JJ work/NN on/IN both/DT ROUGE/NN as/RB well/RB as/IN on/IN human/JJ judgments/NNS of/IN linguistic/JJ quality/NN ./.
