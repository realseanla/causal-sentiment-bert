Crowdsourcing/VBG platforms/NNS enable/VBP to/TO propose/VB simple/JJ human/JJ intelligence/NN tasks/NNS to/IN a/DT large/JJ number/NN of/IN participants/NNS who/WP realise/VBP these/DT tasks/NNS ./.
The/DT workers/NNS often/RB receive/VBP a/DT small/JJ amount/NN of/IN money/NN or/CC the/DT platforms/NNS include/VBP some/DT other/JJ incentive/NN mechanisms/NNS ,/, for/IN example/NN they/PRP can/MD increase/VB the/DT workers/NNS reputation/NN score/NN ,/, if/IN they/PRP complete/VBP the/DT tasks/NNS correctly/RB ./.
We/PRP address/VBP the/DT problem/NN of/IN identifying/VBG experts/NNS among/IN participants/NNS ,/, that/DT is/VBZ ,/, workers/NNS ,/, who/WP tend/VBP to/TO answer/VB the/DT questions/NNS correctly/RB ./.
Knowing/VBG who/WP are/VBP the/DT reliable/JJ workers/NNS could/MD improve/VB the/DT quality/NN of/IN knowledge/NN one/NN can/MD extract/VB from/IN responses/NNS ./.
As/IN opposed/VBN to/IN other/JJ works/NNS in/IN the/DT literature/NN ,/, we/PRP assume/VBP that/IN participants/NNS can/MD give/VB partial/JJ or/CC incomplete/JJ responses/NNS ,/, in/IN case/NN they/PRP are/VBP not/RB sure/JJ that/IN their/PRP$ answers/NNS are/VBP correct/JJ ./.
We/PRP model/VBP such/JJ partial/JJ or/CC incomplete/JJ responses/NNS with/IN the/DT help/NN of/IN belief/NN functions/NNS ,/, and/CC we/PRP derive/VBP a/DT measure/NN that/WDT characterizes/VBZ the/DT expertise/NN level/NN of/IN each/DT participant/NN ./.
This/DT measure/NN is/VBZ based/VBN on/IN precise/JJ and/CC exactitude/NN degrees/NNS that/WDT represent/VBP two/CD parts/NNS of/IN the/DT expertise/NN level/NN ./.
The/DT precision/NN degree/NN reflects/VBZ the/DT reliability/NN level/NN of/IN the/DT participants/NNS and/CC the/DT exactitude/NN degree/NN reflects/VBZ the/DT knowledge/NN level/NN of/IN the/DT participants/NNS ./.
We/PRP also/RB analyze/VBP our/PRP$ model/NN through/IN simulation/NN and/CC demonstrate/VBP that/IN our/PRP$ richer/JJR model/NN can/MD lead/VB to/IN more/JJR reliable/JJ identification/NN of/IN experts/NNS ./.
