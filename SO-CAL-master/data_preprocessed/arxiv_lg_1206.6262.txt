We/PRP pursue/VBP a/DT life/NN -/HYPH long/JJ learning/NN approach/NN to/IN artificial/JJ intelligence/NN that/WDT makes/VBZ extensive/JJ use/NN of/IN reinforcement/NN learning/VBG algorithms/NNS ./.
We/PRP build/VBP on/IN our/PRP$ prior/JJ work/NN with/IN general/JJ value/NN functions/NNS (/-LRB- GVFs/NNS )/-RRB- and/CC the/DT Horde/NNP architecture/NN ./.
GVFs/NNS have/VBP been/VBN shown/VBN able/JJ to/TO represent/VB a/DT wide/JJ variety/NN of/IN facts/NNS about/IN the/DT world/NN 's/POS dynamics/NNS that/WDT may/MD be/VB useful/JJ to/IN a/DT long/JJ -/HYPH lived/JJ agent/NN (/-LRB- Sutton/NNP et/FW al./FW 2011/CD )/-RRB- ./.
We/PRP have/VBP also/RB previously/RB shown/VBN scaling/NN -/: that/IN thousands/NNS of/IN on/IN -/HYPH policy/NN GVFs/NNS can/MD be/VB learned/VBN accurately/RB in/IN real/JJ -/HYPH time/NN on/IN a/DT mobile/JJ robot/NN (/-LRB- Modayil/NNP ,/, White/NNP &amp;/CC Sutton/NNP 2011/CD )/-RRB- ./.
That/DT work/NN was/VBD limited/VBN in/IN that/IN it/PRP learned/VBD about/IN only/RB one/CD policy/NN at/IN a/DT time/NN ,/, whereas/IN the/DT greatest/JJS potential/JJ benefits/NNS of/IN life/NN -/HYPH long/JJ learning/NN come/VBN from/IN learning/VBG about/RB many/JJ policies/NNS in/IN parallel/NN ,/, as/IN we/PRP explore/VBP in/IN this/DT paper/NN ./.
Many/JJ new/JJ challenges/NNS arise/VBP in/IN this/DT off/IN -/HYPH policy/NN learning/NN setting/NN ./.
To/TO deal/VB with/IN convergence/NN and/CC efficiency/NN challenges/NNS ,/, we/PRP utilize/VBP the/DT recently/RB introduced/VBN GTD/NN (/-LRB- {/-LRB- \/SYM lambda/NN }/-RRB- )/-RRB- algorithm/NN ./.
We/PRP show/VBP that/IN GTD/NN (/-LRB- {/-LRB- \/SYM lambda/NN }/-RRB- )/-RRB- with/IN tile/NN coding/NN can/MD simultaneously/RB learn/VB hundreds/NNS of/IN predictions/NNS for/IN five/CD simple/JJ target/NN policies/NNS while/IN following/VBG a/DT single/JJ random/JJ behavior/NN policy/NN ,/, assessing/VBG accuracy/NN with/IN interspersed/VBN on/IN -/HYPH policy/NN tests/NNS ./.
To/TO escape/VB the/DT need/NN for/IN the/DT tests/NNS ,/, which/WDT preclude/VBP further/JJ scaling/NN ,/, we/PRP introduce/VBP and/CC empirically/RB vali/NN -/HYPH date/NN two/CD online/JJ estimators/NNS of/IN the/DT off/NN -/HYPH policy/NN objective/NN (/-LRB- MSPBE/NN )/-RRB- ./.
Finally/RB ,/, we/PRP use/VBP the/DT more/RBR efficient/JJ of/IN the/DT two/CD estimators/NNS to/TO demonstrate/VB off/IN -/HYPH policy/NN learning/NN at/IN scale/NN -/HYPH the/DT learning/NN of/IN value/NN functions/VBZ for/IN one/CD thousand/CD policies/NNS in/IN real/JJ time/NN on/IN a/DT physical/JJ robot/NN ./.
This/DT ability/NN constitutes/VBZ a/DT significant/JJ step/NN towards/IN scaling/JJ life/NN -/HYPH long/JJ off/IN -/HYPH policy/NN learning/NN ./.
