In/IN this/DT paper/NN ,/, we/PRP introduce/VBP a/DT new/JJ set/NN of/IN reinforcement/NN learning/NN (/-LRB- RL/NN )/-RRB- tasks/NNS in/IN Minecraft/NNP (/-LRB- a/DT flexible/JJ 3D/JJ world/NN )/-RRB- ./.
We/PRP then/RB use/VBP these/DT tasks/NNS to/TO systematically/RB compare/VB and/CC contrast/NN existing/VBG deep/JJ reinforcement/NN learning/NN (/-LRB- DRL/NN )/-RRB- architectures/NNS with/IN our/PRP$ new/JJ memory/NN -/HYPH based/VBN DRL/NNP architectures/NNS ./.
These/DT tasks/NNS are/VBP designed/VBN to/TO emphasize/VB ,/, in/IN a/DT controllable/JJ manner/NN ,/, issues/NNS that/WDT pose/VBP challenges/NNS for/IN RL/NN methods/NNS including/VBG partial/JJ observability/NN (/-LRB- due/IN to/IN first/JJ -/HYPH person/NN visual/JJ observations/NNS )/-RRB- ,/, delayed/VBN rewards/NNS ,/, high/JJ -/HYPH dimensional/JJ visual/JJ observations/NNS ,/, and/CC the/DT need/NN to/TO use/VB active/JJ perception/NN in/IN a/DT correct/JJ manner/NN so/RB as/IN to/TO perform/VB well/RB in/IN the/DT tasks/NNS ./.
While/IN these/DT tasks/NNS are/VBP conceptually/RB simple/JJ to/TO describe/VB ,/, by/IN virtue/NN of/IN having/VBG all/DT of/IN these/DT challenges/NNS simultaneously/RB they/PRP are/VBP difficult/JJ for/IN current/JJ DRL/NNP architectures/NNS ./.
Additionally/RB ,/, we/PRP evaluate/VBP the/DT generalization/NN performance/NN of/IN the/DT architectures/NNS on/IN environments/NNS not/RB used/VBN during/IN training/NN ./.
The/DT experimental/JJ results/NNS show/VBP that/IN our/PRP$ new/JJ architectures/NNS generalize/VB to/IN unseen/JJ environments/NNS better/JJR than/IN existing/VBG DRL/NNP architectures/NNS ./.
