Learning/VBG distributed/VBN representations/NNS for/IN relation/NN instances/NNS is/VBZ a/DT central/JJ technique/NN in/IN downstream/JJ NLP/NN applications/NNS ./.
In/IN order/NN to/TO address/VB semantic/JJ modeling/NN of/IN relational/JJ patterns/NNS ,/, this/DT paper/NN constructs/NNS a/DT new/JJ dataset/NN that/WDT provides/VBZ multiple/JJ similarity/NN ratings/NNS for/IN every/DT pair/NN of/IN relational/JJ patterns/NNS on/IN the/DT existing/VBG dataset/NN ./.
In/IN addition/NN ,/, we/PRP conduct/VBP a/DT comparative/JJ study/NN of/IN different/JJ encoders/NNS including/VBG additive/JJ composition/NN ,/, RNN/NN ,/, LSTM/NNP ,/, and/CC GRU/NNP for/IN composing/VBG distributed/VBN representations/NNS of/IN relational/JJ patterns/NNS ./.
We/PRP also/RB present/JJ Gated/VBN Additive/JJ Composition/NN ,/, which/WDT is/VBZ an/DT enhancement/NN of/IN additive/JJ composition/NN with/IN the/DT gating/NN mechanism/NN ./.
Experiments/NNS show/VBP that/IN the/DT new/JJ dataset/NN does/VBZ not/RB only/RB enable/VB detailed/JJ analyses/NNS of/IN the/DT different/JJ encoders/NNS ,/, but/CC also/RB provides/VBZ a/DT gauge/NN to/TO predict/VB successes/NNS of/IN distributed/VBN representations/NNS of/IN relational/JJ patterns/NNS in/IN the/DT relation/NN classification/NN task/NN ./.
