This/DT paper/NN presents/VBZ a/DT model/NN for/IN end/NN -/HYPH to/IN -/HYPH end/NN learning/NN of/IN task/NN -/HYPH oriented/VBN dialog/NN systems/NNS ./.
The/DT main/JJ component/NN of/IN the/DT model/NN is/VBZ a/DT recurrent/JJ neural/JJ network/NN (/-LRB- an/DT LSTM/NN )/-RRB- ,/, which/WDT maps/VBZ from/IN raw/JJ dialog/NN history/NN directly/RB to/IN a/DT distribution/NN over/IN system/NN actions/NNS ./.
The/DT LSTM/NNP automatically/RB infers/VBZ a/DT representation/NN of/IN dialog/NN history/NN ,/, which/WDT relieves/VBZ the/DT system/NN developer/NN of/IN much/JJ of/IN the/DT manual/JJ feature/NN engineering/NN of/IN dialog/NN state/NN ./.
In/IN addition/NN ,/, the/DT developer/NN can/MD provide/VB software/NN that/WDT expresses/VBZ business/NN rules/NNS and/CC provides/VBZ access/NN to/IN programmatic/JJ APIs/NNS ,/, enabling/VBG the/DT LSTM/NNP to/TO take/VB actions/NNS in/IN the/DT real/JJ world/NN on/IN behalf/NN of/IN the/DT user/NN ./.
The/DT LSTM/NNP can/MD be/VB optimized/VBN using/VBG supervised/JJ learning/NN (/-LRB- SL/NNP )/-RRB- ,/, where/WRB a/DT domain/NN expert/NN provides/VBZ example/NN dialogs/NNS which/WDT the/DT LSTM/NNP should/MD imitate/VB ;/: or/CC using/VBG reinforcement/NN learning/NN (/-LRB- RL/NN )/-RRB- ,/, where/WRB the/DT system/NN improves/VBZ by/IN interacting/VBG directly/RB with/IN end/NN users/NNS ./.
Experiments/NNS show/VBP that/IN SL/NNP and/CC RL/NNP are/VBP complementary/JJ :/: SL/NNP alone/RB can/MD derive/VB a/DT reasonable/JJ initial/JJ policy/NN from/IN a/DT small/JJ number/NN of/IN training/NN dialogs/NNS ;/: and/CC starting/VBG RL/NN optimization/NN with/IN a/DT policy/NN trained/VBN with/IN SL/NNP substantially/RB accelerates/VBZ the/DT learning/NN rate/NN of/IN RL/NNP ./.
