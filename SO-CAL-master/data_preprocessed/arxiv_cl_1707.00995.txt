In/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN Neural/JJ Machine/NN Translation/NN (/-LRB- NMT/NN )/-RRB- ,/, an/DT attention/NN mechanism/NN is/VBZ used/VBN during/IN decoding/NN to/TO enhance/VB the/DT translation/NN ./.
At/IN every/DT step/NN ,/, the/DT decoder/NN uses/VBZ this/DT mechanism/NN to/TO focus/VB on/IN different/JJ parts/NNS of/IN the/DT source/NN sentence/NN to/TO gather/VB the/DT most/RBS useful/JJ information/NN before/IN outputting/VBG its/PRP$ target/NN word/NN ./.
Recently/RB ,/, the/DT effectiveness/NN of/IN the/DT attention/NN mechanism/NN has/VBZ also/RB been/VBN explored/VBN for/IN multimodal/JJ tasks/NNS ,/, where/WRB it/PRP becomes/VBZ possible/JJ to/TO focus/VB both/DT on/IN sentence/NN parts/NNS and/CC image/NN regions/NNS that/WDT they/PRP describe/VBP ./.
In/IN this/DT paper/NN ,/, we/PRP compare/VBP several/JJ attention/NN mechanism/NN on/IN the/DT multimodal/JJ translation/NN task/NN (/-LRB- English/NNP ,/, image/NN to/IN German/JJ )/-RRB- and/CC evaluate/VB the/DT ability/NN of/IN the/DT model/NN to/TO make/VB use/NN of/IN images/NNS to/TO improve/VB translation/NN ./.
We/PRP surpass/VBP state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN scores/NNS on/IN the/DT Multi30k/NN data/NNS set/VBN ,/, we/PRP nevertheless/RB identify/VBP and/CC report/VBP different/JJ misbehavior/NN of/IN the/DT machine/NN while/IN translating/VBG ./.
