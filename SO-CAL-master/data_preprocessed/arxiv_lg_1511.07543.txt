Recent/JJ success/NN in/IN training/NN deep/JJ neural/JJ networks/NNS have/VBP prompted/VBN active/JJ investigation/NN into/IN the/DT features/NNS learned/VBN on/IN their/PRP$ intermediate/JJ layers/NNS ./.
Such/JJ research/NN is/VBZ difficult/JJ because/IN it/PRP requires/VBZ making/VBG sense/NN of/IN non-linear/JJ computations/NNS performed/VBN by/IN millions/NNS of/IN learned/VBN parameters/NNS ,/, but/CC valuable/JJ because/IN it/PRP increases/VBZ our/PRP$ ability/NN to/TO understand/VB current/JJ models/NNS and/CC training/NN algorithms/NNS and/CC thus/RB create/VB improved/VBN versions/NNS of/IN them/PRP ./.
In/IN this/DT paper/NN we/PRP investigate/VBP the/DT extent/NN to/TO which/WDT neural/JJ networks/NNS exhibit/VBP what/WP we/PRP call/VBP convergent/JJ learning/NN ,/, which/WDT is/VBZ when/WRB the/DT representations/NNS learned/VBN by/IN multiple/JJ nets/NNS converge/VBP to/IN a/DT set/NN of/IN features/NNS which/WDT are/VBP either/RB individually/RB similar/JJ between/IN networks/NNS or/CC where/WRB subsets/NNS of/IN features/NNS span/VBP similar/JJ low/JJ -/HYPH dimensional/JJ spaces/NNS ./.
We/PRP propose/VBP a/DT specific/JJ method/NN of/IN probing/VBG representations/NNS :/: training/NN multiple/JJ networks/NNS and/CC then/RB comparing/VBG and/CC contrasting/VBG their/PRP$ individual/NN ,/, learned/VBD representations/NNS at/IN the/DT level/NN of/IN neurons/NNS or/CC groups/NNS of/IN neurons/NNS ./.
We/PRP begin/VBP research/NN into/IN this/DT question/NN using/VBG three/CD techniques/NNS to/IN approximately/RB align/VB different/JJ neural/JJ networks/NNS on/IN a/DT feature/NN level/NN :/: a/DT bipartite/JJ matching/NN approach/NN that/WDT makes/VBZ one/CD -/HYPH to/IN -/HYPH one/CD assignments/NNS between/IN neurons/NNS ,/, a/DT sparse/JJ prediction/NN approach/NN that/WDT finds/VBZ one/CD -/HYPH to/IN -/HYPH many/JJ mappings/NNS ,/, and/CC a/DT spectral/JJ clustering/NN approach/NN that/WDT finds/VBZ many/JJ -/HYPH to/IN -/HYPH many/JJ mappings/NNS ./.
This/DT initial/JJ investigation/NN reveals/VBZ a/DT few/JJ previously/RB unknown/JJ properties/NNS of/IN neural/JJ networks/NNS ,/, and/CC we/PRP argue/VBP that/IN future/JJ research/NN into/IN the/DT question/NN of/IN convergent/JJ learning/NN will/MD yield/VB many/JJ more/JJR ./.
The/DT insights/NNS described/VBN here/RB include/VBP (/-LRB- 1/CD )/-RRB- that/IN some/DT features/NNS are/VBP learned/VBN reliably/RB in/IN multiple/JJ networks/NNS ,/, yet/CC other/JJ features/NNS are/VBP not/RB consistently/RB learned/VBN ;/: (/-LRB- 2/LS )/-RRB- that/WDT units/NNS learn/VBP to/TO span/VB low/JJ -/HYPH dimensional/JJ subspaces/NNS and/CC ,/, while/IN these/DT subspaces/NNS are/VBP common/JJ to/IN multiple/JJ networks/NNS ,/, the/DT specific/JJ basis/NN vectors/NNS learned/VBN are/VBP not/RB ;/: (/-LRB- 3/LS )/-RRB- that/IN the/DT representation/NN codes/NNS are/VBP a/DT mix/NN between/IN a/DT local/JJ code/NN and/CC slightly/RB ,/, but/CC not/RB fully/RB ,/, distributed/VBN codes/NNS across/IN multiple/JJ units/NNS ./.
