Stochastic/JJ Gradient/NN Descent/NN (/-LRB- SGD/NNP )/-RRB- is/VBZ a/DT workhorse/NN in/IN machine/NN learning/NN ,/, yet/CC it/PRP is/VBZ also/RB known/VBN to/TO be/VB slow/JJ relative/JJ to/IN steepest/JJS descent/NN ./.
The/DT variance/NN in/IN the/DT stochastic/JJ update/NN directions/NNS only/RB allows/VBZ for/IN sublinear/NN or/CC (/-LRB- with/IN iterate/JJ averaging/NN )/-RRB- linear/JJ convergence/NN rates/NNS ./.
Recently/RB ,/, variance/NN reduction/NN techniques/NNS such/JJ as/IN SVRG/NNP and/CC SAGA/NNP have/VBP been/VBN proposed/VBN to/TO overcome/VB this/DT weakness/NN ./.
With/IN asymptotically/RB vanishing/VBG variance/NN ,/, a/DT constant/JJ step/NN size/NN can/MD be/VB maintained/VBN ,/, resulting/VBG in/IN geometric/JJ convergence/NN rates/NNS ./.
However/RB ,/, these/DT methods/NNS are/VBP either/RB based/VBN on/IN occasional/JJ computations/NNS of/IN full/JJ gradients/NNS at/IN pivot/NN points/NNS (/-LRB- SVRG/NN )/-RRB- ,/, or/CC on/IN keeping/VBG per/IN data/NN point/NN corrections/NNS in/IN memory/NN (/-LRB- SAGA/NN )/-RRB- ./.
This/DT has/VBZ the/DT disadvantage/NN that/WDT one/PRP can/MD not/RB employ/VB these/DT methods/NNS in/IN a/DT streaming/NN setting/NN and/CC that/IN speed/NN -/HYPH ups/NNS relative/JJ to/IN SGD/NNP may/MD need/VB a/DT certain/JJ number/NN of/IN epochs/NNS in/IN order/NN to/TO materialize/VB ./.
This/DT paper/NN investigates/VBZ a/DT new/JJ class/NN of/IN algorithms/NNS that/WDT can/MD exploit/VB neighborhood/NN structure/NN in/IN the/DT training/NN data/NNS to/TO share/VB and/CC re-use/VB information/NN about/IN past/JJ stochastic/JJ gradients/NNS across/IN data/NNS points/NNS ./.
While/IN not/RB meant/VBN to/TO be/VB offering/VBG advantages/NNS in/IN an/DT asymptotic/JJ setting/NN ,/, there/EX are/VBP significant/JJ benefits/NNS in/IN the/DT transient/JJ optimization/NN phase/NN ,/, in/IN particular/JJ in/IN a/DT streaming/NN or/CC single/JJ -/HYPH epoch/NN setting/NN ./.
We/PRP investigate/VBP this/DT family/NN of/IN algorithms/NNS in/IN a/DT thorough/JJ analysis/NN and/CC show/VBP supporting/VBG experimental/JJ results/NNS ./.
As/IN a/DT side/NN -/HYPH product/NN we/PRP provide/VBP a/DT simple/JJ and/CC unified/JJ proof/NN technique/NN for/IN a/DT broad/JJ class/NN of/IN variance/NN reduction/NN algorithms/NNS ./.
