In/IN this/DT paper/NN ,/, a/DT novel/JJ architecture/NN for/IN a/DT deep/JJ recurrent/JJ neural/JJ network/NN ,/, residual/JJ LSTM/NN is/VBZ introduced/VBN ./.
A/DT plain/JJ LSTM/NN has/VBZ an/DT internal/JJ memory/NN cell/NN that/WDT can/MD learn/VB long/JJ term/NN dependencies/NNS of/IN sequential/JJ data/NNS ./.
It/PRP also/RB provides/VBZ a/DT temporal/JJ shortcut/NN path/NN to/TO avoid/VB vanishing/VBG or/CC exploding/VBG gradients/NNS in/IN the/DT temporal/JJ domain/NN ./.
The/DT proposed/VBN residual/JJ LSTM/NN architecture/NN provides/VBZ an/DT additional/JJ spatial/JJ shortcut/NN path/NN from/IN lower/JJR layers/NNS for/IN efficient/JJ training/NN of/IN deep/JJ networks/NNS with/IN multiple/JJ LSTM/NN layers/NNS ./.
Compared/VBN with/IN the/DT previous/JJ work/NN ,/, highway/NN LSTM/NNP ,/, residual/JJ LSTM/NN reuses/VBZ the/DT output/NN projection/NN matrix/NN and/CC the/DT output/NN gate/NN of/IN LSTM/NNP to/TO control/VB the/DT spatial/JJ information/NN flow/NN instead/RB of/IN additional/JJ gate/NN networks/NNS ,/, which/WDT effectively/RB reduces/VBZ more/JJR than/IN 10/CD percent/NN of/IN network/NN parameters/NNS ./.
An/DT experiment/NN for/IN distant/JJ speech/NN recognition/NN on/IN the/DT AMI/NNP SDM/NNP corpus/NN indicates/VBZ that/IN the/DT performance/NN of/IN plain/JJ and/CC highway/NN LSTM/NN networks/NNS degrades/VBZ with/IN increasing/VBG network/NN depth/NN ./.
For/IN example/NN ,/, 10/CD -/HYPH layer/NN plain/NN and/CC highway/NN LSTM/NNP networks/NNS showed/VBD 13.7/CD percent/NN and/CC 6.2/CD percent/NN increase/NN in/IN WER/NNP over/IN 3/CD -/HYPH layer/NN baselines/NNS ,/, respectively/RB ./.
On/IN the/DT contrary/NN ,/, 10/CD -/HYPH layer/NN residual/JJ LSTM/NN networks/NNS provided/VBD the/DT lowest/JJS WER/NN 41.0/CD percent/NN ,/, which/WDT corresponds/VBZ to/IN 3.3/CD percent/NN and/CC 2.8/CD percent/NN WER/NN reduction/NN over/IN 3/CD -/HYPH layer/NN plain/NN and/CC highway/NN LSTM/NN networks/NNS ,/, respectively/RB ./.
Training/VBG with/IN both/CC the/DT IHM/NNP and/CC SDM/NNP corpora/NNS ,/, the/DT residual/JJ LSTM/NN architecture/NN provided/VBN larger/JJR gain/NN from/IN increasing/VBG depth/NN :/: a/DT 10/CD -/HYPH layer/NN residual/JJ LSTM/NN showed/VBD 3.0/CD percent/NN WER/NN reduction/NN over/IN the/DT corresponding/VBG 5/CD -/HYPH layer/NN one/CD ./.
