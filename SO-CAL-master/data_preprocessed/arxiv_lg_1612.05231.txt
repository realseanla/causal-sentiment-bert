We/PRP present/VBP a/DT method/NN for/IN implementing/VBG an/DT Efficient/JJ Unitary/NNP Neural/JJ Network/NN (/-LRB- EUNN/NN )/-RRB- whose/WP$ computational/JJ complexity/NN is/VBZ merely/RB $/$ \/CD mathcal/NN {/-LRB- O/NN }/-RRB- (/-LRB- 1/CD )/-RRB- $/$ per/IN parameter/NN and/CC has/VBZ full/JJ tunability/NN ,/, from/IN spanning/VBG part/NN of/IN unitary/JJ space/NN to/IN all/DT of/IN it/PRP ./.
We/PRP apply/VBP the/DT EUNN/NNP in/IN Recurrent/JJ Neural/JJ Networks/NNS ,/, and/CC test/VB its/PRP$ performance/NN on/IN the/DT standard/JJ copying/NN task/NN and/CC the/DT MNIST/NNP digit/NN recognition/NN benchmark/NN ,/, finding/VBG that/IN it/PRP significantly/RB outperforms/VBZ a/DT non-unitary/JJ RNN/NN ,/, an/DT LSTM/NNP network/NN ,/, an/DT exclusively/RB partial/JJ space/NN URNN/NNP and/CC a/DT projective/JJ URNN/NN with/IN comparable/JJ parameter/NN numbers/NNS ./.
