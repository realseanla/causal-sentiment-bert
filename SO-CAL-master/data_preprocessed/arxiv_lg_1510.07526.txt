In/IN this/DT paper/NN we/PRP explore/VBP deep/JJ learning/NN models/NNS with/IN memory/NN component/NN or/CC attention/NN mechanism/NN for/IN question/NN answering/VBG task/NN ./.
We/PRP combine/VBP and/CC compare/VBP three/CD models/NNS ,/, Neural/JJ Machine/NN Translation/NN ,/, Neural/JJ Turing/NN Machine/NN ,/, and/CC Memory/NN Networks/NNS for/IN a/DT simulated/JJ QA/NN data/NNS set/VBN ./.
This/DT paper/NN is/VBZ the/DT first/JJ one/NN that/WDT uses/VBZ Neural/JJ Machine/NN Translation/NN and/CC Neural/JJ Turing/NN Machines/NNS for/IN solving/VBG QA/NN tasks/NNS ./.
Our/PRP$ results/NNS suggest/VBP that/IN the/DT combination/NN of/IN attention/NN and/CC memory/NN have/VBP potential/JJ to/TO solve/VB certain/JJ QA/NN problem/NN ./.
