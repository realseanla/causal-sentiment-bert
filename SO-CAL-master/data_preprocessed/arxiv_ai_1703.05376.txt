Two/CD -/HYPH timescale/NN Stochastic/JJ Approximation/NN (/-LRB- SA/NNP )/-RRB- algorithms/NNS are/VBP widely/RB used/VBN in/IN Reinforcement/NN Learning/NN (/-LRB- RL/NN )/-RRB- ./.
In/IN such/JJ methods/NNS ,/, the/DT iterates/NNS consist/VBP of/IN two/CD parts/NNS that/WDT are/VBP updated/VBN using/VBG different/JJ stepsizes/NNS ./.
We/PRP develop/VBP the/DT first/JJ convergence/NN rate/NN result/NN for/IN these/DT algorithms/NNS ;/: in/IN particular/JJ ,/, we/PRP provide/VBP a/DT general/JJ methodology/NN for/IN analyzing/VBG two/CD -/HYPH timescale/NN linear/JJ SA/NNP ./.
We/PRP apply/VBP our/PRP$ methodology/NN to/IN two/CD -/HYPH timescale/NN RL/NNP algorithms/NNS such/JJ as/IN GTD/NN (/-LRB- 0/CD )/-RRB- ,/, GTD2/NN ,/, and/CC TDC/NNP ./.
