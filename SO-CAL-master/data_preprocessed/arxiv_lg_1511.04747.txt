There/EX has/VBZ been/VBN a/DT lot/NN of/IN prior/JJ work/NN on/IN representation/NN learning/NN for/IN speech/NN recognition/NN applications/NNS ,/, but/CC not/RB much/JJ emphasis/NN has/VBZ been/VBN given/VBN to/IN an/DT investigation/NN of/IN effective/JJ representations/NNS of/IN affect/NN from/IN speech/NN ,/, where/WRB the/DT paralinguistic/JJ elements/NNS of/IN speech/NN are/VBP separated/VBN out/RP from/IN the/DT verbal/JJ content/NN ./.
In/IN this/DT paper/NN ,/, we/PRP explore/VBP denoising/VBG autoencoders/NNS for/IN learning/VBG paralinguistic/JJ attributes/NNS i.e./FW dimensional/JJ affective/JJ traits/NNS from/IN speech/NN ./.
We/PRP show/VBP that/IN the/DT representations/NNS learnt/VBN by/IN the/DT bottleneck/NN layer/NN of/IN the/DT autoencoder/NN are/VBP highly/RB discriminative/JJ at/IN separating/VBG out/RP negative/JJ sentiments/NNS (/-LRB- sadness/NN and/CC anger/NN )/-RRB- from/IN positive/JJ sentiments/NNS (/-LRB- happiness/NN )/-RRB- ./.
We/PRP also/RB learn/VBP utterance/NN specific/JJ representations/NNS by/IN a/DT combination/NN of/IN denoising/VBG autoencoders/NNS and/CC LSTM/NN based/VBN recurrent/JJ autoencoders/NNS ,/, and/CC perform/VB emotion/NN classification/NN with/IN the/DT learnt/VBN temporal/JJ //HYPH dynamic/JJ representations/NNS ./.
Experiments/NNS on/IN a/DT well/RB -/HYPH established/VBN real/JJ -/HYPH life/NN speech/NN dataset/NN (/-LRB- IEMOCAP/NNP )/-RRB- show/VBP that/IN the/DT utterance/NN representations/NNS are/VBP comparable/JJ to/IN state/NN of/IN the/DT art/NN feature/NN extractors/NNS (/-LRB- such/JJ as/IN voice/NN quality/NN features/NNS and/CC MFCCs/NNS )/-RRB- at/IN emotion/NN and/CC affect/VB recognition/NN ./.
