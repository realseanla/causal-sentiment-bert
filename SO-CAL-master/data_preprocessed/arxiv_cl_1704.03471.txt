Neural/JJ machine/NN translation/NN (/-LRB- MT/NN )/-RRB- models/NNS obtain/VB state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN while/IN maintaining/VBG a/DT simple/JJ ,/, end/NN -/HYPH to/IN -/HYPH end/NN architecture/NN ./.
However/RB ,/, little/JJ is/VBZ known/VBN about/IN what/WP these/DT models/NNS learn/VBP about/IN source/NN and/CC target/NN languages/NNS during/IN the/DT training/NN process/NN ./.
In/IN this/DT work/NN ,/, we/PRP analyze/VBP the/DT representations/NNS learned/VBN by/IN neural/JJ MT/NN models/NNS at/IN various/JJ levels/NNS of/IN granularity/NN and/CC empirically/RB evaluate/VB the/DT quality/NN of/IN the/DT representations/NNS for/IN learning/VBG morphology/NN through/IN extrinsic/JJ part/NN -/HYPH of/IN -/HYPH speech/NN and/CC morphological/JJ tagging/NN tasks/NNS ./.
We/PRP conduct/VBP a/DT thorough/JJ investigation/NN along/IN several/JJ parameters/NNS :/: word/NN -/HYPH based/VBN vs./IN character/NN -/HYPH based/VBN representations/NNS ,/, depth/NN of/IN the/DT encoding/VBG layer/NN ,/, the/DT identity/NN of/IN the/DT target/NN language/NN ,/, and/CC encoder/NN vs./FW decoder/FW representations/NNS ./.
Our/PRP$ data/NN -/HYPH driven/VBN ,/, quantitative/JJ evaluation/NN sheds/VBZ light/NN on/IN important/JJ aspects/NNS in/IN the/DT neural/JJ MT/NN system/NN and/CC its/PRP$ ability/NN to/TO capture/VB word/NN structure/NN ./.
