Existing/VBG methods/NNS for/IN visual/JJ reasoning/NN attempt/NN to/TO directly/RB map/VB inputs/NNS to/IN outputs/NNS using/VBG black/JJ -/HYPH box/NN architectures/NNS without/IN explicitly/RB modeling/VBG the/DT underlying/VBG reasoning/NN processes/NNS ./.
As/IN a/DT result/NN ,/, these/DT black/JJ -/HYPH box/NN models/NNS often/RB learn/VBP to/TO exploit/VB biases/NNS in/IN the/DT data/NNS rather/RB than/IN learning/VBG to/TO perform/VB visual/JJ reasoning/NN ./.
Inspired/VBN by/IN module/NN networks/NNS ,/, this/DT paper/NN proposes/VBZ a/DT model/NN for/IN visual/JJ reasoning/NN that/WDT consists/VBZ of/IN a/DT program/NN generator/NN that/WDT constructs/VBZ an/DT explicit/JJ representation/NN of/IN the/DT reasoning/NN process/NN to/TO be/VB performed/VBN ,/, and/CC an/DT execution/NN engine/NN that/WDT executes/VBZ the/DT resulting/VBG program/NN to/TO produce/VB an/DT answer/NN ./.
Both/CC the/DT program/NN generator/NN and/CC the/DT execution/NN engine/NN are/VBP implemented/VBN by/IN neural/JJ networks/NNS ,/, and/CC are/VBP trained/VBN using/VBG a/DT combination/NN of/IN backpropagation/NN and/CC REINFORCE/VB ./.
Using/VBG the/DT CLEVR/NNP benchmark/NN for/IN visual/JJ reasoning/NN ,/, we/PRP show/VBP that/IN our/PRP$ model/NN significantly/RB outperforms/VBZ strong/JJ baselines/NNS and/CC generalizes/VBZ better/JJR in/IN a/DT variety/NN of/IN settings/NNS ./.
