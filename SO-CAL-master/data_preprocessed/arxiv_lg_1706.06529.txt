Two/CD popular/JJ classes/NNS of/IN methods/NNS for/IN approximate/JJ inference/NN are/VBP Markov/NNP chain/NN Monte/NNP Carlo/NNP (/-LRB- MCMC/NNP )/-RRB- and/CC variational/JJ inference/NN ./.
MCMC/NNP tends/VBZ to/TO be/VB accurate/JJ if/IN run/VBN for/IN a/DT long/JJ enough/JJ time/NN ,/, while/IN variational/JJ inference/NN tends/VBZ to/TO give/VB better/JJR approximations/NNS at/IN shorter/JJR time/NN horizons/NNS ./.
However/RB ,/, the/DT amount/NN of/IN time/NN needed/VBN for/IN MCMC/NNP to/TO exceed/VB the/DT performance/NN of/IN variational/JJ methods/NNS can/MD be/VB quite/RB high/JJ ,/, motivating/VBG more/JJR fine/JJ -/HYPH grained/JJ tradeoffs/NNS ./.
This/DT paper/NN derives/VBZ a/DT distribution/NN over/IN variational/JJ parameters/NNS ,/, designed/VBN to/TO minimize/VB a/DT bound/VBN on/IN the/DT divergence/NN between/IN the/DT resulting/VBG marginal/JJ distribution/NN and/CC the/DT target/NN ,/, and/CC gives/VBZ an/DT example/NN of/IN how/WRB to/TO sample/VB from/IN this/DT distribution/NN in/IN a/DT way/NN that/WDT interpolates/VBZ between/IN the/DT behavior/NN of/IN existing/VBG methods/NNS based/VBN on/IN Langevin/NNP dynamics/NNS and/CC stochastic/JJ gradient/NN variational/JJ inference/NN (/-LRB- SGVI/NN )/-RRB- ./.
