We/PRP consider/VBP the/DT problem/NN of/IN translating/VBG high/JJ -/HYPH level/NN textual/JJ descriptions/NNS to/IN formal/JJ representations/NNS in/IN technical/JJ documentation/NN as/IN part/NN of/IN an/DT effort/NN to/TO model/VB the/DT meaning/NN of/IN such/JJ documentation/NN ./.
We/PRP focus/VBP specifically/RB on/IN the/DT problem/NN of/IN learning/VBG translational/JJ correspondences/NNS between/IN text/NN descriptions/NNS and/CC grounded/VBN representations/NNS in/IN the/DT target/NN documentation/NN ,/, such/JJ as/IN formal/JJ representation/NN of/IN functions/NNS or/CC code/NN templates/NNS ./.
Our/PRP$ approach/NN exploits/VBZ the/DT parallel/JJ nature/NN of/IN such/JJ documentation/NN ,/, or/CC the/DT tight/JJ coupling/NN between/IN high/JJ -/HYPH level/NN text/NN and/CC the/DT low/JJ -/HYPH level/NN representations/NNS we/PRP aim/VBP to/TO learn/VB ./.
Data/NNS is/VBZ collected/VBN by/IN mining/VBG technical/JJ documents/NNS for/IN such/JJ parallel/JJ text/NN -/HYPH representation/NN pairs/NNS ,/, which/WDT we/PRP use/VBP to/TO train/VB a/DT simple/JJ semantic/JJ parsing/VBG model/NN ./.
We/PRP report/VBP new/JJ baseline/NN results/NNS on/IN sixteen/CD novel/JJ datasets/NNS ,/, including/VBG the/DT standard/JJ library/NN documentation/NN for/IN nine/CD popular/JJ programming/NN languages/NNS across/IN seven/CD natural/JJ languages/NNS ,/, and/CC a/DT small/JJ collection/NN of/IN Unix/NNP utility/NN manuals/NNS ./.
