We/PRP propose/VBP a/DT novel/NN vector/NN representation/NN that/WDT integrates/VBZ lexical/JJ contrast/NN into/IN distributional/JJ vectors/NNS and/CC strengthens/VBZ the/DT most/RBS salient/JJ features/NNS for/IN determining/VBG degrees/NNS of/IN word/NN similarity/NN ./.
The/DT improved/VBN vectors/NNS significantly/RB outperform/VBP standard/JJ models/NNS and/CC distinguish/VB antonyms/NNS from/IN synonyms/NNS with/IN an/DT average/JJ precision/NN of/IN 0.66/CD -/HYPH 0.76/CD across/IN word/NN classes/NNS (/-LRB- adjectives/NNS ,/, nouns/NNS ,/, verbs/NNS )/-RRB- ./.
Moreover/RB ,/, we/PRP integrate/VBP the/DT lexical/JJ contrast/NN vectors/NNS into/IN the/DT objective/JJ function/NN of/IN a/DT skip/VB -/HYPH gram/NN model/NN ./.
The/DT novel/JJ embedding/NN outperforms/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN models/NNS on/IN predicting/VBG word/NN similarities/NNS in/IN SimLex/NNP -/HYPH 999/CD ,/, and/CC on/IN distinguishing/VBG antonyms/NNS from/IN synonyms/NNS ./.
