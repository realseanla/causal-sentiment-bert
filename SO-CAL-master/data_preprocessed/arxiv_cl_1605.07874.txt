In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT bidimensional/JJ attention/NN based/VBN recursive/JJ autoencoder/NN (/-LRB- BattRAE/NN )/-RRB- to/TO integrate/VB cues/NNS and/CC source/NN -/HYPH target/NN interactions/NNS at/IN multiple/JJ levels/NNS of/IN granularity/NN into/IN bilingual/JJ phrase/NN representations/NNS ./.
We/PRP employ/VBP recursive/JJ autoencoders/NNS to/TO generate/VB tree/NN structures/NNS of/IN phrase/NN with/IN embeddings/NNS at/IN different/JJ levels/NNS of/IN granularity/NN (/-LRB- e.g./FW ,/, words/NNS ,/, sub-phrases/NNS ,/, phrases/NNS )/-RRB- ./.
Over/IN these/DT embeddings/NNS on/IN the/DT source/NN and/CC target/NN side/NN ,/, we/PRP introduce/VBP a/DT bidimensional/JJ attention/NN network/NN to/TO learn/VB their/PRP$ interactions/NNS encoded/VBN in/IN a/DT bidimensional/JJ attention/NN matrix/NN ,/, from/IN which/WDT we/PRP extract/VBP two/CD soft/JJ attention/NN weight/NN distributions/NNS simultaneously/RB ./.
The/DT weight/NN distributions/NNS enable/VBP BattRAE/NNP to/TO generate/VB compositive/JJ phrase/NN representations/NNS via/IN convolution/NN ./.
Based/VBN on/IN the/DT learned/VBN phrase/NN representations/NNS ,/, we/PRP further/RB use/VBP a/DT bilinear/NN neural/JJ model/NN ,/, trained/VBN via/IN a/DT max/NN -/HYPH margin/NN method/NN ,/, to/TO measure/VB bilingual/JJ semantic/JJ similarity/NN ./.
In/IN order/NN to/TO evaluate/VB the/DT effectiveness/NN of/IN BattRAE/NNP ,/, we/PRP incorporate/VBP this/DT semantic/JJ similarity/NN as/IN an/DT additional/JJ feature/NN into/IN a/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN SMT/NN system/NN ./.
Extensive/JJ experiments/NNS on/IN NIST/NNP Chinese/NNP -/HYPH English/NNP test/NN sets/NNS show/VBP that/IN our/PRP$ model/NN achieves/VBZ a/DT substantial/JJ improvement/NN of/IN up/RB to/IN 1.82/CD BLEU/NN points/NNS over/IN the/DT baseline/NN ./.
