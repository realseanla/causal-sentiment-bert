We/PRP present/VBP a/DT large/JJ -/HYPH scale/NN study/NN ,/, exploring/VBG the/DT capability/NN of/IN temporal/JJ deep/JJ neural/JJ networks/NNS in/IN interpreting/VBG natural/JJ human/JJ kinematics/NNS and/CC introduce/VB the/DT first/JJ method/NN for/IN active/JJ biometric/JJ authentication/NN with/IN mobile/JJ inertial/JJ sensors/NNS ./.
At/IN Google/NNP ,/, we/PRP have/VBP created/VBN a/DT first/JJ -/HYPH of/IN -/HYPH its/PRP$ -/HYPH kind/NN dataset/NN of/IN human/JJ movements/NNS ,/, passively/RB collected/VBN by/IN 1500/CD volunteers/NNS using/VBG their/PRP$ smartphones/NNS daily/RB over/IN several/JJ months/NNS ./.
We/PRP (/-LRB- 1/CD )/-RRB- compare/VBP several/JJ neural/JJ architectures/NNS for/IN efficient/JJ learning/NN of/IN temporal/JJ multi-modal/JJ data/NNS representations/NNS ,/, (/-LRB- 2/LS )/-RRB- propose/VB an/DT optimized/VBN shift/NN -/HYPH invariant/JJ dense/JJ convolutional/JJ mechanism/NN (/-LRB- DCWRNN/NNP )/-RRB- and/CC (/-LRB- 3/LS )/-RRB- incorporate/VB the/DT discriminatively/RB -/HYPH trained/VBN dynamic/JJ features/NNS in/IN a/DT probabilistic/JJ generative/JJ framework/NN taking/VBG into/IN account/NN temporal/JJ characteristics/NNS ./.
Our/PRP$ results/NNS demonstrate/VBP ,/, that/IN human/JJ kinematics/NNS convey/VB important/JJ information/NN about/IN user/NN identity/NN and/CC can/MD serve/VB as/IN a/DT valuable/JJ component/NN of/IN multi-modal/JJ authentication/NN systems/NNS ./.
