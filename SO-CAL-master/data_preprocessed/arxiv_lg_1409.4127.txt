Unconstrained/JJ video/NN recognition/NN and/CC Deep/JJ Convolution/NNP Network/NNP (/-LRB- DCN/NNP )/-RRB- are/VBP two/CD active/JJ topics/NNS in/IN computer/NN vision/NN recently/RB ./.
In/IN this/DT work/NN ,/, we/PRP apply/VBP DCNs/NNS as/IN frame/NN -/HYPH based/VBN recognizers/NNS for/IN video/NN recognition/NN ./.
Our/PRP$ preliminary/JJ studies/NNS ,/, however/RB ,/, show/VBP that/IN video/NN corpora/NNS with/IN complete/JJ ground/NN truth/NN are/VBP usually/RB not/RB large/JJ and/CC diverse/JJ enough/JJ to/TO learn/VB a/DT robust/JJ model/NN ./.
The/DT networks/NNS trained/VBN directly/RB on/IN the/DT video/NN data/NNS set/VBN suffer/VBP from/IN significant/JJ overfitting/NN and/CC have/VBP poor/JJ recognition/NN rate/NN on/IN the/DT test/NN set/NN ./.
The/DT same/JJ lack/NN -/HYPH of/IN -/HYPH training/NN -/HYPH sample/NN problem/NN limits/VBZ the/DT usage/NN of/IN deep/JJ models/NNS on/IN a/DT wide/JJ range/NN of/IN computer/NN vision/NN problems/NNS where/WRB obtaining/VBG training/NN data/NNS are/VBP difficult/JJ ./.
To/TO overcome/VB the/DT problem/NN ,/, we/PRP perform/VBP transfer/NN learning/NN from/IN images/NNS to/IN videos/NNS to/TO utilize/VB the/DT knowledge/NN in/IN the/DT weakly/RB labeled/VBN image/NN corpus/NN for/IN video/NN recognition/NN ./.
The/DT image/NN corpus/NN help/NN to/TO learn/VB important/JJ visual/JJ patterns/NNS for/IN natural/JJ images/NNS ,/, while/IN these/DT patterns/NNS are/VBP ignored/VBN by/IN models/NNS trained/VBN only/RB on/IN the/DT video/NN corpus/NN ./.
Therefore/RB ,/, the/DT resultant/JJ networks/NNS have/VBP better/JJR generalizability/NN and/CC better/JJR recognition/NN rate/NN ./.
We/PRP show/VBP that/IN by/IN means/NNS of/IN transfer/NN learning/NN from/IN image/NN to/IN video/NN ,/, we/PRP can/MD learn/VB a/DT frame/NN -/HYPH based/VBN recognizer/NN with/IN only/JJ 4k/NN videos/NNS ./.
Because/IN the/DT image/NN corpus/NN is/VBZ weakly/RB labeled/VBN ,/, the/DT entire/JJ learning/NN process/NN requires/VBZ only/RB 4k/NN annotated/VBN instances/NNS ,/, which/WDT is/VBZ far/RB less/JJR than/IN the/DT million/CD scale/NN image/NN data/NN sets/NNS required/VBN by/IN previous/JJ works/NNS ./.
The/DT same/JJ approach/NN may/MD be/VB applied/VBN to/IN other/JJ visual/JJ recognition/NN tasks/NNS where/WRB only/RB scarce/JJ training/NN data/NNS is/VBZ available/JJ ,/, and/CC it/PRP improves/VBZ the/DT applicability/NN of/IN DCNs/NNS in/IN various/JJ computer/NN vision/NN problems/NNS ./.
Our/PRP$ experiments/NNS also/RB reveal/VBP the/DT correlation/NN between/IN meta/NN -/HYPH parameters/NNS and/CC the/DT performance/NN of/IN DCNs/NNS ,/, given/VBN the/DT properties/NNS of/IN the/DT target/NN problem/NN and/CC data/NNS ./.
These/DT results/NNS lead/VBP to/IN a/DT heuristic/NN for/IN meta/NN -/HYPH parameter/NN selection/NN for/IN future/JJ researches/NNS ,/, which/WDT does/VBZ not/RB rely/VB on/IN the/DT time/NN consuming/VBG meta/NN -/HYPH parameter/NN search/NN ./.
