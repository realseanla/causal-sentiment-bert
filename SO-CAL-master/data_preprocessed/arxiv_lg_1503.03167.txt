This/DT paper/NN presents/VBZ the/DT Deep/NNP Convolution/NNP Inverse/NNP Graphics/NNP Network/NNP (/-LRB- DC/NNP -/HYPH IGN/NNP )/-RRB- that/WDT aims/VBZ to/TO learn/VB an/DT interpretable/JJ representation/NN of/IN images/NNS that/WDT is/VBZ disentangled/VBN with/IN respect/NN to/IN various/JJ transformations/NNS such/JJ as/IN object/NN out/IN -/HYPH of/IN -/HYPH plane/NN rotations/NNS ,/, lighting/VBG variations/NNS ,/, and/CC texture/NN ./.
The/DT DC/NNP -/HYPH IGN/NNP model/NN is/VBZ composed/VBN of/IN multiple/JJ layers/NNS of/IN convolution/NN and/CC de-convolution/NN operators/NNS and/CC is/VBZ trained/VBN using/VBG the/DT Stochastic/NNP Gradient/NNP Variational/NNP Bayes/NNP (/-LRB- SGVB/NNP )/-RRB- algorithm/NN ./.
We/PRP propose/VBP training/NN procedures/NNS to/TO encourage/VB neurons/NNS in/IN the/DT graphics/NNS code/NN layer/NN to/TO have/VB semantic/JJ meaning/NN and/CC force/VB each/DT group/NN to/TO distinctly/RB represent/VB a/DT specific/JJ transformation/NN (/-LRB- pose/NN ,/, light/NN ,/, texture/NN ,/, shape/NN etc./FW )/-RRB- ./.
Given/VBN a/DT static/JJ face/NN image/NN ,/, our/PRP$ model/NN can/MD re-generate/VB the/DT input/NN image/NN with/IN different/JJ pose/NN ,/, lighting/NN or/CC even/RB texture/NN and/CC shape/NN variations/NNS from/IN the/DT base/NN face/NN ./.
We/PRP present/VBP qualitative/JJ and/CC quantitative/JJ results/NNS of/IN the/DT model/NN 's/POS efficacy/NN to/TO learn/VB a/DT 3D/NN rendering/VBG engine/NN ./.
Moreover/RB ,/, we/PRP also/RB utilize/VBP the/DT learnt/VBN representation/NN for/IN two/CD important/JJ visual/JJ recognition/NN tasks/NNS :/: (/-LRB- 1/LS )/-RRB- an/DT invariant/JJ face/NN recognition/NN task/NN and/CC (/-LRB- 2/LS )/-RRB- using/VBG the/DT representation/NN as/IN a/DT summary/NN statistic/NN for/IN generative/JJ modeling/NN ./.
