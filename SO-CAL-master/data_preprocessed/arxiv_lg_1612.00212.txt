Fully/RB convolutional/JJ neural/JJ networks/NNS give/VBP accurate/JJ ,/, per/IN -/HYPH pixel/NN prediction/NN for/IN input/NN images/NNS and/CC have/VBP applications/NNS like/IN semantic/JJ segmentation/NN ./.
However/RB ,/, a/DT typical/JJ FCN/NNP usually/RB requires/VBZ lots/NNS of/IN floating/VBG point/NN computation/NN and/CC large/JJ run/NN -/HYPH time/NN memory/NN ,/, which/WDT effectively/RB limits/VBZ its/PRP$ usability/NN ./.
We/PRP propose/VBP a/DT method/NN to/TO train/VB Bit/NN Fully/RB Convolution/NNP Network/NNP (/-LRB- BFCN/NNP )/-RRB- ,/, a/DT fully/RB convolutional/JJ neural/JJ network/NN that/WDT has/VBZ low/JJ bit/NN -/HYPH width/NN weights/NNS and/CC activations/NNS ./.
Because/IN most/JJS of/IN its/PRP$ computation/NN -/HYPH intensive/JJ convolutions/NNS are/VBP accomplished/VBN between/IN low/JJ bit/NN -/HYPH width/NN numbers/NNS ,/, a/DT BFCN/NN can/MD be/VB accelerated/VBN by/IN an/DT efficient/JJ bit/NN -/HYPH convolution/NN implementation/NN ./.
On/IN CPU/NN ,/, the/DT dot/NN product/NN operation/NN between/IN two/CD bit/NN vectors/NNS can/MD be/VB reduced/VBN to/IN bitwise/JJ operations/NNS and/CC popcounts/NNS ,/, which/WDT can/MD offer/VB much/RB higher/JJR throughput/NN than/IN 32/CD -/HYPH bit/NN multiplications/NNS and/CC additions/NNS ./.
