An/DT important/JJ subclass/NN of/IN hybrid/NN Bayesian/JJ networks/NNS are/VBP those/DT that/WDT represent/VBP Conditional/JJ Linear/NNP Gaussian/NNP (/-LRB- CLG/NNP )/-RRB- distributions/NNS ---/, a/DT distribution/NN with/IN a/DT multivariate/JJ Gaussian/NNP component/NN for/IN each/DT instantiation/NN of/IN the/DT discrete/JJ variables/NNS ./.
In/IN this/DT paper/NN we/PRP explore/VBP the/DT problem/NN of/IN inference/NN in/IN CLGs/NNS ./.
We/PRP show/VBP that/IN inference/NN in/IN CLGs/NNS can/MD be/VB significantly/RB harder/JJR than/IN inference/NN in/IN Bayes/NNP Nets/NNPS ./.
In/IN particular/JJ ,/, we/PRP prove/VBP that/IN even/RB if/IN the/DT CLG/NN is/VBZ restricted/VBN to/IN an/DT extremely/RB simple/JJ structure/NN of/IN a/DT polytree/NN in/IN which/WDT every/DT continuous/JJ node/NN has/VBZ at/IN most/RBS one/CD discrete/JJ ancestor/NN ,/, the/DT inference/NN task/NN is/VBZ NP/NNP -/HYPH hard.To/NNP deal/NN with/IN the/DT often/RB prohibitive/JJ computational/JJ cost/NN of/IN the/DT exact/JJ inference/NN algorithm/NN for/IN CLGs/NNS ,/, we/PRP explore/VBP several/JJ approximate/JJ inference/NN algorithms/NNS ./.
These/DT algorithms/NNS try/VBP to/TO find/VB a/DT small/JJ subset/NN of/IN Gaussians/NNS which/WDT are/VBP a/DT good/JJ approximation/NN to/IN the/DT full/JJ mixture/NN distribution/NN ./.
We/PRP consider/VBP two/CD Monte/NNP Carlo/NNP approaches/VBZ and/CC a/DT novel/JJ approach/NN that/WDT enumerates/VBZ mixture/NN components/NNS in/IN order/NN of/IN prior/JJ probability/NN ./.
We/PRP compare/VBP these/DT methods/NNS on/IN a/DT variety/NN of/IN problems/NNS and/CC show/VBP that/IN our/PRP$ novel/JJ algorithm/NN is/VBZ very/RB promising/JJ for/IN large/JJ ,/, hybrid/JJ diagnosis/NN problems/NNS ./.
