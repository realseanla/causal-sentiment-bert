Training/VBG directed/VBN neural/JJ networks/NNS typically/RB requires/VBZ forward/RB -/HYPH propagating/VBG data/NNS through/IN a/DT computation/NN graph/NN ,/, followed/VBN by/IN backpropagating/VBG error/NN signal/NN ,/, to/TO produce/VB weight/NN updates/NNS ./.
All/DT layers/NNS ,/, or/CC more/RBR generally/RB ,/, modules/NNS ,/, of/IN the/DT network/NN are/VBP therefore/RB locked/VBN ,/, in/IN the/DT sense/NN that/IN they/PRP must/MD wait/VB for/IN the/DT remainder/NN of/IN the/DT network/NN to/TO execute/VB forwards/NNS and/CC propagate/VB error/NN backwards/RB before/IN they/PRP can/MD be/VB updated/VBN ./.
In/IN this/DT work/NN we/PRP break/VBP this/DT constraint/NN by/IN decoupling/VBG modules/NNS by/IN introducing/VBG a/DT model/NN of/IN the/DT future/JJ computation/NN of/IN the/DT network/NN graph/NN ./.
These/DT models/NNS predict/VBP what/WP the/DT result/NN of/IN the/DT modelled/VBN subgraph/NN will/MD produce/VB using/VBG only/RB local/JJ information/NN ./.
In/IN particular/JJ we/PRP focus/VBP on/IN modelling/VBG error/NN gradients/NNS :/: by/IN using/VBG the/DT modelled/VBN synthetic/JJ gradient/NN in/IN place/NN of/IN true/JJ backpropagated/JJ error/NN gradients/NNS we/PRP decouple/VBP subgraphs/NNS ,/, and/CC can/MD update/VB them/PRP independently/RB and/CC asynchronously/RB i.e./FW we/PRP realise/VBP decoupled/VBN neural/JJ interfaces/VBZ ./.
We/PRP show/VBP results/NNS for/IN feed/NN -/HYPH forward/NN models/NNS ,/, where/WRB every/DT layer/NN is/VBZ trained/VBN asynchronously/RB ,/, recurrent/JJ neural/JJ networks/NNS (/-LRB- RNNs/NNS )/-RRB- where/WRB predicting/VBG one/PRP 's/POS future/JJ gradient/NN extends/VBZ the/DT time/NN over/IN which/WDT the/DT RNN/NN can/MD effectively/RB model/VB ,/, and/CC also/RB a/DT hierarchical/JJ RNN/NN system/NN with/IN ticking/VBG at/IN different/JJ timescales/NNS ./.
Finally/RB ,/, we/PRP demonstrate/VBP that/IN in/IN addition/NN to/IN predicting/VBG gradients/NNS ,/, the/DT same/JJ framework/NN can/MD be/VB used/VBN to/TO predict/VB inputs/NNS ,/, resulting/VBG in/IN models/NNS which/WDT are/VBP decoupled/VBN in/IN both/CC the/DT forward/JJ and/CC backwards/RB pass/VB --/: amounting/VBG to/IN independent/JJ networks/NNS which/WDT co-learn/VBP such/JJ that/IN they/PRP can/MD be/VB composed/VBN into/IN a/DT single/JJ functioning/NN corporation/NN ./.
