Recent/JJ work/NN has/VBZ shown/VBN deep/JJ neural/JJ networks/NNS (/-LRB- DNNs/NNS )/-RRB- to/TO be/VB highly/RB susceptible/JJ to/TO well/RB -/HYPH designed/VBN ,/, small/JJ perturbations/NNS at/IN the/DT input/NN layer/NN ,/, or/CC so/RB -/HYPH called/VBN adversarial/JJ examples/NNS ./.
Taking/VBG images/NNS as/IN an/DT example/NN ,/, such/JJ distortions/NNS are/VBP often/RB imperceptible/JJ ,/, but/CC can/MD result/VB in/IN 100/CD percent/NN mis/NN -/HYPH classification/NN for/IN a/DT state/NN of/IN the/DT art/NN DNN/NN ./.
We/PRP study/VBP the/DT structure/NN of/IN adversarial/JJ examples/NNS and/CC explore/VB network/NN topology/NN ,/, pre-processing/NN and/CC training/NN strategies/NNS to/TO improve/VB the/DT robustness/NN of/IN DNNs/NNS ./.
We/PRP perform/VBP various/JJ experiments/NNS to/TO assess/VB the/DT removability/NN of/IN adversarial/JJ examples/NNS by/IN corrupting/VBG with/IN additional/JJ noise/NN and/CC pre-processing/VBG with/IN denoising/NN autoencoders/NNS (/-LRB- DAEs/NNS )/-RRB- ./.
We/PRP find/VBP that/IN DAEs/NNS can/MD remove/VB substantial/JJ amounts/NNS of/IN the/DT adversarial/JJ noise/NN ./.
How/WRB -/HYPH ever/RB ,/, when/WRB stacking/VBG the/DT DAE/NNP with/IN the/DT original/JJ DNN/NNP ,/, the/DT resulting/VBG network/NN can/MD again/RB be/VB attacked/VBN by/IN new/JJ adversarial/JJ examples/NNS with/IN even/RB smaller/JJR distortion/NN ./.
As/IN a/DT solution/NN ,/, we/PRP propose/VBP Deep/JJ Contractive/NNP Network/NNP ,/, a/DT model/NN with/IN a/DT new/JJ end/NN -/HYPH to/IN -/HYPH end/NN training/NN procedure/NN that/WDT includes/VBZ a/DT smoothness/NN penalty/NN inspired/VBN by/IN the/DT contractive/JJ autoencoder/NN (/-LRB- CAE/NNP )/-RRB- ./.
This/DT increases/VBZ the/DT network/NN robustness/NN to/IN adversarial/JJ exam/NN -/HYPH ples/NNS ,/, without/IN a/DT significant/JJ performance/NN penalty/NN ./.
