Although/IN the/DT latest/JJS high/JJ -/HYPH end/NN smartphone/NN has/VBZ powerful/JJ CPU/NN and/CC GPU/NNP ,/, running/VBG deeper/JJR convolutional/JJ neural/JJ networks/NNS (/-LRB- CNNs/NNS )/-RRB- for/IN complex/JJ tasks/NNS such/JJ as/IN ImageNet/NNP classification/NN on/IN mobile/JJ devices/NNS is/VBZ challenging/JJ ./.
To/TO deploy/VB deep/JJ CNNs/NNS on/IN mobile/JJ devices/NNS ,/, we/PRP present/VBP a/DT simple/JJ and/CC effective/JJ scheme/NN to/TO compress/VB the/DT entire/JJ CNN/NNP ,/, which/WDT we/PRP call/VBP one/CD -/HYPH shot/NN whole/JJ network/NN compression/NN ./.
The/DT proposed/VBN scheme/NN consists/VBZ of/IN three/CD steps/NNS :/: (/-LRB- 1/LS )/-RRB- rank/NN selection/NN with/IN variational/JJ Bayesian/JJ matrix/NN factorization/NN ,/, (/-LRB- 2/LS )/-RRB- Tucker/NNP decomposition/NN on/IN kernel/NN tensor/NN ,/, and/CC (/-LRB- 3/LS )/-RRB- fine/JJ -/HYPH tuning/NN to/TO recover/VB accumulated/VBN loss/NN of/IN accuracy/NN ,/, and/CC each/DT step/NN can/MD be/VB easily/RB implemented/VBN using/VBG publicly/RB available/JJ tools/NNS ./.
We/PRP demonstrate/VBP the/DT effectiveness/NN of/IN the/DT proposed/VBN scheme/NN by/IN testing/VBG the/DT performance/NN of/IN various/JJ compressed/JJ CNNs/NNS (/-LRB- AlexNet/NNP ,/, VGGS/NNP ,/, GoogLeNet/NNP ,/, and/CC VGG/NN -/HYPH 16/CD )/-RRB- on/IN the/DT smartphone/NN ./.
Significant/JJ reductions/NNS in/IN model/NN size/NN ,/, runtime/NN ,/, and/CC energy/NN consumption/NN are/VBP obtained/VBN ,/, at/IN the/DT cost/NN of/IN small/JJ loss/NN in/IN accuracy/NN ./.
In/IN addition/NN ,/, we/PRP address/VBP the/DT important/JJ implementation/NN level/NN issue/NN on/IN 1/CD ?/.
1/CD convolution/NN ,/, which/WDT is/VBZ a/DT key/JJ operation/NN of/IN inception/NN module/NN of/IN GoogLeNet/NNP as/RB well/RB as/IN CNNs/NNS compressed/VBN by/IN our/PRP$ proposed/VBN scheme/NN ./.
