As/IN the/DT emerging/VBG field/NN of/IN machine/NN learning/NN ,/, deep/JJ learning/NN shows/VBZ excellent/JJ ability/NN in/IN solving/VBG complex/JJ learning/NN problems/NNS ./.
However/RB ,/, the/DT size/NN of/IN the/DT networks/NNS becomes/VBZ increasingly/RB large/JJ scale/NN due/IN to/IN the/DT demands/NNS of/IN the/DT practical/JJ applications/NNS ,/, which/WDT poses/VBZ significant/JJ challenge/NN to/TO construct/VB a/DT high/JJ performance/NN implementations/NNS of/IN deep/JJ learning/NN neural/JJ networks/NNS ./.
In/IN order/NN to/TO improve/VB the/DT performance/NN as/RB well/RB to/TO maintain/VB the/DT low/JJ power/NN cost/NN ,/, in/IN this/DT paper/NN we/PRP design/VBP DLAU/NNP ,/, which/WDT is/VBZ a/DT scalable/JJ accelerator/NN architecture/NN for/IN large/JJ -/HYPH scale/NN deep/JJ learning/NN networks/NNS using/VBG FPGA/NNP as/IN the/DT hardware/NN prototype/NN ./.
The/DT DLAU/NNP accelerator/NN employs/VBZ three/CD pipelined/JJ processing/NN units/NNS to/TO improve/VB the/DT throughput/NN and/CC utilizes/VBZ tile/NN techniques/NNS to/TO explore/VB locality/NN for/IN deep/JJ learning/NN applications/NNS ./.
Experimental/JJ results/NNS on/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN Xilinx/NNP FPGA/NNP board/NN demonstrate/VBP that/IN the/DT DLAU/NNP accelerator/NN is/VBZ able/JJ to/TO achieve/VB up/RP to/IN 36.1/CD x/SYM speedup/NN comparing/VBG to/IN the/DT Intel/NNP Core2/NN processors/NNS ,/, with/IN the/DT power/NN consumption/NN at/IN 234mW/NN ./.
