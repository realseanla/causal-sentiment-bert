We/PRP propose/VBP a/DT method/NN for/IN integration/NN of/IN features/NNS extracted/VBN using/VBG deep/JJ representations/NNS of/IN Convolutional/JJ Neural/JJ Networks/NNS (/-LRB- CNNs/NNS )/-RRB- each/DT of/IN which/WDT is/VBZ learned/VBN using/VBG a/DT different/JJ image/NN dataset/NN of/IN objects/NNS and/CC materials/NNS for/IN material/NN recognition/NN ./.
Given/VBN a/DT set/NN of/IN representations/NNS of/IN multiple/JJ pre-trained/JJ CNNs/NNS ,/, we/PRP first/RB compute/VB activations/NNS of/IN features/NNS using/VBG the/DT representations/NNS on/IN the/DT images/NNS to/TO select/VB a/DT set/NN of/IN samples/NNS which/WDT are/VBP best/JJS represented/VBN by/IN the/DT features/NNS ./.
Then/RB ,/, we/PRP measure/VBP the/DT uncertainty/NN of/IN the/DT features/NNS by/IN computing/VBG the/DT entropy/NN of/IN class/NN distributions/NNS for/IN each/DT sample/NN set/NN ./.
Finally/RB ,/, we/PRP compute/VBP the/DT contribution/NN of/IN each/DT feature/NN to/IN representation/NN of/IN classes/NNS for/IN feature/NN selection/NN and/CC integration/NN ./.
We/PRP examine/VBP the/DT proposed/JJ method/NN on/IN three/CD benchmark/NN datasets/NNS for/IN material/NN recognition/NN ./.
Experimental/JJ results/NNS show/VBP that/IN the/DT proposed/JJ method/NN achieves/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN by/IN integrating/VBG deep/JJ features/NNS ./.
Additionally/RB ,/, we/PRP introduce/VBP a/DT new/JJ material/NN dataset/NN called/VBN EFMD/NNP by/IN extending/VBG Flickr/NNP Material/NNP Database/NNP (/-LRB- FMD/NNP )/-RRB- ./.
By/IN the/DT employment/NN of/IN the/DT EFMD/NN with/IN transfer/NN learning/NN for/IN updating/VBG the/DT learned/VBN CNN/NNP models/NNS ,/, we/PRP achieve/VBP 84.0/CD percent/NN //SYM -/HYPH 1.8/CD percent/NN accuracy/NN on/IN the/DT FMD/NNP dataset/NN which/WDT is/VBZ close/JJ to/IN human/JJ performance/NN that/WDT is/VBZ 84.9/CD percent/NN ./.
