We/PRP present/VBP extensions/NNS to/IN a/DT continuous/JJ -/HYPH state/NN dependency/NN parsing/VBG method/NN that/WDT makes/VBZ it/PRP applicable/JJ to/IN morphologically/RB rich/JJ languages/NNS ./.
Starting/VBG with/IN a/DT high/JJ -/HYPH performance/NN transition/NN -/HYPH based/VBN parser/NN that/WDT uses/VBZ long/RB short/JJ -/HYPH term/NN memory/NN (/-LRB- LSTM/NN )/-RRB- recurrent/JJ neural/JJ networks/NNS to/TO learn/VB representations/NNS of/IN the/DT parser/NN state/NN ,/, we/PRP replace/VBP look/VB -/HYPH up/RP based/VBN word/NN representations/NNS with/IN representations/NNS constructed/VBN based/VBN on/IN the/DT orthographic/JJ representations/NNS of/IN the/DT words/NNS ,/, also/RB using/VBG LSTMs/NNS ./.
This/DT allows/VBZ statistical/JJ sharing/NN across/IN word/NN forms/NNS that/WDT are/VBP similar/JJ on/IN the/DT surface/NN ./.
Experiments/NNS for/IN morphologically/RB rich/JJ languages/NNS show/VBP that/IN the/DT parsing/VBG model/NN benefits/NNS from/IN incorporating/VBG the/DT character/NN -/HYPH based/VBN encodings/NNS of/IN words/NNS ./.
