The/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS provided/VBN by/IN deep/JJ learning/NN come/VBN at/IN the/DT price/NN of/IN an/DT intensive/JJ use/NN of/IN computing/NN resources/NNS ./.
The/DT leading/VBG frameworks/NNS (/-LRB- eg./NN ,/, TensorFlow/NNP )/-RRB- are/VBP executed/VBN on/IN GPUs/NNS or/CC on/IN high/JJ -/HYPH end/NN servers/NNS in/IN datacenters/NNS ./.
On/IN the/DT other/JJ end/NN ,/, there/EX is/VBZ a/DT proliferation/NN of/IN personal/JJ devices/NNS with/IN possibly/RB free/JJ CPU/NN cycles/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP ask/VBP the/DT following/VBG question/NN :/: Is/VBZ distributed/VBN deep/JJ learning/NN computation/NN on/IN WAN/NNP connected/JJ devices/NNS feasible/JJ ,/, in/IN spite/NN of/IN the/DT traffic/NN caused/VBN by/IN learning/VBG tasks/NNS ?/.
We/PRP show/VBP that/IN such/PDT a/DT setup/NN rises/VBZ some/DT important/JJ challenges/NNS ,/, most/RBS notably/RB the/DT ingress/NN traffic/NN that/WDT the/DT servers/NNS hosting/VBG the/DT up/NN -/HYPH to/IN -/HYPH date/NN model/NN have/VBP to/TO sustain/VB ./.
In/IN order/NN to/TO reduce/VB this/DT stress/NN ,/, we/PRP propose/VBP AdaComp/NNP ,/, a/DT new/JJ algorithm/NN for/IN compressing/VBG worker/NN updates/NNS to/IN the/DT model/NN on/IN the/DT server/NN ./.
Applicable/NNP to/TO stochastic/JJ gradient/NN descent/NN based/VBN approaches/NNS ,/, it/PRP combines/VBZ efficient/JJ gradient/NN selection/NN and/CC learning/NN rate/NN modulation/NN ./.
We/PRP then/RB experiment/VBP and/CC measure/VBP the/DT impact/NN of/IN compression/NN and/CC device/NN reliability/NN on/IN the/DT accuracy/NN of/IN learned/VBN models/NNS ./.
To/TO do/VB so/RB ,/, we/PRP leverage/VBP an/DT emulator/NN platform/NN we/PRP developed/VBD ,/, that/IN embeds/VBZ the/DT TensorFlow/NNP code/NN into/IN Linux/NNP containers/NNS ./.
We/PRP report/VBP a/DT reduction/NN of/IN the/DT total/JJ amount/NN of/IN data/NNS sent/VBN by/IN workers/NNS to/IN the/DT server/NN by/IN two/CD order/NN of/IN magnitude/NN (/-LRB- eg./NN ,/, 191-fold/JJ reduction/NN for/IN a/DT convolutional/JJ network/NN on/IN the/DT MNIST/NNP dataset/NN )/-RRB- ,/, when/WRB compared/VBN to/IN the/DT standard/JJ algorithm/NN based/VBN on/IN asynchronous/JJ stochastic/JJ gradient/NN descent/NN ,/, while/IN maintaining/VBG model/NN accuracy/NN ./.
