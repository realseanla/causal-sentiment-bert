Recurrent/JJ neural/JJ networks/NNS are/VBP a/DT powerful/JJ tool/NN for/IN modeling/VBG sequential/JJ data/NNS ,/, but/CC the/DT dependence/NN of/IN each/DT timestep/NN 's/POS computation/NN on/IN the/DT previous/JJ timestep/NN 's/POS output/NN limits/NNS parallelism/NN and/CC makes/VBZ RNNs/NNS unwieldy/JJ for/IN very/RB long/JJ sequences/NNS ./.
We/PRP introduce/VBP quasi-recurrent/JJ neural/JJ networks/NNS (/-LRB- QRNNs/NNS )/-RRB- ,/, an/DT approach/NN to/IN neural/JJ sequence/NN modeling/NN that/WDT alternates/VBZ convolutional/JJ layers/NNS ,/, which/WDT apply/VBP in/IN parallel/NN across/IN timesteps/NNS ,/, and/CC a/DT minimalist/JJ recurrent/JJ pooling/VBG function/NN that/WDT applies/VBZ in/IN parallel/NN across/IN channels/NNS ./.
Despite/IN lacking/VBG trainable/JJ recurrent/JJ layers/NNS ,/, stacked/VBN QRNNs/NNS have/VBP better/JJR predictive/JJ accuracy/NN than/IN stacked/VBN LSTMs/NNS of/IN the/DT same/JJ hidden/JJ size/NN ./.
Due/IN to/IN their/PRP$ increased/VBN parallelism/NN ,/, they/PRP are/VBP up/RB to/IN 16/CD times/NNS faster/RBR at/IN train/NN and/CC test/NN time/NN ./.
Experiments/NNS on/IN language/NN modeling/NN ,/, sentiment/NN classification/NN ,/, and/CC character/NN -/HYPH level/NN neural/JJ machine/NN translation/NN demonstrate/VBP these/DT advantages/NNS and/CC underline/VB the/DT viability/NN of/IN QRNNs/NNS as/IN a/DT basic/JJ building/NN block/NN for/IN a/DT variety/NN of/IN sequence/NN tasks/NNS ./.
