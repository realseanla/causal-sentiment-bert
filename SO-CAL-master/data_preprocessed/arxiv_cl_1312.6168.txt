Most/JJS representation/NN learning/NN algorithms/NNS for/IN language/NN and/CC image/NN processing/NN are/VBP local/JJ ,/, in/IN that/IN they/PRP identify/VBP features/NNS for/IN a/DT data/NN point/NN based/VBN on/IN surrounding/VBG points/NNS ./.
Yet/CC in/IN language/NN processing/NN ,/, the/DT correct/JJ meaning/NN of/IN a/DT word/NN often/RB depends/VBZ on/IN its/PRP$ global/JJ context/NN ./.
As/IN a/DT step/NN toward/IN incorporating/VBG global/JJ context/NN into/IN representation/NN learning/NN ,/, we/PRP develop/VBP a/DT representation/NN learning/NN algorithm/NN that/WDT incorporates/VBZ joint/JJ prediction/NN into/IN its/PRP$ technique/NN for/IN producing/VBG features/NNS for/IN a/DT word/NN ./.
We/PRP develop/VBP efficient/JJ variational/JJ methods/NNS for/IN learning/VBG Factorial/NNP Hidden/NNP Markov/NNP Models/NNPS from/IN large/JJ texts/NNS ,/, and/CC use/VB variational/JJ distributions/NNS to/TO produce/VB features/NNS for/IN each/DT word/NN that/WDT are/VBP sensitive/JJ to/IN the/DT entire/JJ input/NN sequence/NN ,/, not/RB just/RB to/IN a/DT local/JJ context/NN window/NN ./.
Experiments/NNS on/IN part/NN -/HYPH of/IN -/HYPH speech/NN tagging/NN and/CC chunking/VBG indicate/VBP that/IN the/DT features/NNS are/VBP competitive/JJ with/IN or/CC better/JJR than/IN existing/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN representation/NN learning/NN methods/NNS ./.
