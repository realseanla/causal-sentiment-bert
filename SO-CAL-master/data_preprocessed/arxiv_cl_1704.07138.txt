We/PRP present/VBP Grid/NNP Beam/NNP Search/NNP (/-LRB- GBS/NNP )/-RRB- ,/, an/DT algorithm/NN which/WDT extends/VBZ beam/NN search/NN to/TO allow/VB the/DT inclusion/NN of/IN pre-specified/JJ lexical/JJ constraints/NNS ./.
The/DT algorithm/NN can/MD be/VB used/VBN with/IN any/DT model/NN that/WDT generates/VBZ a/DT sequence/NN $/$ \/CD mathbf/NN {/-LRB- \/SYM hat/NN {/-LRB- y/NN }/-RRB- }/-RRB- =/SYM \/SYM {/-LRB- y/NN _/NFP {/-LRB- 0/CD }/-RRB- \/SYM ldots/FW y/FW _/NFP {/-LRB- T/NN }/-RRB- \/SYM }/-RRB- $/$ ,/, by/IN maximizing/VBG $/$ p/NN (/-LRB- \/SYM mathbf/NN {/-LRB- y/NN }/-RRB- |/NFP \/SYM mathbf/NN {/-LRB- x/NN }/-RRB- )/-RRB- =/SYM \/SYM prod/NN \/SYM limits/NNS _/NFP {/-LRB- t/NN }/-RRB- p/NN (/-LRB- y/NN _/NFP {/-LRB- t/NN }/-RRB- |/NFP \/SYM mathbf/NN {/-LRB- x/NN }/-RRB- ;/: \/SYM {/-LRB- y/NN _/NFP {/-LRB- 0/CD }/-RRB- \/SYM ldots/FW y/FW _/NFP {/-LRB- t/NN -/HYPH 1/CD }/-RRB- \/SYM }/-RRB- )/-RRB- $/$ ./.
Lexical/JJ constraints/NNS take/VBP the/DT form/NN of/IN phrases/NNS or/CC words/NNS that/WDT must/MD be/VB present/JJ in/IN the/DT output/NN sequence/NN ./.
This/DT is/VBZ a/DT very/RB general/JJ way/NN to/TO incorporate/VB additional/JJ knowledge/NN into/IN a/DT model/NN 's/POS output/NN without/IN requiring/VBG any/DT modification/NN of/IN the/DT model/NN parameters/NNS or/CC training/NN data/NNS ./.
We/PRP demonstrate/VBP the/DT feasibility/NN and/CC flexibility/NN of/IN Lexically/NNP Constrained/NNP Decoding/NNP by/IN conducting/VBG experiments/NNS on/IN Neural/JJ Interactive/JJ -/HYPH Predictive/JJ Translation/NN ,/, as/RB well/RB as/IN Domain/NN Adaptation/NN for/IN Neural/JJ Machine/NN Translation/NN ./.
Experiments/NNS show/VBP that/IN GBS/NNP can/MD provide/VB large/JJ improvements/NNS in/IN translation/NN quality/NN in/IN interactive/JJ scenarios/NNS ,/, and/CC that/IN ,/, even/RB without/IN any/DT user/NN input/NN ,/, GBS/NNP can/MD be/VB used/VBN to/TO achieve/VB significant/JJ gains/NNS in/IN performance/NN in/IN domain/NN adaptation/NN scenarios/NNS ./.
