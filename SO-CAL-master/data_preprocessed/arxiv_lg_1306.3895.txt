We/PRP carefully/RB investigate/VB the/DT on/IN -/HYPH line/NN version/NN of/IN PCA/NNP ,/, where/WRB in/IN each/DT trial/NN a/DT learning/NN algorithm/NN plays/VBZ a/DT k/CD -/HYPH dimensional/JJ subspace/NN ,/, and/CC suffers/VBZ the/DT compression/NN loss/NN on/IN the/DT next/JJ instance/NN when/WRB projected/VBN into/IN the/DT chosen/VBN subspace/NN ./.
In/IN this/DT setting/NN ,/, we/PRP analyze/VBP two/CD popular/JJ on/IN -/HYPH line/NN algorithms/NNS ,/, Gradient/NNP Descent/NNP (/-LRB- GD/NNP )/-RRB- and/CC Exponentiated/NNP Gradient/NNP (/-LRB- EG/NNP )/-RRB- ./.
We/PRP show/VBP that/IN both/DT algorithms/NNS are/VBP essentially/RB optimal/JJ in/IN the/DT worst/JJS -/HYPH case/NN ./.
This/DT comes/VBZ as/IN a/DT surprise/NN ,/, since/IN EG/NNP is/VBZ known/VBN to/TO perform/VB sub-optimally/RB when/WRB the/DT instances/NNS are/VBP sparse/JJ ./.
This/DT different/JJ behavior/NN of/IN EG/NNP for/IN PCA/NNP is/VBZ mainly/RB related/VBN to/IN the/DT non-negativity/NN of/IN the/DT loss/NN in/IN this/DT case/NN ,/, which/WDT makes/VBZ the/DT PCA/NN setting/VBG qualitatively/RB different/JJ from/IN other/JJ settings/NNS studied/VBN in/IN the/DT literature/NN ./.
Furthermore/RB ,/, we/PRP show/VBP that/IN when/WRB considering/VBG regret/NN bounds/NNS as/IN function/NN of/IN a/DT loss/NN budget/NN ,/, EG/NN remains/VBZ optimal/JJ and/CC strictly/RB outperforms/VBZ GD/NNP ./.
Next/RB ,/, we/PRP study/VBP the/DT extension/NN of/IN the/DT PCA/NN setting/NN ,/, in/IN which/WDT the/DT Nature/NNP is/VBZ allowed/VBN to/TO play/VB with/IN dense/JJ instances/NNS ,/, which/WDT are/VBP positive/JJ matrices/NNS with/IN bounded/VBN largest/JJS eigenvalue/NN ./.
Again/RB we/PRP can/MD show/VB that/IN EG/NNP is/VBZ optimal/JJ and/CC strictly/RB better/JJR than/IN GD/NNP in/IN this/DT setting/NN ./.
