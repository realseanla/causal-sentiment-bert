Deep/JJ Neural/JJ Networks/NNS (/-LRB- DNNs/NNS )/-RRB- are/VBP presently/RB the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN for/IN image/NN classification/NN tasks/NNS ./.
However/RB ,/, recent/JJ works/NNS have/VBP shown/VBN that/IN these/DT systems/NNS can/MD be/VB easily/RB fooled/VBN to/IN misidentify/JJ images/NNS by/IN modifying/VBG the/DT image/NN in/IN a/DT particular/JJ way/NN ./.
Moreover/RB ,/, defense/NN mechanisms/NNS proposed/VBN in/IN the/DT literature/NN so/RB far/RB are/VBP mostly/RB attack/NN -/HYPH specific/JJ and/CC prove/VB to/TO be/VB ineffective/JJ against/IN new/JJ attacks/NNS ./.
Indeed/RB ,/, recent/JJ work/NN on/IN universal/JJ perturbations/NNS can/MD generate/VB a/DT single/JJ modification/NN for/IN all/DT test/NN images/NNS that/WDT is/VBZ able/JJ to/TO make/VB existing/VBG networks/NNS misclassify/VB 90/CD percent/NN of/IN the/DT time/NN ./.
Presently/RB ,/, to/IN our/PRP$ knowledge/NN ,/, no/DT defense/NN mechanisms/NNS are/VBP effective/JJ in/IN preventing/VBG this/DT ./.
As/IN such/JJ ,/, the/DT design/NN of/IN a/DT general/JJ defense/NN strategy/NN against/IN a/DT wide/JJ range/NN of/IN attacks/NNS for/IN Neural/JJ Networks/NNS becomes/VBZ a/DT challenging/JJ problem/NN ./.
In/IN this/DT paper/NN ,/, we/PRP derive/VBP inspiration/NN from/IN recent/JJ advances/NNS in/IN the/DT field/NN of/IN cybersecurity/NN and/CC multi-agent/JJ systems/NNS and/CC propose/VB to/TO use/VB the/DT concept/NN of/IN Moving/VBG Target/NNP Defense/NNP (/-LRB- MTD/NN )/-RRB- for/IN increasing/VBG the/DT robustness/NN of/IN well/RB -/HYPH known/VBN deep/JJ networks/NNS trained/VBN on/IN the/DT ImageNet/NNP dataset/NN towards/IN such/JJ adversarial/JJ attacks/NNS ./.
In/IN using/VBG this/DT technique/NN ,/, we/PRP formalize/VBP and/CC exploit/VBP the/DT notion/NN of/IN differential/JJ immunity/NN of/IN different/JJ networks/NNS to/IN specific/JJ attacks/NNS ./.
To/TO classify/VB a/DT single/JJ test/NN image/NN ,/, we/PRP pick/VBP one/CD of/IN the/DT trained/VBN networks/NNS each/DT time/NN and/CC then/RB use/VB its/PRP$ classification/NN output/NN ./.
To/TO ensure/VB maximum/JJ robustness/NN ,/, we/PRP generate/VBP an/DT effective/JJ strategy/NN by/IN formulating/VBG this/DT interaction/NN as/IN a/DT Repeated/VBN Bayesian/JJ Stackelberg/NNP Game/NN with/IN a/DT Defender/NN and/CC the/DT Users/NNS ./.
As/IN a/DT network/NN switching/VBG strategy/NN ,/, we/PRP compute/VBP a/DT Strong/JJ Stackelberg/NNP Equilibrium/NN that/WDT optimizes/VBZ the/DT accuracy/NN of/IN prediction/NN while/IN at/IN the/DT same/JJ time/NN reduces/VBZ the/DT misclassification/NN rate/NN on/IN adversarial/JJ modification/NN of/IN test/NN images/NNS ./.
We/PRP show/VBP that/IN while/IN our/PRP$ approach/NN produces/VBZ an/DT accuracy/NN of/IN 92.79/CD percent/NN for/IN the/DT legitimate/JJ users/NNS ,/, attackers/NNS can/MD only/RB misclassify/VB images/NNS 58/CD percent/NN (/-LRB- instead/RB of/IN 93.7/CD percent/NN )/-RRB- of/IN the/DT time/NN even/RB when/WRB they/PRP select/VBP the/DT best/JJS attack/NN available/JJ to/IN them/PRP ./.
