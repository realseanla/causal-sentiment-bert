This/DT paper/NN introduces/VBZ Grid/NNP Long/NNP Short/NNP -/HYPH Term/NNP Memory/NN ,/, a/DT network/NN of/IN LSTM/NN cells/NNS arranged/VBN in/IN a/DT multidimensional/JJ grid/NN that/WDT can/MD be/VB applied/VBN to/IN vectors/NNS ,/, sequences/NNS or/CC higher/JJR dimensional/JJ data/NNS such/JJ as/IN images/NNS ./.
The/DT network/NN differs/VBZ from/IN existing/VBG deep/JJ LSTM/NNP architectures/NNS in/IN that/IN the/DT cells/NNS are/VBP connected/VBN between/IN network/NN layers/NNS as/RB well/RB as/IN along/IN the/DT spatiotemporal/JJ dimensions/NNS of/IN the/DT data/NNS ./.
It/PRP therefore/RB provides/VBZ a/DT unified/JJ way/NN of/IN using/VBG LSTM/NNP for/IN both/DT deep/JJ and/CC sequential/JJ computation/NN ./.
We/PRP apply/VBP the/DT model/NN to/IN algorithmic/JJ tasks/NNS such/JJ as/IN integer/NN addition/NN and/CC determining/VBG the/DT parity/NN of/IN random/JJ binary/NN vectors/NNS ./.
It/PRP is/VBZ able/JJ to/TO solve/VB these/DT problems/NNS for/IN 15/CD -/HYPH digit/NN integers/NNS and/CC 250/CD -/HYPH bit/NN vectors/NNS respectively/RB ./.
We/PRP then/RB give/VBP results/NNS for/IN three/CD empirical/JJ tasks/NNS ./.
We/PRP find/VBP that/IN 2D/NN Grid/NNP LSTM/NNP achieves/VBZ 1.47/CD bits/NNS per/IN character/NN on/IN the/DT Wikipedia/NNP character/NN prediction/NN benchmark/NN ,/, which/WDT is/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN among/IN neural/JJ approaches/NNS ./.
We/PRP also/RB observe/VBP that/IN a/DT two/CD -/HYPH dimensional/JJ translation/NN model/NN based/VBN on/IN Grid/NNP LSTM/NNP outperforms/VBZ a/DT phrase/NN -/HYPH based/VBN reference/NN system/NN on/IN a/DT Chinese/JJ -/HYPH to/IN -/HYPH English/NNP translation/NN task/NN ,/, and/CC that/DT 3D/NN Grid/NNP LSTM/NNP yields/VBZ a/DT near/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN error/NN rate/NN of/IN 0.32/CD percent/NN on/IN MNIST/NNP ./.
