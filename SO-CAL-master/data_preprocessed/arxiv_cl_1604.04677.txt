We/PRP demonstrate/VBP that/IN an/DT attention/NN -/HYPH based/VBN encoder/NN -/HYPH decoder/NN model/NN can/MD be/VB used/VBN for/IN sentence/NN -/HYPH level/NN grammatical/JJ error/NN identification/NN for/IN the/DT Automated/VBN Evaluation/NN of/IN Scientific/NNP Writing/VBG (/-LRB- AESW/NNP )/-RRB- Shared/NNP Task/NNP 2016/CD ./.
The/DT attention/NN -/HYPH based/VBN encoder/NN -/HYPH decoder/NN models/NNS can/MD be/VB used/VBN for/IN the/DT generation/NN of/IN corrections/NNS ,/, in/IN addition/NN to/IN error/NN identification/NN ,/, which/WDT is/VBZ of/IN interest/NN for/IN certain/JJ end/NN -/HYPH user/NN applications/NNS ./.
We/PRP show/VBP that/IN a/DT character/NN -/HYPH based/VBN encoder/NN -/HYPH decoder/NN model/NN is/VBZ particularly/RB effective/JJ ,/, outperforming/VBG other/JJ results/NNS on/IN the/DT AESW/NNP Shared/NNP Task/NNP on/IN its/PRP$ own/JJ ,/, and/CC showing/VBG gains/NNS over/IN a/DT word/NN -/HYPH based/VBN counterpart/NN ./.
Our/PRP$ final/JJ model/NN --/: a/DT combination/NN of/IN three/CD character/NN -/HYPH based/VBN encoder/NN -/HYPH decoder/NN models/NNS ,/, one/CD word/NN -/HYPH based/VBN encoder/NN -/HYPH decoder/NN model/NN ,/, and/CC a/DT sentence/NN -/HYPH level/NN CNN/NNP --/: is/VBZ the/DT highest/JJS performing/VBG system/NN on/IN the/DT AESW/NNP 2016/CD binary/JJ prediction/NN Shared/NNP Task/NNP ./.
