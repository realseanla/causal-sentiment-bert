We/PRP describe/VBP a/DT method/NN to/TO train/VB spiking/VBG deep/JJ networks/NNS that/WDT can/MD be/VB run/VBN using/VBG leaky/JJ integrate/VB -/HYPH and/CC -/HYPH fire/NN (/-LRB- LIF/NN )/-RRB- neurons/NNS ,/, achieving/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS for/IN spiking/VBG LIF/NN networks/NNS on/IN five/CD datasets/NNS ,/, including/VBG the/DT large/JJ ImageNet/NNP ILSVRC/NNP -/HYPH 2012/CD benchmark/NN ./.
Our/PRP$ method/NN for/IN transforming/VBG deep/JJ artificial/JJ neural/JJ networks/NNS into/IN spiking/NN networks/NNS is/VBZ scalable/JJ and/CC works/VBZ with/IN a/DT wide/JJ range/NN of/IN neural/JJ nonlinearities/NNS ./.
We/PRP achieve/VBP these/DT results/NNS by/IN softening/VBG the/DT neural/JJ response/NN function/NN ,/, such/JJ that/IN its/PRP$ derivative/JJ remains/NNS bounded/VBD ,/, and/CC by/IN training/VBG the/DT network/NN with/IN noise/NN to/TO provide/VB robustness/NN against/IN the/DT variability/NN introduced/VBN by/IN spikes/NNS ./.
Our/PRP$ analysis/NN shows/VBZ that/IN implementations/NNS of/IN these/DT networks/NNS on/IN neuromorphic/JJ hardware/NN will/MD be/VB many/JJ times/NNS more/JJR power/NN -/HYPH efficient/JJ than/IN the/DT equivalent/JJ non-spiking/JJ networks/NNS on/IN traditional/JJ hardware/NN ./.
