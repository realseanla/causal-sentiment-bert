This/DT work/NN provides/VBZ simple/JJ algorithms/NNS for/IN multi-class/NN (/-LRB- and/CC multi-label/NN )/-RRB- prediction/NN in/IN settings/NNS where/WRB both/PDT the/DT number/NN of/IN examples/NNS n/NN and/CC the/DT data/NNS dimension/NN d/NN are/VBP relatively/RB large/JJ ./.
These/DT robust/JJ and/CC parameter/NN free/JJ algorithms/NNS are/VBP essentially/RB iterative/JJ least/RBS -/HYPH squares/NNS updates/NNS and/CC very/RB versatile/JJ both/CC in/IN theory/NN and/CC in/IN practice/NN ./.
On/IN the/DT theoretical/JJ front/NN ,/, we/PRP present/VBP several/JJ variants/NNS with/IN convergence/NN guarantees/NNS ./.
Owing/VBG to/IN their/PRP$ effective/JJ use/NN of/IN second/JJ -/HYPH order/NN structure/NN ,/, these/DT algorithms/NNS are/VBP substantially/RB better/JJR than/IN first/JJ -/HYPH order/NN methods/NNS in/IN many/JJ practical/JJ scenarios/NNS ./.
On/IN the/DT empirical/JJ side/NN ,/, we/PRP present/VBP a/DT scalable/JJ stagewise/NN variant/NN of/IN our/PRP$ approach/NN ,/, which/WDT achieves/VBZ dramatic/JJ computational/JJ speedups/NNS over/IN popular/JJ optimization/NN packages/NNS such/JJ as/IN Liblinear/NNP and/CC Vowpal/NNP Wabbit/NNP on/IN standard/JJ datasets/NNS (/-LRB- MNIST/NN and/CC CIFAR/NN -/HYPH 10/CD )/-RRB- ,/, while/IN attaining/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN accuracies/NNS ./.
