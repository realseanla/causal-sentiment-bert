Dual/JJ decomposition/NN ,/, and/CC more/RBR generally/RB Lagrangian/JJ relaxation/NN ,/, is/VBZ a/DT classical/JJ method/NN for/IN combinatorial/JJ optimization/NN ;/: it/PRP has/VBZ recently/RB been/VBN applied/VBN to/IN several/JJ inference/NN problems/NNS in/IN natural/JJ language/NN processing/NN (/-LRB- NLP/NN )/-RRB- ./.
This/DT tutorial/NN gives/VBZ an/DT overview/NN of/IN the/DT technique/NN ./.
We/PRP describe/VBP example/NN algorithms/NNS ,/, describe/VB formal/JJ guarantees/NNS for/IN the/DT method/NN ,/, and/CC describe/VB practical/JJ issues/NNS in/IN implementing/VBG the/DT algorithms/NNS ./.
While/IN our/PRP$ examples/NNS are/VBP predominantly/RB drawn/VBN from/IN the/DT NLP/NNP literature/NN ,/, the/DT material/NN should/MD be/VB of/IN general/JJ relevance/NN to/IN inference/NN problems/NNS in/IN machine/NN learning/NN ./.
A/DT central/JJ theme/NN of/IN this/DT tutorial/NN is/VBZ that/IN Lagrangian/NNP relaxation/NN is/VBZ naturally/RB applied/VBN in/IN conjunction/NN with/IN a/DT broad/JJ class/NN of/IN combinatorial/JJ algorithms/NNS ,/, allowing/VBG inference/NN in/IN models/NNS that/WDT go/VBP significantly/RB beyond/IN previous/JJ work/NN on/IN Lagrangian/NNP relaxation/NN for/IN inference/NN in/IN graphical/JJ models/NNS ./.
