For/IN an/DT autonomous/JJ system/NN to/TO be/VB helpful/JJ to/IN humans/NNS and/CC to/TO pose/VB no/DT unwarranted/JJ risks/NNS ,/, it/PRP needs/VBZ to/TO align/VB its/PRP$ values/NNS with/IN those/DT of/IN the/DT humans/NNS in/IN its/PRP$ environment/NN in/IN such/PDT a/DT way/NN that/IN its/PRP$ actions/NNS contribute/VBP to/IN the/DT maximization/NN of/IN value/NN for/IN the/DT humans/NNS ./.
We/PRP propose/VBP a/DT formal/JJ definition/NN of/IN the/DT value/NN alignment/NN problem/NN as/IN {/-LRB- \/SYM em/PRP cooperative/JJ inverse/JJ reinforcement/NN learning/VBG }/-RRB- (/-LRB- CIRL/NN )/-RRB- ./.
A/DT CIRL/NN problem/NN is/VBZ a/DT cooperative/JJ ,/, partial/JJ -/HYPH information/NN game/NN with/IN two/CD agents/NNS ,/, human/JJ and/CC robot/NN ;/: both/DT are/VBP rewarded/VBN according/VBG to/IN the/DT human/NN 's/POS reward/NN function/NN ,/, but/CC the/DT robot/NN does/VBZ not/RB initially/RB know/VB what/WP this/DT is/VBZ ./.
In/IN contrast/NN to/IN classical/JJ IRL/NN ,/, where/WRB the/DT human/NN is/VBZ assumed/VBN to/TO act/VB optimally/RB in/IN isolation/NN ,/, optimal/JJ CIRL/NN solutions/NNS produce/VBP behaviors/NNS such/JJ as/IN active/JJ teaching/NN ,/, active/JJ learning/NN ,/, and/CC communicative/JJ actions/NNS that/WDT are/VBP more/RBR effective/JJ in/IN achieving/VBG value/NN alignment/NN ./.
We/PRP show/VBP that/IN computing/VBG optimal/JJ joint/JJ policies/NNS in/IN CIRL/NN games/NNS can/MD be/VB reduced/VBN to/IN solving/VBG a/DT POMDP/NN ,/, prove/VB that/IN optimality/NN in/IN isolation/NN is/VBZ suboptimal/JJ in/IN CIRL/NN ,/, and/CC derive/VBP an/DT approximate/JJ CIRL/NN algorithm/NN ./.
