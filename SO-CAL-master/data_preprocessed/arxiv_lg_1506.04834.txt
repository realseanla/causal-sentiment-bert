Tree/NN -/HYPH structured/VBN neural/JJ networks/NNS encode/VBP a/DT particular/JJ tree/NN geometry/NN for/IN a/DT sentence/NN in/IN the/DT network/NN design/NN ./.
However/RB ,/, these/DT models/NNS have/VBP at/RB best/RBS only/RB slightly/RB outperformed/VBN simpler/JJR sequence/NN -/HYPH based/VBN models/NNS ./.
We/PRP hypothesize/VBP that/IN neural/JJ sequence/NN models/NNS like/IN LSTMs/NNS are/VBP in/IN fact/NN able/JJ to/TO discover/VB and/CC implicitly/RB use/VB recursive/JJ compositional/JJ structure/NN ,/, at/IN least/RBS for/IN tasks/NNS with/IN clear/JJ cues/NNS to/IN that/DT structure/NN in/IN the/DT data/NNS ./.
We/PRP demonstrate/VBP this/DT possibility/NN using/VBG an/DT artificial/JJ data/NNS task/NN for/IN which/WDT recursive/JJ compositional/JJ structure/NN is/VBZ crucial/JJ ,/, and/CC find/VB that/IN the/DT sequence/NN model/NN can/MD learn/VB the/DT underlying/VBG patterning/NN ./.
The/DT sequence/NN model/NN is/VBZ better/JJR in/IN that/IN it/PRP learns/VBZ the/DT value/NN of/IN tree/NN structure/NN from/IN the/DT data/NNS in/IN an/DT emergent/JJ way/NN ,/, while/IN the/DT tree/NN -/HYPH structured/VBN model/NN is/VBZ better/JJR in/IN being/VBG able/JJ to/TO learn/VB with/IN greater/JJR statistical/JJ efficiency/NN due/IN to/IN its/PRP$ informative/JJ prior/JJ model/NN structure/NN ./.
