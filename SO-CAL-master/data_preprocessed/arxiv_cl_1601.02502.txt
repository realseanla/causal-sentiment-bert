We/PRP introduce/VBP Trans/NN -/HYPH gram/NN ,/, a/DT simple/JJ and/CC computationally/RB -/HYPH efficient/JJ method/NN to/TO simultaneously/RB learn/VB and/CC align/VB wordembeddings/NNS for/IN a/DT variety/NN of/IN languages/NNS ,/, using/VBG only/RB monolingual/JJ data/NNS and/CC a/DT smaller/JJR set/NN of/IN sentence/NN -/HYPH aligned/VBN data/NNS ./.
We/PRP use/VBP our/PRP$ new/JJ method/NN to/TO compute/VB aligned/VBN wordembeddings/NNS for/IN twenty/CD -/HYPH one/CD languages/NNS using/VBG English/NNP as/IN a/DT pivot/NN language/NN ./.
We/PRP show/VBP that/IN some/DT linguistic/JJ features/NNS are/VBP aligned/VBN across/IN languages/NNS for/IN which/WDT we/PRP do/VBP not/RB have/VB aligned/VBN data/NNS ,/, even/RB though/IN those/DT properties/NNS do/VBP not/RB exist/VB in/IN the/DT pivot/NN language/NN ./.
We/PRP also/RB achieve/VBP state/NN of/IN the/DT art/NN results/NNS on/IN standard/JJ cross-lingual/JJ text/NN classification/NN and/CC word/NN translation/NN tasks/NNS ./.
