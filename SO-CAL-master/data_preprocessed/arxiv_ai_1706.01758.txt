In/IN this/DT paper/NN ,/, we/PRP explore/VBP SPPIM/NNP -/HYPH based/VBN text/NN classification/NN method/NN ,/, and/CC the/DT experiment/NN reveals/VBZ that/IN the/DT SPPIM/NNP method/NN is/VBZ equal/JJ to/IN or/CC even/RB superior/JJ than/IN SGNS/NN method/NN in/IN text/NN classification/NN task/NN on/IN three/CD international/JJ and/CC standard/JJ text/NN datasets/NNS ,/, namely/RB 20newsgroups/NNS ,/, Reuters52/NN and/CC WebKB/NN ./.
Comparing/VBG to/IN SGNS/NN ,/, although/IN SPPMI/NNP provides/VBZ a/DT better/JJR solution/NN ,/, it/PRP is/VBZ not/RB necessarily/RB better/JJR than/IN SGNS/NN in/IN text/NN classification/NN tasks/NNS ./.
Based/VBN on/IN our/PRP$ analysis/NN ,/, SGNS/NN takes/VBZ into/IN the/DT consideration/NN of/IN weight/NN calculation/NN during/IN decomposition/NN process/NN ,/, so/IN it/PRP has/VBZ better/JJR performance/NN than/IN SPPIM/NNP in/IN some/DT standard/JJ datasets/NNS ./.
Inspired/VBN by/IN this/DT ,/, we/PRP propose/VBP a/DT WL/NNP -/HYPH SPPIM/NNP semantic/JJ model/NN based/VBN on/IN SPPIM/NNP model/NN ,/, and/CC experiment/NN shows/VBZ that/IN WL/NNP -/HYPH SPPIM/NNP approach/NN has/VBZ better/JJR classification/NN and/CC higher/JJR scalability/NN in/IN the/DT text/NN classification/NN task/NN compared/VBN with/IN LDA/NN ,/, SGNS/NN and/CC SPPIM/NN approaches/NNS ./.
