We/PRP study/VBP a/DT novel/JJ multi-armed/JJ bandit/NN problem/NN that/WDT models/NNS the/DT challenge/NN faced/VBN by/IN a/DT company/NN wishing/VBG to/TO explore/VB new/JJ strategies/NNS to/TO maximize/VB revenue/NN whilst/IN simultaneously/RB maintaining/VBG their/PRP$ revenue/NN above/IN a/DT fixed/VBN baseline/NN ,/, uniformly/RB over/IN time/NN ./.
While/IN previous/JJ work/NN addressed/VBD the/DT problem/NN under/IN the/DT weaker/JJR requirement/NN of/IN maintaining/VBG the/DT revenue/NN constraint/NN only/RB at/IN a/DT given/VBN fixed/VBN time/NN in/IN the/DT future/NN ,/, the/DT algorithms/NNS previously/RB proposed/VBN are/VBP unsuitable/JJ due/IN to/IN their/PRP$ design/NN under/IN the/DT more/RBR stringent/JJ constraints/NNS ./.
We/PRP consider/VBP both/CC the/DT stochastic/JJ and/CC the/DT adversarial/JJ settings/NNS ,/, where/WRB we/PRP propose/VBP ,/, natural/JJ ,/, yet/CC novel/JJ strategies/NNS and/CC analyze/VB the/DT price/NN for/IN maintaining/VBG the/DT constraints/NNS ./.
Amongst/IN other/JJ things/NNS ,/, we/PRP prove/VBP both/DT high/JJ probability/NN and/CC expectation/NN bounds/NNS on/IN the/DT regret/NN ,/, while/IN we/PRP also/RB consider/VBP both/CC the/DT problem/NN of/IN maintaining/VBG the/DT constraints/NNS with/IN high/JJ probability/NN or/CC expectation/NN ./.
For/IN the/DT adversarial/JJ setting/VBG the/DT price/NN of/IN maintaining/VBG the/DT constraint/NN appears/VBZ to/TO be/VB higher/JJR ,/, at/IN least/RBS for/IN the/DT algorithm/NN considered/VBN ./.
A/DT lower/JJR bound/JJ is/VBZ given/VBN showing/VBG that/IN the/DT algorithm/NN for/IN the/DT stochastic/JJ setting/NN is/VBZ almost/RB optimal/JJ ./.
Empirical/JJ results/NNS obtained/VBN in/IN synthetic/JJ environments/NNS complement/VBP our/PRP$ theoretical/JJ findings/NNS ./.
