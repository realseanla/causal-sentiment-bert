This/DT paper/NN presents/VBZ a/DT framework/NN for/IN computing/VBG random/JJ operator/NN -/HYPH valued/VBN feature/NN maps/VBZ for/IN operator/NN -/HYPH valued/VBN positive/JJ definite/JJ kernels/NNS ./.
This/DT is/VBZ a/DT generalization/NN of/IN the/DT random/JJ Fourier/NN features/NNS for/IN scalar/JJ -/HYPH valued/VBN kernels/NNS to/IN the/DT operator/NN -/HYPH valued/VBN case/NN ./.
Our/PRP$ general/JJ setting/NN is/VBZ that/IN of/IN operator/NN -/HYPH valued/VBN kernels/NNS corresponding/VBG to/IN RKHS/NNP of/IN functions/NNS with/IN values/NNS in/IN a/DT Hilbert/NNP space/NN ./.
We/PRP show/VBP that/IN in/IN general/JJ ,/, for/IN a/DT given/VBN kernel/NN ,/, there/EX are/VBP potentially/RB infinitely/RB many/JJ random/JJ feature/NN maps/NNS ,/, which/WDT can/MD be/VB bounded/VBN or/CC unbounded/JJ ./.
Most/RBS importantly/RB ,/, given/VBN a/DT kernel/NN ,/, we/PRP present/VBP a/DT general/JJ ,/, closed/JJ form/NN formula/NN for/IN computing/VBG a/DT corresponding/VBG probability/NN measure/NN ,/, which/WDT is/VBZ required/VBN for/IN the/DT construction/NN of/IN the/DT Fourier/NNP features/NNS ,/, and/CC which/WDT ,/, unlike/IN the/DT scalar/JJ case/NN ,/, is/VBZ not/RB uniquely/RB and/CC automatically/RB determined/VBN by/IN the/DT kernel/NN ./.
We/PRP also/RB show/VBP that/IN ,/, under/IN appropriate/JJ conditions/NNS ,/, random/JJ bounded/VBD feature/NN maps/NNS can/MD always/RB be/VB computed/VBN ./.
Furthermore/RB ,/, we/PRP show/VBP the/DT uniform/JJ convergence/NN ,/, under/IN the/DT Hilbert/NNP -/HYPH Schmidt/NNP norm/NN ,/, of/IN the/DT resulting/VBG approximate/JJ kernel/NN to/IN the/DT exact/JJ kernel/NN on/IN any/DT compact/JJ subset/NN of/IN Euclidean/NNP space/NN ./.
Our/PRP$ convergence/NN requires/VBZ differentiable/JJ kernels/NNS ,/, an/DT improvement/NN over/IN the/DT twice/RB -/HYPH differentiability/NN requirement/NN in/IN previous/JJ work/NN in/IN the/DT scalar/JJ setting/NN ./.
We/PRP then/RB show/VBP how/WRB operator/NN -/HYPH valued/VBN feature/NN maps/NNS and/CC their/PRP$ approximations/NNS can/MD be/VB employed/VBN in/IN a/DT general/JJ vector/NN -/HYPH valued/VBN learning/NN framework/NN ./.
The/DT mathematical/JJ formulation/NN is/VBZ illustrated/VBN by/IN numerical/JJ examples/NNS on/IN matrix/NN -/HYPH valued/VBN kernels/NNS ./.
