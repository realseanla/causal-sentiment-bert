We/PRP address/VBP personalization/NN issues/NNS of/IN image/NN captioning/NN ,/, which/WDT have/VBP not/RB been/VBN discussed/VBN yet/RB in/IN previous/JJ research/NN ./.
For/IN a/DT query/NN image/NN ,/, we/PRP aim/VBP to/TO generate/VB a/DT descriptive/JJ sentence/NN ,/, accounting/VBG for/IN prior/JJ knowledge/NN such/JJ as/IN the/DT user/NN 's/POS active/JJ vocabularies/NNS in/IN previous/JJ documents/NNS ./.
As/IN applications/NNS of/IN personalized/VBN image/NN captioning/NN ,/, we/PRP tackle/VBP two/CD post/NN automation/NN tasks/NNS :/: hashtag/NN prediction/NN and/CC post/NN generation/NN ,/, on/IN our/PRP$ newly/RB collected/VBN Instagram/NNP dataset/NN ,/, consisting/VBG of/IN 1.1/CD M/NN posts/NNS from/IN 6.3/CD K/NNP users/NNS ./.
We/PRP propose/VBP a/DT novel/JJ captioning/NN model/NN named/VBN Context/NNP Sequence/NN Memory/NNP Network/NNP (/-LRB- CSMN/NNP )/-RRB- ./.
Its/PRP$ unique/JJ updates/NNS over/IN previous/JJ memory/NN network/NN models/NNS include/VBP (/-LRB- i/LS )/-RRB- exploiting/VBG memory/NN as/IN a/DT repository/NN for/IN multiple/JJ types/NNS of/IN context/NN information/NN ,/, (/-LRB- ii/LS )/-RRB- appending/VBG previously/RB generated/VBN words/NNS into/IN memory/NN to/TO capture/VB long/RB -/HYPH term/NN information/NN without/IN suffering/VBG from/IN the/DT vanishing/VBG gradient/NN problem/NN ,/, and/CC (/-LRB- iii/LS )/-RRB- adopting/VBG CNN/NNP memory/NN structure/NN to/TO jointly/RB represent/VB nearby/JJ ordered/VBN memory/NN slots/NNS for/IN better/JJR context/NN understanding/NN ./.
With/IN quantitative/JJ evaluation/NN and/CC user/NN studies/NNS via/IN Amazon/NNP Mechanical/NNP Turk/NNP ,/, we/PRP show/VBP the/DT effectiveness/NN of/IN the/DT three/CD novel/JJ features/NNS of/IN CSMN/NNP and/CC its/PRP$ performance/NN enhancement/NN for/IN personalized/VBN image/NN captioning/NN over/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN captioning/NN models/NNS ./.
