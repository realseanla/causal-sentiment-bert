When/WRB a/DT neural/JJ language/NN model/NN is/VBZ used/VBN for/IN caption/NN generation/NN ,/, the/DT image/NN information/NN can/MD be/VB fed/VBN to/IN the/DT neural/JJ network/NN either/CC by/IN directly/RB incorporating/VBG it/PRP in/IN a/DT recurrent/JJ neural/JJ network/NN --/: conditioning/VBG the/DT language/NN model/NN by/IN injecting/VBG image/NN features/NNS --/: or/CC in/IN a/DT layer/NN following/VBG the/DT recurrent/JJ neural/JJ network/NN --/: conditioning/VBG the/DT language/NN model/NN by/IN merging/VBG the/DT image/NN features/NNS ./.
While/IN merging/VBG implies/VBZ that/IN visual/JJ features/NNS are/VBP bound/VBN at/IN the/DT end/NN of/IN the/DT caption/NN generation/NN process/NN ,/, injecting/VBG can/MD bind/VB the/DT visual/JJ features/NNS at/IN a/DT variety/NN stages/NNS ./.
In/IN this/DT paper/NN we/PRP empirically/RB show/VBP that/IN late/JJ binding/NN is/VBZ superior/JJ to/IN early/JJ binding/NN in/IN terms/NNS of/IN different/JJ evaluation/NN metrics/NNS ./.
This/DT suggests/VBZ that/IN the/DT different/JJ modalities/NNS (/-LRB- visual/JJ and/CC linguistic/JJ )/-RRB- for/IN caption/NN generation/NN should/MD not/RB be/VB jointly/RB encoded/VBN by/IN the/DT RNN/NN ;/: rather/RB ,/, the/DT multimodal/JJ integration/NN should/MD be/VB delayed/VBN to/IN a/DT subsequent/JJ stage/NN ./.
Furthermore/RB ,/, this/DT suggests/VBZ that/IN recurrent/JJ neural/JJ networks/NNS should/MD not/RB be/VB viewed/VBN as/IN actually/RB generating/VBG text/NN ,/, but/CC only/RB as/IN encoding/VBG it/PRP for/IN prediction/NN in/IN a/DT subsequent/JJ layer/NN ./.
