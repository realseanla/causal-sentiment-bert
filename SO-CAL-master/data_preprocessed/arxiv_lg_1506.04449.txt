Convolutional/JJ neural/JJ networks/NNS (/-LRB- CNN/NNP )/-RRB- are/VBP increasingly/RB used/VBN in/IN many/JJ areas/NNS of/IN computer/NN vision/NN ./.
They/PRP are/VBP particularly/RB attractive/JJ because/IN of/IN their/PRP$ ability/NN to/TO "/`` absorb/VB "/'' great/JJ quantities/NNS of/IN labeled/VBN data/NNS through/IN millions/NNS of/IN parameters/NNS ./.
However/RB ,/, as/IN model/NN sizes/VBZ increase/NN ,/, so/RB do/VB the/DT storage/NN and/CC memory/NN requirements/NNS of/IN the/DT classifiers/NNS ./.
We/PRP present/VBP a/DT novel/JJ network/NN architecture/NN ,/, Frequency/NN -/HYPH Sensitive/JJ Hashed/JJ Nets/NNS (/-LRB- FreshNets/NNP )/-RRB- ,/, which/WDT exploits/VBZ inherent/JJ redundancy/NN in/IN both/CC convolutional/JJ layers/NNS and/CC fully/RB -/HYPH connected/VBN layers/NNS of/IN a/DT deep/JJ learning/NN model/NN ,/, leading/VBG to/IN dramatic/JJ savings/NNS in/IN memory/NN and/CC storage/NN consumption/NN ./.
Based/VBN on/IN the/DT key/JJ observation/NN that/IN the/DT weights/NNS of/IN learned/VBN convolutional/JJ filters/NNS are/VBP typically/RB smooth/JJ and/CC low/JJ -/HYPH frequency/NN ,/, we/PRP first/RB convert/VBP filter/NN weights/NNS to/IN the/DT frequency/NN domain/NN with/IN a/DT discrete/JJ cosine/NN transform/VB (/-LRB- DCT/NNP )/-RRB- and/CC use/VB a/DT low/JJ -/HYPH cost/NN hash/NN function/NN to/IN randomly/RB group/NN frequency/NN parameters/NNS into/IN hash/NN buckets/NNS ./.
All/DT parameters/NNS assigned/VBD the/DT same/JJ hash/NN bucket/NN share/NN a/DT single/JJ value/NN learned/VBN with/IN standard/JJ back/RB -/HYPH propagation/NN ./.
To/TO further/RB reduce/VB model/NN size/NN we/PRP allocate/VBP fewer/JJR hash/NN buckets/NNS to/IN high/JJ -/HYPH frequency/NN components/NNS ,/, which/WDT are/VBP generally/RB less/RBR important/JJ ./.
We/PRP evaluate/VBP FreshNets/NNP on/IN eight/CD data/NNS sets/NNS ,/, and/CC show/VBP that/IN it/PRP leads/VBZ to/IN drastically/RB better/JJR compressed/VBN performance/NN than/IN several/JJ relevant/JJ baselines/NNS ./.
