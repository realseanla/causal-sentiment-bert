Non-stationary/JJ domains/NNS ,/, where/WRB unforeseen/JJ changes/NNS happen/VB ,/, present/VB a/DT challenge/NN for/IN agents/NNS to/TO find/VB an/DT optimal/JJ policy/NN for/IN a/DT sequential/JJ decision/NN making/VBG problem/NN ./.
This/DT work/NN investigates/VBZ a/DT solution/NN to/IN this/DT problem/NN that/WDT combines/VBZ Markov/NNP Decision/NN Processes/NNS (/-LRB- MDP/NN )/-RRB- and/CC Reinforcement/NN Learning/NN (/-LRB- RL/NN )/-RRB- with/IN Answer/NN Set/VBN Programming/NN (/-LRB- ASP/NN )/-RRB- in/IN a/DT method/NN we/PRP call/VBP ASP/NNP (/-LRB- RL/NNP )/-RRB- ./.
In/IN this/DT method/NN ,/, Answer/NN Set/VBN Programming/NN is/VBZ used/VBN to/TO find/VB the/DT possible/JJ trajectories/NNS of/IN an/DT MDP/NN ,/, from/IN where/WRB Reinforcement/NN Learning/NN is/VBZ applied/VBN to/TO learn/VB the/DT optimal/JJ policy/NN of/IN the/DT problem/NN ./.
Results/NNS show/VBP that/IN ASP/NN (/-LRB- RL/NN )/-RRB- is/VBZ capable/JJ of/IN efficiently/RB finding/VBG the/DT optimal/JJ solution/NN of/IN an/DT MDP/NN representing/VBG non-stationary/JJ domains/NNS ./.
