Deep/JJ kernel/NN learning/NN combines/VBZ the/DT non-parametric/JJ flexibility/NN of/IN kernel/NN methods/NNS with/IN the/DT inductive/JJ biases/NNS of/IN deep/JJ learning/NN architectures/NNS ./.
We/PRP propose/VBP a/DT novel/JJ deep/JJ kernel/NN learning/NN model/NN and/CC stochastic/JJ variational/JJ inference/NN procedure/NN which/WDT generalizes/VBZ deep/JJ kernel/NN learning/VBG approaches/NNS to/TO enable/VB classification/NN ,/, multi-task/VB learning/NN ,/, additive/JJ covariance/NN structures/NNS ,/, and/CC stochastic/JJ gradient/NN training/NN ./.
Specifically/RB ,/, we/PRP apply/VBP additive/JJ base/NN kernels/NNS to/IN subsets/NNS of/IN output/NN features/NNS from/IN deep/JJ neural/JJ architectures/NNS ,/, and/CC jointly/RB learn/VB the/DT parameters/NNS of/IN the/DT base/NN kernels/NNS and/CC deep/JJ network/NN through/IN a/DT Gaussian/JJ process/NN marginal/JJ likelihood/NN objective/NN ./.
Within/IN this/DT framework/NN ,/, we/PRP derive/VBP an/DT efficient/JJ form/NN of/IN stochastic/JJ variational/JJ inference/NN which/WDT leverages/VBZ local/JJ kernel/NN interpolation/NN ,/, inducing/VBG points/NNS ,/, and/CC structure/NN exploiting/VBG algebra/NN ./.
We/PRP show/VBP improved/VBN performance/NN over/IN stand/NN alone/RB deep/JJ networks/NNS ,/, SVMs/NNS ,/, and/CC state/NN of/IN the/DT art/NN scalable/JJ Gaussian/JJ processes/NNS on/IN several/JJ classification/NN benchmarks/NNS ,/, including/VBG an/DT airline/NN delay/NN dataset/NN containing/VBG 6/CD million/CD training/NN points/NNS ,/, CIFAR/NNP ,/, and/CC ImageNet/NNP ./.
