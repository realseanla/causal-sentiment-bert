Neural/JJ machine/NN translation/NN (/-LRB- NMT/NN )/-RRB- often/RB makes/VBZ mistakes/NNS in/IN translating/VBG low/JJ -/HYPH frequency/NN content/NN words/NNS that/WDT are/VBP essential/JJ to/IN understanding/VBG the/DT meaning/NN of/IN the/DT sentence/NN ./.
We/PRP propose/VBP a/DT method/NN to/TO alleviate/VB this/DT problem/NN by/IN augmenting/VBG NMT/NN systems/NNS with/IN discrete/JJ translation/NN lexicons/NNS that/WDT efficiently/RB encode/VBP translations/NNS of/IN these/DT low/JJ -/HYPH frequency/NN words/NNS ./.
We/PRP describe/VBP a/DT method/NN to/TO calculate/VB the/DT lexicon/NN probability/NN of/IN the/DT next/JJ word/NN in/IN the/DT translation/NN candidate/NN by/IN using/VBG the/DT attention/NN vector/NN of/IN the/DT NMT/NN model/NN to/TO select/VB which/WDT source/NN word/NN lexical/JJ probabilities/NNS the/DT model/NN should/MD focus/VB on/IN ./.
We/PRP test/VBP two/CD methods/NNS to/TO combine/VB this/DT probability/NN with/IN the/DT standard/JJ NMT/NNP probability/NN :/: (/-LRB- 1/LS )/-RRB- using/VBG it/PRP as/IN a/DT bias/NN ,/, and/CC (/-LRB- 2/LS )/-RRB- linear/JJ interpolation/NN ./.
Experiments/NNS on/IN two/CD corpora/NNS show/VBP an/DT improvement/NN of/IN 2.0/CD -/HYPH 2.3/CD BLEU/NN and/CC 0.13/CD -/HYPH 0.44/CD NIST/NN score/NN ,/, and/CC faster/RBR convergence/NN time/NN ./.
