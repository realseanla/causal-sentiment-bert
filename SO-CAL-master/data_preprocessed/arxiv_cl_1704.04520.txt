Neural/JJ machine/NN translation/NN (/-LRB- NMT/NN )/-RRB- ,/, a/DT new/JJ approach/NN to/IN machine/NN translation/NN ,/, has/VBZ achieved/VBN promising/JJ results/NNS comparable/JJ to/IN those/DT of/IN traditional/JJ approaches/NNS such/JJ as/IN statistical/JJ machine/NN translation/NN (/-LRB- SMT/NN )/-RRB- ./.
Despite/IN its/PRP$ recent/JJ success/NN ,/, NMT/NN can/MD not/RB handle/VB a/DT larger/JJR vocabulary/NN because/IN the/DT training/NN complexity/NN and/CC decoding/NN complexity/NN proportionally/RB increase/VB with/IN the/DT number/NN of/IN target/NN words/NNS ./.
This/DT problem/NN becomes/VBZ even/RB more/RBR serious/JJ when/WRB translating/VBG patent/NN documents/NNS ,/, which/WDT contain/VBP many/JJ technical/JJ terms/NNS that/WDT are/VBP observed/VBN infrequently/RB ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP to/TO select/VB phrases/NNS that/WDT contain/VBP out/RB -/HYPH of/IN -/HYPH vocabulary/NN words/NNS using/VBG the/DT statistical/JJ approach/NN of/IN branching/NN entropy/NN ./.
This/DT allows/VBZ the/DT proposed/VBN NMT/NN system/NN to/TO be/VB applied/VBN to/IN a/DT translation/NN task/NN of/IN any/DT language/NN pair/NN without/IN any/DT language/NN -/HYPH specific/JJ knowledge/NN about/IN technical/JJ term/NN identification/NN ./.
The/DT selected/VBN phrases/NNS are/VBP then/RB replaced/VBN with/IN tokens/NNS during/IN training/NN and/CC post-translated/VBN by/IN the/DT phrase/NN translation/NN table/NN of/IN SMT/NNP ./.
Evaluation/NN on/IN Japanese/JJ -/HYPH to/TO -/HYPH Chinese/JJ and/CC Chinese/JJ -/HYPH to/IN -/HYPH Japanese/JJ patent/NN sentence/NN translation/NN proved/VBD the/DT effectiveness/NN of/IN phrases/NNS selected/VBN with/IN branching/NN entropy/NN ,/, where/WRB the/DT proposed/VBN NMT/NN system/NN achieves/VBZ a/DT substantial/JJ improvement/NN over/IN a/DT baseline/NN NMT/NN system/NN without/IN our/PRP$ proposed/VBN technique/NN ./.
