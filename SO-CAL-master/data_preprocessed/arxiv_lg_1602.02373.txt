One/CD -/HYPH hot/JJ CNN/NNP (/-LRB- convolutional/JJ neural/JJ network/NN )/-RRB- has/VBZ been/VBN shown/VBN to/TO be/VB effective/JJ for/IN text/NN categorization/NN in/IN our/PRP$ previous/JJ work/NN ./.
We/PRP view/VBP it/PRP as/IN a/DT special/JJ case/NN of/IN a/DT general/JJ framework/NN which/WDT jointly/RB trains/VBZ a/DT linear/JJ model/NN with/IN a/DT non-linear/JJ feature/NN generator/NN consisting/VBG of/IN `/`` text/NN region/NN embedding/VBG pooling/VBG '/'' ./.
Under/IN this/DT framework/NN ,/, we/PRP explore/VBP a/DT more/RBR sophisticated/JJ region/NN embedding/NN method/NN using/VBG Long/JJ Short/JJ -/HYPH Term/NN Memory/NN (/-LRB- LSTM/NN )/-RRB- ./.
LSTM/NNP can/MD embed/VB text/NN regions/NNS of/IN variable/JJ (/-LRB- and/CC possibly/RB large/JJ )/-RRB- sizes/NNS ,/, whereas/IN the/DT region/NN size/NN needs/VBZ to/TO be/VB fixed/VBN in/IN a/DT CNN/NNP ./.
We/PRP seek/VBP the/DT best/JJS use/NN of/IN LSTM/NNP for/IN the/DT purpose/NN in/IN the/DT supervised/JJ and/CC semi-supervised/JJ settings/NNS ,/, starting/VBG with/IN the/DT idea/NN of/IN one/CD -/HYPH hot/JJ LSTM/NNP ,/, which/WDT eliminates/VBZ the/DT customarily/RB used/VBN word/NN embedding/NN layer/NN ./.
Our/PRP$ results/NNS indicate/VBP that/IN on/IN this/DT task/NN ,/, embeddings/NNS of/IN text/NN regions/NNS ,/, which/WDT can/MD convey/VB higher/JJR concepts/NNS than/IN single/JJ words/NNS in/IN isolation/NN ,/, are/VBP more/RBR useful/JJ than/IN word/NN embeddings/NNS ./.
We/PRP report/VBP performances/NNS exceeding/VBG the/DT previous/JJ best/JJS results/NNS on/IN four/CD benchmark/NN datasets/NNS ./.
