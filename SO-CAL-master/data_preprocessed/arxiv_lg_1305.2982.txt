Stochastic/JJ neurons/NNS can/MD be/VB useful/JJ for/IN a/DT number/NN of/IN reasons/NNS in/IN deep/JJ learning/NN models/NNS ,/, but/CC in/IN many/JJ cases/NNS they/PRP pose/VBP a/DT challenging/JJ problem/NN :/: how/WRB to/TO estimate/VB the/DT gradient/NN of/IN a/DT loss/NN function/NN with/IN respect/NN to/IN the/DT input/NN of/IN such/JJ stochastic/JJ neurons/NNS ,/, i.e./FW ,/, can/MD we/PRP "/`` back/RB -/HYPH propagate/VB "/`` through/IN these/DT stochastic/JJ neurons/NNS ?/.
We/PRP examine/VBP this/DT question/NN ,/, existing/VBG approaches/NNS ,/, and/CC present/JJ two/CD novel/JJ families/NNS of/IN solutions/NNS ,/, applicable/JJ in/IN different/JJ settings/NNS ./.
In/IN particular/JJ ,/, it/PRP is/VBZ demonstrated/VBN that/IN a/DT simple/JJ biologically/RB plausible/JJ formula/NN gives/VBZ rise/NN to/IN an/DT an/DT unbiased/JJ (/-LRB- but/CC noisy/JJ )/-RRB- estimator/NN of/IN the/DT gradient/NN with/IN respect/NN to/IN a/DT binary/JJ stochastic/JJ neuron/NN firing/VBG probability/NN ./.
Unlike/IN other/JJ estimators/NNS which/WDT view/VBP the/DT noise/NN as/IN a/DT small/JJ perturbation/NN in/IN order/NN to/TO estimate/VB gradients/NNS by/IN finite/JJ differences/NNS ,/, this/DT estimator/NN is/VBZ unbiased/JJ even/RB without/IN assuming/VBG that/IN the/DT stochastic/JJ perturbation/NN is/VBZ small/JJ ./.
This/DT estimator/NN is/VBZ also/RB interesting/JJ because/IN it/PRP can/MD be/VB applied/VBN in/IN very/RB general/JJ settings/NNS which/WDT do/VBP not/RB allow/VB gradient/NN back/RB -/HYPH propagation/NN ,/, including/VBG the/DT estimation/NN of/IN the/DT gradient/NN with/IN respect/NN to/IN future/JJ rewards/NNS ,/, as/IN required/VBN in/IN reinforcement/NN learning/VBG setups/NNS ./.
We/PRP also/RB propose/VBP an/DT approach/NN to/IN approximating/VBG this/DT unbiased/JJ but/CC high/JJ -/HYPH variance/NN estimator/NN by/IN learning/VBG to/TO predict/VB it/PRP using/VBG a/DT biased/JJ estimator/NN ./.
The/DT second/JJ approach/NN we/PRP propose/VBP assumes/VBZ that/IN an/DT estimator/NN of/IN the/DT gradient/NN can/MD be/VB back/RB -/HYPH propagated/VBN and/CC it/PRP provides/VBZ an/DT unbiased/JJ estimator/NN of/IN the/DT gradient/NN ,/, but/CC can/MD only/RB work/VB with/IN non-linearities/NNS unlike/IN the/DT hard/JJ threshold/NN ,/, but/CC like/IN the/DT rectifier/NN ,/, that/WDT are/VBP not/RB flat/JJ for/IN all/DT of/IN their/PRP$ range/NN ./.
This/DT is/VBZ similar/JJ to/IN traditional/JJ sigmoidal/JJ units/NNS but/CC has/VBZ the/DT advantage/NN that/WDT for/IN many/JJ inputs/NNS ,/, a/DT hard/JJ decision/NN (/-LRB- e.g./FW ,/, a/DT 0/CD output/NN )/-RRB- can/MD be/VB produced/VBN ,/, which/WDT would/MD be/VB convenient/JJ for/IN conditional/JJ computation/NN and/CC achieving/VBG sparse/JJ representations/NNS and/CC sparse/JJ gradients/NNS ./.
