Robot/NNP warehouse/NN automation/NN has/VBZ attracted/VBN significant/JJ interest/NN in/IN recent/JJ years/NNS ,/, perhaps/RB most/RBS visibly/RB in/IN the/DT Amazon/NNP Picking/VBG Challenge/NN (/-LRB- APC/NN )/-RRB- ./.
A/DT fully/RB autonomous/JJ warehouse/NN pick/VB -/HYPH and/CC -/HYPH place/NN system/NN requires/VBZ robust/JJ vision/NN that/WDT reliably/RB recognizes/VBZ and/CC locates/VBZ objects/NNS amid/IN cluttered/JJ environments/NNS ,/, self/NN -/HYPH occlusions/NNS ,/, sensor/NN noise/NN ,/, and/CC a/DT large/JJ variety/NN of/IN objects/NNS ./.
In/IN this/DT paper/NN we/PRP present/VBP an/DT approach/NN that/WDT leverages/VBZ multi-view/JJ RGB/NN -/HYPH D/NN data/NNS and/CC self/NN -/HYPH supervised/VBN ,/, data/NN -/HYPH driven/VBN learning/NN to/TO overcome/VB those/DT difficulties/NNS ./.
The/DT approach/NN was/VBD part/NN of/IN the/DT MIT/NNP -/HYPH Princeton/NNP Team/NNP system/NN that/WDT took/VBD 3rd/JJ -/HYPH and/CC 4th/JJ -/HYPH place/NN in/IN the/DT stowing/NN and/CC picking/VBG tasks/NNS ,/, respectively/RB at/IN APC/NN 2016/CD ./.
In/IN the/DT proposed/VBN approach/NN ,/, we/PRP segment/NN and/CC label/NN multiple/JJ views/NNS of/IN a/DT scene/NN with/IN a/DT fully/RB convolutional/JJ neural/JJ network/NN ,/, and/CC then/RB fit/VB pre-scanned/JJ 3D/JJ object/NN models/NNS to/IN the/DT resulting/VBG segmentation/NN to/TO get/VB the/DT 6D/NN object/NN pose/NN ./.
Training/VBG a/DT deep/JJ neural/JJ network/NN for/IN segmentation/NN typically/RB requires/VBZ a/DT large/JJ amount/NN of/IN training/NN data/NNS ./.
We/PRP propose/VBP a/DT self/NN -/HYPH supervised/JJ method/NN to/TO generate/VB a/DT large/JJ labeled/VBN dataset/NN without/IN tedious/JJ manual/JJ segmentation/NN ./.
We/PRP demonstrate/VBP that/IN our/PRP$ system/NN can/MD reliably/RB estimate/VB the/DT 6D/NN pose/NN of/IN objects/NNS under/IN a/DT variety/NN of/IN scenarios/NNS ./.
All/DT code/NN ,/, data/NNS ,/, and/CC benchmarks/NNS are/VBP available/JJ at/IN
