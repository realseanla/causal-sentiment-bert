Recently/RB ,/, topic/NN modeling/NN has/VBZ been/VBN widely/RB used/VBN to/TO discover/VB the/DT abstract/JJ topics/NNS in/IN text/NN corpora/NNS ./.
Most/JJS of/IN the/DT existing/VBG topic/NN models/NNS are/VBP based/VBN on/IN the/DT assumption/NN of/IN three/CD -/HYPH layer/NN hierarchical/JJ Bayesian/JJ structure/NN ,/, i.e./FW each/DT document/NN is/VBZ modeled/VBN as/IN a/DT probability/NN distribution/NN over/IN topics/NNS ,/, and/CC each/DT topic/NN is/VBZ a/DT probability/NN distribution/NN over/IN words/NNS ./.
However/RB ,/, the/DT assumption/NN is/VBZ not/RB optimal/JJ ./.
Intuitively/RB ,/, it/PRP 's/VBZ more/JJR reasonable/JJ to/TO assume/VB that/IN each/DT topic/NN is/VBZ a/DT probability/NN distribution/NN over/IN concepts/NNS ,/, and/CC then/RB each/DT concept/NN is/VBZ a/DT probability/NN distribution/NN over/IN words/NNS ,/, i.e./FW adding/VBG a/DT latent/JJ concept/NN layer/NN between/IN topic/NN layer/NN and/CC word/NN layer/NN in/IN traditional/JJ three/CD -/HYPH layer/NN assumption/NN ./.
In/IN this/DT paper/NN ,/, we/PRP verify/VBP the/DT proposed/VBN assumption/NN by/IN incorporating/VBG the/DT new/JJ assumption/NN in/IN two/CD representative/JJ topic/NN models/NNS ,/, and/CC obtain/VB two/CD novel/JJ topic/NN models/NNS ./.
Extensive/JJ experiments/NNS were/VBD conducted/VBN among/IN the/DT proposed/VBN models/NNS and/CC corresponding/VBG baselines/NNS ,/, and/CC the/DT results/NNS show/VBP that/IN the/DT proposed/VBN models/NNS significantly/RB outperform/VBP the/DT baselines/NNS in/IN terms/NNS of/IN case/NN study/NN and/CC perplexity/NN ,/, which/WDT means/VBZ the/DT new/JJ assumption/NN is/VBZ more/RBR reasonable/JJ than/IN traditional/JJ one/CD ./.
