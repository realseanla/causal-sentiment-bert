We/PRP present/VBP a/DT new/JJ Convolutional/JJ Neural/JJ Network/NN (/-LRB- CNN/NNP )/-RRB- model/NN for/IN text/NN classification/NN that/WDT jointly/RB exploits/VBZ labels/NNS on/IN documents/NNS and/CC their/PRP$ component/NN sentences/NNS ./.
Specifically/RB ,/, we/PRP consider/VBP scenarios/NNS in/IN which/WDT annotators/NNS explicitly/RB mark/VBP sentences/NNS (/-LRB- or/CC snippets/NNS )/-RRB- that/WDT support/VBP their/PRP$ overall/JJ document/NN categorization/NN ,/, i.e./FW ,/, they/PRP provide/VBP rationales/NNS ./.
Our/PRP$ model/NN uses/VBZ such/JJ supervision/NN via/IN a/DT hierarchical/JJ approach/NN in/IN which/WDT each/DT document/NN is/VBZ represented/VBN by/IN a/DT linear/JJ combination/NN of/IN the/DT vector/NN representations/NNS of/IN its/PRP$ constituent/JJ sentences/NNS ./.
We/PRP propose/VBP a/DT sentence/NN -/HYPH level/NN convolutional/JJ model/NN that/WDT estimates/VBZ the/DT probability/NN that/IN a/DT given/VBN sentence/NN is/VBZ a/DT rationale/NN ,/, and/CC we/PRP then/RB scale/VB the/DT contribution/NN of/IN each/DT sentence/NN to/IN the/DT aggregate/JJ document/NN representation/NN in/IN proportion/NN to/IN these/DT estimates/NNS ./.
Experiments/NNS on/IN five/CD classification/NN datasets/NNS that/WDT have/VBP document/NN labels/NNS and/CC associated/VBN rationales/NNS demonstrate/VBP that/IN our/PRP$ approach/NN consistently/RB outperforms/VBZ strong/JJ baselines/NNS ./.
Moreover/RB ,/, our/PRP$ model/NN naturally/RB provides/VBZ explanations/NNS for/IN its/PRP$ predictions/NNS ./.
