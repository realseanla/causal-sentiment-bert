Feature/NN selection/NN in/IN reinforcement/NN learning/NN (/-LRB- RL/NN )/-RRB- ,/, i.e./FW choosing/VBG basis/NN functions/NNS such/JJ that/IN useful/JJ approximations/NNS of/IN the/DT unkown/JJ value/NN function/NN can/MD be/VB obtained/VBN ,/, is/VBZ one/CD of/IN the/DT main/JJ challenges/NNS in/IN scaling/NN RL/NN to/IN real/JJ -/HYPH world/NN applications/NNS ./.
Here/RB we/PRP consider/VBP the/DT Gaussian/JJ process/NN based/VBN framework/NN GPTD/NN for/IN approximate/JJ policy/NN evaluation/NN ,/, and/CC propose/VB feature/NN selection/NN through/IN marginal/JJ likelihood/NN optimization/NN of/IN the/DT associated/VBN hyperparameters/NNS ./.
Our/PRP$ approach/NN has/VBZ two/CD appealing/JJ benefits/NNS :/: (/-LRB- 1/LS )/-RRB- given/VBN just/RB sample/NN transitions/NNS ,/, we/PRP can/MD solve/VB the/DT policy/NN evaluation/NN problem/NN fully/RB automatically/RB (/-LRB- without/IN looking/VBG at/IN the/DT learning/NN task/NN ,/, and/CC ,/, in/IN theory/NN ,/, independent/JJ of/IN the/DT dimensionality/NN of/IN the/DT state/NN space/NN )/-RRB- ,/, and/CC (/-LRB- 2/LS )/-RRB- model/NN selection/NN allows/VBZ us/PRP to/TO consider/VB more/RBR sophisticated/JJ kernels/NNS ,/, which/WDT in/IN turn/NN enable/VBP us/PRP to/TO identify/VB relevant/JJ subspaces/NNS and/CC eliminate/VB irrelevant/JJ state/NN variables/NNS such/JJ that/IN we/PRP can/MD achieve/VB substantial/JJ computational/JJ savings/NNS and/CC improved/VBD prediction/NN performance/NN ./.
