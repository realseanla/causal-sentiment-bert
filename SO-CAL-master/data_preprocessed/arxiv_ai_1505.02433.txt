This/DT paper/NN contributes/VBZ a/DT novel/JJ embedding/NN model/NN which/WDT measures/VBZ the/DT probability/NN of/IN each/DT belief/NN $/$ \/CD langle/NN h/NN ,/, r/NN ,/, t/NN ,/, m/NN \/SYM rangle/NN $/$ in/IN a/DT large/JJ -/HYPH scale/NN knowledge/NN repository/NN via/IN simultaneously/RB learning/VBG distributed/VBN representations/NNS for/IN entities/NNS (/-LRB- $/$ h/LS $/$ and/CC $/$ t/CD $/$ )/-RRB- ,/, relations/NNS (/-LRB- $/$ r/VBP $/$ )/-RRB- ,/, and/CC the/DT words/NNS in/IN relation/NN mentions/VBZ (/-LRB- $/$ m/CD $/$ )/-RRB- ./.
It/PRP facilitates/VBZ knowledge/NN completion/NN by/IN means/NNS of/IN simple/JJ vector/NN operations/NNS to/TO discover/VB new/JJ beliefs/NNS ./.
Given/VBN an/DT imperfect/JJ belief/NN ,/, we/PRP can/MD not/RB only/RB infer/VB the/DT missing/JJ entities/NNS ,/, predict/VB the/DT unknown/JJ relations/NNS ,/, but/CC also/RB tell/VB the/DT plausibility/NN of/IN the/DT belief/NN ,/, just/RB leveraging/VBG the/DT learnt/VBN embeddings/NNS of/IN remaining/VBG evidences/NNS ./.
To/TO demonstrate/VB the/DT scalability/NN and/CC the/DT effectiveness/NN of/IN our/PRP$ model/NN ,/, we/PRP conduct/VBP experiments/NNS on/IN several/JJ large/JJ -/HYPH scale/NN repositories/NNS which/WDT contain/VBP millions/NNS of/IN beliefs/NNS from/IN WordNet/NNP ,/, Freebase/NNP and/CC NELL/NNP ,/, and/CC compare/VB it/PRP with/IN other/JJ cutting/NN -/HYPH edge/NN approaches/NNS via/IN competing/VBG the/DT performances/NNS assessed/VBN by/IN the/DT tasks/NNS of/IN entity/NN inference/NN ,/, relation/NN prediction/NN and/CC triplet/NN classification/NN with/IN respective/JJ metrics/NNS ./.
Extensive/JJ experimental/JJ results/NNS show/VBP that/IN the/DT proposed/VBN model/NN outperforms/VBZ the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH arts/NNS with/IN significant/JJ improvements/NNS ./.
