We/PRP present/VBP a/DT self/NN -/HYPH training/NN approach/NN to/IN unsupervised/JJ dependency/NN parsing/VBG that/IN reuses/VBZ existing/VBG supervised/JJ and/CC unsupervised/JJ parsing/VBG algorithms/NNS ./.
Our/PRP$ approach/NN ,/, called/VBN `/`` iterated/VBN reranking/NN '/'' (/-LRB- IR/NN )/-RRB- ,/, starts/VBZ with/IN dependency/NN trees/NNS generated/VBN by/IN an/DT unsupervised/JJ parser/NN ,/, and/CC iteratively/RB improves/VBZ these/DT trees/NNS using/VBG the/DT richer/JJR probability/NN models/NNS used/VBN in/IN supervised/JJ parsing/VBG that/DT are/VBP in/IN turn/NN trained/VBN on/IN these/DT trees/NNS ./.
Our/PRP$ system/NN achieves/VBZ 1.8/CD percent/NN accuracy/NN higher/JJR than/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH part/NN parser/NN of/IN Spitkovsky/NNP et/FW al./FW (/-LRB- 2013/CD )/-RRB- on/IN the/DT WSJ/NNP corpus/NN ./.
