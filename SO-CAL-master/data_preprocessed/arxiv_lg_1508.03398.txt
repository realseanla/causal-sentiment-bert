We/PRP develop/VBP a/DT fully/RB discriminative/JJ learning/NN approach/NN for/IN supervised/JJ Latent/JJ Dirichlet/NN Allocation/NN (/-LRB- LDA/NN )/-RRB- model/NN ,/, which/WDT maximizes/VBZ the/DT posterior/JJ probability/NN of/IN the/DT prediction/NN variable/JJ given/VBN the/DT input/NN document/NN ./.
Different/JJ from/IN traditional/JJ variational/JJ learning/NN or/CC Gibbs/NNP sampling/NN approaches/NNS ,/, the/DT proposed/VBN learning/NN method/NN applies/VBZ (/-LRB- i/LS )/-RRB- the/DT mirror/NN descent/NN algorithm/NN for/IN exact/JJ maximum/NN a/DT posterior/JJ inference/NN and/CC (/-LRB- ii/LS )/-RRB- back/RB propagation/NN with/IN stochastic/JJ gradient/NN descent/NN for/IN model/NN parameter/NN estimation/NN ,/, leading/VBG to/IN scalable/JJ learning/NN of/IN the/DT model/NN in/IN an/DT end/NN -/HYPH to/IN -/HYPH end/NN discriminative/JJ manner/NN ./.
As/IN a/DT byproduct/NN ,/, we/PRP also/RB apply/VBP this/DT technique/NN to/TO develop/VB a/DT new/JJ learning/NN method/NN for/IN the/DT traditional/JJ unsupervised/JJ LDA/NN model/NN ./.
Experimental/JJ results/NNS on/IN two/CD real/JJ -/HYPH world/NN regression/NN and/CC classification/NN tasks/NNS show/VBP that/IN the/DT proposed/VBN methods/NNS significantly/RB outperform/VBP the/DT previous/JJ supervised/JJ //HYPH unsupervised/JJ LDA/NN learning/NN methods/NNS ./.
