We/PRP propose/VBP an/DT object/NN detection/NN system/NN that/WDT relies/VBZ on/IN a/DT multi-region/NN deep/JJ convolutional/JJ neural/JJ network/NN (/-LRB- CNN/NNP )/-RRB- that/WDT also/RB encodes/VBZ semantic/JJ segmentation/NN -/HYPH aware/JJ features/NNS ./.
The/DT resulting/VBG CNN/NNP -/HYPH based/VBN representation/NN aims/VBZ at/IN capturing/VBG a/DT diverse/JJ set/NN of/IN discriminative/JJ appearance/NN factors/NNS and/CC exhibits/VBZ localization/NN sensitivity/NN that/WDT is/VBZ essential/JJ for/IN accurate/JJ object/NN localization/NN ./.
We/PRP exploit/VBP the/DT above/JJ properties/NNS of/IN our/PRP$ recognition/NN module/NN by/IN integrating/VBG it/PRP on/IN an/DT iterative/JJ localization/NN mechanism/NN that/WDT alternates/VBZ between/IN scoring/VBG a/DT box/NN proposal/NN and/CC refining/NN its/PRP$ location/NN with/IN a/DT deep/JJ CNN/NNP regression/NN model/NN ./.
Thanks/NN to/IN the/DT efficient/JJ use/NN of/IN our/PRP$ modules/NNS ,/, we/PRP detect/VBP objects/NNS with/IN very/RB high/JJ localization/NN accuracy/NN ./.
On/IN the/DT detection/NN challenges/NNS of/IN PASCAL/NNP VOC2007/NN and/CC PASCAL/NNP VOC2012/NNP we/PRP achieve/VBP mAP/NN of/IN 74.9/CD percent/NN and/CC 70.7/CD percent/NN correspondingly/RB ,/, surpassing/VBG any/DT other/JJ published/VBN work/NN by/IN a/DT significant/JJ margin/NN ./.
