We/PRP study/VBP ,/, to/IN the/DT best/JJS of/IN our/PRP$ knowledge/NN ,/, the/DT first/JJ Bayesian/JJ algorithm/NN for/IN unimodal/JJ Multi-Armed/JJ Bandit/NN (/-LRB- MAB/NN )/-RRB- problems/NNS with/IN graph/NN structure/NN ./.
In/IN this/DT setting/NN ,/, each/DT arm/NN corresponds/VBZ to/IN a/DT node/NN of/IN a/DT graph/NN and/CC each/DT edge/NN provides/VBZ a/DT relationship/NN ,/, unknown/JJ to/IN the/DT learner/NN ,/, between/IN two/CD nodes/NNS in/IN terms/NNS of/IN expected/VBN reward/NN ./.
Furthermore/RB ,/, for/IN any/DT node/NN of/IN the/DT graph/NN there/EX is/VBZ a/DT path/NN leading/VBG to/IN the/DT unique/JJ node/NN providing/VBG the/DT maximum/NN expected/VBN reward/NN ,/, along/IN which/WDT the/DT expected/VBN reward/NN is/VBZ monotonically/RB increasing/VBG ./.
Previous/JJ results/NNS on/IN this/DT setting/NN describe/VB the/DT behavior/NN of/IN frequentist/JJ MAB/NN algorithms/NNS ./.
In/IN our/PRP$ paper/NN ,/, we/PRP design/VBP a/DT Thompson/NNP Sampling/NNP -/HYPH based/VBN algorithm/NN whose/WP$ asymptotic/JJ pseudo-regret/NN matches/VBZ the/DT lower/JJR bound/VBN for/IN the/DT considered/VBN setting/NN ./.
We/PRP show/VBP that/IN -/HYPH as/IN it/PRP happens/VBZ in/IN a/DT wide/JJ number/NN of/IN scenarios/NNS -/HYPH Bayesian/JJ MAB/NN algorithms/NNS dramatically/RB outperform/VBP frequentist/JJ ones/NNS ./.
In/IN particular/JJ ,/, we/PRP provide/VBP a/DT thorough/JJ experimental/JJ evaluation/NN of/IN the/DT performance/NN of/IN our/PRP$ and/CC state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN algorithms/NNS as/IN the/DT properties/NNS of/IN the/DT graph/NN vary/VBP ./.
