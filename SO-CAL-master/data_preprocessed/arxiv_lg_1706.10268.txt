Inference/NN using/VBG deep/JJ neural/JJ networks/NNS is/VBZ often/RB outsourced/VBN to/IN the/DT cloud/NN since/IN it/PRP is/VBZ a/DT computationally/RB demanding/VBG task/NN ./.
However/RB ,/, this/DT raises/VBZ a/DT fundamental/JJ issue/NN of/IN trust/NN ./.
How/WRB can/MD a/DT client/NN be/VB sure/JJ that/IN the/DT cloud/NN has/VBZ performed/VBN inference/NN correctly/RB ?/.
A/DT lazy/JJ cloud/NN provider/NN might/MD use/VB a/DT simpler/JJR but/CC less/RBR accurate/JJ model/NN to/TO reduce/VB its/PRP$ own/JJ computational/JJ load/NN ,/, or/CC worse/JJR ,/, maliciously/RB modify/VB the/DT inference/NN results/VBZ sent/VBN to/IN the/DT client/NN ./.
We/PRP propose/VBP SafetyNets/NNPS ,/, a/DT framework/NN that/WDT enables/VBZ an/DT untrusted/JJ server/NN (/-LRB- the/DT cloud/NN )/-RRB- to/TO provide/VB a/DT client/NN with/IN a/DT short/JJ mathematical/JJ proof/NN of/IN the/DT correctness/NN of/IN inference/NN tasks/NNS that/WDT they/PRP perform/VBP on/IN behalf/NN of/IN the/DT client/NN ./.
Specifically/RB ,/, SafetyNets/NNPS develops/VBZ and/CC implements/VBZ a/DT specialized/JJ interactive/JJ proof/NN (/-LRB- IP/NN )/-RRB- protocol/NN for/IN verifiable/JJ execution/NN of/IN a/DT class/NN of/IN deep/JJ neural/JJ networks/NNS ,/, i.e./FW ,/, those/DT that/WDT can/MD be/VB represented/VBN as/IN arithmetic/NN circuits/NNS ./.
Our/PRP$ empirical/JJ results/NNS on/IN three/CD -/HYPH and/CC four/CD -/HYPH layer/NN deep/JJ neural/JJ networks/NNS demonstrate/VBP the/DT run/NN -/HYPH time/NN costs/NNS of/IN SafetyNets/NNPS for/IN both/CC the/DT client/NN and/CC server/NN are/VBP low/JJ ./.
SafetyNets/NNP detects/VBZ any/DT incorrect/JJ computations/NNS of/IN the/DT neural/JJ network/NN by/IN the/DT untrusted/JJ server/NN with/IN high/JJ probability/NN ,/, while/IN achieving/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN accuracy/NN on/IN the/DT MNIST/NNP digit/NN recognition/NN (/-LRB- 99.4/CD percent/NN )/-RRB- and/CC TIMIT/NN speech/NN recognition/NN tasks/NNS (/-LRB- 75.22/CD percent/NN )/-RRB- ./.
