In/IN lexicon/NN -/HYPH based/VBN classification/NN ,/, documents/NNS are/VBP assigned/VBN labels/NNS by/IN comparing/VBG the/DT number/NN of/IN words/NNS that/WDT appear/VBP from/IN two/CD opposed/JJ lexicons/NNS ,/, such/JJ as/IN positive/JJ and/CC negative/JJ sentiment/NN ./.
Creating/VBG such/JJ words/NNS lists/NNS is/VBZ often/RB easier/JJR than/IN labeling/VBG instances/NNS ,/, and/CC they/PRP can/MD be/VB debugged/VBN by/IN non-experts/NNS if/IN classification/NN performance/NN is/VBZ unsatisfactory/JJ ./.
However/RB ,/, there/EX is/VBZ little/JJ analysis/NN or/CC justification/NN of/IN this/DT classification/NN heuristic/NN ./.
This/DT paper/NN describes/VBZ a/DT set/NN of/IN assumptions/NNS that/WDT can/MD be/VB used/VBN to/TO derive/VB a/DT probabilistic/JJ justification/NN for/IN lexicon/NN -/HYPH based/VBN classification/NN ,/, as/RB well/RB as/IN an/DT analysis/NN of/IN its/PRP$ expected/VBN accuracy/NN ./.
One/CD key/JJ assumption/NN behind/IN lexicon/NN -/HYPH based/VBN classification/NN is/VBZ that/IN all/DT words/NNS in/IN each/DT lexicon/NN are/VBP equally/RB predictive/JJ ./.
This/DT is/VBZ rarely/RB true/JJ in/IN practice/NN ,/, which/WDT is/VBZ why/WRB lexicon/NN -/HYPH based/VBN approaches/NNS are/VBP usually/RB outperformed/VBN by/IN supervised/JJ classifiers/NNS that/WDT learn/VBP distinct/JJ weights/NNS on/IN each/DT word/NN from/IN labeled/VBN instances/NNS ./.
This/DT paper/NN shows/VBZ that/IN it/PRP is/VBZ possible/JJ to/TO learn/VB such/JJ weights/NNS without/IN labeled/VBN data/NNS ,/, by/IN leveraging/VBG co-occurrence/NN statistics/NNS across/IN the/DT lexicons/NNS ./.
This/DT offers/VBZ the/DT best/JJS of/IN both/DT worlds/NNS :/: light/JJ supervision/NN in/IN the/DT form/NN of/IN lexicons/NNS ,/, and/CC data/NN -/HYPH driven/VBN classification/NN with/IN higher/JJR accuracy/NN than/IN traditional/JJ word/NN -/HYPH counting/VBG heuristics/NNS ./.
