We/PRP present/VBP a/DT model/NN for/IN compositional/JJ distributional/JJ semantics/NNS related/VBN to/IN the/DT framework/NN of/IN Coecke/NNP et/FW al./FW (/-LRB- 2010/CD )/-RRB- ,/, and/CC emulating/VBG formal/JJ semantics/NNS by/IN representing/VBG functions/NNS as/IN tensors/NNS and/CC arguments/NNS as/IN vectors/NNS ./.
We/PRP introduce/VBP a/DT new/JJ learning/NN method/NN for/IN tensors/NNS ,/, generalising/VBG the/DT approach/NN of/IN Baroni/NNP and/CC Zamparelli/NNP (/-LRB- 2010/CD )/-RRB- ./.
We/PRP evaluate/VBP it/PRP on/IN two/CD benchmark/NN data/NNS sets/NNS ,/, and/CC find/VB it/PRP to/TO outperform/VB existing/VBG leading/VBG methods/NNS ./.
We/PRP argue/VBP in/IN our/PRP$ analysis/NN that/IN the/DT nature/NN of/IN this/DT learning/NN method/NN renders/VBZ it/PRP suitable/JJ also/RB for/IN solving/VBG more/RBR subtle/JJ problems/NNS compositional/JJ distributional/JJ models/NNS might/MD face/VB ./.
