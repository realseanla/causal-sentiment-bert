Planning/VBG actions/NNS using/VBG learned/VBN and/CC differentiable/JJ forward/JJ models/NNS of/IN the/DT world/NN is/VBZ a/DT general/JJ approach/NN which/WDT has/VBZ a/DT number/NN of/IN desirable/JJ properties/NNS ,/, including/VBG improved/VBN sample/NN complexity/NN over/IN model/NN -/HYPH free/JJ RL/NN methods/NNS ,/, reuse/VB of/IN learned/VBN models/NNS across/IN different/JJ tasks/NNS ,/, and/CC the/DT ability/NN to/TO perform/VB efficient/JJ gradient/NN -/HYPH based/VBN optimization/NN in/IN continuous/JJ action/NN spaces/NNS ./.
However/RB ,/, this/DT approach/NN does/VBZ not/RB apply/VB straightforwardly/RB when/WRB the/DT action/NN space/NN is/VBZ discrete/JJ ,/, which/WDT may/MD have/VB limited/VBN its/PRP$ adoption/NN ./.
In/IN this/DT work/NN ,/, we/PRP introduce/VBP two/CD discrete/JJ planning/NN tasks/NNS inspired/VBN by/IN existing/VBG question/NN -/HYPH answering/VBG datasets/NNS and/CC show/VBP that/IN it/PRP is/VBZ in/IN fact/NN possible/JJ to/TO effectively/RB perform/VB planning/VBG via/IN backprop/NN in/IN discrete/JJ action/NN spaces/NNS using/VBG two/CD simple/JJ yet/CC principled/JJ modifications/NNS ./.
Our/PRP$ experiments/NNS show/VBP that/IN this/DT approach/NN can/MD significantly/RB outperform/VB model/NN -/HYPH free/JJ RL/NN based/VBN methods/NNS and/CC supervised/VBD imitation/NN learners/NNS ./.
