Methods/NNS for/IN learning/VBG word/NN representations/NNS using/VBG large/JJ text/NN corpora/NNS have/VBP received/VBN much/JJ attention/NN lately/RB due/IN to/IN their/PRP$ impressive/JJ performance/NN in/IN numerous/JJ natural/JJ language/NN processing/NN (/-LRB- NLP/NN )/-RRB- tasks/NNS such/JJ as/IN ,/, semantic/JJ similarity/NN measurement/NN ,/, and/CC word/NN analogy/NN detection/NN ./.
Despite/IN their/PRP$ success/NN ,/, these/DT data/NNS -/HYPH driven/VBN word/NN representation/NN learning/NN methods/NNS do/VBP not/RB consider/VB the/DT rich/JJ semantic/JJ relational/JJ structure/NN between/IN words/NNS in/IN a/DT co-occurring/NN context/NN ./.
On/IN the/DT other/JJ hand/NN ,/, already/RB much/JJ manual/JJ effort/NN has/VBZ gone/VBN into/IN the/DT construction/NN of/IN semantic/JJ lexicons/NNS such/JJ as/IN the/DT WordNet/NNP that/WDT represent/VBP the/DT meanings/NNS of/IN words/NNS by/IN defining/VBG the/DT various/JJ relationships/NNS that/WDT exist/VBP among/IN the/DT words/NNS in/IN a/DT language/NN ./.
We/PRP consider/VBP the/DT question/NN ,/, can/MD we/PRP improve/VB the/DT word/NN representations/NNS learnt/VBN using/VBG a/DT corpora/NN by/IN integrating/VBG the/DT knowledge/NN from/IN semantic/JJ lexicons/NNS ?/.
./.
For/IN this/DT purpose/NN ,/, we/PRP propose/VBP a/DT joint/JJ word/NN representation/NN learning/NN method/NN that/WDT simultaneously/RB predicts/VBZ the/DT co-occurrences/NNS of/IN two/CD words/NNS in/IN a/DT sentence/NN subject/NN to/IN the/DT relational/JJ constrains/VBZ given/VBN by/IN the/DT semantic/JJ lexicon/NN ./.
We/PRP use/VBP relations/NNS that/WDT exist/VBP between/IN words/NNS in/IN the/DT lexicon/NN to/IN regularize/VB the/DT word/NN representations/NNS learnt/VBN from/IN the/DT corpus/NN ./.
Our/PRP$ proposed/JJ method/NN statistically/RB significantly/RB outperforms/VBZ previously/RB proposed/VBN methods/NNS for/IN incorporating/VBG semantic/JJ lexicons/NNS into/IN word/NN representations/NNS on/IN several/JJ benchmark/NN datasets/NNS for/IN semantic/JJ similarity/NN and/CC word/NN analogy/NN ./.
