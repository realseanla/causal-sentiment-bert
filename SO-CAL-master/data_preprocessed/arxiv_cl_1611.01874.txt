Although/IN end/NN -/HYPH to/IN -/HYPH end/NN Neural/JJ Machine/NN Translation/NN (/-LRB- NMT/NN )/-RRB- has/VBZ achieved/VBN remarkable/JJ progress/NN in/IN the/DT past/JJ two/CD years/NNS ,/, it/PRP suffers/VBZ from/IN a/DT major/JJ drawback/NN :/: translations/NNS generated/VBN by/IN NMT/NN systems/NNS often/RB lack/VBP of/IN adequacy/NN ./.
It/PRP has/VBZ been/VBN widely/RB observed/VBN that/IN NMT/NNP tends/VBZ to/TO repeatedly/RB translate/VB some/DT source/NN words/NNS while/IN mistakenly/RB ignoring/VBG other/JJ words/NNS ./.
To/TO alleviate/VB this/DT problem/NN ,/, we/PRP propose/VBP a/DT novel/JJ encoder/NN -/HYPH decoder/NN -/HYPH reconstructor/NN framework/NN for/IN NMT/NNP ./.
The/DT reconstructor/NN ,/, incorporated/VBN into/IN the/DT NMT/NN model/NN ,/, manages/VBZ to/TO reconstruct/VB the/DT input/NN source/NN sentence/NN from/IN the/DT hidden/JJ layer/NN of/IN the/DT output/NN target/NN sentence/NN ,/, to/TO ensure/VB that/IN the/DT information/NN in/IN the/DT source/NN side/NN is/VBZ transformed/VBN to/IN the/DT target/NN side/NN as/RB much/RB as/IN possible/JJ ./.
Experiments/NNS show/VBP that/IN the/DT proposed/VBN framework/NN significantly/RB improves/VBZ the/DT adequacy/NN of/IN NMT/NN output/NN and/CC achieves/VBZ superior/JJ translation/NN result/NN over/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN NMT/NN and/CC statistical/JJ MT/NN systems/NNS ./.
