This/DT article/NN shows/VBZ how/WRB the/DT recent/JJ breakthroughs/NNS in/IN Reinforcement/NN Learning/NN (/-LRB- RL/NN )/-RRB- that/WDT have/VBP enabled/VBN robots/NNS to/TO learn/VB to/TO play/VB arcade/NN video/NN games/NNS ,/, walk/VB or/CC assemble/VB colored/JJ bricks/NNS ,/, can/MD be/VB used/VBN to/TO perform/VB other/JJ tasks/NNS that/WDT are/VBP currently/RB at/IN the/DT core/NN of/IN engineering/NN cyberphysical/NN systems/NNS ./.
We/PRP present/VBP the/DT first/JJ use/NN of/IN RL/NN for/IN the/DT control/NN of/IN systems/NNS modeled/VBN by/IN discretized/VBN non-linear/JJ Partial/JJ Differential/NNP Equations/NNS (/-LRB- PDEs/NNS )/-RRB- and/CC devise/VB a/DT novel/JJ algorithm/NN to/TO use/VB non-parametric/JJ control/NN techniques/NNS for/IN large/JJ multi-agent/JJ systems/NNS ./.
We/PRP show/VBP how/WRB neural/JJ network/NN based/VBN RL/NNP enables/VBZ the/DT control/NN of/IN discretized/VBN PDEs/NNS whose/WP$ parameters/NNS are/VBP unknown/JJ ,/, random/JJ ,/, and/CC time/NN -/HYPH varying/VBG ./.
We/PRP introduce/VBP an/DT algorithm/NN of/IN Mutual/NNP Weight/NNP Regularization/NN (/-LRB- MWR/NN )/-RRB- which/WDT alleviates/VBZ the/DT curse/NN of/IN dimensionality/NN of/IN multi-agent/JJ control/NN schemes/NNS by/IN sharing/VBG experience/NN between/IN agents/NNS while/IN giving/VBG each/DT agent/NN the/DT opportunity/NN to/TO specialize/VB its/PRP$ action/NN policy/NN so/RB as/IN to/IN tailor/NN it/PRP to/IN the/DT local/JJ parameters/NNS of/IN the/DT part/NN of/IN the/DT system/NN it/PRP is/VBZ located/VBN in/IN ./.
