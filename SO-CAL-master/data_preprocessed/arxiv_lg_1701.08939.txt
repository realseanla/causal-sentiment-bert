We/PRP start/VBP with/IN an/DT overview/NN of/IN a/DT class/NN of/IN submodular/JJ functions/NNS called/VBN SCMMs/NNPS (/-LRB- sums/NNS of/IN concave/JJ composed/VBN with/IN non-negative/JJ modular/JJ functions/NNS plus/CC a/DT final/JJ arbitrary/JJ modular/JJ )/-RRB- ./.
We/PRP then/RB define/VBP a/DT new/JJ class/NN of/IN submodular/JJ functions/NNS we/PRP call/VBP {/-LRB- \/SYM em/PRP deep/RB submodular/JJ functions/NNS }/-RRB- or/CC DSFs/NNS ./.
We/PRP show/VBP that/IN DSFs/NNS are/VBP a/DT flexible/JJ parametric/JJ family/NN of/IN submodular/JJ functions/NNS that/WDT share/VBP many/JJ of/IN the/DT properties/NNS and/CC advantages/NNS of/IN deep/JJ neural/JJ networks/NNS (/-LRB- DNNs/NNS )/-RRB- ./.
DSFs/NNS can/MD be/VB motivated/VBN by/IN considering/VBG a/DT hierarchy/NN of/IN descriptive/JJ concepts/NNS over/IN ground/NN elements/NNS and/CC where/WRB one/CD wishes/VBZ to/TO allow/VB submodular/JJ interaction/NN throughout/IN this/DT hierarchy/NN ./.
Results/NNS in/IN this/DT paper/NN show/VBP that/IN DSFs/NNS constitute/VBP a/DT strictly/RB larger/JJR class/NN of/IN submodular/JJ functions/NNS than/IN SCMMs/NNPS ./.
We/PRP show/VBP that/IN ,/, for/IN any/DT integer/NN $/$ k/CD &gt;/SYM 0/CD $/$ ,/, there/EX are/VBP $/$ k/CD $/$ -/HYPH layer/NN DSFs/NNS that/WDT can/MD not/RB be/VB represented/VBN by/IN a/DT $/$ k/CD '/SYM $/$ -/HYPH layer/NN DSF/NN for/IN any/DT $/$ k/CD '/SYM &lt;/-LRB- k/CD $/$ ./.
This/DT implies/VBZ that/IN ,/, like/IN DNNs/NNS ,/, there/EX is/VBZ a/DT utility/NN to/IN depth/NN ,/, but/CC unlike/IN DNNs/NNS ,/, the/DT family/NN of/IN DSFs/NNS strictly/RB increase/VBP with/IN depth/NN ./.
Despite/IN this/DT ,/, we/PRP show/VBP (/-LRB- using/VBG a/DT "/`` backpropagation/NN "/'' like/IN method/NN )/-RRB- that/WDT DSFs/NNS ,/, even/RB with/IN arbitrarily/RB large/JJ $/$ k/CD $/$ ,/, do/VBP not/RB comprise/VB all/DT submodular/JJ functions/NNS ./.
In/IN offering/VBG the/DT above/JJ results/NNS ,/, we/PRP also/RB define/VBP the/DT notion/NN of/IN an/DT antitone/JJ superdifferential/NN of/IN a/DT concave/NN function/NN and/CC show/VB how/WRB this/DT relates/VBZ to/IN submodular/JJ functions/NNS (/-LRB- in/IN general/JJ )/-RRB- ,/, DSFs/NNS (/-LRB- in/IN particular/JJ )/-RRB- ,/, negative/JJ second/JJ -/HYPH order/NN partial/JJ derivatives/NNS ,/, continuous/JJ submodularity/NN ,/, and/CC concave/JJ extensions/NNS ./.
To/TO further/RB motivate/VB our/PRP$ analysis/NN ,/, we/PRP provide/VBP various/JJ special/JJ case/NN results/VBZ from/IN matroid/JJ theory/NN ,/, comparing/VBG DSFs/NNS with/IN forms/NNS of/IN matroid/JJ rank/NN ,/, in/IN particular/JJ the/DT laminar/JJ matroid/NN ./.
Lastly/RB ,/, we/PRP discuss/VBP strategies/NNS to/TO learn/VB DSFs/NNS ,/, and/CC define/VB the/DT classes/NNS of/IN deep/JJ supermodular/JJ functions/NNS ,/, deep/JJ difference/NN of/IN submodular/JJ functions/NNS ,/, and/CC deep/JJ multivariate/JJ submodular/JJ functions/NNS ,/, and/CC discuss/VB where/WRB these/DT can/MD be/VB useful/JJ in/IN applications/NNS ./.
