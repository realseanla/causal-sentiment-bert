Can/MD one/PRP parallelize/VB complex/JJ exploration/NN exploitation/NN tradeoffs/NNS ?/.
As/IN an/DT example/NN ,/, consider/VB the/DT problem/NN of/IN optimal/JJ high/JJ -/HYPH throughput/NN experimental/JJ design/NN ,/, where/WRB we/PRP wish/VBP to/TO sequentially/RB design/VB batches/NNS of/IN experiments/NNS in/IN order/NN to/TO simultaneously/RB learn/VB a/DT surrogate/JJ function/NN mapping/NN stimulus/NN to/IN response/NN and/CC identify/VB the/DT maximum/NN of/IN the/DT function/NN ./.
We/PRP formalize/VBP the/DT task/NN as/IN a/DT multi-armed/JJ bandit/NN problem/NN ,/, where/WRB the/DT unknown/JJ payoff/NN function/NN is/VBZ sampled/VBN from/IN a/DT Gaussian/JJ process/NN (/-LRB- GP/NNP )/-RRB- ,/, and/CC instead/RB of/IN a/DT single/JJ arm/NN ,/, in/IN each/DT round/NN we/PRP pull/VBP a/DT batch/NN of/IN several/JJ arms/NNS in/IN parallel/NN ./.
We/PRP develop/VBP GP/NNP -/HYPH BUCB/NNP ,/, a/DT principled/JJ algorithm/NN for/IN choosing/VBG batches/NNS ,/, based/VBN on/IN the/DT GP/NNP -/HYPH UCB/NNP algorithm/NN for/IN sequential/JJ GP/NNP optimization/NN ./.
We/PRP prove/VBP a/DT surprising/JJ result/NN ;/: as/IN compared/VBN to/IN the/DT sequential/JJ approach/NN ,/, the/DT cumulative/JJ regret/NN of/IN the/DT parallel/JJ algorithm/NN only/RB increases/VBZ by/IN a/DT constant/JJ factor/NN independent/NN of/IN the/DT batch/NN size/NN B/NN ./.
Our/PRP$ results/NNS provide/VBP rigorous/JJ theoretical/JJ support/NN for/IN exploiting/VBG parallelism/NN in/IN Bayesian/JJ global/JJ optimization/NN ./.
We/PRP demonstrate/VBP the/DT effectiveness/NN of/IN our/PRP$ approach/NN on/IN two/CD real/JJ -/HYPH world/NN applications/NNS ./.
