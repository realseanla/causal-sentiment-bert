We/PRP propose/VBP an/DT approach/NN to/TO learn/VB spatio/JJ -/HYPH temporal/JJ features/NNS in/IN videos/NNS from/IN intermediate/JJ visual/JJ representations/NNS we/PRP call/VBP "/`` percepts/NNS "/'' using/VBG Gated/VBN -/HYPH Recurrent/JJ -/HYPH Unit/NN Recurrent/JJ Networks/NNS (/-LRB- GRUs/NNS )/-RRB- ./.
Our/PRP$ method/NN relies/VBZ on/IN percepts/NNS that/WDT are/VBP extracted/VBN from/IN all/DT level/NN of/IN a/DT deep/JJ convolutional/JJ network/NN trained/VBN on/IN the/DT large/JJ ImageNet/NNP dataset/NN ./.
While/IN high/JJ -/HYPH level/NN percepts/NNS contain/VBP highly/RB discriminative/JJ information/NN ,/, they/PRP tend/VBP to/TO have/VB a/DT low/JJ -/HYPH spatial/JJ resolution/NN ./.
Low/JJ -/HYPH level/NN percepts/NNS ,/, on/IN the/DT other/JJ hand/NN ,/, preserve/VB a/DT higher/JJR spatial/JJ resolution/NN from/IN which/WDT we/PRP can/MD model/VB finer/JJR motion/NN patterns/NNS ./.
Using/VBG low/JJ -/HYPH level/NN percepts/NNS can/MD leads/VBZ to/IN high/JJ -/HYPH dimensionality/NN video/NN representations/NNS ./.
To/TO mitigate/VB this/DT effect/NN and/CC control/VB the/DT model/NN number/NN of/IN parameters/NNS ,/, we/PRP introduce/VBP a/DT variant/NN of/IN the/DT GRU/NNP model/NN that/WDT leverages/VBZ the/DT convolution/NN operations/NNS to/TO enforce/VB sparse/JJ connectivity/NN of/IN the/DT model/NN units/NNS and/CC share/NN parameters/NNS across/IN the/DT input/NN spatial/JJ locations/NNS ./.
