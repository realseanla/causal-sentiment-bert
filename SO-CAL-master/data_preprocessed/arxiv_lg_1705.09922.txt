Bandit/NN based/VBN optimisation/NN has/VBZ a/DT remarkable/JJ advantage/NN over/IN gradient/NN based/VBN approaches/NNS due/IN to/IN their/PRP$ global/JJ perspective/NN ,/, which/WDT eliminates/VBZ the/DT danger/NN of/IN getting/VBG stuck/VBN at/IN local/JJ optima/NN ./.
However/RB ,/, for/IN continuous/JJ optimisation/NN problems/NNS or/CC problems/NNS with/IN a/DT large/JJ number/NN of/IN actions/NNS ,/, bandit/NN based/VBN approaches/NNS can/MD be/VB hindered/VBN by/IN slow/JJ learning/NN ./.
Gradient/NN based/VBN approaches/NNS ,/, on/IN the/DT other/JJ hand/NN ,/, navigate/VB quickly/RB in/IN high/JJ -/HYPH dimensional/JJ continuous/JJ spaces/NNS through/IN local/JJ optimisation/NN ,/, following/VBG the/DT gradient/NN in/IN fine/JJ grained/JJ steps/NNS ./.
Yet/RB ,/, apart/RB from/IN being/VBG susceptible/JJ to/IN local/JJ optima/NN ,/, these/DT schemes/NNS are/VBP less/RBR suited/JJ for/IN online/JJ learning/NN due/IN to/IN their/PRP$ reliance/NN on/IN extensive/JJ trial/NN -/HYPH and/CC -/HYPH error/NN before/IN the/DT optimum/JJ can/MD be/VB identified/VBN ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT Bayesian/JJ approach/NN that/WDT unifies/VBZ the/DT above/JJ two/CD paradigms/NNS in/IN one/CD single/JJ framework/NN ,/, with/IN the/DT aim/NN of/IN combining/VBG their/PRP$ advantages/NNS ./.
At/IN the/DT heart/NN of/IN our/PRP$ approach/NN we/PRP find/VBP a/DT stochastic/JJ linear/JJ approximation/NN of/IN the/DT function/NN to/TO be/VB optimised/VBN ,/, where/WRB both/PDT the/DT gradient/NN and/CC values/NNS of/IN the/DT function/NN are/VBP explicitly/RB captured/VBN ./.
This/DT allows/VBZ us/PRP to/TO learn/VB from/IN both/DT noisy/JJ function/NN and/CC gradient/NN observations/NNS ,/, and/CC predict/VB these/DT properties/NNS across/IN the/DT action/NN space/NN to/TO support/VB optimisation/NN ./.
We/PRP further/RB propose/VBP an/DT accompanying/VBG bandit/NN driven/VBN exploration/NN scheme/NN that/WDT uses/VBZ Bayesian/JJ credible/JJ bounds/NNS to/TO trade/VB off/RP exploration/NN against/IN exploitation/NN ./.
Our/PRP$ empirical/JJ results/NNS demonstrate/VBP that/IN by/IN unifying/JJ bandit/NN and/CC gradient/NN based/VBN learning/NN ,/, one/CD obtains/VBZ consistently/RB improved/VBN performance/NN across/IN a/DT wide/JJ spectrum/NN of/IN problem/NN environments/NNS ./.
Furthermore/RB ,/, even/RB when/WRB gradient/NN feedback/NN is/VBZ unavailable/JJ ,/, the/DT flexibility/NN of/IN our/PRP$ model/NN ,/, including/VBG gradient/NN prediction/NN ,/, still/RB allows/VBZ us/PRP outperform/VB competing/VBG approaches/NNS ,/, although/IN with/IN a/DT smaller/JJR margin/NN ./.
Due/IN to/IN the/DT pervasiveness/NN of/IN bandit/NN based/VBN optimisation/NN ,/, our/PRP$ scheme/NN opens/VBZ up/RP for/IN improved/VBN performance/NN both/CC in/IN meta/NN -/HYPH optimisation/NN and/CC in/IN applications/NNS where/WRB gradient/NN related/JJ information/NN is/VBZ readily/RB available/JJ ./.
