In/IN many/JJ applications/NNS of/IN black/JJ -/HYPH box/NN optimization/NN ,/, one/PRP can/MD evaluate/VB multiple/JJ points/NNS simultaneously/RB ,/, e.g./FW when/WRB evaluating/VBG the/DT performances/NNS of/IN several/JJ different/JJ neural/JJ network/NN architectures/NNS in/IN a/DT parallel/JJ computing/NN environment/NN ./.
In/IN this/DT paper/NN ,/, we/PRP develop/VBP a/DT novel/JJ batch/NN Bayesian/JJ optimization/NN algorithm/NN ---/, the/DT parallel/JJ knowledge/NN gradient/NN method/NN ./.
By/IN construction/NN ,/, this/DT method/NN provides/VBZ the/DT one/CD -/HYPH step/NN Bayes/NNP optimal/JJ batch/NN of/IN points/NNS to/IN sample/NN ./.
We/PRP provide/VBP an/DT efficient/JJ strategy/NN for/IN computing/VBG this/DT Bayes/NNP -/HYPH optimal/JJ batch/NN of/IN points/NNS ,/, and/CC we/PRP demonstrate/VBP that/IN the/DT parallel/JJ knowledge/NN gradient/NN method/NN finds/VBZ global/JJ optima/NN significantly/RB faster/RBR than/IN previous/JJ batch/NN Bayesian/JJ optimization/NN algorithms/NNS on/IN both/DT synthetic/JJ test/NN functions/NNS and/CC when/WRB tuning/VBG hyperparameters/NNS of/IN practical/JJ machine/NN learning/VBG algorithms/NNS ,/, especially/RB when/WRB function/NN evaluations/NNS are/VBP noisy/JJ ./.
