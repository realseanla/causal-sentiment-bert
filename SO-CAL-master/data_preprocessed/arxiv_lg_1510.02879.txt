The/DT ability/NN to/TO transfer/VB knowledge/NN from/IN learnt/VBN source/NN tasks/NNS to/IN a/DT new/JJ target/NN task/NN can/MD be/VB very/RB useful/JJ in/IN speeding/VBG up/RP the/DT learning/NN process/NN of/IN a/DT Reinforcement/NN Learning/VBG agent/NN ./.
This/DT has/VBZ been/VBN receiving/VBG a/DT lot/NN of/IN attention/NN ,/, but/CC the/DT application/NN of/IN transfer/NN poses/VBZ two/CD serious/JJ challenges/NNS which/WDT have/VBP not/RB been/VBN adequately/RB addressed/VBN in/IN the/DT past/NN ./.
First/RB ,/, the/DT agent/NN should/MD be/VB able/JJ to/TO avoid/VB negative/JJ transfer/NN ,/, which/WDT happens/VBZ when/WRB the/DT transfer/NN hampers/VBZ or/CC slows/VBZ down/RP the/DT learning/NN instead/RB of/IN speeding/VBG it/PRP up/RP ./.
Secondly/RB ,/, the/DT agent/NN should/MD be/VB able/JJ to/TO do/VB selective/JJ transfer/NN which/WDT is/VBZ the/DT ability/NN to/TO select/VB and/CC transfer/VB from/IN different/JJ and/CC multiple/JJ source/NN tasks/NNS for/IN different/JJ parts/NNS of/IN the/DT state/NN space/NN of/IN the/DT target/NN task/NN ./.
We/PRP propose/VBP ADAAPT/NNP :/: A/NNP Deep/NNP Architecture/NNP for/IN Adaptive/JJ Policy/NN Transfer/NN ,/, which/WDT addresses/VBZ these/DT challenges/NNS ./.
We/PRP test/VBP ADAAPT/NN using/VBG two/CD different/JJ instantiations/NNS :/: One/CD as/IN ADAAPTive/JJ REINFORCE/NN algorithm/NN for/IN direct/JJ policy/NN search/NN and/CC another/DT as/IN ADAAPTive/NNP Actor/NN -/HYPH Critic/NN where/WRB the/DT actor/NN uses/VBZ ADAAPT/NN ./.
Empirical/JJ evaluations/NNS on/IN simulated/JJ domains/NNS show/VBP that/IN ADAAPT/NNP can/MD be/VB effectively/RB used/VBN for/IN policy/NN transfer/NN from/IN multiple/JJ source/NN MDPs/NNS sharing/VBG the/DT same/JJ state/NN and/CC action/NN space/NN ./.
