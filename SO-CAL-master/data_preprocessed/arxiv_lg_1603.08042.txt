We/PRP study/VBP the/DT problem/NN of/IN compressing/VBG recurrent/JJ neural/JJ networks/NNS (/-LRB- RNNs/NNS )/-RRB- ./.
In/IN particular/JJ ,/, we/PRP focus/VBP on/IN the/DT compression/NN of/IN RNN/NNP acoustic/JJ models/NNS ,/, which/WDT are/VBP motivated/VBN by/IN the/DT goal/NN of/IN building/VBG compact/JJ and/CC accurate/JJ speech/NN recognition/NN systems/NNS which/WDT can/MD be/VB run/VBN efficiently/RB on/IN mobile/JJ devices/NNS ./.
In/IN this/DT work/NN ,/, we/PRP present/VBP a/DT technique/NN for/IN general/JJ recurrent/JJ model/NN compression/NN that/WDT jointly/RB compresses/VBZ both/CC recurrent/JJ and/CC non-recurrent/JJ inter-layer/NN weight/NN matrices/NNS ./.
We/PRP find/VBP that/IN the/DT proposed/VBN technique/NN allows/VBZ us/PRP to/TO reduce/VB the/DT size/NN of/IN our/PRP$ Long/JJ Short/JJ -/HYPH Term/NN Memory/NN (/-LRB- LSTM/NN )/-RRB- acoustic/JJ model/NN to/IN a/DT third/NN of/IN its/PRP$ original/JJ size/NN with/IN negligible/JJ loss/NN in/IN accuracy/NN ./.
