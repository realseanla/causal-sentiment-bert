We/PRP propose/VBP a/DT novel/JJ approach/NN for/IN designing/VBG kernels/NNS for/IN support/NN vector/NN machines/NNS (/-LRB- SVMs/NNS )/-RRB- when/WRB the/DT class/NN label/NN is/VBZ linked/VBN to/IN the/DT observation/NN through/IN a/DT latent/JJ state/NN and/CC the/DT likelihood/NN function/NN of/IN the/DT observation/NN given/VBN the/DT state/NN (/-LRB- the/DT sensing/VBG model/NN )/-RRB- is/VBZ available/JJ ./.
We/PRP show/VBP that/IN the/DT Bayes/NNP -/HYPH optimum/JJ decision/NN boundary/NN is/VBZ a/DT hyperplane/NN under/IN a/DT mapping/NN defined/VBN by/IN the/DT likelihood/NN function/NN ./.
Combining/VBG this/DT with/IN the/DT maximum/JJ margin/NN principle/NN yields/NNS kernels/NNS for/IN SVMs/NNS that/WDT leverage/VBP knowledge/NN of/IN the/DT sensing/VBG model/NN in/IN an/DT optimal/JJ way/NN ./.
We/PRP derive/VBP the/DT optimum/JJ kernel/NN for/IN the/DT bag/NN -/HYPH of/IN -/HYPH words/NNS (/-LRB- BoWs/NNS )/-RRB- sensing/VBG model/NN and/CC demonstrate/VBP its/PRP$ superior/JJ performance/NN over/IN other/JJ kernels/NNS in/IN document/NN and/CC image/NN classification/NN tasks/NNS ./.
These/DT results/NNS indicate/VBP that/IN such/JJ optimum/JJ sensing/VBG -/HYPH aware/JJ kernel/NN SVMs/NNS can/MD match/VB the/DT performance/NN of/IN rather/RB sophisticated/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN approaches/NNS ./.
