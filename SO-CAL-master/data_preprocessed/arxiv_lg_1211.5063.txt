Training/VBG Recurrent/JJ Neural/JJ Networks/NNS is/VBZ more/RBR troublesome/JJ than/IN feedforward/JJ ones/NNS because/IN of/IN the/DT vanishing/VBG and/CC exploding/VBG gradient/NN problems/NNS detailed/VBN in/IN Bengio/NNP et/FW al./FW (/-LRB- 1994/CD )/-RRB- ./.
In/IN this/DT paper/NN we/PRP attempt/VBP to/TO understand/VB the/DT fundamental/JJ issues/NNS underlying/VBG the/DT exploding/VBG gradient/NN problem/NN by/IN exploring/VBG it/PRP from/IN an/DT analytical/JJ ,/, a/DT geometric/JJ and/CC a/DT dynamical/JJ system/NN perspective/NN ./.
Our/PRP$ analysis/NN is/VBZ used/VBN to/TO justify/VB the/DT simple/JJ yet/CC effective/JJ solution/NN of/IN norm/NN clipping/VBG the/DT exploded/VBN gradient/NN ./.
In/IN the/DT experimental/JJ section/NN ,/, the/DT comparison/NN between/IN this/DT heuristic/NN solution/NN and/CC standard/JJ SGD/NNP provides/VBZ empirical/JJ evidence/NN towards/IN our/PRP$ hypothesis/NN as/RB well/RB as/IN it/PRP shows/VBZ that/IN such/PDT a/DT heuristic/NN is/VBZ required/VBN to/TO reach/VB state/NN of/IN the/DT art/NN results/NNS on/IN a/DT character/NN prediction/NN task/NN and/CC a/DT polyphonic/JJ music/NN prediction/NN one/CD ./.
