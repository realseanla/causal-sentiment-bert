A/DT deep/JJ learning/NN approach/NN has/VBZ been/VBN proposed/VBN recently/RB to/TO derive/VB speaker/NN identifies/VBZ (/-LRB- d/NN -/HYPH vector/NN )/-RRB- by/IN a/DT deep/JJ neural/JJ network/NN (/-LRB- DNN/NN )/-RRB- ./.
This/DT approach/NN has/VBZ been/VBN applied/VBN to/IN text/NN -/HYPH dependent/JJ speaker/NN recognition/NN tasks/NNS and/CC shows/VBZ reasonable/JJ performance/NN gains/NNS when/WRB combined/VBN with/IN the/DT conventional/JJ i/NN -/HYPH vector/NN approach/NN ./.
Although/IN promising/JJ ,/, the/DT existing/VBG d/NN -/HYPH vector/NN implementation/NN still/RB can/MD not/RB compete/VB with/IN the/DT i/NN -/HYPH vector/NN baseline/NN ./.
This/DT paper/NN presents/VBZ two/CD improvements/NNS for/IN the/DT deep/JJ learning/NN approach/NN :/: a/DT phonedependent/JJ DNN/NN structure/NN to/TO normalize/VB phone/NN variation/NN ,/, and/CC a/DT new/JJ scoring/NN approach/NN based/VBN on/IN dynamic/JJ time/NN warping/NN (/-LRB- DTW/NN )/-RRB- ./.
Experiments/NNS on/IN a/DT text/NN -/HYPH dependent/JJ speaker/NN recognition/NN task/NN demonstrated/VBD that/IN the/DT proposed/VBN methods/NNS can/MD provide/VB considerable/JJ performance/NN improvement/NN over/IN the/DT existing/VBG d/NN -/HYPH vector/NN implementation/NN ./.
