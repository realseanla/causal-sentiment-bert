We/PRP propose/VBP a/DT new/JJ method/NN for/IN learning/VBG word/NN representations/NNS using/VBG hierarchical/JJ regularization/NN in/IN sparse/JJ coding/NN inspired/VBN by/IN the/DT linguistic/JJ study/NN of/IN word/NN meanings/NNS ./.
We/PRP apply/VBP an/DT efficient/JJ online/NN and/CC distributed/VBN learning/NN method/NN ./.
Experiments/NNS on/IN various/JJ benchmark/NN tasks/NNS ---/, word/NN similarity/NN ranking/NN ,/, analogies/NNS ,/, sentence/NN completion/NN ,/, and/CC sentiment/NN analysis/NN ---/, demonstrate/VBP that/IN the/DT method/NN outperforms/VBZ or/CC is/VBZ competitive/JJ with/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN neural/JJ network/NN representations/NNS ./.
Our/PRP$ word/NN representations/NNS are/VBP available/JJ at/IN \/SYM url/NN {/-LRB-
