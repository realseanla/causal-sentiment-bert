We/PRP consider/VBP apprenticeship/NN learning/NN ,/, i.e./FW ,/, having/VBG an/DT agent/NN learn/VB a/DT task/NN by/IN observing/VBG an/DT expert/NN demonstrating/VBG the/DT task/NN in/IN a/DT partially/RB observable/JJ environment/NN when/WRB the/DT model/NN of/IN the/DT environment/NN is/VBZ uncertain/JJ ./.
This/DT setting/NN is/VBZ useful/JJ in/IN applications/NNS where/WRB the/DT explicit/JJ modeling/NN of/IN the/DT environment/NN is/VBZ difficult/JJ ,/, such/JJ as/IN a/DT dialogue/NN system/NN ./.
We/PRP show/VBP that/IN we/PRP can/MD extract/VB information/NN about/IN the/DT environment/NN model/NN by/IN inferring/VBG action/NN selection/NN process/NN behind/IN the/DT demonstration/NN ,/, under/IN the/DT assumption/NN that/IN the/DT expert/NN is/VBZ choosing/VBG optimal/JJ actions/NNS based/VBN on/IN knowledge/NN of/IN the/DT true/JJ model/NN of/IN the/DT target/NN environment/NN ./.
Proposed/VBN algorithms/NNS can/MD achieve/VB more/RBR accurate/JJ estimates/NNS of/IN POMDP/NN parameters/NNS and/CC better/JJR policies/NNS from/IN a/DT short/JJ demonstration/NN ,/, compared/VBN to/IN methods/NNS that/WDT learns/VBZ only/RB from/IN the/DT reaction/NN from/IN the/DT environment/NN ./.
