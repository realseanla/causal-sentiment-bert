Most/JJS of/IN the/DT existing/VBG image/NN -/HYPH to/IN -/HYPH image/NN translation/NN frameworks/NNS ---/, mapping/VBG an/DT image/NN in/IN one/CD domain/NN to/IN a/DT corresponding/VBG image/NN in/IN another/DT ---/, are/VBP based/VBN on/IN supervised/JJ learning/NN ,/, i.e./FW ,/, pairs/NNS of/IN corresponding/VBG images/NNS in/IN two/CD domains/NNS are/VBP required/VBN for/IN learning/VBG the/DT translation/NN function/NN ./.
This/DT largely/RB limits/VBZ their/PRP$ applications/NNS ,/, because/IN capturing/VBG corresponding/VBG images/NNS in/IN two/CD different/JJ domains/NNS is/VBZ often/RB a/DT difficult/JJ task/NN ./.
To/TO address/VB the/DT issue/NN ,/, we/PRP propose/VBP the/DT UNsupervised/JJ Image/NN -/HYPH to/IN -/HYPH image/NN Translation/NN (/-LRB- UNIT/NN )/-RRB- framework/NN ,/, which/WDT is/VBZ based/VBN on/IN variational/JJ autoencoders/NNS and/CC generative/JJ adversarial/JJ networks/NNS ./.
The/DT proposed/VBN framework/NN can/MD learn/VB the/DT translation/NN function/NN without/IN any/DT corresponding/VBG images/NNS in/IN two/CD domains/NNS ./.
We/PRP enable/VBP this/DT learning/NN capability/NN by/IN combining/VBG a/DT weight/NN -/HYPH sharing/VBG constraint/NN and/CC an/DT adversarial/JJ training/NN objective/NN ./.
Through/IN visualization/NN results/NNS from/IN various/JJ unsupervised/JJ image/NN translation/NN tasks/NNS ,/, we/PRP verify/VBP the/DT effectiveness/NN of/IN the/DT proposed/VBN framework/NN ./.
An/DT ablation/NN study/NN further/RB reveals/VBZ the/DT critical/JJ design/NN choices/NNS ./.
Moreover/RB ,/, we/PRP apply/VBP the/DT UNIT/NNP framework/NN to/IN the/DT unsupervised/JJ domain/NN adaptation/NN task/NN and/CC achieve/VB better/JJR results/NNS than/IN competing/VBG algorithms/NNS do/VBP in/IN benchmark/NN datasets/NNS ./.
