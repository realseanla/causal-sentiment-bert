The/DT essence/NN of/IN distantly/RB supervised/JJ relation/NN extraction/NN is/VBZ that/IN it/PRP is/VBZ an/DT incomplete/JJ multi-label/NN classification/NN problem/NN with/IN sparse/JJ and/CC noisy/JJ features/NNS ./.
To/TO tackle/VB the/DT sparsity/NN and/CC noise/NN challenges/NNS ,/, we/PRP propose/VBP solving/VBG the/DT classification/NN problem/NN using/VBG matrix/NN completion/NN on/IN factorized/JJ matrix/NN of/IN minimized/VBN rank/NN ./.
We/PRP formulate/VBP relation/NN classification/NN as/IN completing/VBG the/DT unknown/JJ labels/NNS of/IN testing/NN items/NNS (/-LRB- entity/NN pairs/NNS )/-RRB- in/IN a/DT sparse/JJ matrix/NN that/WDT concatenates/VBZ training/NN and/CC testing/NN textual/JJ features/NNS with/IN training/NN labels/NNS ./.
Our/PRP$ algorithmic/JJ framework/NN is/VBZ based/VBN on/IN the/DT assumption/NN that/IN the/DT rank/NN of/IN item/NN -/HYPH by/IN -/HYPH feature/NN and/CC item/NN -/HYPH by/IN -/HYPH label/NN joint/NN matrix/NN is/VBZ low/JJ ./.
We/PRP apply/VBP two/CD optimization/NN models/NNS to/TO recover/VB the/DT underlying/VBG low/JJ -/HYPH rank/NN matrix/NN leveraging/VBG the/DT sparsity/NN of/IN feature/NN -/HYPH label/NN matrix/NN ./.
The/DT matrix/NN completion/NN problem/NN is/VBZ then/RB solved/VBN by/IN the/DT fixed/VBN point/NN continuation/NN (/-LRB- FPC/NN )/-RRB- algorithm/NN ,/, which/WDT can/MD find/VB the/DT global/JJ optimum/JJ ./.
Experiments/NNS on/IN two/CD widely/RB used/VBN datasets/NNS with/IN different/JJ dimensions/NNS of/IN textual/JJ features/NNS demonstrate/VBP that/IN our/PRP$ low/JJ -/HYPH rank/NN matrix/NN completion/NN approach/NN significantly/RB outperforms/VBZ the/DT baseline/NN and/CC the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS ./.
