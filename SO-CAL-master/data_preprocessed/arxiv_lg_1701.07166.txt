Ensemble/NN learning/NN has/VBZ been/VBN widely/RB employed/VBN by/IN mobile/JJ applications/NNS ,/, ranging/VBG from/IN environmental/JJ sensing/VBG to/IN activity/NN recognitions/NNS ./.
One/CD of/IN the/DT fundamental/JJ issue/NN in/IN ensemble/NN learning/NN is/VBZ the/DT trade/NN -/HYPH off/NN between/IN classification/NN accuracy/NN and/CC computational/JJ costs/NNS ,/, which/WDT is/VBZ the/DT goal/NN of/IN ensemble/NN pruning/NN ./.
During/IN crowdsourcing/NN ,/, the/DT centralized/JJ aggregator/NN releases/NNS ensemble/NN learning/NN models/NNS to/IN a/DT large/JJ number/NN of/IN mobile/JJ participants/NNS for/IN task/NN evaluation/NN or/CC as/IN the/DT crowdsourcing/VBG learning/NN results/NNS ,/, while/IN different/JJ participants/NNS may/MD seek/VB for/IN different/JJ levels/NNS of/IN the/DT accuracy/NN -/HYPH cost/NN trade/NN -/HYPH off/NN ./.
However/RB ,/, most/JJS of/IN existing/VBG ensemble/NN pruning/NN approaches/VBZ consider/VB only/RB one/CD identical/JJ level/NN of/IN such/JJ trade/NN -/HYPH off/NN ./.
In/IN this/DT study/NN ,/, we/PRP present/VBP an/DT efficient/JJ ensemble/NN pruning/NN framework/NN for/IN personalized/VBN accuracy/NN -/HYPH cost/NN trade/NN -/HYPH offs/NNS via/IN multi-objective/JJ optimization/NN ./.
Specifically/RB ,/, for/IN the/DT commonly/RB used/VBN linear/JJ -/HYPH combination/NN style/NN of/IN the/DT trade/NN -/HYPH off/NN ,/, we/PRP provide/VBP an/DT objective/JJ -/HYPH mixture/NN optimization/NN to/TO further/RB reduce/VB the/DT number/NN of/IN ensemble/NN candidates/NNS ./.
Experimental/JJ results/NNS show/VBP that/IN our/PRP$ framework/NN is/VBZ highly/RB efficient/JJ for/IN personalized/VBN ensemble/NN pruning/NN ,/, and/CC achieves/VBZ much/RB better/JJR pruning/NN performance/NN with/IN objective/JJ -/HYPH mixture/NN optimization/NN when/WRB compared/VBN to/IN state/NN -/HYPH of/IN -/HYPH art/NN approaches/NNS ./.
