In/IN this/DT work/NN we/PRP introduce/VBP a/DT comprehensive/JJ algorithmic/JJ pipeline/NN for/IN multiple/JJ parametric/JJ model/NN estimation/NN ./.
The/DT proposed/VBN approach/NN analyzes/VBZ the/DT information/NN produced/VBN by/IN a/DT random/JJ sampling/NN algorithm/NN (/-LRB- e.g./FW ,/, RANSAC/NN )/-RRB- from/IN a/DT machine/NN learning/NN //HYPH optimization/NN perspective/NN ,/, using/VBG a/DT \/NN textit/NN {/-LRB- parameterless/JJ }/-RRB- biclustering/VBG algorithm/NN based/VBN on/IN L1/NN nonnegative/JJ matrix/NN factorization/NN (/-LRB- L1/NN -/HYPH NMF/NN )/-RRB- ./.
The/DT proposed/VBN framework/NN exploits/NNS consistent/JJ patterns/NNS that/WDT naturally/RB arise/VBP during/IN the/DT RANSAC/NN execution/NN ,/, while/IN explicitly/RB avoiding/VBG spurious/JJ inconsistencies/NNS ./.
Contrarily/RB to/IN the/DT main/JJ trends/NNS in/IN the/DT literature/NN ,/, the/DT proposed/VBN technique/NN does/VBZ not/RB impose/VB non-intersecting/JJ parametric/JJ models/NNS ./.
A/DT new/JJ accelerated/VBN algorithm/NN to/IN compute/VB L1/NN -/HYPH NMFs/NN allows/VBZ to/TO handle/VB medium/JJ -/HYPH sized/JJ problems/NNS faster/RBR while/IN also/RB extending/VBG the/DT usability/NN of/IN the/DT algorithm/NN to/TO much/RB larger/JJR datasets/NNS ./.
This/DT accelerated/VBD algorithm/NN has/VBZ applications/NNS in/IN any/DT other/JJ context/NN where/WRB an/DT L1/NN -/HYPH NMF/NN is/VBZ needed/VBN ,/, beyond/IN the/DT biclustering/VBG approach/NN to/IN parameter/NN estimation/NN here/RB addressed/VBD ./.
We/PRP accompany/VBP the/DT algorithmic/JJ presentation/NN with/IN theoretical/JJ foundations/NNS and/CC numerous/JJ and/CC diverse/JJ examples/NNS ./.
