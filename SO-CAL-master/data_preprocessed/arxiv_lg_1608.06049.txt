We/PRP propose/VBP local/JJ binary/JJ convolution/NN (/-LRB- LBC/NNP )/-RRB- ,/, an/DT efficient/JJ alternative/NN to/IN convolutional/JJ layers/NNS in/IN standard/JJ convolutional/JJ neural/JJ networks/NNS (/-LRB- CNN/NNP )/-RRB- ./.
The/DT design/NN principles/NNS of/IN LBC/NNP are/VBP motivated/VBN by/IN local/JJ binary/JJ patterns/NNS (/-LRB- LBP/NN )/-RRB- ./.
The/DT LBC/NNP layer/NN comprises/VBZ of/IN a/DT set/NN of/IN fixed/VBN sparse/JJ pre-defined/JJ binary/JJ convolutional/JJ filters/NNS that/WDT are/VBP not/RB updated/VBN during/IN the/DT training/NN process/NN ,/, a/DT non-linear/JJ activation/NN function/NN and/CC a/DT set/NN of/IN learnable/JJ linear/JJ weights/NNS ./.
The/DT linear/JJ weights/NNS combine/VBP the/DT activated/VBN filter/NN responses/NNS to/IN approximate/JJ the/DT corresponding/VBG activated/VBN filter/NN responses/NNS of/IN a/DT standard/JJ convolutional/JJ layer/NN ./.
The/DT LBC/NNP layer/NN affords/VBZ significant/JJ parameter/NN savings/NNS ,/, 9x/NN to/IN 169x/NN in/IN the/DT number/NN of/IN learnable/JJ parameters/NNS compared/VBN to/IN a/DT standard/JJ convolutional/JJ layer/NN ./.
Furthermore/RB ,/, due/IN to/IN lower/JJR model/NN complexity/NN and/CC sparse/JJ and/CC binary/JJ nature/NN of/IN the/DT weights/NNS also/RB results/VBZ in/IN up/RB to/IN 9x/NN to/IN 169x/CD savings/NNS in/IN model/NN size/NN compared/VBN to/IN a/DT standard/JJ convolutional/JJ layer/NN ./.
We/PRP demonstrate/VBP both/DT theoretically/RB and/CC experimentally/RB that/IN our/PRP$ local/JJ binary/JJ convolution/NN layer/NN is/VBZ a/DT good/JJ approximation/NN of/IN a/DT standard/JJ convolutional/JJ layer/NN ./.
Empirically/RB ,/, CNNs/NNS with/IN LBC/NNP layers/NNS ,/, called/VBD local/JJ binary/JJ convolutional/JJ neural/JJ networks/NNS (/-LRB- LBCNN/NNP )/-RRB- ,/, reach/VBP state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN on/IN a/DT range/NN of/IN visual/JJ datasets/NNS (/-LRB- MNIST/NNP ,/, SVHN/NNP ,/, CIFAR/NNP -/HYPH 10/CD ,/, and/CC a/DT subset/NN of/IN ImageNet/NNP )/-RRB- while/IN enjoying/VBG significant/JJ computational/JJ savings/NNS ./.
