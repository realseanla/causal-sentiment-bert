We/PRP consider/VBP the/DT problem/NN of/IN sparse/JJ variable/JJ selection/NN in/IN nonparametric/JJ additive/JJ models/NNS ,/, with/IN the/DT prior/JJ knowledge/NN of/IN the/DT structure/NN among/IN the/DT covariates/NNS to/TO encourage/VB those/DT variables/NNS within/IN a/DT group/NN to/TO be/VB selected/VBN jointly/RB ./.
Previous/JJ works/NNS either/CC study/VB the/DT group/NN sparsity/NN in/IN the/DT parametric/JJ setting/NN (/-LRB- e.g./FW ,/, group/NN lasso/NN )/-RRB- ,/, or/CC address/VB the/DT problem/NN in/IN the/DT non-parametric/JJ setting/NN without/IN exploiting/VBG the/DT structural/JJ information/NN (/-LRB- e.g./FW ,/, sparse/JJ additive/JJ models/NNS )/-RRB- ./.
In/IN this/DT paper/NN ,/, we/PRP present/VBP a/DT new/JJ method/NN ,/, called/VBN group/NN sparse/JJ additive/JJ models/NNS (/-LRB- GroupSpAM/NNP )/-RRB- ,/, which/WDT can/MD handle/VB group/NN sparsity/NN in/IN additive/JJ models/NNS ./.
We/PRP generalize/VBP the/DT l1/NN //HYPH l2/NN norm/NN to/IN Hilbert/NNP spaces/NNS as/IN the/DT sparsity/NN -/HYPH inducing/VBG penalty/NN in/IN GroupSpAM/NNP ./.
Moreover/RB ,/, we/PRP derive/VBP a/DT novel/JJ thresholding/NN condition/NN for/IN identifying/VBG the/DT functional/JJ sparsity/NN at/IN the/DT group/NN level/NN ,/, and/CC propose/VB an/DT efficient/JJ block/NN coordinate/NN descent/NN algorithm/NN for/IN constructing/VBG the/DT estimate/NN ./.
We/PRP demonstrate/VBP by/IN simulation/NN that/WDT GroupSpAM/NNP substantially/RB outperforms/VBZ the/DT competing/VBG methods/NNS in/IN terms/NNS of/IN support/NN recovery/NN and/CC prediction/NN accuracy/NN in/IN additive/JJ models/NNS ,/, and/CC also/RB conduct/VB a/DT comparative/JJ experiment/NN on/IN a/DT real/JJ breast/NN cancer/NN dataset/NN ./.
