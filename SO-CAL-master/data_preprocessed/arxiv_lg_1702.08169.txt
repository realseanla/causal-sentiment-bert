We/PRP study/VBP the/DT fundamental/JJ problem/NN of/IN Principal/NN Component/NN Analysis/NN in/IN a/DT statistical/JJ distributed/VBN setting/NN in/IN which/WDT each/DT machine/NN out/IN of/IN $/$ m/CD $/$ stores/NNS a/DT sample/NN of/IN $/$ n/NN $/$ points/NNS sampled/VBN i.i.d./RB from/IN a/DT single/RB unknown/JJ distribution/NN ./.
We/PRP study/VBP algorithms/NNS for/IN estimating/VBG the/DT leading/VBG principal/JJ component/NN of/IN the/DT population/NN covariance/NN matrix/NN that/WDT are/VBP both/DT communication/NN -/HYPH efficient/JJ and/CC achieve/VB estimation/NN error/NN of/IN the/DT order/NN of/IN the/DT centralized/JJ ERM/NN solution/NN that/WDT uses/VBZ all/DT $/$ mn/CD $/$ samples/NNS ./.
On/IN the/DT negative/JJ side/NN ,/, we/PRP show/VBP that/IN in/IN contrast/NN to/IN results/NNS obtained/VBN for/IN distributed/VBN estimation/NN under/IN convexity/NN assumptions/NNS ,/, for/IN the/DT PCA/NN objective/NN ,/, simply/RB averaging/VBG the/DT local/JJ ERM/NNP solutions/NNS can/MD not/RB guarantee/VB error/NN that/WDT is/VBZ consistent/JJ with/IN the/DT centralized/JJ ERM/NNP ./.
We/PRP show/VBP that/IN this/DT unfortunate/JJ phenomena/NN can/MD be/VB remedied/VBN by/IN performing/VBG a/DT simple/JJ correction/NN step/NN which/WDT correlates/VBZ between/IN the/DT individual/JJ solutions/NNS ,/, and/CC provides/VBZ an/DT estimator/NN that/WDT is/VBZ consistent/JJ with/IN the/DT centralized/JJ ERM/NNP for/IN sufficiently/RB -/HYPH large/JJ $/NN n/NN $/$ ./.
We/PRP also/RB introduce/VBP an/DT iterative/JJ distributed/VBN algorithm/NN that/WDT is/VBZ applicable/JJ in/IN any/DT regime/NN of/IN $/$ n/NN $/$ ,/, which/WDT is/VBZ based/VBN on/IN distributed/VBN matrix/NN -/HYPH vector/NN products/NNS ./.
The/DT algorithm/NN gives/VBZ significant/JJ acceleration/NN in/IN terms/NNS of/IN communication/NN rounds/NNS over/IN previous/JJ distributed/VBN algorithms/NNS ,/, in/IN a/DT wide/JJ regime/NN of/IN parameters/NNS ./.
