Gaussian/JJ Graphical/JJ Models/NNS (/-LRB- GGMs/NNS )/-RRB- or/CC Gauss/NNP Markov/NNP random/JJ fields/NNS are/VBP widely/RB used/VBN in/IN many/JJ applications/NNS ,/, and/CC the/DT trade/NN -/HYPH off/NN between/IN the/DT modeling/NN capacity/NN and/CC the/DT efficiency/NN of/IN learning/NN and/CC inference/NN has/VBZ been/VBN an/DT important/JJ research/NN problem/NN ./.
In/IN this/DT paper/NN ,/, we/PRP study/VBP the/DT family/NN of/IN GGMs/NNS with/IN small/JJ feedback/NN vertex/NN sets/NNS (/-LRB- FVSs/NNS )/-RRB- ,/, where/WRB an/DT FVS/NN is/VBZ a/DT set/NN of/IN nodes/NNS whose/WP$ removal/NN breaks/VBZ all/PDT the/DT cycles/NNS ./.
Exact/JJ inference/NN such/JJ as/IN computing/VBG the/DT marginal/JJ distributions/NNS and/CC the/DT partition/NN function/NN has/VBZ complexity/NN $/$ O/UH (/-LRB- k/CD ^/SYM {/-LRB- 2/CD }/-RRB- n/NN )/-RRB- $/$ using/VBG message/NN -/HYPH passing/VBG algorithms/NNS ,/, where/WRB k/NN is/VBZ the/DT size/NN of/IN the/DT FVS/NNP ,/, and/CC n/NN is/VBZ the/DT total/JJ number/NN of/IN nodes/NNS ./.
We/PRP propose/VBP efficient/JJ structure/NN learning/VBG algorithms/NNS for/IN two/CD cases/NNS :/: 1/LS )/-RRB- All/DT nodes/NNS are/VBP observed/VBN ,/, which/WDT is/VBZ useful/JJ in/IN modeling/VBG social/JJ or/CC flight/NN networks/NNS where/WRB the/DT FVS/NNP nodes/NNS often/RB correspond/VBP to/IN a/DT small/JJ number/NN of/IN high/JJ -/HYPH degree/NN nodes/NNS ,/, or/CC hubs/NNS ,/, while/IN the/DT rest/NN of/IN the/DT networks/NNS is/VBZ modeled/VBN by/IN a/DT tree/NN ./.
Regardless/RB of/IN the/DT maximum/JJ degree/NN ,/, without/IN knowing/VBG the/DT full/JJ graph/NN structure/NN ,/, we/PRP can/MD exactly/RB compute/VB the/DT maximum/JJ likelihood/NN estimate/NN in/IN $/$ O/UH (/-LRB- kn/NNP ^/SYM 2/CD n/NN ^/SYM 2/CD \/SYM log/NN n/NN )/-RRB- $/$ if/IN the/DT FVS/NNP is/VBZ known/VBN or/CC in/IN polynomial/JJ time/NN if/IN the/DT FVS/NNP is/VBZ unknown/JJ but/CC has/VBZ bounded/VBN size/NN ./.
2/LS )/-RRB- The/DT FVS/NNP nodes/NNS are/VBP latent/JJ variables/NNS ,/, where/WRB structure/NN learning/NN is/VBZ equivalent/JJ to/IN decomposing/VBG a/DT inverse/JJ covariance/NN matrix/NN (/-LRB- exactly/RB or/CC approximately/RB )/-RRB- into/IN the/DT sum/NN of/IN a/DT tree/NN -/HYPH structured/VBN matrix/NN and/CC a/DT low/JJ -/HYPH rank/NN matrix/NN ./.
By/IN incorporating/VBG efficient/JJ inference/NN into/IN the/DT learning/NN steps/NNS ,/, we/PRP can/MD obtain/VB a/DT learning/NN algorithm/NN using/VBG alternating/VBG low/JJ -/HYPH rank/NN correction/NN with/IN complexity/NN $/$ O/UH (/-LRB- kn/NNP ^/SYM {/-LRB- 2/CD }/-RRB- n/NN ^/SYM {/-LRB- 2/CD }/-RRB- \/SYM log/NN n/NN )/-RRB- $/$ per/IN iteration/NN ./.
We/PRP also/RB perform/VBP experiments/NNS using/VBG both/CC synthetic/JJ data/NNS as/RB well/RB as/IN real/JJ data/NNS of/IN flight/NN delays/NNS to/TO demonstrate/VB the/DT modeling/NN capacity/NN with/IN FVSs/NNS of/IN various/JJ sizes/NNS ./.
