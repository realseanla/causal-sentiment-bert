We/PRP study/VBP the/DT model/NN of/IN projective/JJ simulation/NN (/-LRB- PS/NN )/-RRB- which/WDT is/VBZ a/DT novel/JJ approach/NN to/IN artificial/JJ intelligence/NN (/-LRB- AI/NN )/-RRB- ./.
Recently/RB it/PRP was/VBD shown/VBN that/IN the/DT PS/NNP agent/NN performs/VBZ well/RB in/IN a/DT number/NN of/IN simple/JJ task/NN environments/NNS ,/, also/RB when/WRB compared/VBN to/IN standard/JJ models/NNS of/IN reinforcement/NN learning/NN (/-LRB- RL/NN )/-RRB- ./.
In/IN this/DT paper/NN we/PRP study/VBP the/DT performance/NN of/IN the/DT PS/NNP agent/NN further/RB in/IN more/RBR complicated/JJ scenarios/NNS ./.
To/IN that/DT end/NN we/PRP chose/VBD two/CD well/RB -/HYPH studied/VBN benchmarking/NN problems/NNS ,/, namely/RB the/DT "/`` grid/NN -/HYPH world/NN "/'' and/CC the/DT "/`` mountain/NN -/HYPH car/NN "/'' problem/NN ,/, which/WDT challenge/VBP the/DT model/NN with/IN large/JJ and/CC continuous/JJ input/NN space/NN ./.
We/PRP compare/VBP the/DT performance/NN of/IN the/DT PS/NNP agent/NN model/NN with/IN those/DT of/IN existing/VBG models/NNS and/CC show/VBP that/IN the/DT PS/NNP agent/NN exhibits/VBZ competitive/JJ performance/NN also/RB in/IN such/JJ scenarios/NNS ./.
