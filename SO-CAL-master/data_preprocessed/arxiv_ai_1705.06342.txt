In/IN this/DT work/NN ,/, we/PRP present/VBP a/DT methodology/NN that/WDT enables/VBZ an/DT agent/NN to/TO make/VB efficient/JJ use/NN of/IN its/PRP$ exploratory/JJ actions/NNS by/IN autonomously/RB identifying/VBG possible/JJ objectives/NNS in/IN its/PRP$ environment/NN and/CC learning/VBG them/PRP in/IN parallel/NN ./.
The/DT identification/NN of/IN objectives/NNS is/VBZ achieved/VBN using/VBG an/DT online/JJ and/CC unsupervised/JJ adaptive/JJ clustering/NN algorithm/NN ./.
The/DT identified/VBN objectives/NNS are/VBP learned/VBN (/-LRB- at/IN least/RBS partially/RB )/-RRB- in/IN parallel/NN using/VBG Q/NN -/HYPH learning/NN ./.
Using/VBG a/DT simulated/JJ agent/NN and/CC environment/NN ,/, it/PRP is/VBZ shown/VBN that/IN the/DT converged/VBN or/CC partially/RB converged/VBN value/NN function/VBP weights/NNS resulting/VBG from/IN off/RB -/HYPH policy/NN learning/NN can/MD be/VB used/VBN to/TO accumulate/VB knowledge/NN about/IN multiple/JJ objectives/NNS without/IN any/DT additional/JJ exploration/NN ./.
We/PRP claim/VBP that/IN the/DT proposed/VBN approach/NN could/MD be/VB useful/JJ in/IN scenarios/NNS where/WRB the/DT objectives/NNS are/VBP initially/RB unknown/JJ or/CC in/IN real/JJ world/NN scenarios/NNS where/WRB exploration/NN is/VBZ typically/RB a/DT time/NN and/CC energy/NN intensive/JJ process/NN ./.
The/DT implications/NNS and/CC possible/JJ extensions/NNS of/IN this/DT work/NN are/VBP also/RB briefly/RB discussed/VBN ./.
