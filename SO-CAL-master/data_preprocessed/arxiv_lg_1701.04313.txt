End/NN -/HYPH to/IN -/HYPH end/NN (/-LRB- E2E/NN )/-RRB- systems/NNS have/VBP achieved/VBN competitive/JJ results/NNS compared/VBN to/IN conventional/JJ hybrid/NN hidden/VBN Markov/NNP model/NN (/-LRB- HMM/NN )/-RRB- -/HYPH deep/JJ neural/JJ network/NN based/VBN automatic/JJ speech/NN recognition/NN (/-LRB- ASR/NN )/-RRB- systems/NNS ./.
Such/JJ E2E/NN systems/NNS are/VBP attractive/JJ due/IN to/IN the/DT lack/NN of/IN dependence/NN on/IN alignments/NNS between/IN input/NN acoustic/JJ and/CC output/NN grapheme/NN or/CC HMM/NN state/NN sequence/NN during/IN training/NN ./.
This/DT paper/NN explores/VBZ the/DT design/NN of/IN an/DT ASR/NN -/HYPH free/JJ end/NN -/HYPH to/IN -/HYPH end/NN system/NN for/IN text/NN query/NN -/HYPH based/VBN keyword/JJ search/NN (/-LRB- KWS/NN )/-RRB- from/IN speech/NN trained/VBN with/IN minimal/JJ supervision/NN ./.
Our/PRP$ E2E/NN KWS/NN system/NN consists/VBZ of/IN three/CD sub-systems/NNS ./.
The/DT first/JJ sub-system/NN is/VBZ a/DT recurrent/JJ neural/JJ network/NN (/-LRB- RNN/NN )/-RRB- -/HYPH based/VBN acoustic/JJ auto/NN -/HYPH encoder/NN trained/VBN to/TO reconstruct/VB the/DT audio/NN through/IN a/DT finite/NN -/HYPH dimensional/JJ representation/NN ./.
The/DT second/JJ sub-system/NN is/VBZ a/DT character/NN -/HYPH level/NN RNN/NN language/NN model/NN using/VBG embeddings/NNS learned/VBN from/IN a/DT convolutional/JJ neural/JJ network/NN ./.
Since/IN the/DT acoustic/JJ and/CC text/NN query/NN embeddings/NNS occupy/VBP different/JJ representation/NN spaces/NNS ,/, they/PRP are/VBP input/NN to/IN a/DT third/JJ feed/NN -/HYPH forward/JJ neural/JJ network/NN that/WDT predicts/VBZ whether/IN the/DT query/NN occurs/VBZ in/IN the/DT acoustic/JJ utterance/NN or/CC not/RB ./.
This/DT E2E/NN ASR/NN -/HYPH free/JJ KWS/NN system/NN performs/VBZ respectably/RB despite/IN lacking/VBG a/DT conventional/JJ ASR/NN system/NN and/CC trains/NNS much/RB faster/RBR ./.
