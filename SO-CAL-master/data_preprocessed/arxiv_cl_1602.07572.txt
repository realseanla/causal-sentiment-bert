Embeddings/NNS are/VBP generic/JJ representations/NNS that/WDT are/VBP useful/JJ for/IN many/JJ NLP/NN tasks/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP introduce/VBP DENSIFIER/NNP ,/, a/DT method/NN that/WDT learns/VBZ an/DT orthogonal/JJ transformation/NN of/IN the/DT embedding/NN space/NN that/WDT focuses/VBZ the/DT information/NN relevant/JJ for/IN a/DT task/NN in/IN an/DT ultradense/JJ subspace/NN of/IN a/DT dimensionality/NN that/WDT is/VBZ smaller/JJR by/IN a/DT factor/NN of/IN 100/CD than/IN the/DT original/JJ space/NN ./.
We/PRP show/VBP that/IN ultradense/JJ embeddings/NNS generated/VBN by/IN DENSIFIER/NNP reach/VBP state/NN of/IN the/DT art/NN on/IN a/DT lexicon/NN creation/NN task/NN in/IN which/WDT words/NNS are/VBP annotated/VBN with/IN three/CD types/NNS of/IN lexical/JJ information/NN -/HYPH sentiment/NN ,/, concreteness/NN and/CC frequency/NN ./.
On/IN the/DT SemEval2015/NN 10B/NN sentiment/NN analysis/NN task/NN we/PRP show/VBP that/IN no/DT information/NN is/VBZ lost/VBN when/WRB the/DT ultradense/JJ subspace/NN is/VBZ used/VBN ,/, but/CC training/NN is/VBZ an/DT order/NN of/IN magnitude/NN more/RBR efficient/JJ due/IN to/IN the/DT compactness/NN of/IN the/DT ultradense/JJ space/NN ./.
