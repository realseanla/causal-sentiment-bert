It/PRP is/VBZ challenging/VBG to/TO develop/VB stochastic/JJ gradient/NN based/VBN scalable/JJ inference/NN for/IN deep/JJ discrete/JJ latent/JJ variable/JJ models/NNS (/-LRB- LVMs/NNS )/-RRB- ,/, due/IN to/IN the/DT difficulties/NNS in/IN not/RB only/RB computing/VBG the/DT gradients/NNS ,/, but/CC also/RB adapting/VBG the/DT step/NN sizes/VBZ to/IN different/JJ latent/JJ factors/NNS and/CC hidden/JJ layers/NNS ./.
For/IN the/DT Poisson/NNP gamma/NN belief/NN network/NN (/-LRB- PGBN/NN )/-RRB- ,/, a/DT recently/RB proposed/VBN deep/JJ discrete/JJ LVM/NN ,/, we/PRP derive/VBP an/DT alternative/JJ representation/NN that/WDT is/VBZ referred/VBN to/IN as/RB deep/JJ latent/NN Dirichlet/NNP allocation/NN (/-LRB- DLDA/NN )/-RRB- ./.
Exploiting/VBG data/NNS augmentation/NN and/CC marginalization/NN techniques/NNS ,/, we/PRP derive/VBP a/DT block/NN -/HYPH diagonal/JJ Fisher/NNP information/NN matrix/NN and/CC its/PRP$ inverse/JJ for/IN the/DT simplex/NN -/HYPH constrained/VBN global/JJ model/NN parameters/NNS of/IN DLDA/NNP ./.
Exploiting/VBG that/IN Fisher/NNP information/NN matrix/NN with/IN stochastic/JJ gradient/NN MCMC/NNP ,/, we/PRP present/VBP topic/NN -/HYPH layer/NN -/HYPH adaptive/JJ stochastic/JJ gradient/NN Riemannian/NNP (/-LRB- TLASGR/NNP )/-RRB- MCMC/NNP that/WDT jointly/RB learns/VBZ simplex/NN -/HYPH constrained/VBN global/JJ parameters/NNS across/IN all/DT layers/NNS and/CC topics/NNS ,/, with/IN topic/NN and/CC layer/NN specific/JJ learning/NN rates/NNS ./.
State/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS are/VBP demonstrated/VBN on/IN big/JJ data/NNS sets/NNS ./.
