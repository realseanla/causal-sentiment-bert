Performance/NN of/IN end/NN -/HYPH to/IN -/HYPH end/NN automatic/JJ speech/NN recognition/NN (/-LRB- ASR/NN )/-RRB- systems/NNS can/MD significantly/RB be/VB improved/VBN by/IN the/DT increasing/VBG large/JJ speech/NN corpus/NN and/CC deeper/JJR neural/JJ network/NN ./.
Given/VBN the/DT arising/VBG problem/NN of/IN training/NN speed/NN and/CC recent/JJ success/NN of/IN deep/JJ convolutional/JJ neural/JJ network/NN in/IN ASR/NNP ,/, we/PRP build/VBP a/DT novel/JJ deep/JJ recurrent/JJ convolutional/JJ network/NN for/IN acoustic/JJ modeling/NN and/CC apply/VB deep/JJ residual/JJ learning/NN framework/NN to/IN it/PRP ,/, our/PRP$ experiments/NNS show/VBP that/IN it/PRP has/VBZ not/RB only/RB faster/RBR convergence/NN speed/NN but/CC better/JJR recognition/NN accuracy/NN over/IN traditional/JJ deep/JJ convolutional/JJ recurrent/JJ network/NN ./.
We/PRP mainly/RB compare/VBP convergence/NN speed/NN of/IN two/CD acoustic/JJ models/NNS ,/, which/WDT are/VBP novel/JJ deep/JJ recurrent/JJ convolutional/JJ networks/NNS and/CC traditional/JJ deep/JJ convolutional/JJ recurrent/JJ networks/NNS ./.
With/IN faster/JJR convergence/NN speed/NN ,/, our/PRP$ novel/JJ deep/JJ recurrent/JJ convolutional/JJ networks/NNS can/MD reach/VB the/DT comparable/JJ performance/NN ./.
We/PRP further/RB show/VBP that/IN applying/VBG deep/JJ residual/JJ learning/NN can/MD boost/VB both/DT convergence/NN speed/NN and/CC recognition/NN accuracy/NN of/IN our/PRP$ novel/JJ recurret/NN convolutional/JJ networks/NNS ./.
Finally/RB ,/, we/PRP evaluate/VBP all/PDT our/PRP$ experimental/JJ networks/NNS by/IN phoneme/NN error/NN rate/NN (/-LRB- PER/NN )/-RRB- with/IN newly/RB proposed/VBN bidirectional/JJ statistical/JJ language/NN model/NN ./.
Our/PRP$ evaluation/NN results/NNS show/VBP that/IN our/PRP$ model/NN applied/VBN with/IN deep/JJ residual/JJ learning/NN can/MD reach/VB the/DT best/JJS PER/NN of/IN 17.33/CD percent/NN with/IN fastest/JJS convergence/NN speed/NN in/IN TIMIT/NNP database/NN ./.
