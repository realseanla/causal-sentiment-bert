We/PRP consider/VBP the/DT problem/NN of/IN a/DT robot/NN learning/VBG the/DT mechanical/JJ properties/NNS of/IN objects/NNS through/IN physical/JJ interaction/NN with/IN the/DT object/NN ,/, and/CC introduce/VB a/DT practical/JJ ,/, data/NN -/HYPH efficient/JJ approach/NN for/IN identifying/VBG the/DT motion/NN models/NNS of/IN these/DT objects/NNS ./.
The/DT proposed/JJ method/NN utilizes/VBZ a/DT physics/NN engine/NN ,/, where/WRB the/DT robot/NN seeks/VBZ to/TO identify/VB the/DT inertial/JJ and/CC friction/NN parameters/NNS of/IN the/DT object/NN by/IN simulating/VBG its/PRP$ motion/NN under/IN different/JJ values/NNS of/IN the/DT parameters/NNS and/CC identifying/VBG those/DT that/WDT result/VBP in/IN a/DT simulation/NN which/WDT matches/VBZ the/DT observed/VBN real/JJ motions/NNS ./.
The/DT problem/NN is/VBZ solved/VBN in/IN a/DT Bayesian/JJ optimization/NN framework/NN ./.
The/DT same/JJ framework/NN is/VBZ used/VBN for/IN both/DT identifying/VBG the/DT model/NN of/IN an/DT object/NN online/RB and/CC searching/VBG for/IN a/DT policy/NN that/WDT would/MD minimize/VB a/DT given/VBN cost/NN function/NN according/VBG to/IN the/DT identified/VBN model/NN ./.
Experimental/JJ results/NNS both/CC in/IN simulation/NN and/CC using/VBG a/DT real/JJ robot/NN indicate/VBP that/IN the/DT proposed/JJ method/NN outperforms/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN model/NN -/HYPH free/JJ reinforcement/NN learning/VBG approaches/NNS ./.
