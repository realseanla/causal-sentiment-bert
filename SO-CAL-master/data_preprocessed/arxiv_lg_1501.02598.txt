We/PRP extend/VBP the/DT effective/JJ SKIP/NNP -/HYPH GRAM/NNP model/NN of/IN Mikolov/NNP et/FW al./FW (/-LRB- 2013/CD )/-RRB- by/IN taking/VBG visual/JJ information/NN into/IN account/NN ./.
Like/IN S/NNP KIP/NNP -/HYPH GRAM/NNP ,/, our/PRP$ multimodal/JJ models/NNS (/-LRB- MMSKIP/NN -/HYPH GRAM/NN )/-RRB- build/NN vector/NN -/HYPH based/VBN word/NN representations/NNS by/IN learning/VBG to/TO predict/VB linguistic/JJ contexts/NNS in/IN text/NN corpora/NNS ./.
However/RB ,/, for/IN a/DT restricted/VBN set/NN of/IN words/NNS ,/, the/DT models/NNS are/VBP also/RB exposed/VBN to/IN visual/JJ representations/NNS of/IN the/DT objects/NNS they/PRP denote/VBP (/-LRB- extracted/VBN from/IN natural/JJ images/NNS )/-RRB- ,/, and/CC must/MD predict/VB linguistic/JJ and/CC visual/JJ features/NNS jointly/RB ./.
The/DT MMS/NNP KIP/NNP -/HYPH GRAM/NNP models/NNS achieve/VBP excellent/JJ performance/NN on/IN a/DT variety/NN of/IN semantic/JJ benchmarks/NNS ./.
Moreover/RB ,/, since/IN they/PRP propagate/VBP visual/JJ information/NN to/IN all/DT words/NNS ,/, we/PRP also/RB use/VBP them/PRP to/TO improve/VB image/NN labeling/NN and/CC retrieval/NN in/IN the/DT challenging/JJ zero/CD -/HYPH shot/NN setup/NN ,/, where/WRB the/DT test/NN concepts/NNS are/VBP not/RB seen/VBN in/IN training/NN ./.
Finally/RB ,/, the/DT MMS/NNP KIP/NNP -/HYPH GRAM/NNP models/NNS discover/VBP intriguing/JJ vision/NN -/HYPH related/VBN properties/NNS of/IN abstract/JJ words/NNS ,/, paving/VBG the/DT way/NN to/IN realistic/JJ implementations/NNS of/IN embodied/VBN theories/NNS of/IN meaning/NN ./.
