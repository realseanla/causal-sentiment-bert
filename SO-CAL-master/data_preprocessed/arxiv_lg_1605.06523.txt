Large/JJ knowledge/NN bases/NNS (/-LRB- KBs/NNS )/-RRB- are/VBP useful/JJ in/IN many/JJ tasks/NNS ,/, but/CC it/PRP is/VBZ unclear/JJ how/WRB to/TO integrate/VB this/DT sort/NN of/IN knowledge/NN into/IN "/`` deep/JJ "/'' gradient/NN -/HYPH based/VBN learning/NN systems/NNS ./.
To/TO address/VB this/DT problem/NN ,/, we/PRP describe/VBP a/DT probabilistic/JJ deductive/JJ database/NN ,/, called/VBN TensorLog/NNP ,/, in/IN which/WDT reasoning/NN uses/VBZ a/DT differentiable/JJ process/NN ./.
In/IN TensorLog/NNP ,/, each/DT clause/NN in/IN a/DT logical/JJ theory/NN is/VBZ first/JJ converted/VBD into/IN certain/JJ type/NN of/IN factor/NN graph/NN ./.
Then/RB ,/, for/IN each/DT type/NN of/IN query/NN to/IN the/DT factor/NN graph/NN ,/, the/DT message/NN -/HYPH passing/VBG steps/NNS required/VBN to/TO perform/VB belief/NN propagation/NN (/-LRB- BP/NN )/-RRB- are/VBP "/`` unrolled/JJ "/'' into/IN a/DT function/NN ,/, which/WDT is/VBZ differentiable/JJ ./.
We/PRP show/VBP that/IN these/DT functions/NNS can/MD be/VB composed/VBN recursively/RB to/TO perform/VB inference/NN in/IN non-trivial/JJ logical/JJ theories/NNS containing/VBG multiple/JJ interrelated/JJ clauses/NNS and/CC predicates/NNS ./.
Both/DT compilation/NN and/CC inference/NN in/IN TensorLog/NNP are/VBP efficient/JJ :/: compilation/NN is/VBZ linear/JJ in/IN theory/NN size/NN and/CC proof/NN depth/NN ,/, and/CC inference/NN is/VBZ linear/JJ in/IN database/NN size/NN and/CC the/DT number/NN of/IN message/NN -/HYPH passing/VBG steps/NNS used/VBN in/IN BP/NN ./.
We/PRP also/RB present/JJ experimental/JJ results/NNS with/IN TensorLog/NNP and/CC discuss/VB its/PRP$ relationship/NN to/IN other/JJ first/JJ -/HYPH order/NN probabilistic/JJ logics/NNS ./.
