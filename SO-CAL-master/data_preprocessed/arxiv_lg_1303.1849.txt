We/PRP reconsider/VBP randomized/JJ algorithms/NNS for/IN the/DT low/JJ -/HYPH rank/NN approximation/NN of/IN symmetric/JJ positive/JJ semi-definite/NN (/-LRB- SPSD/NN )/-RRB- matrices/NNS such/JJ as/IN Laplacian/NNP and/CC kernel/NN matrices/NNS that/WDT arise/VBP in/IN data/NNS analysis/NN and/CC machine/NN learning/NN applications/NNS ./.
Our/PRP$ main/JJ results/NNS consist/VBP of/IN an/DT empirical/JJ evaluation/NN of/IN the/DT performance/NN quality/NN and/CC running/NN time/NN of/IN sampling/NN and/CC projection/NN methods/NNS on/IN a/DT diverse/JJ suite/NN of/IN SPSD/NN matrices/NNS ./.
Our/PRP$ results/NNS highlight/VBP complementary/JJ aspects/NNS of/IN sampling/NN versus/CC projection/NN methods/NNS based/VBN on/IN leverage/NN scores/NNS ./.
We/PRP complement/VBP our/PRP$ empirical/JJ results/NNS with/IN a/DT suite/NN of/IN worst/JJS -/HYPH case/NN theoretical/JJ bounds/NNS for/IN both/DT random/JJ sampling/NN and/CC random/JJ projections/NNS methods/NNS ./.
These/DT bounds/NNS are/VBP qualitatively/RB superior/JJ to/IN existing/VBG bounds/NNS ---/, e.g./FW ,/, improved/VBN additive/JJ -/HYPH error/NN bounds/NNS for/IN the/DT spectral/JJ and/CC Frobenius/NNP norm/NN errors/NNS and/CC relative/JJ -/HYPH error/NN bounds/NNS for/IN the/DT trace/NN norm/NN error/NN ./.
