Mobile/JJ edge/NN computing/NN (/-LRB- a.k.a./RB fog/NN computing/NN )/-RRB- has/VBZ recently/RB emerged/VBN to/TO enable/VB in/IN -/HYPH situ/NN processing/NN of/IN delay/NN -/HYPH sensitive/JJ applications/NNS at/IN the/DT edge/NN of/IN mobile/JJ networks/NNS ./.
Providing/VBG grid/NN power/NN supply/NN in/IN support/NN of/IN mobile/JJ edge/NN computing/NN ,/, however/RB ,/, is/VBZ costly/JJ and/CC even/RB infeasible/JJ (/-LRB- in/IN certain/JJ rugged/JJ or/CC under/IN -/HYPH developed/VBN areas/NNS )/-RRB- ,/, thus/RB mandating/VBG on/IN -/HYPH site/NN renewable/JJ energy/NN as/IN a/DT major/JJ or/CC even/RB sole/JJ power/NN supply/NN in/IN increasingly/RB many/JJ scenarios/NNS ./.
Nonetheless/RB ,/, the/DT high/JJ intermittency/NN and/CC unpredictability/NN of/IN renewable/JJ energy/NN make/VB it/PRP very/RB challenging/JJ to/TO deliver/VB a/DT high/JJ quality/NN of/IN service/NN to/IN users/NNS in/IN energy/NN harvesting/NN mobile/JJ edge/NN computing/VBG systems/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP address/VBP the/DT challenge/NN of/IN incorporating/VBG renewables/NNS into/IN mobile/JJ edge/NN computing/NN and/CC propose/VB an/DT efficient/JJ reinforcement/NN learning/NN -/HYPH based/VBN resource/NN management/NN algorithm/NN ,/, which/WDT learns/VBZ on/IN -/HYPH the/DT -/HYPH fly/VB the/DT optimal/JJ policy/NN of/IN dynamic/JJ workload/NN offloading/NN (/-LRB- to/IN the/DT centralized/JJ cloud/NN )/-RRB- and/CC edge/NN server/NN provisioning/VBG to/TO minimize/VB the/DT long/JJ -/HYPH term/NN system/NN cost/NN (/-LRB- including/VBG both/DT service/NN delay/NN and/CC operational/JJ cost/NN )/-RRB- ./.
Our/PRP$ online/JJ learning/NN algorithm/NN uses/VBZ a/DT decomposition/NN of/IN the/DT (/-LRB- offline/RB )/-RRB- value/NN iteration/NN and/CC (/-LRB- online/RB )/-RRB- reinforcement/NN learning/NN ,/, thus/RB achieving/VBG a/DT significant/JJ improvement/NN of/IN learning/NN rate/NN and/CC run/VB -/HYPH time/NN performance/NN when/WRB compared/VBN to/IN standard/JJ reinforcement/NN learning/VBG algorithms/NNS such/JJ as/IN Q/NN -/HYPH learning/NN ./.
We/PRP prove/VBP the/DT convergence/NN of/IN the/DT proposed/VBN algorithm/NN and/CC analytically/RB show/VBP that/IN the/DT learned/VBN policy/NN has/VBZ a/DT simple/JJ monotone/JJ structure/NN amenable/JJ to/IN practical/JJ implementation/NN ./.
Our/PRP$ simulation/NN results/NNS validate/VBP the/DT efficacy/NN of/IN our/PRP$ algorithm/NN ,/, which/WDT significantly/RB improves/VBZ the/DT edge/NN computing/NN performance/NN compared/VBN to/IN fixed/VBN or/CC myopic/JJ optimization/NN schemes/NNS and/CC conventional/JJ reinforcement/NN learning/VBG algorithms/NNS ./.
