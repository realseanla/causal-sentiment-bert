In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT novel/NN and/CC elegant/JJ solution/NN to/TO "/`` Multi-Source/VB Neural/JJ Machine/NN Translation/NN "/'' (/-LRB- MSNMT/NNP )/-RRB- which/WDT only/RB relies/VBZ on/IN preprocessing/VBG a/DT N/NN -/HYPH way/NN multilingual/JJ corpus/NN without/IN modifying/VBG the/DT Neural/JJ Machine/NN Translation/NN (/-LRB- NMT/NN )/-RRB- architecture/NN or/CC training/NN procedure/NN ./.
We/PRP simply/RB concatenate/VBP the/DT source/NN sentences/NNS to/TO form/VB a/DT single/JJ long/JJ multi-source/JJ input/NN sentence/NN while/IN keeping/VBG the/DT target/NN side/NN sentence/NN as/IN it/PRP is/VBZ and/CC train/VB an/DT NMT/NN system/NN using/VBG this/DT augmented/VBN corpus/NN ./.
We/PRP evaluate/VBP our/PRP$ method/NN in/IN a/DT low/JJ resource/NN ,/, general/JJ domain/NN setting/NN and/CC show/VB its/PRP$ effectiveness/NN (/-LRB- 2/CD BLEU/NN using/VBG 2/CD source/NN languages/NNS and/CC 6/CD BLEU/NN using/VBG 5/CD source/NN languages/NNS )/-RRB- along/IN with/IN some/DT insights/NNS on/IN how/WRB the/DT NMT/NN system/NN leverages/VBZ multilingual/JJ information/NN in/IN such/PDT a/DT scenario/NN by/IN visualizing/VBG attention/NN ./.
