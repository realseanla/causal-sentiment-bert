This/DT article/NN demontrates/VBZ that/IN we/PRP can/MD apply/VB deep/JJ learning/NN to/IN text/NN understanding/NN from/IN character/NN -/HYPH level/NN inputs/NNS all/PDT the/DT way/NN up/IN to/IN abstract/JJ text/NN concepts/NNS ,/, using/VBG temporal/JJ convolutional/JJ networks/NNS (/-LRB- ConvNets/NNP )/-RRB- ./.
We/PRP apply/VBP ConvNets/NNP to/IN various/JJ large/JJ -/HYPH scale/NN datasets/NNS ,/, including/VBG ontology/NN classification/NN ,/, sentiment/NN analysis/NN ,/, and/CC text/NN categorization/NN ./.
We/PRP show/VBP that/IN temporal/JJ ConvNets/NNPS can/MD achieve/VB astonishing/JJ performance/NN without/IN the/DT knowledge/NN of/IN words/NNS ,/, phrases/NNS ,/, sentences/NNS and/CC any/DT other/JJ syntactic/JJ or/CC semantic/JJ structures/NNS with/IN regards/NNS to/IN a/DT human/JJ language/NN ./.
Evidence/NN shows/VBZ that/IN our/PRP$ models/NNS can/MD work/VB for/IN both/DT English/NNP and/CC Chinese/NNP ./.
