Meaning/VBG of/IN a/DT word/NN varies/VBZ from/IN one/CD domain/NN to/IN another/DT ./.
Despite/IN this/DT important/JJ domain/NN dependence/NN in/IN word/NN semantics/NNS ,/, existing/VBG word/NN representation/NN learning/NN methods/NNS are/VBP bound/VBN to/IN a/DT single/JJ domain/NN ./.
Given/VBN a/DT pair/NN of/IN \/SYM emph/NN {/-LRB- source/NN }/-RRB- -/HYPH \/SYM emph/NN {/-LRB- target/NN }/-RRB- domains/NNS ,/, we/PRP propose/VBP an/DT unsupervised/JJ method/NN for/IN learning/VBG domain/NN -/HYPH specific/JJ word/NN representations/NNS that/WDT accurately/RB capture/VBP the/DT domain/NN -/HYPH specific/JJ aspects/NNS of/IN word/NN semantics/NNS ./.
First/RB ,/, we/PRP select/VBP a/DT subset/NN of/IN frequent/JJ words/NNS that/WDT occur/VBP in/IN both/DT domains/NNS as/IN \/SYM emph/NN {/-LRB- pivots/VBZ }/-RRB- ./.
Next/RB ,/, we/PRP optimize/VBP an/DT objective/JJ function/NN that/WDT enforces/VBZ two/CD constraints/NNS :/: (/-LRB- a/LS )/-RRB- for/IN both/DT source/NN and/CC target/NN domain/NN documents/NNS ,/, pivots/NNS that/WDT appear/VBP in/IN a/DT document/NN must/MD accurately/RB predict/VB the/DT co-occurring/NN non-pivots/NNS ,/, and/CC (/-LRB- b/LS )/-RRB- word/NN representations/NNS learnt/VBD for/IN pivots/NNS must/MD be/VB similar/JJ in/IN the/DT two/CD domains/NNS ./.
Moreover/RB ,/, we/PRP propose/VBP a/DT method/NN to/TO perform/VB domain/NN adaptation/NN using/VBG the/DT learnt/VBN word/NN representations/NNS ./.
Our/PRP$ proposed/JJ method/NN significantly/RB outperforms/VBZ competitive/JJ baselines/NNS including/VBG the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN domain/NN -/HYPH insensitive/JJ word/NN representations/NNS ,/, and/CC reports/VBZ best/JJS sentiment/NN classification/NN accuracies/NNS for/IN all/DT domain/NN -/HYPH pairs/NNS in/IN a/DT benchmark/NN dataset/NN ./.
