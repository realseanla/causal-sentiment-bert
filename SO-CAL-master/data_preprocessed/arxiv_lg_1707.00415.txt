Many/JJ supervised/JJ learning/NN tasks/NNS are/VBP emerged/VBN in/IN dual/JJ forms/NNS ,/, e.g./FW ,/, English/NNP -/HYPH to/IN -/HYPH French/JJ translation/NN vs./FW French/JJ -/HYPH to/IN -/HYPH English/NNP translation/NN ,/, speech/NN recognition/NN vs./FW text/NN to/IN speech/NN ,/, and/CC image/NN classification/NN vs./FW image/NN generation/NN ./.
Two/CD dual/JJ tasks/NNS have/VBP intrinsic/JJ connections/NNS with/IN each/DT other/JJ due/JJ to/IN the/DT probabilistic/JJ correlation/NN between/IN their/PRP$ models/NNS ./.
This/DT connection/NN is/VBZ ,/, however/RB ,/, not/RB effectively/RB utilized/VBN today/NN ,/, since/IN people/NNS usually/RB train/VBP the/DT models/NNS of/IN two/CD dual/JJ tasks/NNS separately/RB and/CC independently/RB ./.
In/IN this/DT work/NN ,/, we/PRP propose/VBP training/VBG the/DT models/NNS of/IN two/CD dual/JJ tasks/NNS simultaneously/RB ,/, and/CC explicitly/RB exploiting/VBG the/DT probabilistic/JJ correlation/NN between/IN them/PRP to/TO regularize/VB the/DT training/NN process/NN ./.
For/IN ease/NN of/IN reference/NN ,/, we/PRP call/VBP the/DT proposed/VBN approach/NN \/SYM emph/NN {/-LRB- dual/JJ supervised/JJ learning/NN }/-RRB- ./.
We/PRP demonstrate/VBP that/IN dual/JJ supervised/JJ learning/NN can/MD improve/VB the/DT practical/JJ performances/NNS of/IN both/DT tasks/NNS ,/, for/IN various/JJ applications/NNS including/VBG machine/NN translation/NN ,/, image/NN processing/NN ,/, and/CC sentiment/NN analysis/NN ./.
