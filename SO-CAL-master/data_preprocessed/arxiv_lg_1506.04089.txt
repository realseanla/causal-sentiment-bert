We/PRP take/VBP an/DT end/NN -/HYPH to/IN -/HYPH end/NN ,/, sequence/NN -/HYPH to/IN -/HYPH sequence/NN learning/NN approach/NN to/IN the/DT task/NN of/IN following/VBG natural/JJ language/NN route/NN instructions/NNS ,/, i.e./FW ,/, mapping/VBG natural/JJ language/NN instructions/NNS to/IN action/NN sequences/NNS ./.
Our/PRP$ model/NN is/VBZ an/DT alignment/NN -/HYPH based/VBN long/JJ short/JJ -/HYPH term/NN memory/NN recurrent/JJ neural/JJ network/NN (/-LRB- attention/NN -/HYPH based/VBN LSTM/NNP -/HYPH RNN/NNP )/-RRB- that/WDT encodes/VBZ the/DT free/JJ -/HYPH form/NN navigational/JJ instruction/NN sentence/NN and/CC the/DT corresponding/VBG representation/NN of/IN the/DT environment/NN state/NN ./.
We/PRP integrate/VBP alignment/NN as/IN part/NN of/IN our/PRP$ network/NN ,/, thereby/RB empowering/VBG the/DT model/NN to/TO focus/VB on/IN important/JJ sentence/NN "/'' regions/NNS ./. "/''
The/DT alignment/NN -/HYPH based/VBN LSTM/NNP then/RB decodes/VBZ the/DT learned/VBN representation/NN to/TO obtain/VB the/DT inferred/VBN action/NN sequence/NN ./.
Adding/VBG bidirectionality/NN to/IN the/DT network/NN helps/VBZ further/RB ./.
In/IN contrast/NN with/IN existing/VBG methods/NNS ,/, our/PRP$ model/NN uses/VBZ no/DT additional/JJ information/NN or/CC resources/NNS about/IN the/DT task/NN or/CC language/NN at/IN all/DT (/-LRB- e.g./FW ,/, parsers/NNS or/CC seed/NN lexicons/NNS )/-RRB- and/CC still/RB achieves/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN on/IN a/DT single/JJ -/HYPH sentence/NN benchmark/NN dataset/NN and/CC strong/JJ results/NNS in/IN the/DT limited/JJ -/HYPH training/NN multi-sentence/NN setting/NN ./.
Moreover/RB ,/, our/PRP$ model/NN is/VBZ more/RBR stable/JJ across/IN runs/NNS than/IN previous/JJ work/NN ./.
We/PRP evaluate/VBP our/PRP$ model/NN through/IN a/DT series/NN of/IN ablation/NN studies/NNS that/WDT elucidate/VBP the/DT contributions/NNS of/IN the/DT primary/JJ components/NNS of/IN our/PRP$ model/NN ./.
