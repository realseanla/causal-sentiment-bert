Given/VBN a/DT collection/NN of/IN images/NNS and/CC spoken/VBN audio/JJ captions/NNS ,/, we/PRP present/VBP a/DT method/NN for/IN discovering/VBG word/NN -/HYPH like/JJ acoustic/JJ units/NNS in/IN the/DT continuous/JJ speech/NN signal/NN and/CC grounding/VBG them/PRP to/TO semantically/RB relevant/JJ image/NN regions/NNS ./.
For/IN example/NN ,/, our/PRP$ model/NN is/VBZ able/JJ to/TO detect/VB spoken/VBN instances/NNS of/IN the/DT word/NN '/`` lighthouse/NN '/'' within/IN an/DT utterance/NN and/CC associate/VB them/PRP with/IN image/NN regions/NNS containing/VBG lighthouses/NNS ./.
We/PRP do/VBP not/RB use/VB any/DT form/NN of/IN conventional/JJ automatic/JJ speech/NN recognition/NN ,/, nor/CC do/VBP we/PRP use/VB any/DT text/NN transcriptions/NNS or/CC conventional/JJ linguistic/JJ annotations/NNS ./.
Our/PRP$ model/NN effectively/RB implements/VBZ a/DT form/NN of/IN spoken/VBN language/NN acquisition/NN ,/, in/IN which/WDT the/DT computer/NN learns/VBZ not/RB only/RB to/TO recognize/VB word/NN categories/NNS by/IN sound/NN ,/, but/CC also/RB to/TO enrich/VB the/DT words/NNS it/PRP learns/VBZ with/IN semantics/NNS by/IN grounding/VBG them/PRP in/IN images/NNS ./.
