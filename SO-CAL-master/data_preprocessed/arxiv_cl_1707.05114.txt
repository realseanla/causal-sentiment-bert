This/DT paper/NN proposes/VBZ a/DT hierarchical/JJ attentional/JJ neural/JJ translation/NN model/NN which/WDT focuses/VBZ on/IN enhancing/VBG source/NN -/HYPH side/NN hierarchical/JJ representations/NNS by/IN covering/VBG both/DT local/JJ and/CC global/JJ semantic/JJ information/NN using/VBG a/DT bidirectional/JJ tree/NN -/HYPH based/VBN encoder/NN ./.
To/TO maximize/VB the/DT predictive/JJ likelihood/NN of/IN target/NN words/NNS ,/, a/DT weighted/JJ variant/NN of/IN an/DT attention/NN mechanism/NN is/VBZ used/VBN to/TO balance/VB the/DT attentive/JJ information/NN between/IN lexical/JJ and/CC phrase/NN vectors/NNS ./.
Using/VBG a/DT tree/NN -/HYPH based/VBN rare/JJ word/NN encoding/VBG ,/, the/DT proposed/VBN model/NN is/VBZ extended/VBN to/IN sub-word/JJ level/NN to/TO alleviate/VB the/DT out/NN -/HYPH of/IN -/HYPH vocabulary/NN (/-LRB- OOV/NN )/-RRB- problem/NN ./.
Empirical/JJ results/NNS reveal/VBP that/IN the/DT proposed/VBN model/NN significantly/RB outperforms/VBZ sequence/NN -/HYPH to/IN -/HYPH sequence/NN attention/NN -/HYPH based/VBN and/CC tree/NN -/HYPH based/VBN neural/JJ translation/NN models/NNS in/IN English/NNP -/HYPH Chinese/NNP translation/NN tasks/NNS ./.
