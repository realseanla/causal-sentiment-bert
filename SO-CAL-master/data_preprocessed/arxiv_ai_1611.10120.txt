Emotion/NN estimation/NN in/IN music/NN listening/NN is/VBZ confronting/VBG challenges/NNS to/TO capture/VB the/DT emotion/NN variation/NN of/IN listeners/NNS ./.
Recent/JJ years/NNS have/VBP witnessed/VBN attempts/NNS to/TO exploit/VB multimodality/NN fusing/VBG information/NN from/IN musical/JJ contents/NNS and/CC physiological/JJ signals/NNS captured/VBN from/IN listeners/NNS to/TO improve/VB the/DT performance/NN of/IN emotion/NN recognition/NN ./.
In/IN this/DT paper/NN ,/, we/PRP present/VBP a/DT study/NN of/IN fusion/NN of/IN signals/NNS of/IN electroencephalogram/NN (/-LRB- EEG/NN )/-RRB- ,/, a/DT tool/NN to/TO capture/VB brainwaves/NNS at/IN a/DT high/JJ -/HYPH temporal/JJ resolution/NN ,/, and/CC musical/JJ features/NNS at/IN decision/NN level/NN in/IN recognizing/VBG the/DT time/NN -/HYPH varying/VBG binary/JJ classes/NNS of/IN arousal/NN and/CC valence/NN ./.
Our/PRP$ empirical/JJ results/NNS showed/VBD that/IN the/DT fusion/NN could/MD outperform/VB the/DT performance/NN of/IN emotion/NN recognition/NN using/VBG only/RB EEG/NN modality/NN that/WDT was/VBD suffered/VBN from/IN inter-subject/JJ variability/NN ,/, and/CC this/DT suggested/VBD the/DT promise/NN of/IN multimodal/JJ fusion/NN in/IN improving/VBG the/DT accuracy/NN of/IN music/NN -/HYPH emotion/NN recognition/NN ./.
