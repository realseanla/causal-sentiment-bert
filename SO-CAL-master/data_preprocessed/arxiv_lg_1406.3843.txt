Sampling/VBG from/IN hierarchical/JJ Bayesian/JJ models/NNS is/VBZ often/RB difficult/JJ for/IN MCMC/NN methods/NNS ,/, because/IN of/IN the/DT strong/JJ correlations/NNS between/IN the/DT model/NN parameters/NNS and/CC the/DT hyperparameters/NNS ./.
Recent/JJ Riemannian/JJ manifold/NN Hamiltonian/NNP Monte/NNP Carlo/NNP (/-LRB- RMHMC/NNP )/-RRB- methods/NNS have/VBP significant/JJ potential/JJ advantages/NNS in/IN this/DT setting/NN ,/, but/CC are/VBP computationally/RB expensive/JJ ./.
We/PRP introduce/VBP a/DT new/JJ RMHMC/NN method/NN ,/, which/WDT we/PRP call/VBP semi-separable/JJ Hamiltonian/JJ Monte/NNP Carlo/NNP ,/, which/WDT uses/VBZ a/DT specially/RB designed/VBN mass/NN matrix/NN that/WDT allows/VBZ the/DT joint/JJ Hamiltonian/JJ over/IN model/NN parameters/NNS and/CC hyperparameters/NNS to/IN decompose/VB into/IN two/CD simpler/JJR Hamiltonians/NNPS ./.
This/DT structure/NN is/VBZ exploited/VBN by/IN a/DT new/JJ integrator/NN which/WDT we/PRP call/VBP the/DT alternating/VBG blockwise/RB leapfrog/VB algorithm/NN ./.
The/DT resulting/VBG method/NN can/MD mix/VB faster/JJR than/IN simpler/JJR Gibbs/NNP sampling/NN while/IN being/VBG simpler/JJR and/CC more/RBR efficient/JJ than/IN previous/JJ instances/NNS of/IN RMHMC/NNP ./.
