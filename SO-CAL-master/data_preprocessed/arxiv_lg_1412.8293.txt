We/PRP consider/VBP the/DT problem/NN of/IN improving/VBG the/DT efficiency/NN of/IN randomized/JJ Fourier/NNP feature/NN maps/VBZ to/TO accelerate/VB training/NN and/CC testing/NN speed/NN of/IN kernel/NN methods/NNS on/IN large/JJ datasets/NNS ./.
These/DT approximate/JJ feature/NN maps/NNS arise/VBP as/IN Monte/NNP Carlo/NNP approximations/NNS to/IN integral/JJ representations/NNS of/IN shift/NN -/HYPH invariant/JJ kernel/NN functions/NNS (/-LRB- e.g./FW ,/, Gaussian/JJ kernel/NN )/-RRB- ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP to/TO use/VB Quasi-Monte/NNP Carlo/NNP (/-LRB- QMC/NNP )/-RRB- approximations/NNS instead/RB ,/, where/WRB the/DT relevant/JJ integrands/NNS are/VBP evaluated/VBN on/IN a/DT low/JJ -/HYPH discrepancy/NN sequence/NN of/IN points/NNS as/IN opposed/VBN to/IN random/JJ point/NN sets/NNS as/IN in/IN the/DT Monte/NNP Carlo/NNP approach/NN ./.
We/PRP derive/VBP a/DT new/JJ discrepancy/NN measure/NN called/VBN box/NN discrepancy/NN based/VBN on/IN theoretical/JJ characterizations/NNS of/IN the/DT integration/NN error/NN with/IN respect/NN to/IN a/DT given/VBN sequence/NN ./.
We/PRP then/RB propose/VB to/TO learn/VB QMC/NNP sequences/NNS adapted/VBD to/IN our/PRP$ setting/VBG based/VBN on/IN explicit/JJ box/NN discrepancy/NN minimization/NN ./.
Our/PRP$ theoretical/JJ analyses/NNS are/VBP complemented/VBN with/IN empirical/JJ results/NNS that/WDT demonstrate/VBP the/DT effectiveness/NN of/IN classical/JJ and/CC adaptive/JJ QMC/NN techniques/NNS for/IN this/DT problem/NN ./.
