Deep/JJ Reinforcement/NN Learning/NN has/VBZ been/VBN successful/JJ in/IN various/JJ virtual/JJ tasks/NNS ,/, but/CC it/PRP is/VBZ still/RB rarely/RB used/VBN in/IN real/JJ world/NN applications/NNS especially/RB for/IN continuous/JJ control/NN of/IN mobile/JJ robots/NNS navigation/NN ./.
In/IN this/DT paper/NN ,/, we/PRP present/VBP a/DT learning/NN -/HYPH based/VBN mapless/JJ motion/NN planner/NN by/IN taking/VBG the/DT 10/CD -/HYPH dimensional/JJ range/NN findings/NNS and/CC the/DT target/NN position/NN as/IN input/NN and/CC the/DT continuous/JJ steering/NN commands/NNS as/IN output/NN ./.
Traditional/JJ motion/NN planners/NNS for/IN mobile/JJ ground/NN robots/NNS with/IN a/DT laser/NN range/NN sensor/NN mostly/RB depend/VBP on/IN the/DT map/NN of/IN the/DT navigation/NN environment/NN where/WRB both/CC the/DT highly/RB precise/JJ laser/NN sensor/NN and/CC the/DT map/NN building/NN work/NN of/IN the/DT environment/NN are/VBP indispensable/JJ ./.
We/PRP show/VBP that/IN ,/, through/IN an/DT asynchronous/JJ deep/JJ reinforcement/NN learning/NN method/NN ,/, a/DT mapless/JJ motion/NN planner/NN can/MD be/VB trained/VBN end/NN -/HYPH to/IN -/HYPH end/NN without/IN any/DT manually/RB designed/VBN features/NNS and/CC prior/JJ demonstrations/NNS ./.
The/DT trained/VBN planner/NN can/MD be/VB directly/RB applied/VBN in/IN unseen/JJ virtual/JJ and/CC real/JJ environments/NNS ./.
We/PRP also/RB evaluated/VBD this/DT learning/NN -/HYPH based/VBN motion/NN planner/NN and/CC compared/VBN it/PRP with/IN the/DT traditional/JJ motion/NN planning/NN method/NN ,/, both/CC in/IN virtual/JJ and/CC real/JJ environments/NNS ./.
The/DT experiments/NNS show/VBP that/IN the/DT proposed/VBN mapless/NN motion/NN planner/NN can/MD navigate/VB the/DT nonholonomic/JJ mobile/JJ robot/NN to/IN the/DT desired/VBN targets/NNS without/IN colliding/VBG with/IN any/DT obstacles/NNS ./.
