In/IN machine/NN learning/NN ,/, the/DT use/NN of/IN an/DT artificial/JJ neural/JJ network/NN is/VBZ the/DT mainstream/NN approach/NN ./.
Such/PDT a/DT network/NN consists/VBZ of/IN layers/NNS of/IN neurons/NNS ./.
These/DT neurons/NNS are/VBP of/IN the/DT same/JJ type/NN characterized/VBN by/IN the/DT two/CD features/NNS :/: (/-LRB- 1/LS )/-RRB- an/DT inner/JJ product/NN of/IN an/DT input/NN vector/NN and/CC a/DT matching/JJ weighting/NN vector/NN of/IN trainable/JJ parameters/NNS and/CC (/-LRB- 2/LS )/-RRB- a/DT nonlinear/JJ excitation/NN function/NN ./.
Here/RB we/PRP investigate/VB the/DT possibility/NN of/IN replacing/VBG the/DT inner/JJ product/NN with/IN a/DT quadratic/JJ function/NN of/IN the/DT input/NN vector/NN ,/, thereby/RB upgrading/VBG the/DT 1st/JJ order/NN neuron/NN to/IN the/DT 2nd/JJ order/NN neuron/NN ,/, empowering/VBG individual/JJ neurons/NNS ,/, and/CC facilitating/VBG the/DT optimization/NN of/IN neural/JJ networks/NNS ./.
Also/RB ,/, numerical/JJ examples/NNS are/VBP provided/VBN to/TO illustrate/VB the/DT feasibility/NN and/CC merits/NNS of/IN the/DT 2nd/JJ order/NN neurons/NNS ./.
Finally/RB ,/, further/JJ topics/NNS are/VBP discussed/VBN ./.
