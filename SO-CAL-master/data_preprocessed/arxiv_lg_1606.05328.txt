This/DT work/NN explores/VBZ conditional/JJ image/NN generation/NN with/IN a/DT new/JJ image/NN density/NN model/NN based/VBN on/IN the/DT PixelCNN/NNP architecture/NN ./.
The/DT model/NN can/MD be/VB conditioned/VBN on/IN any/DT vector/NN ,/, including/VBG descriptive/JJ labels/NNS or/CC tags/NNS ,/, or/CC latent/JJ embeddings/NNS created/VBN by/IN other/JJ networks/NNS ./.
When/WRB conditioned/VBN on/IN class/NN labels/NNS from/IN the/DT ImageNet/NNP database/NN ,/, the/DT model/NN is/VBZ able/JJ to/TO generate/VB diverse/JJ ,/, realistic/JJ scenes/NNS representing/VBG distinct/JJ animals/NNS ,/, objects/NNS ,/, landscapes/NNS and/CC structures/NNS ./.
When/WRB conditioned/VBN on/IN an/DT embedding/NN produced/VBN by/IN a/DT convolutional/JJ network/NN given/VBN a/DT single/JJ image/NN of/IN an/DT unseen/JJ face/NN ,/, it/PRP generates/VBZ a/DT variety/NN of/IN new/JJ portraits/NNS of/IN the/DT same/JJ person/NN with/IN different/JJ facial/JJ expressions/NNS ,/, poses/NNS and/CC lighting/NN conditions/NNS ./.
We/PRP also/RB show/VBP that/IN conditional/JJ PixelCNN/NN can/MD serve/VB as/IN a/DT powerful/JJ decoder/NN in/IN an/DT image/NN autoencoder/NN ,/, creating/VBG ./.
Additionally/RB ,/, the/DT gated/VBN convolutional/JJ layers/NNS in/IN the/DT proposed/VBN model/NN improve/VB the/DT log/NN -/HYPH likelihood/NN of/IN PixelCNN/NNP to/TO match/VB the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN of/IN PixelRNN/NNP on/IN ImageNet/NNP ,/, with/IN greatly/RB reduced/VBN computational/JJ cost/NN ./.
