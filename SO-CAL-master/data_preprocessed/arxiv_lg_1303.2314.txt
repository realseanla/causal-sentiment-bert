We/PRP address/VBP the/DT issue/NN of/IN using/VBG mini-batches/NNS in/IN stochastic/JJ optimization/NN of/IN SVMs/NNS ./.
We/PRP show/VBP that/IN the/DT same/JJ quantity/NN ,/, the/DT spectral/JJ norm/NN of/IN the/DT data/NNS ,/, controls/VBZ the/DT parallelization/NN speedup/NN obtained/VBN for/IN both/DT primal/JJ stochastic/JJ subgradient/NN descent/NN (/-LRB- SGD/NNP )/-RRB- and/CC stochastic/JJ dual/JJ coordinate/NN ascent/NN (/-LRB- SCDA/NNP )/-RRB- methods/NNS and/CC use/VB it/PRP to/TO derive/VB novel/JJ variants/NNS of/IN mini-batched/VBN SDCA/NN ./.
Our/PRP$ guarantees/NNS for/IN both/DT methods/NNS are/VBP expressed/VBN in/IN terms/NNS of/IN the/DT original/JJ nonsmooth/JJ primal/JJ problem/NN based/VBN on/IN the/DT hinge/NN -/HYPH loss/NN ./.
