This/DT work/NN shows/VBZ that/IN policies/NNS with/IN simple/JJ linear/JJ and/CC RBF/NNP parameterizations/NNS can/MD be/VB trained/VBN to/TO solve/VB a/DT variety/NN of/IN continuous/JJ control/NN tasks/NNS ,/, including/VBG the/DT OpenAI/NN gym/NN benchmarks/NNS ./.
The/DT performance/NN of/IN these/DT trained/VBN policies/NNS are/VBP competitive/JJ with/IN state/NN of/IN the/DT art/NN results/NNS ,/, obtained/VBN with/IN more/JJR elaborate/JJ parameterizations/NNS such/JJ as/IN fully/RB connected/VBN neural/JJ networks/NNS ./.
Furthermore/RB ,/, existing/VBG training/NN and/CC testing/NN scenarios/NNS are/VBP shown/VBN to/TO be/VB very/RB limited/JJ and/CC prone/JJ to/IN over-fitting/NN ,/, thus/RB giving/VBG rise/NN to/IN only/JJ trajectory/NN -/HYPH centric/JJ policies/NNS ./.
Training/VBG with/IN a/DT diverse/JJ initial/JJ state/NN distribution/NN is/VBZ shown/VBN to/TO produce/VB more/JJR global/JJ policies/NNS with/IN better/JJR generalization/NN ./.
This/DT allows/VBZ for/IN interactive/JJ control/NN scenarios/NNS where/WRB the/DT system/NN recovers/VBZ from/IN large/JJ on/IN -/HYPH line/NN perturbations/NNS ;/: as/IN shown/VBN in/IN the/DT supplementary/JJ video/NN ./.
