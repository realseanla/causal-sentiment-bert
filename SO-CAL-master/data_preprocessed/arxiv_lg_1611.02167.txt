At/IN present/JJ ,/, designing/VBG convolutional/JJ neural/JJ network/NN (/-LRB- CNN/NNP )/-RRB- architectures/NNS requires/VBZ both/CC human/JJ expertise/NN and/CC labor/NN ./.
New/NNP architectures/NNS are/VBP handcrafted/VBN by/IN careful/JJ experimentation/NN or/CC modified/VBN from/IN a/DT handful/NN of/IN existing/VBG networks/NNS ./.
We/PRP propose/VBP a/DT meta/NN -/HYPH modelling/NN approach/NN based/VBN on/IN reinforcement/NN learning/VBG to/IN automatically/RB generate/VB high/JJ -/HYPH performing/VBG CNN/NNP architectures/NNS for/IN a/DT given/VBN learning/NN task/NN ./.
The/DT learning/NN agent/NN is/VBZ trained/VBN to/TO sequentially/RB choose/VB CNN/NNP layers/NNS using/VBG Q/NN -/HYPH learning/NN with/IN an/DT $/$ \/CD epsilon/CD $/$ -/HYPH greedy/JJ exploration/NN strategy/NN and/CC experience/NN replay/NN ./.
The/DT agent/NN explores/VBZ a/DT large/JJ but/CC finite/JJ space/NN of/IN possible/JJ architectures/NNS and/CC iteratively/RB discovers/VBZ designs/NNS with/IN improved/VBN performance/NN on/IN the/DT learning/NN task/NN ./.
On/IN image/NN classification/NN benchmarks/NNS ,/, the/DT agent/NN -/HYPH designed/VBN networks/NNS (/-LRB- consisting/VBG of/IN only/RB standard/JJ convolution/NN ,/, pooling/VBG ,/, and/CC fully/RB -/HYPH connected/VBN layers/NNS )/-RRB- beat/VBD existing/VBG networks/NNS designed/VBN with/IN the/DT same/JJ layer/NN types/NNS and/CC are/VBP competitive/JJ against/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS that/WDT use/VBP more/RBR complex/JJ layer/NN types/NNS ./.
We/PRP also/RB outperform/VBP existing/VBG network/NN design/NN meta/NN -/HYPH modelling/NN approaches/NNS on/IN image/NN classification/NN ./.
