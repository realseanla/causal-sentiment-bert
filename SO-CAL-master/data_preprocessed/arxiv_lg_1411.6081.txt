In/IN this/DT paper/NN ,/, we/PRP consider/VBP the/DT matrix/NN completion/NN problem/NN when/WRB the/DT observations/NNS are/VBP one/CD -/HYPH bit/NN measurements/NNS of/IN some/DT underlying/VBG matrix/NN M/NN ,/, and/CC in/IN particular/JJ the/DT observed/VBN samples/NNS consist/VBP only/RB of/IN ones/NNS and/CC no/DT zeros/NNS ./.
This/DT problem/NN is/VBZ motivated/VBN by/IN modern/JJ applications/NNS such/JJ as/IN recommender/NN systems/NNS and/CC social/JJ networks/NNS where/WRB only/RB "/`` likes/NNS "/'' or/CC "/`` friendships/NNS "/'' are/VBP observed/VBN ./.
The/DT problem/NN of/IN learning/VBG from/IN only/RB positive/JJ and/CC unlabeled/JJ examples/NNS ,/, called/VBN PU/NNP (/-LRB- positive/JJ -/HYPH unlabeled/JJ )/-RRB- learning/NN ,/, has/VBZ been/VBN studied/VBN in/IN the/DT context/NN of/IN binary/JJ classification/NN ./.
We/PRP consider/VBP the/DT PU/NNP matrix/NN completion/NN problem/NN ,/, where/WRB an/DT underlying/VBG real/JJ -/HYPH valued/VBN matrix/NN M/NN is/VBZ first/JJ quantized/VBN to/TO generate/VB one/CD -/HYPH bit/NN observations/NNS and/CC then/RB a/DT subset/NN of/IN positive/JJ entries/NNS is/VBZ revealed/VBN ./.
Under/IN the/DT assumption/NN that/IN M/NN has/VBZ bounded/VBN nuclear/JJ norm/NN ,/, we/PRP provide/VBP recovery/NN guarantees/NNS for/IN two/CD different/JJ observation/NN models/NNS :/: 1/LS )/-RRB- M/NN parameterizes/VBZ a/DT distribution/NN that/WDT generates/VBZ a/DT binary/JJ matrix/NN ,/, 2/CD )/-RRB- M/NN is/VBZ thresholded/VBN to/TO obtain/VB a/DT binary/JJ matrix/NN ./.
For/IN the/DT first/JJ case/NN ,/, we/PRP propose/VBP a/DT "/`` shifted/VBD matrix/NN completion/NN "/'' method/NN that/WDT recovers/VBZ M/NN using/VBG only/RB a/DT subset/NN of/IN indices/NNS corresponding/VBG to/IN ones/NNS ,/, while/IN for/IN the/DT second/JJ case/NN ,/, we/PRP propose/VBP a/DT "/`` biased/JJ matrix/NN completion/NN "/'' method/NN that/WDT recovers/VBZ the/DT (/-LRB- thresholded/VBN )/-RRB- binary/JJ matrix/NN ./.
Both/DT methods/NNS yield/VBP strong/JJ error/NN bounds/NNS ---/, if/IN M/NN is/VBZ n/NN by/IN n/NN ,/, the/DT Frobenius/NNP error/NN is/VBZ bounded/VBN as/IN O/NN (/-LRB- 1/CD //SYM (/-LRB- (/-LRB- 1/CD -/SYM rho/NN )/-RRB- n/NN )/-RRB- ,/, where/WRB 1/CD -/HYPH rho/NN denotes/VBZ the/DT fraction/NN of/IN ones/NNS observed/VBN ./.
This/DT implies/VBZ a/DT sample/NN complexity/NN of/IN O/NN (/-LRB- n/NN \/SYM log/NN n/NN )/-RRB- ones/NNS to/TO achieve/VB a/DT small/JJ error/NN ,/, when/WRB M/NN is/VBZ dense/JJ and/CC n/NN is/VBZ large/JJ ./.
We/PRP extend/VBP our/PRP$ methods/NNS and/CC guarantees/NNS to/IN the/DT inductive/JJ matrix/NN completion/NN problem/NN ,/, where/WRB rows/NNS and/CC columns/NNS of/IN M/NN have/VBP associated/VBN features/NNS ./.
We/PRP provide/VBP efficient/JJ and/CC scalable/JJ optimization/NN procedures/NNS for/IN both/CC the/DT methods/NNS and/CC demonstrate/VBP the/DT effectiveness/NN of/IN the/DT proposed/VBN methods/NNS for/IN link/NN prediction/NN (/-LRB- on/IN real/JJ -/HYPH world/NN networks/NNS consisting/VBG of/IN over/IN 2/CD million/CD nodes/NNS and/CC 90/CD million/CD links/NNS )/-RRB- and/CC semi-supervised/VBN clustering/NN tasks/NNS ./.
