Word/NNP -/HYPH vector/NNP representations/NNS associate/VBP a/DT high/JJ dimensional/JJ real/JJ -/HYPH vector/NN to/IN every/DT word/NN from/IN a/DT corpus/NN ./.
Recently/RB ,/, neural/JJ -/HYPH network/NN based/VBN methods/NNS have/VBP been/VBN proposed/VBN for/IN learning/VBG this/DT representation/NN from/IN large/JJ corpora/NNS ./.
This/DT type/NN of/IN word/NN -/HYPH to/IN -/HYPH vector/NN embedding/NN is/VBZ able/JJ to/TO keep/VB ,/, in/IN the/DT learned/VBN vector/NN space/NN ,/, some/DT of/IN the/DT syntactic/JJ and/CC semantic/JJ relationships/NNS present/JJ in/IN the/DT original/JJ word/NN corpus/NN ./.
This/DT ,/, in/IN turn/NN ,/, serves/VBZ to/TO address/VB different/JJ types/NNS of/IN language/NN classification/NN tasks/NNS by/IN doing/VBG algebraic/JJ operations/NNS defined/VBN on/IN the/DT vectors/NNS ./.
The/DT general/JJ practice/NN is/VBZ to/TO assume/VB that/IN the/DT semantic/JJ relationships/NNS between/IN the/DT words/NNS can/MD be/VB inferred/VBN by/IN the/DT application/NN of/IN a-priori/NN specified/VBN algebraic/JJ operations/NNS ./.
Our/PRP$ general/JJ goal/NN in/IN this/DT paper/NN is/VBZ to/TO show/VB that/IN it/PRP is/VBZ possible/JJ to/TO learn/VB methods/NNS for/IN word/NN composition/NN in/IN semantic/JJ spaces/NNS ./.
Instead/RB of/IN expressing/VBG the/DT compositional/JJ method/NN as/IN an/DT algebraic/JJ operation/NN ,/, we/PRP will/MD encode/VB it/PRP as/IN a/DT program/NN ,/, which/WDT can/MD be/VB linear/JJ ,/, nonlinear/JJ ,/, or/CC involve/VB more/JJR intricate/JJ expressions/NNS ./.
More/JJR remarkably/RB ,/, this/DT program/NN will/MD be/VB evolved/VBN from/IN a/DT set/NN of/IN initial/JJ random/JJ programs/NNS by/IN means/NNS of/IN genetic/JJ programming/NN (/-LRB- GP/NNP )/-RRB- ./.
We/PRP show/VBP that/IN our/PRP$ method/NN is/VBZ able/JJ to/TO reproduce/VB the/DT same/JJ behavior/NN as/IN human/JJ -/HYPH designed/VBN algebraic/JJ operators/NNS ./.
Using/VBG a/DT word/NN analogy/NN task/NN as/IN benchmark/NN ,/, we/PRP also/RB show/VBP that/IN GP/NNP -/HYPH generated/VBN programs/NNS are/VBP able/JJ to/TO obtain/VB accuracy/NN values/NNS above/IN those/DT produced/VBN by/IN the/DT commonly/RB used/VBN human/JJ -/HYPH designed/VBN rule/NN for/IN algebraic/JJ manipulation/NN of/IN word/NN vectors/NNS ./.
Finally/RB ,/, we/PRP show/VBP the/DT robustness/NN of/IN our/PRP$ approach/NN by/IN executing/VBG the/DT evolved/VBN programs/NNS on/IN the/DT word2vec/NN GoogleNews/NN vectors/NNS ,/, learned/VBD over/IN 3/CD billion/CD running/VBG words/NNS ,/, and/CC assessing/VBG their/PRP$ accuracy/NN in/IN the/DT same/JJ word/NN analogy/NN task/NN ./.
