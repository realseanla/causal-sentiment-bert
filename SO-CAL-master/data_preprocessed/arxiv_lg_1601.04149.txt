In/IN this/DT paper/NN ,/, we/PRP design/VBP a/DT Deep/JJ Dual/JJ -/HYPH Domain/NN (/-LRB- $/$ \/CD mathbf/NN {/-LRB- D/NN ^/SYM 3/CD }/-RRB- $/$ )/-RRB- based/VBN fast/JJ restoration/NN model/NN to/TO remove/VB artifacts/NNS of/IN JPEG/NNP compressed/VBN images/NNS ./.
It/PRP leverages/VBZ the/DT large/JJ learning/NN capacity/NN of/IN deep/JJ networks/NNS ,/, as/RB well/RB as/IN the/DT problem/NN -/HYPH specific/JJ expertise/NN that/WDT was/VBD hardly/RB incorporated/VBN in/IN the/DT past/JJ design/NN of/IN deep/JJ architectures/NNS ./.
For/IN the/DT latter/JJ ,/, we/PRP take/VBP into/IN consideration/NN both/CC the/DT prior/JJ knowledge/NN of/IN the/DT JPEG/NNP compression/NN scheme/NN ,/, and/CC the/DT successful/JJ practice/NN of/IN the/DT sparsity/NN -/HYPH based/VBN dual/JJ -/HYPH domain/NN approach/NN ./.
We/PRP further/RB design/VB the/DT One/CD -/HYPH Step/NN Sparse/JJ Inference/NN (/-LRB- 1/CD -/SYM SI/NN )/-RRB- module/NN ,/, as/IN an/DT efficient/JJ and/CC light/JJ -/HYPH weighted/JJ feed/NN -/HYPH forward/JJ approximation/NN of/IN sparse/JJ coding/NN ./.
Extensive/JJ experiments/NNS verify/VBP the/DT superiority/NN of/IN the/DT proposed/VBN $/NN D/NN ^/SYM 3/CD $/$ model/NN over/IN several/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS ./.
Specifically/RB ,/, our/PRP$ best/JJS model/NN is/VBZ capable/JJ of/IN outperforming/VBG the/DT latest/JJS deep/JJ model/NN for/IN around/RB 1/CD dB/NN in/IN PSNR/NNP ,/, and/CC is/VBZ 30/CD times/NNS faster/JJR ./.
