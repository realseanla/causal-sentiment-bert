Efficient/JJ exploration/NN in/IN high/JJ -/HYPH dimensional/JJ environments/NNS remains/VBZ a/DT key/JJ challenge/NN in/IN reinforcement/NN learning/NN (/-LRB- RL/NN )/-RRB- ./.
Deep/JJ reinforcement/NN learning/VBG methods/NNS have/VBP demonstrated/VBN the/DT ability/NN to/TO learn/VB with/IN highly/RB general/JJ policy/NN classes/NNS for/IN complex/JJ tasks/NNS with/IN high/JJ -/HYPH dimensional/JJ inputs/NNS ,/, such/JJ as/IN raw/JJ images/NNS ./.
However/RB ,/, many/JJ of/IN the/DT most/RBS effective/JJ exploration/NN techniques/NNS rely/VBP on/IN tabular/JJ representations/NNS ,/, or/CC on/IN the/DT ability/NN to/TO construct/VB a/DT generative/JJ model/NN over/IN states/NNS and/CC actions/NNS ./.
Both/DT are/VBP exceptionally/RB difficult/JJ when/WRB these/DT inputs/NNS are/VBP complex/JJ and/CC high/JJ dimensional/JJ ./.
On/IN the/DT other/JJ hand/NN ,/, it/PRP is/VBZ comparatively/RB easy/JJ to/TO build/VB discriminative/JJ models/NNS on/IN top/NN of/IN complex/JJ states/NNS such/JJ as/IN images/NNS using/VBG standard/JJ deep/JJ neural/JJ networks/NNS ./.
This/DT paper/NN introduces/VBZ a/DT novel/JJ approach/NN ,/, EX2/NN ,/, which/WDT approximates/VBZ state/NN visitation/NN densities/NNS by/IN training/VBG an/DT ensemble/NN of/IN discriminators/NNS ,/, and/CC assigns/VBZ reward/NN bonuses/NNS to/IN rarely/RB visited/VBN states/NNS ./.
We/PRP demonstrate/VBP that/IN EX2/NN achieves/VBZ comparable/JJ performance/NN to/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS on/IN low/JJ -/HYPH dimensional/JJ tasks/NNS ,/, and/CC its/PRP$ effectiveness/NN scales/NNS into/IN high/JJ -/HYPH dimensional/JJ state/NN spaces/NNS such/JJ as/IN visual/JJ domains/NNS without/IN hand/NN -/HYPH designing/VBG features/NNS or/CC density/NN models/NNS ./.
