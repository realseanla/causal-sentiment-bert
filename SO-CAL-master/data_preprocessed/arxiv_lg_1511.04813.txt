Online/NN learning/NN with/IN multiple/JJ kernels/NNS has/VBZ gained/VBN increasing/VBG interests/NNS in/IN recent/JJ years/NNS and/CC found/VBD many/JJ applications/NNS ./.
For/IN classification/NN tasks/NNS ,/, Online/JJ Multiple/JJ Kernel/NNP Classification/NN (/-LRB- OMKC/NN )/-RRB- ,/, which/WDT learns/VBZ a/DT kernel/NN based/VBN classifier/NN by/IN seeking/VBG the/DT optimal/JJ linear/JJ combination/NN of/IN a/DT pool/NN of/IN single/JJ kernel/NN classifiers/NNS in/IN an/DT online/JJ fashion/NN ,/, achieves/VBZ superior/JJ accuracy/NN and/CC enjoys/VBZ great/JJ flexibility/NN compared/VBN with/IN traditional/JJ single/JJ -/HYPH kernel/NN classifiers/NNS ./.
Despite/IN being/VBG studied/VBN extensively/RB ,/, existing/VBG OMKC/NNP algorithms/NNS suffer/VBP from/IN high/JJ computational/JJ cost/NN due/IN to/IN their/PRP$ unbounded/JJ numbers/NNS of/IN support/NN vectors/NNS ./.
To/TO overcome/VB this/DT drawback/NN ,/, we/PRP present/VBP a/DT novel/JJ framework/NN of/IN Budget/NNP Online/NNP Multiple/JJ Kernel/NNP Learning/NNP (/-LRB- BOMKL/NNP )/-RRB- and/CC propose/VB a/DT new/JJ Sparse/NNP Passive/NNP Aggressive/JJ learning/NN to/TO perform/VB effective/JJ budget/NN online/JJ learning/NN ./.
Specifically/RB ,/, we/PRP adopt/VBP a/DT simple/JJ yet/CC effective/JJ Bernoulli/NNP sampling/NN to/TO decide/VB if/IN an/DT incoming/JJ instance/NN should/MD be/VB added/VBN to/IN the/DT current/JJ set/NN of/IN support/NN vectors/NNS ./.
By/IN limiting/VBG the/DT number/NN of/IN support/NN vectors/NNS ,/, our/PRP$ method/NN can/MD significantly/RB accelerate/VB OMKC/NN while/IN maintaining/VBG satisfactory/JJ accuracy/NN that/WDT is/VBZ comparable/JJ to/IN that/DT of/IN the/DT existing/VBG OMKC/NNP algorithms/NNS ./.
We/PRP theoretically/RB prove/VBP that/IN our/PRP$ new/JJ method/NN achieves/VBZ an/DT optimal/JJ regret/NN bound/VBN in/IN expectation/NN ,/, and/CC empirically/RB found/VBD that/IN the/DT proposed/VBN algorithm/NN outperforms/VBZ various/JJ OMKC/NNP algorithms/NNS and/CC can/MD easily/RB scale/VB up/RP to/IN large/JJ -/HYPH scale/NN datasets/NNS ./.
