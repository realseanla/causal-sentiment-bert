Sparsity/NN -/HYPH inducing/VBG penalties/NNS are/VBP useful/JJ tools/NNS to/TO design/VB multiclass/JJ support/NN vector/NN machines/NNS (/-LRB- SVMs/NNS )/-RRB- ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT convex/NN optimization/NN approach/NN for/IN efficiently/RB and/CC exactly/RB solving/VBG the/DT multiclass/NN SVM/NN learning/NN problem/NN involving/VBG a/DT sparse/JJ regularization/NN and/CC the/DT multiclass/NN hinge/NN loss/NN formulated/VBN by/IN Crammer/NNP and/CC Singer/NNP ./.
We/PRP provide/VBP two/CD algorithms/NNS :/: the/DT first/JJ one/CD dealing/VBG with/IN the/DT hinge/NN loss/NN as/IN a/DT penalty/NN term/NN ,/, and/CC the/DT other/JJ one/CD addressing/VBG the/DT case/NN when/WRB the/DT hinge/NN loss/NN is/VBZ enforced/VBN through/IN a/DT constraint/NN ./.
The/DT related/JJ convex/NN optimization/NN problems/NNS can/MD be/VB efficiently/RB solved/VBN thanks/NNS to/IN the/DT flexibility/NN offered/VBN by/IN recent/JJ primal/JJ -/HYPH dual/JJ proximal/JJ algorithms/NNS and/CC epigraphical/JJ splitting/NN techniques/NNS ./.
Experiments/NNS carried/VBD out/RP on/IN several/JJ datasets/NNS demonstrate/VBP the/DT interest/NN of/IN considering/VBG the/DT exact/JJ expression/NN of/IN the/DT hinge/NN loss/NN rather/RB than/IN a/DT smooth/JJ approximation/NN ./.
The/DT efficiency/NN of/IN the/DT proposed/VBN algorithms/NNS w.r.t./IN several/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS is/VBZ also/RB assessed/VBN through/IN comparisons/NNS of/IN execution/NN times/NNS ./.
