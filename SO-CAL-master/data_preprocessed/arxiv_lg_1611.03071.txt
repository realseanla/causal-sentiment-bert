We/PRP initiate/VBP the/DT study/NN of/IN fair/JJ learning/NN in/IN Markovian/JJ settings/NNS ,/, where/WRB the/DT actions/NNS of/IN a/DT learning/NN algorithm/NN may/MD affect/VB its/PRP$ environment/NN and/CC future/JJ rewards/NNS ./.
Working/VBG in/IN the/DT model/NN of/IN reinforcement/NN learning/NN ,/, we/PRP define/VBP a/DT fairness/NN constraint/NN requiring/VBG that/IN an/DT algorithm/NN never/RB prefers/VBZ one/CD action/NN over/IN another/DT if/IN the/DT long/JJ -/HYPH term/NN (/-LRB- discounted/VBN )/-RRB- reward/NN of/IN choosing/VBG the/DT latter/JJ action/NN is/VBZ higher/JJR ./.
