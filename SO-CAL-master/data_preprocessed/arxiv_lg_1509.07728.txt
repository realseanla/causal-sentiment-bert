In/IN this/DT paper/NN ,/, we/PRP study/VBP a/DT special/JJ bandit/NN setting/NN of/IN online/JJ stochastic/JJ linear/JJ optimization/NN ,/, where/WRB only/RB one/CD -/HYPH bit/NN of/IN information/NN is/VBZ revealed/VBN to/IN the/DT learner/NN at/IN each/DT round/NN ./.
This/DT problem/NN has/VBZ found/VBN many/JJ applications/NNS including/VBG online/JJ advertisement/NN and/CC online/JJ recommendation/NN ./.
We/PRP assume/VBP the/DT binary/JJ feedback/NN is/VBZ a/DT random/JJ variable/JJ generated/VBN from/IN the/DT logit/NN model/NN ,/, and/CC aim/VB to/TO minimize/VB the/DT regret/NN defined/VBN by/IN the/DT unknown/JJ linear/JJ function/NN ./.
Although/IN the/DT existing/VBG method/NN for/IN generalized/VBN linear/JJ bandit/NN can/MD be/VB applied/VBN to/IN our/PRP$ problem/NN ,/, the/DT high/JJ computational/JJ cost/NN makes/VBZ it/PRP impractical/JJ for/IN real/JJ -/HYPH world/NN problems/NNS ./.
To/TO address/VB this/DT challenge/NN ,/, we/PRP develop/VBP an/DT efficient/JJ online/JJ learning/NN algorithm/NN by/IN exploiting/VBG particular/JJ structures/NNS of/IN the/DT observation/NN model/NN ./.
Specifically/RB ,/, we/PRP adopt/VBP online/JJ Newton/NNP step/NN to/TO estimate/VB the/DT unknown/JJ parameter/NN and/CC derive/VBP a/DT tight/JJ confidence/NN region/NN based/VBN on/IN the/DT exponential/JJ concavity/NN of/IN the/DT logistic/JJ loss/NN ./.
Our/PRP$ analysis/NN shows/VBZ that/IN the/DT proposed/VBN algorithm/NN achieves/VBZ a/DT regret/NN bound/VBN of/IN $/$ O/UH (/-LRB- d/NN \/SYM sqrt/NN {/-LRB- T/NN }/-RRB- )/-RRB- $/$ ,/, which/WDT matches/VBZ the/DT optimal/JJ result/NN of/IN stochastic/JJ linear/JJ bandits/NNS ./.
