This/DT paper/NN introduces/VBZ a/DT novel/JJ activity/NN dataset/NN which/WDT exhibits/VBZ real/JJ -/HYPH life/NN and/CC diverse/JJ scenarios/NNS of/IN complex/NN ,/, temporally/RB -/HYPH extended/VBN human/JJ activities/NNS and/CC actions/NNS ./.
The/DT dataset/NN presents/VBZ a/DT set/NN of/IN videos/NNS of/IN actors/NNS performing/VBG everyday/JJ activities/NNS in/IN a/DT natural/JJ and/CC unscripted/JJ manner/NN ./.
The/DT dataset/NN was/VBD recorded/VBN using/VBG a/DT static/NN Kinect/NNP 2/CD sensor/NN which/WDT is/VBZ commonly/RB used/VBN on/IN many/JJ robotic/JJ platforms/NNS ./.
The/DT dataset/NN comprises/VBZ of/IN RGB/NNP -/HYPH D/NNP images/NNS ,/, point/NN cloud/NN data/NNS ,/, automatically/RB generated/VBN skeleton/NN tracks/NNS in/IN addition/NN to/IN crowdsourced/VBN annotations/NNS ./.
Furthermore/RB ,/, we/PRP also/RB describe/VBP the/DT methodology/NN used/VBN to/TO acquire/VB annotations/NNS through/IN crowdsourcing/NN ./.
Finally/RB some/DT activity/NN recognition/NN benchmarks/NNS are/VBP presented/VBN using/VBG current/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN techniques/NNS ./.
We/PRP believe/VBP that/IN this/DT dataset/NN is/VBZ particularly/RB suitable/JJ as/IN a/DT testbed/NN for/IN activity/NN recognition/NN research/NN but/CC it/PRP can/MD also/RB be/VB applicable/JJ for/IN other/JJ common/JJ tasks/NNS in/IN robotics/NNS //, computer/NN vision/NN research/NN such/JJ as/IN object/NN detection/NN and/CC human/JJ skeleton/NN tracking/NN ./.
