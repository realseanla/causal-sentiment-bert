We/PRP consider/VBP the/DT problem/NN of/IN efficiently/RB learning/VBG optimal/JJ control/NN policies/NNS and/CC value/NN functions/VBZ over/IN large/JJ state/NN spaces/NNS in/IN an/DT online/JJ setting/NN in/IN which/WDT estimates/NNS must/MD be/VB available/JJ after/IN each/DT interaction/NN with/IN the/DT world/NN ./.
This/DT paper/NN develops/VBZ an/DT explicitly/RB model/NN -/HYPH based/VBN approach/NN extending/VBG the/DT Dyna/NNP architecture/NN to/IN linear/JJ function/NN approximation/NN ./.
Dynastyle/NNP planning/VBG proceeds/NNS by/IN generating/VBG imaginary/JJ experience/NN from/IN the/DT world/NN model/NN and/CC then/RB applying/VBG model/NN -/HYPH free/JJ reinforcement/NN learning/VBG algorithms/NNS to/IN the/DT imagined/VBN state/NN transitions/NNS ./.
Our/PRP$ main/JJ results/NNS are/VBP to/TO prove/VB that/IN linear/JJ Dyna/NNP -/HYPH style/NN planning/NN converges/VBZ to/IN a/DT unique/JJ solution/NN independent/JJ of/IN the/DT generating/VBG distribution/NN ,/, under/IN natural/JJ conditions/NNS ./.
In/IN the/DT policy/NN evaluation/NN setting/NN ,/, we/PRP prove/VBP that/IN the/DT limit/NN point/NN is/VBZ the/DT least/RBS -/HYPH squares/NNS (/-LRB- LSTD/NN )/-RRB- solution/NN ./.
An/DT implication/NN of/IN our/PRP$ results/NNS is/VBZ that/IN prioritized/VBN -/HYPH sweeping/VBG can/MD be/VB soundly/RB extended/VBN to/IN the/DT linear/JJ approximation/NN case/NN ,/, backing/VBG up/RP to/IN preceding/VBG features/NNS rather/RB than/IN to/IN preceding/VBG states/NNS ./.
We/PRP introduce/VBP two/CD versions/NNS of/IN prioritized/VBN sweeping/JJ with/IN linear/JJ Dyna/NNP and/CC briefly/RB illustrate/VBP their/PRP$ performance/NN empirically/RB on/IN the/DT Mountain/NNP Car/NN and/CC Boyan/NNP Chain/NNP problems/NNS ./.
