In/IN conversational/JJ speech/NN ,/, the/DT acoustic/JJ signal/NN provides/VBZ cues/NNS that/WDT help/VBP listeners/NNS disambiguate/JJ difficult/JJ parses/NNS ./.
For/IN automatically/RB parsing/VBG a/DT spoken/VBN utterance/NN ,/, we/PRP introduce/VBP a/DT model/NN that/WDT integrates/VBZ transcribed/VBN text/NN and/CC acoustic/JJ -/HYPH prosodic/JJ features/NNS using/VBG a/DT convolutional/JJ neural/JJ network/NN over/IN energy/NN and/CC pitch/NN trajectories/NNS coupled/VBN with/IN an/DT attention/NN -/HYPH based/VBN recurrent/JJ neural/JJ network/NN that/WDT accepts/VBZ text/NN and/CC word/NN -/HYPH based/VBN prosodic/JJ features/NNS ./.
We/PRP find/VBP that/IN different/JJ types/NNS of/IN acoustic/JJ -/HYPH prosodic/JJ features/NNS are/VBP individually/RB helpful/JJ ,/, and/CC together/RB improve/VB parse/VB F1/NN scores/NNS significantly/RB over/IN a/DT strong/JJ text/NN -/HYPH only/JJ baseline/NN ./.
For/IN this/DT study/NN with/IN known/VBN sentence/NN boundaries/NNS ,/, error/NN analysis/NN shows/VBZ that/IN the/DT main/JJ benefit/NN of/IN acoustic/JJ -/HYPH prosodic/JJ features/NNS is/VBZ in/IN sentences/NNS with/IN disfluencies/NNS and/CC that/IN attachment/NN errors/NNS are/VBP most/RBS improved/VBN ./.
