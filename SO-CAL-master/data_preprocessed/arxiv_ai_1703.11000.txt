Visual/JJ servoing/NN involves/VBZ choosing/VBG actions/NNS that/WDT move/VBP a/DT robot/NN in/IN response/NN to/IN observations/NNS from/IN a/DT camera/NN ,/, in/IN order/NN to/TO reach/VB a/DT goal/NN configuration/NN in/IN the/DT world/NN ./.
Standard/JJ visual/JJ servoing/NN approaches/NNS typically/RB rely/VBP on/IN manually/RB designed/VBN features/NNS and/CC analytical/JJ dynamics/NNS models/NNS ,/, which/WDT limits/VBZ their/PRP$ generalization/NN capability/NN and/CC often/RB requires/VBZ extensive/JJ application/NN -/HYPH specific/JJ feature/NN and/CC model/NN engineering/NN ./.
In/IN this/DT work/NN ,/, we/PRP study/VBP how/WRB learned/VBN visual/JJ features/NNS ,/, learned/VBD predictive/JJ dynamics/NNS models/NNS ,/, and/CC reinforcement/NN learning/NN can/MD be/VB combined/VBN to/TO learn/VB visual/JJ servoing/NN mechanisms/NNS ./.
We/PRP focus/VBP on/IN target/NN following/VBG ,/, with/IN the/DT goal/NN of/IN designing/VBG algorithms/NNS that/WDT can/MD learn/VB a/DT visual/JJ servo/NN using/VBG low/JJ amounts/NNS of/IN data/NNS of/IN the/DT target/NN in/IN question/NN ,/, to/TO enable/VB quick/JJ adaptation/NN to/IN new/JJ targets/NNS ./.
Our/PRP$ approach/NN is/VBZ based/VBN on/IN servoing/VBG the/DT camera/NN in/IN the/DT space/NN of/IN learned/VBN visual/JJ features/NNS ,/, rather/RB than/IN image/NN pixels/NNS or/CC manually/RB -/HYPH designed/VBN keypoints/NNS ./.
We/PRP demonstrate/VBP that/IN standard/JJ deep/JJ features/NNS ,/, in/IN our/PRP$ case/NN taken/VBN from/IN a/DT model/NN trained/VBN for/IN object/NN classification/NN ,/, can/MD be/VB used/VBN together/RB with/IN a/DT bilinear/NN predictive/JJ model/NN to/TO learn/VB an/DT effective/JJ visual/JJ servo/NN that/WDT is/VBZ robust/JJ to/IN visual/JJ variation/NN ,/, changes/NNS in/IN viewing/VBG angle/NN and/CC appearance/NN ,/, and/CC occlusions/NNS ./.
A/DT key/JJ component/NN of/IN our/PRP$ approach/NN is/VBZ to/TO use/VB a/DT sample/NN -/HYPH efficient/JJ fitted/VBN Q/NN -/HYPH iteration/NN algorithm/NN to/TO learn/VB which/WDT features/NNS are/VBP best/RBS suited/JJ for/IN the/DT task/NN at/IN hand/NN ./.
We/PRP show/VBP that/IN we/PRP can/MD learn/VB an/DT effective/JJ visual/JJ servo/NN on/IN a/DT complex/JJ synthetic/JJ car/NN following/VBG benchmark/NN using/VBG just/RB 20/CD training/NN trajectory/NN samples/NNS for/IN reinforcement/NN learning/NN ./.
We/PRP demonstrate/VBP substantial/JJ improvement/NN over/IN a/DT conventional/JJ approach/NN based/VBN on/IN image/NN pixels/NNS or/CC hand/NN -/HYPH designed/VBN keypoints/NNS ,/, and/CC we/PRP show/VBP an/DT improvement/NN in/IN sample/NN -/HYPH efficiency/NN of/IN more/JJR than/IN two/CD orders/NNS of/IN magnitude/NN over/IN standard/JJ model/NN -/HYPH free/JJ deep/JJ reinforcement/NN learning/VBG algorithms/NNS ./.
Videos/NNS are/VBP available/JJ at/IN \/SYM url/NN {/-LRB-
