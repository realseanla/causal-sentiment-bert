Credit/NN assignment/NN in/IN traditional/JJ recurrent/JJ neural/JJ networks/NNS usually/RB involves/VBZ back/RB -/HYPH propagating/VBG through/IN a/DT long/JJ chain/NN of/IN tied/VBN weight/NN matrices/NNS ./.
The/DT length/NN of/IN this/DT chain/NN scales/NNS linearly/RB with/IN the/DT number/NN of/IN time/NN -/HYPH steps/NNS as/IN the/DT same/JJ network/NN is/VBZ run/VBN at/IN each/DT time/NN -/HYPH step/NN ./.
This/DT creates/VBZ many/JJ problems/NNS ,/, such/JJ as/IN vanishing/VBG gradients/NNS ,/, that/WDT have/VBP been/VBN well/RB studied/VBN ./.
In/IN contrast/NN ,/, a/DT NNEM/NNP 's/POS architecture/NN recurrent/JJ activity/NN does/VBZ n't/RB involve/VB a/DT long/JJ chain/NN of/IN activity/NN (/-LRB- though/IN some/DT architectures/NNS such/JJ as/IN the/DT NTM/NNP do/VBP utilize/VB a/DT traditional/JJ recurrent/JJ architecture/NN as/IN a/DT controller/NN )/-RRB- ./.
Rather/RB ,/, the/DT externally/RB stored/VBN embedding/NN vectors/NNS are/VBP used/VBN at/IN each/DT time/NN -/HYPH step/NN ,/, but/CC no/DT messages/NNS are/VBP passed/VBN from/IN previous/JJ time/NN -/HYPH steps/NNS ./.
This/DT means/VBZ that/IN vanishing/VBG gradients/NNS are/VBP n't/RB a/DT problem/NN ,/, as/RB all/DT of/IN the/DT necessary/JJ gradient/NN paths/NNS are/VBP short/JJ ./.
However/RB ,/, these/DT paths/NNS are/VBP extremely/RB numerous/JJ (/-LRB- one/CD per/IN embedding/NN vector/NN in/IN memory/NN )/-RRB- and/CC reused/VBN for/IN a/DT very/RB long/JJ time/NN (/-LRB- until/IN it/PRP leaves/VBZ the/DT memory/NN )/-RRB- ./.
Thus/RB ,/, the/DT forward/JJ -/HYPH pass/NN information/NN of/IN each/DT memory/NN must/MD be/VB stored/VBN for/IN the/DT entire/JJ duration/NN of/IN the/DT memory/NN ./.
This/DT is/VBZ problematic/JJ as/IN this/DT additional/JJ storage/NN far/RB surpasses/VBZ that/IN of/IN the/DT actual/JJ memories/NNS ,/, to/IN the/DT extent/NN that/WDT large/JJ memories/NNS on/IN infeasible/JJ to/TO back/RB -/HYPH propagate/VB through/IN in/IN high/JJ dimensional/JJ settings/NNS ./.
One/CD way/NN to/TO get/VB around/IN the/DT need/NN to/TO hold/VB onto/IN forward/RB -/HYPH pass/VB information/NN is/VBZ to/TO recalculate/VB the/DT forward/JJ -/HYPH pass/NN whenever/WRB gradient/NN information/NN is/VBZ available/JJ ./.
However/RB ,/, if/IN the/DT observations/NNS are/VBP too/RB large/JJ to/TO store/VB in/IN the/DT domain/NN of/IN interest/NN ,/, direct/JJ reinstatement/NN of/IN a/DT forward/JJ pass/NN can/MD not/RB occur/VB ./.
Instead/RB ,/, we/PRP rely/VBP on/IN a/DT learned/VBN autoencoder/NN to/TO reinstate/VB the/DT observation/NN ,/, and/CC then/RB use/VB the/DT embedding/NN network/NN to/TO recalculate/VB the/DT forward/JJ -/HYPH pass/NN ./.
Since/IN the/DT recalculated/VBN embedding/NN vector/NN is/VBZ unlikely/JJ to/TO perfectly/RB match/VB the/DT one/CD stored/VBN in/IN memory/NN ,/, we/PRP try/VBP out/RP 2/CD approximations/NNS to/TO utilize/VB error/NN gradient/NN w.r.t./IN the/DT vector/NN in/IN memory/NN ./.
