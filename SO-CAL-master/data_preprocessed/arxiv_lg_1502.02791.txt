Recent/JJ studies/NNS reveal/VBP that/IN a/DT deep/JJ neural/JJ network/NN can/MD learn/VB transferable/JJ features/NNS which/WDT generalize/VBP well/RB to/IN novel/JJ tasks/NNS for/IN domain/NN adaptation/NN ./.
However/RB ,/, as/IN deep/JJ features/NNS eventually/RB transition/NN from/IN general/JJ to/IN specific/JJ along/IN the/DT network/NN ,/, the/DT feature/NN transferability/NN drops/VBZ significantly/RB in/IN higher/JJR layers/NNS with/IN increasing/VBG domain/NN discrepancy/NN ./.
Hence/RB ,/, it/PRP is/VBZ critical/JJ to/IN formally/RB reduce/VB the/DT domain/NN bias/NN and/CC enhance/VB the/DT transferability/NN in/IN task/NN -/HYPH specific/JJ layers/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT new/JJ Deep/NNP Adaptation/NNP Network/NNP (/-LRB- DAN/NNP )/-RRB- architecture/NN ,/, which/WDT generalizes/VBZ deep/JJ convolutional/JJ neural/JJ network/NN to/IN the/DT domain/NN adaptation/NN scenario/NN ./.
In/IN DAN/NNP ,/, hidden/JJ representations/NNS of/IN all/DT task/NN -/HYPH specific/JJ layers/NNS are/VBP embedded/VBN to/IN a/DT reproducing/VBG kernel/NN Hilbert/NNP space/NN where/WRB the/DT mean/JJ embeddings/NNS of/IN different/JJ domain/NN distributions/NNS can/MD be/VB explicitly/RB matched/VBN ./.
The/DT domain/NN discrepancy/NN is/VBZ further/RB reduced/VBN using/VBG an/DT optimal/JJ multi-kernel/NN selection/NN method/NN for/IN mean/JJ embedding/NN matching/NN ./.
DAN/NNP can/MD learn/VB invariant/JJ features/NNS with/IN enhanced/VBN transferability/NN ,/, and/CC can/MD scale/VB linearly/RB by/IN unbiased/JJ estimate/NN of/IN kernel/NN embedding/NN ./.
Extensive/JJ empirical/JJ evidence/NN demonstrates/VBZ the/DT proposed/VBN architecture/NN significantly/RB outperforms/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS on/IN standard/JJ domain/NN adaptation/NN benchmarks/NNS ./.
