We/PRP consider/VBP a/DT sequential/JJ learning/NN problem/NN with/IN Gaussian/JJ payoffs/NNS and/CC side/NN information/NN :/: after/IN selecting/VBG an/DT action/NN $/$ i/CD $/$ ,/, the/DT learner/NN receives/VBZ information/NN about/IN the/DT payoff/NN of/IN every/DT action/NN $/$ j/NN $/$ in/IN the/DT form/NN of/IN Gaussian/JJ observations/NNS whose/WP$ mean/NN is/VBZ the/DT same/JJ as/IN the/DT mean/JJ payoff/NN ,/, but/CC the/DT variance/NN depends/VBZ on/IN the/DT pair/NN $/$ (/-LRB- i/PRP ,/, j/NN )/-RRB- $/$ (/-LRB- and/CC may/MD be/VB infinite/JJ )/-RRB- ./.
The/DT setup/NN allows/VBZ a/DT more/RBR refined/JJ information/NN transfer/NN from/IN one/CD action/NN to/IN another/DT than/IN previous/JJ partial/JJ monitoring/NN setups/NNS ,/, including/VBG the/DT recently/RB introduced/VBN graph/NN -/HYPH structured/VBN feedback/NN case/NN ./.
For/IN the/DT first/JJ time/NN in/IN the/DT literature/NN ,/, we/PRP provide/VBP non-asymptotic/JJ problem/NN -/HYPH dependent/JJ lower/JJR bounds/NNS on/IN the/DT regret/NN of/IN any/DT algorithm/NN ,/, which/WDT recover/VBP existing/VBG asymptotic/JJ problem/NN -/HYPH dependent/JJ lower/JJR bounds/NNS and/CC finite/NN -/HYPH time/NN minimax/NN lower/JJR bounds/NNS available/JJ in/IN the/DT literature/NN ./.
We/PRP also/RB provide/VBP algorithms/NNS that/WDT achieve/VBP the/DT problem/NN -/HYPH dependent/JJ lower/JJR bound/JJ (/-LRB- up/RP to/IN some/DT universal/JJ constant/JJ factor/NN )/-RRB- or/CC the/DT minimax/NN lower/JJR bounds/NNS (/-LRB- up/RP to/IN logarithmic/JJ factors/NNS )/-RRB- ./.
