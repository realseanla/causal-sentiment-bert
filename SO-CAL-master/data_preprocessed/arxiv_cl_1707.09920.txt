We/PRP investigate/VBP techniques/NNS for/IN supervised/JJ domain/NN adaptation/NN for/IN neural/JJ machine/NN translation/NN where/WRB an/DT existing/VBG model/NN trained/VBN on/IN a/DT large/JJ out/NN -/HYPH of/IN -/HYPH domain/NN dataset/NN is/VBZ adapted/VBN to/IN a/DT small/JJ in/IN -/HYPH domain/NN dataset/NN ./.
In/IN this/DT scenario/NN ,/, overfitting/NN is/VBZ a/DT major/JJ challenge/NN ./.
We/PRP investigate/VBP a/DT number/NN of/IN techniques/NNS to/TO reduce/VB overfitting/NN and/CC improve/VB transfer/NN learning/NN ,/, including/VBG regularization/NN techniques/NNS such/JJ as/IN dropout/NN and/CC L2/NN -/HYPH regularization/NN towards/IN an/DT out/NN -/HYPH of/IN -/HYPH domain/NN prior/JJ ./.
In/IN addition/NN ,/, we/PRP introduce/VBP tuneout/NN ,/, a/DT novel/JJ regularization/NN technique/NN inspired/VBN by/IN dropout/NN ./.
We/PRP apply/VBP these/DT techniques/NNS ,/, alone/JJ and/CC in/IN combination/NN ,/, to/IN neural/JJ machine/NN translation/NN ,/, obtaining/VBG improvements/NNS on/IN IWSLT/NNP datasets/NNS for/IN English/NNP -/HYPH &gt;/SYM German/JJ and/CC English/JJ -/HYPH &gt;/SYM Russian/JJ ./.
We/PRP also/RB investigate/VB the/DT amounts/NNS of/IN in/IN -/HYPH domain/NN training/NN data/NNS needed/VBN for/IN domain/NN adaptation/NN in/IN NMT/NNP ,/, and/CC find/VB a/DT logarithmic/JJ relationship/NN between/IN the/DT amount/NN of/IN training/NN data/NNS and/CC gain/VB in/IN BLEU/NNP score/NN ./.
