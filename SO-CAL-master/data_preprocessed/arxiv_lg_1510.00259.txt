Neural/JJ Language/NNP Models/NNPS are/VBP a/DT powerful/JJ tool/NN to/TO meaningfully/RB embed/VB words/NNS into/IN semantic/JJ vector/NN spaces/NNS ./.
However/RB ,/, learning/VBG vector/NN space/NN models/NNS of/IN language/NN generally/RB relies/VBZ on/IN the/DT availability/NN of/IN abundant/JJ and/CC diverse/JJ training/NN examples/NNS ./.
In/IN highly/RB specialized/JJ domains/NNS this/DT requirement/NN may/MD not/RB be/VB met/VBN due/IN to/IN difficulties/NNS in/IN obtaining/VBG a/DT large/JJ corpus/NN ,/, or/CC the/DT limited/JJ range/NN of/IN expression/NN in/IN average/JJ usage/NN ./.
Prior/JJ knowledge/NN about/IN entities/NNS in/IN the/DT language/NN often/RB exists/VBZ in/IN a/DT knowledge/NN base/NN or/CC ontology/NN ./.
We/PRP propose/VBP a/DT generative/JJ model/NN which/WDT allows/VBZ for/IN modeling/NN and/CC transfering/VBG semantic/JJ information/NN in/IN vector/NN spaces/NNS by/IN combining/VBG diverse/JJ data/NNS sources/NNS ./.
We/PRP generalize/VBP the/DT concept/NN of/IN co-occurrence/NN from/IN distributional/JJ semantics/NNS to/TO include/VB other/JJ types/NNS of/IN relations/NNS between/IN entities/NNS ,/, evidence/NN for/IN which/WDT can/MD come/VB from/IN a/DT knowledge/NN base/NN (/-LRB- such/JJ as/IN WordNet/NNP or/CC UMLS/NNP )/-RRB- ./.
Our/PRP$ model/NN defines/VBZ a/DT probability/NN distribution/NN over/IN triplets/NNS consisting/VBG of/IN word/NN pairs/NNS with/IN relations/NNS ./.
Through/IN stochastic/JJ maximum/JJ likelihood/NN we/PRP learn/VBP a/DT representation/NN of/IN these/DT words/NNS as/IN elements/NNS of/IN a/DT vector/NN space/NN and/CC model/NN the/DT relations/NNS as/IN affine/JJ transformations/NNS ./.
We/PRP demonstrate/VBP the/DT effectiveness/NN of/IN our/PRP$ generative/JJ approach/NN by/IN outperforming/VBG recent/JJ models/NNS on/IN a/DT knowledge/NN -/HYPH base/NN completion/NN task/NN and/CC demonstrating/VBG its/PRP$ ability/NN to/TO profit/VB from/IN the/DT use/NN of/IN partially/RB observed/VBN or/CC fully/RB unobserved/JJ data/NNS entries/NNS ./.
Our/PRP$ model/NN is/VBZ capable/JJ of/IN operating/VBG semi-supervised/VBN ,/, where/WRB word/NN pairs/NNS with/IN no/DT known/JJ relation/NN are/VBP used/VBN as/IN training/NN data/NNS ./.
We/PRP further/RB demonstrate/VBP the/DT usefulness/NN of/IN learning/VBG from/IN different/JJ data/NNS sources/NNS with/IN overlapping/VBG vocabularies/NNS ./.
