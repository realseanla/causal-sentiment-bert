We/PRP present/VBP a/DT simple/JJ and/CC effective/JJ approach/NN to/IN incorporating/VBG syntactic/JJ structure/NN into/IN neural/JJ attention/NN -/HYPH based/VBN encoder/NN -/HYPH decoder/NN models/NNS for/IN machine/NN translation/NN ./.
We/PRP rely/VBP on/IN graph/NN -/HYPH convolutional/JJ networks/NNS (/-LRB- GCNs/NNS )/-RRB- ,/, a/DT recent/JJ class/NN of/IN neural/JJ networks/NNS developed/VBN for/IN modeling/VBG graph/NN -/HYPH structured/VBN data/NNS ./.
Our/PRP$ GCNs/NNS use/VBP predicted/VBN syntactic/JJ dependency/NN trees/NNS of/IN source/NN sentences/NNS to/TO produce/VB representations/NNS of/IN words/NNS (/-LRB- i.e./FW hidden/JJ states/NNS of/IN the/DT encoder/NN )/-RRB- that/WDT are/VBP sensitive/JJ to/IN their/PRP$ syntactic/JJ neighborhoods/NNS ./.
GCNs/NNS take/VBP word/NN representations/NNS as/IN input/NN and/CC produce/VB word/NN representations/NNS as/IN output/NN ,/, so/RB they/PRP can/MD easily/RB be/VB incorporated/VBN as/IN layers/NNS into/IN standard/JJ encoders/NNS (/-LRB- e.g./FW ,/, on/IN top/NN of/IN bidirectional/JJ RNNs/NNS or/CC convolutional/JJ neural/JJ networks/NNS )/-RRB- ./.
We/PRP evaluate/VBP their/PRP$ effectiveness/NN with/IN English/NNP -/HYPH German/NNP and/CC English/NNP -/HYPH Czech/NNP translation/NN experiments/NNS for/IN different/JJ types/NNS of/IN encoders/NNS and/CC observe/VBP substantial/JJ improvements/NNS over/IN their/PRP$ syntax/NN -/HYPH agnostic/JJ versions/NNS in/IN all/PDT the/DT considered/VBN setups/NNS ./.
