Distributed/VBN representation/NN learned/VBD with/IN neural/JJ networks/NNS has/VBZ recently/RB shown/VBN to/TO be/VB effective/JJ in/IN modeling/VBG natural/JJ languages/NNS at/IN fine/JJ granularities/NNS such/JJ as/IN words/NNS ,/, phrases/NNS ,/, and/CC even/RB sentences/NNS ./.
Whether/IN and/CC how/WRB such/PDT an/DT approach/NN can/MD be/VB extended/VBN to/TO help/VB model/NN larger/JJR spans/NNS of/IN text/NN ,/, e.g./FW ,/, documents/NNS ,/, is/VBZ intriguing/JJ ,/, and/CC further/JJ investigation/NN would/MD still/RB be/VB desirable/JJ ./.
This/DT paper/NN aims/VBZ to/TO enhance/VB neural/JJ network/NN models/NNS for/IN such/PDT a/DT purpose/NN ./.
A/DT typical/JJ problem/NN of/IN document/NN -/HYPH level/NN modeling/NN is/VBZ automatic/JJ summarization/NN ,/, which/WDT aims/VBZ to/TO model/VB documents/NNS in/IN order/NN to/TO generate/VB summaries/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP neural/JJ models/NNS to/TO train/VB computers/NNS not/RB just/RB to/TO pay/VB attention/NN to/IN specific/JJ regions/NNS and/CC content/NN of/IN input/NN documents/NNS with/IN attention/NN models/NNS ,/, but/CC also/RB distract/VB them/PRP to/TO traverse/VB between/IN different/JJ content/NN of/IN a/DT document/NN so/IN as/IN to/TO better/RBR grasp/VB the/DT overall/JJ meaning/NN for/IN summarization/NN ./.
Without/IN engineering/VBG any/DT features/NNS ,/, we/PRP train/VBP the/DT models/NNS on/IN two/CD large/JJ datasets/NNS ./.
The/DT models/NNS achieve/VBP the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN ,/, and/CC they/PRP significantly/RB benefit/VBP from/IN the/DT distraction/NN modeling/NN ,/, particularly/RB when/WRB input/NN documents/NNS are/VBP long/JJ ./.
