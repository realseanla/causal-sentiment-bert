Despite/IN the/DT importance/NN of/IN sparsity/NN in/IN many/JJ big/JJ data/NNS applications/NNS ,/, there/EX are/VBP few/JJ existing/VBG methods/NNS for/IN efficient/JJ distributed/VBN optimization/NN of/IN sparsely/RB -/HYPH regularized/VBN objectives/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP present/VBP a/DT communication/NN -/HYPH efficient/JJ framework/NN for/IN L1/NN -/HYPH regularized/VBN optimization/NN in/IN distributed/VBN environments/NNS ./.
By/IN taking/VBG a/DT non-traditional/JJ view/NN of/IN classical/JJ objectives/NNS as/IN part/NN of/IN a/DT more/RBR general/JJ primal/JJ -/HYPH dual/JJ setting/NN ,/, we/PRP obtain/VBP a/DT new/JJ class/NN of/IN methods/NNS that/WDT can/MD be/VB efficiently/RB distributed/VBN and/CC is/VBZ applicable/JJ to/IN common/JJ L1/NN -/HYPH regularized/VBN regression/NN and/CC classification/NN objectives/NNS ,/, such/JJ as/IN Lasso/NNP ,/, sparse/JJ logistic/JJ regression/NN ,/, and/CC elastic/JJ net/JJ regression/NN ./.
We/PRP provide/VBP convergence/NN guarantees/NNS for/IN this/DT framework/NN and/CC demonstrate/VBP strong/JJ empirical/JJ performance/NN as/IN compared/VBN to/IN other/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS on/IN several/JJ real/JJ -/HYPH world/NN distributed/VBN datasets/NNS ./.
