What/WP is/VBZ happiness/NN for/IN reinforcement/NN learning/VBG agents/NNS ?/.
We/PRP seek/VBP a/DT formal/JJ definition/NN satisfying/VBG a/DT list/NN of/IN desiderata/NNS ./.
Our/PRP$ proposed/VBN definition/NN of/IN happiness/NN is/VBZ the/DT temporal/JJ difference/NN error/NN ,/, i.e./FW the/DT difference/NN between/IN the/DT value/NN of/IN the/DT obtained/VBN reward/NN and/CC observation/NN and/CC the/DT agent/NN 's/POS expectation/NN of/IN this/DT value/NN ./.
This/DT definition/NN satisfies/VBZ most/JJS of/IN our/PRP$ desiderata/NNS and/CC is/VBZ compatible/JJ with/IN empirical/JJ research/NN on/IN humans/NNS ./.
We/PRP state/VBP several/JJ implications/NNS and/CC discuss/VB examples/NNS ./.
