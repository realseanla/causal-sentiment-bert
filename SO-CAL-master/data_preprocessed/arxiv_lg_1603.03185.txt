We/PRP describe/VBP a/DT large/JJ vocabulary/NN speech/NN recognition/NN system/NN that/WDT is/VBZ accurate/JJ ,/, has/VBZ low/JJ latency/NN ,/, and/CC yet/RB has/VBZ a/DT small/JJ enough/JJ memory/NN and/CC computational/JJ footprint/NN to/TO run/VB faster/JJR than/IN real/JJ -/HYPH time/NN on/IN a/DT Nexus/NN 5/CD Android/NN smartphone/NN ./.
We/PRP employ/VBP a/DT quantized/VBN Long/JJ Short/JJ -/HYPH Term/NN Memory/NN (/-LRB- LSTM/NN )/-RRB- acoustic/JJ model/NN trained/VBN with/IN connectionist/JJ temporal/JJ classification/NN (/-LRB- CTC/NN )/-RRB- to/TO directly/RB predict/VB phoneme/NN targets/NNS ,/, and/CC further/JJ reduce/VB its/PRP$ memory/NN footprint/NN using/VBG an/DT SVD/NN -/HYPH based/VBN compression/NN scheme/NN ./.
Additionally/RB ,/, we/PRP minimize/VBP our/PRP$ memory/NN footprint/NN by/IN using/VBG a/DT single/JJ language/NN model/NN for/IN both/DT dictation/NN and/CC voice/NN command/NN domains/NNS ,/, constructed/VBN using/VBG Bayesian/JJ interpolation/NN ./.
Finally/RB ,/, in/IN order/NN to/TO properly/RB handle/VB device/NN -/HYPH specific/JJ information/NN ,/, such/JJ as/IN proper/JJ names/NNS and/CC other/JJ context/NN -/HYPH dependent/JJ information/NN ,/, we/PRP inject/VBP vocabulary/NN items/NNS into/IN the/DT decoder/NN graph/NN and/CC bias/NN the/DT language/NN model/NN on/IN -/, the/DT -/HYPH fly/NN ./.
Our/PRP$ system/NN achieves/VBZ 13.5/CD \/SYM percent/NN word/NN error/NN rate/NN on/IN an/DT open/JJ -/HYPH ended/JJ dictation/NN task/NN ,/, running/VBG with/IN a/DT median/JJ speed/NN that/WDT is/VBZ seven/CD times/NNS faster/JJR than/IN real/JJ -/HYPH time/NN ./.
