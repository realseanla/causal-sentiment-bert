We/PRP present/VBP a/DT neural/JJ architecture/NN for/IN sequence/NN processing/NN ./.
The/DT ByteNet/NNP is/VBZ a/DT stack/NN of/IN two/CD dilated/VBN convolutional/JJ neural/JJ networks/NNS ,/, one/CD to/TO encode/VB the/DT source/NN sequence/NN and/CC one/CD to/IN decode/VB the/DT target/NN sequence/NN ,/, where/WRB the/DT target/NN network/NN unfolds/VBZ dynamically/RB to/TO generate/VB variable/JJ length/NN outputs/NNS ./.
The/DT ByteNet/NNP has/VBZ two/CD core/NN properties/NNS :/: it/PRP runs/VBZ in/IN time/NN that/WDT is/VBZ linear/JJ in/IN the/DT length/NN of/IN the/DT sequences/NNS and/CC it/PRP preserves/VBZ the/DT sequences/NNS '/POS temporal/JJ resolution/NN ./.
The/DT ByteNet/NNP decoder/NN attains/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN on/IN character/NN -/HYPH level/NN language/NN modelling/NN and/CC outperforms/VBZ the/DT previous/JJ best/JJS results/NNS obtained/VBN with/IN recurrent/JJ neural/JJ networks/NNS ./.
The/DT ByteNet/NNP also/RB achieves/VBZ a/DT performance/NN on/IN raw/JJ character/NN -/HYPH level/NN machine/NN translation/NN that/WDT approaches/VBZ that/IN of/IN the/DT best/JJS neural/JJ translation/NN models/NNS that/WDT run/VBP in/IN quadratic/JJ time/NN ./.
The/DT implicit/JJ structure/NN learnt/VBN by/IN the/DT ByteNet/NNP mirrors/NNS the/DT expected/VBN alignments/NNS between/IN the/DT sequences/NNS ./.
