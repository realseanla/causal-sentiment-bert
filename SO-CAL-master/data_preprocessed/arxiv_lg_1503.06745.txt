In/IN this/DT paper/NN ,/, we/PRP propose/VBP the/DT problem/NN of/IN online/JJ cost/NN -/HYPH sensitive/JJ clas/NN -/HYPH sifier/NN adaptation/NN and/CC the/DT first/JJ algorithm/NN to/TO solve/VB it/PRP ./.
We/PRP assume/VBP we/PRP have/VBP a/DT base/NN classifier/NN for/IN a/DT cost/NN -/HYPH sensitive/JJ classification/NN problem/NN ,/, but/CC it/PRP is/VBZ trained/VBN with/IN respect/NN to/IN a/DT cost/NN setting/VBG different/JJ to/IN the/DT desired/VBN one/CD ./.
Moreover/RB ,/, we/PRP also/RB have/VBP some/DT training/NN data/NNS samples/NNS streaming/VBG to/IN the/DT algorithm/NN one/CD by/IN one/CD ./.
The/DT prob/NN -/HYPH lem/NN is/VBZ to/TO adapt/VB the/DT given/VBN base/NN classifier/NN to/IN the/DT desired/VBN cost/NN setting/NN using/VBG the/DT steaming/VBG training/NN samples/NNS online/RB ./.
To/TO solve/VB this/DT problem/NN ,/, we/PRP propose/VBP to/TO learn/VB a/DT new/JJ classifier/NN by/IN adding/VBG an/DT adaptation/NN function/NN to/IN the/DT base/NN classifier/NN ,/, and/CC update/VB the/DT adaptation/NN function/NN parameter/NN according/VBG to/IN the/DT streaming/NN data/NN samples/NNS ./.
Given/VBN a/DT input/NN data/NNS sample/NN and/CC the/DT cost/NN of/IN misclassifying/VBG it/PRP ,/, we/PRP up/RB -/HYPH date/NN the/DT adaptation/NN function/NN parameter/NN by/IN minimizing/VBG cost/NN weighted/JJ hinge/NN loss/NN and/CC respecting/VBG previous/JJ learned/VBN parameter/NN simultaneously/RB ./.
The/DT proposed/VBN algorithm/NN is/VBZ compared/VBN to/IN both/DT online/JJ and/CC off/RB -/HYPH line/NN cost/NN -/HYPH sensitive/JJ algorithms/NNS on/IN two/CD cost/NN -/HYPH sensitive/JJ classification/NN problems/NNS ,/, and/CC the/DT experiments/NNS show/VBP that/IN it/PRP not/RB only/RB outperforms/VBZ them/PRP one/CD classification/NN performances/NNS ,/, but/CC also/RB requires/VBZ significantly/RB less/JJR running/NN time/NN ./.
