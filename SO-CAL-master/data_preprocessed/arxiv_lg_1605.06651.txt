In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT new/JJ sequential/JJ decision/NN making/VBG problem/NN called/VBN {/-LRB- \/SYM em/PRP gambler/NN 's/POS ruin/NN bandit/NN problem/NN }/-RRB- (/-LRB- GRBP/NN )/-RRB- ./.
In/IN each/DT round/NN of/IN the/DT GRBP/NNP the/DT learner/NN faces/VBZ a/DT gambler/NN 's/POS ruin/NN problem/NN with/IN two/CD possible/JJ actions/NNS :/: a/DT {/-LRB- \/SYM em/PRP continuation/NN action/NN }/-RRB- that/WDT moves/VBZ the/DT learner/NN randomly/RB over/IN the/DT state/NN space/NN around/IN the/DT current/JJ state/NN ;/: and/CC a/DT {/-LRB- \/SYM em/PRP terminal/JJ action/NN }/-RRB- that/WDT moves/VBZ the/DT learner/NN directly/RB into/IN one/CD of/IN the/DT two/CD terminal/JJ states/NNS (/-LRB- goal/NN and/CC dead/JJ -/HYPH end/NN state/NN )/-RRB- ./.
The/DT current/JJ round/NN ends/VBZ when/WRB a/DT terminal/JJ state/NN is/VBZ reached/VBN ./.
We/PRP first/RB formulate/VB GRBP/NNP as/IN an/DT optimization/NN problem/NN ,/, and/CC prove/VB that/IN the/DT optimal/JJ policy/NN is/VBZ characterized/VBN by/IN a/DT simple/JJ threshold/NN rule/NN ./.
The/DT problem/NN is/VBZ solved/VBN for/IN infinite/JJ time/NN budget/NN ./.
Then/RB ,/, we/PRP consider/VBP the/DT case/NN when/WRB the/DT state/NN transition/NN probabilities/NNS are/VBP unknown/JJ and/CC provide/VB logarithmic/JJ problem/NN specific/JJ regret/NN bounds/NNS ./.
We/PRP also/RB identify/VBP a/DT condition/NN under/IN which/WDT the/DT learner/NN only/RB incurs/VBZ finite/JJ regret/NN ./.
Numerous/JJ applications/NNS including/VBG optimal/JJ medical/JJ treatment/NN assignment/NN can/MD be/VB formulated/VBN as/IN a/DT GRBP/NN ,/, in/IN which/WDT the/DT continuation/NN action/NN corresponds/VBZ to/IN the/DT conservative/JJ treatment/NN and/CC the/DT terminal/JJ action/NN corresponds/VBZ to/IN the/DT surgery/NN ./.
