In/IN this/DT paper/NN ,/, we/PRP present/VBP a/DT time/NN -/HYPH contrastive/JJ learning/NN (/-LRB- TCL/NNP )/-RRB- based/VBN unsupervised/JJ bottleneck/NN (/-LRB- BN/NN )/-RRB- feature/NN extraction/NN method/NN for/IN speech/NN signals/NNS with/IN an/DT application/NN to/IN speaker/NN verification/NN ./.
The/DT method/NN exploits/VBZ the/DT temporal/JJ structure/NN of/IN a/DT speech/NN signal/NN and/CC more/RBR specifically/RB ,/, it/PRP trains/VBZ deep/JJ neural/JJ networks/NNS (/-LRB- DNNs/NNS )/-RRB- to/TO discriminate/VB temporal/JJ events/NNS obtained/VBN by/IN uniformly/RB segmenting/VBG the/DT signal/NN without/IN using/VBG any/DT label/NN information/NN ,/, in/IN contrast/NN to/IN conventional/JJ DNN/NN based/VBN BN/NNP feature/NN extraction/NN methods/NNS that/WDT train/VBP DNNs/NNS using/VBG labeled/VBN data/NNS to/TO discriminate/VB speakers/NNS or/CC passphrases/NNS or/CC phones/NNS or/CC a/DT combination/NN of/IN them/PRP ./.
We/PRP consider/VBP different/JJ strategies/NNS for/IN TCL/NNP and/CC its/PRP$ combination/NN with/IN transfer/NN learning/NN ./.
Experimental/JJ results/NNS on/IN the/DT RSR2015/NN database/NN show/VBP that/IN the/DT TCL/NNP method/NN is/VBZ superior/JJ to/IN the/DT conventional/JJ speaker/NN and/CC pass/VB -/HYPH phrase/NN discriminant/JJ BN/NN feature/NN and/CC Mel/NNP -/HYPH frequency/NN cepstral/JJ coefficients/NNS (/-LRB- MFCCs/NNS )/-RRB- feature/NN for/IN text/NN -/HYPH dependent/JJ speaker/NN verification/NN ./.
The/DT unsupervised/JJ TCL/NNP method/NN further/RB has/VBZ the/DT advantage/NN of/IN being/VBG able/JJ to/TO leverage/VB the/DT huge/JJ amount/NN of/IN unlabeled/JJ data/NNS that/WDT are/VBP often/RB available/JJ in/IN real/JJ life/NN ./.
