In/IN many/JJ real/JJ -/HYPH world/NN scenarios/NNS ,/, rewards/NNS extrinsic/JJ to/IN the/DT agent/NN are/VBP extremely/RB sparse/JJ ,/, or/CC absent/JJ altogether/RB ./.
In/IN such/JJ cases/NNS ,/, curiosity/NN can/MD serve/VB as/IN an/DT intrinsic/JJ reward/NN signal/NN to/TO enable/VB the/DT agent/NN to/TO explore/VB its/PRP$ environment/NN and/CC learn/VB skills/NNS that/WDT might/MD be/VB useful/JJ later/RB in/IN its/PRP$ life/NN ./.
We/PRP formulate/VBP curiosity/NN as/IN the/DT error/NN in/IN an/DT agent/NN 's/POS ability/NN to/TO predict/VB the/DT consequence/NN of/IN its/PRP$ own/JJ actions/NNS in/IN a/DT visual/JJ feature/NN space/NN learned/VBN by/IN a/DT self/NN -/HYPH supervised/JJ inverse/JJ dynamics/NNS model/NN ./.
Our/PRP$ formulation/NN scales/NNS to/IN high/JJ -/HYPH dimensional/JJ continuous/JJ state/NN spaces/NNS like/IN images/NNS ,/, bypasses/VBZ the/DT difficulties/NNS of/IN directly/RB predicting/VBG pixels/NNS ,/, and/CC ,/, critically/RB ,/, ignores/VBZ the/DT aspects/NNS of/IN the/DT environment/NN that/WDT can/MD not/RB affect/VB the/DT agent/NN ./.
The/DT proposed/VBN approach/NN is/VBZ evaluated/VBN in/IN two/CD environments/NNS :/: VizDoom/NNP and/CC Super/NNP Mario/NNP Bros/NNP ./.
Three/CD broad/JJ settings/NNS are/VBP investigated/VBN :/: 1/LS )/-RRB- sparse/JJ extrinsic/JJ reward/NN ,/, where/WRB curiosity/NN allows/VBZ for/IN far/RB fewer/JJR interactions/NNS with/IN the/DT environment/NN to/TO reach/VB the/DT goal/NN ;/: 2/LS )/-RRB- exploration/NN with/IN no/DT extrinsic/JJ reward/NN ,/, where/WRB curiosity/NN pushes/VBZ the/DT agent/NN to/TO explore/VB more/RBR efficiently/RB ;/: and/CC 3/LS )/-RRB- generalization/NN to/IN unseen/JJ scenarios/NNS (/-LRB- e.g./FW new/JJ levels/NNS of/IN the/DT same/JJ game/NN )/-RRB- where/WRB the/DT knowledge/NN gained/VBD from/IN earlier/JJR experience/NN helps/VBZ the/DT agent/NN explore/VB new/JJ places/NNS much/JJ faster/JJR than/IN starting/VBG from/IN scratch/NN ./.
Demo/JJ video/NN and/CC code/NN available/JJ at/IN
