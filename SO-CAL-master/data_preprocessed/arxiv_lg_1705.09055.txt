We/PRP study/VBP the/DT problem/NN of/IN learning/VBG classifiers/NNS with/IN a/DT fairness/NN constraint/NN ,/, with/IN three/CD main/JJ contributions/NNS towards/IN the/DT goal/NN of/IN quantifying/VBG the/DT problem/NN 's/POS inherent/JJ tradeoffs/NNS ./.
First/RB ,/, we/PRP relate/VBP two/CD existing/VBG fairness/NN measures/NNS to/TO cost/VB -/: sensitive/JJ risks/NNS ./.
Second/RB ,/, we/PRP show/VBP that/IN for/IN cost/NN -/HYPH sensitive/JJ classification/NN and/CC fairness/NN measures/NNS ,/, the/DT optimal/JJ classifier/NN is/VBZ an/DT instance/NN -/HYPH dependent/JJ thresholding/NN of/IN the/DT class/NN -/HYPH probability/NN function/NN ./.
Third/JJ ,/, we/PRP show/VBP how/WRB the/DT tradeoff/NN between/IN accuracy/NN and/CC fairness/NN is/VBZ determined/VBN by/IN the/DT alignment/NN between/IN the/DT class/NN -/HYPH probabilities/NNS for/IN the/DT target/NN and/CC sensitive/JJ features/NNS ./.
Underpinning/VBG our/PRP$ analysis/NN is/VBZ a/DT general/JJ framework/NN that/WDT casts/VBZ the/DT problem/NN of/IN learning/VBG with/IN a/DT fairness/NN requirement/NN as/IN one/CD of/IN minimising/VBG the/DT difference/NN of/IN two/CD statistical/JJ risks/NNS ./.
