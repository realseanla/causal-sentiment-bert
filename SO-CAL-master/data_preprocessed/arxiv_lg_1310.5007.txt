We/PRP propose/VBP a/DT voted/VBN dual/JJ averaging/NN method/NN for/IN online/JJ classification/NN problems/NNS with/IN explicit/JJ regularization/NN ./.
This/DT method/NN employs/VBZ the/DT update/NN rule/NN of/IN the/DT regularized/VBN dual/JJ averaging/NN (/-LRB- RDA/NN )/-RRB- method/NN ,/, but/CC only/RB on/IN the/DT subsequence/NN of/IN training/NN examples/NNS where/WRB a/DT classification/NN error/NN is/VBZ made/VBN ./.
We/PRP derive/VBP a/DT bound/VBN on/IN the/DT number/NN of/IN mistakes/NNS made/VBN by/IN this/DT method/NN on/IN the/DT training/NN set/NN ,/, as/RB well/RB as/IN its/PRP$ generalization/NN error/NN rate/NN ./.
We/PRP also/RB introduce/VBP the/DT concept/NN of/IN relative/JJ strength/NN of/IN regularization/NN ,/, and/CC show/VB how/WRB it/PRP affects/VBZ the/DT mistake/NN bound/VBN and/CC generalization/NN performance/NN ./.
We/PRP experimented/VBD with/IN the/DT method/NN using/VBG $/$ \/CD ell_1/CD $/$ regularization/CD on/IN a/DT large/JJ -/HYPH scale/NN natural/JJ language/NN processing/NN task/NN ,/, and/CC obtained/VBN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN classification/NN performance/NN with/IN fairly/RB sparse/JJ models/NNS ./.
