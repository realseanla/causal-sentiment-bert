Agent/NNP modelling/NN involves/VBZ considering/VBG how/WRB other/JJ agents/NNS will/MD behave/VB ,/, in/IN order/NN to/TO influence/VB your/PRP$ own/JJ actions/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP explore/VBP the/DT use/NN of/IN agent/NN modelling/NN in/IN the/DT hidden/JJ -/HYPH information/NN ,/, collaborative/JJ card/NN game/NN Hanabi/NNP ./.
We/PRP implement/VBP a/DT number/NN of/IN rule/NN -/HYPH based/VBN agents/NNS ,/, both/CC from/IN the/DT literature/NN and/CC of/IN our/PRP$ own/JJ devising/VBG ,/, in/IN addition/NN to/IN an/DT Information/NN Set/VBN Monte/NNP Carlo/NNP Tree/NNP Search/NNP (/-LRB- IS/NNP -/HYPH MCTS/NNP )/-RRB- agent/NN ./.
We/PRP observe/VBP poor/JJ results/NNS from/IN IS/NN -/HYPH MCTS/NN ,/, so/RB construct/VB a/DT new/JJ ,/, predictor/NN version/NN that/WDT uses/VBZ a/DT model/NN of/IN the/DT agents/NNS with/IN which/WDT it/PRP is/VBZ paired/VBN ./.
We/PRP observe/VBP a/DT significant/JJ improvement/NN in/IN game/NN -/HYPH playing/VBG strength/NN from/IN this/DT agent/NN in/IN comparison/NN to/IN IS/NN -/HYPH MCTS/NN ,/, resulting/VBG from/IN its/PRP$ consideration/NN of/IN what/WP the/DT other/JJ agents/NNS in/IN a/DT game/NN would/MD do/VB ./.
In/IN addition/NN ,/, we/PRP create/VBP a/DT flawed/JJ rule/NN -/HYPH based/VBN agent/NN to/TO highlight/VB the/DT predictor/NN 's/POS capabilities/NNS with/IN such/PDT an/DT agent/NN ./.
