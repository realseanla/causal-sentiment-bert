Support/NN vector/NN machines/NNS (/-LRB- SVM/NN )/-RRB- can/MD classify/VB data/NNS sets/NNS along/IN highly/RB non-linear/JJ decision/NN boundaries/NNS because/IN of/IN the/DT kernel/NN -/HYPH trick/NN ./.
This/DT expressiveness/NN comes/VBZ at/IN a/DT price/NN :/: During/IN test/NN -/HYPH time/NN ,/, the/DT SVM/NNP classifier/NN needs/VBZ to/TO compute/VB the/DT kernel/NN inner/JJ -/HYPH product/NN between/IN a/DT test/NN sample/NN and/CC all/DT support/NN vectors/NNS ./.
With/IN large/JJ training/NN data/NNS sets/NNS ,/, the/DT time/NN required/VBN for/IN this/DT computation/NN can/MD be/VB substantial/JJ ./.
In/IN this/DT paper/NN ,/, we/PRP introduce/VBP a/DT post-processing/JJ algorithm/NN ,/, which/WDT compresses/VBZ the/DT learned/VBN SVM/NN model/NN by/IN reducing/VBG and/CC optimizing/VBG support/NN vectors/NNS ./.
We/PRP evaluate/VBP our/PRP$ algorithm/NN on/IN several/JJ medium/NN -/HYPH scaled/VBN real/JJ -/HYPH world/NN data/NN sets/NNS ,/, demonstrating/VBG that/IN it/PRP maintains/VBZ high/JJ test/NN accuracy/NN while/IN reducing/VBG the/DT test/NN -/HYPH time/NN evaluation/NN cost/NN by/IN several/JJ orders/NNS of/IN magnitude/NN ---/, in/IN some/DT cases/NNS from/IN hours/NNS to/IN seconds/NNS ./.
It/PRP is/VBZ fair/JJ to/TO say/VB that/IN most/JJS of/IN the/DT work/NN in/IN this/DT paper/NN was/VBD previously/RB been/VBN invented/VBN by/IN Burges/NNP and/CC Sch/NNP \/SYM "/`` olkopf/JJ almost/RB 20/CD years/NNS ago/RB ./.
For/IN most/JJS of/IN the/DT time/NN during/IN which/WDT we/PRP conducted/VBD this/DT research/NN ,/, we/PRP were/VBD unaware/JJ of/IN this/DT prior/JJ work/NN ./.
However/RB ,/, in/IN the/DT past/JJ two/CD decades/NNS ,/, computing/VBG power/NN has/VBZ increased/VBN drastically/RB ,/, and/CC we/PRP can/MD therefore/RB provide/VB empirical/JJ insights/NNS that/WDT were/VBD not/RB possible/JJ in/IN their/PRP$ original/JJ paper/NN ./.
