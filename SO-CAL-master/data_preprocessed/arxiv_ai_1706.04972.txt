The/DT past/JJ few/JJ years/NNS have/VBP witnessed/VBN a/DT growth/NN in/IN size/NN and/CC computational/JJ requirements/NNS for/IN training/NN and/CC inference/NN with/IN neural/JJ networks/NNS ./.
Currently/RB ,/, a/DT common/JJ approach/NN to/TO address/VB these/DT requirements/NNS is/VBZ to/TO use/VB a/DT heterogeneous/JJ distributed/VBN environment/NN with/IN a/DT mixture/NN of/IN hardware/NN devices/NNS such/JJ as/IN CPUs/NNS and/CC GPUs/NNS ./.
Importantly/RB ,/, the/DT decision/NN of/IN placing/VBG parts/NNS of/IN the/DT neural/JJ models/NNS on/IN devices/NNS is/VBZ often/RB made/VBN by/IN human/JJ experts/NNS based/VBN on/IN simple/JJ heuristics/NNS and/CC intuitions/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT method/NN which/WDT learns/VBZ to/TO optimize/VB device/NN placement/NN for/IN TensorFlow/NNP computational/JJ graphs/NNS ./.
Key/JJ to/IN our/PRP$ method/NN is/VBZ the/DT use/NN of/IN a/DT sequence/NN -/HYPH to/IN -/HYPH sequence/NN model/NN to/TO predict/VB which/WDT subsets/NNS of/IN operations/NNS in/IN a/DT TensorFlow/NNP graph/NN should/MD run/VB on/IN which/WDT of/IN the/DT available/JJ devices/NNS ./.
The/DT execution/NN time/NN of/IN the/DT predicted/VBN placements/NNS is/VBZ then/RB used/VBN as/IN the/DT reward/NN signal/NN to/TO optimize/VB the/DT parameters/NNS of/IN the/DT sequence/NN -/HYPH to/IN -/HYPH sequence/NN model/NN ./.
Our/PRP$ main/JJ result/NN is/VBZ that/IN on/IN Inception/NN -/HYPH V3/NN for/IN ImageNet/NNP classification/NN ,/, and/CC on/IN RNN/NNP LSTM/NNP ,/, for/IN language/NN modeling/NN and/CC neural/JJ machine/NN translation/NN ,/, our/PRP$ model/NN finds/VBZ non-trivial/JJ device/NN placements/NNS that/WDT outperform/VBP hand/NN -/HYPH crafted/VBN heuristics/NNS and/CC traditional/JJ algorithmic/JJ methods/NNS ./.
