The/DT reading/NN comprehension/NN task/NN ,/, that/DT asks/VBZ questions/NNS about/IN a/DT given/VBN evidence/NN document/NN ,/, is/VBZ a/DT central/JJ problem/NN in/IN natural/JJ language/NN understanding/NN ./.
Recent/JJ formulations/NNS of/IN this/DT task/NN have/VBP typically/RB focused/VBN on/IN answer/NN selection/NN from/IN a/DT set/NN of/IN candidates/NNS pre-defined/JJ manually/RB or/CC through/IN the/DT use/NN of/IN an/DT external/JJ NLP/NN pipeline/NN ./.
However/RB ,/, Rajpurkar/NNP et/FW al./FW (/-LRB- 2016/CD )/-RRB- recently/RB released/VBD the/DT SQuAD/NN dataset/NN in/IN which/WDT the/DT answers/NNS can/MD be/VB arbitrary/JJ strings/NNS from/IN the/DT supplied/VBN text/NN ./.
In/IN this/DT paper/NN ,/, we/PRP focus/VBP on/IN this/DT answer/NN extraction/NN task/NN ,/, presenting/VBG a/DT novel/JJ model/NN architecture/NN that/WDT efficiently/RB builds/VBZ fixed/VBN length/NN representations/NNS of/IN all/DT spans/NNS in/IN the/DT evidence/NN document/NN with/IN a/DT recurrent/JJ network/NN ./.
We/PRP show/VBP that/IN scoring/VBG explicit/JJ span/NN representations/NNS significantly/RB improves/VBZ performance/NN over/IN other/JJ approaches/NNS that/WDT factor/VBP the/DT prediction/NN into/IN separate/JJ predictions/NNS about/IN words/NNS or/CC start/VB and/CC end/VB markers/NNS ./.
Our/PRP$ approach/NN improves/VBZ upon/IN the/DT best/JJS published/VBN results/NNS of/IN Wang/NNP &amp;/CC Jiang/NNP (/-LRB- 2016/CD )/-RRB- by/IN 5/CD percent/NN and/CC decreases/VBZ the/DT error/NN of/IN Rajpurkar/NNP et/FW al./FW 's/POS baseline/NN by/IN &gt;/SYM 50/CD percent/NN ./.
