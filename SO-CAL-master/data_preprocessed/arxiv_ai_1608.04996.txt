Planning/VBG plays/VBZ an/DT important/JJ role/NN in/IN the/DT broad/JJ class/NN of/IN decision/NN theory/NN ./.
Planning/NN has/VBZ drawn/VBN much/JJ attention/NN in/IN recent/JJ work/NN in/IN the/DT robotics/NNS and/CC sequential/JJ decision/NN making/VBG areas/NNS ./.
Recently/RB ,/, Reinforcement/NN Learning/NN (/-LRB- RL/NN )/-RRB- ,/, as/IN an/DT agent/NN -/HYPH environment/NN interaction/NN problem/NN ,/, has/VBZ brought/VBN further/JJ attention/NN to/IN planning/NN methods/NNS ./.
Generally/RB in/IN RL/NNP ,/, one/PRP can/MD assume/VB a/DT generative/JJ model/NN ,/, e.g./FW graphical/NN models/NNS ,/, for/IN the/DT environment/NN ,/, and/CC then/RB the/DT task/NN for/IN the/DT RL/NNP agent/NN is/VBZ to/TO learn/VB the/DT model/NN parameters/NNS and/CC find/VB the/DT optimal/JJ strategy/NN based/VBN on/IN these/DT learnt/VBN parameters/NNS ./.
Based/VBN on/IN environment/NN behavior/NN ,/, the/DT agent/NN can/MD assume/VB various/JJ types/NNS of/IN generative/JJ models/NNS ,/, e.g./FW Multi/FW Armed/JJ Bandit/NN for/IN a/DT static/JJ environment/NN ,/, or/CC Markov/NNP Decision/NN Process/NN (/-LRB- MDP/NN )/-RRB- for/IN a/DT dynamic/JJ environment/NN ./.
The/DT advantage/NN of/IN these/DT popular/JJ models/NNS is/VBZ their/PRP$ simplicity/NN ,/, which/WDT results/VBZ in/IN tractable/JJ methods/NNS of/IN learning/VBG the/DT parameters/NNS and/CC finding/VBG the/DT optimal/JJ policy/NN ./.
The/DT drawback/NN of/IN these/DT models/NNS is/VBZ again/RB their/PRP$ simplicity/NN :/: these/DT models/NNS usually/RB underfit/VBP and/CC underestimate/VBP the/DT actual/JJ environment/NN behavior/NN ./.
For/IN example/NN ,/, in/IN robotics/NNS ,/, the/DT agent/NN usually/RB has/VBZ noisy/JJ observations/NNS of/IN the/DT environment/NN inner/JJ state/NN and/CC MDP/NN is/VBZ not/RB a/DT suitable/JJ model/NN ./.
