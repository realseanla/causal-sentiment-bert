In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT new/JJ deep/JJ learning/NN approach/NN ,/, called/VBN neural/JJ association/NN model/NN (/-LRB- NAM/NN )/-RRB- ,/, for/IN probabilistic/JJ reasoning/NN in/IN artificial/JJ intelligence/NN ./.
We/PRP propose/VBP to/TO use/VB neural/JJ networks/NNS to/TO model/VB association/NN between/IN any/DT two/CD events/NNS in/IN a/DT domain/NN ./.
Neural/JJ networks/NNS take/VBP one/CD event/NN as/IN input/NN and/CC compute/VB a/DT conditional/JJ probability/NN of/IN the/DT other/JJ event/NN to/TO model/VB how/WRB likely/JJ these/DT two/CD events/NNS are/VBP associated/VBN ./.
The/DT actual/JJ meaning/NN of/IN the/DT conditional/JJ probabilities/NNS varies/VBZ between/IN applications/NNS and/CC depends/VBZ on/IN how/WRB the/DT models/NNS are/VBP trained/VBN ./.
In/IN this/DT work/NN ,/, as/IN two/CD case/NN studies/NNS ,/, we/PRP have/VBP investigated/VBN two/CD NAM/NNP structures/NNS ,/, namely/RB deep/JJ neural/JJ networks/NNS (/-LRB- DNNs/NNS )/-RRB- and/CC relation/NN modulated/VBN neural/JJ nets/NNS (/-LRB- RMNNs/NNS )/-RRB- ,/, on/IN several/JJ probabilistic/JJ reasoning/NN tasks/NNS in/IN AI/NN ,/, including/VBG recognizing/VBG textual/JJ entailment/NN ,/, triple/JJ classification/NN in/IN multirelational/JJ knowledge/NN bases/NNS and/CC common/JJ -/HYPH sense/NN reasoning/NN ./.
Experimental/JJ results/NNS on/IN several/JJ popular/JJ data/NNS sets/NNS derived/VBN from/IN WordNet/NNP ,/, FreeBase/NNP and/CC ConceptNet/NNP have/VBP all/DT demonstrated/VBD that/IN both/DT DNNs/NNS and/CC RMNNs/NNS perform/VBP equally/RB well/RB and/CC they/PRP can/MD significantly/RB outperform/VB the/DT conventional/JJ methods/NNS available/JJ for/IN these/DT reasoning/NN tasks/NNS ./.
Moreover/RB ,/, comparing/VBG with/IN DNNs/NNS ,/, RMNNs/NNS are/VBP superior/JJ in/IN knowledge/NN transfer/NN ,/, where/WRB a/DT pre-trained/JJ model/NN can/MD be/VB quickly/RB extended/VBN to/IN an/DT unseen/JJ relation/NN after/IN observing/VBG only/RB a/DT few/JJ training/NN samples/NNS ./.
