In/IN this/DT paper/NN we/PRP propose/VBP a/DT new/JJ method/NN for/IN regularizing/VBG autoencoders/NNS by/IN imposing/VBG an/DT arbitrary/JJ prior/JJ on/IN the/DT latent/JJ representation/NN of/IN the/DT autoencoder/NN ./.
Our/PRP$ method/NN ,/, named/VBN "/`` adversarial/JJ autoencoder/NN "/'' ,/, uses/VBZ the/DT recently/RB proposed/VBN generative/JJ adversarial/JJ networks/NNS (/-LRB- GAN/NNP )/-RRB- in/IN order/NN to/TO match/VB the/DT aggregated/VBN posterior/NN of/IN the/DT hidden/JJ code/NN vector/NN of/IN the/DT autoencoder/NN with/IN an/DT arbitrary/JJ prior/JJ ./.
Matching/VBG the/DT aggregated/VBN posterior/JJ to/IN the/DT prior/JJ ensures/VBZ that/IN there/EX are/VBP no/DT "/`` holes/NNS "/'' in/IN the/DT prior/JJ ,/, and/CC generating/VBG from/IN any/DT part/NN of/IN prior/JJ space/NN results/NNS in/IN meaningful/JJ samples/NNS ./.
As/IN a/DT result/NN ,/, the/DT decoder/NN of/IN the/DT adversarial/JJ autoencoder/NN learns/VBZ a/DT deep/JJ generative/NN model/NN that/WDT maps/VBZ the/DT imposed/VBN prior/JJ to/IN the/DT data/NNS distribution/NN ./.
We/PRP show/VBP how/WRB adversarial/JJ autoencoders/NNS can/MD be/VB used/VBN to/TO disentangle/VB style/NN and/CC content/NN of/IN images/NNS and/CC achieve/VB competitive/JJ generative/JJ performance/NN on/IN MNIST/NNP ,/, Street/NNP View/NNP House/NNP Numbers/NNS and/CC Toronto/NNP Face/NNP datasets/NNS ./.
