We/PRP introduce/VBP Parseval/NNP networks/NNS ,/, a/DT form/NN of/IN deep/JJ neural/JJ networks/NNS in/IN which/WDT the/DT Lipschitz/NNP constant/NN of/IN linear/JJ ,/, convolutional/JJ and/CC aggregation/NN layers/NNS is/VBZ constrained/VBN to/TO be/VB smaller/JJR than/IN 1/CD ./.
Parseval/JJ networks/NNS are/VBP empirically/RB and/CC theoretically/RB motivated/VBN by/IN an/DT analysis/NN of/IN the/DT robustness/NN of/IN the/DT predictions/NNS made/VBN by/IN deep/JJ neural/JJ networks/NNS when/WRB their/PRP$ input/NN is/VBZ subject/JJ to/IN an/DT adversarial/JJ perturbation/NN ./.
The/DT most/RBS important/JJ feature/NN of/IN Parseval/NNP networks/NNS is/VBZ to/TO maintain/VB weight/NN matrices/NNS of/IN linear/JJ and/CC convolutional/JJ layers/NNS to/TO be/VB (/-LRB- approximately/RB )/-RRB- Parseval/NN tight/JJ frames/NNS ,/, which/WDT are/VBP extensions/NNS of/IN orthogonal/JJ matrices/NNS to/IN non-square/JJ matrices/NNS ./.
We/PRP describe/VBP how/WRB these/DT constraints/NNS can/MD be/VB maintained/VBN efficiently/RB during/IN SGD/NNP ./.
We/PRP show/VBP that/IN Parseval/NNP networks/NNS match/VBP the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN in/IN terms/NNS of/IN accuracy/NN on/IN CIFAR/NNP -/HYPH 10/100/CD and/CC Street/NNP View/NNP House/NNP Numbers/NNS (/-LRB- SVHN/NNP )/-RRB- while/IN being/VBG more/RBR robust/JJ than/IN their/PRP$ vanilla/NN counterpart/NN against/IN adversarial/JJ examples/NNS ./.
Incidentally/RB ,/, Parseval/NNP networks/NNS also/RB tend/VBP to/TO train/VB faster/RBR and/CC make/VB a/DT better/JJR usage/NN of/IN the/DT full/JJ capacity/NN of/IN the/DT networks/NNS ./.
