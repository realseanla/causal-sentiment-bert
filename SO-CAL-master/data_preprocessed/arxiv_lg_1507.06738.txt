We/PRP consider/VBP the/DT linear/JJ contextual/JJ bandit/NN problem/NN with/IN global/JJ convex/NN constraints/NNS and/CC a/DT concave/JJ objective/NN function/NN ./.
In/IN each/DT round/NN ,/, the/DT outcome/NN of/IN pulling/VBG an/DT arm/NN is/VBZ a/DT vector/NN ,/, that/IN depends/VBZ linearly/RB on/IN the/DT context/NN of/IN that/DT arm/NN ./.
The/DT global/JJ constraints/NNS require/VBP the/DT average/NN of/IN these/DT vectors/NNS to/TO lie/VB in/IN a/DT certain/JJ convex/NN set/NN ./.
The/DT objective/NN is/VBZ a/DT concave/NN function/NN of/IN this/DT average/NN vector/NN ./.
This/DT problem/NN turns/VBZ out/RP to/TO be/VB a/DT common/JJ generalization/NN of/IN classic/JJ linear/JJ contextual/JJ bandits/NNS (/-LRB- linContextual/NN )/-RRB- [/-LRB- Auer/NNP 2003/CD ]/-RRB- ,/, bandits/NNS with/IN concave/JJ rewards/NNS and/CC convex/NN knapsacks/NNS (/-LRB- BwCR/NN )/-RRB- [/-LRB- Agrawal/NNP ,/, Devanur/NNP 2014/CD ]/-RRB- ,/, and/CC the/DT online/JJ stochastic/JJ convex/NN programming/NN (/-LRB- OSCP/NN )/-RRB- problem/NN [/-LRB- Agrawal/NNP ,/, Devanur/NNP 2015/CD ]/-RRB- ./.
We/PRP present/VBP algorithms/NNS with/IN near/JJ -/HYPH optimal/JJ regret/NN bounds/NNS for/IN this/DT problem/NN ./.
Our/PRP$ bounds/NNS compare/VBP favorably/RB to/IN results/NNS on/IN the/DT unstructured/JJ version/NN of/IN the/DT problem/NN [/-LRB- Agrawal/NNP et/FW al./FW 2015/CD ,/, Badanidiyuru/NNP et/FW al./FW 2014/CD ]/-RRB- where/WRB the/DT relation/NN between/IN the/DT contexts/NNS and/CC the/DT outcomes/NNS could/MD be/VB arbitrary/JJ ,/, but/CC the/DT algorithm/NN only/RB competes/VBZ against/IN a/DT fixed/VBN set/NN of/IN policies/NNS ./.
