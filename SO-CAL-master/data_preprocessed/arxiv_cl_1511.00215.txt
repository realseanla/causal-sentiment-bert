Bidirectional/JJ Long/JJ Short/JJ -/HYPH Term/NN Memory/NN Recurrent/JJ Neural/JJ Network/NN (/-LRB- BLSTM/NN -/HYPH RNN/NN )/-RRB- has/VBZ been/VBN shown/VBN to/TO be/VB very/RB effective/JJ for/IN modeling/NN and/CC predicting/VBG sequential/JJ data/NNS ,/, e.g./FW speech/NN utterances/NNS or/CC handwritten/JJ documents/NNS ./.
In/IN this/DT study/NN ,/, we/PRP propose/VBP to/TO use/VB BLSTM/NNP -/HYPH RNN/NNP for/IN a/DT unified/JJ tagging/NN solution/NN that/WDT can/MD be/VB applied/VBN to/IN various/JJ tagging/NN tasks/NNS including/VBG part/NN -/HYPH of/IN -/HYPH speech/NN tagging/NN ,/, chunking/VBG and/CC named/VBN entity/NN recognition/NN ./.
Instead/RB of/IN exploiting/VBG specific/JJ features/NNS carefully/RB optimized/VBN for/IN each/DT task/NN ,/, our/PRP$ solution/NN only/RB uses/VBZ one/CD set/NN of/IN task/NN -/HYPH independent/JJ features/NNS and/CC internal/JJ representations/NNS learnt/VBN from/IN unlabeled/JJ text/NN for/IN all/DT tasks.Requiring/VBG no/DT task/NN specific/JJ knowledge/NN or/CC sophisticated/JJ feature/NN engineering/NN ,/, our/PRP$ approach/NN gets/VBZ nearly/RB state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN in/IN all/PDT these/DT three/CD tagging/NN tasks/NNS ./.
