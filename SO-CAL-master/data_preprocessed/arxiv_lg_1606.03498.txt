We/PRP present/VBP a/DT variety/NN of/IN new/JJ architectural/JJ features/NNS and/CC training/NN procedures/NNS that/WDT we/PRP apply/VBP to/IN the/DT generative/JJ adversarial/JJ networks/NNS (/-LRB- GANs/NNS )/-RRB- framework/NN ./.
We/PRP focus/VBP on/IN two/CD applications/NNS of/IN GANs/NNS :/: semi-supervised/JJ learning/NN ,/, and/CC the/DT generation/NN of/IN images/NNS that/WDT humans/NNS find/VBP visually/RB realistic/JJ ./.
Unlike/IN most/JJS work/NN on/IN generative/JJ models/NNS ,/, our/PRP$ primary/JJ goal/NN is/VBZ not/RB to/TO train/VB a/DT model/NN that/WDT assigns/VBZ high/JJ likelihood/NN to/TO test/VB data/NNS ,/, nor/CC do/VBP we/PRP require/VBP the/DT model/NN to/TO be/VB able/JJ to/TO learn/VB well/RB without/IN using/VBG any/DT labels/NNS ./.
Using/VBG our/PRP$ new/JJ techniques/NNS ,/, we/PRP achieve/VBP state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS in/IN semi-supervised/JJ classification/NN on/IN MNIST/NNP ,/, CIFAR/NNP -/HYPH 10/CD and/CC SVHN/NNP ./.
The/DT generated/VBN images/NNS are/VBP of/IN high/JJ quality/NN as/IN confirmed/VBN by/IN a/DT visual/JJ Turing/NN test/NN :/: our/PRP$ model/NN generates/VBZ MNIST/NN samples/NNS that/WDT humans/NNS can/MD not/RB distinguish/VB from/IN real/JJ data/NNS ,/, and/CC CIFAR/NN -/HYPH 10/CD samples/NNS that/WDT yield/VBP a/DT human/JJ error/NN rate/NN of/IN 21.3/CD percent/NN ./.
We/PRP also/RB present/JJ ImageNet/NNP samples/NNS with/IN unprecedented/JJ resolution/NN and/CC show/VBP that/IN our/PRP$ methods/NNS enable/VBP the/DT model/NN to/TO learn/VB recognizable/JJ features/NNS of/IN ImageNet/NNP classes/NNS ./.
