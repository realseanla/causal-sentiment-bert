While/IN the/DT optimization/NN problem/NN behind/IN deep/JJ neural/JJ networks/NNS is/VBZ highly/RB non-convex/JJ ,/, it/PRP is/VBZ frequently/RB observed/VBN in/IN practice/NN that/WDT training/NN deep/JJ networks/NNS seems/VBZ possible/JJ without/IN getting/VBG stuck/JJ in/IN suboptimal/JJ points/NNS ./.
It/PRP has/VBZ been/VBN argued/VBN that/IN this/DT is/VBZ the/DT case/NN as/IN all/DT local/JJ minima/NN are/VBP close/JJ to/IN being/VBG globally/RB optimal/JJ ./.
We/PRP show/VBP that/IN this/DT is/VBZ (/-LRB- almost/RB )/-RRB- true/JJ ,/, in/IN fact/NN almost/RB all/DT local/JJ minima/NN are/VBP globally/RB optimal/JJ ,/, for/IN a/DT fully/RB connected/JJ network/NN with/IN squared/JJ loss/NN and/CC analytic/JJ activation/NN function/NN given/VBN that/IN the/DT number/NN of/IN hidden/VBN units/NNS of/IN one/CD layer/NN of/IN the/DT network/NN is/VBZ larger/JJR than/IN the/DT number/NN of/IN training/NN points/NNS and/CC the/DT network/NN structure/NN from/IN this/DT layer/NN on/IN is/VBZ pyramidal/JJ ./.
