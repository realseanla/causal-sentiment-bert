In/IN this/DT paper/NN we/PRP propose/VBP a/DT novel/JJ model/NN for/IN unconditional/JJ audio/JJ generation/NN based/VBN on/IN generating/VBG one/CD audio/JJ sample/NN at/IN a/DT time/NN ./.
We/PRP show/VBP that/IN our/PRP$ model/NN ,/, which/WDT profits/VBZ from/IN combining/VBG memory-less/JJ modules/NNS ,/, namely/RB autoregressive/JJ multilayer/JJ perceptrons/NNS ,/, and/CC stateful/JJ recurrent/JJ neural/JJ networks/NNS in/IN a/DT hierarchical/JJ structure/NN is/VBZ able/JJ to/TO capture/VB underlying/VBG sources/NNS of/IN variations/NNS in/IN the/DT temporal/JJ sequences/NNS over/IN very/RB long/JJ time/NN spans/NNS ,/, on/IN three/CD datasets/NNS of/IN different/JJ nature/NN ./.
Human/JJ evaluation/NN on/IN the/DT generated/VBN samples/NNS indicate/VBP that/IN our/PRP$ model/NN is/VBZ preferred/VBN over/IN competing/VBG models/NNS ./.
We/PRP also/RB show/VBP how/WRB each/DT component/NN of/IN the/DT model/NN contributes/VBZ to/IN the/DT exhibited/VBN performance/NN ./.
