In/IN this/DT paper/NN we/PRP propose/VBP a/DT simple/JJ yet/CC powerful/JJ method/NN for/IN learning/VBG representations/NNS in/IN supervised/JJ learning/NN scenarios/NNS where/WRB each/DT original/JJ input/NN datapoint/NN is/VBZ described/VBN by/IN a/DT set/NN of/IN vectors/NNS and/CC their/PRP$ associated/VBN outputs/NNS may/MD be/VB given/VBN by/IN soft/JJ labels/NNS indicating/VBG ,/, for/IN example/NN ,/, class/NN probabilities/NNS ./.
We/PRP represent/VBP an/DT input/NN datapoint/NN as/IN a/DT mixture/NN of/IN probabilities/NNS over/IN the/DT corresponding/VBG set/NN of/IN feature/NN vectors/NNS where/WRB each/DT probability/NN indicates/VBZ how/WRB likely/JJ each/DT vector/NN is/VBZ to/TO belong/VB to/IN an/DT unknown/JJ prototype/NN pattern/NN ./.
We/PRP propose/VBP a/DT probabilistic/JJ model/NN that/WDT parameterizes/VBZ these/DT prototype/NN patterns/NNS in/IN terms/NNS of/IN hidden/JJ variables/NNS and/CC therefore/RB it/PRP can/MD be/VB trained/VBN with/IN conventional/JJ approaches/NNS based/VBN on/IN likelihood/NN maximization/NN ./.
More/RBR importantly/RB ,/, both/CC the/DT model/NN parameters/NNS and/CC the/DT prototype/NN patterns/NNS can/MD be/VB learned/VBN from/IN data/NNS in/IN a/DT discriminative/JJ way/NN ./.
We/PRP show/VBP that/IN our/PRP$ model/NN can/MD be/VB seen/VBN as/IN a/DT probabilistic/JJ generalization/NN of/IN learning/NN vector/NN quantization/NN (/-LRB- LVQ/NN )/-RRB- ./.
We/PRP apply/VBP our/PRP$ method/NN to/IN the/DT problems/NNS of/IN shape/NN classification/NN ,/, hyperspectral/JJ imaging/NN classification/NN and/CC people/NNS 's/POS work/NN class/NN categorization/NN ,/, showing/VBG the/DT superior/JJ performance/NN of/IN our/PRP$ method/NN compared/VBN to/IN the/DT standard/JJ prototype/NN -/HYPH based/VBN classification/NN approach/NN and/CC other/JJ competitive/JJ benchmark/NN methods/NNS ./.
