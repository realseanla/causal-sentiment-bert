Although/IN traditionally/RB used/VBN in/IN the/DT machine/NN translation/NN field/NN ,/, the/DT encoder/NN -/HYPH decoder/NN framework/NN has/VBZ been/VBN recently/RB applied/VBN for/IN the/DT generation/NN of/IN video/NN and/CC image/NN descriptions/NNS ./.
The/DT combination/NN of/IN Convolutional/NNP and/CC Recurrent/JJ Neural/JJ Networks/NNS in/IN these/DT models/NNS has/VBZ proven/VBN to/TO outperform/VB the/DT previous/JJ state/NN of/IN the/DT art/NN ,/, obtaining/VBG more/RBR accurate/JJ video/NN descriptions/NNS ./.
In/IN this/DT work/NN we/PRP propose/VBP pushing/VBG further/RB this/DT model/NN by/IN introducing/VBG two/CD contributions/NNS into/IN the/DT encoding/VBG stage/NN ./.
First/RB ,/, producing/VBG richer/JJR image/NN representations/NNS by/IN combining/VBG object/NN and/CC location/NN information/NN from/IN Convolutional/JJ Neural/JJ Networks/NNS and/CC second/RB ,/, introducing/VBG Bidirectional/JJ Recurrent/JJ Neural/JJ Networks/NNS for/IN capturing/VBG both/DT forward/JJ and/CC backward/JJ temporal/JJ relationships/NNS in/IN the/DT input/NN frames/NNS ./.
