Having/VBG accurate/JJ ,/, detailed/JJ ,/, and/CC up/IN -/HYPH to/IN -/HYPH date/NN information/NN about/IN wildlife/NN location/NN and/CC behavior/NN across/IN broad/JJ geographic/JJ areas/NNS would/MD revolutionize/VB our/PRP$ ability/NN to/TO study/VB ,/, conserve/VBP ,/, and/CC manage/VB species/NNS and/CC ecosystems/NNS ./.
Currently/RB such/JJ data/NNS are/VBP mostly/RB gathered/VBN manually/RB at/IN great/JJ expense/NN ,/, and/CC thus/RB are/VBP sparsely/RB and/CC infrequently/RB collected/VBN ./.
Here/RB we/PRP investigate/VB the/DT ability/NN to/TO automatically/RB ,/, accurately/RB ,/, and/CC inexpensively/RB collect/VB such/JJ data/NNS from/IN motion/NN sensor/NN cameras/NNS ./.
These/DT camera/NN traps/NNS enable/VBP pictures/NNS of/IN wildlife/NN to/TO be/VB collected/VBN inexpensively/RB ,/, unobtrusively/RB ,/, and/CC at/IN high/JJ -/HYPH volume/NN ./.
However/RB ,/, identifying/VBG the/DT animals/NNS ,/, animal/NN attributes/NNS ,/, and/CC behaviors/NNS in/IN these/DT pictures/NNS remains/VBZ an/DT expensive/JJ ,/, time/NN -/HYPH consuming/VBG ,/, manual/JJ task/NN often/RB performed/VBN by/IN researchers/NNS ,/, hired/VBN technicians/NNS ,/, or/CC crowdsourced/VBN teams/NNS of/IN human/JJ volunteers/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP demonstrate/VBP that/IN such/JJ data/NNS can/MD be/VB automatically/RB extracted/VBN by/IN deep/JJ neural/JJ networks/NNS (/-LRB- aka/RB deep/JJ learning/NN )/-RRB- ,/, which/WDT is/VBZ a/DT cutting/NN -/HYPH edge/NN type/NN of/IN artificial/JJ intelligence/NN ./.
In/IN particular/JJ ,/, we/PRP use/VBP the/DT existing/VBG human/JJ -/HYPH labeled/VBN images/NNS from/IN the/DT Snapshot/NNP Serengeti/NNP dataset/NN to/TO train/VB deep/JJ convolutional/JJ neural/JJ networks/NNS for/IN identifying/VBG 48/CD species/NNS in/IN 3.2/CD million/CD images/NNS taken/VBN from/IN Tanzania/NNP 's/POS Serengeti/NNP National/NNP Park/NNP ./.
We/PRP train/VBP neural/JJ networks/NNS that/WDT automatically/RB identify/VBP animals/NNS with/IN over/IN 92/CD percent/NN accuracy/NN ./.
More/RBR importantly/RB ,/, we/PRP can/MD choose/VB to/TO have/VB our/PRP$ system/NN classify/VB only/RB the/DT images/NNS it/PRP is/VBZ highly/RB confident/JJ about/RB ,/, allowing/VBG valuable/JJ human/JJ time/NN to/TO be/VB focused/VBN only/RB on/IN challenging/JJ images/NNS ./.
In/IN this/DT case/NN ,/, our/PRP$ automatic/JJ animal/NN identification/NN system/NN saves/VBZ approximately/RB ~/SYM 8.3/CD years/NNS (/-LRB- at/IN 40/CD hours/NNS per/IN week/NN )/-RRB- of/IN human/JJ labeling/NN effort/NN (/-LRB- i.e./FW over/IN 17,000/CD hours/NNS )/-RRB- while/IN operating/VBG on/IN a/DT 3.2/CD -/HYPH million/CD -/HYPH image/NN dataset/NN at/IN the/DT same/JJ 96/CD percent/NN accuracy/NN level/NN of/IN crowdsourced/VBN teams/NNS of/IN human/JJ volunteers/NNS ./.
Those/DT efficiency/NN gains/NNS immediately/RB highlight/VBP the/DT importance/NN of/IN using/VBG deep/JJ neural/JJ networks/NNS to/IN automate/VB data/NNS extraction/NN from/IN camera/NN trap/NN images/NNS ./.
