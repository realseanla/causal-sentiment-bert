Recently/RB ,/, there/EX has/VBZ been/VBN much/JJ interest/NN in/IN spectral/JJ approaches/NNS to/IN learning/VBG manifolds/NNS ---/, so/RB -/HYPH called/VBN kernel/NN eigenmap/NN methods/NNS ./.
These/DT methods/NNS have/VBP had/VBN some/DT successes/NNS ,/, but/CC their/PRP$ applicability/NN is/VBZ limited/VBN because/IN they/PRP are/VBP not/RB robust/JJ to/IN noise/NN ./.
To/TO address/VB this/DT limitation/NN ,/, we/PRP look/VBP at/IN two/CD -/HYPH manifold/NN problems/NNS ,/, in/IN which/WDT we/PRP simultaneously/RB reconstruct/VBP two/CD related/JJ manifolds/NNS ,/, each/DT representing/VBG a/DT different/JJ view/NN of/IN the/DT same/JJ data/NNS ./.
By/IN solving/VBG these/DT interconnected/VBN learning/NN problems/NNS together/RB and/CC allowing/VBG information/NN to/IN flow/NN between/IN them/PRP ,/, two/CD -/HYPH manifold/NN algorithms/NNS are/VBP able/JJ to/TO succeed/VB where/WRB a/DT non-integrated/JJ approach/NN would/MD fail/VB :/: each/DT view/NN allows/VBZ us/PRP to/TO suppress/VB noise/NN in/IN the/DT other/JJ ,/, reducing/VBG bias/NN in/IN the/DT same/JJ way/NN that/WRB an/DT instrumental/JJ variable/JJ allows/VBZ us/PRP to/TO remove/VB bias/NN in/IN a/DT {/-LRB- linear/JJ }/-RRB- dimensionality/NN reduction/NN problem/NN ./.
We/PRP propose/VBP a/DT class/NN of/IN algorithms/NNS for/IN two/CD -/HYPH manifold/NN problems/NNS ,/, based/VBN on/IN spectral/JJ decomposition/NN of/IN cross-covariance/NN operators/NNS in/IN Hilbert/NNP space/NN ./.
Finally/RB ,/, we/PRP discuss/VBP situations/NNS where/WRB two/CD -/HYPH manifold/NN problems/NNS are/VBP useful/JJ ,/, and/CC demonstrate/VBP that/IN solving/VBG a/DT two/CD -/HYPH manifold/JJ problem/NN can/MD aid/VB in/IN learning/VBG a/DT nonlinear/JJ dynamical/JJ system/NN from/IN limited/JJ data/NNS ./.
