In/IN this/DT paper/NN ,/, we/PRP propose/VBP phraseNet/NNP ,/, a/DT neural/JJ machine/NN translator/NN with/IN a/DT phrase/NN memory/NN which/WDT stores/VBZ phrase/NN pairs/NNS in/IN symbolic/JJ form/NN ,/, mined/VBN from/IN corpus/NN or/CC specified/VBN by/IN human/JJ experts/NNS ./.
For/IN any/DT given/VBN source/NN sentence/NN ,/, phraseNet/NN scans/VBZ the/DT phrase/NN memory/NN to/TO determine/VB the/DT candidate/NN phrase/NN pairs/NNS and/CC integrates/VBZ tagging/VBG information/NN in/IN the/DT representation/NN of/IN source/NN sentence/NN accordingly/RB ./.
The/DT decoder/NN utilizes/VBZ a/DT mixture/NN of/IN word/NN -/HYPH generating/VBG component/NN and/CC phrase/NN -/HYPH generating/VBG component/NN ,/, with/IN a/DT specifically/RB designed/VBN strategy/NN to/TO generate/VB a/DT sequence/NN of/IN multiple/JJ words/NNS all/DT at/IN once/RB ./.
The/DT phraseNet/NN not/RB only/RB approaches/VBZ one/CD step/NN towards/IN incorporating/VBG external/JJ knowledge/NN into/IN neural/JJ machine/NN translation/NN ,/, but/CC also/RB makes/VBZ an/DT effort/NN to/TO extend/VB the/DT word/NN -/HYPH by/IN -/HYPH word/NN generation/NN mechanism/NN of/IN recurrent/JJ neural/JJ network/NN ./.
Our/PRP$ empirical/JJ study/NN on/IN Chinese/JJ -/HYPH to/IN -/HYPH English/NNP translation/NN shows/VBZ that/IN ,/, with/IN carefully/RB -/HYPH chosen/VBN phrase/NN table/NN in/IN memory/NN ,/, phraseNet/NN yields/NNS 3.45/CD BLEU/NN improvement/NN over/IN the/DT generic/JJ neural/JJ machine/NN translator/NN ./.
