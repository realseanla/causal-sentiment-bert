Learning/VBG probabilistic/JJ models/NNS over/IN strings/NNS is/VBZ an/DT important/JJ issue/NN for/IN many/JJ applications/NNS ./.
Spectral/JJ methods/NNS propose/VBP elegant/JJ solutions/NNS to/IN the/DT problem/NN of/IN inferring/VBG weighted/JJ automata/NN from/IN finite/JJ samples/NNS of/IN variable/JJ -/HYPH length/NN strings/NNS drawn/VBN from/IN an/DT unknown/JJ target/NN distribution/NN ./.
These/DT methods/NNS rely/VBP on/IN a/DT singular/JJ value/NN decomposition/NN of/IN a/DT matrix/NN $/$ H_S/CD $/$ ,/, called/VBD the/DT Hankel/NNP matrix/NN ,/, that/IN records/NNS the/DT frequencies/NNS of/IN (/-LRB- some/DT of/IN )/-RRB- the/DT observed/VBN strings/NNS ./.
The/DT accuracy/NN of/IN the/DT learned/VBN distribution/NN depends/VBZ both/DT on/IN the/DT quantity/NN of/IN information/NN embedded/VBN in/IN $/$ H_S/CD $/$ and/CC on/IN the/DT distance/NN between/IN $/$ H_S/CD $/$ and/CC its/PRP$ mean/JJ $/$ H_r/CD $/$ ./.
Existing/VBG concentration/NN bounds/NNS seem/VBP to/TO indicate/VB that/IN the/DT concentration/NN over/IN $/$ H_r/CD $/$ gets/VBZ looser/JJR with/IN the/DT size/NN of/IN $/$ H_r/CD $/$ ,/, suggesting/VBG to/TO make/VB a/DT trade/NN -/HYPH off/NN between/IN the/DT quantity/NN of/IN used/JJ information/NN and/CC the/DT size/NN of/IN $/$ H_r/CD $/$ ./.
We/PRP propose/VBP new/JJ dimension/NN -/HYPH free/JJ concentration/NN bounds/NNS for/IN several/JJ variants/NNS of/IN Hankel/NNP matrices/NNS ./.
Experiments/NNS demonstrate/VBP that/IN these/DT bounds/NNS are/VBP tight/JJ and/CC that/IN they/PRP significantly/RB improve/VBP existing/VBG bounds/NNS ./.
These/DT results/NNS suggest/VBP that/IN the/DT concentration/NN rate/NN of/IN the/DT Hankel/NNP matrix/NN around/IN its/PRP$ mean/NN does/VBZ not/RB constitute/VB an/DT argument/NN for/IN limiting/VBG its/PRP$ size/NN ./.
