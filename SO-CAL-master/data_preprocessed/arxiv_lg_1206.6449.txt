Bayesian/JJ reinforcement/NN learning/NN (/-LRB- BRL/NN )/-RRB- encodes/VBZ prior/JJ knowledge/NN of/IN the/DT world/NN in/IN a/DT model/NN and/CC represents/VBZ uncertainty/NN in/IN model/NN parameters/NNS by/IN maintaining/VBG a/DT probability/NN distribution/NN over/IN them/PRP ./.
This/DT paper/NN presents/VBZ Monte/NNP Carlo/NNP BRL/NNP (/-LRB- MC/NNP -/HYPH BRL/NNP )/-RRB- ,/, a/DT simple/JJ and/CC general/JJ approach/NN to/IN BRL/NN ./.
MC/NNP -/HYPH BRL/NNP samples/NNS a/FW priori/FW a/DT finite/NN set/NN of/IN hypotheses/NNS for/IN the/DT model/NN parameter/NN values/NNS and/CC forms/VBZ a/DT discrete/JJ partially/RB observable/JJ Markov/NNP decision/NN process/NN (/-LRB- POMDP/NN )/-RRB- whose/WP$ state/NN space/NN is/VBZ a/DT cross/NN product/NN of/IN the/DT state/NN space/NN for/IN the/DT reinforcement/NN learning/VBG task/NN and/CC the/DT sampled/VBN model/NN parameter/NN space/NN ./.
The/DT POMDP/NN does/VBZ not/RB require/VB conjugate/JJ distributions/NNS for/IN belief/NN representation/NN ,/, as/IN earlier/JJR works/NNS do/VBP ,/, and/CC can/MD be/VB solved/VBN relatively/RB easily/RB with/IN point/NN -/HYPH based/VBN approximation/NN algorithms/NNS ./.
MC/NNP -/HYPH BRL/NNP naturally/RB handles/VBZ both/CC fully/RB and/CC partially/RB observable/JJ worlds/NNS ./.
Theoretical/JJ and/CC experimental/JJ results/NNS show/VBP that/IN the/DT discrete/JJ POMDP/NN approximates/VBZ the/DT underlying/VBG BRL/NN task/NN well/RB with/IN guaranteed/VBN performance/NN ./.
