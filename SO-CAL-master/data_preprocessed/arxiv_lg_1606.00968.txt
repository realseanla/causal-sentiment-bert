We/PRP study/VBP the/DT problem/NN of/IN smooth/JJ imitation/NN learning/NN for/IN online/JJ sequence/NN prediction/NN ,/, where/WRB the/DT goal/NN is/VBZ to/TO train/VB a/DT policy/NN that/WDT can/MD smoothly/RB imitate/VB demonstrated/VBN behavior/NN in/IN a/DT dynamic/JJ and/CC continuous/JJ environment/NN in/IN response/NN to/IN online/RB ,/, sequential/JJ context/NN input/NN ./.
Since/IN the/DT mapping/NN from/IN context/NN to/IN behavior/NN is/VBZ often/RB complex/JJ ,/, we/PRP take/VBP a/DT learning/NN reduction/NN approach/NN to/TO reduce/VB smooth/JJ imitation/NN learning/NN to/IN a/DT regression/NN problem/NN using/VBG complex/JJ function/NN classes/NNS that/WDT are/VBP regularized/VBN to/TO ensure/VB smoothness/NN ./.
We/PRP present/VBP a/DT learning/NN meta/NN -/HYPH algorithm/NN that/WDT achieves/VBZ fast/RB and/CC stable/JJ convergence/NN to/IN a/DT good/JJ policy/NN ./.
Our/PRP$ approach/NN enjoys/VBZ several/JJ attractive/JJ properties/NNS ,/, including/VBG being/VBG fully/RB deterministic/JJ ,/, employing/VBG an/DT adaptive/JJ learning/NN rate/NN that/WDT can/MD provably/RB yield/VB larger/JJR policy/NN improvements/NNS compared/VBN to/IN previous/JJ approaches/NNS ,/, and/CC the/DT ability/NN to/TO ensure/VB stable/JJ convergence/NN ./.
Our/PRP$ empirical/JJ results/NNS demonstrate/VBP significant/JJ performance/NN gains/NNS over/IN previous/JJ approaches/NNS ./.
