Classifier/NNP ensemble/NN generally/RB should/MD combine/VB diverse/JJ component/NN classifiers/NNS ./.
However/RB ,/, it/PRP is/VBZ difficult/JJ to/TO give/VB a/DT definitive/JJ connection/NN between/IN diversity/NN measure/NN and/CC ensemble/NN accuracy/NN ./.
Given/VBN a/DT list/NN of/IN available/JJ component/NN classifiers/NNS ,/, how/WRB to/TO adaptively/RB and/CC diversely/RB ensemble/NN classifiers/NNS becomes/VBZ a/DT big/JJ challenge/NN in/IN the/DT literature/NN ./.
In/IN this/DT paper/NN ,/, we/PRP argue/VBP that/IN diversity/NN ,/, not/RB direct/JJ diversity/NN on/IN samples/NNS but/CC adaptive/JJ diversity/NN with/IN data/NNS ,/, is/VBZ highly/RB correlated/VBN to/IN ensemble/NN accuracy/NN ,/, and/CC we/PRP propose/VBP a/DT novel/JJ technology/NN for/IN classifier/NN ensemble/NN ,/, learning/VBG to/TO diversify/VB ,/, which/WDT learns/VBZ to/TO adaptively/RB combine/VB classifiers/NNS by/IN considering/VBG both/DT accuracy/NN and/CC diversity/NN ./.
Specifically/RB ,/, our/PRP$ approach/NN ,/, Learning/VBG TO/TO Diversify/VB via/IN Weighted/NNP Kernels/NNPS (/-LRB- L2DWK/NN )/-RRB- ,/, performs/VBZ classifier/NN combination/NN by/IN optimizing/VBG a/DT direct/JJ but/CC simple/JJ criterion/NN :/: maximizing/VBG ensemble/NN accuracy/NN and/CC adaptive/JJ diversity/NN simultaneously/RB by/IN minimizing/VBG a/DT convex/NN loss/NN function/NN ./.
Given/VBN a/DT measure/NN formulation/NN ,/, the/DT diversity/NN is/VBZ calculated/VBN with/IN weighted/JJ kernels/NNS (/-LRB- i.e./FW ,/, the/DT diversity/NN is/VBZ measured/VBN on/IN the/DT component/NN classifiers/NNS '/POS outputs/NNS which/WDT are/VBP kernelled/VBN and/CC weighted/VBN )/-RRB- ,/, and/CC the/DT kernel/NN weights/NNS are/VBP automatically/RB learned/VBN ./.
We/PRP minimize/VB this/DT loss/NN function/NN by/IN estimating/VBG the/DT kernel/NN weights/NNS in/IN conjunction/NN with/IN the/DT classifier/NN weights/NNS ,/, and/CC propose/VB a/DT self/NN -/HYPH training/NN algorithm/NN for/IN conducting/VBG this/DT convex/NN optimization/NN procedure/NN iteratively/RB ./.
Extensive/JJ experiments/NNS on/IN a/DT variety/NN of/IN 32/CD UCI/NN classification/NN benchmark/NN datasets/NNS show/VBP that/IN the/DT proposed/VBN approach/NN consistently/RB outperforms/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN ensembles/NNS such/JJ as/IN Bagging/NN ,/, AdaBoost/NNP ,/, Random/NNP Forests/NNS ,/, Gasen/NNP ,/, Regularized/NNP Selective/NNP Ensemble/NNP ,/, and/CC Ensemble/NNP Pruning/NNP via/IN Semi-Definite/NNP Programming/NNP ./.
