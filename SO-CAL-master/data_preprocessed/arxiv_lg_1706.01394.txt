We/PRP study/VBP loss/NN functions/NNS that/WDT measure/VBP the/DT accuracy/NN of/IN a/DT prediction/NN based/VBN on/IN multiple/JJ data/NNS points/NNS simultaneously/RB ./.
To/IN our/PRP$ knowledge/NN ,/, such/JJ loss/NN functions/NNS have/VBP not/RB been/VBN studied/VBN before/IN in/IN the/DT area/NN of/IN property/NN elicitation/NN or/CC in/IN machine/NN learning/VBG more/RBR broadly/RB ./.
As/IN compared/VBN to/IN traditional/JJ loss/NN functions/VBZ that/DT take/VB only/RB a/DT single/JJ data/NN point/NN ,/, these/DT multi-observation/JJ loss/NN functions/NNS can/MD in/IN some/DT cases/NNS drastically/RB reduce/VBP the/DT dimensionality/NN of/IN the/DT hypothesis/NN required/VBN ./.
In/IN elicitation/NN ,/, this/DT corresponds/VBZ to/IN requiring/VBG many/JJ fewer/JJR reports/NNS ;/: in/IN empirical/JJ risk/NN minimization/NN ,/, it/PRP corresponds/VBZ to/IN algorithms/NNS on/IN a/DT hypothesis/NN space/NN of/IN much/RB smaller/JJR dimension/NN ./.
We/PRP explore/VBP some/DT examples/NNS of/IN the/DT tradeoff/NN between/IN dimensionality/NN and/CC number/NN of/IN observations/NNS ,/, give/VB some/DT geometric/JJ characterizations/NNS and/CC intuition/NN for/IN relating/VBG loss/NN functions/NNS and/CC the/DT properties/NNS that/WDT they/PRP elicit/VBP ,/, and/CC discuss/VB some/DT implications/NNS for/IN both/DT elicitation/NN and/CC machine/NN -/HYPH learning/VBG contexts/NNS ./.
