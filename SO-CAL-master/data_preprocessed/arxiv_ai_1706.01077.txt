In/IN many/JJ robotic/JJ applications/NNS ,/, some/DT aspects/NNS of/IN the/DT system/NN dynamics/NNS can/MD be/VB modeled/VBN accurately/RB while/IN others/NNS are/VBP difficult/JJ to/TO obtain/VB or/CC model/NN ./.
We/PRP present/VBP a/DT novel/JJ reinforcement/NN learning/NN (/-LRB- RL/NN )/-RRB- method/NN for/IN continuous/JJ state/NN and/CC action/NN spaces/NNS that/WDT learns/VBZ with/IN partial/JJ knowledge/NN of/IN the/DT system/NN and/CC without/IN active/JJ exploration/NN ./.
It/PRP solves/VBZ linearly/RB -/HYPH solvable/JJ Markov/NNP decision/NN processes/NNS (/-LRB- L/NN -/HYPH MDPs/NNS )/-RRB- ,/, which/WDT are/VBP well/RB suited/JJ for/IN continuous/JJ state/NN and/CC action/NN spaces/NNS ,/, based/VBN on/IN an/DT actor/NN -/HYPH critic/NN architecture/NN ./.
Compared/VBN to/IN previous/JJ RL/NN methods/NNS for/IN L/NN -/HYPH MDPs/NNS and/CC path/NN integral/JJ methods/NNS which/WDT are/VBP model/NN based/VBN ,/, the/DT actor/NN -/HYPH critic/NN learning/NN does/VBZ not/RB need/VB a/DT model/NN of/IN the/DT uncontrolled/JJ dynamics/NNS and/CC ,/, importantly/RB ,/, transition/NN noise/NN levels/NNS ;/: however/RB ,/, it/PRP requires/VBZ knowing/VBG the/DT control/NN dynamics/NNS for/IN the/DT problem/NN ./.
We/PRP evaluate/VBP our/PRP$ method/NN on/IN two/CD synthetic/JJ test/NN problems/NNS ,/, and/CC one/CD real/JJ -/HYPH world/NN problem/NN in/IN simulation/NN and/CC using/VBG real/JJ traffic/NN data/NNS ./.
Our/PRP$ experiments/NNS demonstrate/VBP improved/VBN learning/NN and/CC policy/NN performance/NN ./.
