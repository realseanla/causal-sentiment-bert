Stochastic/JJ games/NNS generalize/VB Markov/NNP decision/NN processes/NNS (/-LRB- MDPs/NNS )/-RRB- to/IN a/DT multiagent/JJ setting/NN by/IN allowing/VBG the/DT state/NN transitions/NNS to/TO depend/VB jointly/RB on/IN all/DT player/NN actions/NNS ,/, and/CC having/VBG rewards/NNS determined/VBN by/IN multiplayer/NN matrix/NN games/NNS at/IN each/DT state/NN ./.
We/PRP consider/VBP the/DT problem/NN of/IN computing/VBG Nash/NNP equilibria/NNS in/IN stochastic/JJ games/NNS ,/, the/DT analogue/NN of/IN planning/NN in/IN MDPs/NNS ./.
We/PRP begin/VBP by/IN providing/VBG a/DT generalization/NN of/IN finite/NN -/HYPH horizon/NN value/NN iteration/NN that/WDT computes/VBZ a/DT Nash/NNP strategy/NN for/IN each/DT player/NN in/IN generalsum/NN stochastic/JJ games/NNS ./.
The/DT algorithm/NN takes/VBZ an/DT arbitrary/JJ Nash/NNP selection/NN function/NN as/IN input/NN ,/, which/WDT allows/VBZ the/DT translation/NN of/IN local/JJ choices/NNS between/IN multiple/JJ Nash/NNP equilibria/NNS into/IN the/DT selection/NN of/IN a/DT single/JJ global/JJ Nash/NNP equilibrium/NN ./.
