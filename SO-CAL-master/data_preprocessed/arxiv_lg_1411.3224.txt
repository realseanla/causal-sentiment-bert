We/PRP provide/VBP non-asymptotic/JJ bounds/NNS for/IN the/DT well/NN -/HYPH known/VBN temporal/JJ difference/NN learning/VBG algorithm/NN TD/NN (/-LRB- 0/CD )/-RRB- with/IN linear/JJ function/NN approximators/NNS ./.
These/DT include/VBP high/JJ -/HYPH probability/NN bounds/NNS as/RB well/RB as/IN bounds/NNS in/IN expectation/NN ./.
Our/PRP$ analysis/NN suggests/VBZ that/IN a/DT step/NN -/HYPH size/NN inversely/RB proportional/JJ to/IN the/DT number/NN of/IN iterations/NNS can/MD not/RB guarantee/VB optimal/JJ rate/NN of/IN convergence/NN unless/IN we/PRP assume/VBP knowledge/NN of/IN the/DT mixing/VBG rate/NN for/IN the/DT Markov/NNP chain/NN underlying/VBG the/DT policy/NN considered/VBN ./.
This/DT problem/NN is/VBZ alleviated/VBN by/IN employing/VBG the/DT well/RB -/HYPH known/VBN Polyak/NNP -/HYPH Ruppert/NNP averaging/VBG scheme/NN ,/, leading/VBG to/IN optimal/JJ rate/NN of/IN convergence/NN without/IN any/DT knowledge/NN of/IN the/DT mixing/VBG rate/NN ./.
Furthermore/RB ,/, we/PRP propose/VBP a/DT variant/NN of/IN TD/NN (/-LRB- 0/CD )/-RRB- with/IN linear/JJ approximators/NNS that/WDT incorporates/VBZ a/DT centering/VBG sequence/NN ,/, and/CC we/PRP establish/VBP that/IN it/PRP exhibits/VBZ an/DT exponential/JJ rate/NN of/IN convergence/NN in/IN expectation/NN ./.
