We/PRP introduce/VBP a/DT general/JJ strategy/NN for/IN improving/VBG neural/JJ sequence/NN generation/NN by/IN incorporating/VBG knowledge/NN about/IN the/DT future/NN ./.
Our/PRP$ decoder/NN combines/VBZ a/DT standard/JJ sequence/NN decoder/NN with/IN a/DT `/`` soothsayer/NN '/'' prediction/NN function/NN Q/NN that/WDT estimates/VBZ the/DT outcome/NN in/IN the/DT future/NN of/IN generating/VBG a/DT word/NN in/IN the/DT present/JJ ./.
Our/PRP$ model/NN draws/VBZ on/IN the/DT same/JJ intuitions/NNS as/IN reinforcement/NN learning/NN ,/, but/CC is/VBZ both/DT simpler/JJR and/CC higher/JJR performing/VBG ,/, avoiding/VBG known/VBN problems/NNS with/IN the/DT use/NN of/IN reinforcement/NN learning/VBG in/IN tasks/NNS with/IN enormous/JJ search/NN spaces/NNS like/IN sequence/NN generation/NN ./.
We/PRP demonstrate/VBP our/PRP$ model/NN by/IN incorporating/VBG Q/NN functions/NNS that/WDT incrementally/RB predict/VBP what/WP the/DT future/JJ BLEU/NN or/CC ROUGE/NN score/NN of/IN the/DT completed/VBN sequence/NN will/MD be/VB ,/, its/PRP$ future/JJ length/NN ,/, and/CC the/DT backwards/RB probability/NN of/IN the/DT source/NN given/VBN the/DT future/JJ target/NN sequence/NN ./.
Experimental/JJ results/NNS show/VBP that/IN future/JJ rediction/NN yields/NNS improved/VBN performance/NN in/IN abstractive/JJ summarization/NN and/CC conversational/JJ response/NN generation/NN and/CC the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN in/IN machine/NN translation/NN ,/, while/IN also/RB enabling/VBG the/DT decoder/NN to/TO generate/VB outputs/NNS that/WDT have/VBP specific/JJ properties/NNS ./.
