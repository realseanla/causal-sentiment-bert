This/DT works/VBZ handles/VBZ the/DT inverse/JJ reinforcement/NN learning/VBG problem/NN in/IN high/JJ -/HYPH dimensional/JJ state/NN spaces/NNS ,/, which/WDT relies/VBZ on/IN an/DT efficient/JJ solution/NN of/IN model/NN -/HYPH based/VBN high/JJ -/HYPH dimensional/JJ reinforcement/NN learning/VBG problems/NNS ./.
To/TO solve/VB the/DT computationally/RB expensive/JJ reinforcement/NN learning/VBG problems/NNS ,/, we/PRP propose/VBP a/DT function/NN approximation/NN method/NN to/TO ensure/VB that/IN the/DT Bellman/NNP Optimality/NNP Equation/NN always/RB holds/VBZ ,/, and/CC then/RB estimate/VB a/DT function/NN based/VBN on/IN the/DT observed/VBN human/JJ actions/NNS for/IN inverse/JJ reinforcement/NN learning/VBG problems/NNS ./.
The/DT time/NN complexity/NN of/IN the/DT proposed/JJ method/NN is/VBZ linearly/RB proportional/JJ to/IN the/DT cardinality/NN of/IN the/DT action/NN set/NN ,/, thus/RB it/PRP can/MD handle/VB high/JJ -/HYPH dimensional/JJ even/RB continuous/JJ state/NN spaces/NNS efficiently/RB ./.
We/PRP test/VBP the/DT proposed/JJ method/NN in/IN a/DT simulated/JJ environment/NN to/TO show/VB its/PRP$ accuracy/NN ,/, and/CC three/CD clinical/JJ tasks/NNS to/TO show/VB how/WRB it/PRP can/MD be/VB used/VBN to/TO evaluate/VB a/DT doctor/NN 's/POS proficiency/NN ./.
