Understanding/VBG unstructured/JJ text/NN is/VBZ a/DT major/JJ goal/NN within/IN natural/JJ language/NN processing/NN ./.
Comprehension/NN tests/NNS pose/VBP questions/NNS based/VBN on/IN short/JJ text/NN passages/NNS to/TO evaluate/VB such/JJ understanding/NN ./.
In/IN this/DT work/NN ,/, we/PRP investigate/VBP machine/NN comprehension/NN on/IN the/DT challenging/JJ {/-LRB- \/SYM it/PRP MCTest/JJS }/-RRB- benchmark/NN ./.
Partly/RB because/IN of/IN its/PRP$ limited/JJ size/NN ,/, prior/JJ work/NN on/IN {/-LRB- \/SYM it/PRP MCTest/JJS }/-RRB- has/VBZ focused/VBN mainly/RB on/IN engineering/VBG better/JJR features/NNS ./.
We/PRP tackle/VBP the/DT dataset/NN with/IN a/DT neural/JJ approach/NN ,/, harnessing/VBG simple/JJ neural/JJ networks/NNS arranged/VBN in/IN a/DT parallel/JJ hierarchy/NN ./.
The/DT parallel/JJ hierarchy/NN enables/VBZ our/PRP$ model/NN to/TO compare/VB the/DT passage/NN ,/, question/NN ,/, and/CC answer/VB from/IN a/DT variety/NN of/IN trainable/JJ perspectives/NNS ,/, as/IN opposed/VBN to/IN using/VBG a/DT manually/RB designed/VBN ,/, rigid/JJ feature/NN set/NN ./.
Perspectives/NNS range/VBP from/IN the/DT word/NN level/NN to/IN sentence/NN fragments/NNS to/IN sequences/NNS of/IN sentences/NNS ;/: the/DT networks/NNS operate/VBP only/RB on/IN word/NN -/HYPH embedding/NN representations/NNS of/IN text/NN ./.
When/WRB trained/VBN with/IN a/DT methodology/NN designed/VBN to/TO help/VB cope/VB with/IN limited/JJ training/NN data/NNS ,/, our/PRP$ Parallel/JJ -/HYPH Hierarchical/JJ model/NN sets/VBZ a/DT new/JJ state/NN of/IN the/DT art/NN for/IN {/-LRB- \/SYM it/PRP MCTest/JJS }/-RRB- ,/, outperforming/VBG previous/JJ feature/NN -/HYPH engineered/VBN approaches/NNS slightly/RB and/CC previous/JJ neural/JJ approaches/NNS by/IN a/DT significant/JJ margin/NN (/-LRB- over/IN 15/CD \/SYM percent/NN absolute/JJ )/-RRB- ./.
