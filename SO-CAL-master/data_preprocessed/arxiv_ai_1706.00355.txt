As/IN robots/NNS begin/VBP to/TO cohabit/VB with/IN humans/NNS in/IN semi-structured/JJ environments/NNS ,/, the/DT need/NN arises/VBZ to/TO understand/VB instructions/NNS involving/VBG rich/JJ variability/NN ---/, for/IN instance/NN ,/, learning/VBG to/TO ground/VB symbols/NNS in/IN the/DT physical/JJ world/NN ./.
Realistically/RB ,/, this/DT task/NN must/MD cope/VB with/IN small/JJ datasets/NNS consisting/VBG of/IN a/DT particular/JJ users/NNS '/POS contextual/JJ assignment/NN of/IN meaning/VBG to/IN terms/NNS ./.
We/PRP present/VBP a/DT method/NN for/IN processing/VBG a/DT raw/JJ stream/NN of/IN cross-modal/JJ input/NN ---/, i.e./FW ,/, linguistic/JJ instructions/NNS ,/, visual/JJ perception/NN of/IN a/DT scene/NN and/CC a/DT concurrent/JJ trace/NN of/IN 3D/JJ eye/NN tracking/VBG fixations/NNS ---/, to/TO produce/VB the/DT segmentation/NN of/IN objects/NNS with/IN a/DT correspondent/NN association/NN to/IN high/JJ -/HYPH level/NN concepts/NNS ./.
To/TO test/VB our/PRP$ framework/NN we/PRP present/VBP experiments/NNS in/IN a/DT table/NN -/HYPH top/JJ object/NN manipulation/NN scenario/NN ./.
Our/PRP$ results/NNS show/VBP our/PRP$ model/NN learns/VBZ the/DT user/NN 's/POS notion/NN of/IN colour/NN and/CC shape/NN from/IN a/DT small/JJ number/NN of/IN physical/JJ demonstrations/NNS ,/, generalising/VBG to/IN identifying/VBG physical/JJ referents/NNS for/IN novel/JJ combinations/NNS of/IN the/DT words/NNS ./.
