This/DT work/NN targets/VBZ people/NNS identification/NN in/IN video/NN based/VBN on/IN the/DT way/NN they/PRP walk/VBP (/-LRB- i.e./FW gait/FW )/-RRB- ./.
While/IN classical/JJ methods/NNS typically/RB derive/VBP gait/NN signatures/NNS from/IN sequences/NNS of/IN binary/JJ silhouettes/NNS ,/, in/IN this/DT work/NN we/PRP explore/VBP the/DT use/NN of/IN convolutional/JJ neural/JJ networks/NNS (/-LRB- CNN/NNP )/-RRB- for/IN learning/VBG high/JJ -/HYPH level/NN descriptors/NNS from/IN low/JJ -/HYPH level/NN motion/NN features/NNS (/-LRB- i.e./FW optical/JJ flow/NN components/NNS )/-RRB- ./.
We/PRP carry/VBP out/RP a/DT thorough/JJ experimental/JJ evaluation/NN of/IN the/DT proposed/VBN CNN/NNP architecture/NN on/IN the/DT challenging/JJ TUM/NN -/HYPH GAID/NN dataset/NN ./.
The/DT experimental/JJ results/NNS indicate/VBP that/IN using/VBG spatio/JJ -/HYPH temporal/JJ cuboids/NNS of/IN optical/JJ flow/NN as/IN input/NN data/NNS for/IN CNN/NNP allows/VBZ to/TO obtain/VB state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS on/IN the/DT gait/NN task/NN with/IN an/DT image/NN resolution/NN eight/CD times/NNS lower/JJR than/IN the/DT previously/RB reported/VBN results/NNS (/-LRB- i.e./FW 80x60/FW pixels/NNS )/-RRB- ./.
