This/DT paper/NN develops/VBZ a/DT model/NN that/WDT addresses/VBZ sentence/NN embedding/NN using/VBG recurrent/JJ neural/JJ networks/NNS (/-LRB- RNN/NN )/-RRB- with/IN Long/JJ Short/JJ Term/NN Memory/NN (/-LRB- LSTM/NN )/-RRB- cells/NNS ./.
The/DT proposed/VBN LSTM/NN -/HYPH RNN/NN model/NN sequentially/RB takes/VBZ each/DT word/NN in/IN a/DT sentence/NN ,/, extracts/NNS its/PRP$ information/NN ,/, and/CC embeds/VBZ it/PRP into/IN a/DT semantic/JJ vector/NN ./.
Due/IN to/IN its/PRP$ ability/NN to/TO capture/VB long/JJ term/NN memory/NN ,/, the/DT LSTM/NNP -/HYPH RNN/NNP accumulates/VBZ increasingly/RB richer/JJR information/NN as/IN it/PRP goes/VBZ through/IN the/DT sentence/NN ,/, and/CC when/WRB it/PRP reaches/VBZ the/DT last/JJ word/NN ,/, the/DT hidden/JJ layer/NN of/IN the/DT network/NN provides/VBZ a/DT semantic/JJ representation/NN of/IN the/DT whole/JJ sentence/NN ./.
In/IN this/DT paper/NN ,/, the/DT LSTM/NNP -/HYPH RNN/NNP is/VBZ trained/VBN in/IN a/DT weakly/RB supervised/JJ manner/NN on/IN user/NN click/VB -/HYPH through/RP data/NNS logged/VBN by/IN a/DT commercial/JJ web/NN search/NN engine/NN ./.
Visualization/NN and/CC analysis/NN are/VBP performed/VBN to/TO understand/VB how/WRB the/DT embedding/NN process/NN works/VBZ ./.
The/DT model/NN automatically/RB attenuates/VBZ the/DT unimportant/JJ words/NNS and/CC detects/VBZ the/DT salient/JJ keywords/NNS in/IN the/DT sentence/NN ./.
Furthermore/RB ,/, these/DT detected/VBN keywords/NNS automatically/RB activate/VBP different/JJ cells/NNS of/IN the/DT LSTM/NNP -/HYPH RNN/NNP ,/, where/WRB words/NNS belonging/VBG to/IN a/DT similar/JJ topic/NN activate/VBP the/DT same/JJ cell/NN ./.
As/IN a/DT semantic/JJ representation/NN of/IN the/DT sentence/NN ,/, the/DT embedding/NN vector/NN can/MD be/VB used/VBN in/IN many/JJ different/JJ applications/NNS ./.
These/DT keyword/JJ detection/NN and/CC topic/NN allocation/NN tasks/NNS enabled/VBN by/IN the/DT LSTM/NNP -/HYPH RNN/NNP allow/VB the/DT network/NN to/TO perform/VB web/NN document/NN retrieval/NN ,/, where/WRB the/DT similarity/NN between/IN the/DT query/NN and/CC documents/NNS can/MD be/VB measured/VBN by/IN the/DT distance/NN between/IN their/PRP$ corresponding/VBG sentence/NN embedding/NN vectors/NNS computed/VBN by/IN the/DT LSTM/NNP -/HYPH RNN/NNP ./.
On/IN a/DT web/NN search/NN task/NN ,/, the/DT LSTM/NN -/HYPH RNN/NN embedding/NN is/VBZ shown/VBN to/TO significantly/RB outperform/VB all/DT existing/VBG state/NN of/IN the/DT art/NN methods/NNS ./.
