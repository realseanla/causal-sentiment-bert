With/IN data/NNS sizes/VBZ constantly/RB expanding/VBG ,/, and/CC with/IN classical/JJ machine/NN learning/VBG algorithms/NNS that/WDT analyze/VBP such/JJ data/NNS requiring/VBG larger/JJR and/CC larger/JJR amounts/NNS of/IN computation/NN time/NN and/CC storage/NN space/NN ,/, the/DT need/NN to/TO distribute/VB computation/NN and/CC memory/NN requirements/NNS among/IN several/JJ computers/NNS has/VBZ become/VBN apparent/JJ ./.
Although/IN substantial/JJ work/NN has/VBZ been/VBN done/VBN in/IN developing/VBG distributed/VBN binary/JJ SVM/NN algorithms/NNS and/CC multi-class/NN SVM/NN algorithms/NNS individually/RB ,/, the/DT field/NN of/IN multi-class/NN distributed/VBN SVMs/NNS remains/VBZ largely/RB unexplored/JJ ./.
This/DT research/NN proposes/VBZ a/DT novel/JJ algorithm/NN that/WDT implements/VBZ the/DT Support/NN Vector/NNP Machine/NNP over/IN a/DT multi-class/JJ dataset/NN and/CC is/VBZ efficient/JJ in/IN a/DT distributed/VBN environment/NN (/-LRB- here/RB ,/, Hadoop/NNP )/-RRB- ./.
The/DT idea/NN is/VBZ to/TO divide/VB the/DT dataset/NN into/IN half/NN recursively/RB and/CC thus/RB compute/VB the/DT optimal/JJ Support/NN Vector/NNP Machine/NNP for/IN this/DT half/NN during/IN the/DT training/NN phase/NN ,/, much/RB like/IN a/DT divide/NN and/CC conquer/VB approach/NN ./.
While/IN testing/NN ,/, this/DT structure/NN has/VBZ been/VBN effectively/RB exploited/VBN to/IN significantly/RB reduce/VB the/DT prediction/NN time/NN ./.
Our/PRP$ algorithm/NN has/VBZ shown/VBN better/JJR computation/NN time/NN during/IN the/DT prediction/NN phase/NN than/IN the/DT traditional/JJ sequential/JJ SVM/NN methods/NNS (/-LRB- One/CD vs./IN One/CD ,/, One/CD vs./FW Rest/NNP )/-RRB- and/CC out/IN -/HYPH performs/VBZ them/PRP as/IN the/DT size/NN of/IN the/DT dataset/NN grows/VBZ ./.
This/DT approach/NN also/RB classifies/VBZ the/DT data/NNS with/IN higher/JJR accuracy/NN than/IN the/DT traditional/JJ multi-class/NN algorithms/NNS ./.
