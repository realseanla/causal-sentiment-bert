We/PRP study/VBP the/DT problem/NN of/IN learning/NN to/IN reason/NN in/IN large/JJ scale/NN knowledge/NN graphs/NNS (/-LRB- KGs/NNS )/-RRB- ./.
More/RBR specifically/RB ,/, we/PRP describe/VBP a/DT novel/JJ reinforcement/NN learning/VBG framework/NN for/IN learning/VBG multi-hop/JJ relational/JJ paths/NNS :/: we/PRP use/VBP a/DT policy/NN -/HYPH based/VBN agent/NN with/IN continuous/JJ states/NNS based/VBN on/IN knowledge/NN graph/NN embeddings/NNS ,/, which/WDT reasons/NNS in/IN a/DT KG/NN vector/NN space/NN by/IN sampling/VBG the/DT most/RBS promising/JJ relation/NN to/TO extend/VB its/PRP$ path/NN ./.
In/IN contrast/NN to/IN prior/JJ work/NN ,/, our/PRP$ approach/NN includes/VBZ a/DT reward/NN function/NN that/WDT takes/VBZ the/DT accuracy/NN ,/, diversity/NN ,/, and/CC efficiency/NN into/IN consideration/NN ./.
Experimentally/RB ,/, we/PRP show/VBP that/IN our/PRP$ proposed/JJ method/NN outperforms/VBZ a/DT path/NN -/HYPH ranking/VBG based/VBN algorithm/NN and/CC knowledge/NN graph/NN embedding/NN methods/NNS on/IN Freebase/NN and/CC Never/RB -/HYPH Ending/VBG Language/NNP Learning/NNP datasets/NNS ./.
