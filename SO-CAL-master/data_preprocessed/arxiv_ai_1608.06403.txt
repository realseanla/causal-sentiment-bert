Partial/JJ monitoring/NN games/NNS are/VBP repeated/VBN games/NNS where/WRB the/DT learner/NN receives/VBZ feedback/NN that/WDT might/MD be/VB different/JJ from/IN adversary/NN 's/POS move/NN or/CC even/RB the/DT reward/NN gained/VBN by/IN the/DT learner/NN ./.
Recently/RB ,/, a/DT general/JJ model/NN of/IN combinatorial/JJ partial/JJ monitoring/NN (/-LRB- CPM/NN )/-RRB- games/NNS was/VBD proposed/VBN ,/, where/WRB the/DT learner/NN 's/POS action/NN space/NN can/MD be/VB exponentially/RB large/JJ and/CC adversary/NN samples/NNS its/PRP$ moves/NNS from/IN a/DT bounded/VBN ,/, continuous/JJ space/NN ,/, according/VBG to/IN a/DT fixed/JJ distribution/NN ./.
The/DT paper/NN gave/VBD a/DT confidence/NN bound/VBN based/VBN algorithm/NN (/-LRB- GCB/NN )/-RRB- that/WDT achieves/VBZ $/$ O/UH (/-LRB- T/NN ^/SYM {/-LRB- 2/3/CD }/-RRB- \/SYM log/NN T/NN )/-RRB- $/$ distribution/NN independent/JJ and/CC $/$ O/UH (/-LRB- \/SYM log/NN T/NN )/-RRB- $/$ distribution/NN dependent/JJ regret/NN bounds/NNS ./.
The/DT implementation/NN of/IN their/PRP$ algorithm/NN depends/VBZ on/IN two/CD separate/JJ offline/RB oracles/NNS and/CC the/DT distribution/NN dependent/JJ regret/NN additionally/RB requires/VBZ existence/NN of/IN a/DT unique/JJ optimal/JJ action/NN for/IN the/DT learner/NN ./.
Adopting/VBG their/PRP$ CPM/NNP model/NN ,/, our/PRP$ first/JJ contribution/NN is/VBZ a/DT Phased/NNP Exploration/NNP with/IN Greedy/NNP Exploitation/NNP (/-LRB- PEGE/NNP )/-RRB- algorithmic/JJ framework/NN for/IN the/DT problem/NN ./.
Different/JJ algorithms/NNS within/IN the/DT framework/NN achieve/VB $/$ O/UH (/-LRB- T/NN ^/SYM {/-LRB- 2/3/CD }/-RRB- \/SYM sqrt/NN {/-LRB- \/SYM log/NN T/NN }/-RRB- )/-RRB- $/$ distribution/NN independent/JJ and/CC $/$ O/UH (/-LRB- \/SYM log/NN ^/SYM 2/CD T/NN )/-RRB- $/$ distribution/NN dependent/JJ regret/NN respectively/RB ./.
Crucially/RB ,/, our/PRP$ framework/NN needs/VBZ only/RB the/DT simpler/JJR "/`` argmax/NN "/'' oracle/NN from/IN GCB/NNP and/CC the/DT distribution/NN dependent/JJ regret/NN does/VBZ not/RB require/VB existence/NN of/IN a/DT unique/JJ optimal/JJ action/NN ./.
Our/PRP$ second/JJ contribution/NN is/VBZ another/DT algorithm/NN ,/, PEGE2/NN ,/, which/WDT combines/VBZ gap/NN estimation/NN with/IN a/DT PEGE/NN algorithm/NN ,/, to/TO achieve/VB an/DT $/$ O/UH (/-LRB- \/SYM log/NN T/NN )/-RRB- $/$ regret/NN bound/VBN ,/, matching/VBG the/DT GCB/NN guarantee/NN but/CC removing/VBG the/DT dependence/NN on/IN size/NN of/IN the/DT learner/NN 's/POS action/NN space/NN ./.
However/RB ,/, like/IN GCB/NNP ,/, PEGE2/NN requires/VBZ access/NN to/IN both/CC offline/RB oracles/NNS and/CC the/DT existence/NN of/IN a/DT unique/JJ optimal/JJ action/NN ./.
Finally/RB ,/, we/PRP discuss/VBP how/WRB our/PRP$ algorithm/NN can/MD be/VB efficiently/RB applied/VBN to/IN a/DT CPM/NNP problem/NN of/IN practical/JJ interest/NN :/: namely/RB ,/, online/RB ranking/VBG with/IN feedback/NN at/IN the/DT top/NN ./.
