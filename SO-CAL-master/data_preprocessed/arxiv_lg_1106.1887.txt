This/DT paper/NN considers/VBZ the/DT problem/NN of/IN learning/NN ,/, from/IN samples/NNS ,/, the/DT dependency/NN structure/NN of/IN a/DT system/NN of/IN linear/JJ stochastic/JJ differential/JJ equations/NNS ,/, when/WRB some/DT of/IN the/DT variables/NNS are/VBP latent/JJ ./.
In/IN particular/JJ ,/, we/PRP observe/VBP the/DT time/NN evolution/NN of/IN some/DT variables/NNS ,/, and/CC never/RB observe/VBP other/JJ variables/NNS ;/: from/IN this/DT ,/, we/PRP would/MD like/VB to/TO find/VB the/DT dependency/NN structure/NN between/IN the/DT observed/VBN variables/NNS --/: separating/VBG out/RP the/DT spurious/JJ interactions/NNS caused/VBN by/IN the/DT (/-LRB- marginalizing/VBG out/IN of/IN the/DT )/-RRB- latent/JJ variables/NNS '/POS time/NN series/NN ./.
We/PRP develop/VBP a/DT new/JJ method/NN ,/, based/VBN on/IN convex/NN optimization/NN ,/, to/TO do/VB so/RB in/IN the/DT case/NN when/WRB the/DT number/NN of/IN latent/JJ variables/NNS is/VBZ smaller/JJR than/IN the/DT number/NN of/IN observed/VBN ones/NNS ./.
For/IN the/DT case/NN when/WRB the/DT dependency/NN structure/NN between/IN the/DT observed/VBN variables/NNS is/VBZ sparse/JJ ,/, we/PRP theoretically/RB establish/VB a/DT high/JJ -/HYPH dimensional/JJ scaling/NN result/NN for/IN structure/NN recovery/NN ./.
We/PRP verify/VBP our/PRP$ theoretical/JJ result/NN with/IN both/CC synthetic/JJ and/CC real/JJ data/NNS (/-LRB- from/IN the/DT stock/NN market/NN )/-RRB- ./.
