Sentiment/NN understanding/NN has/VBZ been/VBN a/DT long/JJ -/HYPH term/NN goal/NN of/IN AI/NN in/IN the/DT past/JJ decades/NNS ./.
This/DT paper/NN deals/NNS with/IN sentence/NN -/HYPH level/NN sentiment/NN classification/NN ./.
Though/IN a/DT variety/NN of/IN neural/JJ network/NN models/NNS have/VBP been/VBN proposed/VBN very/RB recently/RB ,/, however/RB ,/, previous/JJ models/NNS either/CC depend/VB on/IN expensive/JJ phrase/NN -/HYPH level/NN annotation/NN ,/, whose/WP$ performance/NN drops/VBZ substantially/RB when/WRB trained/VBN with/IN only/JJ sentence/NN -/HYPH level/NN annotation/NN ;/: or/CC do/VBP not/RB fully/RB employ/VB linguistic/JJ resources/NNS (/-LRB- e.g./FW ,/, sentiment/NN lexicons/NNS ,/, negation/NN words/NNS ,/, intensity/NN words/NNS )/-RRB- ,/, thus/RB not/RB being/VBG able/JJ to/TO produce/VB linguistically/RB coherent/JJ representations/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP simple/JJ models/NNS trained/VBN with/IN sentence/NN -/HYPH level/NN annotation/NN ,/, but/CC also/RB attempt/VB to/TO generating/VBG linguistically/RB coherent/JJ representations/NNS by/IN employing/VBG regularizers/NNS that/WDT model/VBP the/DT linguistic/JJ role/NN of/IN sentiment/NN lexicons/NNS ,/, negation/NN words/NNS ,/, and/CC intensity/NN words/NNS ./.
Results/NNS show/VBP that/IN our/PRP$ models/NNS are/VBP effective/JJ to/TO capture/VB the/DT sentiment/NN shifting/VBG effect/NN of/IN sentiment/NN ,/, negation/NN ,/, and/CC intensity/NN words/NNS ,/, while/IN still/RB obtain/VB competitive/JJ results/NNS without/IN sacrificing/VBG the/DT models/NNS '/POS simplicity/NN ./.
