Despite/IN their/PRP$ great/JJ success/NN ,/, there/EX is/VBZ still/RB no/DT com/NN -/HYPH prehensive/JJ theoretical/JJ understanding/NN of/IN learning/VBG with/IN Deep/JJ Neural/JJ Networks/NNS (/-LRB- DNNs/NNS )/-RRB- or/CC their/PRP$ in/IN -/HYPH ner/NN organization/NN ./.
Previous/JJ work/NN [/-LRB- Tishby/NNP &amp;/CC Zaslavsky/NNP (/-LRB- 2015/CD )/-RRB- ]/-RRB- proposed/VBN to/TO analyze/VB DNNs/NNS in/IN the/DT Information/NN Plane/NN ;/: i.e./FW ,/, the/DT plane/NN of/IN the/DT Mutual/JJ Information/NN values/NNS that/WDT each/DT layer/NN preserves/VBZ on/IN the/DT input/NN and/CC output/NN variables/NNS ./.
They/PRP suggested/VBD that/IN the/DT goal/NN of/IN the/DT network/NN is/VBZ to/TO optimize/VB the/DT In/IN -/HYPH formation/NN Bottleneck/NNP (/-LRB- IB/NNP )/-RRB- tradeoff/NN between/IN com/NN -/HYPH pression/NN and/CC prediction/NN ,/, successively/RB ,/, for/IN each/DT layer/NN ./.
