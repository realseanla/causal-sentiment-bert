Support/NN vector/NN machine/NN (/-LRB- SVM/NN )/-RRB- has/VBZ been/VBN one/CD of/IN the/DT most/RBS popular/JJ learning/NN algorithms/NNS ,/, with/IN the/DT central/JJ idea/NN of/IN maximizing/VBG the/DT minimum/JJ margin/NN ,/, i.e./FW ,/, the/DT smallest/JJS distance/NN from/IN the/DT instances/NNS to/IN the/DT classification/NN boundary/NN ./.
Recent/JJ theoretical/JJ results/NNS ,/, however/RB ,/, disclosed/VBD that/IN maximizing/VBG the/DT minimum/JJ margin/NN does/VBZ not/RB necessarily/RB lead/VB to/IN better/JJR generalization/NN performances/NNS ,/, and/CC instead/RB ,/, the/DT margin/NN distribution/NN has/VBZ been/VBN proven/VBN to/TO be/VB more/RBR crucial/JJ ./.
Based/VBN on/IN this/DT idea/NN ,/, we/PRP propose/VBP a/DT new/JJ method/NN ,/, named/VBN Optimal/JJ margin/NN Distribution/NN Machine/NN (/-LRB- ODM/NN )/-RRB- ,/, which/WDT tries/VBZ to/TO achieve/VB a/DT better/JJR generalization/NN performance/NN by/IN optimizing/VBG the/DT margin/NN distribution/NN ./.
We/PRP characterize/VBP the/DT margin/NN distribution/NN by/IN the/DT first/JJ -/HYPH and/CC second/JJ -/HYPH order/NN statistics/NNS ,/, i.e./FW ,/, the/DT margin/NN mean/NN and/CC variance/NN ./.
The/DT proposed/JJ method/NN is/VBZ a/DT general/JJ learning/NN approach/NN which/WDT can/MD be/VB used/VBN in/IN any/DT place/NN where/WRB SVM/NNP can/MD be/VB applied/VBN ,/, and/CC their/PRP$ superiority/NN is/VBZ verified/VBN both/DT theoretically/RB and/CC empirically/RB in/IN this/DT paper/NN ./.
