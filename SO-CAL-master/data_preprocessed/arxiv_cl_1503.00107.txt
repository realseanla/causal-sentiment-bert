Modern/JJ statistical/JJ machine/NN translation/NN (/-LRB- SMT/NN )/-RRB- systems/NNS usually/RB use/VBP a/DT linear/JJ combination/NN of/IN features/NNS to/TO model/VB the/DT quality/NN of/IN each/DT translation/NN hypothesis/NN ./.
The/DT linear/JJ combination/NN assumes/VBZ that/IN all/PDT the/DT features/NNS are/VBP in/IN a/DT linear/JJ relationship/NN and/CC constrains/VBZ that/IN each/DT feature/NN interacts/VBZ with/IN the/DT rest/NN features/VBZ in/IN an/DT linear/JJ manner/NN ,/, which/WDT might/MD limit/VB the/DT expressive/JJ power/NN of/IN the/DT model/NN and/CC lead/VB to/IN a/DT under/RB -/HYPH fit/JJ model/NN on/IN the/DT current/JJ data/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT non-linear/JJ modeling/NN for/IN the/DT quality/NN of/IN translation/NN hypotheses/NNS based/VBN on/IN neural/JJ networks/NNS ,/, which/WDT allows/VBZ more/RBR complex/JJ interaction/NN between/IN features/NNS ./.
A/DT learning/NN framework/NN is/VBZ presented/VBN for/IN training/VBG the/DT non-linear/JJ models/NNS ./.
We/PRP also/RB discuss/VBP possible/JJ heuristics/NNS in/IN designing/VBG the/DT network/NN structure/NN which/WDT may/MD improve/VB the/DT non-linear/JJ learning/NN performance/NN ./.
Experimental/JJ results/NNS show/VBP that/IN with/IN the/DT basic/JJ features/NNS of/IN a/DT hierarchical/JJ phrase/NN -/HYPH based/VBN machine/NN translation/NN system/NN ,/, our/PRP$ method/NN produce/VBP translations/NNS that/WDT are/VBP better/JJR than/IN a/DT linear/JJ model/NN ./.
