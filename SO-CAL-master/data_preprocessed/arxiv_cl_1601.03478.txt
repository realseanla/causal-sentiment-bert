The/DT ability/NN to/TO describe/VB images/NNS with/IN natural/JJ language/NN sentences/NNS is/VBZ the/DT hallmark/NN for/IN image/NN and/CC language/NN understanding/NN ./.
Such/PDT a/DT system/NN has/VBZ wide/RB ranging/VBG applications/NNS such/JJ as/IN annotating/VBG images/NNS and/CC using/VBG natural/JJ sentences/NNS to/TO search/VB for/IN images.In/NNP this/DT project/NN we/PRP focus/VBP on/IN the/DT task/NN of/IN bidirectional/JJ image/NN retrieval/NN :/: such/JJ asystem/NN is/VBZ capable/JJ of/IN retrieving/VBG an/DT image/NN based/VBN on/IN a/DT sentence/NN (/-LRB- image/NN search/NN )/-RRB- andretrieve/NN sentence/NN based/VBN on/IN an/DT image/NN query/NN (/-LRB- image/NN annotation/NN )/-RRB- ./.
We/PRP present/VBP asystem/NN based/VBN on/IN a/DT global/JJ ranking/NN objective/NN function/NN which/WDT uses/VBZ a/DT combinationof/NN convolutional/JJ neural/JJ networks/NNS (/-LRB- CNN/NNP )/-RRB- and/CC multi/JJ layer/NN perceptrons/NNS (/-LRB- MLP/NN )/-RRB- ./.
It/PRP takes/VBZ a/DT pair/NN of/IN image/NN and/CC sentence/NN and/CC processes/VBZ them/PRP in/IN different/JJ channels/NNS ,/, finally/RB embedding/VBG it/PRP into/IN a/DT common/JJ multimodal/JJ vector/NN space/NN ./.
These/DT embeddingsencode/JJ abstract/JJ semantic/JJ information/NN about/IN the/DT two/CD inputs/NNS and/CC can/MD be/VB comparedusing/VBG traditional/JJ information/NN retrieval/NN approaches/NNS ./.
For/IN each/DT such/JJ pair/NN ,/, the/DT modelreturns/NNS a/DT score/NN which/WDT is/VBZ interpretted/VBN as/IN a/DT similarity/NN metric/JJ ./.
If/IN this/DT score/NN is/VBZ high/JJ ,/, the/DT image/NN and/CC sentence/NN are/VBP likely/JJ to/TO convey/VB similar/JJ meaning/NN ,/, and/CC if/IN the/DT score/NN is/VBZ low/JJ then/RB they/PRP are/VBP likely/JJ not/RB to/TO ./.
