The/DT goal/NN of/IN language/NN modeling/NN techniques/NNS is/VBZ to/TO capture/VB the/DT statistical/JJ and/CC structural/JJ properties/NNS of/IN natural/JJ languages/NNS from/IN training/NN corpora/NNS ./.
This/DT task/NN typically/RB involves/VBZ the/DT learning/NN of/IN short/JJ range/NN dependencies/NNS ,/, which/WDT generally/RB model/VBP the/DT syntactic/JJ properties/NNS of/IN a/DT language/NN and/CC //HYPH or/CC long/JJ range/NN dependencies/NNS ,/, which/WDT are/VBP semantic/JJ in/IN nature/NN ./.
We/PRP propose/VBP in/IN this/DT paper/NN a/DT new/JJ multi-span/JJ architecture/NN ,/, which/WDT separately/RB models/NNS the/DT short/JJ and/CC long/JJ context/NN information/NN while/IN it/PRP dynamically/RB merges/VBZ them/PRP to/TO perform/VB the/DT language/NN modeling/NN task/NN ./.
This/DT is/VBZ done/VBN through/IN a/DT novel/JJ recurrent/JJ Long/JJ -/HYPH Short/JJ Range/NNP Context/NNP (/-LRB- LSRC/NNP )/-RRB- network/NN ,/, which/WDT explicitly/RB models/NNS the/DT local/JJ (/-LRB- short/JJ )/-RRB- and/CC global/JJ (/-LRB- long/JJ )/-RRB- context/NN using/VBG two/CD separate/JJ hidden/JJ states/NNS that/WDT evolve/VBP in/IN time/NN ./.
This/DT new/JJ architecture/NN is/VBZ an/DT adaptation/NN of/IN the/DT Long/JJ -/HYPH Short/JJ Term/NN Memory/NN network/NN (/-LRB- LSTM/NN )/-RRB- to/TO take/VB into/IN account/NN the/DT linguistic/JJ properties/NNS ./.
Extensive/JJ experiments/NNS conducted/VBN on/IN the/DT Penn/NNP Treebank/NNP (/-LRB- PTB/NNP )/-RRB- and/CC the/DT Large/JJ Text/VB Compression/NNP Benchmark/NNP (/-LRB- LTCB/NNP )/-RRB- corpus/NN showed/VBD a/DT significant/JJ reduction/NN of/IN the/DT perplexity/NN when/WRB compared/VBN to/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN language/NN modeling/NN techniques/NNS ./.
