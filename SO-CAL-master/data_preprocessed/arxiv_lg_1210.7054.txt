Sparse/JJ PCA/NN provides/VBZ a/DT linear/JJ combination/NN of/IN small/JJ number/NN of/IN features/NNS that/WDT maximizes/VBZ variance/NN across/IN data/NNS ./.
Although/IN Sparse/JJ PCA/NN has/VBZ apparent/JJ advantages/NNS compared/VBN to/IN PCA/NNP ,/, such/JJ as/IN better/JJR interpretability/NN ,/, it/PRP is/VBZ generally/RB thought/VBN to/TO be/VB computationally/RB much/RB more/RBR expensive/JJ ./.
In/IN this/DT paper/NN ,/, we/PRP demonstrate/VBP the/DT surprising/JJ fact/NN that/IN sparse/JJ PCA/NN can/MD be/VB easier/JJR than/IN PCA/NN in/IN practice/NN ,/, and/CC that/IN it/PRP can/MD be/VB reliably/RB applied/VBN to/IN very/RB large/JJ data/NNS sets/NNS ./.
This/DT comes/VBZ from/IN a/DT rigorous/JJ feature/NN elimination/NN pre-processing/VBG result/NN ,/, coupled/VBN with/IN the/DT favorable/JJ fact/NN that/IN features/NNS in/IN real/JJ -/HYPH life/NN data/NNS typically/RB have/VBP exponentially/RB decreasing/VBG variances/NNS ,/, which/WDT allows/VBZ for/IN many/JJ features/NNS to/TO be/VB eliminated/VBN ./.
We/PRP introduce/VBP a/DT fast/JJ block/NN coordinate/NN ascent/NN algorithm/NN with/IN much/RB better/JJR computational/JJ complexity/NN than/IN the/DT existing/VBG first/RB -/HYPH order/NN ones/NNS ./.
We/PRP provide/VBP experimental/JJ results/NNS obtained/VBN on/IN text/NN corpora/NNS involving/VBG millions/NNS of/IN documents/NNS and/CC hundreds/NNS of/IN thousands/NNS of/IN features/NNS ./.
These/DT results/NNS illustrate/VBP how/WRB Sparse/JJ PCA/NN can/MD help/VB organize/VB a/DT large/JJ corpus/NN of/IN text/NN data/NNS in/IN a/DT user/NN -/HYPH interpretable/JJ way/NN ,/, providing/VBG an/DT attractive/JJ alternative/JJ approach/NN to/IN topic/NN models/NNS ./.
