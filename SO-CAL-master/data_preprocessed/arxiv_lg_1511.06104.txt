The/DT recent/JJ promising/JJ achievements/NNS of/IN deep/JJ learning/NN rely/VBP on/IN the/DT large/JJ amount/NN of/IN labeled/VBN data/NNS ./.
Considering/VBG the/DT abundance/NN of/IN data/NNS on/IN the/DT web/NN ,/, most/JJS of/IN them/PRP do/VBP not/RB have/VB labels/NNS at/IN all/DT ./.
Therefore/RB ,/, it/PRP is/VBZ important/JJ to/TO improve/VB generalization/NN performance/NN using/VBG unlabeled/JJ data/NNS on/IN supervised/JJ tasks/NNS with/IN few/JJ labeled/VBN instances/NNS ./.
In/IN this/DT work/NN ,/, we/PRP revisit/VBP graph/NN -/HYPH based/VBN semi-supervised/JJ learning/NN algorithms/NNS and/CC propose/VB an/DT online/JJ graph/NN construction/NN technique/NN which/WDT suits/VBZ deep/RB convolutional/JJ neural/JJ network/NN better/RBR ./.
We/PRP consider/VBP an/DT EM/NN -/HYPH like/JJ algorithm/NN for/IN semi-supervised/JJ learning/NN on/IN deep/JJ neural/JJ networks/NNS :/: In/IN forward/JJ pass/NN ,/, the/DT graph/NN is/VBZ constructed/VBN based/VBN on/IN the/DT network/NN output/NN ,/, and/CC the/DT graph/NN is/VBZ then/RB used/VBN for/IN loss/NN calculation/NN to/TO help/VB update/VB the/DT network/NN by/IN back/RB propagation/NN in/IN the/DT backward/JJ pass/NN ./.
We/PRP demonstrate/VBP the/DT strength/NN of/IN our/PRP$ online/JJ approach/NN compared/VBN to/IN the/DT conventional/JJ ones/NNS whose/WP$ graph/NN is/VBZ constructed/VBN on/IN static/NN but/CC not/RB robust/JJ enough/JJ feature/NN representations/NNS beforehand/RB ./.
