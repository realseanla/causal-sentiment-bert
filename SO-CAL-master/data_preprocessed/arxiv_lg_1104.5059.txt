In/IN experimenting/VBG with/IN off/RB -/HYPH policy/NN temporal/JJ difference/NN (/-LRB- TD/NN )/-RRB- methods/NNS in/IN hierarchical/JJ reinforcement/NN learning/NN (/-LRB- HRL/NN )/-RRB- systems/NNS ,/, we/PRP have/VBP observed/VBN unwanted/JJ on/IN -/HYPH policy/NN learning/NN under/IN reproducible/JJ conditions/NNS ./.
Here/RB we/PRP present/VBP modifications/NNS to/IN several/JJ TD/NN methods/NNS that/WDT prevent/VBP unintentional/JJ on/IN -/HYPH policy/NN learning/NN from/IN occurring/VBG ./.
These/DT modifications/NNS create/VBP a/DT tension/NN between/IN exploration/NN and/CC learning/NN ./.
Traditional/JJ TD/NN methods/NNS require/VBP commitment/NN to/IN finishing/VBG subtasks/NNS without/IN exploration/NN in/IN order/NN to/TO update/VB Q/NN -/HYPH values/NNS for/IN early/JJ actions/NNS with/IN high/JJ probability/NN ./.
One/CD -/HYPH step/NN intra-option/NN learning/NN and/CC temporal/JJ second/JJ difference/NN traces/NNS (/-LRB- TSDT/NN )/-RRB- do/VBP not/RB suffer/VB from/IN this/DT limitation/NN ./.
We/PRP demonstrate/VBP that/IN our/PRP$ HRL/NN system/NN is/VBZ efficient/JJ without/IN commitment/NN to/IN completion/NN of/IN subtasks/NNS in/IN a/DT cliff/NN -/HYPH walking/VBG domain/NN ,/, contrary/NN to/IN a/DT widespread/JJ claim/NN in/IN the/DT literature/NN that/IN it/PRP is/VBZ critical/JJ for/IN efficiency/NN of/IN learning/NN ./.
Furthermore/RB ,/, decreasing/VBG commitment/NN as/IN exploration/NN progresses/VBZ is/VBZ shown/VBN to/TO improve/VB both/DT online/JJ performance/NN and/CC the/DT resultant/JJ policy/NN in/IN the/DT taxicab/NN domain/NN ,/, opening/VBG a/DT new/JJ avenue/NN for/IN research/NN into/IN when/WRB it/PRP is/VBZ more/RBR beneficial/JJ to/TO continue/VB with/IN the/DT current/JJ subtask/NN or/CC to/TO replan/VB ./.
