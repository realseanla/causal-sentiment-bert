Several/JJ recent/JJ results/NNS in/IN machine/NN learning/NN have/VBP established/VBN formal/JJ connections/NNS between/IN autoencoders/NNS ---/, artificial/JJ neural/JJ network/NN models/NNS that/WDT attempt/VBP to/TO reproduce/VB their/PRP$ inputs/NNS ---/NFP and/CC other/JJ coding/VBG models/NNS like/IN sparse/JJ coding/NN and/CC K/NN -/HYPH means/NNS ./.
This/DT paper/NN explores/VBZ in/IN depth/NN an/DT autoencoder/NN model/NN that/WDT is/VBZ constructed/VBN using/VBG rectified/VBN linear/JJ activations/NNS on/IN its/PRP$ hidden/JJ units/NNS ./.
Our/PRP$ analysis/NN builds/VBZ on/IN recent/JJ results/NNS to/TO further/RB unify/VB the/DT world/NN of/IN sparse/JJ linear/JJ coding/NN models/NNS ./.
We/PRP provide/VBP an/DT intuitive/JJ interpretation/NN of/IN the/DT behavior/NN of/IN these/DT coding/VBG models/NNS and/CC demonstrate/VBP this/DT intuition/NN using/VBG small/JJ ,/, artificial/JJ datasets/NNS with/IN known/VBN distributions/NNS ./.
