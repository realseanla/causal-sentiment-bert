This/DT paper/NN provides/VBZ a/DT novel/JJ characterization/NN of/IN the/DT max/NN -/HYPH margin/NN distribution/NN in/IN input/NN space/NN ./.
The/DT use/NN of/IN the/DT statistical/JJ Extreme/NNP Value/NNP Theory/NNP (/-LRB- EVT/NNP )/-RRB- is/VBZ introduced/VBN for/IN modeling/VBG margin/NN distances/NNS ,/, allowing/VBG us/PRP to/TO derive/VB a/DT scalable/JJ non-linear/JJ model/NN called/VBD the/DT Extreme/NNP Value/NNP Machine/NNP (/-LRB- EVM/NNP )/-RRB- ./.
Without/IN the/DT need/NN for/IN a/DT kernel/NN ,/, the/DT EVM/NNP leverages/VBZ a/DT margin/NN model/NN to/TO estimate/VB the/DT probability/NN of/IN sample/NN inclusion/NN in/IN each/DT class/NN ./.
The/DT EVM/NNP selects/VBZ a/DT near/JJ -/HYPH optimal/JJ subset/NN of/IN the/DT training/NN vectors/NNS to/TO optimize/VB the/DT gain/NN in/IN terms/NNS of/IN points/NNS covered/VBN versus/IN parameters/NNS used/VBN ./.
We/PRP show/VBP that/IN the/DT problem/NN reduces/VBZ to/IN the/DT NP/NNP -/HYPH hard/JJ Set/VBN Cover/NN problem/NN which/WDT has/VBZ a/DT provable/JJ polynomial/JJ time/NN approximation/NN ./.
The/DT resulting/VBG machine/NN has/VBZ comparable/JJ closed/JJ set/NN accuracy/NN (/-LRB- i.e./FW ,/, when/WRB all/DT testing/NN classes/NNS are/VBP known/VBN at/IN training/NN time/NN )/-RRB- to/IN optimized/VBN RBF/NNP SVMs/NNPS and/CC exhibits/VBZ far/RB superior/JJ performance/NN in/IN open/JJ set/NN recognition/NN (/-LRB- i.e./FW ,/, when/WRB unknown/JJ classes/NNS exist/VBP at/IN testing/NN time/NN )/-RRB- ./.
In/IN open/JJ set/NN recognition/NN performance/NN ,/, the/DT EVM/NNP is/VBZ more/RBR accurate/JJ and/CC more/RBR scalable/JJ than/IN the/DT state/NN of/IN the/DT art/NN ./.
