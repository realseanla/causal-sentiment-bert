This/DT paper/NN presents/VBZ a/DT novel/JJ communication/NN -/HYPH efficient/JJ parallel/JJ belief/NN propagation/NN (/-LRB- CE/NN -/HYPH PBP/NN )/-RRB- algorithm/NN for/IN training/NN latent/NN Dirichlet/NNP allocation/NN (/-LRB- LDA/NN )/-RRB- ./.
Based/VBN on/IN the/DT synchronous/JJ belief/NN propagation/NN (/-LRB- BP/NN )/-RRB- algorithm/NN ,/, we/PRP first/RB develop/VB a/DT parallel/JJ belief/NN propagation/NN (/-LRB- PBP/NN )/-RRB- algorithm/NN on/IN the/DT parallel/JJ architecture/NN ./.
Because/IN the/DT extensive/JJ communication/NN delay/NN often/RB causes/VBZ a/DT low/JJ efficiency/NN of/IN parallel/JJ topic/NN modeling/NN ,/, we/PRP further/RB use/VBP Zipf/NNP 's/POS law/NN to/TO reduce/VB the/DT total/JJ communication/NN cost/NN in/IN PBP/NN ./.
Extensive/JJ experiments/NNS on/IN different/JJ data/NNS sets/NNS demonstrate/VBP that/IN CE/NN -/HYPH PBP/NN achieves/VBZ a/DT higher/JJR topic/NN modeling/NN accuracy/NN and/CC reduces/VBZ more/JJR than/IN 80/CD percent/NN communication/NN cost/NN than/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN parallel/JJ Gibbs/NNP sampling/NN (/-LRB- PGS/NN )/-RRB- algorithm/NN ./.
