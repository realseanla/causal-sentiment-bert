We/PRP present/VBP a/DT new/JJ model/NN for/IN singing/NN synthesis/NN based/VBN on/IN a/DT modified/VBN version/NN of/IN the/DT WaveNet/NNP architecture/NN ./.
Instead/RB of/IN modeling/VBG raw/JJ waveform/NN ,/, we/PRP model/VBP features/NNS produced/VBN by/IN a/DT parametric/JJ vocoder/NN that/WDT separates/VBZ the/DT influence/NN of/IN pitch/NN and/CC timbre/NN ./.
This/DT allows/VBZ conveniently/RB modifying/VBG pitch/NN to/TO match/VB any/DT target/NN melody/NN ,/, facilitates/VBZ training/NN on/IN more/JJR modest/JJ dataset/NN sizes/NNS ,/, and/CC significantly/RB reduces/VBZ training/NN and/CC generation/NN times/NNS ./.
Our/PRP$ model/NN makes/VBZ frame-wise/JJ predictions/NNS using/VBG mixture/NN density/NN outputs/NNS rather/RB than/IN categorical/JJ outputs/NNS in/IN order/NN to/TO reduce/VB the/DT required/VBN parameter/NN count/NN ./.
As/IN we/PRP found/VBD overfitting/VBG to/TO be/VB an/DT issue/NN with/IN the/DT relatively/RB small/JJ datasets/NNS used/VBN in/IN our/PRP$ experiments/NNS ,/, we/PRP propose/VBP a/DT method/NN to/TO regularize/VB the/DT model/NN and/CC make/VB the/DT autoregressive/JJ generation/NN process/NN more/RBR robust/JJ to/IN prediction/NN errors/NNS ./.
Using/VBG a/DT simple/JJ multi-stream/JJ architecture/NN ,/, harmonic/JJ ,/, aperiodic/JJ and/CC voiced/JJ //HYPH unvoiced/JJ components/NNS can/MD all/DT be/VB predicted/VBN in/IN a/DT coherent/JJ manner/NN ./.
We/PRP compare/VBP our/PRP$ method/NN to/IN existing/VBG parametric/JJ statistical/JJ and/CC state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN concatenative/JJ methods/NNS using/VBG quantitative/JJ metrics/NNS and/CC a/DT listening/NN test/NN ./.
While/IN naive/JJ implementations/NNS of/IN the/DT autoregressive/JJ generation/NN algorithm/NN tend/VBP to/TO be/VB inefficient/JJ ,/, using/VBG a/DT smart/JJ algorithm/NN we/PRP can/MD greatly/RB speed/VB up/RP the/DT process/NN and/CC obtain/VB a/DT system/NN that/WDT 's/VBZ competitive/JJ in/IN both/CC speed/NN and/CC quality/NN ./.
