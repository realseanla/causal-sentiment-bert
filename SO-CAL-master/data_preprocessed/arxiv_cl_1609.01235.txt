The/DT negative/JJ sampling/NN (/-LRB- NEG/NN )/-RRB- objective/JJ function/NN ,/, used/VBN in/IN word2vec/NN ,/, is/VBZ a/DT simplification/NN of/IN the/DT Noise/NN Contrastive/JJ Estimation/NN (/-LRB- NCE/NN )/-RRB- method/NN ./.
NEG/NN was/VBD found/VBN to/TO be/VB highly/RB effective/JJ in/IN learning/VBG continuous/JJ word/NN representations/NNS ./.
However/RB ,/, unlike/IN NCE/NNP ,/, it/PRP was/VBD considered/VBN inapplicable/JJ for/IN the/DT purpose/NN of/IN learning/VBG the/DT parameters/NNS of/IN a/DT language/NN model/NN ./.
In/IN this/DT study/NN ,/, we/PRP refute/VBP this/DT assertion/NN by/IN providing/VBG a/DT principled/JJ derivation/NN for/IN NEG/NN -/HYPH based/VBN language/NN modeling/NN ,/, founded/VBN on/IN a/DT novel/JJ analysis/NN of/IN a/DT low/JJ -/HYPH dimensional/JJ approximation/NN of/IN the/DT matrix/NN of/IN pointwise/NN mutual/JJ information/NN between/IN the/DT contexts/NNS and/CC the/DT predicted/VBN words/NNS ./.
The/DT obtained/VBN language/NN modeling/NN is/VBZ closely/RB related/VBN to/IN NCE/NNP language/NN models/NNS but/CC is/VBZ based/VBN on/IN a/DT simplified/JJ objective/NN function/NN ./.
We/PRP thus/RB provide/VBP a/DT unified/VBN formulation/NN for/IN two/CD main/JJ language/NN processing/NN tasks/NNS ,/, namely/RB word/NN embedding/NN and/CC language/NN modeling/NN ,/, based/VBN on/IN the/DT NEG/NN objective/NN function/NN ./.
Experimental/JJ results/NNS on/IN two/CD popular/JJ language/NN modeling/NN benchmarks/NNS show/VBP comparable/JJ perplexity/NN results/NNS ,/, with/IN a/DT small/JJ advantage/NN to/IN NEG/NN over/IN NCE/NNP ./.
