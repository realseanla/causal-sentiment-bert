Domain/NN similarity/NN measures/NNS can/MD be/VB used/VBN to/TO gauge/VB adaptability/NN and/CC select/VB suitable/JJ data/NNS for/IN transfer/NN learning/NN ,/, but/CC existing/VBG approaches/NNS define/VB ad/FW hoc/FW measures/NNS that/WDT are/VBP deemed/VBN suitable/JJ for/IN respective/JJ tasks/NNS ./.
Inspired/VBN by/IN work/NN on/IN curriculum/NN learning/NN ,/, we/PRP propose/VBP to/IN \/SYM emph/NN {/-LRB- learn/VB }/-RRB- data/NNS selection/NN measures/NNS using/VBG Bayesian/JJ Optimization/NN and/CC evaluate/VB them/PRP across/IN models/NNS ,/, domains/NNS and/CC tasks/NNS ./.
Our/PRP$ learned/VBN measures/NNS outperform/VBP existing/VBG domain/NN similarity/NN measures/NNS significantly/RB on/IN three/CD tasks/NNS :/: sentiment/NN analysis/NN ,/, part/NN -/HYPH of/IN -/HYPH speech/NN tagging/NN ,/, and/CC parsing/VBG ./.
We/PRP show/VBP the/DT importance/NN of/IN complementing/VBG similarity/NN with/IN diversity/NN ,/, and/CC that/DT learned/VBD measures/NNS are/VBP --/: to/IN some/DT degree/NN --/: transferable/JJ across/IN models/NNS ,/, domains/NNS ,/, and/CC even/RB tasks/NNS ./.
