Most/JJS real/JJ -/HYPH world/NN reinforcement/NN learning/VBG problems/NNS have/VBP a/DT hierarchical/JJ nature/NN ,/, and/CC often/RB exhibit/VBP some/DT degree/NN of/IN partial/JJ observability/NN ./.
While/IN hierarchy/NN and/CC partial/JJ observability/NN are/VBP usually/RB tackled/VBN separately/RB ,/, for/IN instance/NN by/IN combining/VBG recurrent/JJ neural/JJ networks/NNS and/CC options/NNS ,/, we/PRP show/VBP that/IN addressing/VBG both/DT problems/NNS simultaneously/RB is/VBZ simpler/JJR and/CC more/RBR efficient/JJ in/IN many/JJ cases/NNS ./.
More/RBR specifically/RB ,/, we/PRP make/VBP the/DT initiation/NN set/NN of/IN options/NNS conditional/JJ on/IN the/DT previously/RB -/HYPH executed/VBN option/NN ,/, and/CC show/VBP that/IN options/NNS with/IN such/JJ Option/NN -/HYPH Observation/NNP Initiation/NN Sets/NNS (/-LRB- OOIs/NNS )/-RRB- are/VBP at/IN least/RBS as/IN expressive/JJ as/IN Finite/NNP State/NNP Controllers/NNPS (/-LRB- FSCs/NNS )/-RRB- ,/, a/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN approach/NN for/IN learning/VBG in/IN POMDPs/NNS ./.
In/IN contrast/NN to/IN other/JJ hierarchical/JJ methods/NNS in/IN partially/RB observable/JJ environments/NNS ,/, OOIs/NNS are/VBP easy/JJ to/TO design/VB based/VBN on/IN an/DT intuitive/JJ description/NN of/IN the/DT task/NN ,/, lead/VB to/IN explainable/JJ policies/NNS and/CC keep/VB the/DT top/JJ -/HYPH level/NN and/CC option/NN policies/NNS memoryless/NNS ./.
Our/PRP$ experiments/NNS show/VBP that/IN OOIs/NNS allow/VBP agents/NNS to/TO learn/VB optimal/JJ policies/NNS in/IN challenging/JJ POMDPs/NNS ,/, outperforming/VBG an/DT human/JJ -/HYPH provided/VBN policy/NN in/IN our/PRP$ robotic/JJ experiment/NN ,/, while/IN learning/VBG much/JJ faster/JJR than/IN a/DT recurrent/JJ neural/JJ network/NN over/IN options/NNS ./.
