We/PRP propose/VBP zoneout/NN ,/, a/DT novel/JJ method/NN for/IN regularizing/VBG RNNs/NNS ./.
At/IN each/DT timestep/NN ,/, zoneout/NN stochastically/RB forces/VBZ some/DT hidden/JJ units/NNS to/TO maintain/VB their/PRP$ previous/JJ values/NNS ./.
Like/IN dropout/NN ,/, zoneout/NN uses/VBZ random/JJ noise/NN to/TO train/VB a/DT pseudo-ensemble/NN ,/, improving/VBG generalization/NN ./.
But/CC by/IN preserving/VBG instead/RB of/IN dropping/VBG hidden/VBN units/NNS ,/, gradient/NN information/NN and/CC state/NN information/NN are/VBP more/RBR readily/RB propagated/VBN through/IN time/NN ,/, as/IN in/IN feedforward/NN stochastic/JJ depth/NN networks/NNS ./.
We/PRP perform/VBP an/DT empirical/JJ investigation/NN of/IN various/JJ RNN/NNP regularizers/NNS ,/, and/CC find/VB encouraging/JJ results/NNS :/: zoneout/NN gives/VBZ significant/JJ performance/NN improvements/NNS across/IN tasks/NNS ,/, yielding/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS in/IN character/NN -/HYPH level/NN language/NN modeling/NN on/IN the/DT Penn/NNP Treebank/NNP dataset/NN and/CC competitive/JJ results/NNS on/IN word/NN -/HYPH level/NN Penn/NNP Treebank/NNP and/CC permuted/VBN sequential/JJ MNIST/NN classification/NN tasks/NNS ./.
