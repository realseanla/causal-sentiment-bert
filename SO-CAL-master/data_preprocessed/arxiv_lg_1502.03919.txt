We/PRP provide/VBP sampling/NN -/HYPH based/VBN algorithms/NNS for/IN optimization/NN under/IN a/DT coherent/JJ -/HYPH risk/NN objective/NN ./.
The/DT class/NN of/IN coherent/JJ -/HYPH risk/NN measures/NNS is/VBZ widely/RB accepted/VBN in/IN finance/NN and/CC operations/NNS research/NN ,/, among/IN other/JJ fields/NNS ,/, and/CC encompasses/VBZ popular/JJ risk/NN -/HYPH measures/NNS such/JJ as/IN the/DT conditional/JJ value/NN at/IN risk/NN (/-LRB- CVaR/NN )/-RRB- and/CC the/DT mean/NN -/HYPH semi-deviation/NN ./.
Our/PRP$ approach/NN is/VBZ suitable/JJ for/IN problems/NNS in/IN which/WDT the/DT tunable/JJ parameters/NNS control/VBP the/DT distribution/NN of/IN the/DT cost/NN ,/, such/JJ as/IN in/IN reinforcement/NN learning/VBG with/IN a/DT parameterized/JJ policy/NN ;/: such/JJ problems/NNS can/MD not/RB be/VB solved/VBN using/VBG previous/JJ approaches/NNS ./.
We/PRP consider/VBP both/DT static/JJ risk/NN measures/NNS ,/, and/CC time/NN -/HYPH consistent/JJ dynamic/JJ risk/NN measures/NNS ./.
For/IN static/NN risk/NN measures/NNS ,/, our/PRP$ approach/NN is/VBZ in/IN the/DT spirit/NN of/IN policy/NN gradient/NN algorithms/NNS ,/, while/IN for/IN the/DT dynamic/JJ risk/NN measures/NNS our/PRP$ approach/NN is/VBZ actor/NN -/HYPH critic/NN style/NN ./.
