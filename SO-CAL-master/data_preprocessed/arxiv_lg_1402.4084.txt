Recently/RB there/EX has/VBZ been/VBN much/JJ work/NN on/IN selective/JJ sampling/NN ,/, an/DT online/JJ active/JJ learning/NN setting/NN ,/, in/IN which/WDT algorithms/NNS work/VBP in/IN rounds/NNS ./.
On/IN each/DT round/NN an/DT algorithm/NN receives/VBZ an/DT input/NN and/CC makes/VBZ a/DT prediction/NN ./.
Then/RB ,/, it/PRP can/MD decide/VB whether/IN to/TO query/VB a/DT label/NN ,/, and/CC if/IN so/RB to/IN update/NN its/PRP$ model/NN ,/, otherwise/RB the/DT input/NN is/VBZ discarded/VBN ./.
Most/JJS of/IN this/DT work/NN is/VBZ focused/VBN on/IN the/DT stationary/JJ case/NN ,/, where/WRB it/PRP is/VBZ assumed/VBN that/IN there/EX is/VBZ a/DT fixed/JJ target/NN model/NN ,/, and/CC the/DT performance/NN of/IN the/DT algorithm/NN is/VBZ compared/VBN to/IN a/DT fixed/VBN model/NN ./.
However/RB ,/, in/IN many/JJ real/JJ -/HYPH world/NN applications/NNS ,/, such/JJ as/IN spam/NN prediction/NN ,/, the/DT best/JJS target/NN function/NN may/MD drift/VB over/IN time/NN ,/, or/CC have/VBP shifts/NNS from/IN time/NN to/IN time/NN ./.
We/PRP develop/VBP a/DT novel/JJ selective/JJ sampling/NN algorithm/NN for/IN the/DT drifting/VBG setting/NN ,/, analyze/VB it/PRP under/IN no/DT assumptions/NNS on/IN the/DT mechanism/NN generating/VBG the/DT sequence/NN of/IN instances/NNS ,/, and/CC derive/VBP new/JJ mistake/NN bounds/NNS that/WDT depend/VBP on/IN the/DT amount/NN of/IN drift/NN in/IN the/DT problem/NN ./.
Simulations/NNS on/IN synthetic/JJ and/CC real/JJ -/HYPH world/NN datasets/NNS demonstrate/VBP the/DT superiority/NN of/IN our/PRP$ algorithms/NNS as/IN a/DT selective/JJ sampling/NN algorithm/NN in/IN the/DT drifting/VBG setting/NN ./.
