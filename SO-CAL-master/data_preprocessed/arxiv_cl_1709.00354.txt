Retrieving/VBG spoken/VBN content/NN with/IN spoken/VBN queries/NNS ,/, or/CC query/NN -/HYPH by/IN -/HYPH example/NN spoken/VBN term/NN detection/NN (/-LRB- STD/NN )/-RRB- ,/, is/VBZ attractive/JJ because/IN it/PRP makes/VBZ possible/JJ the/DT matching/NN of/IN signals/NNS directly/RB on/IN the/DT acoustic/JJ level/NN without/IN transcribing/VBG them/PRP into/IN text/NN ./.
Here/RB ,/, we/PRP propose/VBP an/DT end/NN -/HYPH to/IN -/HYPH end/NN query/NN -/HYPH by/IN -/HYPH example/NN STD/NN model/NN based/VBN on/IN an/DT attention/NN -/HYPH based/VBN multi-hop/JJ network/NN ,/, whose/WP$ input/NN is/VBZ a/DT spoken/VBN query/NN and/CC an/DT audio/JJ segment/NN containing/VBG several/JJ utterances/NNS ;/: the/DT output/NN states/NNS whether/IN the/DT audio/JJ segment/NN includes/VBZ the/DT query/NN ./.
The/DT model/NN can/MD be/VB trained/VBN in/IN either/CC a/DT supervised/JJ scenario/NN using/VBG labeled/VBN data/NNS ,/, or/CC in/IN an/DT unsupervised/JJ fashion/NN ./.
In/IN the/DT supervised/JJ scenario/NN ,/, we/PRP find/VBP that/IN the/DT attention/NN mechanism/NN and/CC multiple/JJ hops/VBZ improve/VB performance/NN ,/, and/CC that/IN the/DT attention/NN weights/NNS indicate/VBP the/DT time/NN span/NN of/IN the/DT detected/VBN terms/NNS ./.
In/IN the/DT unsupervised/JJ setting/NN ,/, the/DT model/NN mimics/VBZ the/DT behavior/NN of/IN the/DT existing/VBG query/NN -/HYPH by/IN -/HYPH example/NN STD/NN system/NN ,/, yielding/VBG performance/NN comparable/JJ to/IN the/DT existing/VBG system/NN but/CC with/IN a/DT lower/JJR search/NN time/NN complexity/NN ./.
