The/DT follow/VB the/DT leader/NN (/-LRB- FTL/NN )/-RRB- algorithm/NN ,/, perhaps/RB the/DT simplest/JJS of/IN all/DT online/JJ learning/NN algorithms/NNS ,/, is/VBZ known/VBN to/TO perform/VB well/RB when/WRB the/DT loss/NN functions/VBZ it/PRP is/VBZ used/VBN on/IN are/VBP convex/NN and/CC positively/RB curved/JJ ./.
In/IN this/DT paper/NN we/PRP ask/VBP whether/IN there/EX are/VBP other/JJ "/`` lucky/JJ "/'' settings/NNS when/WRB FTL/NNP achieves/VBZ sublinear/NN ,/, "/'' small/JJ "/`` regret/NN ./.
In/IN particular/JJ ,/, we/PRP study/VBP the/DT fundamental/JJ problem/NN of/IN linear/JJ prediction/NN over/IN a/DT non-empty/JJ convex/NN ,/, compact/JJ domain/NN ./.
Amongst/IN other/JJ results/NNS ,/, we/PRP prove/VBP that/IN the/DT curvature/NN of/IN the/DT boundary/NN of/IN the/DT domain/NN can/MD act/VB as/IN if/IN the/DT losses/NNS were/VBD curved/JJ :/: In/IN this/DT case/NN ,/, we/PRP prove/VBP that/IN as/RB long/JJ as/IN the/DT mean/NN of/IN the/DT loss/NN vectors/NNS have/VBP positive/JJ lengths/NNS bounded/VBD away/RB from/IN zero/CD ,/, FTL/NNP enjoys/VBZ a/DT logarithmic/JJ growth/NN rate/NN of/IN regret/NN ,/, while/IN ,/, e.g./FW ,/, for/IN polytope/NN domains/NNS and/CC stochastic/JJ data/NNS it/PRP enjoys/VBZ finite/NN expected/VBN regret/NN ./.
Building/NN on/IN a/DT previously/RB known/VBN meta/NN -/HYPH algorithm/NN ,/, we/PRP also/RB get/VBP an/DT algorithm/NN that/WDT simultaneously/RB enjoys/VBZ the/DT worst/JJS -/HYPH case/NN guarantees/NNS and/CC the/DT bound/VBN available/JJ for/IN FTL/NN ./.
