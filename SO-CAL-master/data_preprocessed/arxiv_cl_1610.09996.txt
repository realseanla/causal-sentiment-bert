This/DT paper/NN proposes/VBZ dynamic/JJ chunk/NN reader/NN (/-LRB- DCR/NNP )/-RRB- ,/, an/DT end/NN -/HYPH to/IN -/HYPH end/NN neural/JJ reading/NN comprehension/NN (/-LRB- RC/NNP )/-RRB- model/NN that/WDT is/VBZ able/JJ to/TO extract/VB and/CC rank/VB a/DT set/NN of/IN answer/NN candidates/NNS from/IN a/DT given/VBN document/NN to/TO answer/VB questions/NNS ./.
DCR/NNP is/VBZ able/JJ to/TO predict/VB answers/NNS of/IN variable/JJ lengths/NNS ,/, whereas/IN previous/JJ neural/JJ RC/NNP models/NNS primarily/RB focused/VBD on/IN predicting/VBG single/JJ tokens/NNS or/CC entities/NNS ./.
DCR/NNP encodes/VBZ a/DT document/NN and/CC an/DT input/NN question/NN with/IN recurrent/JJ neural/JJ networks/NNS ,/, and/CC then/RB applies/VBZ a/DT word/NN -/HYPH by/IN -/HYPH word/NN attention/NN mechanism/NN to/TO acquire/VB question/NN -/HYPH aware/JJ representations/NNS for/IN the/DT document/NN ,/, followed/VBN by/IN the/DT generation/NN of/IN chunk/NN representations/NNS and/CC a/DT ranking/VBG module/NN to/TO propose/VB the/DT top/JJ -/HYPH ranked/VBN chunk/NN as/IN the/DT answer/NN ./.
Experimental/JJ results/NNS show/VBP that/IN DCR/NNP achieves/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN exact/JJ match/NN and/CC F1/NN scores/NNS on/IN the/DT SQuAD/NN dataset/NN ./.
