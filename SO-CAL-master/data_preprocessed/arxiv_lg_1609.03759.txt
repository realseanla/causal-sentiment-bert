Intelligent/NNP control/NN of/IN robotic/JJ arms/NNS has/VBZ huge/JJ potential/NN over/IN the/DT coming/VBG years/NNS ,/, but/CC as/IN of/IN now/RB will/MD often/RB fail/VB to/TO adapt/VB when/WRB presented/VBN with/IN new/JJ and/CC unfamiliar/JJ environments/NNS ./.
Recent/JJ trends/NNS to/TO solve/VB this/DT problem/NN have/VBP seen/VBN a/DT shift/NN to/TO end/VB -/: to/IN -/HYPH end/NN solutions/NNS using/VBG deep/JJ reinforcement/NN learning/VBG to/TO learn/VB policies/NNS from/IN visual/JJ input/NN ,/, rather/RB than/IN relying/VBG on/IN a/DT handcrafted/VBN ,/, modular/JJ pipeline/NN ./.
Building/NNP upon/IN the/DT recent/JJ success/NN of/IN deep/JJ Q/NN -/HYPH networks/NNS ,/, we/PRP present/VBP an/DT approach/NN which/WDT uses/VBZ three/CD -/HYPH dimensional/JJ simulations/NNS to/TO train/VB a/DT 7/CD -/HYPH DOF/NN robotic/JJ arm/NN in/IN a/DT robot/NN arm/NN control/NN task/NN without/IN any/DT prior/JJ knowledge/NN ./.
Policies/NNS accept/VBP images/NNS of/IN the/DT environment/NN as/IN input/NN and/CC output/NN motor/NN actions/NNS ./.
However/RB ,/, the/DT high/JJ -/HYPH dimensionality/NN of/IN the/DT policies/NNS as/RB well/RB as/IN the/DT large/JJ state/NN space/NN makes/VBZ policy/NN search/NN difficult/JJ ./.
This/DT is/VBZ overcome/VBN by/IN ensuring/VBG interesting/JJ states/NNS are/VBP explored/VBN via/IN intermediate/JJ rewards/NNS that/WDT guide/VBP the/DT policy/NN towards/IN higher/JJR reward/NN states/NNS ./.
Our/PRP$ results/NNS demonstrate/VBP that/IN deep/JJ Q/NN -/HYPH networks/NNS can/MD be/VB used/VBN to/TO learn/VB policies/NNS for/IN a/DT task/NN that/WDT involves/VBZ locating/VBG a/DT cube/NN ,/, grasping/VBG ,/, and/CC then/RB finally/RB lifting/VBG ./.
The/DT agent/NN is/VBZ able/JJ to/TO learn/VB to/TO deal/VB with/IN a/DT range/NN of/IN starting/VBG joint/JJ configurations/NNS and/CC starting/VBG cube/NN positions/NNS when/WRB tested/VBN in/IN simulation/NN ./.
Moreover/RB ,/, we/PRP show/VBP that/IN policies/NNS trained/VBN via/IN simulation/NN have/VBP the/DT potential/NN to/TO be/VB directly/RB applied/VBN to/IN real/JJ -/HYPH world/NN equivalents/NNS without/IN any/DT further/JJ training/NN ./.
We/PRP believe/VBP that/IN robot/NN simulations/NNS can/MD decrease/VB the/DT dependency/NN on/IN physical/JJ robots/NNS and/CC ultimately/RB improve/VB productivity/NN of/IN training/NN robot/NN control/NN tasks/NNS ./.
