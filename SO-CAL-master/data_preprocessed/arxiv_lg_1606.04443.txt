We/PRP present/VBP a/DT general/JJ framework/NN for/IN classification/NN of/IN sparse/JJ and/CC irregularly/RB -/HYPH sampled/VBN time/NN series/NN ./.
The/DT properties/NNS of/IN such/JJ time/NN series/NN can/MD result/VB in/IN substantial/JJ uncertainty/NN about/IN the/DT values/NNS of/IN the/DT underlying/VBG temporal/JJ processes/NNS ,/, while/IN making/VBG the/DT data/NNS difficult/JJ to/TO deal/VB with/IN using/VBG standard/JJ classification/NN methods/NNS that/WDT assume/VBP fixed/VBN -/HYPH dimensional/JJ feature/NN spaces/NNS ./.
To/TO address/VB these/DT challenges/NNS ,/, we/PRP propose/VBP an/DT uncertainty/NN -/HYPH aware/JJ classification/NN framework/NN based/VBN on/IN a/DT special/JJ computational/JJ layer/NN we/PRP refer/VBP to/IN as/IN the/DT Gaussian/JJ process/NN adapter/NN that/WDT can/MD connect/VB irregularly/RB sampled/VBN time/NN series/NN data/NNS to/IN to/IN any/DT black/JJ -/HYPH box/NN classifier/NN learnable/JJ using/VBG gradient/NN descent/NN ./.
We/PRP show/VBP how/WRB to/TO scale/VB up/RP the/DT required/VBN computations/NNS based/VBN on/IN combining/VBG the/DT structured/JJ kernel/NN interpolation/NN framework/NN and/CC the/DT Lanczos/NNPS approximation/NN method/NN ,/, and/CC how/WRB to/TO discriminatively/RB train/VB the/DT Gaussian/JJ process/NN adapter/NN in/IN combination/NN with/IN a/DT number/NN of/IN classifiers/NNS end/NN -/HYPH to/IN -/HYPH end/NN using/VBG backpropagation/NN ./.
