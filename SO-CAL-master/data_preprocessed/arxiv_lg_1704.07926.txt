Our/PRP$ goal/NN is/VBZ to/TO learn/VB a/DT semantic/JJ parser/NN that/WDT maps/VBZ natural/JJ language/NN utterances/NNS into/IN executable/JJ programs/NNS when/WRB only/RB indirect/JJ supervision/NN is/VBZ available/JJ :/: examples/NNS are/VBP labeled/VBN with/IN the/DT correct/JJ execution/NN result/NN ,/, but/CC not/RB the/DT program/NN itself/PRP ./.
Consequently/RB ,/, we/PRP must/MD search/VB the/DT space/NN of/IN programs/NNS for/IN those/DT that/WDT output/NN the/DT correct/JJ result/NN ,/, while/IN not/RB being/VBG misled/VBN by/IN spurious/JJ programs/NNS :/: incorrect/JJ programs/NNS that/WDT coincidentally/RB output/NN the/DT correct/JJ result/NN ./.
We/PRP connect/VBP two/CD common/JJ learning/NN paradigms/NNS ,/, reinforcement/NN learning/NN (/-LRB- RL/NN )/-RRB- and/CC maximum/JJ marginal/JJ likelihood/NN (/-LRB- MML/NN )/-RRB- ,/, and/CC then/RB present/VB a/DT new/JJ learning/NN algorithm/NN that/WDT combines/VBZ the/DT strengths/NNS of/IN both/DT ./.
The/DT new/JJ algorithm/NN guards/NNS against/IN spurious/JJ programs/NNS by/IN combining/VBG the/DT systematic/JJ search/NN traditionally/RB employed/VBN in/IN MML/NN with/IN the/DT randomized/JJ exploration/NN of/IN RL/NNP ,/, and/CC by/IN updating/VBG parameters/NNS such/JJ that/IN probability/NN is/VBZ spread/VBN more/RBR evenly/RB across/IN consistent/JJ programs/NNS ./.
We/PRP apply/VBP our/PRP$ learning/NN algorithm/NN to/IN a/DT new/JJ neural/JJ semantic/JJ parser/NN and/CC show/VBP significant/JJ gains/NNS over/IN existing/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS on/IN a/DT recent/JJ context/NN -/HYPH dependent/JJ semantic/JJ parsing/VBG task/NN ./.
