This/DT paper/NN reports/VBZ a/DT novel/JJ deep/JJ architecture/NN referred/VBN to/IN as/IN Maxout/NNP network/NN In/IN Network/NN (/-LRB- MIN/NN )/-RRB- ,/, which/WDT can/MD enhance/VB model/NN discriminability/NN and/CC facilitate/VB the/DT process/NN of/IN information/NN abstraction/NN within/IN the/DT receptive/JJ field/NN ./.
The/DT proposed/VBN network/NN adopts/VBZ the/DT framework/NN of/IN the/DT recently/RB developed/VBN Network/NNP In/NNP Network/NNP structure/NN ,/, which/WDT slides/VBZ a/DT universal/JJ approximator/NN ,/, multilayer/JJ perceptron/NN (/-LRB- MLP/NN )/-RRB- with/IN rectifier/NN units/NNS ,/, to/IN exact/JJ features/NNS ./.
Instead/RB of/IN MLP/NNP ,/, we/PRP employ/VBP maxout/NN MLP/NN to/TO learn/VB a/DT variety/NN of/IN piecewise/JJ linear/JJ activation/NN functions/NNS and/CC to/TO mediate/VB the/DT problem/NN of/IN vanishing/VBG gradients/NNS that/WDT can/MD occur/VB when/WRB using/VBG rectifier/NN units/NNS ./.
Moreover/RB ,/, batch/NN normalization/NN is/VBZ applied/VBN to/TO reduce/VB the/DT saturation/NN of/IN maxout/NN units/NNS by/IN pre-conditioning/VBG the/DT model/NN and/CC dropout/NN is/VBZ applied/VBN to/TO prevent/VB overfitting/NN ./.
Finally/RB ,/, average/JJ pooling/VBG is/VBZ used/VBN in/IN all/DT pooling/VBG layers/NNS to/TO regularize/VB maxout/NN MLP/NNP in/IN order/NN to/TO facilitate/VB information/NN abstraction/NN in/IN every/DT receptive/JJ field/NN while/IN tolerating/VBG the/DT change/NN of/IN object/NN position/NN ./.
Because/IN average/JJ pooling/VBG preserves/VBZ all/DT features/NNS in/IN the/DT local/JJ patch/NN ,/, the/DT proposed/VBN MIN/NN model/NN can/MD enforce/VB the/DT suppression/NN of/IN irrelevant/JJ information/NN during/IN training/NN ./.
Our/PRP$ experiments/NNS demonstrated/VBD the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN classification/NN performance/NN when/WRB the/DT MIN/NNP model/NN was/VBD applied/VBN to/IN MNIST/NNP ,/, CIFAR/NNP -/HYPH 10/CD ,/, and/CC CIFAR/NN -/HYPH 100/CD datasets/NNS and/CC comparable/JJ performance/NN for/IN SVHN/NNP dataset/NN ./.
