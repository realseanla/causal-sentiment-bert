We/PRP introduce/VBP Group/NNP equivariant/JJ Convolutional/JJ Neural/JJ Networks/NNS (/-LRB- G/NN -/HYPH CNNs/NNS )/-RRB- ,/, a/DT natural/JJ generalization/NN of/IN convolutional/JJ neural/JJ networks/NNS that/WDT reduces/VBZ sample/NN complexity/NN by/IN exploiting/VBG symmetries/NNS ./.
By/IN convolving/VBG over/IN groups/NNS larger/JJR than/IN the/DT translation/NN group/NN ,/, G/NN -/HYPH CNNs/NNS build/VBP representations/NNS that/WDT are/VBP equivariant/JJ to/IN these/DT groups/NNS ,/, which/WDT makes/VBZ it/PRP possible/JJ to/TO greatly/RB increase/VB the/DT degree/NN of/IN parameter/NN sharing/NN ./.
We/PRP show/VBP how/WRB G/NNP -/HYPH CNNs/NNPS can/MD be/VB implemented/VBN with/IN negligible/JJ computational/JJ overhead/NN for/IN discrete/JJ groups/NNS such/JJ as/IN the/DT group/NN of/IN translations/NNS ,/, reflections/NNS and/CC rotations/NNS by/IN multiples/NNS of/IN 90/CD degrees/NNS ./.
G/NN -/HYPH CNNs/NNS achieve/VBP state/NN of/IN the/DT art/NN results/NNS on/IN rotated/VBN MNIST/NN and/CC significantly/RB improve/VB over/IN a/DT competitive/JJ baseline/NN on/IN augmented/VBN and/CC non-augmented/JJ CIFAR/NN -/HYPH 10/CD ./.
