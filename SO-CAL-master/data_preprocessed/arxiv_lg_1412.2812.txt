We/PRP introduce/VBP a/DT new/JJ approach/NN to/IN unsupervised/JJ estimation/NN of/IN feature/NN -/HYPH rich/JJ semantic/JJ role/NN labeling/NN models/NNS ./.
Our/PRP$ model/NN consists/VBZ of/IN two/CD components/NNS :/: (/-LRB- 1/LS )/-RRB- an/DT encoding/VBG component/NN :/: a/DT semantic/JJ role/NN labeling/NN model/NN which/WDT predicts/VBZ roles/NNS given/VBN a/DT rich/JJ set/NN of/IN syntactic/JJ and/CC lexical/JJ features/NNS ;/: (/-LRB- 2/LS )/-RRB- a/DT reconstruction/NN component/NN :/: a/DT tensor/NN factorization/NN model/NN which/WDT relies/VBZ on/IN roles/NNS to/TO predict/VB argument/NN fillers/NNS ./.
When/WRB the/DT components/NNS are/VBP estimated/VBN jointly/RB to/TO minimize/VB errors/NNS in/IN argument/NN reconstruction/NN ,/, the/DT induced/VBN roles/NNS largely/RB correspond/VBP to/IN roles/NNS defined/VBN in/IN annotated/VBN resources/NNS ./.
Our/PRP$ method/NN performs/VBZ on/IN par/NN with/IN most/JJS accurate/JJ role/NN induction/NN methods/NNS on/IN English/NNP and/CC German/NNP ,/, even/RB though/IN ,/, unlike/IN these/DT previous/JJ approaches/NNS ,/, we/PRP do/VBP not/RB incorporate/VB any/DT prior/JJ linguistic/JJ knowledge/NN about/IN the/DT languages/NNS ./.
