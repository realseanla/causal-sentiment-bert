The/DT recent/JJ success/NN of/IN deep/JJ neural/JJ networks/NNS relies/VBZ on/IN massive/JJ amounts/NNS of/IN labeled/VBN data/NNS ./.
For/IN a/DT target/NN task/NN where/WRB labeled/VBN data/NNS is/VBZ unavailable/JJ ,/, domain/NN adaptation/NN can/MD transfer/VB a/DT learner/NN from/IN a/DT different/JJ source/NN domain/NN ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT new/JJ approach/NN to/IN domain/NN adaptation/NN in/IN deep/JJ networks/NNS that/WDT can/MD simultaneously/RB learn/VB adaptive/JJ classifiers/NNS and/CC transferable/JJ features/NNS from/IN labeled/VBN data/NNS in/IN the/DT source/NN domain/NN and/CC unlabeled/JJ data/NNS in/IN the/DT target/NN domain/NN ./.
We/PRP relax/VBP a/DT shared/VBN -/HYPH classifier/NN assumption/NN made/VBN by/IN previous/JJ methods/NNS and/CC assume/VB that/IN the/DT source/NN classifier/NN and/CC target/NN classifier/NN differ/VBP by/IN a/DT residual/JJ function/NN ./.
We/PRP enable/VBP classifier/NN adaptation/NN by/IN plugging/VBG several/JJ layers/NNS into/IN the/DT deep/JJ network/NN to/TO explicitly/RB learn/VB the/DT residual/JJ function/NN with/IN reference/NN to/IN the/DT target/NN classifier/NN ./.
We/PRP embed/VBP features/NNS of/IN multiple/JJ layers/NNS into/IN reproducing/VBG kernel/NN Hilbert/NNP spaces/NNS (/-LRB- RKHSs/NNS )/-RRB- and/CC match/NN feature/NN distributions/NNS for/IN feature/NN adaptation/NN ./.
The/DT adaptation/NN behaviors/NNS can/MD be/VB achieved/VBN in/IN most/JJS feed/NN -/HYPH forward/NN models/NNS by/IN extending/VBG them/PRP with/IN new/JJ residual/JJ layers/NNS and/CC loss/NN functions/NNS ,/, which/WDT can/MD be/VB trained/VBN efficiently/RB using/VBG standard/JJ back/RB -/HYPH propagation/NN ./.
Empirical/JJ evidence/NN exhibits/VBZ that/IN the/DT approach/NN outperforms/VBZ state/NN of/IN art/NN methods/NNS on/IN standard/JJ domain/NN adaptation/NN datasets/NNS ./.
