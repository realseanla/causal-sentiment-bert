Deep/JJ learning/NN and/CC reinforcement/NN learning/VBG methods/NNS have/VBP recently/RB been/VBN used/VBN to/TO solve/VB a/DT variety/NN of/IN problems/NNS in/IN continuous/JJ control/NN domains/NNS ./.
An/DT obvious/JJ application/NN of/IN these/DT techniques/NNS is/VBZ dexterous/JJ manipulation/NN tasks/NNS in/IN robotics/NNS which/WDT are/VBP difficult/JJ to/TO solve/VB using/VBG traditional/JJ control/NN theory/NN or/CC hand/NN -/HYPH engineered/VBN approaches/NNS ./.
One/CD example/NN of/IN such/PDT a/DT task/NN is/VBZ to/TO grasp/VB an/DT object/NN and/CC precisely/RB stack/VB it/PRP on/IN another/DT ./.
Solving/VBG this/DT difficult/JJ and/CC practically/RB relevant/JJ problem/NN in/IN the/DT real/JJ world/NN is/VBZ an/DT important/JJ long/JJ -/HYPH term/NN goal/NN for/IN the/DT field/NN of/IN robotics/NNS ./.
Here/RB we/PRP take/VBP a/DT step/NN towards/IN this/DT goal/NN by/IN examining/VBG the/DT problem/NN in/IN simulation/NN and/CC providing/VBG models/NNS and/CC techniques/NNS aimed/VBN at/IN solving/VBG it/PRP ./.
We/PRP introduce/VBP two/CD extensions/NNS to/IN the/DT Deep/JJ Deterministic/JJ Policy/NN Gradient/NN algorithm/NN (/-LRB- DDPG/NN )/-RRB- ,/, a/DT model/NN -/HYPH free/JJ Q/NN -/HYPH learning/NN based/VBN method/NN ,/, which/WDT make/VBP it/PRP significantly/RB more/RBR data/NN -/HYPH efficient/JJ and/CC scalable/JJ ./.
Our/PRP$ results/NNS show/VBP that/IN by/IN making/VBG extensive/JJ use/NN of/IN off/RB -/HYPH policy/NN data/NNS and/CC replay/NN ,/, it/PRP is/VBZ possible/JJ to/TO find/VB control/NN policies/NNS that/WDT robustly/RB grasp/VBP objects/NNS and/CC stack/VB them/PRP ./.
Further/RB ,/, our/PRP$ results/NNS hint/VBP that/IN it/PRP may/MD soon/RB be/VB feasible/JJ to/TO train/VB successful/JJ stacking/VBG policies/NNS by/IN collecting/VBG interactions/NNS on/IN real/JJ robots/NNS ./.
