Machine/NN translation/NN is/VBZ a/DT natural/JJ candidate/NN problem/NN for/IN reinforcement/NN learning/VBG from/IN human/JJ feedback/NN :/: users/NNS provide/VBP quick/JJ ,/, dirty/JJ ratings/NNS on/IN candidate/NN translations/NNS to/TO guide/VB a/DT system/NN to/TO improve/VB ./.
Yet/RB ,/, current/JJ neural/JJ machine/NN translation/NN training/NN focuses/VBZ on/IN expensive/JJ human/JJ -/HYPH generated/VBN reference/NN translations/NNS ./.
We/PRP describe/VBP a/DT reinforcement/NN learning/VBG algorithm/NN that/WDT improves/VBZ neural/JJ machine/NN translation/NN systems/NNS from/IN simulated/VBN human/JJ feedback/NN ./.
Our/PRP$ algorithm/NN combines/VBZ the/DT advantage/NN actor/NN -/HYPH critic/NN algorithm/NN (/-LRB- Mnih/NNP et/FW al./FW ,/, 2016/CD )/-RRB- with/IN the/DT attention/NN -/HYPH based/VBN neural/JJ encoder/NN -/HYPH decoder/NN architecture/NN (/-LRB- Luong/NNP et/FW al./FW ,/, 2015/CD )/-RRB- ./.
This/DT algorithm/NN (/-LRB- a/DT )/-RRB- is/VBZ well/RB -/HYPH designed/VBN for/IN problems/NNS with/IN a/DT large/JJ action/NN space/NN and/CC delayed/VBN rewards/NNS ,/, (/-LRB- b/LS )/-RRB- effectively/RB optimizes/VBZ traditional/JJ corpus/NN -/HYPH level/NN machine/NN translation/NN metrics/NNS ,/, and/CC (/-LRB- c/LS )/-RRB- is/VBZ robust/JJ to/IN skewed/VBN ,/, high/JJ -/HYPH variance/NN ,/, granular/JJ feedback/NN modeled/VBN after/IN actual/JJ human/JJ behaviors/NNS ./.
