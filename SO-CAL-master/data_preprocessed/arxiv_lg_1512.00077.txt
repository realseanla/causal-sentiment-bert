In/IN this/DT paper/NN ,/, we/PRP present/VBP a/DT novel/JJ algorithm/NN for/IN the/DT maximum/NN a/DT posteriori/JJ decoding/NN (/-LRB- MAPD/NN )/-RRB- of/IN time/NN -/HYPH homogeneous/JJ Hidden/JJ Markov/NNP Models/NNPS (/-LRB- HMM/NNP )/-RRB- ,/, improving/VBG the/DT worst/JJS -/HYPH case/NN running/VBG time/NN of/IN the/DT classical/JJ Viterbi/NNP algorithm/NN by/IN a/DT logarithmic/JJ factor/NN ./.
In/IN our/PRP$ approach/NN ,/, we/PRP interpret/VBP the/DT Viterbi/NNP algorithm/NN as/IN a/DT repeated/VBN computation/NN of/IN matrix/NN -/HYPH vector/NN $/$ (/-LRB- \/SYM max/NN ,/, )/-RRB- $/$ -/HYPH multiplications/NNS ./.
On/IN time/NN -/HYPH homogeneous/JJ HMMs/NNS ,/, this/DT computation/NN is/VBZ online/JJ :/: a/DT matrix/NN ,/, known/VBN in/IN advance/NN ,/, has/VBZ to/TO be/VB multiplied/VBN with/IN several/JJ vectors/NNS revealed/VBD one/CD at/IN a/DT time/NN ./.
Our/PRP$ main/JJ contribution/NN is/VBZ an/DT algorithm/NN solving/VBG this/DT version/NN of/IN matrix/NN -/HYPH vector/NN $/$ (/-LRB- \/SYM max/NN ,/, )/-RRB- $/$ -/HYPH multiplication/NN in/IN subquadratic/JJ time/NN ,/, by/IN performing/VBG a/DT polynomial/JJ preprocessing/NN of/IN the/DT matrix/NN ./.
Employing/VBG this/DT fast/JJ multiplication/NN algorithm/NN ,/, we/PRP solve/VBP the/DT MAPD/NNP problem/NN in/IN $/$ O/UH (/-LRB- mn/NN ^/SYM 2/CD //HYPH \/SYM log/NN n/NN )/-RRB- $/$ time/NN for/IN any/DT time/NN -/HYPH homogeneous/JJ HMM/NN of/IN size/NN $/$ n/NN $/$ and/CC observation/NN sequence/NN of/IN length/NN $/$ m/CD $/$ ,/, with/IN an/DT extra/JJ polynomial/JJ preprocessing/NN cost/NN negligible/JJ for/IN $/$ m/CD &gt;/SYM n/NN $/$ ./.
To/IN the/DT best/JJS of/IN our/PRP$ knowledge/NN ,/, this/DT is/VBZ the/DT first/JJ algorithm/NN for/IN the/DT MAPD/NNP problem/NN requiring/VBG subquadratic/JJ time/NN per/IN observation/NN ,/, under/IN the/DT assumption/NN --/: usually/RB verified/VBN in/IN practice/NN --/: that/IN the/DT transition/NN probability/NN matrix/NN does/VBZ not/RB change/VB with/IN time/NN ./.
