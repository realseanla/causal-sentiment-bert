Extracting/VBG and/CC understanding/VBG affective/JJ states/NNS of/IN subjects/NNS through/IN analysis/NN of/IN face/NN images/NNS //, videos/NNS is/VBZ of/IN high/JJ consequence/NN to/TO advance/VB the/DT levels/NNS of/IN interaction/NN in/IN human/JJ -/HYPH computer/NN interfaces/VBZ ./.
This/DT paper/NN aims/VBZ to/TO highlight/VB vision/NN -/HYPH related/VBN tasks/NNS focused/VBD on/IN understanding/NN "/'' reactions/NNS "/'' of/IN subjects/NNS to/IN presented/VBN content/NN which/WDT has/VBZ not/RB been/VBN largely/RB studied/VBN by/IN the/DT vision/NN community/NN in/IN comparison/NN to/IN other/JJ emotions/NNS ./.
To/TO facilitate/VB future/JJ study/NN in/IN this/DT field/NN ,/, we/PRP present/VBP an/DT effort/NN in/IN collecting/VBG DAiSEE/NN ,/, a/DT free/JJ to/TO use/VB large/JJ -/HYPH scale/NN dataset/NN using/VBG crowd/NN annotation/NN ,/, that/IN not/RB only/RB simulates/VBZ a/DT real/JJ world/NN setting/VBG for/IN e-learning/NN environments/NNS ,/, but/CC also/RB captures/VBZ the/DT interpretability/NN issues/NNS of/IN such/JJ affective/JJ states/NNS by/IN human/JJ annotators/NNS ./.
In/IN addition/NN to/IN the/DT dataset/NN ,/, we/PRP present/VBP benchmark/NN results/NNS based/VBN on/IN standard/JJ baseline/NN methods/NNS and/CC vote/NN aggregation/NN strategies/NNS ,/, thus/RB providing/VBG a/DT springboard/NN for/IN further/JJ research/NN ./.
