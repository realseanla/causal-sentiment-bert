The/DT paradigm/NN shift/NN from/IN shallow/JJ classifiers/NNS with/IN hand/NN -/HYPH crafted/VBN features/NNS to/TO end/VB -/: to/IN -/HYPH end/NN trainable/JJ deep/JJ learning/NN models/NNS has/VBZ shown/VBN significant/JJ improvements/NNS on/IN supervised/JJ learning/NN tasks/NNS ./.
Despite/IN the/DT promising/JJ power/NN of/IN deep/JJ neural/JJ networks/NNS (/-LRB- DNN/NN )/-RRB- ,/, how/WRB to/TO alleviate/VB overfitting/NN during/IN training/NN has/VBZ been/VBN a/DT research/NN topic/NN of/IN interest/NN ./.
In/IN this/DT paper/NN ,/, we/PRP present/VBP a/DT Generative/JJ -/HYPH Discriminative/JJ Variational/NNP Model/NNP (/-LRB- GDVM/NNP )/-RRB- for/IN visual/JJ classification/NN ,/, in/IN which/WDT we/PRP introduce/VBP a/DT latent/JJ variable/JJ inferred/VBN from/IN inputs/NNS for/IN exhibiting/VBG generative/JJ abilities/NNS towards/IN prediction/NN ./.
In/IN other/JJ words/NNS ,/, our/PRP$ GDVM/NNP casts/VBZ the/DT supervised/JJ learning/NN task/NN as/IN a/DT generative/JJ learning/NN process/NN ,/, with/IN data/NNS discrimination/NN to/TO be/VB jointly/RB exploited/VBN for/IN improved/VBN classification/NN ./.
In/IN our/PRP$ experiments/NNS ,/, we/PRP consider/VBP the/DT tasks/NNS of/IN multi-class/NN classification/NN ,/, multi-label/JJ classification/NN ,/, and/CC zero/CD -/HYPH shot/NN learning/NN ./.
We/PRP show/VBP that/IN our/PRP$ GDVM/NNP performs/VBZ favorably/RB against/IN the/DT baselines/NNS or/CC recent/JJ generative/JJ DNN/NN models/NNS ./.
