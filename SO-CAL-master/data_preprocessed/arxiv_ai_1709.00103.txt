A/DT significant/JJ amount/NN of/IN the/DT world/NN 's/POS knowledge/NN is/VBZ stored/VBN in/IN relational/JJ databases/NNS ./.
However/RB ,/, the/DT ability/NN for/IN users/NNS to/TO retrieve/VB facts/NNS from/IN a/DT database/NN is/VBZ limited/VBN due/IN to/IN a/DT lack/NN of/IN understanding/NN of/IN query/NN languages/NNS such/JJ as/IN SQL/NN ./.
We/PRP propose/VBP Seq2SQL/NN ,/, a/DT deep/JJ neural/JJ network/NN for/IN translating/VBG natural/JJ language/NN questions/NNS to/IN corresponding/VBG SQL/NN queries/NNS ./.
Our/PRP$ model/NN leverages/VBZ the/DT structure/NN of/IN SQL/NN queries/NNS to/TO significantly/RB reduce/VB the/DT output/NN space/NN of/IN generated/VBN queries/NNS ./.
Moreover/RB ,/, we/PRP use/VBP rewards/NNS from/IN in/IN -/HYPH the/DT -/HYPH loop/NN query/NN execution/NN over/IN the/DT database/NN to/TO learn/VB a/DT policy/NN to/TO generate/VB unordered/JJ parts/NNS of/IN the/DT query/NN ,/, which/WDT we/PRP show/VBP are/VBP less/RBR suitable/JJ for/IN optimization/NN via/IN cross/NN entropy/NN loss/NN ./.
In/IN addition/NN ,/, we/PRP will/MD publish/VB WikiSQL/NNP ,/, a/DT dataset/NN of/IN 87726/CD hand/NN -/HYPH annotated/VBN examples/NNS of/IN questions/NNS and/CC SQL/NN queries/NNS distributed/VBN across/IN 26375/CD tables/NNS from/IN Wikipedia/NNP ./.
This/DT dataset/NN is/VBZ required/VBN to/TO train/VB our/PRP$ model/NN and/CC is/VBZ an/DT order/NN of/IN magnitude/NN larger/JJR than/IN comparable/JJ datasets/NNS ./.
By/IN applying/VBG policy/NN -/HYPH based/VBN reinforcement/NN learning/VBG with/IN a/DT query/NN execution/NN environment/NN to/IN WikiSQL/NNP ,/, our/PRP$ model/NN Seq2SQL/NN outperforms/VBZ attentional/JJ sequence/NN to/IN sequence/NN models/NNS ,/, improving/VBG execution/NN accuracy/NN from/IN 35.9/CD percent/NN to/IN 60.3/CD percent/NN and/CC logical/JJ form/NN accuracy/NN from/IN 23.4/CD percent/NN to/IN 49.2/CD percent/NN ./.
