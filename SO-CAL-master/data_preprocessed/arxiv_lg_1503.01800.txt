The/DT task/NN of/IN the/DT emotion/NN recognition/NN in/IN the/DT wild/JJ (/-LRB- EmotiW/NN )/-RRB- Challenge/NN is/VBZ to/TO assign/VB one/CD of/IN seven/CD emotions/NNS to/IN short/JJ video/NN clips/NNS extracted/VBN from/IN Hollywood/NNP style/NN movies/NNS ./.
The/DT videos/NNS depict/VBP acted/VBN -/HYPH out/RP emotions/NNS under/IN realistic/JJ conditions/NNS with/IN a/DT large/JJ degree/NN of/IN variation/NN in/IN attributes/NNS such/JJ as/IN pose/NN and/CC illumination/NN ,/, making/VBG it/PRP worthwhile/JJ to/TO explore/VB approaches/NNS which/WDT consider/VBP combinations/NNS of/IN features/NNS from/IN multiple/JJ modalities/NNS for/IN label/NN assignment/NN ./.
In/IN this/DT paper/NN we/PRP present/VBP our/PRP$ approach/NN to/IN learning/VBG several/JJ specialist/NN models/NNS using/VBG deep/JJ learning/NN techniques/NNS ,/, each/DT focusing/VBG on/IN one/CD modality/NN ./.
Among/IN these/DT are/VBP a/DT convolutional/JJ neural/JJ network/NN ,/, focusing/VBG on/IN capturing/VBG visual/JJ information/NN in/IN detected/VBN faces/NNS ,/, a/DT deep/JJ belief/NN net/NN focusing/VBG on/IN the/DT representation/NN of/IN the/DT audio/JJ stream/NN ,/, a/DT K/NNP -/HYPH Means/NNP based/VBN "/`` bag/NN -/HYPH of/IN -/HYPH mouths/NNS "/'' model/NN ,/, which/WDT extracts/NNS visual/JJ features/NNS around/IN the/DT mouth/NN region/NN and/CC a/DT relational/JJ autoencoder/NN ,/, which/WDT addresses/VBZ spatio/JJ -/HYPH temporal/JJ aspects/NNS of/IN videos/NNS ./.
We/PRP explore/VBP multiple/JJ methods/NNS for/IN the/DT combination/NN of/IN cues/NNS from/IN these/DT modalities/NNS into/IN one/CD common/JJ classifier/NN ./.
This/DT achieves/VBZ a/DT considerably/RB greater/JJR accuracy/NN than/IN predictions/NNS from/IN our/PRP$ strongest/JJS single/JJ -/HYPH modality/NN classifier/NN ./.
Our/PRP$ method/NN was/VBD the/DT winning/VBG submission/NN in/IN the/DT 2013/CD EmotiW/NN challenge/NN and/CC achieved/VBD a/DT test/NN set/VBN accuracy/NN of/IN 47.67/CD percent/NN on/IN the/DT 2014/CD dataset/NN ./.
