Exponential/JJ Linear/NNP Units/NNS (/-LRB- ELUs/NNS )/-RRB- are/VBP a/DT useful/JJ rectifier/NN for/IN constructing/VBG deep/JJ learning/NN architectures/NNS ,/, as/IN they/PRP may/MD speed/VB up/RP and/CC otherwise/RB improve/VB learning/NN by/IN virtue/NN of/IN not/RB have/VB vanishing/VBG gradients/NNS and/CC by/IN having/VBG mean/JJ activations/NNS near/IN zero/CD ./.
However/RB ,/, the/DT ELU/NNP activation/NN as/IN parametrized/JJ in/IN [/-LRB- 1/CD ]/-RRB- is/VBZ not/RB continuously/RB differentiable/JJ with/IN respect/NN to/IN its/PRP$ input/NN when/WRB the/DT shape/NN parameter/NN alpha/NN is/VBZ not/RB equal/JJ to/IN 1/CD ./.
We/PRP present/VBP an/DT alternative/JJ parametrization/NN which/WDT is/VBZ C1/NN continuous/JJ for/IN all/DT values/NNS of/IN alpha/NN ,/, making/VBG the/DT rectifier/NN easier/JJR to/TO reason/VB about/RB and/CC making/VBG alpha/NN easier/JJR to/TO tune/VB ./.
This/DT alternative/JJ parametrization/NN has/VBZ several/JJ other/JJ useful/JJ properties/NNS that/WDT the/DT original/JJ parametrization/NN of/IN ELU/NNP does/VBZ not/RB :/: 1/LS )/-RRB- its/PRP$ derivative/JJ with/IN respect/NN to/IN x/NN is/VBZ bounded/VBN ,/, 2/CD )/-RRB- it/PRP contains/VBZ both/CC the/DT linear/JJ transfer/NN function/NN and/CC ReLU/NN as/IN special/JJ cases/NNS ,/, and/CC 3/LS )/-RRB- it/PRP is/VBZ scale/NN -/HYPH similar/JJ with/IN respect/NN to/IN alpha/NN ./.
