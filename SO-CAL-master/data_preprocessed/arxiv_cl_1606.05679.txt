Natural/JJ language/NN understanding/NN often/RB requires/VBZ deep/JJ semantic/JJ knowledge/NN ./.
Expanding/VBG on/IN previous/JJ proposals/NNS ,/, we/PRP suggest/VBP that/IN some/DT important/JJ aspects/NNS of/IN semantic/JJ knowledge/NN can/MD be/VB modeled/VBN as/IN a/DT language/NN model/NN if/IN done/VBN at/IN an/DT appropriate/JJ level/NN of/IN abstraction/NN ./.
We/PRP develop/VBP two/CD distinct/JJ models/NNS that/WDT capture/VBP semantic/JJ frame/NN chains/NNS and/CC discourse/NN information/NN while/IN abstracting/VBG over/IN the/DT specific/JJ mentions/VBZ of/IN predicates/NNS and/CC entities/NNS ./.
For/IN each/DT model/NN ,/, we/PRP investigate/VBP four/CD implementations/NNS :/: a/DT "/`` standard/JJ "/'' N/NN -/HYPH gram/NN language/NN model/NN and/CC three/CD discriminatively/RB trained/VBN "/`` neural/JJ "/'' language/NN models/NNS that/WDT generate/VBP embeddings/NNS for/IN semantic/JJ frames/NNS ./.
The/DT quality/NN of/IN the/DT semantic/JJ language/NN models/NNS (/-LRB- SemLM/NN )/-RRB- is/VBZ evaluated/VBN both/DT intrinsically/RB ,/, using/VBG perplexity/NN and/CC a/DT narrative/NN cloze/NN test/NN and/CC extrinsically/RB -/HYPH we/PRP show/VBP that/IN our/PRP$ SemLM/NN helps/VBZ improve/VB performance/NN on/IN semantic/JJ natural/JJ language/NN processing/NN tasks/NNS such/JJ as/IN co-reference/NN resolution/NN and/CC discourse/NN parsing/VBG ./.
