Recent/JJ work/NN has/VBZ shown/VBN how/WRB denoising/NN and/CC contractive/JJ autoencoders/NNS implicitly/RB capture/VBP the/DT structure/NN of/IN the/DT data/NNS generating/VBG density/NN ,/, in/IN the/DT case/NN where/WRB the/DT corruption/NN noise/NN is/VBZ Gaussian/JJ ,/, the/DT reconstruction/NN error/NN is/VBZ the/DT squared/JJ error/NN ,/, and/CC the/DT data/NNS is/VBZ continuous/JJ -/HYPH valued/VBN ./.
This/DT has/VBZ led/VBN to/IN various/JJ proposals/NNS for/IN sampling/NN from/IN this/DT implicitly/RB learned/VBN density/NN function/NN ,/, using/VBG Langevin/NNP and/CC Metropolis/NNP -/HYPH Hastings/NNP MCMC/NNP ./.
However/RB ,/, it/PRP remained/VBD unclear/JJ how/WRB to/TO connect/VB the/DT training/NN procedure/NN of/IN regularized/VBN auto/NN -/HYPH encoders/NNS to/IN the/DT implicit/JJ estimation/NN of/IN the/DT underlying/VBG data/NNS generating/VBG distribution/NN when/WRB the/DT data/NNS are/VBP discrete/JJ ,/, or/CC using/VBG other/JJ forms/NNS of/IN corruption/NN process/NN and/CC reconstruction/NN errors/NNS ./.
Another/DT issue/NN is/VBZ the/DT mathematical/JJ justification/NN which/WDT is/VBZ only/RB valid/JJ in/IN the/DT limit/NN of/IN small/JJ corruption/NN noise/NN ./.
We/PRP propose/VBP here/RB a/DT different/JJ attack/NN on/IN the/DT problem/NN ,/, which/WDT deals/VBZ with/IN all/PDT these/DT issues/NNS :/: arbitrary/JJ (/-LRB- but/CC noisy/JJ enough/JJ )/-RRB- corruption/NN ,/, arbitrary/JJ reconstruction/NN loss/NN (/-LRB- seen/VBN as/IN a/DT log/NN -/HYPH likelihood/NN )/-RRB- ,/, handling/VBG both/CC discrete/JJ and/CC continuous/JJ -/HYPH valued/VBN variables/NNS ,/, and/CC removing/VBG the/DT bias/NN due/IN to/IN non-infinitesimal/JJ corruption/NN noise/NN (/-LRB- or/CC non-infinitesimal/JJ contractive/JJ penalty/NN )/-RRB- ./.
