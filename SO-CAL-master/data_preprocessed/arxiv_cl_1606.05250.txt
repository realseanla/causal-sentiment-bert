We/PRP present/VBP a/DT new/JJ reading/NN comprehension/NN dataset/NN ,/, SQuAD/NN ,/, consisting/VBG of/IN 100,000/CD questions/NNS posed/VBN by/IN crowdworkers/NNS on/IN a/DT set/NN of/IN Wikipedia/NNP articles/NNS ,/, where/WRB the/DT answer/NN to/IN each/DT question/NN is/VBZ a/DT segment/NN of/IN text/NN from/IN the/DT corresponding/VBG reading/NN passage/NN ./.
We/PRP analyze/VBP the/DT dataset/NN in/IN both/CC manual/JJ and/CC automatic/JJ ways/NNS to/TO understand/VB the/DT types/NNS of/IN reasoning/NN required/VBN to/TO answer/VB the/DT questions/NNS ,/, leaning/VBG heavily/RB on/IN dependency/NN and/CC constituency/NN trees/NNS ./.
We/PRP built/VBD a/DT strong/JJ logistic/JJ regression/NN model/NN ,/, which/WDT achieves/VBZ an/DT F1/NN score/NN of/IN 51.0/CD percent/NN ,/, a/DT significant/JJ improvement/NN over/IN a/DT simple/JJ baseline/NN (/-LRB- 20/CD percent/NN )/-RRB- ./.
However/RB ,/, human/JJ performance/NN (/-LRB- 86.8/CD percent/NN )/-RRB- is/VBZ much/RB higher/JJR ,/, indicating/VBG that/IN the/DT dataset/NN presents/VBZ a/DT good/JJ challenge/NN problem/NN for/IN future/JJ research/NN ./.
