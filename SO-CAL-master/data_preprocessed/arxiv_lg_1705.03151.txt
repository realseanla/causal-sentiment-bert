Deep/JJ neural/JJ models/NNS ,/, particularly/RB the/DT LSTM/NN -/HYPH RNN/NN model/NN ,/, have/VBP shown/VBN great/JJ potential/NN in/IN language/NN identification/NN (/-LRB- LID/NN )/-RRB- ./.
However/RB ,/, the/DT phonetic/JJ information/NN has/VBZ been/VBN largely/RB overlooked/VBN by/IN most/JJS of/IN existing/VBG neural/JJ LID/NN methods/NNS ,/, although/IN this/DT information/NN has/VBZ been/VBN used/VBN in/IN the/DT conventional/JJ phonetic/JJ LID/NN systems/NNS with/IN a/DT great/JJ success/NN ./.
We/PRP present/VBP a/DT phonetic/JJ temporal/JJ neural/JJ model/NN for/IN LID/NN ,/, which/WDT is/VBZ an/DT LSTM/NN -/HYPH RNN/NN LID/NN system/NN but/CC accepts/VBZ phonetic/JJ features/NNS produced/VBN by/IN a/DT phone/NN -/HYPH discriminative/JJ DNN/NN as/IN the/DT input/NN ,/, rather/RB than/IN raw/JJ acoustic/JJ features/NNS ./.
This/DT new/JJ model/NN is/VBZ a/DT reminiscence/NN of/IN the/DT old/JJ phonetic/JJ LID/NN methods/NNS ,/, but/CC the/DT phonetic/JJ knowledge/NN here/RB is/VBZ much/JJ richer/JJR :/: it/PRP is/VBZ at/IN the/DT frame/NN level/NN and/CC involves/VBZ compacted/JJ information/NN of/IN all/DT phones/NNS ./.
Our/PRP$ experiments/NNS conducted/VBN on/IN the/DT Babel/NNP database/NN and/CC the/DT AP16/NN -/HYPH OLR/NN database/NN demonstrate/VBP that/IN the/DT temporal/JJ phonetic/JJ neural/JJ approach/NN is/VBZ very/RB effective/JJ ,/, and/CC significantly/RB outperforms/VBZ existing/VBG acoustic/JJ neural/JJ models/NNS ./.
It/PRP also/RB outperforms/VBZ the/DT conventional/JJ i/NN -/HYPH vector/NN approach/NN on/IN short/JJ utterances/NNS and/CC in/IN noisy/JJ conditions/NNS ./.
