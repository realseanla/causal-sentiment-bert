Learning/VBG hash/NN functions/NNS //, codes/NNS for/IN similarity/NN search/NN over/IN multi-view/JJ data/NNS is/VBZ attracting/VBG increasing/VBG attention/NN ,/, where/WRB similar/JJ hash/NN codes/NNS are/VBP assigned/VBN to/IN the/DT data/NNS objects/NNS characterizing/VBG consistently/RB neighborhood/NN relationship/NN across/IN views/NNS ./.
Traditional/JJ methods/NNS in/IN this/DT category/NN inherently/RB suffer/VBP three/CD limitations/NNS :/: 1/LS )/-RRB- they/PRP commonly/RB adopt/VB a/DT two/CD -/HYPH stage/NN scheme/NN where/WRB similarity/NN matrix/NN is/VBZ first/JJ constructed/VBN ,/, followed/VBN by/IN a/DT subsequent/JJ hash/NN function/NN learning/NN ;/: 2/LS )/-RRB- these/DT methods/NNS are/VBP commonly/RB developed/VBN on/IN the/DT assumption/NN that/IN data/NNS samples/NNS with/IN multiple/JJ representations/NNS are/VBP noise/NN -/HYPH free/JJ ,/, which/WDT is/VBZ not/RB practical/JJ in/IN real/JJ -/HYPH life/NN applications/NNS ;/: 3/LS )/-RRB- they/PRP often/RB incur/VBP cumbersome/JJ training/NN model/NN caused/VBN by/IN the/DT neighborhood/NN graph/NN construction/NN using/VBG all/DT $/$ N$/CD points/NNS in/IN the/DT database/NN (/-LRB- $/$ O/UH (/-LRB- N/NN )/-RRB- $/$ )/-RRB- ./.
In/IN this/DT paper/NN ,/, we/PRP motivate/VBP the/DT problem/NN of/IN jointly/RB and/CC efficiently/RB training/VBG the/DT robust/JJ hash/NN functions/VBZ over/IN data/NNS objects/NNS with/IN multi-feature/NN representations/NNS which/WDT may/MD be/VB noise/NN corrupted/VBN ./.
To/TO achieve/VB both/CC the/DT robustness/NN and/CC training/NN efficiency/NN ,/, we/PRP propose/VBP an/DT approach/NN to/IN effectively/RB and/CC efficiently/RB learning/VBG low/JJ -/HYPH rank/NN kernelized/VBN \/SYM footnote/NN {/-LRB- We/PRP use/VBP kernelized/VBN similarity/NN rather/RB than/IN kernel/NN ,/, as/IN it/PRP is/VBZ not/RB a/DT squared/VBN symmetric/JJ matrix/NN for/IN data/NN -/HYPH landmark/NN affinity/NN matrix/NN ./. }/-RRB-
hash/NN functions/VBZ shared/VBN across/IN views/NNS ./.
Specifically/RB ,/, we/PRP utilize/VBP landmark/NN graphs/NNS to/TO construct/VB tractable/JJ similarity/NN matrices/NNS in/IN multi-views/NNS to/TO automatically/RB discover/VB neighborhood/NN structure/NN in/IN the/DT data/NNS ./.
To/TO learn/VB robust/JJ hash/NN functions/NNS ,/, a/DT latent/JJ low/JJ -/HYPH rank/NN kernel/NN function/NN is/VBZ used/VBN to/TO construct/VB hash/NN functions/NNS in/IN order/NN to/TO accommodate/VB linearly/RB inseparable/JJ data/NNS ./.
In/IN particular/JJ ,/, a/DT latent/JJ kernelized/VBN similarity/NN matrix/NN is/VBZ recovered/VBN by/IN rank/NN minimization/NN on/IN multiple/JJ kernel/NN -/HYPH based/VBN similarity/NN matrices/NNS ./.
Extensive/JJ experiments/NNS on/IN real/JJ -/HYPH world/NN multi-view/NN datasets/NNS validate/VBP the/DT efficacy/NN of/IN our/PRP$ method/NN in/IN the/DT presence/NN of/IN error/NN corruptions/NNS ./.
