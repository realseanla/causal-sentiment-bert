We/PRP address/VBP the/DT problem/NN of/IN integrating/VBG textual/JJ and/CC visual/JJ information/NN in/IN vector/NN space/NN models/NNS for/IN word/NN meaning/VBG representation/NN ./.
We/PRP first/RB present/VBP the/DT Residual/JJ CCA/NN (/-LRB- R/NN -/HYPH CCA/NN )/-RRB- method/NN ,/, that/IN complements/VBZ the/DT standard/JJ CCA/NN method/NN by/IN representing/VBG ,/, for/IN each/DT modality/NN ,/, the/DT difference/NN between/IN the/DT original/JJ signal/NN and/CC the/DT signal/NN projected/VBN to/IN the/DT shared/VBN ,/, max/NN correlation/NN ,/, space/NN ./.
We/PRP then/RB show/VBP that/IN constructing/VBG visual/JJ and/CC textual/JJ representations/NNS and/CC then/RB post-processing/JJ them/PRP through/IN composition/NN of/IN common/JJ modeling/NN motifs/NNS such/JJ as/IN PCA/NNP ,/, CCA/NNP ,/, R/NNP -/HYPH CCA/NNP and/CC linear/JJ interpolation/NN (/-LRB- a.k.a/JJ sequential/JJ modeling/NN )/-RRB- yields/VBZ high/JJ quality/NN models/NNS ./.
On/IN five/CD standard/JJ semantic/JJ benchmarks/NNS our/PRP$ sequential/JJ models/NNS outperform/VBP recent/JJ multimodal/JJ representation/NN learning/VBG alternatives/NNS ,/, including/VBG ones/NNS that/WDT rely/VBP on/IN joint/JJ representation/NN learning/NN ./.
For/IN two/CD of/IN these/DT benchmarks/NNS our/PRP$ R/NN -/HYPH CCA/NN method/NN is/VBZ part/NN of/IN the/DT Best/JJS configuration/NN our/PRP$ algorithm/NN yields/NNS ./.
