This/DT paper/NN proposes/VBZ to/TO address/VB the/DT word/NN sense/NN ambiguity/NN issue/NN in/IN an/DT unsupervised/JJ manner/NN ,/, where/WRB word/NN sense/NN representations/NNS are/VBP learned/VBN along/IN a/DT word/NN sense/NN selection/NN mechanism/NN given/VBN contexts/NNS ./.
Prior/JJ work/NN about/IN learning/VBG multi-sense/JJ embeddings/NNS suffered/VBN from/IN either/CC ambiguity/NN of/IN different/JJ -/HYPH level/NN embeddings/NNS or/CC inefficient/JJ sense/NN selection/NN ./.
The/DT proposed/VBN modular/JJ framework/NN ,/, MUSE/NNP ,/, implements/NNS flexible/JJ modules/NNS to/TO optimize/VB distinct/JJ mechanisms/NNS ,/, achieving/VBG the/DT first/JJ purely/RB sense/NN -/HYPH level/NN representation/NN learning/NN system/NN with/IN linear/JJ -/HYPH time/NN sense/NN selection/NN ./.
We/PRP leverage/VBP reinforcement/NN learning/VBG to/TO enable/VB joint/JJ training/NN on/IN the/DT proposed/VBN modules/NNS ,/, and/CC introduce/VB various/JJ exploration/NN techniques/NNS on/IN sense/NN selection/NN for/IN better/JJR robustness/NN ./.
The/DT experiments/NNS on/IN benchmark/NN data/NNS show/VBP that/IN the/DT proposed/VBN approach/NN achieves/VBZ the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN on/IN synonym/NN selection/NN as/RB well/RB as/IN on/IN contextual/JJ word/NN similarities/NNS in/IN terms/NNS of/IN MaxSimC/NNP ./.
