Deep/JJ CCA/NN is/VBZ a/DT recently/RB proposed/VBN deep/JJ neural/JJ network/NN extension/NN to/IN the/DT traditional/JJ canonical/JJ correlation/NN analysis/NN (/-LRB- CCA/NN )/-RRB- ,/, and/CC has/VBZ been/VBN successful/JJ for/IN multi-view/JJ representation/NN learning/NN in/IN several/JJ domains/NNS ./.
However/RB ,/, stochastic/JJ optimization/NN of/IN the/DT deep/JJ CCA/NN objective/NN is/VBZ not/RB straightforward/JJ ,/, because/IN it/PRP does/VBZ not/RB decouple/VB over/IN training/NN examples/NNS ./.
Previous/JJ optimizers/NNS for/IN deep/JJ CCA/NN are/VBP either/CC batch/NN -/HYPH based/VBN algorithms/NNS or/CC stochastic/JJ optimization/NN using/VBG large/JJ minibatches/NNS ,/, which/WDT can/MD have/VB high/JJ memory/NN consumption/NN ./.
In/IN this/DT paper/NN ,/, we/PRP tackle/VBP the/DT problem/NN of/IN stochastic/JJ optimization/NN for/IN deep/JJ CCA/NN with/IN small/JJ minibatches/NNS ,/, based/VBN on/IN an/DT iterative/JJ solution/NN to/IN the/DT CCA/NN objective/NN ,/, and/CC show/VBP that/IN we/PRP can/MD achieve/VB as/RB good/JJ performance/NN as/IN previous/JJ optimizers/NNS and/CC thus/RB alleviate/VB the/DT memory/NN requirement/NN ./.
