Any/DT agent/NN that/WDT is/VBZ part/NN of/IN the/DT environment/NN it/PRP interacts/VBZ with/IN and/CC has/VBZ versatile/JJ actuators/NNS (/-LRB- such/JJ as/IN arms/NNS and/CC fingers/NNS )/-RRB- ,/, will/MD in/IN principle/NN have/VBP the/DT ability/NN to/TO self/NN -/HYPH modify/VB --/: for/IN example/NN by/IN changing/VBG its/PRP$ own/JJ source/NN code/NN ./.
As/IN we/PRP continue/VBP to/TO create/VB more/JJR and/CC more/JJR intelligent/JJ agents/NNS ,/, chances/NNS increase/VBP that/IN they/PRP will/MD learn/VB about/IN this/DT ability/NN ./.
The/DT question/NN is/VBZ :/: will/MD they/PRP want/VB to/TO use/VB it/PRP ?/.
For/IN example/NN ,/, highly/RB intelligent/JJ systems/NNS may/MD find/VB ways/NNS to/TO change/VB their/PRP$ goals/NNS to/IN something/NN more/RBR easily/RB achievable/JJ ,/, thereby/RB `/`` escaping/VBG '/'' the/DT control/NN of/IN their/PRP$ designers/NNS ./.
In/IN an/DT important/JJ paper/NN ,/, Omohundro/NNP (/-LRB- 2008/CD )/-RRB- argued/VBD that/IN goal/NN preservation/NN is/VBZ a/DT fundamental/JJ drive/NN of/IN any/DT intelligent/JJ system/NN ,/, since/IN a/DT goal/NN is/VBZ more/RBR likely/JJ to/TO be/VB achieved/VBN if/IN future/JJ versions/NNS of/IN the/DT agent/NN strive/VBP towards/IN the/DT same/JJ goal/NN ./.
In/IN this/DT paper/NN ,/, we/PRP formalise/VBP this/DT argument/NN in/IN general/JJ reinforcement/NN learning/NN ,/, and/CC explore/VB situations/NNS where/WRB it/PRP fails/VBZ ./.
Our/PRP$ conclusion/NN is/VBZ that/IN the/DT self/NN -/HYPH modification/NN possibility/NN is/VBZ harmless/JJ if/IN and/CC only/RB if/IN the/DT value/NN function/NN of/IN the/DT agent/NN anticipates/VBZ the/DT consequences/NNS of/IN self/NN -/HYPH modifications/NNS and/CC use/VB the/DT current/JJ utility/NN function/NN when/WRB evaluating/VBG the/DT future/NN ./.
