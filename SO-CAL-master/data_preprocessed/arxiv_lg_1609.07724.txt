In/IN this/DT paper/NN we/PRP examine/VBP learning/VBG methods/NNS combining/VBG the/DT Random/NNP Neural/JJ Network/NN ,/, a/DT biologically/RB inspired/VBN neural/JJ network/NN and/CC the/DT Extreme/NNP Learning/NNP Machine/NNP that/WDT achieve/VBP state/NN of/IN the/DT art/NN classification/NN performance/NN while/IN requiring/VBG much/JJ shorter/JJR training/NN time/NN ./.
The/DT Random/NNP Neural/JJ Network/NN is/VBZ a/DT integrate/VB and/CC fire/VB computational/JJ model/NN of/IN a/DT neural/JJ network/NN whose/WP$ mathematical/JJ structure/NN permits/VBZ the/DT efficient/JJ analysis/NN of/IN large/JJ ensembles/NNS of/IN neurons/NNS ./.
An/DT activation/NN function/NN is/VBZ derived/VBN from/IN the/DT RNN/NN and/CC used/VBN in/IN an/DT Extreme/NNP Learning/NNP Machine/NNP ./.
We/PRP compare/VBP the/DT performance/NN of/IN this/DT combination/NN against/IN the/DT ELM/NN with/IN various/JJ activation/NN functions/NNS ,/, we/PRP reduce/VBP the/DT input/NN dimensionality/NN via/IN PCA/NNP and/CC compare/VB its/PRP$ performance/NN vs./FW autoencoder/FW based/VBN versions/NNS of/IN the/DT RNN/NN -/HYPH ELM/NN ./.
