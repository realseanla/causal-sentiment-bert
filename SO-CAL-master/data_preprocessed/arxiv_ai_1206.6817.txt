We/PRP consider/VBP in/IN this/DT paper/NN the/DT formulation/NN of/IN approximate/JJ inference/NN in/IN Bayesian/JJ networks/NNS as/IN a/DT problem/NN of/IN exact/JJ inference/NN on/IN an/DT approximate/JJ network/NN that/WDT results/VBZ from/IN deleting/VBG edges/NNS (/-LRB- to/TO reduce/VB treewidth/NN )/-RRB- ./.
We/PRP have/VBP shown/VBN in/IN earlier/JJR work/NN that/WDT deleting/VBG edges/NNS calls/VBZ for/IN introducing/VBG auxiliary/JJ network/NN parameters/NNS to/TO compensate/VB for/IN lost/VBN dependencies/NNS ,/, and/CC proposed/VBN intuitive/JJ conditions/NNS for/IN determining/VBG these/DT parameters/NNS ./.
We/PRP have/VBP also/RB shown/VBN that/IN our/PRP$ method/NN corresponds/VBZ to/IN IBP/NNP when/WRB enough/JJ edges/NNS are/VBP deleted/VBN to/TO yield/VB a/DT polytree/NN ,/, and/CC corresponds/VBZ to/IN some/DT generalizations/NNS of/IN IBP/NNP when/WRB fewer/JJR edges/NNS are/VBP deleted/VBN ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT different/JJ criteria/NNS for/IN determining/VBG auxiliary/JJ parameters/NNS based/VBN on/IN optimizing/VBG the/DT KL/NN -/HYPH divergence/NN between/IN the/DT original/JJ and/CC approximate/JJ networks/NNS ./.
We/PRP discuss/VBP the/DT relationship/NN between/IN the/DT two/CD methods/NNS for/IN selecting/VBG parameters/NNS ,/, shedding/VBG new/JJ light/NN on/IN IBP/NNP and/CC its/PRP$ generalizations/NNS ./.
We/PRP also/RB discuss/VBP the/DT application/NN of/IN our/PRP$ new/JJ method/NN to/TO approximating/VBG inference/NN problems/NNS which/WDT are/VBP exponential/JJ in/IN constrained/VBN treewidth/NN ,/, including/VBG MAP/NN and/CC nonmyopic/JJ value/NN of/IN information/NN ./.
