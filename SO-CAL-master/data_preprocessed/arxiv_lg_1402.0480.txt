Hierarchical/JJ Bayesian/JJ networks/NNS and/CC neural/JJ networks/NNS with/IN stochastic/JJ hidden/JJ units/NNS are/VBP commonly/RB perceived/VBN as/IN two/CD separate/JJ types/NNS of/IN models/NNS ./.
We/PRP show/VBP that/IN either/DT of/IN these/DT types/NNS of/IN models/NNS can/MD be/VB transformed/VBN into/IN an/DT instance/NN of/IN the/DT other/JJ ,/, by/IN switching/VBG between/IN centered/VBN and/CC differentiable/JJ non-centered/JJ parameterizations/NNS (/-LRB- CP/NN vs/IN DNCP/NN )/-RRB- of/IN the/DT latent/JJ variables/NNS ./.
We/PRP derive/VBP rules/NNS for/IN deciding/VBG when/WRB such/JJ parameterizations/NNS are/VBP beneficial/JJ for/IN gradient/NN -/HYPH based/VBN inference/NN in/IN terms/NNS of/IN decreased/VBN posterior/JJ correlations/NNS ,/, and/CC show/VBP that/IN in/IN the/DT DNCP/NN ,/, a/DT Monte/NNP Carlo/NNP estimator/NN of/IN the/DT marginal/JJ likelihood/NN can/MD be/VB used/VBN for/IN learning/VBG the/DT parameters/NNS ./.
Theoretical/JJ results/NNS are/VBP validated/VBN in/IN experiments/NNS ./.
