This/DT paper/NN proposes/VBZ to/TO improve/VB visual/JJ question/NN answering/VBG (/-LRB- VQA/NN )/-RRB- with/IN structured/JJ representations/NNS of/IN both/DT scene/NN contents/NNS and/CC questions/NNS ./.
A/DT key/JJ challenge/NN in/IN VQA/NNP is/VBZ to/TO require/VB joint/JJ reasoning/NN over/IN the/DT visual/JJ and/CC text/NN domains/NNS ./.
The/DT predominant/JJ CNN/NNP //HYPH LSTM/NNP -/HYPH based/VBN approach/NN to/IN VQA/NNP is/VBZ limited/VBN by/IN monolithic/JJ vector/NN representations/NNS that/WDT largely/RB ignore/VBP structure/NN in/IN the/DT scene/NN and/CC in/IN the/DT form/NN of/IN the/DT question/NN ./.
CNN/NNP feature/NN vectors/NNS can/MD not/RB effectively/RB capture/NN situations/NNS as/RB simple/JJ as/IN multiple/JJ object/NN instances/NNS ,/, and/CC LSTMs/NNPS process/NN questions/NNS as/IN series/NN of/IN words/NNS ,/, which/WDT does/VBZ not/RB reflect/VB the/DT true/JJ complexity/NN of/IN language/NN structure/NN ./.
We/PRP instead/RB propose/VBP to/TO build/VB graphs/NNS over/IN the/DT scene/NN objects/NNS and/CC over/IN the/DT question/NN words/NNS ,/, and/CC we/PRP describe/VBP a/DT deep/JJ neural/JJ network/NN that/WDT exploits/VBZ the/DT structure/NN in/IN these/DT representations/NNS ./.
This/DT shows/VBZ significant/JJ benefit/NN over/IN the/DT sequential/JJ processing/NN of/IN LSTMs/NNPS ./.
The/DT overall/JJ efficacy/NN of/IN our/PRP$ approach/NN is/VBZ demonstrated/VBN by/IN significant/JJ improvements/NNS over/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN ,/, from/IN 71.2/CD percent/NN to/IN 74.4/CD percent/NN in/IN accuracy/NN on/IN the/DT "/`` abstract/JJ scenes/NNS "/'' multiple/JJ -/HYPH choice/NN benchmark/NN ,/, and/CC from/IN 34.7/CD percent/NN to/IN 39.1/CD percent/NN in/IN accuracy/NN over/IN pairs/NNS of/IN "/`` balanced/JJ "/'' scenes/NNS ,/, i.e./FW images/NNS with/IN fine/JJ -/HYPH grained/JJ differences/NNS and/CC opposite/JJ yes/NN //: no/DT answers/NNS to/IN a/DT same/JJ question/NN ./.
