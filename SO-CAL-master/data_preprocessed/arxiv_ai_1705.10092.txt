In/IN this/DT paper/NN ,/, we/PRP present/VBP the/DT Role/NN Playing/VBG Learning/NN (/-LRB- RPL/NN )/-RRB- scheme/NN for/IN a/DT mobile/JJ robot/NN to/TO navigate/VB socially/RB with/IN its/PRP$ human/JJ companion/NN in/IN populated/JJ environments/NNS ./.
Neural/JJ networks/NNS (/-LRB- NN/NNP )/-RRB- are/VBP constructed/VBN to/IN parameterize/NN a/DT stochastic/JJ policy/NN that/WDT directly/RB maps/VBZ sensory/JJ data/NNS collected/VBN by/IN the/DT robot/NN to/IN its/PRP$ velocity/NN outputs/NNS ,/, while/IN respecting/VBG a/DT set/NN of/IN social/JJ norms/NNS ./.
An/DT efficient/JJ simulative/JJ learning/NN environment/NN is/VBZ built/VBN with/IN maps/NNS and/CC pedestrians/NNS trajectories/NNS collected/VBN from/IN a/DT number/NN of/IN real/JJ -/HYPH world/NN crowd/NN data/NNS sets/NNS ./.
In/IN each/DT learning/NN iteration/NN ,/, a/DT robot/NN equipped/VBN with/IN the/DT NN/NNP policy/NN is/VBZ created/VBN virtually/RB in/IN the/DT learning/NN environment/NN to/TO play/VB itself/PRP as/IN a/DT companied/JJ pedestrian/NN and/CC navigate/VB towards/IN a/DT goal/NN in/IN a/DT socially/RB concomitant/JJ manner/NN ./.
Thus/RB ,/, we/PRP call/VBP this/DT process/NN Role/NN Playing/VBG Learning/NN ,/, which/WDT is/VBZ formulated/VBN under/IN a/DT reinforcement/NN learning/NN (/-LRB- RL/NN )/-RRB- framework/NN ./.
The/DT NN/NNP policy/NN is/VBZ optimized/VBN end/NN -/HYPH to/IN -/HYPH end/NN using/VBG Trust/NNP Region/NNP Policy/NNP Optimization/NN (/-LRB- TRPO/NN )/-RRB- ,/, with/IN consideration/NN of/IN the/DT imperfectness/NN of/IN robot/NN 's/POS sensor/NN measurements/NNS ./.
Simulative/JJ and/CC experimental/JJ results/NNS are/VBP provided/VBN to/TO demonstrate/VB the/DT efficacy/NN and/CC superiority/NN of/IN our/PRP$ method/NN ./.
