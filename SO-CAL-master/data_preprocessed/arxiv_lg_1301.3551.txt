In/IN this/DT paper/NN ,/, we/PRP develop/VBP a/DT framework/NN for/IN information/NN theoretic/JJ learning/NN based/VBN on/IN infinitely/RB divisible/JJ matrices/NNS ./.
We/PRP formulate/VBP an/DT entropy/NN -/HYPH like/JJ functional/JJ on/IN positive/JJ definite/JJ matrices/NNS based/VBN on/IN Renyi/NNP 's/POS entropy/NN definition/NN and/CC examine/VB some/DT key/JJ properties/NNS of/IN this/DT functional/JJ that/WDT lead/VBP to/IN the/DT concept/NN of/IN infinite/JJ divisibility/NN ./.
The/DT proposed/VBN formulation/NN avoids/VBZ the/DT plug/NN in/IN estimation/NN of/IN density/NN and/CC brings/VBZ along/IN the/DT representation/NN power/NN of/IN reproducing/VBG kernel/NN Hilbert/NNP spaces/NNS ./.
We/PRP show/VBP how/WRB analogues/NNS to/IN quantities/NNS such/JJ as/IN conditional/JJ entropy/NN can/MD be/VB defined/VBN ,/, enabling/VBG solutions/NNS to/IN learning/NN problems/NNS ./.
In/IN particular/JJ ,/, we/PRP derive/VBP a/DT supervised/JJ metric/JJ learning/NN algorithm/NN with/IN very/RB competitive/JJ results/NNS ./.
