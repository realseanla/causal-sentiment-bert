Stochastic/JJ gradient/NN descent/NN (/-LRB- SGD/NNP )/-RRB- holds/VBZ as/IN a/DT classical/JJ method/NN to/TO build/VB large/JJ scale/NN machine/NN learning/NN models/NNS over/IN big/JJ data/NNS ./.
A/DT stochastic/JJ gradient/NN is/VBZ typically/RB calculated/VBN from/IN a/DT limited/JJ number/NN of/IN samples/NNS (/-LRB- known/VBN as/IN mini-batch/NN )/-RRB- ,/, so/IN it/PRP potentially/RB incurs/VBZ a/DT high/JJ variance/NN and/CC causes/VBZ the/DT estimated/VBN parameters/NNS bounce/VBP around/IN the/DT optimal/JJ solution/NN ./.
To/TO improve/VB the/DT stability/NN of/IN stochastic/JJ gradient/NN ,/, recent/JJ years/NNS have/VBP witnessed/VBN the/DT proposal/NN of/IN several/JJ semi-stochastic/JJ gradient/NN descent/NN algorithms/NNS ,/, which/WDT distinguish/VBP themselves/PRP from/IN standard/JJ SGD/NNP by/IN incorporating/VBG global/JJ information/NN into/IN gradient/NN computation/NN ./.
In/IN this/DT paper/NN we/PRP contribute/VBP a/DT novel/JJ stratified/JJ semi-stochastic/JJ gradient/NN descent/NN (/-LRB- S3GD/NN )/-RRB- algorithm/NN to/IN this/DT nascent/JJ research/NN area/NN ,/, accelerating/VBG the/DT optimization/NN of/IN a/DT large/JJ family/NN of/IN composite/JJ convex/NN functions/NNS ./.
Though/IN theoretically/RB converging/VBG faster/RBR ,/, prior/JJ semi-stochastic/JJ algorithms/NNS are/VBP found/VBN to/TO suffer/VB from/IN high/JJ iteration/NN complexity/NN ,/, which/WDT makes/VBZ them/PRP even/RB slower/JJR than/IN SGD/NNP in/IN practice/NN on/IN many/JJ datasets/NNS ./.
In/IN our/PRP$ proposed/VBN S3GD/NN ,/, the/DT semi-stochastic/JJ gradient/NN is/VBZ calculated/VBN based/VBN on/IN efficient/JJ manifold/JJ propagation/NN ,/, which/WDT can/MD be/VB numerically/RB accomplished/VBN by/IN sparse/JJ matrix/NN multiplications/NNS ./.
This/DT way/NN S3GD/NN is/VBZ able/JJ to/TO generate/VB a/DT highly/RB -/HYPH accurate/JJ estimate/NN of/IN the/DT exact/JJ gradient/NN from/IN each/DT mini-batch/NN with/IN largely/RB -/HYPH reduced/VBN computational/JJ complexity/NN ./.
Theoretic/JJ analysis/NN reveals/VBZ that/IN the/DT proposed/VBN S3GD/NN elegantly/RB balances/VBZ the/DT geometric/JJ algorithmic/JJ convergence/NN rate/NN against/IN the/DT space/NN and/CC time/NN complexities/NNS during/IN the/DT optimization/NN ./.
The/DT efficacy/NN of/IN S3GD/NN is/VBZ also/RB experimentally/RB corroborated/VBN on/IN several/JJ large/JJ -/HYPH scale/NN benchmark/NN datasets/NNS ./.
