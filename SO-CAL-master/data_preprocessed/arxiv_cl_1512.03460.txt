In/IN this/DT paper/NN we/PRP consider/VBP the/DT problem/NN of/IN continuously/RB discovering/VBG image/NN contents/NNS by/IN actively/RB asking/VBG image/NN based/VBN questions/NNS and/CC subsequently/RB answering/VBG the/DT questions/NNS being/VBG asked/VBN ./.
The/DT key/JJ components/NNS include/VBP a/DT Visual/JJ Question/NN Generation/NN (/-LRB- VQG/NN )/-RRB- module/NN and/CC a/DT Visual/JJ Question/NN Answering/VBG module/NN ,/, in/IN which/WDT Recurrent/JJ Neural/JJ Networks/NNS (/-LRB- RNN/NN )/-RRB- and/CC Convolutional/JJ Neural/JJ Network/NN (/-LRB- CNN/NNP )/-RRB- are/VBP used/VBN ./.
Given/VBN a/DT dataset/NN that/WDT contains/VBZ images/NNS ,/, questions/NNS and/CC their/PRP$ answers/NNS ,/, both/CC modules/NNS are/VBP trained/VBN at/IN the/DT same/JJ time/NN ,/, with/IN the/DT difference/NN being/VBG VQG/NNP uses/VBZ the/DT images/NNS as/IN input/NN and/CC the/DT corresponding/VBG questions/NNS as/IN output/NN ,/, while/IN VQA/NNP uses/VBZ images/NNS and/CC questions/NNS as/IN input/NN and/CC the/DT corresponding/VBG answers/NNS as/IN output/NN ./.
We/PRP evaluate/VBP the/DT self/NN talk/NN process/NN subjectively/RB using/VBG Amazon/NNP Mechanical/NNP Turk/NNP ,/, which/WDT show/VBP effectiveness/NN of/IN the/DT proposed/JJ method/NN ./.
