Recent/JJ works/NNS have/VBP highlighted/VBN scale/NN invariance/NN or/CC symmetry/NN that/WDT is/VBZ present/JJ in/IN the/DT weight/NN space/NN of/IN a/DT typical/JJ deep/JJ network/NN and/CC the/DT adverse/JJ effect/NN that/IN it/PRP has/VBZ on/IN the/DT Euclidean/JJ gradient/NN based/VBN stochastic/JJ gradient/NN descent/NN optimization/NN ./.
In/IN this/DT work/NN ,/, we/PRP show/VBP that/IN these/DT and/CC other/JJ commonly/RB used/VBN deep/JJ networks/NNS ,/, such/JJ as/IN those/DT which/WDT use/VBP a/DT max/NN -/HYPH pooling/VBG and/CC sub-sampling/VBG layer/NN ,/, possess/VBP more/RBR complex/JJ forms/NNS of/IN symmetry/NN arising/VBG from/IN scaling/VBG based/VBN reparameterization/NN of/IN the/DT network/NN weights/NNS ./.
We/PRP then/RB propose/VB two/CD symmetry/NN -/HYPH invariant/JJ gradient/NN based/VBN weight/NN updates/NNS for/IN stochastic/JJ gradient/NN descent/NN based/VBN learning/NN ./.
Our/PRP$ empirical/JJ evidence/NN based/VBN on/IN the/DT MNIST/NNP dataset/NN shows/VBZ that/IN these/DT updates/NNS improve/VBP the/DT test/NN performance/NN without/IN sacrificing/VBG the/DT computational/JJ efficiency/NN of/IN the/DT weight/NN updates/NNS ./.
We/PRP also/RB show/VBP the/DT results/NNS of/IN training/NN with/IN one/CD of/IN the/DT proposed/VBN weight/NN updates/NNS on/IN an/DT image/NN segmentation/NN problem/NN ./.
