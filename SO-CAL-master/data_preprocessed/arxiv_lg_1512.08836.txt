Latent/JJ state/NN space/NN models/NNS are/VBP one/CD of/IN the/DT most/RBS fundamental/JJ and/CC widely/RB used/VBN tools/NNS for/IN modeling/VBG dynamical/JJ systems/NNS ./.
Traditional/JJ Maximum/JJ Likelihood/NN Estimation/NN (/-LRB- MLE/NNP )/-RRB- based/VBN approaches/NNS aim/VBP to/TO maximize/VB the/DT likelihood/NN objective/NN ,/, which/WDT is/VBZ non-convex/NN due/IN to/IN latent/JJ states/NNS ./.
While/IN non-convex/JJ optimization/NN methods/NNS like/IN EM/NNP can/MD learn/VB models/NNS that/WDT locally/RB optimize/VBP the/DT likelihood/NN objective/NN ,/, using/VBG the/DT locally/RB optimal/JJ model/NN for/IN an/DT inference/NN task/NN such/JJ as/IN Bayesian/JJ filtering/NN usually/RB does/VBZ not/RB have/VB performance/NN guarantees/NNS ./.
In/IN this/DT work/NN ,/, we/PRP propose/VBP a/DT method/NN that/WDT considers/VBZ the/DT inference/NN procedure/NN on/IN the/DT dynamical/JJ system/NN as/IN a/DT composition/NN of/IN predictors/NNS ./.
Instead/RB of/IN optimizing/VBG a/DT given/VBN parametrization/NN of/IN latent/JJ states/NNS ,/, we/PRP learn/VBP predictors/NNS for/IN inference/NN in/IN predictive/JJ belief/NN space/NN ,/, where/WRB we/PRP can/MD use/VB sufficient/JJ features/NNS of/IN observations/NNS for/IN supervision/NN of/IN our/PRP$ learning/NN algorithm/NN ./.
We/PRP further/RB show/VBP that/IN our/PRP$ algorithm/NN ,/, the/DT Predictive/NNP State/NNP Inference/NNP Machine/NNP ,/, has/VBZ theoretical/JJ performance/NN guarantees/NNS on/IN the/DT inference/NN task/NN ./.
Empirical/JJ verification/NN across/IN several/JJ of/IN dynamical/JJ system/NN benchmarks/NNS ranging/VBG from/IN a/DT simulated/JJ helicopter/NN to/IN recorded/VBN telemetry/NN traces/NNS from/IN a/DT robot/NN showcase/VB the/DT abilities/NNS of/IN training/NN Inference/NN Machines/NNS ./.
