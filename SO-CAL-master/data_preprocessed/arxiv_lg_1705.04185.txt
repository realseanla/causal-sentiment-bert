In/IN this/DT paper/NN we/PRP present/VBP the/DT first/JJ empirical/JJ study/NN of/IN the/DT emphatic/JJ temporal/JJ -/HYPH difference/NN learning/NN algorithm/NN (/-LRB- ETD/NN )/-RRB- ,/, comparing/VBG it/PRP with/IN conventional/JJ temporal/JJ -/HYPH difference/NN learning/NN ,/, in/IN particular/JJ ,/, with/IN linear/JJ TD/NN (/-LRB- 0/CD )/-RRB- ,/, on/IN on/IN -/HYPH policy/NN and/CC off/IN -/HYPH policy/NN variations/NNS of/IN the/DT Mountain/NNP Car/NN problem/NN ./.
The/DT initial/JJ motivation/NN for/IN developing/VBG ETD/NNP was/VBD that/IN it/PRP has/VBZ good/JJ convergence/NN properties/NNS under/IN \/SYM emph/NN {/-LRB- off/IN }/-RRB- -/HYPH policy/NN training/NN (/-LRB- Sutton/NNP ,/, Mahmood/NNP \/NNP &amp;/CC White/NNP 2016/CD )/-RRB- ,/, but/CC it/PRP is/VBZ also/RB a/DT new/JJ algorithm/NN for/IN the/DT \/SYM emph/NN {/-LRB- on/IN }/-RRB- -/HYPH policy/NN case/NN ./.
In/IN both/CC our/PRP$ on/IN -/HYPH policy/NN and/CC off/IN -/HYPH policy/NN experiments/NNS ,/, we/PRP found/VBD that/IN each/DT method/NN converged/VBD to/IN a/DT characteristic/JJ asymptotic/JJ level/NN of/IN error/NN ,/, with/IN ETD/NN better/JJR than/IN TD/NN (/-LRB- 0/CD )/-RRB- ./.
TD/NN (/-LRB- 0/CD )/-RRB- achieved/VBD a/DT still/RB lower/JJR error/NN level/NN temporarily/RB before/IN falling/VBG back/RB to/IN its/PRP$ higher/JJR asymptote/NN ,/, whereas/IN ETD/NNP never/RB showed/VBD this/DT kind/NN of/IN "/`` bounce/NN "/'' ./.
In/IN the/DT off/NN -/HYPH policy/NN case/NN (/-LRB- in/IN which/WDT TD/NN (/-LRB- 0/CD )/-RRB- is/VBZ not/RB guaranteed/VBN to/TO converge/VB )/-RRB- ,/, ETD/NNP was/VBD significantly/RB slower/JJR ./.
