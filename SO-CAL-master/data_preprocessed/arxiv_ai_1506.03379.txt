Transferring/VBG knowledge/NN across/IN a/DT sequence/NN of/IN related/JJ tasks/NNS is/VBZ an/DT important/JJ challenge/NN in/IN reinforcement/NN learning/NN ./.
Despite/IN much/JJ encouraging/JJ empirical/JJ evidence/NN that/WDT shows/VBZ benefits/NNS of/IN transfer/NN ,/, there/EX has/VBZ been/VBN very/RB little/JJ theoretical/JJ analysis/NN ./.
In/IN this/DT paper/NN ,/, we/PRP study/VBP a/DT class/NN of/IN lifelong/JJ reinforcement/NN -/HYPH learning/NN problems/NNS :/: the/DT agent/NN solves/VBZ a/DT sequence/NN of/IN tasks/NNS modeled/VBN as/IN finite/JJ Markov/NNP decision/NN processes/NNS (/-LRB- MDPs/NNS )/-RRB- ,/, each/DT of/IN which/WDT is/VBZ from/IN a/DT finite/NN set/NN of/IN MDPs/NNS with/IN the/DT same/JJ state/NN //HYPH action/NN spaces/NNS and/CC different/JJ transition/NN //HYPH reward/NN functions/NNS ./.
Inspired/VBN by/IN the/DT need/NN for/IN cross-task/JJ exploration/NN in/IN lifelong/JJ learning/NN ,/, we/PRP formulate/VBP a/DT novel/JJ online/JJ discovery/NN problem/NN and/CC give/VB an/DT optimal/JJ learning/NN algorithm/NN to/TO solve/VB it/PRP ./.
Such/JJ results/NNS allow/VBP us/PRP to/TO develop/VB a/DT new/JJ lifelong/JJ reinforcement/NN -/HYPH learning/VBG algorithm/NN ,/, whose/WP$ overall/JJ sample/NN complexity/NN in/IN a/DT sequence/NN of/IN tasks/NNS is/VBZ much/RB smaller/JJR than/IN that/DT of/IN single/JJ -/HYPH task/NN learning/NN ,/, with/IN high/JJ probability/NN ,/, even/RB if/IN the/DT sequence/NN of/IN tasks/NNS is/VBZ generated/VBN by/IN an/DT adversary/NN ./.
Benefits/NNS of/IN the/DT algorithm/NN are/VBP demonstrated/VBN in/IN a/DT simulated/JJ problem/NN ./.
