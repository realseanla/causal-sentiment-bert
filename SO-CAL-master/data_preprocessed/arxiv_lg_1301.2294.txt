This/DT paper/NN presents/VBZ a/DT new/JJ deterministic/JJ approximation/NN technique/NN in/IN Bayesian/JJ networks/NNS ./.
This/DT method/NN ,/, "/'' Expectation/NNP Propagation/NNP "/'' ,/, unifies/VBZ two/CD previous/JJ techniques/NNS :/: assumed/VBN -/HYPH density/NN filtering/NN ,/, an/DT extension/NN of/IN the/DT Kalman/NNP filter/NN ,/, and/CC loopy/JJ belief/NN propagation/NN ,/, an/DT extension/NN of/IN belief/NN propagation/NN in/IN Bayesian/JJ networks/NNS ./.
All/DT three/CD algorithms/NNS try/VBP to/TO recover/VB an/DT approximate/JJ distribution/NN which/WDT is/VBZ close/JJ in/IN KL/NN divergence/NN to/IN the/DT true/JJ distribution/NN ./.
Loopy/JJ belief/NN propagation/NN ,/, because/IN it/PRP propagates/VBZ exact/JJ belief/NN states/NNS ,/, is/VBZ useful/JJ for/IN a/DT limited/JJ class/NN of/IN belief/NN networks/NNS ,/, such/JJ as/IN those/DT which/WDT are/VBP purely/RB discrete/JJ ./.
Expectation/NN Propagation/NN approximates/VBZ the/DT belief/NN states/NNS by/IN only/RB retaining/VBG certain/JJ expectations/NNS ,/, such/JJ as/IN mean/NN and/CC variance/NN ,/, and/CC iterates/VBZ until/IN these/DT expectations/NNS are/VBP consistent/JJ throughout/IN the/DT network/NN ./.
This/DT makes/VBZ it/PRP applicable/JJ to/IN hybrid/NN networks/NNS with/IN discrete/JJ and/CC continuous/JJ nodes/NNS ./.
Expectation/NN Propagation/NN also/RB extends/VBZ belief/NN propagation/NN in/IN the/DT opposite/JJ direction/NN -/, it/PRP can/MD propagate/VB richer/JJR belief/NN states/NNS that/WDT incorporate/VBP correlations/NNS between/IN nodes/NNS ./.
Experiments/NNS with/IN Gaussian/JJ mixture/NN models/NNS show/VBP Expectation/NNP Propagation/NNP to/TO be/VB convincingly/RB better/JJR than/IN methods/NNS with/IN similar/JJ computational/JJ cost/NN :/: Laplace/NNP 's/POS method/NN ,/, variational/NNP Bayes/NNP ,/, and/CC Monte/NNP Carlo/NNP ./.
Expectation/NN Propagation/NN also/RB provides/VBZ an/DT efficient/JJ algorithm/NN for/IN training/NN Bayes/NNS point/VBP machine/NN classifiers/NNS ./.
