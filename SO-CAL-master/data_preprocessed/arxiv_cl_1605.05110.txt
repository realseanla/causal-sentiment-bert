Modeling/VBG human/JJ conversations/NNS is/VBZ the/DT essence/NN for/IN building/VBG satisfying/VBG chat/NN -/HYPH bots/NNS with/IN multi-turn/JJ dialog/NN ability/NN ./.
Conversation/NN modeling/NN will/MD notably/RB benefit/VB from/IN domain/NN knowledge/NN since/IN the/DT relationships/NNS between/IN sentences/NNS can/MD be/VB clarified/VBN due/IN to/IN semantic/JJ hints/NNS introduced/VBN by/IN knowledge/NN ./.
In/IN this/DT paper/NN ,/, a/DT deep/JJ neural/JJ network/NN is/VBZ proposed/VBN to/TO incorporate/VB background/NN knowledge/NN for/IN conversation/NN modeling/NN ./.
Through/IN a/DT specially/RB designed/VBN Recall/NNP gate/NN ,/, domain/NN knowledge/NN can/MD be/VB transformed/VBN into/IN the/DT extra/JJ global/JJ memory/NN of/IN Long/JJ Short/JJ -/HYPH Term/NN Memory/NN (/-LRB- LSTM/NN )/-RRB- ,/, so/RB as/IN to/TO enhance/VB LSTM/NNP by/IN cooperating/VBG with/IN its/PRP$ local/JJ memory/NN to/TO capture/VB the/DT implicit/JJ semantic/JJ relevance/NN between/IN sentences/NNS within/IN conversations/NNS ./.
In/IN addition/NN ,/, this/DT paper/NN introduces/VBZ the/DT loose/JJ structured/JJ domain/NN knowledge/NN base/NN ,/, which/WDT can/MD be/VB built/VBN with/IN slight/JJ amount/NN of/IN manual/JJ work/NN and/CC easily/RB adopted/VBN by/IN the/DT Recall/NNP gate/NN ./.
Our/PRP$ model/NN is/VBZ evaluated/VBN on/IN the/DT context/NN -/HYPH oriented/VBN response/NN selecting/VBG task/NN ,/, and/CC experimental/JJ results/NNS on/IN both/DT two/CD datasets/NNS have/VBP shown/VBN that/IN our/PRP$ approach/NN is/VBZ promising/VBG for/IN modeling/VBG human/JJ conversations/NNS and/CC building/VBG key/JJ components/NNS of/IN automatic/JJ chatting/VBG systems/NNS ./.
