Metric/NNP learning/VBG seeks/VBZ a/DT transformation/NN of/IN the/DT feature/NN space/NN that/WDT enhances/VBZ prediction/NN quality/NN for/IN the/DT given/VBN task/NN at/IN hand/NN ./.
In/IN this/DT work/NN we/PRP provide/VBP PAC/NN -/HYPH style/NN sample/NN complexity/NN rates/NNS for/IN supervised/JJ metric/JJ learning/NN ./.
We/PRP give/VBP matching/VBG lower/JJR -/HYPH and/CC upper/JJ -/HYPH bounds/NNS showing/VBG that/IN the/DT sample/NN complexity/NN scales/NNS with/IN the/DT representation/NN dimension/NN when/WRB no/DT assumptions/NNS are/VBP made/VBN about/IN the/DT underlying/VBG data/NNS distribution/NN ./.
However/RB ,/, by/IN leveraging/VBG the/DT structure/NN of/IN the/DT data/NNS distribution/NN ,/, we/PRP show/VBP that/IN one/PRP can/MD achieve/VB rates/NNS that/WDT are/VBP fine/JJ -/HYPH tuned/VBN to/IN a/DT specific/JJ notion/NN of/IN intrinsic/JJ complexity/NN for/IN a/DT given/VBN dataset/NN ./.
Our/PRP$ analysis/NN reveals/VBZ that/IN augmenting/VBG the/DT metric/JJ learning/NN optimization/NN criterion/NN with/IN a/DT simple/JJ norm/NN -/HYPH based/VBN regularization/NN can/MD help/VB adapt/VB to/IN a/DT dataset/NN 's/POS intrinsic/JJ complexity/NN ,/, yielding/VBG better/JJR generalization/NN ./.
Experiments/NNS on/IN benchmark/NN datasets/NNS validate/VBP our/PRP$ analysis/NN and/CC show/VBP that/IN regularizing/VBG the/DT metric/JJ can/MD help/VB discern/VB the/DT signal/NN even/RB when/WRB the/DT data/NN contains/VBZ high/JJ amounts/NNS of/IN noise/NN ./.
