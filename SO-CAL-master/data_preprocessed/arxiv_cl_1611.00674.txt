We/PRP figure/VBP out/RP a/DT trap/NN that/WDT is/VBZ not/RB carefully/RB addressed/VBN in/IN the/DT previous/JJ works/NNS using/VBG lexicons/NNS or/CC ontologies/NNS to/TO train/VB or/CC improve/VB distributed/VBN word/NN representations/NNS :/: For/IN polysemantic/JJ words/NNS and/CC utterances/NNS changing/VBG meaning/NN in/IN different/JJ contexts/NNS ,/, their/PRP$ paraphrases/NNS or/CC related/VBN entities/NNS in/IN a/DT lexicon/NN or/CC an/DT ontology/NN are/VBP unreliable/JJ and/CC sometimes/RB deteriorate/VBP the/DT learning/NN of/IN word/NN representations/NNS ./.
Thus/RB ,/, we/PRP propose/VBP an/DT approach/NN to/TO address/VB the/DT problem/NN that/WDT considers/VBZ each/DT paraphrase/NN of/IN a/DT word/NN in/IN a/DT lexicon/NN not/RB fully/RB a/DT paraphrase/NN ,/, but/CC a/DT fuzzy/JJ member/NN (/-LRB- i.e./FW ,/, fuzzy/JJ paraphrase/NN )/-RRB- in/IN the/DT paraphrase/NN set/NN whose/WP$ degree/NN of/IN truth/NN (/-LRB- i.e./FW ,/, membership/NN )/-RRB- depends/VBZ on/IN the/DT contexts/NNS ./.
Then/RB we/PRP propose/VBP an/DT efficient/JJ method/NN to/TO use/VB the/DT fuzzy/JJ paraphrases/NNS to/TO learn/VB word/NN embeddings/NNS ./.
We/PRP approximately/RB estimate/VBP the/DT local/JJ membership/NN of/IN paraphrases/NNS ,/, and/CC train/NN word/NN embeddings/NNS using/VBG a/DT lexicon/NN jointly/RB by/IN replacing/VBG the/DT words/NNS in/IN the/DT contexts/NNS with/IN their/PRP$ paraphrases/NNS randomly/RB subject/JJ to/IN the/DT membership/NN of/IN each/DT paraphrase/NN ./.
The/DT experimental/JJ results/NNS show/VBP that/IN our/PRP$ method/NN is/VBZ efficient/JJ ,/, overcomes/VBZ the/DT weakness/NN of/IN the/DT previous/JJ related/JJ works/NNS in/IN extracting/VBG semantic/JJ information/NN and/CC outperforms/VBZ the/DT previous/JJ works/NNS of/IN learning/VBG word/NN representations/NNS using/VBG lexicons/NNS ./.
