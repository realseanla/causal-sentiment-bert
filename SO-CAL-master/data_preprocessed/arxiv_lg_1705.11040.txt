We/PRP introduce/VBP neural/JJ networks/NNS for/IN end/NN -/HYPH to/IN -/HYPH end/NN differentiable/JJ theorem/NN proving/VBG that/IN operate/VB on/IN dense/JJ vector/NN representations/NNS of/IN symbols/NNS ./.
These/DT neural/JJ networks/NNS are/VBP constructed/VBN recursively/RB by/IN taking/VBG inspiration/NN from/IN the/DT backward/JJ chaining/VBG algorithm/NN as/IN used/VBN in/IN Prolog/NNP ./.
Specifically/RB ,/, we/PRP replace/VBP symbolic/JJ unification/NN with/IN a/DT differentiable/JJ computation/NN on/IN vector/NN representations/NNS of/IN symbols/NNS using/VBG a/DT radial/JJ basis/NN function/NN kernel/NN ,/, thereby/RB combining/VBG symbolic/JJ reasoning/NN with/IN learning/VBG subsymbolic/JJ vector/NN representations/NNS ./.
By/IN using/VBG gradient/NN descent/NN ,/, the/DT resulting/VBG neural/JJ network/NN can/MD be/VB trained/VBN to/TO infer/VB facts/NNS from/IN a/DT given/VBN incomplete/JJ knowledge/NN base/NN ./.
It/PRP learns/VBZ to/IN (/-LRB- i/LS )/-RRB- place/NN representations/NNS of/IN similar/JJ symbols/NNS in/IN close/JJ proximity/NN in/IN a/DT vector/NN space/NN ,/, (/-LRB- ii/LS )/-RRB- make/VB use/NN of/IN such/JJ similarities/NNS to/TO prove/VB facts/NNS ,/, (/-LRB- iii/LS )/-RRB- induce/VB logical/JJ rules/NNS ,/, and/CC (/-LRB- iv/NN )/-RRB- use/VBP provided/VBN and/CC induced/VBN logical/JJ rules/NNS for/IN complex/JJ multi-hop/JJ reasoning/NN ./.
We/PRP demonstrate/VBP that/IN this/DT architecture/NN outperforms/VBZ ComplEx/NN ,/, a/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN neural/JJ link/NN prediction/NN model/NN ,/, on/IN four/CD benchmark/NN knowledge/NN bases/NNS while/IN at/IN the/DT same/JJ time/NN inducing/VBG interpretable/JJ function/NN -/HYPH free/JJ first/JJ -/HYPH order/NN logic/NN rules/NNS ./.
