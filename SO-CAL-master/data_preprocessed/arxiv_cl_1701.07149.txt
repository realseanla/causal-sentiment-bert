We/PRP study/VBP multi-turn/JJ response/NN generation/NN in/IN chatbots/NNS where/WRB a/DT response/NN is/VBZ generated/VBN according/VBG to/IN a/DT conversation/NN context/NN ./.
Existing/VBG work/NN has/VBZ modeled/VBN the/DT hierarchy/NN of/IN the/DT context/NN ,/, but/CC does/VBZ not/RB pay/VB enough/JJ attention/NN to/IN the/DT fact/NN that/IN words/NNS and/CC utterances/NNS in/IN the/DT context/NN are/VBP differentially/RB important/JJ ./.
As/IN a/DT result/NN ,/, they/PRP may/MD lose/VB important/JJ information/NN in/IN context/NN and/CC generate/VBP irrelevant/JJ responses/NNS ./.
We/PRP propose/VBP a/DT hierarchical/JJ recurrent/JJ attention/NN network/NN (/-LRB- HRAN/NN )/-RRB- to/TO model/VB both/DT aspects/NNS in/IN a/DT unified/JJ framework/NN ./.
In/IN HRAN/NNP ,/, a/DT hierarchical/JJ attention/NN mechanism/NN attends/VBZ to/IN important/JJ parts/NNS within/IN and/CC among/IN utterances/NNS with/IN word/NN level/NN attention/NN and/CC utterance/NN level/NN attention/NN respectively/RB ./.
With/IN the/DT word/NN level/NN attention/NN ,/, hidden/VBN vectors/NNS of/IN a/DT word/NN level/NN encoder/NN are/VBP synthesized/VBN as/IN utterance/NN vectors/NNS and/CC fed/VBN to/IN an/DT utterance/NN level/NN encoder/NN to/TO construct/VB hidden/JJ representations/NNS of/IN the/DT context/NN ./.
The/DT hidden/JJ vectors/NNS of/IN the/DT context/NN are/VBP then/RB processed/VBN by/IN the/DT utterance/NN level/NN attention/NN and/CC formed/VBN as/IN context/NN vectors/NNS for/IN decoding/VBG the/DT response/NN ./.
Empirical/JJ studies/NNS on/IN both/DT automatic/JJ evaluation/NN and/CC human/JJ judgment/NN show/NN that/WDT HRAN/NNP can/MD significantly/RB outperform/VB state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN models/NNS for/IN multi-turn/JJ response/NN generation/NN ./.
