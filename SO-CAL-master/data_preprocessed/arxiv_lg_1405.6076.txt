We/PRP present/VBP a/DT new/JJ optimization/NN -/HYPH theoretic/JJ approach/NN to/IN analyzing/VBG Follow/VB -/HYPH the/DT -/HYPH Leader/NN style/NN algorithms/NNS ,/, particularly/RB in/IN the/DT setting/NN where/WRB perturbations/NNS are/VBP used/VBN as/IN a/DT tool/NN for/IN regularization/NN ./.
We/PRP show/VBP that/IN adding/VBG a/DT strongly/RB convex/JJ penalty/NN function/NN to/IN the/DT decision/NN rule/NN and/CC adding/VBG stochastic/JJ perturbations/NNS to/IN data/NNS correspond/VBP to/IN deterministic/JJ and/CC stochastic/JJ smoothing/NN operations/NNS ,/, respectively/RB ./.
We/PRP establish/VBP an/DT equivalence/NN between/IN "/`` Follow/VB the/DT Regularized/NNP Leader/NNP "/'' and/CC "/`` Follow/VB the/DT Perturbed/NNP Leader/NNP "/'' up/RP to/IN the/DT smoothness/NN properties/NNS ./.
This/DT intuition/NN leads/VBZ to/IN a/DT new/JJ generic/JJ analysis/NN framework/NN that/WDT recovers/VBZ and/CC improves/VBZ the/DT previous/JJ known/VBN regret/NN bounds/NNS of/IN the/DT class/NN of/IN algorithms/NNS commonly/RB known/VBN as/IN Follow/VB the/DT Perturbed/NNP Leader/NNP ./.
