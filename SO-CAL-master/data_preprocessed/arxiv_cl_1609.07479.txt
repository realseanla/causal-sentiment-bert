Distantly/RB supervised/JJ relation/NN extraction/NN has/VBZ been/VBN widely/RB used/VBN to/TO find/VB novel/JJ relational/JJ facts/NNS from/IN plain/JJ text/NN ./.
To/TO predict/VB the/DT relation/NN between/IN a/DT pair/NN of/IN two/CD target/NN entities/NNS ,/, existing/VBG methods/NNS solely/RB rely/VBP on/IN those/DT direct/JJ sentences/NNS containing/VBG both/CC entities/NNS ./.
In/IN fact/NN ,/, there/EX are/VBP also/RB many/JJ sentences/NNS containing/VBG only/RB one/CD of/IN the/DT target/NN entities/NNS ,/, which/WDT provide/VBP rich/JJ and/CC useful/JJ information/NN for/IN relation/NN extraction/NN ./.
To/TO address/VB this/DT issue/NN ,/, we/PRP build/VBP inference/NN chains/NNS between/IN two/CD target/NN entities/NNS via/IN intermediate/JJ entities/NNS ,/, and/CC propose/VB a/DT path/NN -/HYPH based/VBN neural/JJ relation/NN extraction/NN model/NN to/TO encode/VB the/DT relational/JJ semantics/NNS from/IN both/DT direct/JJ sentences/NNS and/CC inference/NN chains/NNS ./.
Experimental/JJ results/NNS on/IN real/JJ -/HYPH world/NN datasets/NNS show/VBP that/IN ,/, our/PRP$ model/NN can/MD make/VB full/JJ use/NN of/IN those/DT sentences/NNS containing/VBG only/RB one/CD target/NN entity/NN ,/, and/CC achieves/VBZ significant/JJ and/CC consistent/JJ improvements/NNS on/IN relation/NN extraction/NN as/IN compared/VBN with/IN baselines/NNS ./.
