The/DT ability/NN to/TO map/VB descriptions/NNS of/IN scenes/NNS to/IN 3D/JJ geometric/JJ representations/NNS has/VBZ many/JJ applications/NNS in/IN areas/NNS such/JJ as/IN art/NN ,/, education/NN ,/, and/CC robotics/NNS ./.
However/RB ,/, prior/JJ work/NN on/IN the/DT text/NN to/IN 3D/JJ scene/NN generation/NN task/NN has/VBZ used/VBN manually/RB specified/VBN object/NN categories/NNS and/CC language/NN that/WDT identifies/VBZ them/PRP ./.
We/PRP introduce/VBP a/DT dataset/NN of/IN 3D/JJ scenes/NNS annotated/VBN with/IN natural/JJ language/NN descriptions/NNS and/CC learn/VB from/IN this/DT data/NNS how/WRB to/TO ground/VB textual/JJ descriptions/NNS to/IN physical/JJ objects/NNS ./.
Our/PRP$ method/NN successfully/RB grounds/NNS a/DT variety/NN of/IN lexical/JJ terms/NNS to/IN concrete/JJ referents/NNS ,/, and/CC we/PRP show/VBP quantitatively/RB that/IN our/PRP$ method/NN improves/VBZ 3D/JJ scene/NN generation/NN over/IN previous/JJ work/NN using/VBG purely/RB rule/NN -/HYPH based/VBN methods/NNS ./.
We/PRP evaluate/VBP the/DT fidelity/NN and/CC plausibility/NN of/IN 3D/JJ scenes/NNS generated/VBN with/IN our/PRP$ grounding/NN approach/NN through/IN human/JJ judgments/NNS ./.
To/TO ease/VB evaluation/NN on/IN this/DT task/NN ,/, we/PRP also/RB introduce/VBP an/DT automated/VBN metric/NN that/WDT strongly/RB correlates/VBZ with/IN human/JJ judgments/NNS ./.
