This/DT paper/NN addresses/VBZ the/DT issue/NN of/IN model/NN selection/NN for/IN hidden/JJ Markov/NNP models/NNS (/-LRB- HMMs/NNS )/-RRB- ./.
We/PRP generalize/VBP factorized/VBN asymptotic/JJ Bayesian/JJ inference/NN (/-LRB- FAB/NN )/-RRB- ,/, which/WDT has/VBZ been/VBN recently/RB developed/VBN for/IN model/NN selection/NN on/IN independent/JJ hidden/JJ variables/NNS (/-LRB- i.e./FW ,/, mixture/NN models/NNS )/-RRB- ,/, for/IN time/NN -/HYPH dependent/JJ hidden/JJ variables/NNS ./.
As/IN with/IN FAB/NNP in/IN mixture/NN models/NNS ,/, FAB/NNP for/IN HMMs/NNPS is/VBZ derived/VBN as/IN an/DT iterative/JJ lower/JJR bound/JJ maximization/NN algorithm/NN of/IN a/DT factorized/JJ information/NN criterion/NN (/-LRB- FIC/NN )/-RRB- ./.
It/PRP inherits/VBZ ,/, from/IN FAB/NNP for/IN mixture/NN models/NNS ,/, several/JJ desirable/JJ properties/NNS for/IN learning/VBG HMMs/NNS ,/, such/JJ as/IN asymptotic/JJ consistency/NN of/IN FIC/NNP with/IN marginal/JJ log/NN -/HYPH likelihood/NN ,/, a/DT shrinkage/NN effect/NN for/IN hidden/JJ state/NN selection/NN ,/, monotonic/JJ increase/NN of/IN the/DT lower/JJR FIC/NN bound/VBN through/IN the/DT iterative/JJ optimization/NN ./.
Further/RB ,/, it/PRP does/VBZ not/RB have/VB a/DT tunable/JJ hyper/JJ -/HYPH parameter/NN ,/, and/CC thus/RB its/PRP$ model/NN selection/NN process/NN can/MD be/VB fully/RB automated/VBN ./.
Experimental/JJ results/NNS shows/VBZ that/IN FAB/NNP outperforms/VBZ states/NNS -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN variational/JJ Bayesian/JJ HMM/NN and/CC non-parametric/JJ Bayesian/JJ HMM/NN in/IN terms/NNS of/IN model/NN selection/NN accuracy/NN and/CC computational/JJ efficiency/NN ./.
