Question/NN answering/NN forums/NNS are/VBP rapidly/RB growing/VBG in/IN size/NN with/IN no/DT automated/VBN ability/NN to/TO refer/VB to/IN and/CC reuse/VB existing/VBG answers/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP develop/VBP a/DT methodology/NN for/IN finding/VBG semantically/RB related/JJ questions/NNS ./.
The/DT task/NN is/VBZ difficult/JJ since/IN 1/CD )/-RRB- key/JJ pieces/NNS of/IN information/NN are/VBP often/RB buried/VBN in/IN extraneous/JJ detail/NN in/IN the/DT question/NN body/NN and/CC 2/CD )/-RRB- available/JJ annotations/NNS are/VBP scarce/JJ and/CC fragmented/JJ ,/, driven/VBN by/IN participants/NNS ./.
We/PRP design/VBP a/DT novel/JJ combination/NN of/IN recurrent/JJ and/CC convolutional/JJ models/NNS (/-LRB- gated/VBN convolutions/NNS )/-RRB- to/TO effectively/RB map/VB questions/NNS to/IN their/PRP$ semantic/JJ representations/NNS ./.
The/DT models/NNS are/VBP pre-trained/VBN within/IN an/DT encoder/NN -/HYPH decoder/NN framework/NN (/-LRB- from/IN body/NN to/IN title/NN )/-RRB- on/IN the/DT basis/NN of/IN the/DT entire/JJ raw/JJ corpus/NN ,/, and/CC fine/JJ -/HYPH tuned/VBN discriminatively/RB from/IN limited/JJ annotations/NNS ./.
Our/PRP$ evaluation/NN demonstrates/VBZ that/IN our/PRP$ model/NN yields/NNS 10/CD \/SYM percent/NN gain/NN over/IN a/DT standard/JJ IR/NN baseline/NN ,/, and/CC 6/CD \/SYM percent/NN over/IN standard/JJ neural/JJ network/NN architectures/NNS (/-LRB- including/VBG CNNs/NNS and/CC LSTMs/NNS )/-RRB- trained/VBN analogously/RB ./.
