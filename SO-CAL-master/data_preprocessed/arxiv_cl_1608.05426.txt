While/IN cross-lingual/JJ word/NN embeddings/NNS have/VBP been/VBN studied/VBN extensively/RB in/IN recent/JJ years/NNS ,/, the/DT qualitative/JJ differences/NNS between/IN the/DT different/JJ algorithms/NNS remains/VBZ vague/JJ ./.
We/PRP observe/VBP that/IN whether/IN or/CC not/RB an/DT algorithm/NN uses/VBZ a/DT particular/JJ feature/NN set/NN (/-LRB- sentence/NN IDs/NNS )/-RRB- accounts/VBZ for/IN a/DT significant/JJ performance/NN gap/NN among/IN these/DT algorithms/NNS ./.
This/DT feature/NN set/NN is/VBZ also/RB used/VBN by/IN traditional/JJ alignment/NN algorithms/NNS ,/, such/JJ as/IN IBM/NNP Model/NNP -/HYPH 1/CD ,/, which/WDT demonstrate/VBP similar/JJ performance/NN to/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN embedding/NN algorithms/NNS on/IN a/DT variety/NN of/IN benchmarks/NNS ./.
Overall/RB ,/, we/PRP observe/VBP that/IN different/JJ algorithmic/JJ approaches/NNS for/IN utilizing/VBG the/DT sentence/NN ID/NN feature/NN space/NN result/NN in/IN similar/JJ performance/NN ./.
This/DT paper/NN draws/VBZ both/CC empirical/JJ and/CC theoretical/JJ parallels/NNS between/IN the/DT embedding/NN and/CC alignment/NN literature/NN ,/, and/CC suggests/VBZ that/IN adding/VBG additional/JJ sources/NNS of/IN information/NN ,/, which/WDT go/VBP beyond/IN the/DT traditional/JJ signal/NN of/IN bilingual/JJ sentence/NN -/HYPH aligned/VBN corpora/NNS ,/, is/VBZ an/DT appealing/JJ approach/NN for/IN substantially/RB improving/VBG crosslingual/JJ word/NN embeddings/NNS ./.
