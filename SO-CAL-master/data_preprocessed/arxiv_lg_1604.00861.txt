In/IN this/DT paper/NN we/PRP present/VBP an/DT approach/NN to/IN polyphonic/JJ sound/NN event/NN detection/NN in/IN real/JJ life/NN recordings/NNS based/VBN on/IN bi-directional/JJ long/JJ short/JJ term/NN memory/NN (/-LRB- BLSTM/NN )/-RRB- recurrent/JJ neural/JJ networks/NNS (/-LRB- RNNs/NNS )/-RRB- ./.
A/DT single/JJ multilabel/NN BLSTM/NNP RNN/NNP is/VBZ trained/VBN to/TO map/VB acoustic/JJ features/NNS of/IN a/DT mixture/NN signal/NN consisting/VBG of/IN sounds/NNS from/IN multiple/JJ classes/NNS ,/, to/IN binary/JJ activity/NN indicators/NNS of/IN each/DT event/NN class/NN ./.
Our/PRP$ method/NN is/VBZ tested/VBN on/IN a/DT large/JJ database/NN of/IN real/JJ -/HYPH life/NN recordings/NNS ,/, with/IN 61/CD classes/NNS (/-LRB- e.g./FW music/NN ,/, car/NN ,/, speech/NN )/-RRB- from/IN 10/CD different/JJ everyday/JJ contexts/NNS ./.
The/DT proposed/JJ method/NN outperforms/VBZ previous/JJ approaches/NNS by/IN a/DT large/JJ margin/NN ,/, and/CC the/DT results/NNS are/VBP further/RB improved/VBN using/VBG data/NNS augmentation/NN techniques/NNS ./.
Overall/RB ,/, our/PRP$ system/NN reports/VBZ an/DT average/JJ F1/NN -/HYPH score/NN of/IN 65.5/CD percent/NN on/IN 1/CD second/JJ blocks/NNS and/CC 64.7/CD percent/NN on/IN single/JJ frames/NNS ,/, a/DT relative/JJ improvement/NN over/IN previous/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN approach/NN of/IN 6.8/CD percent/NN and/CC 15.1/CD percent/NN respectively/RB ./.
