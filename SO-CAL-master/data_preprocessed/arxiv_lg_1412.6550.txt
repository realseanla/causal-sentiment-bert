While/IN depth/NN tends/VBZ to/TO improve/VB network/NN performances/NNS ,/, it/PRP also/RB makes/VBZ gradient/NN -/HYPH based/VBN training/NN more/RBR difficult/JJ since/IN deeper/JJR networks/NNS tend/VBP to/TO be/VB more/RBR non-linear/JJ ./.
The/DT recently/RB proposed/VBN knowledge/NN distillation/NN approach/NN is/VBZ aimed/VBN at/IN obtaining/VBG small/JJ and/CC fast/JJ -/HYPH to/TO -/HYPH execute/VB models/NNS ,/, and/CC it/PRP has/VBZ shown/VBN that/IN a/DT student/NN network/NN could/MD imitate/VB the/DT soft/JJ output/NN of/IN a/DT larger/JJR teacher/NN network/NN or/CC ensemble/NN of/IN networks/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP extend/VBP this/DT idea/NN to/TO allow/VB the/DT training/NN of/IN a/DT student/NN that/WDT is/VBZ deeper/JJR and/CC thinner/JJR than/IN the/DT teacher/NN ,/, using/VBG not/RB only/RB the/DT outputs/NNS but/CC also/RB the/DT intermediate/JJ representations/NNS learned/VBN by/IN the/DT teacher/NN as/IN hints/NNS to/TO improve/VB the/DT training/NN process/NN and/CC final/JJ performance/NN of/IN the/DT student/NN ./.
Because/IN the/DT student/NN intermediate/JJ hidden/JJ layer/NN will/MD generally/RB be/VB smaller/JJR than/IN the/DT teacher/NN 's/POS intermediate/JJ hidden/JJ layer/NN ,/, additional/JJ parameters/NNS are/VBP introduced/VBN to/TO map/VB the/DT student/NN hidden/VBN layer/NN to/IN the/DT prediction/NN of/IN the/DT teacher/NN hidden/VBN layer/NN ./.
This/DT allows/VBZ one/CD to/TO train/VB deeper/JJR students/NNS that/WDT can/MD generalize/VB better/JJR or/CC run/VBP faster/RBR ,/, a/DT trade/NN -/HYPH off/NN that/WDT is/VBZ controlled/VBN by/IN the/DT chosen/VBN student/NN capacity/NN ./.
For/IN example/NN ,/, on/IN CIFAR/NNP -/HYPH 10/CD ,/, a/DT deep/JJ student/NN network/NN with/IN almost/RB 10.4/CD times/NNS less/JJR parameters/NNS outperforms/VBZ a/DT larger/JJR ,/, state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN teacher/NN network/NN ./.
