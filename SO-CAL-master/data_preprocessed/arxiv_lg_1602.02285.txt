We/PRP show/VBP how/WRB deep/JJ learning/NN methods/NNS can/MD be/VB applied/VBN in/IN the/DT context/NN of/IN crowdsourcing/VBG and/CC unsupervised/JJ ensemble/NN learning/NN ./.
First/RB ,/, we/PRP prove/VBP that/IN the/DT popular/JJ model/NN of/IN Dawid/NNP and/CC Skene/NNP ,/, which/WDT assumes/VBZ that/IN all/DT classifiers/NNS are/VBP conditionally/RB independent/JJ ,/, is/VBZ {/-LRB- \/SYM em/PRP equivalent/JJ }/-RRB- to/IN a/DT Restricted/VBN Boltzmann/NNP Machine/NNP (/-LRB- RBM/NNP )/-RRB- with/IN a/DT single/JJ hidden/JJ node/NN ./.
Hence/RB ,/, under/IN this/DT model/NN ,/, the/DT posterior/JJ probabilities/NNS of/IN the/DT true/JJ labels/NNS can/MD be/VB instead/RB estimated/VBN via/IN a/DT trained/VBN RBM/NNP ./.
Next/RB ,/, to/TO address/VB the/DT more/RBR general/JJ case/NN ,/, where/WRB classifiers/NNS may/MD strongly/RB violate/VB the/DT conditional/JJ independence/NN assumption/NN ,/, we/PRP propose/VBP to/TO apply/VB RBM/NNP -/HYPH based/VBN Deep/JJ Neural/JJ Net/NN (/-LRB- DNN/NN )/-RRB- ./.
Experimental/JJ results/NNS on/IN various/JJ simulated/JJ and/CC real/JJ -/HYPH world/NN datasets/NNS demonstrate/VBP that/IN our/PRP$ proposed/VBN DNN/NN approach/NN outperforms/VBZ other/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS ,/, in/IN particular/JJ when/WRB the/DT data/NNS violates/VBZ the/DT conditional/JJ independence/NN assumption/NN ./.
