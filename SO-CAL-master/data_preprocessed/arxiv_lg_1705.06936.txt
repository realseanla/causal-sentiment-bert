The/DT asynchronous/JJ nature/NN of/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN reinforcement/NN learning/VBG algorithms/NNS such/JJ as/IN the/DT Asynchronous/JJ Advantage/NN Actor/NN -/HYPH Critic/NN algorithm/NN ,/, makes/VBZ them/PRP exceptionally/RB suitable/JJ for/IN CPU/NN computations/NNS ./.
However/RB ,/, given/VBN the/DT fact/NN that/IN deep/JJ reinforcement/NN learning/VBG often/RB deals/VBZ with/IN interpreting/VBG visual/JJ information/NN ,/, a/DT large/JJ part/NN of/IN the/DT train/NN and/CC inference/NN time/NN is/VBZ spent/VBN performing/VBG convolutions/NNS ./.
In/IN this/DT work/NN we/PRP present/VBP our/PRP$ results/NNS on/IN learning/VBG strategies/NNS in/IN Atari/NNP games/NNS using/VBG a/DT Convolutional/JJ Neural/JJ Network/NN ,/, the/DT Math/NNP Kernel/NNP Library/NNP and/CC TensorFlow/NNP 0.11/CD rc0/NN machine/NN learning/NN framework/NN ./.
We/PRP also/RB analyze/VBP effects/NNS of/IN asynchronous/JJ computations/NNS on/IN the/DT convergence/NN of/IN reinforcement/NN learning/VBG algorithms/NNS ./.
