In/IN the/DT high/JJ -/HYPH dimensional/JJ regression/NN model/NN a/DT response/NN variable/NN is/VBZ linearly/RB related/VBN to/IN $/$ p/NN $/$ covariates/NNS ,/, but/CC the/DT sample/NN size/NN $/$ n/NN $/$ is/VBZ smaller/JJR than/IN $/$ p/NN $/$ ./.
We/PRP assume/VBP that/IN only/RB a/DT small/JJ subset/NN of/IN covariates/NNS is/VBZ `/`` active/JJ '/'' (/-LRB- i.e./FW ,/, the/DT corresponding/VBG coefficients/NNS are/VBP non-zero/JJ )/-RRB- ,/, and/CC consider/VB the/DT model/NN -/HYPH selection/NN problem/NN of/IN identifying/VBG the/DT active/JJ covariates/NNS ./.
A/DT popular/JJ approach/NN is/VBZ to/TO estimate/VB the/DT regression/NN coefficients/NNS through/IN the/DT Lasso/NNP (/-LRB- $/$ \/CD ell_1/CD $/$ -/HYPH regularized/VBN least/JJS squares/NNS )/-RRB- ./.
This/DT is/VBZ known/VBN to/TO correctly/RB identify/VB the/DT active/JJ set/NN only/RB if/IN the/DT irrelevant/JJ covariates/NNS are/VBP roughly/RB orthogonal/JJ to/IN the/DT relevant/JJ ones/NNS ,/, as/IN quantified/VBN through/IN the/DT so/RB called/VBN `/`` irrepresentability/NN '/'' condition/NN ./.
In/IN this/DT paper/NN we/PRP study/VBP the/DT `/`` Gauss/NNP -/HYPH Lasso/NNP '/POS selector/NN ,/, a/DT simple/JJ two/CD -/HYPH stage/NN method/NN that/WDT first/RB solves/VBZ the/DT Lasso/NNP ,/, and/CC then/RB performs/VBZ ordinary/JJ least/JJS squares/NNS restricted/VBN to/IN the/DT Lasso/NNP active/JJ set/NN ./.
We/PRP formulate/VBP `/`` generalized/VBN irrepresentability/NN condition/NN '/'' (/-LRB- GIC/NNP )/-RRB- ,/, an/DT assumption/NN that/WDT is/VBZ substantially/RB weaker/JJR than/IN irrepresentability/NN ./.
We/PRP prove/VBP that/IN ,/, under/IN GIC/NNP ,/, the/DT Gauss/NNP -/HYPH Lasso/NNP correctly/RB recovers/VBZ the/DT active/JJ set/NN ./.
