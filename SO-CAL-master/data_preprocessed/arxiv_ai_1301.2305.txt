We/PRP consider/VBP the/DT problem/NN of/IN approximate/JJ belief/NN -/HYPH state/NN monitoring/NN using/VBG particle/NN filtering/VBG for/IN the/DT purposes/NNS of/IN implementing/VBG a/DT policy/NN for/IN a/DT partially/RB -/HYPH observable/JJ Markov/NNP decision/NN process/NN (/-LRB- POMDP/NN )/-RRB- ./.
While/IN particle/NN filtering/NN has/VBZ become/VBN a/DT widely/RB -/HYPH used/VBN tool/NN in/IN AI/NN for/IN monitoring/VBG dynamical/JJ systems/NNS ,/, rather/RB scant/JJ attention/NN has/VBZ been/VBN paid/VBN to/IN their/PRP$ use/NN in/IN the/DT context/NN of/IN decision/NN making/NN ./.
Assuming/VBG the/DT existence/NN of/IN a/DT value/NN function/NN ,/, we/PRP derive/VBP error/NN bounds/NNS on/IN decision/NN quality/NN associated/VBN with/IN filtering/NN using/VBG importance/NN sampling/NN ./.
We/PRP also/RB describe/VBP an/DT adaptive/JJ procedure/NN that/WDT can/MD be/VB used/VBN to/TO dynamically/RB determine/VB the/DT number/NN of/IN samples/NNS required/VBN to/TO meet/VB specific/JJ error/NN bounds/NNS ./.
Empirical/JJ evidence/NN is/VBZ offered/VBN supporting/VBG this/DT technique/NN as/IN a/DT profitable/JJ means/NNS of/IN directing/VBG sampling/NN effort/NN where/WRB it/PRP is/VBZ needed/VBN to/TO distinguish/VB policies/NNS ./.
