We/PRP introduce/VBP a/DT new/JJ neural/JJ architecture/NN to/TO learn/VB the/DT conditional/JJ probability/NN of/IN an/DT output/NN sequence/NN with/IN elements/NNS that/WDT are/VBP discrete/JJ tokens/NNS corresponding/VBG to/IN positions/NNS in/IN an/DT input/NN sequence/NN ./.
Such/JJ problems/NNS can/MD not/RB be/VB trivially/RB addressed/VBN by/IN existent/JJ approaches/NNS such/JJ as/IN sequence/NN -/HYPH to/IN -/HYPH sequence/NN and/CC Neural/JJ Turing/NN Machines/NNS ,/, because/IN the/DT number/NN of/IN target/NN classes/NNS in/IN each/DT step/NN of/IN the/DT output/NN depends/VBZ on/IN the/DT length/NN of/IN the/DT input/NN ,/, which/WDT is/VBZ variable/JJ ./.
Problems/NNS such/JJ as/IN sorting/VBG variable/JJ sized/JJ sequences/NNS ,/, and/CC various/JJ combinatorial/JJ optimization/NN problems/NNS belong/VBP to/IN this/DT class/NN ./.
Our/PRP$ model/NN solves/VBZ the/DT problem/NN of/IN variable/JJ size/NN output/NN dictionaries/NNS using/VBG a/DT recently/RB proposed/VBN mechanism/NN of/IN neural/JJ attention/NN ./.
It/PRP differs/VBZ from/IN the/DT previous/JJ attention/NN attempts/NNS in/IN that/DT ,/, instead/RB of/IN using/VBG attention/NN to/IN blend/NN hidden/VBN units/NNS of/IN an/DT encoder/NN to/IN a/DT context/NN vector/NN at/IN each/DT decoder/NN step/NN ,/, it/PRP uses/VBZ attention/NN as/IN a/DT pointer/NN to/TO select/VB a/DT member/NN of/IN the/DT input/NN sequence/NN as/IN the/DT output/NN ./.
We/PRP call/VBP this/DT architecture/NN a/DT Pointer/NN Net/NN (/-LRB- Ptr/NN -/HYPH Net/NN )/-RRB- ./.
We/PRP show/VBP Ptr/NN -/HYPH Nets/NNS can/MD be/VB used/VBN to/TO learn/VB approximate/JJ solutions/NNS to/IN three/CD challenging/JJ geometric/JJ problems/NNS --/: finding/VBG planar/NN convex/NN hulls/NNS ,/, computing/VBG Delaunay/NNP triangulations/NNS ,/, and/CC the/DT planar/NN Travelling/VBG Salesman/NN Problem/NN --/: using/VBG training/NN examples/NNS alone/RB ./.
Ptr/NN -/HYPH Nets/NNS not/RB only/RB improve/VB over/IN sequence/NN -/HYPH to/IN -/HYPH sequence/NN with/IN input/NN attention/NN ,/, but/CC also/RB allow/VB us/PRP to/TO generalize/VB to/IN variable/JJ size/NN output/NN dictionaries/NNS ./.
We/PRP show/VBP that/IN the/DT learnt/VBN models/NNS generalize/VB beyond/IN the/DT maximum/JJ lengths/NNS they/PRP were/VBD trained/VBN on/IN ./.
We/PRP hope/VBP our/PRP$ results/NNS on/IN these/DT tasks/NNS will/MD encourage/VB a/DT broader/JJR exploration/NN of/IN neural/JJ learning/NN for/IN discrete/JJ problems/NNS ./.
