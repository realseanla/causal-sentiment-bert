The/DT Vocal/JJ Joystick/NNP Vowel/NNP Corpus/NNP ,/, by/IN Washington/NNP University/NNP ,/, was/VBD used/VBN to/TO study/VB monophthongs/NNS pronounced/VBN by/IN native/JJ English/NNP speakers/NNS ./.
The/DT objective/NN of/IN this/DT study/NN was/VBD to/TO quantitatively/RB measure/VB the/DT extent/NN at/IN which/WDT speech/NN recognition/NN methods/NNS can/MD distinguish/VB between/IN similar/JJ sounding/VBG vowels/NNS ./.
In/IN particular/JJ ,/, the/DT phonemes/NNS //, \/SYM textipa/NN {/-LRB- @/IN }/-RRB- //SYM ,/, //SYM {/-LRB- \/SYM ae/NN }/-RRB- //HYPH ,/, //SYM \/SYM textipa/NN {/-LRB- A/NN }/-RRB- :/: //, and/CC //HYPH \/SYM textipa/NN {/-LRB- 2/CD }/-RRB- //HYPH were/VBD analysed/VBN ./.
748/CD sound/JJ files/NNS from/IN the/DT corpus/NN were/VBD used/VBN and/CC subjected/VBN to/IN Linear/NNP Predictive/NNP Coding/NNP (/-LRB- LPC/NNP )/-RRB- to/IN compute/VB their/PRP$ formants/NNS ,/, and/CC to/IN Mel/NNP Frequency/NN Cepstral/NNP Coefficients/NNS (/-LRB- MFCC/NN )/-RRB- algorithm/NN ,/, to/IN compute/VB the/DT cepstral/JJ coefficients/NNS ./.
A/DT Decision/NN Tree/NNP Classifier/NNP was/VBD used/VBN to/TO build/VB a/DT predictive/JJ model/NN that/WDT learnt/VBD the/DT patterns/NNS of/IN the/DT two/CD first/JJ formants/NNS measured/VBN in/IN the/DT data/NNS set/NN ,/, as/RB well/RB as/IN the/DT patterns/NNS of/IN the/DT 13/CD cepstral/JJ coefficients/NNS ./.
An/DT accuracy/NN of/IN 70/CD \/SYM percent/NN was/VBD achieved/VBN using/VBG formants/NNS for/IN the/DT mentioned/VBN phonemes/NNS ./.
For/IN the/DT MFCC/NN analysis/NN an/DT accuracy/NN of/IN 52/CD \/SYM percent/NN was/VBD achieved/VBN and/CC an/DT accuracy/NN of/IN 71/CD \/SYM percent/NN when/WRB //SYM \/SYM textipa/NN {/-LRB- @/IN }/-RRB- //, was/VBD ignored/VBN ./.
The/DT results/NNS obtained/VBN show/VBP that/IN the/DT studied/VBN algorithms/NNS are/VBP far/RB from/IN mimicking/VBG the/DT ability/NN of/IN distinguishing/VBG subtle/JJ differences/NNS in/IN sounds/NNS like/IN human/JJ hearing/NN does/VBZ ./.
