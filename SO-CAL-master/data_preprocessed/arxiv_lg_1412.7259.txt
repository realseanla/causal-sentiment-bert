In/IN this/DT paper/NN ,/, we/PRP investigate/VBP the/DT problem/NN of/IN learning/VBG feature/NN representation/NN from/IN unlabeled/JJ data/NNS using/VBG a/DT single/JJ -/HYPH layer/NN K/NN -/HYPH means/NN network/NN ./.
A/DT K/NN -/HYPH means/NN network/NN maps/VBZ the/DT input/NN data/NNS into/IN a/DT feature/NN representation/NN by/IN finding/VBG the/DT nearest/JJS centroid/NN for/IN each/DT input/NN point/NN ,/, which/WDT has/VBZ attracted/VBN researchers/NNS '/POS great/JJ attention/NN recently/RB due/IN to/IN its/PRP$ simplicity/NN ,/, effectiveness/NN ,/, and/CC scalability/NN ./.
However/RB ,/, one/CD drawback/NN of/IN this/DT feature/NN mapping/NN is/VBZ that/IN it/PRP tends/VBZ to/TO be/VB unreliable/JJ when/WRB the/DT training/NN data/NN contains/VBZ noise/NN ./.
To/TO address/VB this/DT issue/NN ,/, we/PRP propose/VBP a/DT SVDD/NNP based/VBN feature/NN learning/NN algorithm/NN that/WDT describes/VBZ the/DT density/NN and/CC distribution/NN of/IN each/DT cluster/NN from/IN K/NNP -/HYPH means/VBZ with/IN an/DT SVDD/NNP ball/NN for/IN more/JJR robust/JJ feature/NN representation/NN ./.
For/IN this/DT purpose/NN ,/, we/PRP present/VBP a/DT new/JJ SVDD/NNP algorithm/NN called/VBN C/NN -/HYPH SVDD/NN that/WDT centers/VBZ the/DT SVDD/NNP ball/NN towards/IN the/DT mode/NN of/IN local/JJ density/NN of/IN each/DT cluster/NN ,/, and/CC we/PRP show/VBP that/IN the/DT objective/NN of/IN C/NN -/HYPH SVDD/NN can/MD be/VB solved/VBN very/RB efficiently/RB as/IN a/DT linear/JJ programming/NN problem/NN ./.
Additionally/RB ,/, previous/JJ single/JJ -/HYPH layer/NN networks/NNS favor/VBP a/DT large/JJ number/NN of/IN centroids/NNS but/CC a/DT crude/NN pooling/VBG size/NN ,/, resulting/VBG in/IN a/DT representation/NN that/WDT highlights/VBZ the/DT global/JJ aspects/NNS of/IN the/DT object/NN ./.
Here/RB we/PRP explore/VB an/DT alternative/JJ network/NN architecture/NN with/IN much/RB smaller/JJR number/NN of/IN nodes/NNS but/CC with/IN much/JJ finer/JJR pooling/VBG size/NN ,/, hence/RB emphasizing/VBG the/DT local/JJ details/NNS of/IN the/DT object/NN ./.
The/DT architecture/NN is/VBZ also/RB extended/VBN with/IN multiple/JJ receptive/JJ field/NN scales/NNS and/CC multiple/JJ pooling/VBG sizes/NNS ./.
Extensive/JJ experiments/NNS on/IN several/JJ popular/JJ object/NN recognition/NN benchmarks/NNS ,/, such/JJ as/IN MINST/NNP ,/, NORB/NNP ,/, CIFAR/NNP -/HYPH 10/CD and/CC STL/NNP -/HYPH 10/CD ,/, shows/VBZ that/IN the/DT proposed/VBN C/NN -/HYPH SVDDNet/NN method/NN yields/NNS comparable/JJ or/CC better/JJR performance/NN than/IN that/DT of/IN the/DT previous/JJ state/NN of/IN the/DT art/NN methods/NNS ./.
