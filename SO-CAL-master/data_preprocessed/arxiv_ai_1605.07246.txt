The/DT alternating/VBG direction/NN method/NN of/IN multipliers/NNS (/-LRB- ADMM/NN )/-RRB- is/VBZ a/DT versatile/JJ tool/NN for/IN solving/VBG a/DT wide/JJ range/NN of/IN constrained/VBN optimization/NN problems/NNS ,/, with/IN differentiable/JJ or/CC non-differentiable/JJ objective/JJ functions/NNS ./.
Unfortunately/RB ,/, its/PRP$ performance/NN is/VBZ highly/RB sensitive/JJ to/IN a/DT penalty/NN parameter/NN ,/, which/WDT makes/VBZ ADMM/NN often/RB unreliable/JJ and/CC hard/JJ to/TO automate/VB for/IN a/DT non-expert/NN user/NN ./.
We/PRP tackle/VBP this/DT weakness/NN of/IN ADMM/NNP by/IN proposing/VBG a/DT method/NN to/TO adaptively/RB tune/VB the/DT penalty/NN parameters/NNS to/TO achieve/VB fast/JJ convergence/NN ./.
The/DT resulting/VBG adaptive/JJ ADMM/NN (/-LRB- AADMM/NN )/-RRB- algorithm/NN ,/, inspired/VBN by/IN the/DT successful/JJ Barzilai/NNP -/HYPH Borwein/NNP spectral/JJ method/NN for/IN gradient/NN descent/NN ,/, yields/NNS fast/VBP convergence/NN and/CC relative/JJ insensitivity/NN to/IN the/DT initial/JJ stepsize/NN and/CC problem/NN scaling/NN ./.
