K/NN -/HYPH means/NN is/VBZ one/CD of/IN the/DT most/RBS widely/RB used/VBN algorithms/NNS for/IN clustering/NN in/IN Data/NNP Mining/NNP applications/NNS ,/, which/WDT attempts/VBZ to/TO minimize/VB the/DT sum/NN of/IN square/NN of/IN Euclidean/JJ distance/NN of/IN the/DT points/NNS in/IN the/DT clusters/NNS from/IN the/DT respective/JJ means/NNS of/IN the/DT clusters/NNS ./.
The/DT simplicity/NN and/CC scalability/NN of/IN K/NN -/HYPH means/NN makes/VBZ it/PRP very/RB appealing/JJ ./.
However/RB ,/, K/NN -/HYPH means/NN suffers/VBZ from/IN local/JJ minima/NN problem/NN ,/, and/CC comes/VBZ with/IN no/DT guarantee/NN to/TO converge/VB to/IN the/DT optimal/JJ cost/NN ./.
K/NN -/HYPH means/NN tries/VBZ to/TO address/VB the/DT problem/NN by/IN seeding/VBG the/DT means/NNS using/VBG a/DT distance/NN based/VBN sampling/NN scheme/NN ./.
However/RB ,/, seeding/VBG the/DT means/NNS in/IN K/NN -/HYPH means/NN needs/VBZ O/NN (/-LRB- K/NN )/-RRB- passes/VBZ through/IN the/DT entire/JJ dataset/NN ,/, which/WDT could/MD be/VB very/RB costly/JJ in/IN large/JJ amount/NN of/IN dataset/NN ./.
Here/RB we/PRP propose/VBP a/DT method/NN of/IN seeding/VBG initial/JJ means/NNS based/VBN on/IN higher/JJR order/NN moments/NNS of/IN the/DT data/NNS ,/, which/WDT takes/VBZ O/NN (/-LRB- 1/CD )/-RRB- passes/VBZ through/IN the/DT entire/JJ dataset/NN to/TO extract/VB the/DT initial/JJ set/NN of/IN means/NNS ./.
Our/PRP$ method/NN yields/NNS competitive/JJ performance/NN with/IN respect/NN to/IN all/PDT the/DT existing/VBG K/NN -/HYPH means/NN algorithms/NNS ,/, whilst/IN avoiding/VBG the/DT expensive/JJ mean/NN selection/NN steps/NNS of/IN K/NN -/HYPH means/NNS and/CC other/JJ heuristics/NNS ./.
We/PRP demonstrate/VBP the/DT performance/NN of/IN our/PRP$ algorithm/NN in/IN comparison/NN with/IN the/DT existing/VBG algorithms/NNS on/IN various/JJ benchmark/NN datasets/NNS ./.
