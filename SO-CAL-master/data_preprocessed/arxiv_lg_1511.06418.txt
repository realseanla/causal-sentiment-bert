Disentangled/VBN distributed/VBN representations/NNS of/IN data/NNS are/VBP desirable/JJ for/IN machine/NN learning/NN ,/, since/IN they/PRP are/VBP more/RBR expressive/JJ and/CC can/MD generalize/VB from/IN fewer/JJR examples/NNS ./.
However/RB ,/, for/IN complex/JJ data/NNS ,/, the/DT distributed/VBN representations/NNS of/IN multiple/JJ objects/NNS present/JJ in/IN the/DT same/JJ input/NN can/MD interfere/VB and/CC lead/VB to/IN ambiguities/NNS ,/, which/WDT is/VBZ commonly/RB referred/VBN to/IN as/IN the/DT binding/NN problem/NN ./.
We/PRP argue/VBP for/IN the/DT importance/NN of/IN the/DT binding/NN problem/NN to/IN the/DT field/NN of/IN representation/NN learning/NN ,/, and/CC develop/VB a/DT probabilistic/JJ framework/NN that/WDT explicitly/RB models/NNS inputs/NNS as/IN a/DT composition/NN of/IN multiple/JJ objects/NNS ./.
We/PRP propose/VBP an/DT unsupervised/JJ algorithm/NN that/WDT uses/VBZ denoising/NN autoencoders/NNS to/TO dynamically/RB bind/VB features/NNS together/RB in/IN multi-object/JJ inputs/NNS through/IN an/DT Expectation/NN -/HYPH Maximization/NN -/HYPH like/JJ clustering/NN process/NN ./.
The/DT effectiveness/NN of/IN this/DT method/NN is/VBZ demonstrated/VBN on/IN artificially/RB generated/VBN datasets/NNS of/IN binary/JJ images/NNS ,/, showing/VBG that/IN it/PRP can/MD even/RB generalize/VB to/TO bind/VB together/RB new/JJ objects/NNS never/RB seen/VBN by/IN the/DT autoencoder/NN during/IN training/NN ./.
