We/PRP marry/VBP ideas/NNS from/IN deep/JJ neural/JJ networks/NNS and/CC approximate/JJ Bayesian/JJ inference/NN to/TO derive/VB a/DT generalised/VBN class/NN of/IN deep/JJ ,/, directed/VBN generative/JJ models/NNS ,/, endowed/VBN with/IN a/DT new/JJ algorithm/NN for/IN scalable/JJ inference/NN and/CC learning/NN ./.
Our/PRP$ algorithm/NN introduces/VBZ a/DT recognition/NN model/NN to/TO represent/VB approximate/JJ posterior/JJ distributions/NNS ,/, and/CC that/DT acts/VBZ as/IN a/DT stochastic/JJ encoder/NN of/IN the/DT data/NNS ./.
We/PRP develop/VBP stochastic/JJ back/RB -/HYPH propagation/NN --/: rules/NNS for/IN back/RB -/HYPH propagation/NN through/IN stochastic/JJ variables/NNS --/: and/CC use/VB this/DT to/TO develop/VB an/DT algorithm/NN that/WDT allows/VBZ for/IN joint/JJ optimisation/NN of/IN the/DT parameters/NNS of/IN both/CC the/DT generative/JJ and/CC recognition/NN model/NN ./.
We/PRP demonstrate/VBP on/IN several/JJ real/JJ -/HYPH world/NN data/NN sets/VBZ that/IN the/DT model/NN generates/VBZ realistic/JJ samples/NNS ,/, provides/VBZ accurate/JJ imputations/NNS of/IN missing/VBG data/NNS and/CC is/VBZ a/DT useful/JJ tool/NN for/IN high/JJ -/HYPH dimensional/JJ data/NNS visualisation/NN ./.
