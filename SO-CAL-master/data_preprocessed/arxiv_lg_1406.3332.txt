An/DT important/JJ goal/NN in/IN visual/JJ recognition/NN is/VBZ to/TO devise/VB image/NN representations/NNS that/WDT are/VBP invariant/JJ to/IN particular/JJ transformations/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP address/VBP this/DT goal/NN with/IN a/DT new/JJ type/NN of/IN convolutional/JJ neural/JJ network/NN (/-LRB- CNN/NNP )/-RRB- whose/WP$ invariance/NN is/VBZ encoded/VBN by/IN a/DT reproducing/VBG kernel/NN ./.
Unlike/IN traditional/JJ approaches/NNS where/WRB neural/JJ networks/NNS are/VBP learned/VBN either/CC to/TO represent/VB data/NNS or/CC for/IN solving/VBG a/DT classification/NN task/NN ,/, our/PRP$ network/NN learns/VBZ to/TO approximate/VB the/DT kernel/NN feature/NN map/NN on/IN training/NN data/NNS ./.
Such/PDT an/DT approach/NN enjoys/VBZ several/JJ benefits/NNS over/IN classical/JJ ones/NNS ./.
First/RB ,/, by/IN teaching/VBG CNNs/NNS to/TO be/VB invariant/JJ ,/, we/PRP obtain/VBP simple/JJ network/NN architectures/NNS that/WDT achieve/VBP a/DT similar/JJ accuracy/NN to/IN more/RBR complex/JJ ones/NNS ,/, while/IN being/VBG easy/JJ to/TO train/VB and/CC robust/JJ to/IN overfitting/VBG ./.
Second/RB ,/, we/PRP bridge/VBP a/DT gap/NN between/IN the/DT neural/JJ network/NN literature/NN and/CC kernels/NNS ,/, which/WDT are/VBP natural/JJ tools/NNS to/TO model/VB invariance/NN ./.
We/PRP evaluate/VBP our/PRP$ methodology/NN on/IN visual/JJ recognition/NN tasks/NNS where/WRB CNNs/NNS have/VBP proven/VBN to/TO perform/VB well/RB ,/, e.g./FW ,/, digit/NN recognition/NN with/IN the/DT MNIST/NN dataset/NN ,/, and/CC the/DT more/RBR challenging/JJ CIFAR/NN -/HYPH 10/CD and/CC STL/NNP -/HYPH 10/CD datasets/NNS ,/, where/WRB our/PRP$ accuracy/NN is/VBZ competitive/JJ with/IN the/DT state/NN of/IN the/DT art/NN ./.
