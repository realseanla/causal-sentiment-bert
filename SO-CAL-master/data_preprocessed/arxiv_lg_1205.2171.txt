We/PRP study/VBP the/DT problem/NN of/IN structured/JJ output/NN learning/NN from/IN a/DT regression/NN perspective/NN ./.
We/PRP first/RB provide/VBP a/DT general/JJ formulation/NN of/IN the/DT kernel/NN dependency/NN estimation/NN (/-LRB- KDE/NNP )/-RRB- problem/NN using/VBG operator/NN -/HYPH valued/VBN kernels/NNS ./.
We/PRP show/VBP that/IN some/DT of/IN the/DT existing/VBG formulations/NNS of/IN this/DT problem/NN are/VBP special/JJ cases/NNS of/IN our/PRP$ framework/NN ./.
We/PRP then/RB propose/VB a/DT covariance/NN -/HYPH based/VBN operator/NN -/HYPH valued/VBN kernel/NN that/WDT allows/VBZ us/PRP to/TO take/VB into/IN account/NN the/DT structure/NN of/IN the/DT kernel/NN feature/NN space/NN ./.
This/DT kernel/NN operates/VBZ on/IN the/DT output/NN space/NN and/CC encodes/VBZ the/DT interactions/NNS between/IN the/DT outputs/NNS without/IN any/DT reference/NN to/IN the/DT input/NN space/NN ./.
To/TO address/VB this/DT issue/NN ,/, we/PRP introduce/VBP a/DT variant/NN of/IN our/PRP$ KDE/NNP method/NN based/VBN on/IN the/DT conditional/JJ covariance/NN operator/NN that/WDT in/IN addition/NN to/IN the/DT correlation/NN between/IN the/DT outputs/NNS takes/VBZ into/IN account/NN the/DT effects/NNS of/IN the/DT input/NN variables/NNS ./.
Finally/RB ,/, we/PRP evaluate/VBP the/DT performance/NN of/IN our/PRP$ KDE/NNP approach/NN using/VBG both/CC covariance/NN and/CC conditional/JJ covariance/NN kernels/NNS on/IN two/CD structured/JJ output/NN problems/NNS ,/, and/CC compare/VB it/PRP to/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN kernel/NN -/HYPH based/VBN structured/JJ output/NN regression/NN methods/NNS ./.
