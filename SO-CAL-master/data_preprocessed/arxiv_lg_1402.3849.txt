Kernel/NNP -/HYPH based/VBN clustering/NN algorithms/NNS have/VBP the/DT ability/NN to/TO capture/VB the/DT non-linear/JJ structure/NN in/IN real/JJ world/NN data/NNS ./.
Among/IN various/JJ kernel/NN -/HYPH based/VBN clustering/NN algorithms/NNS ,/, kernel/NN k/CD -/HYPH means/NN has/VBZ gained/VBN popularity/NN due/IN to/IN its/PRP$ simple/JJ iterative/JJ nature/NN and/CC ease/NN of/IN implementation/NN ./.
However/RB ,/, its/PRP$ run/NN -/HYPH time/NN complexity/NN and/CC memory/NN footprint/NN increase/NN quadratically/RB in/IN terms/NNS of/IN the/DT size/NN of/IN the/DT data/NNS set/NN ,/, and/CC hence/RB ,/, large/JJ data/NNS sets/NNS can/MD not/RB be/VB clustered/VBN efficiently/RB ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP an/DT approximation/NN scheme/NN based/VBN on/IN randomization/NN ,/, called/VBD the/DT Approximate/JJ Kernel/NNP k/CD -/HYPH means/NNS ./.
We/PRP approximate/VBP the/DT cluster/NN centers/NNS using/VBG the/DT kernel/NN similarity/NN between/IN a/DT few/JJ sampled/VBN points/NNS and/CC all/PDT the/DT points/NNS in/IN the/DT data/NNS set/NN ./.
We/PRP show/VBP that/IN the/DT proposed/JJ method/NN achieves/VBZ better/JJR clustering/NN performance/NN than/IN the/DT traditional/JJ low/JJ rank/NN kernel/NN approximation/NN based/VBN clustering/NN schemes/NNS ./.
We/PRP also/RB demonstrate/VBP that/IN its/PRP$ running/NN time/NN and/CC memory/NN requirements/NNS are/VBP significantly/RB lower/JJR than/IN those/DT of/IN kernel/NN k/CD -/HYPH means/NNS ,/, with/IN only/RB a/DT small/JJ reduction/NN in/IN the/DT clustering/NN quality/NN on/IN several/JJ public/JJ domain/NN large/JJ data/NNS sets/NNS ./.
We/PRP then/RB employ/VBP ensemble/NN clustering/NN techniques/NNS to/TO further/RB enhance/VB the/DT performance/NN of/IN our/PRP$ algorithm/NN ./.
