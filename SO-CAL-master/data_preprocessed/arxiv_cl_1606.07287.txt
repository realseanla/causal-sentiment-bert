In/IN this/DT paper/NN we/PRP tackle/VBP the/DT problem/NN of/IN image/NN search/NN when/WRB the/DT query/NN is/VBZ a/DT short/JJ textual/JJ description/NN of/IN the/DT image/NN the/DT user/NN is/VBZ looking/VBG for/IN ./.
We/PRP choose/VBP to/TO implement/VB the/DT actual/JJ search/NN process/NN as/IN a/DT similarity/NN search/NN in/IN a/DT visual/JJ feature/NN space/NN ,/, by/IN learning/VBG to/IN translate/VB a/DT textual/JJ query/NN into/IN a/DT visual/JJ representation/NN ./.
Searching/VBG in/IN the/DT visual/JJ feature/NN space/NN has/VBZ the/DT advantage/NN that/IN any/DT update/NN to/IN the/DT translation/NN model/NN does/VBZ not/RB require/VB to/IN reprocess/VB the/DT ,/, typically/RB huge/JJ ,/, image/NN collection/NN on/IN which/WDT the/DT search/NN is/VBZ performed/VBN ./.
We/PRP propose/VBP Text2Vis/NNP ,/, a/DT neural/JJ network/NN that/WDT generates/VBZ a/DT visual/JJ representation/NN ,/, in/IN the/DT visual/JJ feature/NN space/NN of/IN the/DT fc6/NN -/HYPH fc7/NN layers/NNS of/IN ImageNet/NNP ,/, from/IN a/DT short/JJ descriptive/JJ text/NN ./.
Text2Vis/NNP optimizes/VBZ two/CD loss/NN functions/NNS ,/, using/VBG a/DT stochastic/JJ loss/NN -/HYPH selection/NN method/NN ./.
A/DT visual/JJ -/HYPH focused/JJ loss/NN is/VBZ aimed/VBN at/IN learning/VBG the/DT actual/JJ text/NN -/HYPH to/IN -/HYPH visual/JJ feature/NN mapping/NN ,/, while/IN a/DT text/NN -/HYPH focused/JJ loss/NN is/VBZ aimed/VBN at/IN modeling/VBG the/DT higher/JJR -/HYPH level/NN semantic/JJ concepts/NNS expressed/VBN in/IN language/NN and/CC countering/VBG the/DT overfit/NN on/IN non-relevant/JJ visual/JJ components/NNS of/IN the/DT visual/JJ loss/NN ./.
We/PRP report/VBP preliminary/JJ results/NNS on/IN the/DT MS/NN -/HYPH COCO/NN dataset/NN ./.
