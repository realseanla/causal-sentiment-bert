Many/JJ classification/NN algorithms/NNS produce/VBP confidence/NN measures/NNS in/IN the/DT form/NN of/IN conditional/JJ probability/NN of/IN labels/NNS given/VBN the/DT features/NNS of/IN the/DT target/NN instance/NN ./.
It/PRP is/VBZ desirable/JJ to/TO be/VB make/VB these/DT confidence/NN measures/NNS calibrated/VBN or/CC consistent/JJ ,/, in/IN the/DT sense/NN that/IN they/PRP correctly/RB capture/VB the/DT belief/NN of/IN the/DT algorithm/NN in/IN the/DT label/NN output/NN ./.
For/IN instance/NN ,/, if/IN the/DT algorithm/NN outputs/NNS a/DT label/NN with/IN confidence/NN measure/NN $/$ p/NN $/$ for/IN $/$ n/NN $/$ times/NNS ,/, then/RB the/DT output/NN label/NN should/MD be/VB correct/JJ approximately/RB $/$ np/CD $/$ times/CC overall/JJ ./.
Calibrated/VBN confidence/NN measures/NNS lead/VBP to/IN higher/JJR interpretability/NN by/IN humans/NNS and/CC computers/NNS and/CC enable/VB downstream/JJ analysis/NN or/CC processing/NN ./.
In/IN this/DT paper/NN ,/, we/PRP formally/RB characterize/VBP the/DT consistency/NN of/IN confidence/NN measures/NNS and/CC prove/VB a/DT PAC/NN -/HYPH style/NN uniform/NN convergence/NN result/NN for/IN the/DT consistency/NN of/IN confidence/NN measures/NNS ./.
We/PRP show/VBP that/IN finite/JJ VC/NNP -/HYPH dimension/NN is/VBZ sufficient/JJ for/IN guaranteeing/VBG the/DT consistency/NN of/IN confidence/NN measures/NNS produced/VBN by/IN empirically/RB consistent/JJ classifiers/NNS ./.
Our/PRP$ result/NN also/RB implies/VBZ that/IN we/PRP can/MD calibrate/VB confidence/NN measures/NNS produced/VBN by/IN any/DT existing/VBG algorithms/NNS with/IN monotonic/JJ functions/NNS ,/, and/CC still/RB get/VB the/DT same/JJ generalization/NN guarantee/NN on/IN consistency/NN ./.
