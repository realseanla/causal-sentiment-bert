This/DT paper/NN proposes/VBZ a/DT deep/JJ denoising/NN auto/NN -/HYPH encoder/NN technique/NN to/TO extract/VB better/JJR acoustic/JJ features/NNS for/IN speech/NN synthesis/NN ./.
The/DT technique/NN allows/VBZ us/PRP to/TO automatically/RB extract/VB low/JJ -/HYPH dimensional/JJ features/NNS from/IN high/JJ dimensional/JJ spectral/JJ features/NNS in/IN a/DT non-linear/JJ ,/, data/NN -/HYPH driven/VBN ,/, unsupervised/JJ way/NN ./.
We/PRP compared/VBD the/DT new/JJ stochastic/JJ feature/NN extractor/NN with/IN conventional/JJ mel/NN -/HYPH cepstral/JJ analysis/NN in/IN analysis/NN -/HYPH by/IN -/HYPH synthesis/NN and/CC text/NN -/HYPH to/IN -/HYPH speech/NN experiments/NNS ./.
Our/PRP$ results/NNS confirm/VBP that/IN the/DT proposed/JJ method/NN increases/VBZ the/DT quality/NN of/IN synthetic/JJ speech/NN in/IN both/CC experiments/NNS ./.
