Many/JJ Proper/JJ Names/NNS (/-LRB- PNs/NNS )/-RRB- are/VBP Out/IN -/HYPH Of/IN -/HYPH Vocabulary/NN (/-LRB- OOV/NN )/-RRB- words/NNS for/IN speech/NN recognition/NN systems/NNS used/VBN to/TO process/VB diachronic/JJ audio/JJ data/NNS ./.
To/TO help/VB recovery/NN of/IN the/DT PNs/NNPS missed/VBN by/IN the/DT system/NN ,/, relevant/JJ OOV/NN PNs/NNS can/MD be/VB retrieved/VBN out/IN of/IN the/DT many/JJ OOVs/NNS by/IN exploiting/VBG semantic/JJ context/NN of/IN the/DT spoken/VBN content/NN ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP two/CD neural/JJ network/NN models/NNS targeted/VBN to/TO retrieve/VB OOV/NNP PNs/NNS relevant/JJ to/IN an/DT audio/JJ document/NN :/: (/-LRB- a/LS )/-RRB- Document/NN level/NN Continuous/JJ Bag/NN of/IN Words/NNS (/-LRB- D/NN -/HYPH CBOW/NN )/-RRB- ,/, (/-LRB- b/LS )/-RRB- Document/NN level/NN Continuous/JJ Bag/NN of/IN Weighted/JJ Words/NNS (/-LRB- D/NN -/HYPH CBOW2/NN )/-RRB- ./.
Both/PDT these/DT models/NNS take/VBP document/NN words/NNS as/IN input/NN and/CC learn/VB with/IN an/DT objective/NN to/TO maximise/VB the/DT retrieval/NN of/IN co-occurring/VBG OOV/NNP PNs/NNS ./.
With/IN the/DT D/NN -/HYPH CBOW2/NN model/NN we/PRP propose/VBP a/DT new/JJ approach/NN in/IN which/WDT the/DT input/NN embedding/NN layer/NN is/VBZ augmented/VBN with/IN a/DT context/NN anchor/NN layer/NN ./.
This/DT layer/NN learns/VBZ to/TO assign/VB importance/NN to/IN input/NN words/NNS and/CC has/VBZ the/DT ability/NN to/TO capture/VB (/-LRB- task/NN specific/JJ )/-RRB- key/JJ -/HYPH words/NNS in/IN a/DT bag/NN -/HYPH of/IN -/HYPH word/NN neural/JJ network/NN model/NN ./.
With/IN experiments/NNS on/IN French/JJ broadcast/NN news/NN videos/NNS we/PRP show/VBP that/IN these/DT two/CD models/NNS outperform/VBP the/DT baseline/NN methods/NNS based/VBN on/IN raw/JJ embeddings/NNS from/IN LDA/NN ,/, Skip/VB -/HYPH gram/NN and/CC Paragraph/NN Vectors/NNS ./.
Combining/VBG the/DT D/NN -/HYPH CBOW/NN and/CC D/NN -/HYPH CBOW2/NN models/NNS gives/VBZ faster/RBR convergence/NN during/IN training/NN ./.
