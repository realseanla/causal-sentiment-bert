Neural/JJ machine/NN translation/NN (/-LRB- NMT/NN )/-RRB- offers/VBZ a/DT novel/JJ alternative/JJ formulation/NN of/IN translation/NN that/WDT is/VBZ potentially/RB simpler/JJR than/IN statistical/JJ approaches/NNS ./.
However/RB to/TO reach/VB competitive/JJ performance/NN ,/, NMT/NN models/NNS need/VBP to/TO be/VB exceedingly/RB large/JJ ./.
In/IN this/DT paper/NN we/PRP consider/VBP applying/VBG knowledge/NN distillation/NN approaches/NNS (/-LRB- Bucila/NNP et/FW al/FW ,/, 2006/CD ;/: Hinton/NNP et/FW al./FW ,/, 2015/CD )/-RRB- that/WDT have/VBP proven/VBN successful/JJ for/IN reducing/VBG the/DT size/NN of/IN neural/JJ models/NNS in/IN other/JJ domains/NNS to/IN the/DT problem/NN of/IN NMT/NNP ./.
We/PRP demonstrate/VBP that/IN standard/JJ knowledge/NN distillation/NN applied/VBD to/IN word/NN -/HYPH level/NN prediction/NN can/MD be/VB effective/JJ for/IN NMT/NN ,/, and/CC also/RB introduce/VB two/CD novel/JJ sequence/NN -/HYPH level/NN versions/NNS of/IN knowledge/NN distillation/NN that/WDT further/RB improve/VBP performance/NN ,/, and/CC somewhat/RB surprisingly/RB ,/, seem/VBP to/TO eliminate/VB the/DT need/NN for/IN beam/NN search/NN (/-LRB- even/RB when/WRB applied/VBN on/IN the/DT original/JJ teacher/NN model/NN )/-RRB- ./.
Our/PRP$ best/JJS student/NN model/NN runs/VBZ 10/CD times/NNS faster/JJR than/IN its/PRP$ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN teacher/NN with/IN only/RB a/DT decrease/NN of/IN 0.2/CD BLEU/NN ./.
It/PRP is/VBZ also/RB significantly/RB better/JJR than/IN a/DT baseline/NN model/NN trained/VBN without/IN knowledge/NN distillation/NN :/: by/IN 4.2/CD //SYM 1.7/CD BLEU/NN with/IN greedy/JJ decoding/NN //HYPH beam/NN search/NN ./.
