We/PRP consider/VBP the/DT problem/NN of/IN learning/VBG for/IN planning/NN ,/, where/WRB knowledge/NN acquired/VBN while/IN planning/NN is/VBZ reused/VBN to/TO plan/VB faster/RBR in/IN new/JJ problem/NN instances/NNS ./.
For/IN robotic/JJ tasks/NNS ,/, among/IN others/NNS ,/, plan/NN execution/NN can/MD be/VB captured/VBN as/IN a/DT sequence/NN of/IN visual/JJ images/NNS ./.
For/IN such/JJ domains/NNS ,/, we/PRP propose/VBP to/TO use/VB deep/JJ neural/JJ networks/NNS in/IN learning/VBG for/IN planning/NN ,/, based/VBN on/IN learning/VBG a/DT reactive/JJ policy/NN that/WDT imitates/VBZ execution/NN traces/NNS produced/VBN by/IN a/DT planner/NN ./.
We/PRP investigate/VBP architectural/JJ properties/NNS of/IN deep/JJ networks/NNS that/WDT are/VBP suitable/JJ for/IN learning/VBG long/JJ -/HYPH horizon/NN planning/NN behavior/NN ,/, and/CC explore/VB how/WRB to/TO learn/VB ,/, in/IN addition/NN to/IN the/DT policy/NN ,/, a/DT heuristic/NN function/NN that/WDT can/MD be/VB used/VBN with/IN classical/JJ planners/NNS or/CC search/VB algorithms/NNS such/JJ as/IN A/DT */NFP ./.
Our/PRP$ results/NNS on/IN the/DT challenging/JJ Sokoban/NNP domain/NN show/NN that/WDT ,/, with/IN a/DT suitable/JJ network/NN design/NN ,/, complex/JJ decision/NN making/VBG policies/NNS and/CC powerful/JJ heuristic/NN functions/NNS can/MD be/VB learned/VBN through/IN imitation/NN ./.
