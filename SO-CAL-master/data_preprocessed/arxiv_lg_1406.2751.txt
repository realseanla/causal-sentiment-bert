Training/VBG deep/JJ directed/VBN graphical/JJ models/NNS with/IN many/JJ hidden/JJ variables/NNS and/CC performing/VBG inference/NN remains/VBZ a/DT major/JJ challenge/NN ./.
Helmholtz/NNP machines/NNS and/CC deep/JJ belief/NN networks/NNS are/VBP such/JJ models/NNS ,/, and/CC the/DT wake/NN -/HYPH sleep/NN algorithm/NN has/VBZ been/VBN proposed/VBN to/TO train/VB them/PRP ./.
The/DT wake/NN -/HYPH sleep/NN algorithm/NN relies/VBZ on/IN training/NN not/RB just/RB the/DT directed/VBN generative/JJ model/NN but/CC also/RB a/DT conditional/JJ generative/JJ model/NN (/-LRB- the/DT inference/NN network/NN )/-RRB- that/WDT runs/VBZ backward/RB from/IN visible/JJ to/IN latent/NN ,/, estimating/VBG the/DT posterior/JJ distribution/NN of/IN latent/JJ given/VBN visible/JJ ./.
We/PRP propose/VBP a/DT novel/JJ interpretation/NN of/IN the/DT wake/NN -/HYPH sleep/NN algorithm/NN which/WDT suggests/VBZ that/IN better/JJR estimators/NNS of/IN the/DT gradient/NN can/MD be/VB obtained/VBN by/IN sampling/NN latent/NN variables/NNS multiple/JJ times/NNS from/IN the/DT inference/NN network/NN ./.
This/DT view/NN is/VBZ based/VBN on/IN importance/NN sampling/NN as/IN an/DT estimator/NN of/IN the/DT likelihood/NN ,/, with/IN the/DT approximate/JJ inference/NN network/NN as/IN a/DT proposal/NN distribution/NN ./.
This/DT interpretation/NN is/VBZ confirmed/VBN experimentally/RB ,/, showing/VBG that/IN better/JJR likelihood/NN can/MD be/VB achieved/VBN with/IN this/DT reweighted/VBN wake/NN -/HYPH sleep/NN procedure/NN ,/, which/WDT also/RB provides/VBZ a/DT natural/JJ way/NN to/TO estimate/VB the/DT likelihood/NN itself/PRP ./.
Based/VBN on/IN this/DT interpretation/NN ,/, we/PRP propose/VBP that/IN a/DT sigmoid/NN belief/NN network/NN is/VBZ not/RB sufficiently/RB powerful/JJ for/IN the/DT layers/NNS of/IN the/DT inference/NN network/NN ,/, in/IN order/NN to/TO recover/VB a/DT good/JJ estimator/NN of/IN the/DT posterior/JJ distribution/NN of/IN latent/JJ variables/NNS ./.
Our/PRP$ experiments/NNS show/VBP that/IN using/VBG a/DT more/RBR powerful/JJ layer/NN model/NN ,/, such/JJ as/IN NADE/NNP ,/, yields/VBZ substantially/RB better/JJR generative/NN models/NNS ./.
