We/PRP design/VBP an/DT Enriched/VBN Deep/JJ Recurrent/JJ Visual/JJ Attention/NN Model/NN (/-LRB- EDRAM/NN )/-RRB- -/: an/DT improved/JJ attention/NN -/HYPH based/VBN architecture/NN for/IN multiple/JJ object/NN recognition/NN ./.
The/DT proposed/VBN model/NN is/VBZ a/DT fully/RB differentiable/JJ unit/NN that/WDT can/MD be/VB optimized/VBN end/NN -/HYPH to/IN -/HYPH end/NN by/IN using/VBG Stochastic/NNP Gradient/NNP Descent/NNP (/-LRB- SGD/NNP )/-RRB- ./.
The/DT Spatial/JJ Transformer/NN (/-LRB- ST/NNP )/-RRB- was/VBD employed/VBN as/IN visual/JJ attention/NN mechanism/NN which/WDT allows/VBZ to/TO learn/VB the/DT geometric/JJ transformation/NN of/IN objects/NNS within/IN images/NNS ./.
With/IN the/DT combination/NN of/IN the/DT Spatial/JJ Transformer/NN and/CC the/DT powerful/JJ recurrent/JJ architecture/NN ,/, the/DT proposed/VBN EDRAM/NN can/MD localize/VB and/CC recognize/VB objects/NNS simultaneously/RB ./.
EDRAM/NNP has/VBZ been/VBN evaluated/VBN on/IN two/CD publicly/RB available/JJ datasets/NNS including/VBG MNIST/NN Cluttered/JJ (/-LRB- with/IN 70K/NN cluttered/JJ digits/NNS )/-RRB- and/CC SVHN/NN (/-LRB- with/IN up/RB to/IN 250k/CD real/JJ world/NN images/NNS of/IN house/NN numbers/NNS )/-RRB- ./.
Experiments/NNS show/VBP that/IN it/PRP obtains/VBZ superior/JJ performance/NN as/IN compared/VBN with/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN models/NNS ./.
