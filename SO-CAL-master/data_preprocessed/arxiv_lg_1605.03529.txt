We/PRP consider/VBP a/DT broad/JJ class/NN of/IN first/JJ -/HYPH order/NN optimization/NN algorithms/NNS which/WDT are/VBP \/SYM emph/VBP {/-LRB- oblivious/JJ }/-RRB- ,/, in/IN the/DT sense/NN that/IN their/PRP$ step/NN sizes/NNS are/VBP scheduled/VBN regardless/RB of/IN the/DT function/NN under/IN consideration/NN ,/, except/IN for/IN limited/JJ side/NN -/HYPH information/NN such/JJ as/IN smoothness/NN or/CC strong/JJ convexity/NN parameters/NNS ./.
With/IN the/DT knowledge/NN of/IN these/DT two/CD parameters/NNS ,/, we/PRP show/VBP that/IN any/DT such/JJ algorithm/NN attains/VBZ an/DT iteration/NN complexity/NN lower/JJR bound/VBN of/IN $/$ \/SYM Omega/NN (/-LRB- \/SYM sqrt/NN {/-LRB- L/NN //HYPH \/SYM epsilon/NN }/-RRB- )/-RRB- $/$ for/IN $/$ L$/CD -/HYPH smooth/JJ convex/NN functions/NNS ,/, and/CC $/$ \/CD tilde/NN {/-LRB- \/SYM Omega/NN }/-RRB- (/-LRB- \/SYM sqrt/NN {/-LRB- L/NN //HYPH \/SYM mu/NNS }/-RRB- \/SYM ln/NN (/-LRB- 1/CD //SYM \/SYM epsilon/SYM )/-RRB- )/-RRB- $/$ for/IN $/$ L$/CD -/HYPH smooth/JJ $/$ \/SYM mu/NNS $/$ -/HYPH strongly/RB convex/JJ functions/NNS ./.
These/DT lower/JJR bounds/NNS are/VBP stronger/JJR than/IN those/DT in/IN the/DT traditional/JJ oracle/NN model/NN ,/, as/IN they/PRP hold/VBP independently/RB of/IN the/DT dimension/NN ./.
To/TO attain/VB these/DT ,/, we/PRP abandon/VBP the/DT oracle/NN model/NN in/IN favor/NN of/IN a/DT structure/NN -/HYPH based/VBN approach/NN which/WDT builds/VBZ upon/IN a/DT framework/NN recently/RB proposed/VBN in/IN (/-LRB- Arjevani/NNP et/FW al./FW ,/, 2015/CD )/-RRB- ./.
We/PRP further/RB show/VBP that/IN without/IN knowing/VBG the/DT strong/JJ convexity/NN parameter/NN ,/, it/PRP is/VBZ impossible/JJ to/TO attain/VB an/DT iteration/NN complexity/NN better/JJR than/IN $/$ \/SYM tilde/NN {/-LRB- \/SYM Omega/NN }/-RRB- \/SYM left/JJ (/-LRB- (/-LRB- L/NN //HYPH \/SYM mu/NNS )/-RRB- \/SYM ln/NN (/-LRB- 1/CD //SYM \/SYM epsilon/SYM )/-RRB- \/SYM right/NN )/-RRB- $/$ ./.
This/DT result/NN is/VBZ then/RB used/VBN to/TO formalize/VB an/DT observation/NN regarding/VBG $/$ L$/CD -/HYPH smooth/JJ convex/NN functions/NNS ,/, namely/RB ,/, that/IN the/DT iteration/NN complexity/NN of/IN algorithms/NNS employing/VBG time/NN -/HYPH invariant/JJ step/NN sizes/NNS must/MD be/VB at/IN least/RBS $/$ \/SYM Omega/NN (/-LRB- L/NN //HYPH \/SYM epsilon/NN )/-RRB- $/$ ./.
