As/IN training/NN data/NNS rapid/JJ growth/NN ,/, large/JJ -/HYPH scale/NN parallel/JJ training/NN with/IN multi-GPUs/JJ cluster/NN is/VBZ widely/RB applied/VBN in/IN the/DT neural/JJ network/NN model/NN learning/VBG currently.We/NNP present/VB a/DT new/JJ approach/NN that/WDT applies/VBZ exponential/JJ moving/VBG average/JJ method/NN in/IN large/JJ -/HYPH scale/NN parallel/JJ training/NN of/IN neural/JJ network/NN model/NN ./.
It/PRP is/VBZ a/DT non-interference/NN strategy/NN that/WDT the/DT exponential/JJ moving/VBG average/JJ model/NN is/VBZ not/RB broadcasted/VBN to/IN distributed/VBN workers/NNS to/TO update/VB their/PRP$ local/JJ models/NNS after/IN model/NN synchronization/NN in/IN the/DT training/NN process/NN ,/, and/CC it/PRP is/VBZ implemented/VBN as/IN the/DT final/JJ model/NN of/IN the/DT training/NN system/NN ./.
Fully/RB -/HYPH connected/VBN feed/NN -/HYPH forward/JJ neural/JJ networks/NNS (/-LRB- DNNs/NNS )/-RRB- and/CC deep/JJ unidirectional/JJ Long/JJ short/JJ -/HYPH term/NN memory/NN (/-LRB- LSTM/NN )/-RRB- recurrent/JJ neural/JJ networks/NNS (/-LRB- RNNs/NNS )/-RRB- are/VBP successfully/RB trained/VBN with/IN proposed/JJ method/NN for/IN large/JJ vocabulary/NN continuous/JJ speech/NN recognition/NN on/IN Shenma/NNP voice/NN search/NN data/NNS in/IN Mandarin/NNP ./.
The/DT character/NN error/NN rate/NN (/-LRB- CER/NN )/-RRB- of/IN Mandarin/NNP speech/NN recognition/NN further/RB degrades/VBZ than/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN approaches/NNS of/IN parallel/JJ training/NN ./.
