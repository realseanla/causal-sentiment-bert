Performing/VBG exact/JJ posterior/JJ inference/NN in/IN complex/JJ generative/JJ models/NNS is/VBZ often/RB difficult/JJ or/CC impossible/JJ due/IN to/IN an/DT expensive/JJ to/TO evaluate/VB or/CC intractable/JJ likelihood/NN function/NN ./.
Approximate/JJ Bayesian/JJ computation/NN (/-LRB- ABC/NNP )/-RRB- is/VBZ an/DT inference/NN framework/NN that/WDT constructs/VBZ an/DT approximation/NN to/IN the/DT true/JJ likelihood/NN based/VBN on/IN the/DT similarity/NN between/IN the/DT observed/VBN and/CC simulated/VBN data/NNS as/IN measured/VBN by/IN a/DT predefined/JJ set/NN of/IN summary/NN statistics/NNS ./.
Although/IN the/DT choice/NN of/IN appropriate/JJ problem/NN -/HYPH specific/JJ summary/NN statistics/NNS crucially/RB influences/VBZ the/DT quality/NN of/IN the/DT likelihood/NN approximation/NN and/CC hence/RB also/RB the/DT quality/NN of/IN the/DT posterior/JJ sample/NN in/IN ABC/NNP ,/, there/EX are/VBP only/RB few/JJ principled/JJ general/JJ -/HYPH purpose/NN approaches/NNS to/IN the/DT selection/NN or/CC construction/NN of/IN such/JJ summary/NN statistics/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP develop/VBP a/DT novel/JJ framework/NN for/IN this/DT task/NN using/VBG kernel/NN -/HYPH based/VBN distribution/NN regression/NN ./.
We/PRP model/VBP the/DT functional/JJ relationship/NN between/IN data/NNS distributions/NNS and/CC the/DT optimal/JJ choice/NN (/-LRB- with/IN respect/NN to/IN a/DT loss/NN function/NN )/-RRB- of/IN summary/NN statistics/NNS using/VBG kernel/NN -/HYPH based/VBN distribution/NN regression/NN ./.
We/PRP show/VBP that/IN our/PRP$ approach/NN can/MD be/VB implemented/VBN in/IN a/DT computationally/RB and/CC statistically/RB efficient/JJ way/NN using/VBG the/DT random/JJ Fourier/NN features/VBZ framework/NN for/IN large/JJ -/HYPH scale/NN kernel/NN learning/NN ./.
In/IN addition/NN to/IN that/DT ,/, our/PRP$ framework/NN shows/VBZ superior/JJ performance/NN when/WRB compared/VBN to/IN related/JJ methods/NNS on/IN toy/NN and/CC real/JJ -/HYPH world/NN problems/NNS ./.
