Recently/RB ,/, there/EX has/VBZ been/VBN an/DT increasing/VBG interest/NN in/IN end/NN -/HYPH to/IN -/HYPH end/NN speech/NN recognition/NN that/WDT directly/RB transcribes/VBZ speech/NN to/IN text/NN without/IN any/DT predefined/JJ alignments/NNS ./.
One/CD approach/NN is/VBZ the/DT attention/NN -/HYPH based/VBN encoder/NN -/HYPH decoder/NN framework/NN that/WDT learns/VBZ a/DT mapping/NN between/IN variable/JJ -/HYPH length/NN input/NN and/CC output/NN sequences/NNS in/IN one/CD step/NN using/VBG a/DT purely/RB data/NN -/HYPH driven/VBN method/NN ./.
The/DT attention/NN model/NN has/VBZ often/RB been/VBN shown/VBN to/TO improve/VB the/DT performance/NN over/IN another/DT end/NN -/HYPH to/IN -/HYPH end/NN approach/NN ,/, the/DT Connectionist/NN Temporal/JJ Classification/NN (/-LRB- CTC/NN )/-RRB- ,/, mainly/RB because/IN it/PRP explicitly/RB uses/VBZ the/DT history/NN of/IN the/DT target/NN character/NN without/IN any/DT conditional/JJ independence/NN assumptions/NNS ./.
However/RB ,/, we/PRP observed/VBD that/IN the/DT attention/NN model/NN has/VBZ shown/VBN poor/JJ results/NNS especially/RB in/IN noisy/JJ condition/NN and/CC is/VBZ hard/JJ to/TO be/VB trained/VBN in/IN the/DT initial/JJ training/NN stage/NN with/IN long/JJ input/NN sequences/NNS ,/, as/IN compared/VBN with/IN CTC/NN ./.
This/DT is/VBZ because/IN the/DT attention/NN model/NN is/VBZ too/RB flexible/JJ to/TO predict/VB proper/JJ alignments/NNS in/IN such/JJ cases/NNS due/IN to/IN the/DT lack/NN of/IN left/JJ -/HYPH to/TO -/HYPH right/JJ constraints/NNS as/IN used/VBN in/IN CTC/NN ./.
This/DT paper/NN presents/VBZ a/DT novel/JJ method/NN for/IN end/NN -/HYPH to/IN -/HYPH end/NN speech/NN recognition/NN to/TO improve/VB robustness/NN and/CC achieve/VB fast/JJ convergence/NN by/IN using/VBG a/DT joint/JJ CTC/NN -/HYPH attention/NN model/NN within/IN the/DT multi-task/VB learning/NN framework/NN ,/, thereby/RB mitigating/VBG the/DT alignment/NN issue/NN ./.
An/DT experiment/NN on/IN the/DT WSJ/NNP and/CC CHiME/NNP -/HYPH 4/CD tasks/NNS demonstrates/VBZ its/PRP$ advantages/NNS over/IN both/CC the/DT CTC/NN and/CC attention/NN -/HYPH based/VBN encoder/NN -/HYPH decoder/NN baselines/NNS ,/, showing/VBG 6.6/CD -/HYPH 10.3/CD percent/NN relative/JJ improvements/NNS in/IN Character/NNP Error/NNP Rate/NNP (/-LRB- CER/NNP )/-RRB- ./.
