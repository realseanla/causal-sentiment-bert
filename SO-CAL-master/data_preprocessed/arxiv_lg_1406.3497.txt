This/DT paper/NN is/VBZ about/IN learning/VBG a/DT continuous/JJ approximation/NN of/IN the/DT Pareto/NNP frontier/NN in/IN Multi-Objective/NNP Markov/NNP Decision/NN Problems/NNS (/-LRB- MOMDPs/NNS )/-RRB- ./.
We/PRP propose/VBP a/DT policy/NN -/HYPH based/VBN approach/NN that/WDT exploits/VBZ gradient/NN information/NN to/TO generate/VB solutions/NNS close/VB to/IN the/DT Pareto/NNP ones/NNS ./.
Differently/RB from/IN previous/JJ policy/NN -/HYPH gradient/NN multi-objective/JJ algorithms/NNS ,/, where/WRB n/NN optimization/NN routines/NNS are/VBP use/NN to/TO have/VB n/NN solutions/NNS ,/, our/PRP$ approach/NN performs/VBZ a/DT single/JJ gradient/NN -/HYPH ascent/NN run/NN that/WDT at/IN each/DT step/NN generates/VBZ an/DT improved/JJ continuous/JJ approximation/NN of/IN the/DT Pareto/NNP frontier/NN ./.
The/DT idea/NN is/VBZ to/TO exploit/VB a/DT gradient/NN -/HYPH based/VBN approach/NN to/TO optimize/VB the/DT parameters/NNS of/IN a/DT function/NN that/WDT defines/VBZ a/DT manifold/NN in/IN the/DT policy/NN parameter/NN space/NN so/IN that/IN the/DT corresponding/VBG image/NN in/IN the/DT objective/JJ space/NN gets/VBZ as/RB close/JJ as/IN possible/JJ to/IN the/DT Pareto/NNP frontier/NN ./.
Besides/IN deriving/VBG how/WRB to/TO compute/VB and/CC estimate/VB such/JJ gradient/NN ,/, we/PRP will/MD also/RB discuss/VB the/DT non-trivial/JJ issue/NN of/IN defining/VBG a/DT metric/JJ to/TO assess/VB the/DT quality/NN of/IN the/DT candidate/NN Pareto/NNP frontiers/NNS ./.
Finally/RB ,/, the/DT properties/NNS of/IN the/DT proposed/VBN approach/NN are/VBP empirically/RB evaluated/VBN on/IN two/CD interesting/JJ MOMDPs/NNS ./.
