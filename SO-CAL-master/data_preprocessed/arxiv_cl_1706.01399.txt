Generative/JJ Adversarial/JJ Networks/NNS (/-LRB- GANs/NNS )/-RRB- have/VBP shown/VBN great/JJ promise/NN recently/RB in/IN image/NN generation/NN ./.
Training/VBG GANs/NNS for/IN text/NN generation/NN has/VBZ proven/VBN to/TO be/VB more/RBR difficult/JJ ,/, because/IN of/IN the/DT non-differentiable/JJ nature/NN of/IN generating/VBG text/NN with/IN recurrent/JJ neural/JJ networks/NNS ./.
Consequently/RB ,/, past/JJ work/NN has/VBZ either/CC resorted/VBN to/IN pre-training/VBG with/IN maximum/JJ -/HYPH likelihood/NN or/CC used/VBN convolutional/JJ networks/NNS for/IN generation/NN ./.
In/IN this/DT work/NN ,/, we/PRP show/VBP that/IN recurrent/JJ neural/JJ networks/NNS can/MD be/VB trained/VBN to/TO generate/VB text/NN with/IN GANs/NNS from/IN scratch/NN by/IN employing/VBG curriculum/NN learning/NN ,/, slowly/RB increasing/VBG the/DT length/NN of/IN the/DT generated/VBN text/NN ,/, and/CC by/IN training/VBG the/DT RNN/NN simultaneously/RB to/TO generate/VB sequences/NNS of/IN different/JJ lengths/NNS ./.
We/PRP show/VBP that/IN this/DT approach/NN vastly/RB improves/VBZ the/DT quality/NN of/IN generated/VBN sequences/NNS compared/VBN to/IN the/DT convolutional/JJ baseline/NN ./.
