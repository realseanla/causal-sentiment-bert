We/PRP investigate/VBP a/DT paradigm/NN in/IN multi-task/VB reinforcement/NN learning/NN (/-LRB- MT/NN -/HYPH RL/NN )/-RRB- in/IN which/WDT an/DT agent/NN is/VBZ placed/VBN in/IN an/DT environment/NN and/CC needs/VBZ to/TO learn/VB to/TO perform/VB a/DT series/NN of/IN tasks/NNS ,/, within/IN this/DT space/NN ./.
Since/IN the/DT environment/NN does/VBZ not/RB change/VB ,/, there/EX is/VBZ potentially/RB a/DT lot/NN of/IN common/JJ ground/NN amongst/IN tasks/NNS and/CC learning/VBG to/TO solve/VB them/PRP individually/RB seems/VBZ extremely/RB wasteful/JJ ./.
In/IN this/DT paper/NN ,/, we/PRP explicitly/RB model/NN and/CC learn/VB this/DT shared/VBN structure/NN as/IN it/PRP arises/VBZ in/IN the/DT state/NN -/HYPH action/NN value/NN space/NN ./.
We/PRP will/MD show/VB how/WRB one/PRP can/MD jointly/RB learn/VB optimal/JJ value/NN -/HYPH functions/NNS by/IN modifying/VBG the/DT popular/JJ Value/NN -/HYPH Iteration/NN and/CC Policy/NN -/HYPH Iteration/NN procedures/NNS to/TO accommodate/VB this/DT shared/VBN representation/NN assumption/NN and/CC leverage/NN the/DT power/NN of/IN multi-task/VB supervised/JJ learning/NN ./.
Finally/RB ,/, we/PRP demonstrate/VBP that/IN the/DT proposed/VBN model/NN and/CC training/NN procedures/NNS ,/, are/VBP able/JJ to/TO infer/VB good/JJ value/NN functions/NNS ,/, even/RB under/IN low/JJ samples/NNS regimes/NNS ./.
In/IN addition/NN to/IN data/NNS efficiency/NN ,/, we/PRP will/MD show/VB in/IN our/PRP$ analysis/NN ,/, that/IN learning/VBG abstractions/NNS of/IN the/DT state/NN space/NN jointly/RB across/IN tasks/NNS leads/VBZ to/IN more/JJR robust/JJ ,/, transferable/JJ representations/NNS with/IN the/DT potential/NN for/IN better/JJR generalization/NN ./.
this/DT shared/VBD representation/NN assumption/NN and/CC leverage/NN the/DT power/NN of/IN multi-task/VB supervised/JJ learning/NN ./.
Finally/RB ,/, we/PRP demonstrate/VBP that/IN the/DT proposed/VBN model/NN and/CC training/NN procedures/NNS ,/, are/VBP able/JJ to/TO infer/VB good/JJ value/NN functions/NNS ,/, even/RB under/IN low/JJ samples/NNS regimes/NNS ./.
In/IN addition/NN to/IN data/NNS efficiency/NN ,/, we/PRP will/MD show/VB in/IN our/PRP$ analysis/NN ,/, that/IN learning/VBG abstractions/NNS of/IN the/DT state/NN space/NN jointly/RB across/IN tasks/NNS leads/VBZ to/IN more/JJR robust/JJ ,/, transferable/JJ representations/NNS with/IN the/DT potential/NN for/IN better/JJR generalization/NN ./.
