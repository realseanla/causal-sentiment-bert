We/PRP consider/VBP the/DT problem/NN of/IN learning/VBG causal/JJ networks/NNS with/IN interventions/NNS ,/, when/WRB each/DT intervention/NN is/VBZ limited/VBN in/IN size/NN under/IN Pearl/NNP 's/POS Structural/NNP Equation/NN Model/NN with/IN independent/JJ errors/NNS (/-LRB- SEM/NN -/HYPH IE/NNP )/-RRB- ./.
The/DT objective/NN is/VBZ to/TO minimize/VB the/DT number/NN of/IN experiments/NNS to/TO discover/VB the/DT causal/JJ directions/NNS of/IN all/PDT the/DT edges/NNS in/IN a/DT causal/JJ graph/NN ./.
Previous/JJ work/NN has/VBZ focused/VBN on/IN the/DT use/NN of/IN separating/VBG systems/NNS for/IN complete/JJ graphs/NNS for/IN this/DT task/NN ./.
We/PRP prove/VBP that/IN any/DT deterministic/JJ adaptive/JJ algorithm/NN needs/VBZ to/TO be/VB a/DT separating/VBG system/NN in/IN order/NN to/TO learn/VB complete/JJ graphs/NNS in/IN the/DT worst/JJS case/NN ./.
In/IN addition/NN ,/, we/PRP present/VBP a/DT novel/JJ separating/VBG system/NN construction/NN ,/, whose/WP$ size/NN is/VBZ close/JJ to/IN optimal/JJ and/CC is/VBZ arguably/RB simpler/JJR than/IN previous/JJ work/NN in/IN combinatorics/NNS ./.
We/PRP also/RB develop/VBP a/DT novel/JJ information/NN theoretic/JJ lower/JJR bound/VBN on/IN the/DT number/NN of/IN interventions/NNS that/WDT applies/VBZ in/IN full/JJ generality/NN ,/, including/VBG for/IN randomized/JJ adaptive/JJ learning/NN algorithms/NNS ./.
