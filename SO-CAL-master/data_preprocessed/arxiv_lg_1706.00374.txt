We/PRP present/VBP Attract/VB -/HYPH Repel/VB ,/, an/DT algorithm/NN for/IN improving/VBG the/DT semantic/JJ quality/NN of/IN word/NN vectors/NNS by/IN injecting/VBG constraints/NNS extracted/VBN from/IN lexical/JJ resources/NNS ./.
Attract/VB -/HYPH Repel/VB facilitates/VBZ the/DT use/NN of/IN constraints/NNS from/IN mono/NN -/HYPH and/CC cross-lingual/JJ resources/NNS ,/, yielding/VBG semantically/RB specialised/VBN cross-lingual/JJ vector/NN spaces/NNS ./.
Our/PRP$ evaluation/NN shows/VBZ that/IN the/DT method/NN can/MD make/VB use/NN of/IN existing/VBG cross-lingual/JJ lexicons/NNS to/TO construct/VB high/JJ -/HYPH quality/NN vector/NN spaces/NNS for/IN a/DT plethora/NN of/IN different/JJ languages/NNS ,/, facilitating/VBG semantic/JJ transfer/NN from/IN high/JJ -/HYPH to/TO lower/VB -/: resource/NN ones/NNS ./.
The/DT effectiveness/NN of/IN our/PRP$ approach/NN is/VBZ demonstrated/VBN with/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS on/IN semantic/JJ similarity/NN datasets/NNS in/IN six/CD languages/NNS ./.
We/PRP next/RB show/VBP that/IN Attract/VB -/HYPH Repel/VB -/HYPH specialised/VBN vectors/NNS boost/VBP performance/NN in/IN the/DT downstream/JJ task/NN of/IN dialogue/NN state/NN tracking/NN (/-LRB- DST/NN )/-RRB- across/IN multiple/JJ languages/NNS ./.
Finally/RB ,/, we/PRP show/VBP that/IN cross-lingual/JJ vector/NN spaces/NNS produced/VBN by/IN our/PRP$ algorithm/NN facilitate/VB the/DT training/NN of/IN multilingual/JJ DST/NN models/NNS ,/, which/WDT brings/VBZ further/JJ performance/NN improvements/NNS ./.
