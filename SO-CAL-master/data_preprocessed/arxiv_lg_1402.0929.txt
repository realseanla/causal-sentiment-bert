Bayesian/JJ optimization/NN has/VBZ proven/VBN to/TO be/VB a/DT highly/RB effective/JJ methodology/NN for/IN the/DT global/JJ optimization/NN of/IN unknown/JJ ,/, expensive/JJ and/CC multimodal/JJ functions/NNS ./.
The/DT ability/NN to/TO accurately/RB model/VB distributions/NNS over/IN functions/NNS is/VBZ critical/JJ to/IN the/DT effectiveness/NN of/IN Bayesian/JJ optimization/NN ./.
Although/IN Gaussian/JJ processes/NNS provide/VBP a/DT flexible/JJ prior/JJ over/IN functions/NNS which/WDT can/MD be/VB queried/VBN efficiently/RB ,/, there/EX are/VBP various/JJ classes/NNS of/IN functions/NNS that/WDT remain/VBP difficult/JJ to/TO model/VB ./.
One/CD of/IN the/DT most/RBS frequently/RB occurring/VBG of/IN these/DT is/VBZ the/DT class/NN of/IN non-stationary/JJ functions/NNS ./.
The/DT optimization/NN of/IN the/DT hyperparameters/NNS of/IN machine/NN learning/NN algorithms/NNS is/VBZ a/DT problem/NN domain/NN in/IN which/WDT parameters/NNS are/VBP often/RB manually/RB transformed/VBN a/FW priori/FW ,/, for/IN example/NN by/IN optimizing/VBG in/IN "/`` log/NN -/HYPH space/NN ,/, "/'' to/TO mitigate/VB the/DT effects/NNS of/IN spatially/RB -/HYPH varying/VBG length/NN scale/NN ./.
We/PRP develop/VBP a/DT methodology/NN for/IN automatically/RB learning/VBG a/DT wide/JJ family/NN of/IN bijective/JJ transformations/NNS or/CC warpings/NNS of/IN the/DT input/NN space/NN using/VBG the/DT Beta/NN cumulative/JJ distribution/NN function/NN ./.
We/PRP further/RB extend/VBP the/DT warping/NN framework/NN to/TO multi-task/VB Bayesian/JJ optimization/NN so/IN that/IN multiple/JJ tasks/NNS can/MD be/VB warped/JJ into/IN a/DT jointly/RB stationary/JJ space/NN ./.
On/IN a/DT set/NN of/IN challenging/JJ benchmark/NN optimization/NN tasks/NNS ,/, we/PRP observe/VBP that/IN the/DT inclusion/NN of/IN warping/VBG greatly/RB improves/VBZ on/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN ,/, producing/VBG better/JJR results/NNS faster/RBR and/CC more/RBR reliably/RB ./.
