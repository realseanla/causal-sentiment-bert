Automated/VBN story/NN generation/NN is/VBZ the/DT problem/NN of/IN automatically/RB selecting/VBG a/DT sequence/NN of/IN events/NNS ,/, actions/NNS ,/, or/CC words/NNS that/WDT can/MD be/VB told/VBN as/IN a/DT story/NN ./.
We/PRP seek/VBP to/TO develop/VB a/DT system/NN that/WDT can/MD generate/VB stories/NNS by/IN learning/VBG everything/NN it/PRP needs/VBZ to/TO know/VB from/IN textual/JJ story/NN corpora/NNS ./.
To/IN date/NN ,/, recurrent/JJ neural/JJ networks/NNS that/WDT learn/VBP language/NN models/NNS at/IN character/NN ,/, word/NN ,/, or/CC sentence/NN levels/NNS have/VBP had/VBN little/JJ success/NN generating/VBG coherent/JJ stories/NNS ./.
We/PRP explore/VBP the/DT question/NN of/IN event/NN representations/NNS that/WDT provide/VBP a/DT mid-level/NN of/IN abstraction/NN between/IN words/NNS and/CC sentences/NNS in/IN order/NN to/TO retain/VB the/DT semantic/JJ information/NN of/IN the/DT original/JJ data/NNS while/IN minimizing/VBG event/NN sparsity/NN ./.
We/PRP present/VBP a/DT technique/NN for/IN preprocessing/VBG textual/JJ story/NN data/NNS into/IN event/NN sequences/NNS ./.
We/PRP then/RB present/VBP a/DT technique/NN for/IN automated/VBN story/NN generation/NN whereby/WRB we/PRP decompose/VBP the/DT problem/NN into/IN the/DT generation/NN of/IN successive/JJ events/NNS (/-LRB- event2event/NN )/-RRB- and/CC the/DT generation/NN of/IN natural/JJ language/NN sentences/NNS from/IN events/NNS (/-LRB- event2sentence/NN )/-RRB- ./.
We/PRP give/VBP empirical/JJ results/NNS comparing/VBG different/JJ event/NN representations/NNS and/CC their/PRP$ effects/NNS on/IN event/NN successor/NN generation/NN and/CC the/DT translation/NN of/IN events/NNS to/IN natural/JJ language/NN ./.
