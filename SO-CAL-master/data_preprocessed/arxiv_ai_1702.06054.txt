Reinforcement/NN Learning/VBG algorithms/NNS can/MD learn/VB complex/JJ behavioral/JJ patterns/NNS for/IN sequential/JJ decision/NN making/VBG tasks/NNS wherein/WRB an/DT agent/NN interacts/VBZ with/IN an/DT environment/NN and/CC acquires/VBZ feedback/NN in/IN the/DT form/NN of/IN rewards/NNS sampled/VBN from/IN it/PRP ./.
Traditionally/RB ,/, such/JJ algorithms/NNS make/VBP decisions/NNS ,/, i.e./FW ,/, select/JJ actions/NNS to/TO execute/VB ,/, at/IN every/DT single/JJ time/NN step/NN of/IN the/DT agent/NN -/HYPH environment/NN interactions/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT novel/JJ framework/NN ,/, Fine/JJ Grained/NNP Action/NNP Repetition/NNP (/-LRB- FiGAR/NNP )/-RRB- ,/, which/WDT enables/VBZ the/DT agent/NN to/TO decide/VB the/DT action/NN as/RB well/RB as/IN the/DT time/NN scale/NN of/IN repeating/VBG it/PRP ./.
FiGAR/NNP can/MD be/VB used/VBN for/IN improving/VBG any/DT Deep/JJ Reinforcement/NN Learning/VBG algorithm/NN which/WDT maintains/VBZ an/DT explicit/JJ policy/NN estimate/NN by/IN enabling/VBG temporal/JJ abstractions/NNS in/IN the/DT action/NN space/NN ./.
We/PRP empirically/RB demonstrate/VBP the/DT efficacy/NN of/IN our/PRP$ framework/NN by/IN showing/VBG performance/NN improvements/NNS on/IN top/NN of/IN three/CD policy/NN search/NN algorithms/NNS in/IN different/JJ domains/NNS :/: Asynchronous/JJ Advantage/NN Actor/NN Critic/NN in/IN the/DT Atari/NNP 2600/CD domain/NN ,/, Trust/NNP Region/NNP Policy/NNP Optimization/NN in/IN Mujoco/NNP domain/NN and/CC Deep/JJ Deterministic/JJ Policy/NN Gradients/NNS in/IN the/DT TORCS/NN car/NN racing/NN domain/NN ./.
