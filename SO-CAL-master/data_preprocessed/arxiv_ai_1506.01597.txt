We/PRP propose/VBP an/DT abstraction/NN -/HYPH based/VBN multi-document/JJ summarization/NN framework/NN that/WDT can/MD construct/VB new/JJ sentences/NNS by/IN exploring/VBG more/JJR fine/JJ -/HYPH grained/JJ syntactic/JJ units/NNS than/IN sentences/NNS ,/, namely/RB ,/, noun/NN //, verb/VB phrases/NNS ./.
Different/JJ from/IN existing/VBG abstraction/NN -/HYPH based/VBN approaches/NNS ,/, our/PRP$ method/NN first/JJ constructs/NNS a/DT pool/NN of/IN concepts/NNS and/CC facts/NNS represented/VBN by/IN phrases/NNS from/IN the/DT input/NN documents/NNS ./.
Then/RB new/JJ sentences/NNS are/VBP generated/VBN by/IN selecting/VBG and/CC merging/VBG informative/JJ phrases/NNS to/TO maximize/VB the/DT salience/NN of/IN phrases/NNS and/CC meanwhile/RB satisfy/VB the/DT sentence/NN construction/NN constraints/NNS ./.
We/PRP employ/VBP integer/NN linear/JJ optimization/NN for/IN conducting/VBG phrase/NN selection/NN and/CC merging/VBG simultaneously/RB in/IN order/NN to/TO achieve/VB the/DT global/JJ optimal/JJ solution/NN for/IN a/DT summary/NN ./.
Experimental/JJ results/NNS on/IN the/DT benchmark/NN data/NNS set/VBP TAC/NN 2011/CD show/NN that/IN our/PRP$ framework/NN outperforms/VBZ the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN models/NNS under/IN automated/VBN pyramid/NN evaluation/NN metric/JJ ,/, and/CC achieves/VBZ reasonably/RB well/RB results/VBZ on/IN manual/JJ linguistic/JJ quality/NN evaluation/NN ./.
