The/DT logistic/JJ loss/NN function/NN is/VBZ often/RB advocated/VBN in/IN machine/NN learning/NN and/CC statistics/NNS as/IN a/DT smooth/JJ and/CC strictly/RB convex/JJ surrogate/NN for/IN the/DT 0/CD -/HYPH 1/CD loss/NN ./.
In/IN this/DT paper/NN we/PRP investigate/VBP the/DT question/NN of/IN whether/IN these/DT smoothness/NN and/CC convexity/NN properties/NNS make/VBP the/DT logistic/JJ loss/NN preferable/JJ to/IN other/JJ widely/RB considered/VBN options/NNS such/JJ as/IN the/DT hinge/NN loss/NN ./.
We/PRP show/VBP that/IN in/IN contrast/NN to/IN known/VBN asymptotic/JJ bounds/NNS ,/, as/RB long/RB as/IN the/DT number/NN of/IN prediction/NN //HYPH optimization/NN iterations/NNS is/VBZ sub/NN exponential/JJ ,/, the/DT logistic/JJ loss/NN provides/VBZ no/DT improvement/NN over/IN a/DT generic/JJ non-smooth/JJ loss/NN function/NN such/JJ as/IN the/DT hinge/NN loss/NN ./.
In/IN particular/JJ we/PRP show/VBP that/IN the/DT convergence/NN rate/NN of/IN stochastic/JJ logistic/JJ optimization/NN is/VBZ bounded/VBN from/IN below/RB by/IN a/DT polynomial/JJ in/IN the/DT diameter/NN of/IN the/DT decision/NN set/NN and/CC the/DT number/NN of/IN prediction/NN iterations/NNS ,/, and/CC provide/VB a/DT matching/NN tight/JJ upper/JJ bound/VBN ./.
This/DT resolves/VBZ the/DT COLT/NN open/JJ problem/NN of/IN McMahan/NNP and/CC Streeter/NNP (/-LRB- 2012/CD )/-RRB- ./.
