Policy/NN iteration/NN (/-LRB- PI/NN )/-RRB- is/VBZ a/DT recursive/JJ process/NN of/IN policy/NN evaluation/NN and/CC improvement/NN to/TO solve/VB an/DT optimal/JJ decision/NN -/HYPH making/NN ,/, e.g./FW ,/, reinforcement/NN learning/NN (/-LRB- RL/NN )/-RRB- or/CC optimal/JJ control/NN problem/NN and/CC has/VBZ served/VBN as/IN the/DT fundamental/JJ to/TO develop/VB RL/NN methods/NNS ./.
Motivated/VBN by/IN integral/JJ PI/NN (/-LRB- IPI/NN )/-RRB- schemes/NNS in/IN optimal/JJ control/NN and/CC RL/NN methods/NNS in/IN continuous/JJ time/NN and/CC space/NN (/-LRB- CTS/NNP )/-RRB- ,/, this/DT paper/NN proposes/VBZ on/IN -/HYPH policy/NN IPI/NN to/TO solve/VB the/DT general/JJ RL/NN problem/NN in/IN CTS/NNP ,/, with/IN its/PRP$ environment/NN modeled/VBN by/IN an/DT ordinary/JJ differential/JJ equation/NN (/-LRB- ODE/NN )/-RRB- ./.
In/IN such/JJ continuous/JJ domain/NN ,/, we/PRP also/RB propose/VBP four/CD off/IN -/HYPH policy/NN IPI/NN methods/NNS ---/, two/CD are/VBP the/DT ideal/JJ PI/NN forms/VBZ that/IN use/NN advantage/NN and/CC Q/NN -/HYPH functions/NNS ,/, respectively/RB ,/, and/CC the/DT other/JJ two/CD are/VBP natural/JJ extensions/NNS of/IN the/DT existing/VBG off/RB -/HYPH policy/NN IPI/NN schemes/NNS to/IN our/PRP$ general/JJ RL/NN framework/NN ./.
Compared/VBN to/IN the/DT IPI/NN methods/NNS in/IN optimal/JJ control/NN ,/, the/DT proposed/VBN IPI/NN schemes/NNS can/MD be/VB applied/VBN to/IN more/JJR general/JJ situations/NNS and/CC do/VBP not/RB require/VB an/DT initial/JJ stabilizing/VBG policy/NN to/TO run/VB ;/: they/PRP are/VBP also/RB strongly/RB relevant/JJ to/IN the/DT RL/NNP algorithms/NNS in/IN CTS/NNP such/JJ as/IN advantage/NN updating/NN ,/, Q/NN -/HYPH learning/NN ,/, and/CC value/NN -/HYPH gradient/NN based/VBN (/-LRB- VGB/NN )/-RRB- greedy/JJ policy/NN improvement/NN ./.
Our/PRP$ on/IN -/HYPH policy/NN IPI/NNP is/VBZ basically/RB model/NN -/HYPH based/VBN but/CC can/MD be/VB made/VBN partially/RB model/NN -/HYPH free/JJ ;/: each/DT off/IN -/HYPH policy/NN method/NN is/VBZ also/RB either/CC partially/RB or/CC completely/RB model/NN -/HYPH free/JJ ./.
The/DT mathematical/JJ properties/NNS of/IN the/DT IPI/NN methods/NNS ---/, admissibility/NN ,/, monotone/JJ improvement/NN ,/, and/CC convergence/NN towards/IN the/DT optimal/JJ solution/NN ---/, are/VBP all/DT rigorously/RB proven/VBN ,/, together/RB with/IN the/DT equivalence/NN of/IN on/IN -/HYPH and/CC off/RB -/HYPH policy/NN IPI/NNP ./.
Finally/RB ,/, the/DT IPI/NNP methods/NNS are/VBP simulated/VBN with/IN an/DT inverted/VBN -/HYPH pendulum/NN model/NN to/TO support/VB the/DT theory/NN and/CC verify/VB the/DT performance/NN ./.
