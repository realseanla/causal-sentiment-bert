We/PRP show/VBP how/WRB to/TO estimate/VB a/DT model/NN 's/POS test/NN error/NN from/IN unlabeled/JJ data/NNS ,/, on/IN distributions/NNS very/RB different/JJ from/IN the/DT training/NN distribution/NN ,/, while/IN assuming/VBG only/RB that/IN certain/JJ conditional/JJ independencies/NNS are/VBP preserved/VBN between/IN train/NN and/CC test/NN ./.
We/PRP do/VBP not/RB need/VB to/TO assume/VB that/IN the/DT optimal/JJ predictor/NN is/VBZ the/DT same/JJ between/IN train/NN and/CC test/NN ,/, or/CC that/IN the/DT true/JJ distribution/NN lies/VBZ in/IN any/DT parametric/JJ family/NN ./.
We/PRP can/MD also/RB efficiently/RB differentiate/VB the/DT error/NN estimate/NN to/TO perform/VB unsupervised/JJ discriminative/JJ learning/NN ./.
Our/PRP$ technical/JJ tool/NN is/VBZ the/DT method/NN of/IN moments/NNS ,/, which/WDT allows/VBZ us/PRP to/TO exploit/VB conditional/JJ independencies/NNS in/IN the/DT absence/NN of/IN a/DT fully/RB -/HYPH specified/VBN model/NN ./.
Our/PRP$ framework/NN encompasses/VBZ a/DT large/JJ family/NN of/IN losses/NNS including/VBG the/DT log/NN and/CC exponential/JJ loss/NN ,/, and/CC extends/VBZ to/IN structured/JJ output/NN settings/NNS such/JJ as/IN hidden/JJ Markov/NNP models/NNS ./.
