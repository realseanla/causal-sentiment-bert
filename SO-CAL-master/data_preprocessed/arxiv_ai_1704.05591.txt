In/IN this/DT paper/NN ,/, we/PRP propose/VBP an/DT OCR/NN (/-LRB- optical/JJ character/NN recognition/NN )/-RRB- -/HYPH based/VBN localization/NN system/NN called/VBN OCRAPOSE/NNP II/NNP ,/, which/WDT is/VBZ applicable/JJ in/IN a/DT number/NN of/IN indoor/JJ scenarios/NNS including/VBG office/NN buildings/NNS ,/, parkings/NNS ,/, airports/NNS ,/, grocery/NN stores/NNS ,/, etc/FW ./.
In/IN these/DT scenarios/NNS ,/, characters/NNS (/-LRB- i.e./FW texts/NNS or/CC numbers/NNS )/-RRB- can/MD be/VB used/VBN as/IN suitable/JJ distinctive/JJ landmarks/NNS for/IN localization/NN ./.
The/DT proposed/VBN system/NN takes/VBZ advantage/NN of/IN OCR/NNP to/TO read/VB these/DT characters/NNS in/IN the/DT query/NN still/RB images/NNS and/CC provides/VBZ a/DT rough/JJ location/NN estimate/NN using/VBG a/DT floor/NN plan/NN ./.
Then/RB ,/, it/PRP finds/VBZ depth/NN and/CC angle/NN -/HYPH of/IN -/HYPH view/NN of/IN the/DT query/NN using/VBG the/DT information/NN provided/VBN by/IN the/DT OCR/NNP engine/NN in/IN order/NN to/TO refine/VB the/DT location/NN estimate/NN ./.
We/PRP derive/VBP novel/JJ formulas/NNS for/IN the/DT query/NN angle/NN -/HYPH of/IN -/HYPH view/NN and/CC depth/NN estimation/NN using/VBG image/NN line/NN segments/NNS and/CC the/DT OCR/NNP box/NN information/NN ./.
We/PRP demonstrate/VBP the/DT applicability/NN and/CC effectiveness/NN of/IN the/DT proposed/VBN system/NN through/IN experiments/NNS in/IN indoor/JJ scenarios/NNS ./.
It/PRP is/VBZ shown/VBN that/IN our/PRP$ system/NN demonstrates/VBZ better/JJR performance/NN compared/VBN to/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN benchmarks/NNS in/IN terms/NNS of/IN location/NN recognition/NN rate/NN and/CC average/JJ localization/NN error/NN specially/RB under/IN sparse/JJ database/NN condition/NN ./.
