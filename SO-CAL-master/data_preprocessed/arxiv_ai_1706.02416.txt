In/IN this/DT paper/NN ,/, we/PRP introduce/VBP a/DT generalized/VBN value/NN iteration/NN network/NN (/-LRB- GVIN/NN )/-RRB- ,/, which/WDT is/VBZ an/DT end/NN -/HYPH to/IN -/HYPH end/NN neural/JJ network/NN planning/NN module/NN ./.
GVIN/NNP emulates/VBZ the/DT value/NN iteration/NN algorithm/NN by/IN using/VBG a/DT novel/JJ graph/NN convolution/NN operator/NN ,/, which/WDT enables/VBZ GVIN/NNP to/TO learn/VB and/CC plan/VB on/IN irregular/JJ spatial/JJ graphs/NNS ./.
We/PRP propose/VBP three/CD novel/JJ differentiable/JJ kernels/NNS as/IN graph/NN convolution/NN operators/NNS and/CC show/VBP that/IN the/DT embedding/NN based/VBN kernel/NN achieves/VBZ the/DT best/JJS performance/NN ./.
We/PRP further/RB propose/VBP episodic/JJ Q/NN -/HYPH learning/NN ,/, an/DT improvement/NN upon/IN traditional/JJ n/NN -/HYPH step/NN Q/NN -/HYPH learning/NN that/WDT stabilizes/VBZ training/NN for/IN networks/NNS that/WDT contain/VBP a/DT planning/NN module/NN ./.
Lastly/RB ,/, we/PRP evaluate/VBP GVIN/NNP on/IN planning/VBG problems/NNS in/IN 2D/NN mazes/NNS ,/, irregular/JJ graphs/NNS ,/, and/CC real/JJ -/HYPH world/NN street/NN networks/NNS ,/, showing/VBG that/IN GVIN/NNP generalizes/VBZ well/RB for/IN both/DT arbitrary/JJ graphs/NNS and/CC unseen/JJ graphs/NNS of/IN larger/JJR scale/NN and/CC outperforms/VBZ a/DT naive/JJ generalization/NN of/IN VIN/NN (/-LRB- discretizing/VBG a/DT spatial/JJ graph/NN into/IN a/DT 2D/NN image/NN )/-RRB- ./.
