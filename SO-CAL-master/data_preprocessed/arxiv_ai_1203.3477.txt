Partially/RB -/HYPH Observable/JJ Markov/NNP Decision/NN Processes/NNS (/-LRB- POMDPs/NNS )/-RRB- are/VBP typically/RB solved/VBN by/IN finding/VBG an/DT approximate/JJ global/JJ solution/NN to/IN a/DT corresponding/VBG belief/NN -/HYPH MDP/NN ./.
In/IN this/DT paper/NN ,/, we/PRP offer/VBP a/DT new/JJ planning/NN algorithm/NN for/IN POMDPs/NNS with/IN continuous/JJ state/NN ,/, action/NN and/CC observation/NN spaces/NNS ./.
Since/IN such/JJ domains/NNS have/VBP an/DT inherent/JJ notion/NN of/IN locality/NN ,/, we/PRP can/MD find/VB an/DT approximate/JJ solution/NN using/VBG local/JJ optimization/NN methods/NNS ./.
We/PRP parameterize/VBP the/DT belief/NN distribution/NN as/IN a/DT Gaussian/JJ mixture/NN ,/, and/CC use/VB the/DT Extended/NNP Kalman/NNP Filter/NNP (/-LRB- EKF/NNP )/-RRB- to/TO approximate/VB the/DT belief/NN update/NN ./.
Since/IN the/DT EKF/NNP is/VBZ a/DT first/JJ -/HYPH order/NN filter/NN ,/, we/PRP can/MD marginalize/VB over/IN the/DT observations/NNS analytically/RB ./.
By/IN using/VBG feedback/NN control/NN and/CC state/NN estimation/NN during/IN policy/NN execution/NN ,/, we/PRP recover/VBP a/DT behavior/NN that/WDT is/VBZ effectively/RB conditioned/VBN on/IN incoming/JJ observations/NNS despite/IN the/DT unconditioned/JJ planning/NN ./.
Local/JJ optimization/NN provides/VBZ no/DT guarantees/NNS of/IN global/JJ optimality/NN ,/, but/CC it/PRP allows/VBZ us/PRP to/TO tackle/VB domains/NNS that/WDT are/VBP at/IN least/RBS an/DT order/NN of/IN magnitude/NN larger/JJR than/IN the/DT current/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN ./.
We/PRP demonstrate/VBP the/DT scalability/NN of/IN our/PRP$ algorithm/NN by/IN considering/VBG a/DT simulated/JJ hand/NN -/HYPH eye/NN coordination/NN domain/NN with/IN 16/CD continuous/JJ state/NN dimensions/NNS and/CC 6/CD continuous/JJ action/NN dimensions/NNS ./.
