Factorizing/VBG low/JJ -/HYPH rank/NN matrices/NNS has/VBZ many/JJ applications/NNS in/IN machine/NN learning/NN and/CC statistics/NNS ./.
For/IN probabilistic/JJ models/NNS in/IN the/DT Bayes/NNP optimal/JJ setting/NN ,/, a/DT general/JJ expression/NN for/IN the/DT mutual/JJ information/NN has/VBZ been/VBN proposed/VBN using/VBG heuristic/NN statistical/JJ physics/NN computations/NNS ,/, and/CC proven/VBN in/IN few/JJ specific/JJ cases/NNS ./.
Here/RB ,/, we/PRP show/VBP how/WRB to/TO rigorously/RB prove/VB the/DT conjectured/JJ formula/NN for/IN the/DT symmetric/JJ rank/NN -/HYPH one/CD case/NN ./.
This/DT allows/VBZ to/TO express/VB the/DT minimal/JJ mean/NN -/HYPH square/NN -/HYPH error/NN and/CC to/TO characterize/VB the/DT detectability/NN phase/NN transitions/NNS in/IN a/DT large/JJ set/NN of/IN estimation/NN problems/NNS ranging/VBG from/IN community/NN detection/NN to/IN sparse/JJ PCA/NN ./.
We/PRP also/RB show/VBP that/IN for/IN a/DT large/JJ set/NN of/IN parameters/NNS ,/, an/DT iterative/JJ algorithm/NN called/VBN approximate/JJ message/NN -/HYPH passing/NN is/VBZ Bayes/NNP optimal/JJ ./.
There/RB exists/VBZ ,/, however/RB ,/, a/DT gap/NN between/IN what/WP currently/RB known/VBN polynomial/JJ algorithms/NNS can/MD do/VB and/CC what/WP is/VBZ expected/VBN information/NN theoretically/RB ./.
Additionally/RB ,/, the/DT proof/NN technique/NN has/VBZ an/DT interest/NN of/IN its/PRP$ own/JJ and/CC exploits/NNS three/CD essential/JJ ingredients/NNS :/: the/DT interpolation/NN method/NN introduced/VBN in/IN statistical/JJ physics/NN by/IN Guerra/NNP ,/, the/DT analysis/NN of/IN the/DT approximate/JJ message/NN -/HYPH passing/VBG algorithm/NN and/CC the/DT theory/NN of/IN spatial/JJ coupling/NN and/CC threshold/NN saturation/NN in/IN coding/VBG ./.
Our/PRP$ approach/NN is/VBZ generic/JJ and/CC applicable/JJ to/IN other/JJ open/JJ problems/NNS in/IN statistical/JJ estimation/NN where/WRB heuristic/NN statistical/JJ physics/NN predictions/NNS are/VBP available/JJ ./.
