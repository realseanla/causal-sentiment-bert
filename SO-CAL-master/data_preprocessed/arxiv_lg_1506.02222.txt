Ordinary/JJ least/JJS squares/NNS (/-LRB- OLS/NN )/-RRB- is/VBZ the/DT default/NN method/NN for/IN fitting/JJ linear/JJ models/NNS ,/, but/CC is/VBZ not/RB applicable/JJ for/IN problems/NNS with/IN dimensionality/NN larger/JJR than/IN the/DT sample/NN size/NN ./.
For/IN these/DT problems/NNS ,/, we/PRP advocate/VBP the/DT use/NN of/IN a/DT generalized/VBN version/NN of/IN OLS/NNP motivated/VBN by/IN ridge/NN regression/NN ,/, and/CC propose/VB two/CD novel/JJ three/CD -/HYPH step/NN algorithms/NNS involving/VBG least/JJS squares/NNS fitting/VBG and/CC hard/JJ thresholding/NN ./.
The/DT algorithms/NNS are/VBP methodologically/RB simple/JJ to/TO understand/VB intuitively/RB ,/, computationally/RB easy/JJ to/TO implement/VB efficiently/RB ,/, and/CC theoretically/RB appealing/VBG for/IN choosing/VBG models/NNS consistently/RB ./.
Numerical/NNP exercises/VBZ comparing/VBG our/PRP$ methods/NNS with/IN penalization/NN -/HYPH based/VBN approaches/NNS in/IN simulations/NNS and/CC data/NNS analyses/NNS illustrate/VBP the/DT great/JJ potential/NN of/IN the/DT proposed/VBN algorithms/NNS ./.
