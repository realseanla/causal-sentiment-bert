A/DT new/JJ algorithm/NN named/VBN EXPected/NNP Similarity/NNP Estimation/NNP (/-LRB- EXPoSE/VB )/-RRB- was/VBD recently/RB proposed/VBN to/TO solve/VB the/DT problem/NN of/IN large/JJ -/HYPH scale/NN anomaly/NN detection/NN ./.
It/PRP is/VBZ a/DT non-parametric/JJ and/CC distribution/NN free/JJ kernel/NN method/NN based/VBN on/IN the/DT Hilbert/NNP space/NN embedding/NN of/IN probability/NN measures/NNS ./.
Given/VBN a/DT dataset/NN of/IN $/$ n/NN $/$ samples/NNS ,/, EXPoSE/VB needs/VBZ only/RB $/$ \/CD mathcal/NN {/-LRB- O/NN }/-RRB- (/-LRB- n/NN )/-RRB- $/$ (/-LRB- linear/JJ time/NN )/-RRB- to/TO build/VB a/DT model/NN and/CC $/$ \/CD mathcal/NN {/-LRB- O/NN }/-RRB- (/-LRB- 1/CD )/-RRB- $/$ (/-LRB- constant/JJ time/NN )/-RRB- to/TO make/VB a/DT prediction/NN ./.
In/IN this/DT work/NN we/PRP improve/VBP the/DT linear/JJ computational/JJ complexity/NN and/CC show/VBP that/IN an/DT $/$ \/CD epsilon/CD $/$ -/HYPH accurate/JJ model/NN can/MD be/VB estimated/VBN in/IN constant/JJ time/NN ,/, which/WDT has/VBZ significant/JJ implications/NNS for/IN large/JJ -/HYPH scale/NN learning/NN problems/NNS ./.
To/TO achieve/VB this/DT goal/NN ,/, we/PRP cast/VBD the/DT original/JJ EXPoSE/NN formulation/NN into/IN a/DT stochastic/JJ optimization/NN problem/NN ./.
It/PRP is/VBZ crucial/JJ that/IN this/DT approach/NN allows/VBZ us/PRP to/TO determine/VB the/DT number/NN of/IN iteration/NN based/VBN on/IN a/DT desired/VBN accuracy/NN $/$ \/CD epsilon/CD $/$ ,/, independent/JJ of/IN the/DT dataset/NN size/NN $/$ n/NN $/$ ./.
We/PRP will/MD show/VB that/IN the/DT proposed/VBN stochastic/JJ gradient/NN descent/NN algorithm/NN works/VBZ in/IN general/JJ (/-LRB- possible/JJ infinite/JJ -/HYPH dimensional/JJ )/-RRB- Hilbert/NNP spaces/NNS ,/, is/VBZ easy/JJ to/TO implement/VB and/CC requires/VBZ no/DT additional/JJ step/NN -/HYPH size/NN parameters/NNS ./.
