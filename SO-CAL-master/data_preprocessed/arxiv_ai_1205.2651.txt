We/PRP introduce/VBP a/DT challenging/JJ real/JJ -/HYPH world/NN planning/NN problem/NN where/WRB actions/NNS must/MD be/VB taken/VBN at/IN each/DT location/NN in/IN a/DT spatial/JJ area/NN at/IN each/DT point/NN in/IN time/NN ./.
We/PRP use/VBP forestry/NN planning/NN as/IN the/DT motivating/VBG application/NN ./.
In/IN Large/JJ Scale/NN Spatial/JJ -/HYPH Temporal/JJ (/-LRB- LSST/NN )/-RRB- planning/NN problems/NNS ,/, the/DT state/NN and/CC action/NN spaces/NNS are/VBP defined/VBN as/IN the/DT cross-products/NNS of/IN many/JJ local/JJ state/NN and/CC action/NN spaces/NNS spread/VBP over/IN a/DT large/JJ spatial/JJ area/NN such/JJ as/IN a/DT city/NN or/CC forest/NN ./.
These/DT problems/NNS possess/VBP state/NN uncertainty/NN ,/, have/VBP complex/JJ utility/NN functions/VBZ involving/VBG spatial/JJ constraints/NNS and/CC we/PRP generally/RB must/MD rely/VB on/IN simulations/NNS rather/RB than/IN an/DT explicit/JJ transition/NN model/NN ./.
We/PRP define/VBP LSST/NN problems/NNS as/IN reinforcement/NN learning/NN problems/NNS and/CC present/VB a/DT solution/NN using/VBG policy/NN gradients/NNS ./.
We/PRP compare/VBP two/CD different/JJ policy/NN formulations/NNS :/: an/DT explicit/JJ policy/NN that/WDT identifies/VBZ each/DT location/NN in/IN space/NN and/CC the/DT action/NN to/TO take/VB there/RB ;/: and/CC an/DT abstract/JJ policy/NN that/WDT defines/VBZ the/DT proportion/NN of/IN actions/NNS to/TO take/VB across/RB all/DT locations/NNS in/IN space/NN ./.
We/PRP show/VBP that/IN the/DT abstract/JJ policy/NN is/VBZ more/RBR robust/JJ and/CC achieves/VBZ higher/JJR rewards/NNS with/IN far/RB fewer/JJR parameters/NNS than/IN the/DT elementary/JJ policy/NN ./.
This/DT abstract/JJ policy/NN is/VBZ also/RB a/DT better/JJR fit/NN to/IN the/DT properties/NNS that/WDT practitioners/NNS in/IN LSST/NN problem/NN domains/NNS require/VBP for/IN such/JJ methods/NNS to/TO be/VB widely/RB useful/JJ ./.
