In/IN this/DT paper/NN ,/, we/PRP investigate/VBP the/DT cross-media/JJ retrieval/NN between/IN images/NNS and/CC text/NN ,/, i.e./FW ,/, using/VBG image/NN to/TO search/VB text/NN (/-LRB- I2T/NN )/-RRB- and/CC using/VBG text/NN to/TO search/VB images/NNS (/-LRB- T2I/NN )/-RRB- ./.
Existing/VBG cross-media/JJ retrieval/NN methods/NNS usually/RB learn/VBP one/CD couple/NN of/IN projections/NNS ,/, by/IN which/WDT the/DT original/JJ features/NNS of/IN images/NNS and/CC text/NN can/MD be/VB projected/VBN into/IN a/DT common/JJ latent/JJ space/NN to/TO measure/VB the/DT content/NN similarity/NN ./.
However/RB ,/, using/VBG the/DT same/JJ projections/NNS for/IN the/DT two/CD different/JJ retrieval/NN tasks/NNS (/-LRB- I2T/NN and/CC T2I/NN )/-RRB- may/MD lead/VB to/IN a/DT tradeoff/NN between/IN their/PRP$ respective/JJ performances/NNS ,/, rather/RB than/IN their/PRP$ best/JJS performances/NNS ./.
Different/JJ from/IN previous/JJ works/NNS ,/, we/PRP propose/VBP a/DT modality/NN -/HYPH dependent/JJ cross-media/NN retrieval/NN (/-LRB- MDCR/NN )/-RRB- model/NN ,/, where/WRB two/CD couples/NNS of/IN projections/NNS are/VBP learned/VBN for/IN different/JJ cross-media/JJ retrieval/NN tasks/NNS instead/RB of/IN one/CD couple/NN of/IN projections/NNS ./.
Specifically/RB ,/, by/IN jointly/RB optimizing/VBG the/DT correlation/NN between/IN images/NNS and/CC text/NN and/CC the/DT linear/JJ regression/NN from/IN one/CD modal/JJ space/NN (/-LRB- image/NN or/CC text/NN )/-RRB- to/IN the/DT semantic/JJ space/NN ,/, two/CD couples/NNS of/IN mappings/NNS are/VBP learned/VBN to/TO project/VB images/NNS and/CC text/NN from/IN their/PRP$ original/JJ feature/NN spaces/NNS into/IN two/CD common/JJ latent/JJ subspaces/NNS (/-LRB- one/CD for/IN I2T/NN and/CC the/DT other/JJ for/IN T2I/NN )/-RRB- ./.
Extensive/JJ experiments/NNS show/VBP the/DT superiority/NN of/IN the/DT proposed/VBN MDCR/NN compared/VBN with/IN other/JJ methods/NNS ./.
In/IN particular/JJ ,/, based/VBN the/DT 4,096/CD dimensional/JJ convolutional/JJ neural/JJ network/NN (/-LRB- CNN/NNP )/-RRB- visual/JJ feature/NN and/CC 100/CD dimensional/JJ LDA/NN textual/JJ feature/NN ,/, the/DT mAP/NN of/IN the/DT proposed/JJ method/NN achieves/VBZ 41.5/CD \/SYM percent/NN ,/, which/WDT is/VBZ a/DT new/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN on/IN the/DT Wikipedia/NNP dataset/NN ./.
