In/IN the/DT Markov/NNP decision/NN process/NN model/NN ,/, policies/NNS are/VBP usually/RB evaluated/VBN by/IN expected/VBN cumulative/JJ rewards/NNS ./.
As/IN this/DT decision/NN criterion/NN is/VBZ not/RB always/RB suitable/JJ ,/, we/PRP propose/VBP in/IN this/DT paper/NN an/DT algorithm/NN for/IN computing/VBG a/DT policy/NN optimal/JJ for/IN the/DT quantile/NN criterion/NN ./.
Both/DT finite/JJ and/CC infinite/JJ horizons/NNS are/VBP considered/VBN ./.
Finally/RB we/PRP experimentally/RB evaluate/VB our/PRP$ approach/NN on/IN random/JJ MDPs/NNS and/CC on/IN a/DT data/NN center/NN control/NN problem/NN ./.
