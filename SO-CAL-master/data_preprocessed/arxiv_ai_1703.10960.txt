While/IN recent/JJ neural/JJ encoder/NN -/HYPH decoder/NN models/NNS have/VBP shown/VBN great/JJ promise/NN in/IN modeling/VBG open/JJ -/HYPH domain/NN conversations/NNS ,/, they/PRP often/RB generate/VBP dull/JJ and/CC generic/JJ responses/NNS ./.
Unlike/IN past/JJ work/NN that/WDT has/VBZ focused/VBN on/IN diversifying/VBG the/DT output/NN of/IN the/DT decoder/NN at/IN word/NN -/HYPH level/NN to/TO alleviate/VB this/DT problem/NN ,/, we/PRP present/VBP a/DT novel/JJ framework/NN based/VBN on/IN conditional/JJ variational/JJ autoencoders/NNS that/WDT captures/VBZ the/DT discourse/NN -/HYPH level/NN diversity/NN in/IN the/DT encoder/NN ./.
Our/PRP$ model/NN uses/VBZ latent/JJ variables/NNS to/TO learn/VB a/DT distribution/NN over/IN potential/JJ conversational/JJ intents/NNS and/CC generates/VBZ diverse/JJ responses/NNS using/VBG only/RB greedy/JJ decoders/NNS ./.
We/PRP have/VBP further/RB developed/VBN a/DT novel/JJ variant/NN that/WDT is/VBZ integrated/VBN with/IN linguistic/JJ prior/JJ knowledge/NN for/IN better/JJR performance/NN ./.
Finally/RB ,/, the/DT training/NN procedure/NN is/VBZ improved/VBN by/IN introducing/VBG a/DT bag/NN -/HYPH of/IN -/HYPH word/NN loss/NN ./.
Our/PRP$ proposed/VBN models/NNS have/VBP been/VBN validated/VBN to/TO generate/VB significantly/RB more/JJR diverse/JJ responses/NNS than/IN baseline/NN approaches/NNS and/CC exhibit/VBP competence/NN in/IN discourse/NN -/HYPH level/NN decision/NN -/HYPH making/NN ./.
