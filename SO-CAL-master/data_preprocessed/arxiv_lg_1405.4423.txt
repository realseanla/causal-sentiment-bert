Dyadic/JJ prediction/NN methods/NNS operate/VBP on/IN pairs/NNS of/IN objects/NNS (/-LRB- dyads/NNS )/-RRB- ,/, aiming/VBG to/TO infer/VB labels/NNS for/IN out/RB -/HYPH of/IN -/HYPH sample/NN dyads/NNS ./.
We/PRP consider/VBP the/DT full/JJ and/CC almost/RB full/JJ cold/JJ start/NN problem/NN in/IN dyadic/JJ prediction/NN ,/, a/DT setting/NN that/WDT occurs/VBZ when/WRB both/DT objects/NNS in/IN an/DT out/NN -/HYPH of/IN -/HYPH sample/NN dyad/NN have/VBP not/RB been/VBN observed/VBN during/IN training/NN ,/, or/CC if/IN one/CD of/IN them/PRP has/VBZ been/VBN observed/VBN ,/, but/CC very/RB few/JJ times/NNS ./.
A/DT popular/JJ approach/NN for/IN addressing/VBG this/DT problem/NN is/VBZ to/TO train/VB a/DT model/NN that/WDT makes/VBZ predictions/NNS based/VBN on/IN a/DT pairwise/JJ feature/NN representation/NN of/IN the/DT dyads/NNS ,/, or/CC ,/, in/IN case/NN of/IN kernel/NN methods/NNS ,/, based/VBN on/IN a/DT tensor/NN product/NN pairwise/JJ kernel/NN ./.
As/IN an/DT alternative/NN to/IN such/PDT a/DT kernel/NN approach/NN ,/, we/PRP introduce/VBP a/DT novel/JJ two/CD -/HYPH step/NN learning/NN algorithm/NN that/WDT borrows/VBZ ideas/NNS from/IN the/DT fields/NNS of/IN pairwise/JJ learning/NN and/CC spectral/JJ filtering/NN ./.
We/PRP show/VBP theoretically/RB that/IN the/DT two/CD -/HYPH step/NN method/NN is/VBZ very/RB closely/RB related/VBN to/IN the/DT tensor/NN product/NN kernel/NN approach/NN ,/, and/CC experimentally/RB that/IN it/PRP yields/VBZ a/DT slightly/RB better/JJR predictive/JJ performance/NN ./.
Moreover/RB ,/, unlike/IN existing/VBG tensor/NNP product/NN kernel/NN methods/NNS ,/, the/DT two/CD -/HYPH step/NN method/NN allows/VBZ closed/JJ -/HYPH form/NN solutions/NNS for/IN training/NN and/CC parameter/NN selection/NN via/IN cross-validation/NN estimates/VBZ both/CC in/IN the/DT full/JJ and/CC almost/RB full/JJ cold/JJ start/NN settings/NNS ,/, making/VBG the/DT approach/NN much/RB more/RBR efficient/JJ and/CC straightforward/JJ to/TO implement/VB ./.
