We/PRP consider/VBP the/DT general/JJ problem/NN of/IN utilizing/VBG both/DT labeled/VBN and/CC unlabeled/JJ data/NNS to/TO improve/VB data/NNS representation/NN performance/NN ./.
A/DT new/JJ semi-supervised/JJ learning/NN framework/NN is/VBZ proposed/VBN by/IN combing/VBG manifold/JJ regularization/NN and/CC data/NNS representation/NN methods/NNS such/JJ as/IN Non/FW negative/JJ matrix/NN factorization/NN and/CC sparse/JJ coding/NN ./.
We/PRP adopt/VBP unsupervised/JJ data/NNS representation/NN methods/NNS as/IN the/DT learning/NN machines/NNS because/IN they/PRP do/VBP not/RB depend/VB on/IN the/DT labeled/VBN data/NNS ,/, which/WDT can/MD improve/VB machine/NN 's/POS generation/NN ability/NN as/RB much/RB as/IN possible/JJ ./.
The/DT proposed/VBN framework/NN forms/VBZ the/DT Laplacian/JJ regularizer/NN through/IN learning/VBG the/DT affinity/NN graph/NN ./.
We/PRP incorporate/VBP the/DT new/JJ Laplacian/NNP regularizer/NN into/IN the/DT unsupervised/JJ data/NNS representation/NN to/TO smooth/VB the/DT low/JJ dimensional/JJ representation/NN of/IN data/NNS and/CC make/VB use/NN of/IN label/NN information/NN ./.
Experimental/JJ results/NNS on/IN several/JJ real/JJ benchmark/NN datasets/NNS indicate/VBP that/IN our/PRP$ semi-supervised/JJ learning/NN framework/NN achieves/VBZ encouraging/JJ results/NNS compared/VBN with/IN state/NN -/HYPH of/IN -/HYPH art/NN methods/NNS ./.
