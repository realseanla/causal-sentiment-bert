We/PRP apply/VBP kernel/NN -/HYPH based/VBN methods/NNS to/TO solve/VB the/DT difficult/JJ reinforcement/NN learning/VBG problem/NN of/IN 3vs2/CD keepaway/NN in/IN RoboCup/NNP simulated/JJ soccer/NN ./.
Key/JJ challenges/NNS in/IN keepaway/NN are/VBP the/DT high/JJ -/HYPH dimensionality/NN of/IN the/DT state/NN space/NN (/-LRB- rendering/VBG conventional/JJ discretization/NN -/HYPH based/VBN function/NN approximation/NN like/IN tilecoding/VBG infeasible/JJ )/-RRB- ,/, the/DT stochasticity/NN due/IN to/IN noise/NN and/CC multiple/JJ learning/NN agents/NNS needing/VBG to/TO cooperate/VB (/-LRB- meaning/VBG that/IN the/DT exact/JJ dynamics/NNS of/IN the/DT environment/NN are/VBP unknown/JJ )/-RRB- and/CC real/JJ -/HYPH time/NN learning/NN (/-LRB- meaning/VBG that/IN an/DT efficient/JJ online/JJ implementation/NN is/VBZ required/VBN )/-RRB- ./.
We/PRP employ/VBP the/DT general/JJ framework/NN of/IN approximate/JJ policy/NN iteration/NN with/IN least/JJS -/HYPH squares/NNS -/HYPH based/VBN policy/NN evaluation/NN ./.
As/IN underlying/VBG function/NN approximator/NN we/PRP consider/VBP the/DT family/NN of/IN regularization/NN networks/NNS with/IN subset/NN of/IN regressors/NNS approximation/NN ./.
The/DT core/NN of/IN our/PRP$ proposed/VBN solution/NN is/VBZ an/DT efficient/JJ recursive/JJ implementation/NN with/IN automatic/JJ supervised/JJ selection/NN of/IN relevant/JJ basis/NN functions/NNS ./.
Simulation/NNP results/VBZ indicate/VBP that/IN the/DT behavior/NN learned/VBD through/IN our/PRP$ approach/NN clearly/RB outperforms/VBZ the/DT best/JJS results/NNS obtained/VBN earlier/RBR with/IN tilecoding/NN by/IN Stone/NNP et/FW al./FW (/-LRB- 2005/CD )/-RRB- ./.
