In/IN this/DT paper/NN ,/, we/PRP propose/VBP and/CC study/VBP a/DT novel/JJ visual/JJ object/NN tracking/VBG approach/NN based/VBN on/IN convolutional/JJ networks/NNS and/CC recurrent/JJ networks/NNS ./.
The/DT proposed/VBN approach/NN is/VBZ distinct/JJ from/IN the/DT existing/VBG approaches/NNS to/IN visual/JJ object/NN tracking/NN ,/, such/JJ as/IN filtering/NN -/HYPH based/VBN ones/NNS and/CC tracking/NN -/HYPH by/IN -/HYPH detection/NN ones/NNS ,/, in/IN the/DT sense/NN that/IN the/DT tracking/NN system/NN is/VBZ explicitly/RB trained/VBN off/RB -/HYPH line/NN to/TO track/VB anonymous/JJ objects/NNS in/IN a/DT noisy/JJ environment/NN ./.
The/DT proposed/VBN visual/JJ tracking/NN model/NN is/VBZ end/NN -/HYPH to/IN -/HYPH end/NN trainable/JJ ,/, minimizing/VBG any/DT adversarial/JJ effect/NN from/IN mismatches/NNS in/IN object/NN representation/NN and/CC between/IN the/DT true/JJ underlying/JJ dynamics/NNS and/CC learning/VBG dynamics/NNS ./.
We/PRP empirically/RB show/VBP that/IN the/DT proposed/VBN tracking/NN approach/NN works/VBZ well/RB in/IN various/JJ scenarios/NNS by/IN generating/VBG artificial/JJ video/NN sequences/NNS with/IN varying/VBG conditions/NNS ;/: the/DT number/NN of/IN objects/NNS ,/, amount/NN of/IN noise/NN and/CC the/DT match/NN between/IN the/DT training/NN shapes/NNS and/CC test/NN shapes/NNS ./.
