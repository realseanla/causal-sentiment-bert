Inference/NN for/IN latent/JJ feature/NN models/NNS is/VBZ inherently/RB difficult/JJ as/IN the/DT inference/NN space/NN grows/VBZ exponentially/RB with/IN the/DT size/NN of/IN the/DT input/NN data/NNS and/CC number/NN of/IN latent/NN features/NNS ./.
In/IN this/DT work/NN ,/, we/PRP use/VBP Kurihara/NNP &amp;/CC Welling/NNP (/-LRB- 2008/CD )/-RRB- 's/POS maximization/NN -/HYPH expectation/NN framework/NN to/TO perform/VB approximate/JJ MAP/NN inference/NN for/IN linear/JJ -/HYPH Gaussian/JJ latent/NN feature/NN models/NNS with/IN an/DT Indian/JJ Buffet/NNP Process/NN (/-LRB- IBP/NN )/-RRB- prior/JJ ./.
This/DT formulation/NN yields/VBZ a/DT submodular/JJ function/NN of/IN the/DT features/NNS that/WDT corresponds/VBZ to/IN a/DT lower/JJR bound/VBN on/IN the/DT model/NN evidence/NN ./.
By/IN adding/VBG a/DT constant/JJ to/IN this/DT function/NN ,/, we/PRP obtain/VBP a/DT nonnegative/JJ submodular/JJ function/NN that/WDT can/MD be/VB maximized/VBN via/IN a/DT greedy/JJ algorithm/NN that/WDT obtains/VBZ at/IN least/JJS a/DT one/CD -/HYPH third/JJ approximation/NN to/IN the/DT optimal/JJ solution/NN ./.
Our/PRP$ inference/NN method/NN scales/NNS linearly/RB with/IN the/DT size/NN of/IN the/DT input/NN data/NNS ,/, and/CC we/PRP show/VBP the/DT efficacy/NN of/IN our/PRP$ method/NN on/IN the/DT largest/JJS datasets/NNS currently/RB analyzed/VBN using/VBG an/DT IBP/NN model/NN ./.
