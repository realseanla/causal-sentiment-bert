In/IN a/DT semi-supervised/JJ learning/NN scenario/NN ,/, (/-LRB- possibly/RB noisy/JJ )/-RRB- partially/RB observed/VBD labels/NNS are/VBP used/VBN as/IN input/NN to/TO train/VB a/DT classifier/NN ,/, in/IN order/NN to/TO assign/VB labels/NNS to/IN unclassified/JJ samples/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP study/VBP this/DT classifier/NN learning/NN problem/NN from/IN a/DT graph/NN signal/NN processing/NN (/-LRB- GSP/NN )/-RRB- perspective/NN ./.
Specifically/RB ,/, by/IN viewing/VBG a/DT binary/JJ classifier/NN as/IN a/DT piecewise/JJ constant/JJ graph/NN -/HYPH signal/NN in/IN a/DT high/JJ -/HYPH dimensional/JJ feature/NN space/NN ,/, we/PRP cast/VBD classifier/NN learning/NN as/IN a/DT signal/NN restoration/NN problem/NN via/IN a/DT classical/JJ maximum/NN a/DT posteriori/NN (/-LRB- MAP/NN )/-RRB- formulation/NN ./.
Unlike/IN previous/JJ graph/NN -/HYPH signal/NN restoration/NN works/VBZ ,/, we/PRP consider/VBP in/IN addition/NN edges/NNS with/IN negative/JJ weights/NNS that/WDT signify/VBP anti-correlation/NN between/IN samples/NNS ./.
One/CD unfortunate/JJ consequence/NN is/VBZ that/IN the/DT graph/NN Laplacian/JJ matrix/NN $/$ \/CD mathbf/NN {/-LRB- L/NN }/-RRB- $/$ can/MD be/VB indefinite/JJ ,/, and/CC previously/RB proposed/VBN graph/NN -/HYPH signal/NN smoothness/NN prior/RB $/$ \/CD mathbf/NN {/-LRB- x/NN }/-RRB- ^/SYM T/NN \/SYM mathbf/NN {/-LRB- L/NN }/-RRB- \/SYM mathbf/NN {/-LRB- x/NN }/-RRB- $/$ for/IN candidate/NN signal/NN $/$ \/CD mathbf/NN {/-LRB- x/NN }/-RRB- $/$ can/MD lead/VB to/IN pathological/JJ solutions/NNS ./.
In/IN response/NN ,/, we/PRP derive/VBP an/DT optimal/JJ perturbation/NN matrix/NN $/$ \/CD boldsymbol/NN {/-LRB- \/SYM Delta/NNP }/-RRB- $/$ -/HYPH based/VBN on/IN a/DT fast/RB lower/JJR -/HYPH bound/VBN computation/NN of/IN the/DT minimum/JJ eigenvalue/NN of/IN $/$ \/CD mathbf/NN {/-LRB- L/NN }/-RRB- $/$ via/IN a/DT novel/JJ application/NN of/IN the/DT Haynsworth/NNP inertia/NN additivity/NN formula/NN ---/, so/IN that/IN $/$ \/CD mathbf/NN {/-LRB- L/NN }/-RRB- \/SYM boldsymbol/NN {/-LRB- \/SYM Delta/NNP }/-RRB- $/$ is/VBZ positive/JJ semi-definite/NN ,/, resulting/VBG in/IN a/DT stable/JJ signal/NN prior/JJ ./.
Further/RB ,/, instead/RB of/IN forcing/VBG a/DT hard/JJ binary/JJ decision/NN for/IN each/DT sample/NN ,/, we/PRP define/VBP the/DT notion/NN of/IN generalized/VBN smoothness/NN on/IN graph/NN that/WDT promotes/VBZ ambiguity/NN in/IN the/DT classifier/NN signal/NN ./.
Finally/RB ,/, we/PRP propose/VBP an/DT algorithm/NN based/VBN on/IN iterative/JJ reweighted/VBN least/JJS squares/NNS (/-LRB- IRLS/NN )/-RRB- that/WDT solves/VBZ the/DT posed/VBN MAP/NN problem/NN efficiently/RB ./.
Extensive/JJ simulation/NN results/NNS show/VBP that/IN our/PRP$ proposed/VBN algorithm/NN outperforms/VBZ both/DT SVM/NN variants/NNS and/CC graph/NN -/HYPH based/VBN classifiers/NNS using/VBG positive/JJ -/HYPH edge/NN graphs/NNS noticeably/RB ./.
