This/DT paper/NN presents/VBZ a/DT joint/JJ model/NN for/IN performing/VBG unsupervised/JJ morphological/JJ analysis/NN on/IN words/NNS ,/, and/CC learning/VBG a/DT character/NN -/HYPH level/NN composition/NN function/NN from/IN morphemes/NNS to/IN word/NN embeddings/NNS ./.
Our/PRP$ model/NN splits/VBZ individual/JJ words/NNS into/IN segments/NNS ,/, and/CC weights/NNS each/DT segment/NN according/VBG to/IN its/PRP$ ability/NN to/TO predict/VB context/NN words/NNS ./.
Our/PRP$ morphological/JJ analysis/NN is/VBZ comparable/JJ to/IN dedicated/JJ morphological/JJ analyzers/NNS at/IN the/DT task/NN of/IN morpheme/NN boundary/NN recovery/NN ,/, and/CC also/RB performs/VBZ better/JJR than/IN word/NN -/HYPH based/VBN embedding/NN models/NNS at/IN the/DT task/NN of/IN syntactic/JJ analogy/NN answering/VBG ./.
Finally/RB ,/, we/PRP show/VBP that/IN incorporating/VBG morphology/NN explicitly/RB into/IN character/NN -/HYPH level/NN models/NNS help/VBP them/PRP produce/VB embeddings/NNS for/IN unseen/JJ words/NNS which/WDT correlate/VBP better/JJR with/IN human/JJ judgments/NNS ./.
