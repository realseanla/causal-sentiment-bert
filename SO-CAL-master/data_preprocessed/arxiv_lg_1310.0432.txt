This/DT paper/NN addresses/VBZ the/DT problem/NN of/IN online/JJ learning/NN in/IN a/DT dynamic/JJ setting/NN ./.
We/PRP consider/VBP a/DT social/JJ network/NN in/IN which/WDT each/DT individual/JJ observes/VBZ a/DT private/JJ signal/NN about/IN the/DT underlying/VBG state/NN of/IN the/DT world/NN and/CC communicates/VBZ with/IN her/PRP$ neighbors/NNS at/IN each/DT time/NN period/NN ./.
Unlike/IN many/JJ existing/JJ approaches/NNS ,/, the/DT underlying/VBG state/NN is/VBZ dynamic/JJ ,/, and/CC evolves/VBZ according/VBG to/IN a/DT geometric/JJ random/JJ walk/NN ./.
We/PRP view/VBP the/DT scenario/NN as/IN an/DT optimization/NN problem/NN where/WRB agents/NNS aim/VBP to/TO learn/VB the/DT true/JJ state/NN while/IN suffering/VBG the/DT smallest/JJS possible/JJ loss/NN ./.
Based/VBN on/IN the/DT decomposition/NN of/IN the/DT global/JJ loss/NN function/NN ,/, we/PRP introduce/VBP two/CD update/NN mechanisms/NNS ,/, each/DT of/IN which/WDT generates/VBZ an/DT estimate/NN of/IN the/DT true/JJ state/NN ./.
We/PRP establish/VBP a/DT tight/JJ bound/VBN on/IN the/DT rate/NN of/IN change/NN of/IN the/DT underlying/VBG state/NN ,/, under/IN which/WDT individuals/NNS can/MD track/VB the/DT parameter/NN with/IN a/DT bounded/VBN variance/NN ./.
Then/RB ,/, we/PRP characterize/VBP explicit/JJ expressions/NNS for/IN the/DT steady/JJ state/NN mean/NN -/HYPH square/JJ deviation/NN (/-LRB- MSD/NN )/-RRB- of/IN the/DT estimates/NNS from/IN the/DT truth/NN ,/, per/IN individual/NN ./.
We/PRP observe/VBP that/IN only/RB one/CD of/IN the/DT estimators/NNS recovers/VBZ the/DT optimal/JJ MSD/NN ,/, which/WDT underscores/VBZ the/DT impact/NN of/IN the/DT objective/JJ function/NN decomposition/NN on/IN the/DT learning/NN quality/NN ./.
Finally/RB ,/, we/PRP provide/VBP an/DT upper/JJ bound/VBN on/IN the/DT regret/NN of/IN the/DT proposed/VBN methods/NNS ,/, measured/VBN as/IN an/DT average/NN of/IN errors/NNS in/IN estimating/VBG the/DT parameter/NN in/IN a/DT finite/JJ time/NN ./.
