As/IN datasets/NNS become/VBP larger/JJR and/CC more/JJR distributed/VBN ,/, algorithms/NNS for/IN distributed/VBN clustering/NN have/VBP become/VBN more/RBR and/CC more/RBR important/JJ ./.
In/IN this/DT work/NN ,/, we/PRP present/VBP a/DT general/JJ framework/NN for/IN designing/VBG distributed/VBN clustering/NN algorithms/NNS that/WDT are/VBP robust/JJ to/IN outliers/NNS ./.
Using/VBG our/PRP$ framework/NN ,/, we/PRP give/VBP a/DT distributed/VBN approximation/NN algorithm/NN for/IN k/CD -/HYPH means/NNS ,/, k/CD -/HYPH median/NN ,/, or/CC generally/RB any/DT L_p/NN objective/NN ,/, with/IN z/NN outliers/NNS and/CC //HYPH or/CC balance/NN constraints/NNS ,/, using/VBG O/NN (/-LRB- m/NN (/-LRB- k/CD z/NN )/-RRB- (/-LRB- d/NN log/NN n/NN )/-RRB- )/-RRB- bits/NNS of/IN communication/NN ,/, where/WRB m/NN is/VBZ the/DT number/NN of/IN machines/NNS ,/, n/NN is/VBZ the/DT size/NN of/IN the/DT point/NN set/NN ,/, and/CC d/NN is/VBZ the/DT dimension/NN ./.
This/DT generalizes/VBZ and/CC improves/VBZ over/IN previous/JJ work/NN of/IN Bateni/NNP et/FW al./FW and/CC Malkomes/NNP et/FW al/FW ./.
As/IN a/DT special/JJ case/NN ,/, we/PRP achieve/VBP the/DT first/JJ distributed/VBN algorithm/NN for/IN k/CD -/HYPH median/NN with/IN outliers/NNS ,/, answering/VBG an/DT open/JJ question/NN posed/VBN by/IN Malkomes/NNP et/FW al/FW ./.
For/IN distributed/VBN k/CD -/HYPH means/NN clustering/NN ,/, we/PRP provide/VBP the/DT first/JJ dimension/NN -/HYPH dependent/JJ communication/NN complexity/NN lower/JJR bound/VBN for/IN finding/VBG the/DT optimal/JJ clustering/NN ./.
This/DT improves/VBZ over/IN the/DT lower/JJR bound/VBN from/IN Chen/NNP et/FW al./FW which/WDT is/VBZ dimension/NN -/HYPH agnostic/JJ ./.
