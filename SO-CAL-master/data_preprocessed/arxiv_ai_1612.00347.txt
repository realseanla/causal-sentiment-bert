We/PRP present/VBP a/DT method/NN for/IN inducing/VBG new/JJ dialogue/NN systems/NNS from/IN very/RB small/JJ amounts/NNS of/IN unannotated/JJ dialogue/NN data/NNS ,/, showing/VBG how/WRB word/NN -/HYPH level/NN exploration/NN using/VBG Reinforcement/NN Learning/NN (/-LRB- RL/NN )/-RRB- ,/, combined/VBN with/IN an/DT incremental/JJ and/CC semantic/JJ grammar/NN -/HYPH Dynamic/JJ Syntax/NN (/-LRB- DS/NNP )/-RRB- -/HYPH allows/VBZ systems/NNS to/TO discover/VB ,/, generate/VB ,/, and/CC understand/VBP many/JJ new/JJ dialogue/NN variants/NNS ./.
The/DT method/NN avoids/VBZ the/DT use/NN of/IN expensive/JJ and/CC time/NN -/HYPH consuming/VBG dialogue/NN act/NN annotations/NNS ,/, and/CC supports/VBZ more/RBR natural/JJ (/-LRB- incremental/JJ )/-RRB- dialogues/NNS than/IN turn/VB -/HYPH based/VBN systems/NNS ./.
Here/RB ,/, language/NN generation/NN and/CC dialogue/NN management/NN are/VBP treated/VBN as/IN a/DT joint/JJ decision/NN //HYPH optimisation/NN problem/NN ,/, and/CC the/DT MDP/NNP model/NN for/IN RL/NNP is/VBZ constructed/VBN automatically/RB ./.
With/IN an/DT implemented/VBN system/NN ,/, we/PRP show/VBP that/IN this/DT method/NN enables/VBZ a/DT wide/JJ range/NN of/IN dialogue/NN variations/NNS to/TO be/VB automatically/RB captured/VBN ,/, even/RB when/WRB the/DT system/NN is/VBZ trained/VBN from/IN only/RB a/DT single/JJ dialogue/NN ./.
The/DT variants/NNS include/VBP question/NN -/HYPH answer/NN pairs/NNS ,/, over/IN -/HYPH and/CC under/IN -/HYPH answering/NN ,/, self/NN -/HYPH and/CC other/JJ -/HYPH corrections/NNS ,/, clarification/NN interaction/NN ,/, split/NN -/HYPH utterances/NNS ,/, and/CC ellipsis/NN ./.
This/DT generalisation/NN property/NN results/NNS from/IN the/DT structural/JJ knowledge/NN and/CC constraints/NNS present/VBP within/IN the/DT DS/NNP grammar/NN ,/, and/CC highlights/VBZ some/DT limitations/NNS of/IN recent/JJ systems/NNS built/VBN using/VBG machine/NN learning/NN techniques/NNS only/RB ./.
