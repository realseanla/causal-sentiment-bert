A/DT common/JJ approach/NN in/IN positive/JJ -/HYPH unlabeled/JJ learning/NN is/VBZ to/TO train/VB a/DT classification/NN model/NN between/IN labeled/VBN and/CC unlabeled/JJ data/NNS ./.
This/DT strategy/NN is/VBZ in/IN fact/NN known/VBN to/TO give/VB an/DT optimal/JJ classifier/NN under/IN mild/JJ conditions/NNS ;/: however/RB ,/, it/PRP results/VBZ in/IN biased/JJ empirical/JJ estimates/NNS of/IN the/DT classifier/NN performance/NN ./.
In/IN this/DT work/NN ,/, we/PRP show/VBP that/IN the/DT typically/RB used/VBN performance/NN measures/NNS such/JJ as/IN the/DT receiver/NN operating/VBG characteristic/JJ curve/NN ,/, or/CC the/DT precision/NN -/HYPH recall/NN curve/NN obtained/VBN on/IN such/JJ data/NNS can/MD be/VB corrected/VBN with/IN the/DT knowledge/NN of/IN class/NN priors/NNS ;/: i.e./FW ,/, the/DT proportions/NNS of/IN the/DT positive/JJ and/CC negative/JJ examples/NNS in/IN the/DT unlabeled/JJ data/NNS ./.
We/PRP extend/VBP the/DT results/NNS to/IN a/DT noisy/JJ setting/NN where/WRB some/DT of/IN the/DT examples/NNS labeled/VBN positive/JJ are/VBP in/IN fact/NN negative/JJ and/CC show/VBP that/IN the/DT correction/NN also/RB requires/VBZ the/DT knowledge/NN of/IN the/DT proportion/NN of/IN noisy/JJ examples/NNS in/IN the/DT labeled/VBN positives/NNS ./.
Using/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN algorithms/NNS to/TO estimate/VB the/DT positive/JJ class/NN prior/JJ and/CC the/DT proportion/NN of/IN noise/NN ,/, we/PRP experimentally/RB evaluate/VB two/CD correction/NN approaches/NNS and/CC demonstrate/VBP their/PRP$ efficacy/NN on/IN real/JJ -/HYPH life/NN data/NNS ./.
