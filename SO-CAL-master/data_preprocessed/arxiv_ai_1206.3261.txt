We/PRP study/VBP a/DT multiagent/JJ learning/NN problem/NN where/WRB agents/NNS can/MD either/CC learn/VB via/IN repeated/VBN interactions/NNS ,/, or/CC can/MD follow/VB the/DT advice/NN of/IN a/DT mediator/NN who/WP suggests/VBZ possible/JJ actions/NNS to/TO take/VB ./.
We/PRP present/VBP an/DT algorithmthat/NN each/DT agent/NN can/MD use/VB so/IN that/IN ,/, with/IN high/JJ probability/NN ,/, they/PRP can/MD verify/VB whether/IN or/CC not/RB the/DT mediator/NN 's/POS advice/NN is/VBZ useful/JJ ./.
In/IN particular/JJ ,/, if/IN the/DT mediator/NN 's/POS advice/NN is/VBZ useful/JJ then/RB agents/NNS will/MD reach/VB a/DT correlated/VBN equilibrium/NN ,/, but/CC if/IN the/DT mediator/NN 's/POS advice/NN is/VBZ not/RB useful/JJ ,/, then/RB agents/NNS are/VBP not/RB harmed/VBN by/IN using/VBG our/PRP$ test/NN ,/, and/CC can/MD fall/VB back/RB to/IN their/PRP$ original/JJ learning/NN algorithm/NN ./.
We/PRP then/RB generalize/VB our/PRP$ algorithm/NN and/CC show/VBP that/IN in/IN the/DT limit/NN it/PRP always/RB correctly/RB verifies/VBZ the/DT mediator/NN 's/POS advice/NN ./.
