We/PRP give/VBP an/DT oracle/NN -/HYPH based/VBN algorithm/NN for/IN the/DT adversarial/JJ contextual/JJ bandit/NN problem/NN ,/, where/WRB either/CC contexts/NNS are/VBP drawn/VBN i.i.d./NN or/CC the/DT sequence/NN of/IN contexts/NNS is/VBZ known/VBN a/FW priori/FW ,/, but/CC where/WRB the/DT losses/NNS are/VBP picked/VBN adversarially/RB ./.
Our/PRP$ algorithm/NN is/VBZ computationally/RB efficient/JJ ,/, assuming/VBG access/NN to/IN an/DT offline/RB optimization/NN oracle/NN ,/, and/CC enjoys/VBZ a/DT regret/NN of/IN order/NN $/$ O/UH (/-LRB- (/-LRB- KT/NNP )/-RRB- ^/SYM {/-LRB- \/SYM frac/NN {/-LRB- 2/CD }/-RRB- {/-LRB- 3/CD }/-RRB- }/-RRB- (/-LRB- \/SYM log/NN N/NN )/-RRB- ^/SYM {/-LRB- \/SYM frac/NN {/-LRB- 1/CD }/-RRB- {/-LRB- 3/CD }/-RRB- }/-RRB- )/-RRB- $/$ ,/, where/WRB $/$ K$/CD is/VBZ the/DT number/NN of/IN actions/NNS ,/, $/$ T$/CD is/VBZ the/DT number/NN of/IN iterations/NNS and/CC $/$ N$/CD is/VBZ the/DT number/NN of/IN baseline/NN policies/NNS ./.
Our/PRP$ result/NN is/VBZ the/DT first/JJ to/TO break/VB the/DT $/$ O/UH (/-LRB- T/NN ^/SYM {/-LRB- \/SYM frac/NN {/-LRB- 3/CD }/-RRB- {/-LRB- 4/CD }/-RRB- }/-RRB- )/-RRB- $/$ barrier/NN that/WDT is/VBZ achieved/VBN by/IN recently/RB introduced/VBN algorithms/NNS ./.
Breaking/VBG this/DT barrier/NN was/VBD left/VBN as/IN a/DT major/JJ open/JJ problem/NN ./.
Our/PRP$ analysis/NN is/VBZ based/VBN on/IN the/DT recent/JJ relaxation/NN based/VBN approach/NN of/IN (/-LRB- Rakhlin/NNP and/CC Sridharan/NNP ,/, 2016/CD )/-RRB- ./.
