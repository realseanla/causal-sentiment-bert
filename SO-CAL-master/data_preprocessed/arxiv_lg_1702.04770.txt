While/IN Truncated/VBN Back/RB -/HYPH Propagation/NN through/IN Time/NNP (/-LRB- BPTT/NNP )/-RRB- is/VBZ the/DT most/RBS popular/JJ approach/NN to/IN training/NN Recurrent/JJ Neural/JJ Networks/NNS (/-LRB- RNNs/NNS )/-RRB- ,/, it/PRP suffers/VBZ from/IN being/VBG inherently/RB sequential/JJ (/-LRB- making/VBG parallelization/NN difficult/JJ )/-RRB- and/CC from/IN truncating/VBG gradient/NN flow/NN between/IN distant/JJ time/NN -/HYPH steps/NNS ./.
We/PRP investigate/VBP whether/IN Target/NN Propagation/NN (/-LRB- TPROP/NN )/-RRB- style/NN approaches/NNS can/MD address/VB these/DT shortcomings/NNS ./.
Unfortunately/RB ,/, extensive/JJ experiments/NNS suggest/VBP that/IN TPROP/NN generally/RB underperforms/VBZ BPTT/NNP ,/, and/CC we/PRP end/VBP with/IN an/DT analysis/NN of/IN this/DT phenomenon/NN ,/, and/CC suggestions/NNS for/IN future/JJ work/NN ./.
