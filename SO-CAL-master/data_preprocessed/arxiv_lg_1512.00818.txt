We/PRP propose/VBP a/DT new/JJ zero/CD -/HYPH shot/NN Event/NN Detection/NN method/NN by/IN Multi-modal/JJ Distributional/JJ Semantic/JJ embedding/NN of/IN videos/NNS ./.
Our/PRP$ model/NN embeds/VBZ object/NN and/CC action/NN concepts/NNS as/RB well/RB as/IN other/JJ available/JJ modalities/NNS from/IN videos/NNS into/IN a/DT distributional/JJ semantic/JJ space/NN ./.
To/IN our/PRP$ knowledge/NN ,/, this/DT is/VBZ the/DT first/JJ Zero/CD -/HYPH Shot/NN event/NN detection/NN model/NN that/WDT is/VBZ built/VBN on/IN top/NN of/IN distributional/JJ semantics/NNS and/CC extends/VBZ it/PRP in/IN the/DT following/VBG directions/NNS :/: (/-LRB- a/LS )/-RRB- semantic/JJ embedding/NN of/IN multimodal/JJ information/NN in/IN videos/NNS (/-LRB- with/IN focus/NN on/IN the/DT visual/JJ modalities/NNS )/-RRB- ,/, (/-LRB- b/LS )/-RRB- automatically/RB determining/VBG relevance/NN of/IN concepts/NNS //, attributes/NNS to/IN a/DT free/JJ text/NN query/NN ,/, which/WDT could/MD be/VB useful/JJ for/IN other/JJ applications/NNS ,/, and/CC (/-LRB- c/LS )/-RRB- retrieving/VBG videos/NNS by/IN free/JJ text/NN event/NN query/NN (/-LRB- e.g./FW ,/, "/`` changing/VBG a/DT vehicle/NN tire/NN "/'' )/-RRB- based/VBN on/IN their/PRP$ content/NN ./.
We/PRP embed/VBP videos/NNS into/IN a/DT distributional/JJ semantic/JJ space/NN and/CC then/RB measure/VB the/DT similarity/NN between/IN videos/NNS and/CC the/DT event/NN query/NN in/IN a/DT free/JJ text/NN form/NN ./.
We/PRP validated/VBD our/PRP$ method/NN on/IN the/DT large/JJ TRECVID/NN MED/NN (/-LRB- Multimedia/NNP Event/NNP Detection/NN )/-RRB- challenge/NN ./.
Using/VBG only/RB the/DT event/NN title/NN as/IN a/DT query/NN ,/, our/PRP$ method/NN outperformed/VBD the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN that/WDT uses/VBZ big/JJ descriptions/NNS from/IN 12.6/CD percent/NN to/IN 13.5/CD percent/NN with/IN MAP/NN metric/JJ and/CC 0.73/CD to/IN 0.83/CD with/IN ROC/NNP -/HYPH AUC/NNP metric/JJ ./.
It/PRP is/VBZ also/RB an/DT order/NN of/IN magnitude/NN faster/RBR ./.
