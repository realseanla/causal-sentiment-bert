Knowledge/NN base/NN (/-LRB- KB/NN )/-RRB- completion/NN adds/VBZ new/JJ facts/NNS to/IN a/DT KB/NN by/IN making/VBG inferences/NNS from/IN existing/VBG facts/NNS ,/, for/IN example/NN by/IN inferring/VBG with/IN high/JJ likelihood/NN nationality/NN (/-LRB- X/NN ,/, Y/NN )/-RRB- from/IN bornIn/NN (/-LRB- X/NN ,/, Y/NN )/-RRB- ./.
Most/JJS previous/JJ methods/NNS infer/VBP simple/JJ one/CD -/HYPH hop/NN relational/JJ synonyms/NNS like/IN this/DT ,/, or/CC use/VB as/IN evidence/NN a/DT multi-hop/JJ relational/JJ path/NN treated/VBN as/IN an/DT atomic/JJ feature/NN ,/, like/IN bornIn/NN (/-LRB- X/NN ,/, Z/NN )/-RRB- -/HYPH &gt;/SYM containedIn/NN (/-LRB- Z/NN ,/, Y/NN )/-RRB- ./.
This/DT paper/NN presents/VBZ an/DT approach/NN that/WDT reasons/NNS about/IN conjunctions/NNS of/IN multi-hop/JJ relations/NNS non-atomically/RB ,/, composing/VBG the/DT implications/NNS of/IN a/DT path/NN using/VBG a/DT recursive/JJ neural/JJ network/NN (/-LRB- RNN/NN )/-RRB- that/WDT takes/VBZ as/RB inputs/NNS vector/NN embeddings/NNS of/IN the/DT binary/JJ relation/NN in/IN the/DT path/NN ./.
Not/RB only/RB does/VBZ this/DT allow/VB us/PRP to/TO generalize/VB to/IN paths/NNS unseen/JJ at/IN training/NN time/NN ,/, but/CC also/RB ,/, with/IN a/DT single/JJ high/JJ -/HYPH capacity/NN RNN/NN ,/, to/TO predict/VB new/JJ relation/NN types/NNS not/RB seen/VBN when/WRB the/DT compositional/JJ model/NN was/VBD trained/VBN (/-LRB- zero/CD -/SYM shot/NN learning/NN )/-RRB- ./.
We/PRP assemble/VBP a/DT new/JJ dataset/NN of/IN over/IN 52M/NN relational/JJ triples/NNS ,/, and/CC show/VBP that/IN our/PRP$ method/NN improves/VBZ over/IN a/DT traditional/JJ classifier/NN by/IN 11/CD percent/NN ,/, and/CC a/DT method/NN leveraging/VBG pre-trained/JJ embeddings/NNS by/IN 7/CD percent/NN ./.
