Learning/VBG representations/NNS of/IN data/NNS ,/, and/CC in/IN particular/JJ learning/NN features/NNS for/IN a/DT subsequent/JJ prediction/NN task/NN ,/, has/VBZ been/VBN a/DT fruitful/JJ area/NN of/IN research/NN delivering/VBG impressive/JJ empirical/JJ results/NNS in/IN recent/JJ years/NNS ./.
However/RB ,/, relatively/RB little/JJ is/VBZ understood/VBN about/IN what/WP makes/VBZ a/DT representation/NN `/`` good/JJ '/'' ./.
We/PRP propose/VBP the/DT idea/NN of/IN a/DT risk/NN gap/NN induced/VBN by/IN representation/NN learning/NN for/IN a/DT given/VBN prediction/NN context/NN ,/, which/WDT measures/VBZ the/DT difference/NN in/IN the/DT risk/NN of/IN some/DT learner/NN using/VBG the/DT learned/VBN features/NNS as/IN compared/VBN to/IN the/DT original/JJ inputs/NNS ./.
We/PRP describe/VBP a/DT set/NN of/IN sufficient/JJ conditions/NNS for/IN unsupervised/JJ representation/NN learning/NN to/TO provide/VB a/DT benefit/NN ,/, as/IN measured/VBN by/IN this/DT risk/NN gap/NN ./.
These/DT conditions/NNS decompose/VBP the/DT problem/NN of/IN when/WRB representation/NN learning/NN works/VBZ into/IN its/PRP$ constituent/JJ parts/NNS ,/, which/WDT can/MD be/VB separately/RB evaluated/VBN using/VBG an/DT unlabeled/JJ sample/NN ,/, suitable/JJ domain/NN -/HYPH specific/JJ assumptions/NNS about/IN the/DT joint/JJ distribution/NN ,/, and/CC analysis/NN of/IN the/DT feature/NN learner/NN and/CC subsequent/JJ supervised/JJ learner/NN ./.
We/PRP provide/VBP two/CD examples/NNS of/IN such/JJ conditions/NNS in/IN the/DT context/NN of/IN specific/JJ properties/NNS of/IN the/DT unlabeled/JJ distribution/NN ,/, namely/RB when/WRB the/DT data/NNS lies/VBZ close/RB to/IN a/DT low/JJ -/HYPH dimensional/JJ manifold/NN and/CC when/WRB it/PRP forms/VBZ clusters/NNS ./.
We/PRP compare/VBP our/PRP$ approach/NN to/IN a/DT recently/RB proposed/VBN analysis/NN of/IN semi-supervised/VBN learning/NN ./.
