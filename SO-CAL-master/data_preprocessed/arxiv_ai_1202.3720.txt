Markov/NNP control/NN algorithms/NNS that/WDT perform/VBP smooth/JJ ,/, non-greedy/JJ updates/NNS of/IN the/DT policy/NN have/VBP been/VBN shown/VBN to/TO be/VB very/RB general/JJ and/CC versatile/JJ ,/, with/IN policy/NN gradient/NN and/CC Expectation/NN Maximisation/NN algorithms/NNS being/VBG particularly/RB popular/JJ ./.
For/IN these/DT algorithms/NNS ,/, marginal/JJ inference/NN of/IN the/DT reward/NN weighted/JJ trajectory/NN distribution/NN is/VBZ required/VBN to/TO perform/VB policy/NN updates/NNS ./.
We/PRP discuss/VBP a/DT new/JJ exact/JJ inference/NN algorithm/NN for/IN these/DT marginals/NNS in/IN the/DT finite/JJ horizon/NN case/NN that/WDT is/VBZ more/RBR efficient/JJ than/IN the/DT standard/JJ approach/NN based/VBN on/IN classical/JJ forward/RB -/HYPH backward/JJ recursions/NNS ./.
We/PRP also/RB provide/VBP a/DT principled/JJ extension/NN to/IN infinite/JJ horizon/NN Markov/NNP Decision/NN Problems/NNS that/WDT explicitly/RB accounts/VBZ for/IN an/DT infinite/JJ horizon/NN ./.
This/DT extension/NN provides/VBZ a/DT novel/JJ algorithm/NN for/IN both/DT policy/NN gradients/NNS and/CC Expectation/NN Maximisation/NN in/IN infinite/JJ horizon/NN problems/NNS ./.
