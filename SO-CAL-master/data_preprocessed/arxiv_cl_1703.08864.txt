Learning/VBG useful/JJ information/NN across/IN long/JJ time/NN lags/VBZ is/VBZ a/DT critical/JJ and/CC difficult/JJ problem/NN for/IN temporal/JJ neural/JJ models/NNS in/IN tasks/NNS like/IN language/NN modeling/NN ./.
Existing/VBG architectures/NNS that/WDT address/VBP the/DT issue/NN are/VBP often/RB complex/JJ and/CC costly/JJ to/TO train/VB ./.
The/DT Delta/NNP Recurrent/JJ Neural/JJ Network/NN (/-LRB- Delta/NNP -/HYPH RNN/NNP )/-RRB- framework/NN is/VBZ a/DT simple/JJ and/CC high/JJ -/HYPH performing/VBG design/NN that/WDT unifies/VBZ previously/RB proposed/VBN gated/VBN neural/JJ models/NNS ./.
The/DT Delta/NNP -/HYPH RNN/NNP models/NNS maintain/VBP longer/RBR -/HYPH term/NN memory/NN by/IN learning/VBG to/IN interpolate/NN between/IN a/DT fast/JJ -/HYPH changing/VBG data/NNS -/HYPH driven/VBN representation/NN and/CC a/DT slowly/RB changing/VBG ,/, implicitly/RB stable/JJ state/NN ./.
This/DT requires/VBZ hardly/RB any/DT more/RBR parameters/NNS than/IN a/DT classical/JJ simple/JJ recurrent/JJ network/NN ./.
The/DT models/NNS outperform/VBP popular/JJ complex/JJ architectures/NNS ,/, such/JJ as/IN the/DT Long/JJ Short/JJ Term/NN Memory/NN (/-LRB- LSTM/NN )/-RRB- and/CC the/DT Gated/JJ Recurrent/JJ Unit/NN (/-LRB- GRU/NN )/-RRB- and/CC achieve/VB state/NN -/HYPH of/IN -/HYPH the/DT art/NN performance/NN in/IN language/NN modeling/NN at/IN character/NN and/CC word/NN levels/NNS and/CC yield/NN comparable/JJ performance/NN at/IN the/DT subword/JJ level/NN ./.
