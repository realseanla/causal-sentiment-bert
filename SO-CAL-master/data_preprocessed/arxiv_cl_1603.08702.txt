ROOT9/NN is/VBZ a/DT supervised/JJ system/NN for/IN the/DT classification/NN of/IN hypernyms/NNS ,/, co-hyponyms/NNS and/CC random/JJ words/NNS that/WDT is/VBZ derived/VBN from/IN the/DT already/RB introduced/VBN ROOT13/NN (/-LRB- Santus/NNP et/FW al./FW ,/, 2016/CD )/-RRB- ./.
It/PRP relies/VBZ on/IN a/DT Random/NNP Forest/NNP algorithm/NN and/CC nine/CD unsupervised/JJ corpus/NN -/HYPH based/VBN features/NNS ./.
We/PRP evaluate/VBP it/PRP with/IN a/DT 10-fold/RB cross/NN validation/NN on/IN 9,600/CD pairs/NNS ,/, equally/RB distributed/VBN among/IN the/DT three/CD classes/NNS and/CC involving/VBG several/JJ Parts/NNS -/: Of/IN -/HYPH Speech/NNP (/-LRB- i.e./FW adjectives/NNS ,/, nouns/NNS and/CC verbs/NNS )/-RRB- ./.
When/WRB all/PDT the/DT classes/NNS are/VBP present/JJ ,/, ROOT9/NN achieves/VBZ an/DT F1/NN score/NN of/IN 90.7/CD percent/NN ,/, against/IN a/DT baseline/NN of/IN 57.2/CD percent/NN (/-LRB- vector/NN cosine/NN )/-RRB- ./.
When/WRB the/DT classification/NN is/VBZ binary/JJ ,/, ROOT9/NN achieves/VBZ the/DT following/JJ results/NNS against/IN the/DT baseline/NN :/: hypernyms/NNS -/HYPH co-hyponyms/NNS 95.7/CD percent/NN vs./FW 69.8/CD percent/NN ,/, hypernyms/NN -/HYPH random/JJ 91.8/CD percent/NN vs./FW 64.1/CD percent/NN and/CC co-hyponyms-random/NN 97.8/CD percent/NN vs./FW 79.4/CD percent/NN ./.
In/IN order/NN to/TO compare/VB the/DT performance/NN with/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN ,/, we/PRP have/VBP also/RB evaluated/VBN ROOT9/NN in/IN subsets/NNS of/IN the/DT Weeds/NNS et/FW al./FW (/-LRB- 2014/CD )/-RRB- datasets/NNS ,/, proving/VBG that/IN it/PRP is/VBZ in/IN fact/NN competitive/JJ ./.
Finally/RB ,/, we/PRP investigated/VBD whether/IN the/DT system/NN learns/VBZ the/DT semantic/JJ relation/NN or/CC it/PRP simply/RB learns/VBZ the/DT prototypical/JJ hypernyms/NNS ,/, as/IN claimed/VBN by/IN Levy/NNP et/FW al./FW (/-LRB- 2015/CD )/-RRB- ./.
The/DT second/JJ possibility/NN seems/VBZ to/TO be/VB the/DT most/RBS likely/JJ ,/, even/RB though/IN ROOT9/NN can/MD be/VB trained/VBN on/IN negative/JJ examples/NNS (/-LRB- i.e./FW ,/, switched/VBD hypernyms/NNS )/-RRB- to/IN drastically/RB reduce/VB this/DT bias/NN ./.
