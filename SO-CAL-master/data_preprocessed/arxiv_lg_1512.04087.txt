The/DT temporal/JJ -/HYPH difference/NN methods/NNS TD/NN (/-LRB- $/$ \/CD lambda/NN $/$ )/-RRB- and/CC Sarsa/NN (/-LRB- $/$ \/CD lambda/NN $/$ )/-RRB- form/VBP a/DT core/NN part/NN of/IN modern/JJ reinforcement/NN learning/NN ./.
Their/PRP$ appeal/NN comes/VBZ from/IN their/PRP$ good/JJ performance/NN ,/, low/JJ computational/JJ cost/NN ,/, and/CC their/PRP$ simple/JJ interpretation/NN ,/, given/VBN by/IN their/PRP$ forward/JJ view/NN ./.
Recently/RB ,/, new/JJ versions/NNS of/IN these/DT methods/NNS were/VBD introduced/VBN ,/, called/VBN true/JJ online/JJ TD/NN (/-LRB- $/$ \/CD lambda/NN $/$ )/-RRB- and/CC true/JJ online/JJ Sarsa/NNP (/-LRB- $/$ \/CD lambda/NN $/$ )/-RRB- ,/, respectively/RB (/-LRB- van/NNP Seijen/NNP and/CC Sutton/NNP ,/, 2014/CD )/-RRB- ./.
Algorithmically/RB ,/, these/DT true/JJ online/JJ methods/NNS only/RB make/VBP two/CD small/JJ changes/NNS to/IN the/DT update/NN rules/NNS of/IN the/DT regular/JJ methods/NNS ,/, and/CC the/DT extra/JJ computational/JJ cost/NN is/VBZ negligible/JJ in/IN most/JJS cases/NNS ./.
However/RB ,/, they/PRP follow/VBP the/DT ideas/NNS underlying/VBG the/DT forward/JJ view/NN much/RB more/RBR closely/RB ./.
In/IN particular/JJ ,/, they/PRP maintain/VBP an/DT exact/JJ equivalence/NN with/IN the/DT forward/JJ view/NN at/IN all/DT times/NNS ,/, whereas/IN the/DT traditional/JJ versions/NNS only/RB approximate/VBP it/PRP for/IN small/JJ step/NN -/HYPH sizes/NNS ./.
We/PRP hypothesize/VBP that/IN these/DT true/JJ online/JJ methods/NNS not/RB only/RB have/VB better/JJR theoretical/JJ properties/NNS ,/, but/CC also/RB dominate/VB the/DT regular/JJ methods/NNS empirically/RB ./.
In/IN this/DT article/NN ,/, we/PRP put/VBD this/DT hypothesis/NN to/IN the/DT test/NN by/IN performing/VBG an/DT extensive/JJ empirical/JJ comparison/NN ./.
Specifically/RB ,/, we/PRP compare/VBP the/DT performance/NN of/IN true/JJ online/JJ TD/NN (/-LRB- $/$ \/CD lambda/NN $/$ )/-RRB- //, Sarsa/NN (/-LRB- $/$ \/CD lambda/NN $/$ )/-RRB- with/IN regular/JJ TD/NN (/-LRB- $/$ \/CD lambda/NN $/$ )/-RRB- //, Sarsa/NN (/-LRB- $/$ \/CD lambda/NN $/$ )/-RRB- on/IN random/JJ MRPs/NNS ,/, a/DT real/JJ -/HYPH world/NN myoelectric/NN prosthetic/JJ arm/NN ,/, and/CC a/DT domain/NN from/IN the/DT Arcade/NNP Learning/NNP Environment/NNP ./.
We/PRP use/VBP linear/JJ function/NN approximation/NN with/IN tabular/JJ ,/, binary/JJ ,/, and/CC non-binary/JJ features/NNS ./.
Our/PRP$ results/NNS suggest/VBP that/IN the/DT true/JJ online/JJ methods/NNS indeed/RB dominate/VB the/DT regular/JJ methods/NNS ./.
Across/IN all/DT domains/NNS //, representations/NNS the/DT learning/NN speed/NN of/IN the/DT true/JJ online/JJ methods/NNS are/VBP often/RB better/RBR ,/, but/CC never/RB worse/JJR than/IN that/DT of/IN the/DT regular/JJ methods/NNS ./.
An/DT additional/JJ advantage/NN is/VBZ that/IN no/DT choice/NN between/IN traces/NNS has/VBZ to/TO be/VB made/VBN for/IN the/DT true/JJ online/JJ methods/NNS ./.
We/PRP show/VBP that/IN new/JJ true/JJ online/JJ temporal/JJ -/HYPH difference/NN methods/NNS can/MD be/VB derived/VBN by/IN making/VBG changes/NNS to/IN the/DT real/JJ -/HYPH time/NN forward/JJ view/NN and/CC then/RB rewriting/VBG the/DT update/NN equations/NNS ./.
