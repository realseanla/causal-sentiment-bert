We/PRP propose/VBP a/DT novel/JJ algorithm/NN for/IN optimizing/VBG multivariate/JJ linear/JJ threshold/NN functions/VBZ as/IN split/NN functions/NNS of/IN decision/NN trees/NNS to/TO create/VB improved/VBN Random/NNP Forest/NNP classifiers/NNS ./.
Standard/JJ tree/NN induction/NN methods/NNS resort/VBP to/IN sampling/NN and/CC exhaustive/JJ search/NN to/TO find/VB good/JJ univariate/JJ split/NN functions/NNS ./.
In/IN contrast/NN ,/, our/PRP$ method/NN computes/VBZ a/DT linear/JJ combination/NN of/IN the/DT features/NNS at/IN each/DT node/NN ,/, and/CC optimizes/VBZ the/DT parameters/NNS of/IN the/DT linear/JJ combination/NN (/-LRB- oblique/JJ )/-RRB- split/NN functions/NNS by/IN adopting/VBG a/DT variant/NN of/IN latent/JJ variable/JJ SVM/NN formulation/NN ./.
We/PRP develop/VBP a/DT convex/NN -/HYPH concave/JJ upper/JJ bound/VBN on/IN the/DT classification/NN loss/NN for/IN a/DT one/CD -/HYPH level/NN decision/NN tree/NN ,/, and/CC optimize/VB the/DT bound/VBN by/IN stochastic/JJ gradient/NN descent/NN at/IN each/DT internal/JJ node/NN of/IN the/DT tree/NN ./.
Forests/NNS of/IN up/RB to/IN 1000/CD Continuously/RB Optimized/VBN Oblique/NNP (/-LRB- CO2/NN )/-RRB- decision/NN trees/NNS are/VBP created/VBN ,/, which/WDT significantly/RB outperform/VBP Random/NNP Forest/NNP with/IN univariate/JJ splits/NNS and/CC previous/JJ techniques/NNS for/IN constructing/VBG oblique/JJ trees/NNS ./.
Experimental/JJ results/NNS are/VBP reported/VBN on/IN multi-class/NN classification/NN benchmarks/NNS and/CC on/IN Labeled/VBN Faces/NNS in/IN the/DT Wild/NNP (/-LRB- LFW/NNP )/-RRB- dataset/NN ./.
