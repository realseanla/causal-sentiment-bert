Tree/NN -/HYPH structured/VBN neural/JJ networks/NNS exploit/VBP valuable/JJ syntactic/JJ parse/VBP information/NN as/IN they/PRP interpret/VBP the/DT meanings/NNS of/IN sentences/NNS ./.
However/RB ,/, they/PRP suffer/VBP from/IN two/CD key/JJ technical/JJ problems/NNS that/WDT make/VBP them/PRP slow/JJ and/CC unwieldy/JJ for/IN large/JJ -/HYPH scale/NN NLP/NN tasks/NNS :/: they/PRP can/MD only/RB operate/VB on/IN parsed/JJ sentences/NNS and/CC they/PRP do/VBP not/RB directly/RB support/VB batched/JJ computation/NN ./.
We/PRP address/VBP these/DT issues/NNS by/IN introducing/VBG the/DT Stack/NN -/HYPH augmented/VBN Parser/NN -/HYPH Interpreter/NN Neural/JJ Network/NN (/-LRB- SPINN/NN )/-RRB- ,/, which/WDT combines/VBZ parsing/VBG and/CC interpretation/NN within/IN a/DT single/JJ tree/NN -/HYPH sequence/NN hybrid/NN model/NN by/IN integrating/VBG tree/NN -/HYPH structured/VBN sentence/NN interpretation/NN into/IN the/DT linear/JJ sequential/JJ structure/NN of/IN a/DT shift/NN -/HYPH reduce/VB parser/NN ./.
Our/PRP$ model/NN supports/VBZ batched/JJ computation/NN for/IN a/DT speedup/NN of/IN up/RB to/IN 25x/NN over/IN other/JJ tree/NN -/HYPH structured/VBN models/NNS ,/, and/CC its/PRP$ integrated/VBN parser/NN allows/VBZ it/PRP to/TO operate/VB on/IN unparsed/JJ data/NNS with/IN little/JJ loss/NN of/IN accuracy/NN ./.
We/PRP evaluate/VBP it/PRP on/IN the/DT Stanford/NNP NLI/NNP entailment/NN task/NN and/CC show/VBP that/IN it/PRP significantly/RB outperforms/VBZ other/JJ sentence/NN -/HYPH encoding/VBG models/NNS ./.
