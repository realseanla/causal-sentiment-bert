Generative/JJ models/NNS in/IN vision/NN have/VBP seen/VBN rapid/JJ progress/NN due/IN to/IN algorithmic/JJ improvements/NNS and/CC the/DT availability/NN of/IN high/JJ -/HYPH quality/NN image/NN datasets/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP offer/VBP contributions/NNS in/IN both/CC these/DT areas/NNS to/TO enable/VB similar/JJ progress/NN in/IN audio/JJ modeling/NN ./.
First/RB ,/, we/PRP detail/VBP a/DT powerful/JJ new/JJ WaveNet/NNP -/HYPH style/NN autoencoder/NN model/NN that/WDT conditions/NNS an/DT autoregressive/JJ decoder/NN on/IN temporal/JJ codes/NNS learned/VBN from/IN the/DT raw/JJ audio/NN waveform/NN ./.
Second/RB ,/, we/PRP introduce/VBP NSynth/NNP ,/, a/DT large/JJ -/HYPH scale/NN and/CC high/JJ -/HYPH quality/NN dataset/NN of/IN musical/JJ notes/NNS that/WDT is/VBZ an/DT order/NN of/IN magnitude/NN larger/JJR than/IN comparable/JJ public/JJ datasets/NNS ./.
Using/VBG NSynth/NN ,/, we/PRP demonstrate/VBP improved/VBN qualitative/JJ and/CC quantitative/JJ performance/NN of/IN the/DT WaveNet/NNP autoencoder/NN over/IN a/DT well/RB -/HYPH tuned/VBN spectral/JJ autoencoder/NN baseline/NN ./.
Finally/RB ,/, we/PRP show/VBP that/IN the/DT model/NN learns/VBZ a/DT manifold/NN of/IN embeddings/NNS that/WDT allows/VBZ for/IN morphing/VBG between/IN instruments/NNS ,/, meaningfully/RB interpolating/VBG in/IN timbre/NN to/TO create/VB new/JJ types/NNS of/IN sounds/NNS that/WDT are/VBP realistic/JJ and/CC expressive/JJ ./.
