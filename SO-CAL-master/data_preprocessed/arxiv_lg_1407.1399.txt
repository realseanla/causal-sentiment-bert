Higher/JJR -/HYPH order/NN tensors/NNS are/VBP becoming/VBG prevalent/JJ in/IN many/JJ scientific/JJ areas/NNS such/JJ as/IN computer/NN vision/NN ,/, social/JJ network/NN analysis/NN ,/, data/NNS mining/NN and/CC neuroscience/NN ./.
Traditional/JJ tensor/NN decomposition/NN approaches/VBZ face/NN three/CD major/JJ challenges/NNS :/: model/NN selecting/VBG ,/, gross/JJ corruptions/NNS and/CC computational/JJ efficiency/NN ./.
To/TO address/VB these/DT problems/NNS ,/, we/PRP first/RB propose/VB a/DT parallel/JJ trace/NN norm/NN regularized/VBN tensor/NN decomposition/NN method/NN ,/, and/CC formulate/VB it/PRP as/IN a/DT convex/NN optimization/NN problem/NN ./.
This/DT method/NN does/VBZ not/RB require/VB the/DT rank/NN of/IN each/DT mode/NN to/TO be/VB specified/VBN beforehand/RB ,/, and/CC can/MD automatically/RB determine/VB the/DT number/NN of/IN factors/NNS in/IN each/DT mode/NN through/IN our/PRP$ optimization/NN scheme/NN ./.
By/IN considering/VBG the/DT low/JJ -/HYPH rank/NN structure/NN of/IN the/DT observed/VBN tensor/NN ,/, we/PRP analyze/VBP the/DT equivalent/JJ relationship/NN of/IN the/DT trace/NN norm/NN between/IN a/DT low/JJ -/HYPH rank/NN tensor/NN and/CC its/PRP$ core/NN tensor/NN ./.
Then/RB ,/, we/PRP cast/VBD a/DT non-convex/JJ tensor/NN decomposition/NN model/NN into/IN a/DT weighted/JJ combination/NN of/IN multiple/JJ much/RB smaller/JJR -/HYPH scale/NN matrix/NN trace/NN norm/NN minimization/NN ./.
Finally/RB ,/, we/PRP develop/VBP two/CD parallel/JJ alternating/VBG direction/NN methods/NNS of/IN multipliers/NNS (/-LRB- ADMM/NN )/-RRB- to/TO solve/VB our/PRP$ problems/NNS ./.
Experimental/JJ results/NNS verify/VBP that/IN our/PRP$ regularized/VBN formulation/NN is/VBZ effective/JJ ,/, and/CC our/PRP$ methods/NNS are/VBP robust/JJ to/IN noise/NN or/CC outliers/NNS ./.
