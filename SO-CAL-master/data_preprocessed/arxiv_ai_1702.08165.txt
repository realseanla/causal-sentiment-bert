We/PRP propose/VBP a/DT method/NN for/IN learning/VBG expressive/JJ energy/NN -/HYPH based/VBN policies/NNS for/IN continuous/JJ states/NNS and/CC actions/NNS ,/, which/WDT has/VBZ been/VBN feasible/JJ only/RB in/IN tabular/JJ domains/NNS before/IN ./.
We/PRP apply/VBP our/PRP$ method/NN to/IN learning/VBG maximum/JJ entropy/NN policies/NNS ,/, resulting/VBG into/IN a/DT new/JJ algorithm/NN ,/, called/VBN soft/JJ Q/NN -/HYPH learning/NN ,/, that/IN expresses/VBZ the/DT optimal/JJ policy/NN via/IN a/DT Boltzmann/JJ distribution/NN ./.
We/PRP use/VBP the/DT recently/RB proposed/VBN amortized/VBN Stein/NNP variational/JJ gradient/NN descent/NN to/TO learn/VB a/DT stochastic/JJ sampling/NN network/NN that/WDT approximates/VBZ samples/NNS from/IN this/DT distribution/NN ./.
The/DT benefits/NNS of/IN the/DT proposed/VBN algorithm/NN include/VBP improved/VBN exploration/NN and/CC compositionality/NN that/WDT allows/VBZ transferring/VBG skills/NNS between/IN tasks/NNS ,/, which/WDT we/PRP confirm/VBP in/IN simulated/JJ experiments/NNS with/IN swimming/NN and/CC walking/VBG robots/NNS ./.
We/PRP also/RB draw/VBP a/DT connection/NN to/IN actor/NN -/HYPH critic/NN methods/NNS ,/, which/WDT can/MD be/VB viewed/VBN performing/VBG approximate/JJ inference/NN on/IN the/DT corresponding/VBG energy/NN -/HYPH based/VBN model/NN ./.
