Deep/JJ neural/JJ networks/NNS are/VBP widely/RB used/VBN in/IN machine/NN learning/NN applications/NNS ./.
However/RB ,/, the/DT deployment/NN of/IN large/JJ neural/JJ networks/NNS models/NNS can/MD be/VB difficult/JJ to/TO deploy/VB on/IN mobile/JJ devices/NNS with/IN limited/JJ power/NN budgets/NNS ./.
To/TO solve/VB this/DT problem/NN ,/, we/PRP propose/VBP Trained/VBN Ternary/NNP Quantization/NN (/-LRB- TTQ/NN )/-RRB- ,/, a/DT method/NN that/WDT can/MD reduce/VB the/DT precision/NN of/IN weights/NNS in/IN neural/JJ networks/NNS to/IN ternary/JJ values/NNS ./.
This/DT method/NN has/VBZ very/RB little/JJ accuracy/NN degradation/NN and/CC can/MD even/RB improve/VB the/DT accuracy/NN of/IN some/DT models/NNS (/-LRB- 32/CD ,/, 44/CD ,/, 56/CD -/HYPH layer/NN ResNet/NNP )/-RRB- on/IN CIFAR/NN -/HYPH 10/CD and/CC AlexNet/NNP on/IN ImageNet/NNP ./.
And/CC our/PRP$ AlexNet/NNP model/NN is/VBZ trained/VBN from/IN scratch/NN ,/, which/WDT means/VBZ it/PRP 's/VBZ as/RB easy/JJ as/IN to/TO train/VB normal/JJ full/JJ precision/NN model/NN ./.
We/PRP highlight/VBP our/PRP$ trained/VBN quantization/NN method/NN that/WDT can/MD learn/VB both/DT ternary/JJ values/NNS and/CC ternary/JJ assignment/NN ./.
During/IN inference/NN ,/, only/RB ternary/JJ values/NNS (/-LRB- 2/CD -/HYPH bit/NN weights/NNS )/-RRB- and/CC scaling/VBG factors/NNS are/VBP needed/VBN ,/, therefore/RB our/PRP$ models/NNS are/VBP nearly/RB 16x/CD smaller/JJR than/IN full/JJ -/HYPH precision/NN models/NNS ./.
Our/PRP$ ternary/JJ models/NNS can/MD also/RB be/VB viewed/VBN as/IN sparse/JJ binary/JJ weight/NN networks/NNS ,/, which/WDT can/MD potentially/RB be/VB accelerated/VBN with/IN custom/NN circuit/NN ./.
Experiments/NNS on/IN CIFAR/NN -/HYPH 10/CD show/NN that/IN the/DT ternary/JJ models/NNS obtained/VBN by/IN trained/VBN quantization/NN method/NN outperform/VBP full/JJ -/HYPH precision/NN models/NNS of/IN ResNet/NNP -/HYPH 32,44,56/CD by/IN 0.04/CD percent/NN ,/, 0.16/CD percent/NN ,/, 0.36/CD percent/NN ,/, respectively/RB ./.
On/IN ImageNet/NNP ,/, our/PRP$ model/NN outperforms/VBZ full/JJ -/HYPH precision/NN AlexNet/NNP model/NN by/IN 0.3/CD percent/NN of/IN Top/JJ -/HYPH 1/CD accuracy/NN and/CC outperforms/VBZ previous/JJ ternary/JJ models/NNS by/IN 3/CD percent/NN ./.
