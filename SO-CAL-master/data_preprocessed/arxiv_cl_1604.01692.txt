A/DT currently/RB successful/JJ approach/NN to/IN computational/JJ semantics/NNS is/VBZ to/TO represent/VB words/NNS as/IN embeddings/NNS in/IN a/DT machine/NN -/HYPH learned/VBN vector/NN space/NN ./.
We/PRP present/VBP an/DT ensemble/NN method/NN that/WDT combines/VBZ embeddings/NNS produced/VBN by/IN GloVe/NN (/-LRB- Pennington/NNP et/FW al./FW ,/, 2014/CD )/-RRB- and/CC word2vec/NN (/-LRB- Mikolov/NNP et/FW al./FW ,/, 2013/CD )/-RRB- with/IN structured/JJ knowledge/NN from/IN the/DT semantic/JJ networks/NNS ConceptNet/NNP (/-LRB- Speer/NNP and/CC Havasi/NNP ,/, 2012/CD )/-RRB- and/CC PPDB/NN (/-LRB- Ganitkevitch/NNP et/FW al./FW ,/, 2013/CD )/-RRB- ,/, merging/VBG their/PRP$ information/NN into/IN a/DT common/JJ representation/NN with/IN a/DT large/JJ ,/, multilingual/JJ vocabulary/NN ./.
The/DT embeddings/NNS it/PRP produces/VBZ achieve/VB state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN on/IN many/JJ word/NN -/HYPH similarity/NN evaluations/NNS ./.
Its/PRP$ score/NN of/IN $/$ \/SYM rho/NN =/SYM .596/CD $/$ on/IN an/DT evaluation/NN of/IN rare/JJ words/NNS (/-LRB- Luong/NNP et/FW al./FW ,/, 2013/CD )/-RRB- is/VBZ 16/CD percent/NN higher/JJR than/IN the/DT previous/JJ best/RBS known/JJ system/NN ./.
