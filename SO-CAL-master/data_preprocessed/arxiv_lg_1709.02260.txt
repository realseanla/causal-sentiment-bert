We/PRP study/VBP embedded/VBN Binarized/VBN Neural/JJ Networks/NNS (/-LRB- eBNNs/NNS )/-RRB- with/IN the/DT aim/NN of/IN allowing/VBG current/JJ binarized/VBN neural/JJ networks/NNS (/-LRB- BNNs/NNS )/-RRB- in/IN the/DT literature/NN to/TO perform/VB feedforward/JJ inference/NN efficiently/RB on/IN small/JJ embedded/VBN devices/NNS ./.
We/PRP focus/VBP on/IN minimizing/VBG the/DT required/VBN memory/NN footprint/NN ,/, given/VBN that/IN these/DT devices/NNS often/RB have/VBP memory/NN as/IN small/JJ as/IN tens/NNS of/IN kilobytes/NNS (/-LRB- KB/NN )/-RRB- ./.
Beyond/IN minimizing/VBG the/DT memory/NN required/VBN to/TO store/VB weights/NNS ,/, as/IN in/IN a/DT BNN/NNP ,/, we/PRP show/VBP that/IN it/PRP is/VBZ essential/JJ to/TO minimize/VB the/DT memory/NN used/VBN for/IN temporaries/NNS which/WDT hold/VBP intermediate/JJ results/NNS between/IN layers/NNS in/IN feedforward/JJ inference/NN ./.
To/TO accomplish/VB this/DT ,/, eBNN/NN reorders/VBZ the/DT computation/NN of/IN inference/NN while/IN preserving/VBG the/DT original/JJ BNN/NNP structure/NN ,/, and/CC uses/VBZ just/RB a/DT single/JJ floating/NN -/HYPH point/NN temporary/JJ for/IN the/DT entire/JJ neural/JJ network/NN ./.
All/DT intermediate/JJ results/NNS from/IN a/DT layer/NN are/VBP stored/VBN as/IN binary/JJ values/NNS ,/, as/IN opposed/VBN to/IN floating/VBG -/HYPH points/NNS used/VBN in/IN current/JJ BNN/NNP implementations/NNS ,/, leading/VBG to/IN a/DT 32x/NN reduction/NN in/IN required/VBN temporary/JJ space/NN ./.
We/PRP provide/VBP empirical/JJ evidence/NN that/IN our/PRP$ proposed/VBN eBNN/NN approach/NN allows/VBZ efficient/JJ inference/NN (/-LRB- 10s/NNS of/IN ms/NN )/-RRB- on/IN devices/NNS with/IN severely/RB limited/VBN memory/NN (/-LRB- 10s/NNS of/IN KB/NNP )/-RRB- ./.
For/IN example/NN ,/, eBNN/NN achieves/VBZ 95/CD \/SYM percent/NN accuracy/NN on/IN the/DT MNIST/NN dataset/NN running/VBG on/IN an/DT Intel/NNP Curie/NNP with/IN only/RB 15/CD KB/NN of/IN usable/JJ memory/NN with/IN an/DT inference/NN runtime/NN of/IN under/IN 50/CD ms/NNS per/IN sample/NN ./.
To/TO ease/VB the/DT development/NN of/IN applications/NNS in/IN embedded/VBN contexts/NNS ,/, we/PRP make/VBP our/PRP$ source/NN code/NN available/JJ that/WDT allows/VBZ users/NNS to/TO train/VB and/CC discover/VB eBNN/NN models/NNS for/IN a/DT learning/NN task/NN at/IN hand/NN ,/, which/WDT fit/VBP within/IN the/DT memory/NN constraint/NN of/IN the/DT target/NN device/NN ./.
