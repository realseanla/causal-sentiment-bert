Tree/NN structures/NNS are/VBP commonly/RB used/VBN in/IN the/DT tasks/NNS of/IN semantic/JJ analysis/NN and/CC understanding/NN over/IN the/DT data/NNS of/IN different/JJ modalities/NNS ,/, such/JJ as/IN natural/JJ language/NN ,/, 2D/NN or/CC 3D/JJ graphics/NNS and/CC images/NNS ,/, or/CC Web/NN pages/NNS ./.
Previous/JJ studies/NNS model/VBP the/DT tree/NN structures/NNS in/IN a/DT bottom/NN -/HYPH up/NN manner/NN ,/, where/WRB the/DT leaf/NN nodes/NNS (/-LRB- given/VBN in/IN advance/NN )/-RRB- are/VBP merged/VBN into/IN internal/JJ nodes/NNS until/IN they/PRP reach/VBP the/DT root/NN node/NN ./.
However/RB ,/, these/DT models/NNS are/VBP not/RB applicable/JJ when/WRB the/DT leaf/NN nodes/NNS are/VBP not/RB explicitly/RB specified/VBN ahead/RB of/IN prediction/NN ./.
Here/RB ,/, we/PRP introduce/VBP a/DT neural/JJ machine/NN for/IN top/JJ -/HYPH down/JJ generation/NN of/IN tree/NN structures/NNS that/WDT aims/VBZ to/TO infer/VB such/JJ tree/NN structures/NNS without/IN the/DT specified/VBN leaf/NN nodes/NNS ./.
In/IN this/DT model/NN ,/, the/DT history/NN memories/NNS from/IN ancestors/NNS are/VBP fed/VBN to/IN a/DT node/NN to/TO generate/VB its/PRP$ (/-LRB- ordered/VBN )/-RRB- children/NNS in/IN a/DT recursive/JJ manner/NN ./.
This/DT model/NN can/MD be/VB utilized/VBN as/IN a/DT tree/NN -/HYPH structured/VBN decoder/NN in/IN the/DT framework/NN of/IN "/`` X/NN to/IN tree/NN "/'' learning/NN ,/, where/WRB X/NN stands/VBZ for/IN any/DT structure/NN (/-LRB- e.g./FW chain/NN ,/, tree/NN etc./FW )/-RRB- that/WDT can/MD be/VB represented/VBN as/IN a/DT latent/NN vector/NN ./.
By/IN transforming/VBG the/DT dialogue/NN generation/NN problem/NN into/IN a/DT sequence/NN -/HYPH to/IN -/HYPH tree/NN task/NN ,/, we/PRP demonstrate/VBP the/DT proposed/VBN X2Tree/NN framework/NN achieves/VBZ a/DT 11.15/CD percent/NN increase/NN of/IN response/NN acceptance/NN ratio/NN over/IN the/DT baseline/NN methods/NNS ./.
