Recent/JJ literature/NN has/VBZ pointed/VBN out/RP that/IN machine/NN learning/NN classifiers/NNS ,/, including/VBG deep/JJ neural/JJ networks/NNS (/-LRB- DNN/NN )/-RRB- ,/, are/VBP vulnerable/JJ to/IN adversarial/JJ samples/NNS that/WDT are/VBP maliciously/RB created/VBN inputs/NNS that/WDT force/VBP a/DT machine/NN learning/VBG classifier/NN to/TO produce/VB wrong/JJ output/NN labels/NNS ./.
Multiple/JJ studies/NNS have/VBP tried/VBN to/TO analyze/VB and/CC thus/RB harden/VB machine/NN classifiers/NNS under/IN such/JJ adversarial/JJ noise/NN (/-LRB- AN/DT )/-RRB- ./.
However/RB ,/, they/PRP are/VBP mostly/RB empirical/JJ and/CC provide/VBP little/JJ understanding/NN of/IN the/DT underlying/VBG principles/NNS that/WDT enable/VBP evaluation/NN of/IN the/DT robustness/NN of/IN a/DT classier/JJR against/IN AN/DT ./.
This/DT paper/NN proposes/VBZ a/DT unified/JJ framework/NN using/VBG two/CD metric/JJ spaces/NNS to/TO evaluate/VB classifiers/NNS '/POS robustness/NN against/IN AN/DT and/CC provides/VBZ general/JJ guidance/NN for/IN hardening/VBG such/JJ classifiers/NNS ./.
The/DT central/JJ idea/NN of/IN our/PRP$ work/NN is/VBZ that/IN for/IN a/DT certain/JJ classification/NN task/NN ,/, the/DT robustness/NN of/IN a/DT classifier/NN $/$ f_1/CD $/$ against/IN AN/DT is/VBZ decided/VBN by/IN both/DT $/$ f_1/CD $/$ and/CC its/PRP$ oracle/NN $/$ f_2/CD $/$ (/-LRB- like/IN human/JJ annotator/NN of/IN that/DT specific/JJ task/NN )/-RRB- ./.
In/IN particular/JJ :/: (/-LRB- 1/LS )/-RRB- By/IN adding/VBG oracle/NN $/$ f_2/CD $/$ into/IN the/DT framework/NN ,/, we/PRP provide/VBP a/DT general/JJ definition/NN of/IN the/DT adversarial/JJ sample/NN problem/NN ./.
(/-LRB- 2/LS )/-RRB- We/PRP theoretically/RB formulate/VB a/DT definition/NN that/WDT decides/VBZ whether/IN a/DT classifier/NN is/VBZ always/RB robust/JJ against/IN AN/DT (/-LRB- strong/JJ -/HYPH robustness/NN )/-RRB- ;/: (/-LRB- 3/LS )/-RRB- Using/VBG two/CD metric/JJ spaces/NNS (/-LRB- $/$ X_1/CD ,/, d_1/CD $/$ )/-RRB- and/CC (/-LRB- $/$ X_2/CD ,/, d_2/CD $/$ )/-RRB- defined/VBN by/IN $/$ f_1/CD $/$ and/CC $/$ f_2/CD $/$ respectively/RB ,/, we/PRP prove/VBP that/IN the/DT topological/JJ equivalence/NN between/IN (/-LRB- $/$ X_1/CD ,/, d_1/CD $/$ )/-RRB- and/CC (/-LRB- $/$ X_2/CD ,/, d_2/CD $/$ )/-RRB- is/VBZ sufficient/JJ in/IN deciding/VBG whether/IN $/$ f_1/CD $/$ is/VBZ strong/JJ -/HYPH robust/JJ at/IN test/NN time/NN ,/, or/CC not/RB ;/: (/-LRB- 5/LS )/-RRB- By/IN training/VBG a/DT DNN/NNP classifier/NN using/VBG the/DT Siamese/JJ architecture/NN ,/, we/PRP propose/VBP a/DT new/JJ defense/NN strategy/NN "/'' Siamese/JJ training/NN "/'' to/IN intuitively/RB approach/NN topological/JJ equivalence/NN between/IN (/-LRB- $/$ X_1/CD ,/, d_1/CD $/$ )/-RRB- and/CC (/-LRB- $/$ X_2/CD ,/, d_2/CD $/$ )/-RRB- ./.
Experimental/JJ results/NNS show/VBP that/IN Siamese/JJ training/NN helps/VBZ multiple/JJ DNN/NN models/NNS achieve/VBP better/JJR accuracy/NN compared/VBN to/IN previous/JJ defense/NN strategies/NNS in/IN an/DT adversarial/JJ setting/NN ./.
DNN/NN models/NNS after/IN Siamese/JJ training/NN exhibit/VBP better/JJR robustness/NN than/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN baselines/NNS ./.
