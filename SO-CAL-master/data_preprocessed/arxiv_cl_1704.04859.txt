Previous/JJ work/NN has/VBZ modeled/VBN the/DT compositionality/NN of/IN words/NNS by/IN creating/VBG character/NN -/HYPH level/NN models/NNS of/IN meaning/NN ,/, reducing/VBG problems/NNS of/IN sparsity/NN for/IN rare/JJ words/NNS ./.
However/RB ,/, in/IN many/JJ writing/NN systems/NNS compositionality/NN has/VBZ an/DT effect/NN even/RB on/IN the/DT character/NN -/HYPH level/NN :/: the/DT meaning/NN of/IN a/DT character/NN is/VBZ derived/VBN by/IN the/DT sum/NN of/IN its/PRP$ parts/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP model/VBP this/DT effect/NN by/IN creating/VBG embeddings/NNS for/IN characters/NNS based/VBN on/IN their/PRP$ visual/JJ characteristics/NNS ,/, creating/VBG an/DT image/NN for/IN the/DT character/NN and/CC running/VBG it/PRP through/IN a/DT convolutional/JJ neural/JJ network/NN to/TO produce/VB a/DT visual/JJ character/NN embedding/NN ./.
Experiments/NNS on/IN a/DT text/NN classification/NN task/NN demonstrate/VBP that/IN such/JJ model/NN allows/VBZ for/IN better/JJR processing/NN of/IN instances/NNS with/IN rare/JJ characters/NNS in/IN languages/NNS such/JJ as/IN Chinese/JJ ,/, Japanese/JJ ,/, and/CC Korean/JJ ./.
Additionally/RB ,/, qualitative/JJ analyses/NNS demonstrate/VBP that/IN our/PRP$ proposed/VBN model/NN learns/VBZ to/TO focus/VB on/IN the/DT parts/NNS of/IN characters/NNS that/WDT carry/VBP semantic/JJ content/NN ,/, resulting/VBG in/IN embeddings/NNS that/WDT are/VBP coherent/JJ in/IN visual/JJ space/NN ./.
