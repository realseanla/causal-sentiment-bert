We/PRP propose/VBP new/JJ methods/NNS to/TO speed/VB up/RP convergence/NN of/IN the/DT Alternating/NNP Direction/NNP Method/NNP of/IN Multipliers/NNPS (/-LRB- ADMM/NNP )/-RRB- ,/, a/DT common/JJ optimization/NN tool/NN in/IN the/DT context/NN of/IN large/JJ scale/NN and/CC distributed/VBN learning/NN ./.
The/DT proposed/JJ method/NN accelerates/VBZ the/DT speed/NN of/IN convergence/NN by/IN automatically/RB deciding/VBG the/DT constraint/NN penalty/NN needed/VBN for/IN parameter/NN consensus/NN in/IN each/DT iteration/NN ./.
In/IN addition/NN ,/, we/PRP also/RB propose/VBP an/DT extension/NN of/IN the/DT method/NN that/WDT adaptively/RB determines/VBZ the/DT maximum/JJ number/NN of/IN iterations/NNS to/TO update/VB the/DT penalty/NN ./.
We/PRP show/VBP that/IN this/DT approach/NN effectively/RB leads/VBZ to/IN an/DT adaptive/JJ ,/, dynamic/JJ network/NN topology/NN underlying/VBG the/DT distributed/VBN optimization/NN ./.
The/DT utility/NN of/IN the/DT new/JJ penalty/NN update/NN schemes/NNS is/VBZ demonstrated/VBN on/IN both/DT synthetic/JJ and/CC real/JJ data/NNS ,/, including/VBG a/DT computer/NN vision/NN application/NN of/IN distributed/VBN structure/NN from/IN motion/NN ./.
