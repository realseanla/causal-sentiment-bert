Natural/NNP Language/NNP Processing/NNP (/-LRB- NLP/NNP )/-RRB- systems/NNS commonly/RB leverage/VBP bag/NN -/HYPH of/IN -/HYPH words/NNS co-occurrence/NN techniques/NNS to/TO capture/VB semantic/JJ and/CC syntactic/JJ word/NN relationships/NNS ./.
The/DT resulting/VBG word/NN -/HYPH level/NN distributed/VBN representations/NNS often/RB ignore/VBP morphological/JJ information/NN ,/, though/IN character/NN -/HYPH level/NN embeddings/NNS have/VBP proven/VBN valuable/JJ to/IN NLP/NN tasks/NNS ./.
We/PRP propose/VBP a/DT new/JJ neural/JJ language/NN model/NN incorporating/VBG both/CC word/NN order/NN and/CC character/NN order/NN in/IN its/PRP$ embedding/NN ./.
The/DT model/NN produces/VBZ several/JJ vector/NN spaces/NNS with/IN meaningful/JJ substructure/NN ,/, as/IN evidenced/VBN by/IN its/PRP$ performance/NN of/IN 85.8/CD percent/NN on/IN a/DT recent/JJ word/NN -/HYPH analogy/NN task/NN ,/, exceeding/VBG best/JJS published/VBN syntactic/JJ word/NN -/HYPH analogy/NN scores/NNS by/IN a/DT 58/CD percent/NN error/NN margin/NN ./.
Furthermore/RB ,/, the/DT model/NN includes/VBZ several/JJ parallel/JJ training/NN methods/NNS ,/, most/RBS notably/RB allowing/VBG a/DT skip/VB -/HYPH gram/NN network/NN with/IN 160/CD billion/CD parameters/NNS to/TO be/VB trained/VBN overnight/RB on/IN 3/CD multi-core/JJ CPUs/NNS ,/, 14x/NN larger/JJR than/IN the/DT previous/JJ largest/JJS neural/JJ network/NN ./.
