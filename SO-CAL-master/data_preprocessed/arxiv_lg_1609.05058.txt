A/DT Bayesian/JJ agent/NN acting/VBG in/IN a/DT multi-agent/JJ environment/NN learns/VBZ to/TO predict/VB the/DT other/JJ agents/NNS '/POS policies/NNS if/IN its/PRP$ prior/JJ assigns/VBZ positive/JJ probability/NN to/IN them/PRP (/-LRB- in/IN other/JJ words/NNS ,/, its/PRP$ prior/JJ contains/VBZ a/DT \/NN emph/NN {/-LRB- grain/NN of/IN truth/NN }/-RRB- )/-RRB- ./.
Finding/VBG a/DT reasonably/RB large/JJ class/NN of/IN policies/NNS that/WDT contains/VBZ the/DT Bayes/NNP -/HYPH optimal/JJ policies/NNS with/IN respect/NN to/IN this/DT class/NN is/VBZ known/VBN as/IN the/DT \/SYM emph/NN {/-LRB- grain/NN of/IN truth/NN problem/NN }/-RRB- ./.
Only/RB small/JJ classes/NNS are/VBP known/VBN to/TO have/VB a/DT grain/NN of/IN truth/NN and/CC the/DT literature/NN contains/VBZ several/JJ related/JJ impossibility/NN results/NNS ./.
In/IN this/DT paper/NN we/PRP present/VBP a/DT formal/JJ and/CC general/JJ solution/NN to/IN the/DT full/JJ grain/NN of/IN truth/NN problem/NN :/: we/PRP construct/VB a/DT class/NN of/IN policies/NNS that/WDT contains/VBZ all/DT computable/JJ policies/NNS as/RB well/RB as/IN Bayes/NNP -/HYPH optimal/JJ policies/NNS for/IN every/DT lower/JJR semicomputable/JJ prior/JJ over/IN the/DT class/NN ./.
When/WRB the/DT environment/NN is/VBZ unknown/JJ ,/, Bayes/NNP -/HYPH optimal/JJ agents/NNS may/MD fail/VB to/TO act/VB optimally/RB even/RB asymptotically/RB ./.
However/RB ,/, agents/NNS based/VBN on/IN Thompson/NNP sampling/NN converge/VBP to/TO play/VB {/-LRB- \/SYM epsilon/NN }/-RRB- -/HYPH Nash/NNP equilibria/NN in/IN arbitrary/JJ unknown/JJ computable/JJ multi-agent/JJ environments/NNS ./.
While/IN these/DT results/NNS are/VBP purely/RB theoretical/JJ ,/, we/PRP show/VBP that/IN they/PRP can/MD be/VB computationally/RB approximated/VBN arbitrarily/RB closely/RB ./.
