There/EX has/VBZ been/VBN an/DT explosion/NN of/IN work/NN in/IN the/DT vision/NN &amp;/CC language/NN community/NN during/IN the/DT past/JJ few/JJ years/NNS from/IN image/NN captioning/NN to/IN video/NN transcription/NN ,/, and/CC answering/VBG questions/NNS about/IN images/NNS ./.
These/DT tasks/NNS focus/VBP on/IN literal/JJ descriptions/NNS of/IN the/DT image/NN ./.
To/TO move/VB beyond/IN the/DT literal/JJ ,/, we/PRP choose/VBP to/TO explore/VB how/WRB questions/NNS about/IN an/DT image/NN often/RB address/VBP abstract/JJ events/NNS that/WDT the/DT objects/NNS evoke/VBP ./.
In/IN this/DT paper/NN ,/, we/PRP introduce/VBP the/DT novel/JJ task/NN of/IN '/`` Visual/JJ Question/NN Generation/NN (/-LRB- VQG/NN )/-RRB- '/'' ,/, where/WRB the/DT system/NN is/VBZ tasked/VBN with/IN asking/VBG a/DT natural/JJ and/CC engaging/JJ question/NN when/WRB shown/VBN an/DT image/NN ./.
We/PRP provide/VBP three/CD datasets/NNS which/WDT cover/VBP a/DT variety/NN of/IN images/NNS from/IN object/NN -/HYPH centric/JJ to/IN event/NN -/HYPH centric/JJ ,/, providing/VBG different/JJ and/CC more/RBR abstract/JJ training/NN data/NNS than/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN captioning/NN systems/NNS have/VBP used/VBN thus/RB far/RB ./.
We/PRP train/VBP and/CC test/VBP several/JJ generative/JJ and/CC retrieval/NN models/NNS to/TO tackle/VB the/DT task/NN of/IN VQG/NNP ./.
Evaluation/NN results/NNS show/VBP that/IN while/IN such/JJ models/NNS ask/VBP reasonable/JJ questions/NNS given/VBN various/JJ images/NNS ,/, there/EX is/VBZ still/RB a/DT wide/JJ gap/NN with/IN human/JJ performance/NN ./.
Our/PRP$ proposed/VBN task/NN offers/VBZ a/DT new/JJ challenge/NN to/IN the/DT community/NN which/WDT we/PRP hope/VBP can/MD spur/VB further/JJ interest/NN in/IN exploring/VBG deeper/JJR connections/NNS between/IN vision/NN &amp;/CC language/NN ./.
