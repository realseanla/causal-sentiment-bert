While/IN neural/JJ machine/NN translation/NN (/-LRB- NMT/NN )/-RRB- is/VBZ making/VBG good/JJ progress/NN in/IN the/DT past/JJ two/CD years/NNS ,/, tens/NNS of/IN millions/NNS of/IN bilingual/JJ sentence/NN pairs/NNS are/VBP needed/VBN for/IN its/PRP$ training/NN ./.
However/RB ,/, human/JJ labeling/NN is/VBZ very/RB costly/JJ ./.
To/TO tackle/VB this/DT training/NN data/NNS bottleneck/NN ,/, we/PRP develop/VBP a/DT dual/JJ -/HYPH learning/NN mechanism/NN ,/, which/WDT can/MD enable/VB an/DT NMT/NN system/NN to/TO automatically/RB learn/VB from/IN unlabeled/JJ data/NNS through/IN a/DT dual/JJ -/HYPH learning/NN game/NN ./.
This/DT mechanism/NN is/VBZ inspired/VBN by/IN the/DT following/VBG observation/NN :/: any/DT machine/NN translation/NN task/NN has/VBZ a/DT dual/JJ task/NN ,/, e.g./FW ,/, English/NNP -/HYPH to/IN -/HYPH French/JJ translation/NN (/-LRB- primal/JJ )/-RRB- versus/CC French/JJ -/HYPH to/IN -/HYPH English/NNP translation/NN (/-LRB- dual/JJ )/-RRB- ;/: the/DT primal/JJ and/CC dual/JJ tasks/NNS can/MD form/VB a/DT closed/JJ loop/NN ,/, and/CC generate/VBP informative/JJ feedback/NN signals/NNS to/TO train/VB the/DT translation/NN models/NNS ,/, even/RB if/IN without/IN the/DT involvement/NN of/IN a/DT human/JJ labeler/NN ./.
In/IN the/DT dual/JJ -/HYPH learning/NN mechanism/NN ,/, we/PRP use/VBP one/CD agent/NN to/TO represent/VB the/DT model/NN for/IN the/DT primal/JJ task/NN and/CC the/DT other/JJ agent/NN to/TO represent/VB the/DT model/NN for/IN the/DT dual/JJ task/NN ,/, then/RB ask/VB them/PRP to/TO teach/VB each/DT other/JJ through/IN a/DT reinforcement/NN learning/VBG process/NN ./.
Based/VBN on/IN the/DT feedback/NN signals/NNS generated/VBN during/IN this/DT process/NN (/-LRB- e.g./FW ,/, the/DT language/NN -/HYPH model/NN likelihood/NN of/IN the/DT output/NN of/IN a/DT model/NN ,/, and/CC the/DT reconstruction/NN error/NN of/IN the/DT original/JJ sentence/NN after/IN the/DT primal/JJ and/CC dual/JJ translations/NNS )/-RRB- ,/, we/PRP can/MD iteratively/RB update/VB the/DT two/CD models/NNS until/IN convergence/NN (/-LRB- e.g./FW ,/, using/VBG the/DT policy/NN gradient/NN methods/NNS )/-RRB- ./.
We/PRP call/VBP the/DT corresponding/VBG approach/NN to/IN neural/JJ machine/NN translation/NN \/SYM emph/NN {/-LRB- dual/JJ -/HYPH NMT/NN }/-RRB- ./.
Experiments/NNS show/VBP that/IN dual/JJ -/HYPH NMT/NN works/NNS very/RB well/RB on/IN English/NNP $/$ \/SYM leftrightarrow/NN $/$ French/JJ translation/NN ;/: especially/RB ,/, by/IN learning/VBG from/IN monolingual/JJ data/NNS (/-LRB- with/IN 10/CD percent/NN bilingual/JJ data/NNS for/IN warm/JJ start/NN )/-RRB- ,/, it/PRP achieves/VBZ a/DT comparable/JJ accuracy/NN to/IN NMT/NNP trained/VBN from/IN the/DT full/JJ bilingual/JJ data/NNS for/IN the/DT French/JJ -/HYPH to/IN -/HYPH English/NNP translation/NN task/NN ./.
