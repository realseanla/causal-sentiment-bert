One/CD of/IN the/DT long/JJ -/HYPH term/NN goals/NNS of/IN artificial/JJ intelligence/NN is/VBZ to/TO build/VB an/DT agent/NN that/WDT can/MD communicate/VB intelligently/RB with/IN human/JJ in/IN natural/JJ language/NN ./.
Most/JJS existing/VBG work/NN on/IN natural/JJ language/NN learning/NN relies/VBZ heavily/RB on/IN training/NN over/IN a/DT pre-collected/JJ dataset/NN with/IN annotated/VBN labels/NNS ,/, leading/VBG to/IN an/DT agent/NN that/WDT essentially/RB captures/VBZ the/DT statistics/NNS of/IN the/DT fixed/VBN external/JJ training/NN data/NNS ./.
As/IN the/DT training/NN data/NNS is/VBZ essentially/RB a/DT static/NN snapshot/NN representation/NN of/IN the/DT knowledge/NN from/IN the/DT annotator/NN ,/, the/DT agent/NN trained/VBN this/DT way/NN is/VBZ limited/VBN in/IN adaptiveness/NN and/CC generalization/NN of/IN its/PRP$ behavior/NN ./.
Moreover/RB ,/, this/DT is/VBZ very/RB different/JJ from/IN the/DT language/NN learning/NN process/NN of/IN humans/NNS ,/, where/WRB language/NN is/VBZ acquired/VBN during/IN communication/NN by/IN taking/VBG speaking/VBG action/NN and/CC learning/NN from/IN the/DT consequences/NNS of/IN speaking/VBG action/NN in/IN an/DT interactive/JJ manner/NN ./.
This/DT paper/NN presents/VBZ an/DT interactive/JJ setting/NN for/IN grounded/VBN natural/JJ language/NN learning/NN ,/, where/WRB an/DT agent/NN learns/VBZ natural/JJ language/NN by/IN interacting/VBG with/IN a/DT teacher/NN and/CC learning/NN from/IN feedback/NN ,/, thus/RB learning/VBG and/CC improving/VBG language/NN skills/NNS while/IN taking/VBG part/NN in/IN the/DT conversation/NN ./.
To/TO achieve/VB this/DT goal/NN ,/, we/PRP propose/VBP a/DT model/NN which/WDT incorporates/VBZ both/DT imitation/NN and/CC reinforcement/NN by/IN leveraging/VBG jointly/RB sentence/NN and/CC reward/NN feedbacks/NNS from/IN the/DT teacher/NN ./.
Experiments/NNS are/VBP conducted/VBN to/TO validate/VB the/DT effectiveness/NN of/IN the/DT proposed/VBN approach/NN ./.
