Recent/JJ research/NN in/IN multi-robot/JJ exploration/NN and/CC mapping/NN has/VBZ focused/VBN on/IN sampling/NN environmental/JJ fields/NNS ,/, which/WDT are/VBP typically/RB modeled/VBN using/VBG the/DT Gaussian/JJ process/NN (/-LRB- GP/NNP )/-RRB- ./.
Existing/VBG information/NN -/HYPH theoretic/JJ exploration/NN strategies/NNS for/IN learning/VBG GP/NNP -/HYPH based/VBN environmental/JJ field/NN maps/VBZ adopt/VB the/DT non-Markovian/JJ problem/NN structure/NN and/CC consequently/RB scale/NN poorly/RB with/IN the/DT length/NN of/IN history/NN of/IN observations/NNS ./.
Hence/RB ,/, it/PRP becomes/VBZ computationally/RB impractical/JJ to/TO use/VB these/DT strategies/NNS for/IN in/FW situ/FW ,/, real/JJ -/HYPH time/NN active/JJ sampling/NN ./.
To/TO ease/VB this/DT computational/JJ burden/NN ,/, this/DT paper/NN presents/VBZ a/DT Markov/NNP -/HYPH based/VBN approach/NN to/IN efficient/JJ information/NN -/HYPH theoretic/JJ path/NN planning/NN for/IN active/JJ sampling/NN of/IN GP/NNP -/HYPH based/VBN fields/NNS ./.
We/PRP analyze/VBP the/DT time/NN complexity/NN of/IN solving/VBG the/DT Markov/NNP -/HYPH based/VBN path/NN planning/NN problem/NN ,/, and/CC demonstrate/VBP analytically/RB that/IN it/PRP scales/VBZ better/JJR than/IN that/DT of/IN deriving/VBG the/DT non-Markovian/JJ strategies/NNS with/IN increasing/VBG length/NN of/IN planning/VBG horizon/NN ./.
For/IN a/DT class/NN of/IN exploration/NN tasks/NNS called/VBD the/DT transect/NN sampling/NN task/NN ,/, we/PRP provide/VBP theoretical/JJ guarantees/NNS on/IN the/DT active/JJ sampling/NN performance/NN of/IN our/PRP$ Markov/NNP -/HYPH based/VBN policy/NN ,/, from/IN which/WDT ideal/JJ environmental/JJ field/NN conditions/NNS and/CC sampling/NN task/NN settings/NNS can/MD be/VB established/VBN to/TO limit/VB its/PRP$ performance/NN degradation/NN due/IN to/IN violation/NN of/IN the/DT Markov/NNP assumption/NN ./.
Empirical/JJ evaluation/NN on/IN real/JJ -/HYPH world/NN temperature/NN and/CC plankton/NN density/NN field/NN data/NNS shows/VBZ that/IN our/PRP$ Markov/NNP -/HYPH based/VBN policy/NN can/MD generally/RB achieve/VB active/JJ sampling/NN performance/NN comparable/JJ to/IN that/DT of/IN the/DT widely/RB -/HYPH used/VBN non-Markovian/JJ greedy/JJ policies/NNS under/IN less/RBR favorable/JJ realistic/JJ field/NN conditions/NNS and/CC task/NN settings/NNS while/IN enjoying/VBG significant/JJ computational/JJ gain/NN over/IN them/PRP ./.
