In/IN this/DT work/NN ,/, we/PRP introduce/VBP a/DT novel/JJ interpretation/NN of/IN residual/JJ networks/NNS showing/VBG they/PRP are/VBP exponential/JJ ensembles/NNS ./.
This/DT observation/NN is/VBZ supported/VBN by/IN a/DT large/JJ -/HYPH scale/NN lesion/NN study/NN that/WDT demonstrates/VBZ they/PRP behave/VBP just/RB like/IN ensembles/NNS at/IN test/NN time/NN ./.
Subsequently/RB ,/, we/PRP perform/VBP an/DT analysis/NN showing/VBG these/DT ensembles/NNS mostly/RB consist/VBP of/IN networks/NNS that/WDT are/VBP each/DT relatively/RB shallow/JJ ./.
For/IN example/NN ,/, contrary/NN to/IN our/PRP$ expectations/NNS ,/, most/JJS of/IN the/DT gradient/NN in/IN a/DT residual/JJ network/NN with/IN 110/CD layers/NNS comes/VBZ from/IN an/DT ensemble/NN of/IN very/RB short/JJ networks/NNS ,/, i.e./FW ,/, only/RB 10/CD -/HYPH 34/CD layers/NNS deep/RB ./.
This/DT suggests/VBZ that/IN in/IN addition/NN to/IN describing/VBG neural/JJ networks/NNS in/IN terms/NNS of/IN width/NN and/CC depth/NN ,/, there/EX is/VBZ a/DT third/JJ dimension/NN :/: multiplicity/NN ,/, the/DT size/NN of/IN the/DT implicit/JJ ensemble/NN ./.
Ultimately/RB ,/, residual/JJ networks/NNS do/VBP not/RB resolve/VB the/DT vanishing/VBG gradient/NN problem/NN by/IN preserving/VBG gradient/NN flow/NN throughout/IN the/DT entire/JJ depth/NN of/IN the/DT network/NN -/HYPH rather/RB ,/, they/PRP avoid/VBP the/DT problem/NN simply/RB by/IN ensembling/VBG many/JJ short/JJ networks/NNS together/RB ./.
This/DT insight/NN reveals/VBZ that/IN depth/NN is/VBZ still/RB an/DT open/JJ research/NN question/NN and/CC invites/VBZ the/DT exploration/NN of/IN the/DT related/JJ notion/NN of/IN multiplicity/NN ./.
