Neural/JJ networks/NNS and/CC rational/JJ functions/NNS efficiently/RB approximate/VBP each/DT other/JJ ./.
In/IN more/JJR detail/NN ,/, it/PRP is/VBZ shown/VBN here/RB that/IN for/IN any/DT ReLU/NN network/NN ,/, there/EX exists/VBZ a/DT rational/JJ function/NN of/IN degree/NN $/$ O/UH (/-LRB- \/SYM text/NN {/-LRB- polylog/NN }/-RRB- (/-LRB- 1/CD //SYM \/SYM epsilon/SYM )/-RRB- )/-RRB- $/$ which/WDT is/VBZ $/$ \/CD epsilon/CD $/$ -/HYPH close/NN ,/, and/CC similarly/RB for/IN any/DT rational/JJ function/NN there/RB exists/VBZ a/DT ReLU/NN network/NN of/IN size/NN $/$ O/UH (/-LRB- \/SYM text/NN {/-LRB- polylog/NN }/-RRB- (/-LRB- 1/CD //SYM \/SYM epsilon/SYM )/-RRB- )/-RRB- $/$ which/WDT is/VBZ $/$ \/CD epsilon/CD $/$ -/HYPH close/NN ./.
By/IN contrast/NN ,/, polynomials/NNS need/VBP degree/NN $/$ \/SYM Omega/NN (/-LRB- \/SYM text/NN {/-LRB- poly/NN }/-RRB- (/-LRB- 1/CD //SYM \/SYM epsilon/SYM )/-RRB- )/-RRB- $/$ to/TO approximate/VB even/RB a/DT single/JJ ReLU/NN ./.
When/WRB converting/VBG a/DT ReLU/NN network/NN to/IN a/DT rational/JJ function/NN as/IN above/RB ,/, the/DT hidden/JJ constants/NNS depend/VBP exponentially/RB on/IN the/DT number/NN of/IN layers/NNS ,/, which/WDT is/VBZ shown/VBN to/TO be/VB tight/JJ ;/: in/IN other/JJ words/NNS ,/, a/DT compositional/JJ representation/NN can/MD be/VB beneficial/JJ even/RB for/IN rational/JJ functions/NNS ./.
