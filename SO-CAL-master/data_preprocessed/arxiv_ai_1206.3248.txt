A/DT graphical/JJ multiagent/NN model/NN (/-LRB- GMM/NN )/-RRB- represents/VBZ a/DT joint/JJ distribution/NN over/IN the/DT behavior/NN of/IN a/DT set/NN of/IN agents/NNS ./.
One/CD source/NN of/IN knowledge/NN about/IN agents/NNS '/POS behavior/NN may/MD come/VB from/IN gametheoretic/JJ analysis/NN ,/, as/IN captured/VBN by/IN several/JJ graphical/JJ game/NN representations/NNS developed/VBN in/IN recent/JJ years/NNS ./.
GMMs/NNS generalize/VBP this/DT approach/NN to/TO express/VB arbitrary/JJ distributions/NNS ,/, based/VBN on/IN game/NN descriptions/NNS or/CC other/JJ sources/NNS of/IN knowledge/NN bearing/NN on/IN beliefs/NNS about/IN agent/NN behavior/NN ./.
To/TO illustrate/VB the/DT flexibility/NN of/IN GMMs/NNS ,/, we/PRP exhibit/VBP game/NN -/HYPH derived/VBN models/NNS that/WDT allow/VBP probabilistic/JJ deviation/NN from/IN equilibrium/NN ,/, as/RB well/RB as/IN models/NNS based/VBN on/IN heuristic/NN action/NN choice/NN ./.
We/PRP investigate/VBP three/CD different/JJ methods/NNS of/IN integrating/VBG these/DT models/NNS into/IN a/DT single/JJ model/NN representing/VBG the/DT combined/VBN knowledge/NN sources/NNS ./.
To/TO evaluate/VB the/DT predictive/JJ performance/NN of/IN the/DT combined/VBN model/NN ,/, we/PRP treat/VBP as/IN actual/JJ outcome/NN the/DT behavior/NN produced/VBN by/IN a/DT reinforcement/NN learning/VBG process/NN ./.
We/PRP find/VBP that/IN combining/VBG the/DT two/CD knowledge/NN sources/NNS ,/, using/VBG any/DT of/IN the/DT methods/NNS ,/, provides/VBZ better/JJR predictions/NNS than/IN either/CC source/NN alone/RB ./.
Among/IN the/DT combination/NN methods/NNS ,/, mixing/VBG data/NNS outperforms/VBZ the/DT opinion/NN pool/NN and/CC direct/JJ update/NN methods/NNS investigated/VBN in/IN this/DT empirical/JJ trial/NN ./.
