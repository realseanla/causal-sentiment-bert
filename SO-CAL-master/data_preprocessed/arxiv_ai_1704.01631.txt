End/NN -/HYPH to/IN -/HYPH end/NN training/NN of/IN deep/JJ learning/NN -/HYPH based/VBN models/NNS allows/VBZ for/IN implicit/JJ learning/NN of/IN intermediate/JJ representations/NNS based/VBN on/IN the/DT final/JJ task/NN loss/NN ./.
However/RB ,/, the/DT end/NN -/HYPH to/IN -/HYPH end/NN approach/NN ignores/VBZ the/DT useful/JJ domain/NN knowledge/NN encoded/VBN in/IN explicit/JJ intermediate/JJ -/HYPH level/NN supervision/NN ./.
We/PRP hypothesize/VBP that/IN using/VBG intermediate/JJ representations/NNS as/IN auxiliary/JJ supervision/NN at/IN lower/JJR levels/NNS of/IN deep/JJ networks/NNS may/MD be/VB a/DT good/JJ way/NN of/IN combining/VBG the/DT advantages/NNS of/IN end/NN -/HYPH to/IN -/HYPH end/NN training/NN and/CC more/RBR traditional/JJ pipeline/NN approaches/NNS ./.
We/PRP present/VBP experiments/NNS on/IN conversational/JJ speech/NN recognition/NN where/WRB we/PRP use/VBP lower/JJR -/HYPH level/NN tasks/NNS ,/, such/JJ as/IN phoneme/NN recognition/NN ,/, in/IN a/DT multitask/JJ training/NN approach/NN with/IN an/DT encoder/NN -/HYPH decoder/NN model/NN for/IN direct/JJ character/NN transcription/NN ./.
We/PRP compare/VBP multiple/JJ types/NNS of/IN lower/JJR -/HYPH level/NN tasks/NNS and/CC analyze/VB the/DT effects/NNS of/IN the/DT auxiliary/JJ tasks/NNS ./.
Our/PRP$ results/NNS on/IN the/DT Switchboard/NN corpus/NN show/VBP that/IN this/DT approach/NN improves/VBZ recognition/NN accuracy/NN over/IN a/DT standard/JJ encoder/NN -/HYPH decoder/NN model/NN on/IN the/DT Eval2000/NN test/NN set/NN ./.
