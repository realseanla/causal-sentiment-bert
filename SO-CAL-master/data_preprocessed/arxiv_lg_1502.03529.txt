Stochastic/JJ alternating/VBG direction/NN method/NN of/IN multipliers/NNS (/-LRB- ADMM/NN )/-RRB- ,/, which/WDT visits/VBZ only/RB one/CD sample/NN or/CC a/DT mini-batch/NN of/IN samples/NNS each/DT time/NN ,/, has/VBZ recently/RB been/VBN proved/VBN to/TO achieve/VB better/JJR performance/NN than/IN batch/NN ADMM/NN ./.
However/RB ,/, most/JJS stochastic/JJ methods/NNS can/MD only/RB achieve/VB a/DT convergence/NN rate/NN $/$ O/UH (/-LRB- 1/CD //SYM \/SYM sqrt/SYM T/NN )/-RRB- $/$ on/IN general/JJ convex/NN problems/NNS ,/, where/WRB T/NN is/VBZ the/DT number/NN of/IN iterations/NNS ./.
Hence/RB ,/, these/DT methods/NNS are/VBP not/RB scalable/JJ with/IN respect/NN to/IN convergence/NN rate/NN (/-LRB- computation/NN cost/NN )/-RRB- ./.
There/RB exists/VBZ only/RB one/CD stochastic/JJ method/NN ,/, called/VBN SA/NNP -/HYPH ADMM/NNP ,/, which/WDT can/MD achieve/VB convergence/NN rate/NN $/$ O/UH (/-LRB- 1/CD //SYM T/NN )/-RRB- $/$ on/IN general/JJ convex/NN problems/NNS ./.
However/RB ,/, an/DT extra/JJ memory/NN is/VBZ needed/VBN for/IN SA/NNP -/HYPH ADMM/NNP to/TO store/VB the/DT historic/JJ gradients/NNS on/IN all/DT samples/NNS ,/, and/CC thus/RB it/PRP is/VBZ not/RB scalable/JJ with/IN respect/NN to/IN storage/NN cost/NN ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT novel/JJ method/NN ,/, called/VBN scalable/JJ stochastic/JJ ADMM/NN (/-LRB- SCAS/NN -/HYPH ADMM/NN )/-RRB- ,/, for/IN large/JJ -/HYPH scale/NN optimization/NN and/CC learning/NN problems/NNS ./.
Without/IN the/DT need/NN to/TO store/VB the/DT historic/JJ gradients/NNS ,/, SCAS/NN -/HYPH ADMM/NN can/MD achieve/VB the/DT same/JJ convergence/NN rate/NN $/$ O/UH (/-LRB- 1/CD //SYM T/NN )/-RRB- $/$ as/IN the/DT best/JJS stochastic/JJ method/NN SA/NNP -/HYPH ADMM/NNP and/CC batch/NN ADMM/NN on/IN general/JJ convex/NN problems/NNS ./.
Experiments/NNS on/IN graph/NN -/HYPH guided/VBN fused/VBN lasso/NN show/NN that/WDT SCAS/NNP -/HYPH ADMM/NNP can/MD achieve/VB state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN in/IN real/JJ applications/NNS
