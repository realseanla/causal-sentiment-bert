We/PRP present/VBP an/DT interpretable/JJ neural/JJ network/NN approach/NN to/IN predicting/VBG and/CC understanding/VBG politeness/NN in/IN natural/JJ language/NN requests/NNS ./.
Our/PRP$ models/NNS are/VBP based/VBN on/IN simple/JJ convolutional/JJ neural/JJ networks/NNS directly/RB on/IN raw/JJ text/NN ,/, avoiding/VBG any/DT manual/JJ identification/NN of/IN complex/JJ sentiment/NN or/CC syntactic/JJ features/NNS ,/, while/IN performing/VBG better/JJR than/IN such/JJ feature/NN -/HYPH based/VBN models/NNS from/IN previous/JJ work/NN ./.
More/RBR importantly/RB ,/, we/PRP use/VBP the/DT challenging/JJ task/NN of/IN politeness/NN prediction/NN as/IN a/DT testbed/NN to/TO next/RB present/VB a/DT much/JJ -/HYPH needed/VBN understanding/NN of/IN what/WP these/DT successful/JJ networks/NNS are/VBP actually/RB learning/VBG ./.
For/IN this/DT ,/, we/PRP present/VBP several/JJ network/NN visualizations/NNS based/VBN on/IN activation/NN clusters/NNS ,/, first/JJ derivative/JJ saliency/NN ,/, and/CC embedding/VBG space/NN transformations/NNS ,/, helping/VBG us/PRP automatically/RB identify/VB several/JJ subtle/JJ linguistics/NN markers/NNS of/IN politeness/NN theories/NNS ./.
Further/RB ,/, this/DT analysis/NN reveals/VBZ multiple/JJ novel/NN ,/, high/JJ -/HYPH scoring/NN politeness/NN strategies/NNS which/WDT ,/, when/WRB added/VBN back/RB as/IN new/JJ features/NNS ,/, reduce/VB the/DT accuracy/NN gap/NN between/IN the/DT original/JJ featurized/JJ system/NN and/CC the/DT neural/JJ model/NN ,/, thus/RB providing/VBG a/DT clear/JJ quantitative/JJ interpretation/NN of/IN the/DT success/NN of/IN these/DT neural/JJ networks/NNS ./.
