We/PRP propose/VBP a/DT novel/JJ linear/JJ semi-supervised/VBN learning/NN formulation/NN that/WDT is/VBZ derived/VBN from/IN a/DT solid/JJ probabilistic/JJ framework/NN :/: belief/NN propagation/NN ./.
We/PRP show/VBP that/IN our/PRP$ formulation/NN generalizes/VBZ a/DT number/NN of/IN label/NN propagation/NN algorithms/NNS described/VBN in/IN the/DT literature/NN by/IN allowing/VBG them/PRP to/TO propagate/VB generalized/VBN assumptions/NNS about/IN influences/NNS between/IN classes/NNS of/IN neighboring/VBG nodes/NNS ./.
We/PRP call/VBP this/DT formulation/NN Semi-Supervised/VBN Learning/VBG with/IN Heterophily/NNP (/-LRB- SSL/NN -/HYPH H/NN )/-RRB- ./.
We/PRP also/RB show/VBP how/WRB the/DT affinity/NN matrix/NN can/MD be/VB learned/VBN from/IN observed/VBN data/NNS with/IN a/DT simple/JJ convex/NN optimization/NN framework/NN that/WDT is/VBZ inspired/VBN by/IN locally/RB linear/JJ embedding/NN ./.
We/PRP call/VBP this/DT approach/NN Linear/NNP Heterophily/NNP Estimation/NNP (/-LRB- LHE/NNP )/-RRB- ./.
Experiments/NNS on/IN synthetic/JJ data/NNS show/VBP that/IN both/DT approaches/NNS combined/VBN can/MD learn/VB heterophily/RB of/IN a/DT graph/NN with/IN 1M/NN nodes/NNS ,/, 10M/NN edges/NNS and/CC few/JJ labels/NNS in/IN under/IN 1/CD min/NN ,/, and/CC give/VB better/JJR labeling/NN accuracies/NNS than/IN a/DT baseline/NN method/NN in/IN the/DT case/NN of/IN small/JJ fraction/NN of/IN explicitly/RB labeled/VBN nodes/NNS ./.
