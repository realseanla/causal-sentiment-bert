Gradient/NN descent/NN optimization/NN algorithms/NNS ,/, while/IN increasingly/RB popular/JJ ,/, are/VBP often/RB used/VBN as/IN black/JJ -/HYPH box/NN optimizers/NNS ,/, as/IN practical/JJ explanations/NNS of/IN their/PRP$ strengths/NNS and/CC weaknesses/NNS are/VBP hard/JJ to/TO come/VB by/IN ./.
This/DT article/NN aims/VBZ to/TO provide/VB the/DT reader/NN with/IN intuitions/NNS with/IN regard/NN to/IN the/DT behaviour/NN of/IN different/JJ algorithms/NNS that/WDT will/MD allow/VB her/PRP to/TO put/VB them/PRP to/TO use/VB ./.
In/IN the/DT course/NN of/IN this/DT overview/NN ,/, we/PRP look/VBP at/IN different/JJ variants/NNS of/IN gradient/NN descent/NN ,/, summarize/VB challenges/NNS ,/, introduce/VB the/DT most/RBS common/JJ optimization/NN algorithms/NNS ,/, review/NN architectures/NNS in/IN a/DT parallel/NN and/CC distributed/VBN setting/NN ,/, and/CC investigate/VB additional/JJ strategies/NNS for/IN optimizing/VBG gradient/NN descent/NN ./.
