Many/JJ data/NNS analysis/NN problems/NNS are/VBP NP/NNP -/HYPH hard/JJ ,/, a/DT reality/NN that/WDT has/VBZ motivated/VBN researchers/NNS to/TO develop/VB a/DT wealth/NN of/IN approximation/NN algorithms/NNS and/CC heuristics/NNS over/IN the/DT past/JJ few/JJ decades/NNS ./.
Max/NNP -/HYPH cut/VBN ,/, clustering/NN ,/, and/CC many/JJ other/JJ widely/RB applicable/JJ partitioning/NN problems/NNS fall/VBP into/IN this/DT camp/NN ./.
We/PRP focus/VBP on/IN two/CD common/JJ classes/NNS of/IN algorithms/NNS that/WDT are/VBP used/VBN for/IN clustering/NN and/CC partitioning/NN problems/NNS ,/, including/VBG SDP/NN rounding/VBG algorithms/NNS and/CC agglomerative/JJ clustering/NN algorithms/NNS with/IN dynamic/JJ programming/NN ./.
The/DT best/JJS algorithm/NN to/TO use/VB typically/RB depends/VBZ on/IN the/DT specific/JJ application/NN or/CC distribution/NN over/IN instances/NNS ./.
A/DT worst/RBS -/HYPH case/NN analysis/NN is/VBZ often/RB used/VBN to/TO compare/VB algorithms/NNS ,/, but/CC worst/JJS -/HYPH case/NN instances/NNS may/MD not/RB be/VB present/JJ in/IN the/DT particular/JJ problem/NN domain/NN ,/, and/CC thus/RB may/MD be/VB misleading/JJ when/WRB determining/VBG which/WDT algorithm/NN to/TO apply/VB ./.
Therefore/RB ,/, it/PRP is/VBZ necessary/JJ to/TO develop/VB optimization/NN methods/NNS which/WDT return/VBP the/DT algorithms/NNS and/CC parameters/NNS best/RBS suited/VBN for/IN typical/JJ inputs/NNS from/IN the/DT application/NN at/IN hand/NN ./.
We/PRP address/VBP this/DT problem/NN for/IN integer/NN quadratic/JJ programming/NN and/CC clustering/NN within/IN a/DT learning/NN -/HYPH theoretic/JJ framework/NN where/WRB the/DT learning/NN algorithm/NN is/VBZ given/VBN samples/NNS from/IN an/DT application/NN -/HYPH specific/JJ distribution/NN over/IN problem/NN instances/NNS and/CC learns/VBZ an/DT algorithm/NN which/WDT performs/VBZ well/RB over/IN the/DT distribution/NN ./.
We/PRP provide/VBP sample/NN complexity/NN guarantees/NNS and/CC computationally/RB efficient/JJ algorithms/NNS which/WDT optimize/VBP an/DT algorithm/NN family/NN 's/POS parameters/NNS to/TO best/JJS suit/NN typical/JJ inputs/NNS from/IN a/DT particular/JJ application/NN ./.
We/PRP analyze/VBP these/DT algorithms/NNS using/VBG the/DT learning/NN -/HYPH theoretic/JJ notion/NN of/IN pseudo-dimension/NN ./.
Along/IN with/IN upper/JJ bounds/NNS ,/, we/PRP provide/VBP the/DT first/JJ pseudo-dimension/NN lower/JJR bounds/NNS in/IN this/DT line/NN of/IN work/NN ,/, which/WDT require/VBP an/DT involved/JJ analysis/NN of/IN each/DT algorithm/NN family/NN 's/POS performance/NN on/IN carefully/RB constructed/VBN problem/NN instances/NNS ./.
Our/PRP$ bounds/NNS are/VBP tight/JJ and/CC therefore/RB nail/NN down/RP the/DT intrinsic/JJ complexity/NN of/IN the/DT algorithm/NN classes/NNS we/PRP analyze/VBP ,/, which/WDT are/VBP significantly/RB more/RBR complex/JJ than/IN classes/NNS commonly/RB used/VBN in/IN learning/VBG theory/NN ./.
