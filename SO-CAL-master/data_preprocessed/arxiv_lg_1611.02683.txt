Sequence/NN to/IN sequence/NN models/NNS are/VBP successful/JJ tools/NNS for/IN supervised/JJ sequence/NN learning/NN tasks/NNS ,/, such/JJ as/IN machine/NN translation/NN ./.
Despite/IN their/PRP$ success/NN ,/, these/DT models/NNS still/RB require/VBP much/JJ labeled/VBN data/NNS and/CC it/PRP is/VBZ unclear/JJ how/WRB to/TO improve/VB them/PRP using/VBG unlabeled/JJ data/NNS ,/, which/WDT is/VBZ much/RB less/RBR expensive/JJ to/TO obtain/VB ./.
In/IN this/DT paper/NN ,/, we/PRP present/VBP simple/JJ changes/NNS that/WDT lead/VBP to/IN a/DT significant/JJ improvement/NN in/IN the/DT accuracy/NN of/IN seq2seq/NN models/NNS when/WRB the/DT labeled/VBN set/NN is/VBZ small/JJ ./.
Our/PRP$ method/NN intializes/VBZ the/DT encoder/NN and/CC decoder/NN of/IN the/DT seq2seq/NN model/NN with/IN the/DT trained/VBN weights/NNS of/IN two/CD language/NN models/NNS ,/, and/CC then/RB all/DT weights/NNS are/VBP jointly/RB fine/JJ -/HYPH tuned/VBN with/IN labeled/VBN data/NNS ./.
An/DT additional/JJ language/NN modeling/NN loss/NN can/MD be/VB used/VBN to/TO regularize/VB the/DT model/NN during/IN fine/JJ -/HYPH tuning/NN ./.
We/PRP apply/VBP this/DT method/NN to/TO low/RB -/HYPH resource/NN tasks/NNS in/IN machine/NN translation/NN and/CC abstractive/JJ summarization/NN and/CC find/VB that/IN it/PRP significantly/RB improves/VBZ the/DT subsequent/JJ supervised/JJ models/NNS ./.
Our/PRP$ main/JJ finding/NN is/VBZ that/IN the/DT pretraining/NN accelerates/VBZ training/NN and/CC improves/VBZ generalization/NN of/IN seq2seq/NN models/NNS ,/, achieving/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS on/IN the/DT WMT/NNP English/NNP $/$ \/CD rightarrow/RB $/$ German/JJ task/NN ./.
Our/PRP$ model/NN obtains/VBZ an/DT improvement/NN of/IN 1.3/CD BLEU/NN from/IN the/DT previous/JJ best/JJS models/NNS on/IN both/DT WMT/NNP '14/CD and/CC WMT/NNP '15/CD English/NNP $/$ \/CD rightarrow/RB $/$ German/JJ ./.
Our/PRP$ ablation/NN study/NN shows/VBZ that/IN pretraining/NN helps/VBZ seq2seq/NN models/NNS in/IN different/JJ ways/NNS depending/VBG on/IN the/DT nature/NN of/IN the/DT task/NN :/: translation/NN benefits/NNS from/IN the/DT improved/VBN generalization/NN whereas/IN summarization/NN benefits/NNS from/IN the/DT improved/VBN optimization/NN ./.
