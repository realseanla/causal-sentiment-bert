The/DT average/JJ uncertainty/NN associated/VBN with/IN words/NNS is/VBZ an/DT information/NN -/HYPH theoretic/JJ concept/NN at/IN the/DT heart/NN of/IN quantitative/JJ and/CC computational/JJ linguistics/NNS ./.
The/DT entropy/NN has/VBZ been/VBN established/VBN as/IN a/DT measure/NN of/IN this/DT average/JJ uncertainty/NN -/HYPH also/RB called/VBN average/JJ information/NN content/NN ./.
We/PRP here/RB use/VBP parallel/JJ texts/NNS of/IN 21/CD languages/NNS to/TO establish/VB the/DT number/NN of/IN tokens/NNS at/IN which/WDT word/NN entropies/NNS converge/VBP to/IN stable/JJ values/NNS ./.
These/DT convergence/NN points/NNS are/VBP then/RB used/VBN to/TO select/VB texts/NNS from/IN a/DT massively/RB parallel/JJ corpus/NN ,/, and/CC to/TO estimate/VB word/NN entropies/NNS across/IN more/JJR than/IN 1000/CD languages/NNS ./.
Our/PRP$ results/NNS help/VBP to/TO establish/VB quantitative/JJ language/NN comparisons/NNS ,/, to/TO understand/VB the/DT performance/NN of/IN multilingual/JJ translation/NN systems/NNS ,/, and/CC to/TO normalize/VB semantic/JJ similarity/NN measures/NNS ./.
