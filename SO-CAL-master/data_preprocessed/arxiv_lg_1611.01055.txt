The/DT use/NN of/IN deep/JJ reinforcement/NN learning/VBG allows/VBZ for/IN high/JJ -/HYPH dimensional/JJ state/NN descriptors/NNS ,/, but/CC little/JJ is/VBZ known/VBN about/IN how/WRB the/DT choice/NN of/IN action/NN representation/NN impacts/NNS the/DT learning/NN difficulty/NN and/CC the/DT resulting/VBG performance/NN ./.
We/PRP compare/VBP the/DT impact/NN of/IN four/CD different/JJ action/NN parameterizations/NNS (/-LRB- torques/NNS ,/, muscle/NN -/HYPH activations/NNS ,/, target/NN joint/JJ angles/NNS ,/, and/CC target/NN joint/NN -/HYPH angle/NN velocities/NNS )/-RRB- in/IN terms/NNS of/IN learning/NN time/NN ,/, policy/NN robustness/NN ,/, motion/NN quality/NN ,/, and/CC policy/NN query/NN rates/NNS ./.
Our/PRP$ results/NNS are/VBP evaluated/VBN on/IN a/DT gait/NN -/HYPH cycle/NN imitation/NN task/NN for/IN multiple/JJ planar/NN articulated/VBN figures/NNS and/CC multiple/JJ gaits/NNS ./.
We/PRP demonstrate/VBP that/IN the/DT local/JJ feedback/NN provided/VBN by/IN higher/JJR -/HYPH level/NN action/NN parameterizations/NNS can/MD significantly/RB impact/VB the/DT learning/NN ,/, robustness/NN ,/, and/CC quality/NN of/IN the/DT resulting/VBG policies/NNS ./.
