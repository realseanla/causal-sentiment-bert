How/WRB can/MD we/PRP efficiently/RB propagate/VB uncertainty/NN in/IN a/DT latent/JJ state/NN representation/NN with/IN recurrent/JJ neural/JJ networks/NNS ?/.
This/DT paper/NN introduces/VBZ stochastic/JJ recurrent/JJ neural/JJ networks/NNS which/WDT glue/NN a/DT deterministic/JJ recurrent/JJ neural/JJ network/NN and/CC a/DT state/NN space/NN model/NN together/RB to/TO form/VB a/DT stochastic/JJ and/CC sequential/JJ neural/JJ generative/NN model/NN ./.
The/DT clear/JJ separation/NN of/IN deterministic/JJ and/CC stochastic/JJ layers/NNS allows/VBZ a/DT structured/JJ variational/JJ inference/NN network/NN to/TO track/VB the/DT factorization/NN of/IN the/DT model/NN 's/POS posterior/JJ distribution/NN ./.
By/IN retaining/VBG both/CC the/DT nonlinear/JJ recursive/JJ structure/NN of/IN a/DT recurrent/JJ neural/JJ network/NN and/CC averaging/VBG over/IN the/DT uncertainty/NN in/IN a/DT latent/JJ path/NN ,/, like/IN a/DT state/NN space/NN model/NN ,/, we/PRP improve/VBP the/DT state/NN of/IN the/DT art/NN results/NNS on/IN the/DT Blizzard/NNP and/CC TIMIT/NNP speech/NN modeling/NN data/NN sets/NNS by/IN a/DT large/JJ margin/NN ,/, while/IN achieving/VBG comparable/JJ performances/NNS to/IN competing/VBG methods/NNS on/IN polyphonic/JJ music/NN modeling/NN ./.
