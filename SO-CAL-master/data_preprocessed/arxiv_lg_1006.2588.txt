We/PRP present/VBP and/CC analyze/VBP an/DT agnostic/JJ active/JJ learning/NN algorithm/NN that/WDT works/VBZ without/IN keeping/VBG a/DT version/NN space/NN ./.
This/DT is/VBZ unlike/IN all/DT previous/JJ approaches/NNS where/WRB a/DT restricted/VBN set/NN of/IN candidate/NN hypotheses/NNS is/VBZ maintained/VBN throughout/IN learning/NN ,/, and/CC only/RB hypotheses/NNS from/IN this/DT set/NN are/VBP ever/RB returned/VBN ./.
By/IN avoiding/VBG this/DT version/NN space/NN approach/NN ,/, our/PRP$ algorithm/NN sheds/VBZ the/DT computational/JJ burden/NN and/CC brittleness/NN associated/VBN with/IN maintaining/VBG version/NN spaces/NNS ,/, yet/CC still/RB allows/VBZ for/IN substantial/JJ improvements/NNS over/IN supervised/JJ learning/NN for/IN classification/NN ./.
