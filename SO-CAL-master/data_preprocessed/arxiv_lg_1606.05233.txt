One/CD -/HYPH shot/NN learning/NN is/VBZ usually/RB tackled/VBN by/IN using/VBG generative/NN models/NNS or/CC discriminative/JJ embeddings/NNS ./.
Discriminative/JJ methods/NNS based/VBN on/IN deep/JJ learning/NN ,/, which/WDT are/VBP very/RB effective/JJ in/IN other/JJ learning/NN scenarios/NNS ,/, are/VBP ill/JJ -/HYPH suited/JJ for/IN one/CD -/HYPH shot/NN learning/NN as/IN they/PRP need/VBP large/JJ amounts/NNS of/IN training/NN data/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT method/NN to/TO learn/VB the/DT parameters/NNS of/IN a/DT deep/JJ model/NN in/IN one/CD shot/NN ./.
We/PRP construct/VBP the/DT learner/NN as/IN a/DT second/JJ deep/JJ network/NN ,/, called/VBD a/DT learnet/NN ,/, which/WDT predicts/VBZ the/DT parameters/NNS of/IN a/DT pupil/NN network/NN from/IN a/DT single/JJ exemplar/NN ./.
In/IN this/DT manner/NN we/PRP obtain/VBP an/DT efficient/JJ feed/NN -/HYPH forward/JJ one/CD -/HYPH shot/NN learner/NN ,/, trained/VBN end/NN -/HYPH to/IN -/HYPH end/NN by/IN minimizing/VBG a/DT one/CD -/HYPH shot/NN classification/NN objective/NN in/IN a/DT learning/NN to/TO learn/VB formulation/NN ./.
In/IN order/NN to/TO make/VB the/DT construction/NN feasible/JJ ,/, we/PRP propose/VBP a/DT number/NN of/IN factorizations/NNS of/IN the/DT parameters/NNS of/IN the/DT pupil/NN network/NN ./.
We/PRP demonstrate/VBP encouraging/JJ results/NNS by/IN learning/VBG characters/NNS from/IN single/JJ exemplars/NNS in/IN Omniglot/NNP ,/, and/CC by/IN tracking/VBG visual/JJ objects/NNS from/IN a/DT single/JJ initial/JJ exemplar/NN in/IN the/DT Visual/JJ Object/NN Tracking/VBG benchmark/NN ./.
