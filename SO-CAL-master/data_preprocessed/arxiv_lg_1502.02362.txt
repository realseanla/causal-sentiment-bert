We/PRP develop/VBP a/DT learning/NN principle/NN and/CC an/DT efficient/JJ algorithm/NN for/IN batch/NN learning/NN from/IN logged/VBN bandit/NN feedback/NN ./.
This/DT learning/NN setting/NN is/VBZ ubiquitous/JJ in/IN online/JJ systems/NNS (/-LRB- e.g./FW ,/, ad/FW placement/NN ,/, web/NN search/NN ,/, recommendation/NN )/-RRB- ,/, where/WRB an/DT algorithm/NN makes/VBZ a/DT prediction/NN (/-LRB- e.g./FW ,/, ad/NN ranking/NN )/-RRB- for/IN a/DT given/VBN input/NN (/-LRB- e.g./FW ,/, query/NN )/-RRB- and/CC observes/VBZ bandit/NN feedback/NN (/-LRB- e.g./FW ,/, user/NN clicks/VBZ on/IN presented/VBN ads/NNS )/-RRB- ./.
We/PRP first/RB address/VB the/DT counterfactual/JJ nature/NN of/IN the/DT learning/NN problem/NN through/IN propensity/NN scoring/NN ./.
Next/RB ,/, we/PRP prove/VBP generalization/NN error/NN bounds/NNS that/WDT account/VBP for/IN the/DT variance/NN of/IN the/DT propensity/NN -/HYPH weighted/VBN empirical/JJ risk/NN estimator/NN ./.
These/DT constructive/JJ bounds/NNS give/VBP rise/NN to/IN the/DT Counterfactual/JJ Risk/NN Minimization/NN (/-LRB- CRM/NNP )/-RRB- principle/NN ./.
We/PRP show/VBP how/WRB CRM/NNP can/MD be/VB used/VBN to/TO derive/VB a/DT new/JJ learning/NN method/NN --/: called/VBN Policy/NNP Optimizer/NNP for/IN Exponential/NNP Models/NNPS (/-LRB- POEM/NN )/-RRB- --/: for/IN learning/VBG stochastic/JJ linear/JJ rules/NNS for/IN structured/JJ output/NN prediction/NN ./.
We/PRP present/VBP a/DT decomposition/NN of/IN the/DT POEM/NN objective/NN that/WDT enables/VBZ efficient/JJ stochastic/JJ gradient/NN optimization/NN ./.
POEM/NN is/VBZ evaluated/VBN on/IN several/JJ multi-label/JJ classification/NN problems/NNS showing/VBG substantially/RB improved/VBN robustness/NN and/CC generalization/NN performance/NN compared/VBN to/IN the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN ./.
