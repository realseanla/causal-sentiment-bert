In/IN this/DT paper/NN we/PRP propose/VBP a/DT model/NN to/TO learn/VB multimodal/JJ multilingual/JJ representations/NNS for/IN matching/VBG images/NNS and/CC sentences/NNS in/IN different/JJ languages/NNS ,/, with/IN the/DT aim/NN of/IN advancing/VBG multilingual/JJ versions/NNS of/IN image/NN search/NN and/CC image/NN understanding/NN ./.
Our/PRP$ model/NN learns/VBZ a/DT common/JJ representation/NN for/IN images/NNS and/CC their/PRP$ descriptions/NNS in/IN two/CD different/JJ languages/NNS (/-LRB- which/WDT need/VBP not/RB be/VB parallel/JJ )/-RRB- by/IN considering/VBG the/DT image/NN as/IN a/DT pivot/NN between/IN two/CD languages/NNS ./.
We/PRP introduce/VBP a/DT new/JJ pairwise/JJ ranking/NN loss/NN function/NN which/WDT can/MD handle/VB both/DT symmetric/JJ and/CC asymmetric/JJ similarity/NN between/IN the/DT two/CD modalities/NNS ./.
We/PRP evaluate/VBP our/PRP$ models/NNS on/IN image/NN -/HYPH description/NN ranking/NN for/IN German/JJ and/CC English/JJ ,/, and/CC on/IN semantic/JJ textual/JJ similarity/NN of/IN image/NN descriptions/NNS in/IN English/NNP ./.
In/IN both/DT cases/NNS we/PRP achieve/VBP state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN ./.
