Our/PRP$ work/NN addresses/NNS two/CD important/JJ issues/NNS with/IN recurrent/JJ neural/JJ networks/NNS :/: (/-LRB- 1/LS )/-RRB- they/PRP are/VBP over-parameterized/VBN ,/, and/CC (/-LRB- 2/LS )/-RRB- the/DT recurrence/NN matrix/NN is/VBZ ill/RB -/HYPH conditioned/VBN ./.
The/DT former/JJ increases/VBZ the/DT sample/NN complexity/NN of/IN learning/NN and/CC the/DT training/NN time/NN ./.
The/DT latter/JJ causes/VBZ the/DT vanishing/VBG and/CC exploding/VBG gradient/NN problem/NN ./.
