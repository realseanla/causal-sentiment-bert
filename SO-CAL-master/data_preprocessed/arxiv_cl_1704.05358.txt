Sentences/NNS are/VBP important/JJ semantic/JJ units/NNS of/IN natural/JJ language/NN ./.
A/DT generic/JJ ,/, distributional/JJ representation/NN of/IN sentences/NNS that/WDT can/MD capture/VB the/DT latent/JJ semantics/NNS is/VBZ beneficial/JJ to/IN multiple/JJ downstream/JJ applications/NNS ./.
We/PRP observe/VBP a/DT simple/JJ geometry/NN of/IN sentences/NNS --/: the/DT word/NN representations/NNS of/IN a/DT given/VBN sentence/NN (/-LRB- on/IN average/JJ 10.23/CD words/NNS in/IN all/DT SemEval/NNP datasets/NNS with/IN a/DT standard/JJ deviation/NN 4.84/CD )/-RRB- roughly/RB lie/VBP in/IN a/DT low/JJ -/HYPH rank/NN subspace/NN (/-LRB- roughly/RB ,/, rank/NN 4/CD )/-RRB- ./.
Motivated/VBN by/IN this/DT observation/NN ,/, we/PRP represent/VBP a/DT sentence/NN by/IN the/DT low/JJ -/HYPH rank/NN subspace/NN spanned/VBN by/IN its/PRP$ word/NN vectors/NNS ./.
Such/PDT an/DT unsupervised/JJ representation/NN is/VBZ empirically/RB validated/VBN via/IN semantic/JJ textual/JJ similarity/NN tasks/NNS on/IN 19/CD different/JJ datasets/NNS ,/, where/WRB it/PRP outperforms/VBZ the/DT sophisticated/JJ neural/JJ network/NN models/NNS ,/, including/VBG skip/VB -/HYPH thought/VBN vectors/NNS ,/, by/IN 15/CD percent/NN on/IN average/JJ ./.
