Acoustic/JJ models/NNS using/VBG probabilistic/JJ linear/JJ discriminant/JJ analysis/NN (/-LRB- PLDA/NN )/-RRB- capture/NN the/DT correlations/NNS within/IN feature/NN vectors/NNS using/VBG subspaces/NNS which/WDT do/VBP not/RB vastly/RB expand/VB the/DT model/NN ./.
This/DT allows/VBZ high/JJ dimensional/JJ and/CC correlated/VBD feature/NN spaces/NNS to/TO be/VB used/VBN ,/, without/IN requiring/VBG the/DT estimation/NN of/IN multiple/JJ high/JJ dimension/NN covariance/NN matrices/NNS ./.
In/IN this/DT letter/NN we/PRP extend/VBP the/DT recently/RB presented/VBN PLDA/NNP mixture/NN model/NN for/IN speech/NN recognition/NN through/IN a/DT tied/VBN PLDA/NN approach/NN ,/, which/WDT is/VBZ better/JJR able/JJ to/TO control/VB the/DT model/NN size/NN to/TO avoid/VB overfitting/NN ./.
We/PRP carried/VBD out/RP experiments/NNS using/VBG the/DT Switchboard/NN corpus/NN ,/, with/IN both/DT mel/NN frequency/NN cepstral/NN coefficient/NN features/NNS and/CC bottleneck/NN feature/NN derived/VBN from/IN a/DT deep/JJ neural/JJ network/NN ./.
Reductions/NNS in/IN word/NN error/NN rate/NN were/VBD obtained/VBN by/IN using/VBG tied/VBN PLDA/NNP ,/, compared/VBN with/IN the/DT PLDA/NNP mixture/NN model/NN ,/, subspace/NN Gaussian/JJ mixture/NN models/NNS ,/, and/CC deep/JJ neural/JJ networks/NNS ./.
