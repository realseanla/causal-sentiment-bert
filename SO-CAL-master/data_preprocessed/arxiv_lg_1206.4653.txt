We/PRP present/VBP local/JJ discriminative/JJ Gaussian/NNP (/-LRB- LDG/NNP )/-RRB- dimensionality/NN reduction/NN ,/, a/DT supervised/JJ dimensionality/NN reduction/NN technique/NN for/IN classification/NN ./.
The/DT LDG/NN objective/NN function/NN is/VBZ an/DT approximation/NN to/IN the/DT leave/NN -/HYPH one/CD -/HYPH out/NN training/NN error/NN of/IN a/DT local/JJ quadratic/JJ discriminant/JJ analysis/NN classifier/NN ,/, and/CC thus/RB acts/VBZ locally/RB to/IN each/DT training/NN point/NN in/IN order/NN to/TO find/VB a/DT mapping/NN where/WRB similar/JJ data/NNS can/MD be/VB discriminated/VBN from/IN dissimilar/JJ data/NNS ./.
While/IN other/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN linear/JJ dimensionality/NN reduction/NN methods/NNS require/VBP gradient/NN descent/NN or/CC iterative/JJ solution/NN approaches/NNS ,/, LDG/NN is/VBZ solved/VBN with/IN a/DT single/JJ eigen/NN -/HYPH decomposition/NN ./.
Thus/RB ,/, it/PRP scales/VBZ better/JJR for/IN datasets/NNS with/IN a/DT large/JJ number/NN of/IN feature/NN dimensions/NNS or/CC training/NN examples/NNS ./.
We/PRP also/RB adapt/VBP LDG/NN to/IN the/DT transfer/NN learning/VBG setting/NN ,/, and/CC show/VBP that/IN it/PRP achieves/VBZ good/JJ performance/NN when/WRB the/DT test/NN data/NNS distribution/NN differs/VBZ from/IN that/DT of/IN the/DT training/NN data/NNS ./.
