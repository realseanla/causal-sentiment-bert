Multiple/JJ extensions/NNS of/IN Recurrent/JJ Neural/JJ Networks/NNS (/-LRB- RNNs/NNS )/-RRB- have/VBP been/VBN proposed/VBN recently/RB to/TO address/VB the/DT difficulty/NN of/IN storing/VBG information/NN over/IN long/JJ time/NN periods/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP experiment/VBP with/IN the/DT capacity/NN of/IN Neural/JJ Turing/NN Machines/NNS (/-LRB- NTMs/NNS )/-RRB- to/TO deal/VB with/IN these/DT long/JJ -/HYPH term/NN dependencies/NNS on/RB well/RB -/HYPH balanced/VBN strings/NNS of/IN parentheses/NNS ./.
We/PRP show/VBP that/IN not/RB only/RB does/VBZ the/DT NTM/NNP emulate/VB a/DT stack/NN with/IN its/PRP$ heads/NNS and/CC learn/VB an/DT algorithm/NN to/TO recognize/VB such/JJ words/NNS ,/, but/CC it/PRP is/VBZ also/RB capable/JJ of/IN strongly/RB generalizing/VBG to/IN much/RB longer/JJR sequences/NNS ./.
