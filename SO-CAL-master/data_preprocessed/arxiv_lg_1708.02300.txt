Sequence/NN -/HYPH to/IN -/HYPH sequence/NN models/NNS have/VBP shown/VBN promising/JJ improvements/NNS on/IN the/DT temporal/JJ task/NN of/IN video/NN captioning/NN ,/, but/CC they/PRP optimize/VBP word/NN -/HYPH level/NN cross-entropy/JJ loss/NN during/IN training/NN ./.
First/RB ,/, using/VBG policy/NN gradient/NN and/CC mixed/JJ -/HYPH loss/NN methods/NNS for/IN reinforcement/NN learning/NN ,/, we/PRP directly/RB optimize/VBP sentence/NN -/HYPH level/NN task/NN -/HYPH based/VBN metrics/NNS (/-LRB- as/IN rewards/NNS )/-RRB- ,/, achieving/VBG significant/JJ improvements/NNS over/IN the/DT baseline/NN ,/, based/VBN on/IN both/DT automatic/JJ metrics/NNS and/CC human/JJ evaluation/NN on/IN multiple/JJ datasets/NNS ./.
Next/RB ,/, we/PRP propose/VBP a/DT novel/JJ entailment/NN -/HYPH enhanced/VBN reward/NN (/-LRB- CIDEnt/NN )/-RRB- that/WDT corrects/VBZ phrase/NN -/HYPH matching/VBG based/VBN metrics/NNS (/-LRB- such/JJ as/IN CIDEr/NN )/-RRB- to/IN only/RB allow/VB for/IN logically/RB -/HYPH implied/VBN partial/JJ matches/NNS and/CC avoid/VB contradictions/NNS ,/, achieving/VBG further/RBR significant/JJ improvements/NNS over/IN the/DT CIDEr/NN -/HYPH reward/NN model/NN ./.
Overall/RB ,/, our/PRP$ CIDEnt/NN -/HYPH reward/NN model/NN achieves/VBZ the/DT new/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN on/IN the/DT MSR/NN -/HYPH VTT/NN dataset/NN ./.
