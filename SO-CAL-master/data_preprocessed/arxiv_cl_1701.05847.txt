Traditional/JJ visual/JJ speech/NN recognition/NN systems/NNS consist/VBP of/IN two/CD stages/NNS ,/, feature/NN extraction/NN and/CC classification/NN ./.
Recently/RB ,/, several/JJ deep/JJ learning/NN approaches/NNS have/VBP been/VBN presented/VBN which/WDT automatically/RB extract/VBP features/NNS from/IN the/DT mouth/NN images/NNS and/CC aim/VB to/TO replace/VB the/DT feature/NN extraction/NN stage/NN ./.
However/RB ,/, research/NN on/IN joint/JJ learning/NN of/IN features/NNS and/CC classification/NN is/VBZ very/RB limited/JJ ./.
In/IN this/DT work/NN ,/, we/PRP present/VBP an/DT end/NN -/HYPH to/IN -/HYPH end/NN visual/JJ speech/NN recognition/NN system/NN based/VBN on/IN Long/JJ -/HYPH Short/JJ Memory/NN (/-LRB- LSTM/NN )/-RRB- networks/NNS ./.
To/IN the/DT best/JJS of/IN our/PRP$ knowledge/NN ,/, this/DT is/VBZ the/DT first/JJ model/NN which/WDT simultaneously/RB learns/VBZ to/TO extract/VB features/NNS directly/RB from/IN the/DT pixels/NNS and/CC perform/VB classification/NN and/CC also/RB achieves/VBZ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN in/IN visual/JJ speech/NN classification/NN ./.
The/DT model/NN consists/VBZ of/IN two/CD streams/NNS which/WDT extract/VBP features/NNS directly/RB from/IN the/DT mouth/NN and/CC difference/NN images/NNS ,/, respectively/RB ./.
The/DT temporal/JJ dynamics/NNS in/IN each/DT stream/NN are/VBP modelled/VBN by/IN an/DT LSTM/NN and/CC the/DT fusion/NN of/IN the/DT two/CD streams/NNS takes/VBZ place/NN via/IN a/DT Bidirectional/JJ LSTM/NN (/-LRB- BLSTM/NN )/-RRB- ./.
An/DT absolute/JJ improvement/NN of/IN 9.7/CD percent/NN over/IN the/DT base/NN line/NN is/VBZ reported/VBN on/IN the/DT OuluVS2/NN database/NN ,/, and/CC 1.5/CD percent/NN on/IN the/DT CUAVE/NNP database/NN when/WRB compared/VBN with/IN other/JJ methods/NNS which/WDT use/VBP a/DT similar/JJ visual/JJ front/NN -/HYPH end/NN ./.
