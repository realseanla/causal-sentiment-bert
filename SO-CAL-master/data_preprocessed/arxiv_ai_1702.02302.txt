In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT new/JJ autonomous/JJ braking/NN system/NN based/VBN on/IN deep/JJ reinforcement/NN learning/NN ./.
The/DT proposed/VBN autonomous/JJ braking/NN system/NN automatically/RB decides/VBZ whether/IN to/TO apply/VB the/DT brake/NN at/IN each/DT time/NN step/NN when/WRB confronting/VBG the/DT risk/NN of/IN collision/NN using/VBG the/DT information/NN on/IN the/DT obstacle/NN obtained/VBN by/IN the/DT sensors/NNS ./.
The/DT problem/NN of/IN designing/VBG brake/NN control/NN is/VBZ formulated/VBN as/IN searching/VBG for/IN the/DT optimal/JJ policy/NN in/IN Markov/NNP decision/NN process/NN (/-LRB- MDP/NN )/-RRB- model/NN where/WRB the/DT state/NN is/VBZ given/VBN by/IN the/DT relative/JJ position/NN of/IN the/DT obstacle/NN and/CC the/DT vehicle/NN 's/POS speed/NN ,/, and/CC the/DT action/NN space/NN is/VBZ defined/VBN as/IN whether/IN brake/NN is/VBZ stepped/VBN or/CC not/RB ./.
The/DT policy/NN used/VBN for/IN brake/NN control/NN is/VBZ learned/VBN through/IN computer/NN simulations/NNS using/VBG the/DT deep/JJ reinforcement/NN learning/NN method/NN called/VBN deep/JJ Q/NN -/HYPH network/NN (/-LRB- DQN/NN )/-RRB- ./.
In/IN order/NN to/TO derive/VB desirable/JJ braking/VBG policy/NN ,/, we/PRP propose/VBP the/DT reward/NN function/NN which/WDT balances/VBZ the/DT damage/NN imposed/VBN to/IN the/DT obstacle/NN in/IN case/NN of/IN accident/NN and/CC the/DT reward/NN achieved/VBN when/WRB the/DT vehicle/NN runs/VBZ out/IN of/IN risk/NN as/RB soon/RB as/IN possible/JJ ./.
DQN/NNP is/VBZ trained/VBN for/IN the/DT scenario/NN where/WRB a/DT vehicle/NN is/VBZ encountered/VBN with/IN a/DT pedestrian/NN crossing/VBG the/DT urban/JJ road/NN ./.
Experiments/NNS show/VBP that/IN the/DT control/NN agent/NN exhibits/VBZ desirable/JJ control/NN behavior/NN and/CC avoids/VBZ collision/NN without/IN any/DT mistake/NN in/IN various/JJ uncertain/JJ environments/NNS ./.
