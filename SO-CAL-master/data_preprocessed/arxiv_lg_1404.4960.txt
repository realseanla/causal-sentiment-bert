Machine/NN learning/NN algorithms/NNS have/VBP been/VBN applied/VBN to/TO predict/VB agent/NN behaviors/NNS in/IN real/JJ -/HYPH world/NN dynamic/JJ systems/NNS ,/, such/JJ as/IN advertiser/NN behaviors/NNS in/IN sponsored/VBN search/NN and/CC worker/NN behaviors/NNS in/IN crowdsourcing/VBG ./.
The/DT behavior/NN data/NNS in/IN these/DT systems/NNS are/VBP generated/VBN by/IN live/JJ agents/NNS :/: once/IN the/DT systems/NNS change/VBP due/IN to/IN the/DT adoption/NN of/IN the/DT prediction/NN models/NNS learnt/VBN from/IN the/DT behavior/NN data/NNS ,/, agents/NNS will/MD observe/VB and/CC respond/VB to/IN these/DT changes/NNS by/IN changing/VBG their/PRP$ own/JJ behaviors/NNS accordingly/RB ./.
As/IN a/DT result/NN ,/, the/DT behavior/NN data/NNS will/MD evolve/VB and/CC will/MD not/RB be/VB identically/RB and/CC independently/RB distributed/VBN ,/, posing/VBG great/JJ challenges/NNS to/IN the/DT theoretical/JJ analysis/NN on/IN the/DT machine/NN learning/VBG algorithms/NNS for/IN behavior/NN prediction/NN ./.
To/TO tackle/VB this/DT challenge/NN ,/, in/IN this/DT paper/NN ,/, we/PRP propose/VBP to/TO use/VB Markov/NNP Chain/NNP in/IN Random/NNP Environments/NNPS (/-LRB- MCRE/NNP )/-RRB- to/TO describe/VB the/DT behavior/NN data/NNS ,/, and/CC perform/VB generalization/NN analysis/NN of/IN the/DT machine/NN learning/VBG algorithms/NNS on/IN its/PRP$ basis/NN ./.
Since/IN the/DT one/CD -/HYPH step/NN transition/NN probability/NN matrix/NN of/IN MCRE/NNP depends/VBZ on/IN both/DT previous/JJ states/NNS and/CC the/DT random/JJ environment/NN ,/, conventional/JJ techniques/NNS for/IN generalization/NN analysis/NN can/MD not/RB be/VB directly/RB applied/VBN ./.
To/TO address/VB this/DT issue/NN ,/, we/PRP propose/VBP a/DT novel/JJ technique/NN that/WDT transforms/VBZ the/DT original/JJ MCRE/NN into/IN a/DT higher/JJR -/HYPH dimensional/JJ time/NN -/HYPH homogeneous/JJ Markov/NNP chain/NN ./.
The/DT new/JJ Markov/NNP chain/NN involves/VBZ more/JJR variables/NNS but/CC is/VBZ more/RBR regular/JJ ,/, and/CC thus/RB easier/JJR to/TO deal/VB with/IN ./.
We/PRP prove/VBP the/DT convergence/NN of/IN the/DT new/JJ Markov/NNP chain/NN when/WRB time/NN approaches/VBZ infinity/NN ./.
Then/RB we/PRP prove/VBP a/DT generalization/NN bound/VBN for/IN the/DT machine/NN learning/VBG algorithms/NNS on/IN the/DT behavior/NN data/NNS generated/VBN by/IN the/DT new/JJ Markov/NNP chain/NN ,/, which/WDT depends/VBZ on/IN both/CC the/DT Markovian/JJ parameters/NNS and/CC the/DT covering/VBG number/NN of/IN the/DT function/NN class/NN compounded/VBN by/IN the/DT loss/NN function/NN for/IN behavior/NN prediction/NN and/CC the/DT behavior/NN prediction/NN model/NN ./.
To/IN the/DT best/JJS of/IN our/PRP$ knowledge/NN ,/, this/DT is/VBZ the/DT first/JJ work/NN that/WDT performs/VBZ the/DT generalization/NN analysis/NN on/IN data/NNS generated/VBN by/IN complex/JJ processes/NNS in/IN real/JJ -/HYPH world/NN dynamic/JJ systems/NNS ./.
