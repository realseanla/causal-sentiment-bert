Sum/NNP -/HYPH product/NN networks/NNS (/-LRB- SPNs/NNS )/-RRB- are/VBP a/DT class/NN of/IN probabilistic/JJ graphical/JJ models/NNS that/WDT allow/VBP tractable/JJ marginal/JJ inference/NN ./.
However/RB ,/, the/DT maximum/NN a/DT posteriori/NN (/-LRB- MAP/NN )/-RRB- inference/NN in/IN SPNs/NNS is/VBZ NP/NNP -/HYPH hard/JJ ./.
We/PRP investigate/VBP MAP/NN inference/NN in/IN SPNs/NNS from/IN both/DT theoretical/JJ and/CC algorithmic/JJ perspectives/NNS ./.
For/IN the/DT theoretical/JJ part/NN ,/, we/PRP reduce/VBP general/JJ MAP/NN inference/NN to/IN its/PRP$ special/JJ case/NN without/IN evidence/NN and/CC hidden/VBN variables/NNS ;/: we/PRP also/RB show/VBP that/IN it/PRP is/VBZ NP/NNP -/HYPH hard/JJ to/TO approximate/VB the/DT MAP/NN problem/NN to/IN $/$ 2/CD ^/SYM {/-LRB- n/NN ^/SYM \/SYM epsilon/SYM }/-RRB- $/$ for/IN fixed/VBN $/$ 0/CD \/SYM leq/CD \/SYM epsilon/NN &lt;/SYM 1/CD $/$ ,/, where/WRB $/$ n/NN $/$ is/VBZ the/DT input/NN size/NN ./.
For/IN the/DT algorithmic/JJ part/NN ,/, we/PRP first/RB present/VBP an/DT exact/JJ MAP/NN solver/NN that/WDT runs/VBZ reasonably/RB fast/JJ and/CC could/MD handle/VB SPNs/NNS with/IN up/RB to/IN 1k/NN variables/NNS and/CC 150k/CD arcs/NNS in/IN our/PRP$ experiments/NNS ./.
We/PRP then/RB present/VBP a/DT new/JJ approximate/JJ MAP/NN solver/NN with/IN a/DT good/JJ balance/NN between/IN speed/NN and/CC accuracy/NN ,/, and/CC our/PRP$ comprehensive/JJ experiments/NNS on/IN real/JJ -/HYPH world/NN datasets/NNS show/VBP that/IN it/PRP has/VBZ better/JJR overall/JJ performance/NN than/IN existing/VBG approximate/JJ solvers/NNS ./.
