In/IN an/DT online/JJ decision/NN problem/NN ,/, one/CD makes/VBZ decisions/NNS often/RB with/IN a/DT pool/NN of/IN decision/NN sequence/NN called/VBN experts/NNS but/CC without/IN knowledge/NN of/IN the/DT future/NN ./.
After/IN each/DT step/NN ,/, one/CD pays/VBZ a/DT cost/NN based/VBN on/IN the/DT decision/NN and/CC observed/VBN rate/NN ./.
One/CD reasonal/JJ goal/NN would/MD be/VB to/TO perform/VB as/RB well/RB as/IN the/DT best/JJS expert/NN in/IN the/DT pool/NN ./.
The/DT modern/JJ and/CC well/RB -/HYPH known/VBN way/NN to/IN attain/VB this/DT goal/NN is/VBZ the/DT algorithm/NN of/IN exponential/JJ weighting/NN ./.
However/RB ,/, recently/RB ,/, another/DT algorithm/NN called/VBN follow/VBP the/DT perturbed/VBN leader/NN is/VBZ developed/VBN and/CC achieved/VBN about/IN the/DT same/JJ performance/NN ./.
In/IN our/PRP$ work/NN ,/, we/PRP first/RB show/VBP the/DT properties/NNS shared/VBN in/IN common/JJ by/IN the/DT two/CD algorithms/NNS which/WDT explain/VBP the/DT similarities/NNS on/IN the/DT performance/NN ./.
Next/RB we/PRP will/MD show/VB that/IN for/IN a/DT specific/JJ perturbation/NN ,/, the/DT two/CD algorithms/NNS are/VBP identical/JJ ./.
Finally/RB ,/, we/PRP show/VBP with/IN some/DT examples/NNS that/WDT follow/VBP -/: the/DT -/HYPH leader/NN style/NN algorithms/NNS extend/VBP naturally/RB to/IN a/DT large/JJ class/NN of/IN structured/VBN online/JJ problems/NNS for/IN which/WDT the/DT exponential/JJ algorithms/NNS are/VBP inefficient/JJ ./.
