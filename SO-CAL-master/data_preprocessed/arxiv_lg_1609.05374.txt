The/DT convex/NN hull/NN of/IN $/$ n/NN $/$ -/HYPH symbol/NN Huffman/NNP trees/NNS is/VBZ known/VBN to/TO have/VB exponentially/RB many/JJ facets/NNS //, constraints/NNS ./.
This/DT makes/VBZ the/DT standard/NN on/IN -/HYPH line/NN learning/NN techniques/NNS for/IN learning/VBG Huffman/NNP trees/NNS impractical/JJ ,/, since/IN they/PRP use/VBP multiplicative/JJ updates/NNS followed/VBN by/IN projections/NNS to/TO satisfy/VB all/DT of/IN the/DT constraints/NNS ./.
However/RB ,/, there/EX are/VBP general/JJ extended/VBN formulation/NN techniques/NNS that/WDT encode/VBP the/DT convex/NN hull/NN of/IN Huffman/NNP trees/NNS as/IN a/DT polytope/NN in/IN a/DT higher/JJR dimensional/JJ space/NN with/IN only/RB polynomially/RB many/JJ facets/NNS ./.
This/DT extended/VBD formulation/NN methodology/NN can/MD also/RB be/VB used/VBN to/TO encode/VB the/DT $/$ n/NN $/$ -/HYPH element/NN permutahedron/NN in/IN $/$ O/UH (/-LRB- n/NN \/SYM log/NN n/NN )/-RRB- $/$ dimensions/NNS with/IN only/RB a/DT polynomial/JJ number/NN of/IN facets/NNS ./.
We/PRP develop/VBP a/DT general/JJ technique/NN for/IN converting/VBG these/DT extended/VBN formulations/NNS into/IN efficient/JJ on/IN -/HYPH line/NN algorithms/NNS with/IN good/JJ relative/JJ loss/NN bounds/NNS ./.
The/DT resulting/VBG algorithms/NNS have/VBP nearly/RB the/DT same/JJ regret/NN bounds/NNS as/IN state/NN of/IN the/DT art/NN algorithms/NNS for/IN permutations/NNS ,/, and/CC are/VBP the/DT first/JJ efficient/JJ algorithms/NNS for/IN the/DT on/IN -/HYPH line/NN learning/NN of/IN Huffman/NNP trees/NNS ./.
