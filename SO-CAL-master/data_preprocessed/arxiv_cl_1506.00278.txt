In/IN this/DT paper/NN ,/, we/PRP introduce/VBP a/DT new/JJ dataset/NN consisting/VBG of/IN 360,001/CD focused/JJ natural/JJ language/NN descriptions/NNS for/IN 10,738/CD images/NNS ./.
This/DT dataset/NN ,/, the/DT Visual/JJ Madlibs/NN dataset/NN ,/, is/VBZ collected/VBN using/VBG automatically/RB produced/VBN fill/NN -/HYPH in/IN -/HYPH the/DT -/HYPH blank/JJ templates/NNS designed/VBN to/TO gather/VB targeted/VBN descriptions/NNS about/IN :/: people/NNS and/CC objects/NNS ,/, their/PRP$ appearances/NNS ,/, activities/NNS ,/, and/CC interactions/NNS ,/, as/RB well/RB as/IN inferences/NNS about/IN the/DT general/JJ scene/NN or/CC its/PRP$ broader/JJR context/NN ./.
We/PRP provide/VBP several/JJ analyses/NNS of/IN the/DT Visual/JJ Madlibs/NN dataset/NN and/CC demonstrate/VBP its/PRP$ applicability/NN to/IN two/CD new/JJ description/NN generation/NN tasks/NNS :/: focused/JJ description/NN generation/NN ,/, and/CC multiple/JJ -/HYPH choice/NN question/NN -/HYPH answering/VBG for/IN images/NNS ./.
Experiments/NNS using/VBG joint/JJ -/HYPH embedding/NN and/CC deep/JJ learning/NN methods/NNS show/VBP promising/JJ results/NNS on/IN these/DT tasks/NNS ./.
