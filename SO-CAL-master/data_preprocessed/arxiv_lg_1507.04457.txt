In/IN this/DT paper/NN we/PRP consider/VBP the/DT collaborative/JJ ranking/NN setting/NN :/: a/DT pool/NN of/IN users/NNS each/DT provides/VBZ a/DT small/JJ number/NN of/IN pairwise/JJ preferences/NNS between/IN $/$ d/LS $/$ possible/JJ items/NNS ;/: from/IN these/DT we/PRP need/VBP to/TO predict/VB preferences/NNS of/IN the/DT users/NNS for/IN items/NNS they/PRP have/VBP not/RB yet/RB seen/VBN ./.
We/PRP do/VBP so/RB by/IN fitting/VBG a/DT rank/NN $/$ r/VBP $/$ score/NN matrix/NN to/IN the/DT pairwise/JJ data/NNS ,/, and/CC provide/VB two/CD main/JJ contributions/NNS :/: (/-LRB- a/LS )/-RRB- we/PRP show/VBP that/IN an/DT algorithm/NN based/VBN on/IN convex/NN optimization/NN provides/VBZ good/JJ generalization/NN guarantees/NNS once/IN each/DT user/NN provides/VBZ as/IN few/JJ as/IN $/$ O/UH (/-LRB- r/NN \/SYM log/NN ^/SYM 2/CD d/NN )/-RRB- $/$ pairwise/JJ comparisons/NNS --/: essentially/RB matching/VBG the/DT sample/NN complexity/NN required/VBN in/IN the/DT related/JJ matrix/NN completion/NN setting/NN (/-LRB- which/WDT uses/VBZ actual/JJ numerical/JJ as/IN opposed/VBN to/IN pairwise/JJ information/NN )/-RRB- ,/, and/CC (/-LRB- b/LS )/-RRB- we/PRP develop/VBP a/DT large/JJ -/HYPH scale/NN non-convex/JJ implementation/NN ,/, which/WDT we/PRP call/VBP AltSVM/NNP ,/, that/DT trains/VBZ a/DT factored/JJ form/NN of/IN the/DT matrix/NN via/IN alternating/VBG minimization/NN (/-LRB- which/WDT we/PRP show/VBP reduces/VBZ to/IN alternating/VBG SVM/NN problems/NNS )/-RRB- ,/, and/CC scales/NNS and/CC parallelizes/NNS very/RB well/RB to/IN large/JJ problem/NN settings/NNS ./.
It/PRP also/RB outperforms/VBZ common/JJ baselines/NNS on/IN many/JJ moderately/RB large/JJ popular/JJ collaborative/JJ filtering/NN datasets/NNS in/IN both/DT NDCG/NNP and/CC in/IN other/JJ measures/NNS of/IN ranking/VBG performance/NN ./.
