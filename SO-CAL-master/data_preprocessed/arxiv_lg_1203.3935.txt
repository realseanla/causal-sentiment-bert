In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT distributed/VBN reinforcement/NN learning/NN (/-LRB- RL/NN )/-RRB- technique/NN called/VBN distributed/VBN power/NN control/NN using/VBG Q/NN -/HYPH learning/NN (/-LRB- DPC/NNP -/HYPH Q/NNP )/-RRB- to/TO manage/VB the/DT interference/NN caused/VBN by/IN the/DT femtocells/NNS on/IN macro-users/NNS in/IN the/DT downlink/NN ./.
The/DT DPC/NNP -/HYPH Q/NNP leverages/VBZ Q/NN -/HYPH Learning/VBG to/TO identify/VB the/DT sub-optimal/JJ pattern/NN of/IN power/NN allocation/NN ,/, which/WDT strives/VBZ to/TO maximize/VB femtocell/NN capacity/NN ,/, while/IN guaranteeing/VBG macrocell/NN capacity/NN level/NN in/IN an/DT underlay/NN cognitive/JJ setting/NN ./.
We/PRP propose/VBP two/CD different/JJ approaches/NNS for/IN the/DT DPC/NNP -/HYPH Q/NNP algorithm/NN :/: namely/RB ,/, independent/JJ ,/, and/CC cooperative/JJ ./.
In/IN the/DT former/JJ ,/, femtocells/NNS learn/VBP independently/RB from/IN each/DT other/JJ while/IN in/IN the/DT latter/JJ ,/, femtocells/NNS share/VBP some/DT information/NN during/IN learning/NN in/IN order/NN to/TO enhance/VB their/PRP$ performance/NN ./.
Simulation/NNP results/NNS show/VBP that/IN the/DT independent/JJ approach/NN is/VBZ capable/JJ of/IN mitigating/VBG the/DT interference/NN generated/VBN by/IN the/DT femtocells/NNS on/IN macro-users/NNS ./.
Moreover/RB ,/, the/DT results/NNS show/VBP that/IN cooperation/NN enhances/VBZ the/DT performance/NN of/IN the/DT femtocells/NNS in/IN terms/NNS of/IN speed/NN of/IN convergence/NN ,/, fairness/NN and/CC aggregate/NN femtocell/NN capacity/NN ./.
