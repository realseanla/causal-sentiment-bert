In/IN topic/NN modeling/NN ,/, many/JJ algorithms/NNS that/WDT guarantee/VBP identifiability/NN of/IN the/DT topics/NNS have/VBP been/VBN developed/VBN under/IN the/DT premise/NN that/IN there/EX exist/VBP anchor/NN words/NNS --/: i.e./FW ,/, words/NNS that/WDT only/RB appear/VBP (/-LRB- with/IN positive/JJ probability/NN )/-RRB- in/IN one/CD topic/NN ./.
Follow/VB -/HYPH up/RP work/NN has/VBZ resorted/VBN to/IN three/CD or/CC higher/JJR -/HYPH order/NN statistics/NNS of/IN the/DT data/NNS corpus/NN to/TO relax/VB the/DT anchor/NN word/NN assumption/NN ./.
Reliable/NNP estimates/NNS of/IN higher/JJR -/HYPH order/NN statistics/NNS are/VBP hard/JJ to/TO obtain/VB ,/, however/RB ,/, and/CC the/DT identification/NN of/IN topics/NNS under/IN those/DT models/NNS hinges/VBZ on/IN uncorrelatedness/NN of/IN the/DT topics/NNS ,/, which/WDT can/MD be/VB unrealistic/JJ ./.
This/DT paper/NN revisits/VBZ topic/NN modeling/NN based/VBN on/IN second/JJ -/HYPH order/NN moments/NNS ,/, and/CC proposes/VBZ an/DT anchor/NN -/HYPH free/JJ topic/NN mining/NN framework/NN ./.
The/DT proposed/VBN approach/NN guarantees/VBZ the/DT identification/NN of/IN the/DT topics/NNS under/IN a/DT much/JJ milder/JJR condition/NN compared/VBN to/IN the/DT anchor/NN -/HYPH word/NN assumption/NN ,/, thereby/RB exhibiting/VBG much/RB better/JJR robustness/NN in/IN practice/NN ./.
The/DT associated/JJ algorithm/NN only/RB involves/VBZ one/CD eigen/NN -/HYPH decomposition/NN and/CC a/DT few/JJ small/JJ linear/JJ programs/NNS ./.
This/DT makes/VBZ it/PRP easy/JJ to/TO implement/VB and/CC scale/VB up/RP to/IN very/RB large/JJ problem/NN instances/NNS ./.
Experiments/NNS using/VBG the/DT TDT2/NN and/CC Reuters/NNP -/HYPH 21578/CD corpus/NN demonstrate/VBP that/IN the/DT proposed/VBN anchor/NN -/HYPH free/JJ approach/NN exhibits/VBZ very/RB favorable/JJ performance/NN (/-LRB- measured/VBN using/VBG coherence/NN ,/, similarity/NN count/NN ,/, and/CC clustering/NN accuracy/NN metrics/NNS )/-RRB- compared/VBN to/IN the/DT prior/JJ art/NN ./.
