Deep/JJ Learning/NN (/-LRB- DL/NN )/-RRB- methods/NNS show/VBP very/RB good/JJ performance/NN when/WRB trained/VBN on/IN large/JJ ,/, balanced/JJ data/NNS sets/NNS ./.
However/RB ,/, many/JJ practical/JJ problems/NNS involve/VBP imbalanced/VBN data/NNS sets/NNS ,/, or/CC //HYPH and/CC classes/NNS with/IN a/DT small/JJ number/NN of/IN training/NN samples/NNS ./.
The/DT performance/NN of/IN DL/NN methods/NNS as/RB well/RB as/IN more/RBR traditional/JJ classifiers/NNS drops/VBZ significantly/RB in/IN such/JJ settings/NNS ./.
Most/JJS of/IN the/DT existing/VBG solutions/NNS for/IN imbalanced/JJ problems/NNS focus/VBP on/IN customizing/VBG the/DT data/NNS for/IN training/NN ./.
A/DT more/JJR principled/JJ solution/NN is/VBZ to/TO use/VB mixed/JJ Hinge/NNP -/HYPH Minimax/NNP risk/NN [/-LRB- 19/CD ]/-RRB- specifically/RB designed/VBN to/TO solve/VB binary/JJ problems/NNS with/IN imbalanced/JJ training/NN sets/NNS ./.
Here/RB we/PRP propose/VBP a/DT Latent/JJ Hinge/NNP Minimax/NNP (/-LRB- LHM/NNP )/-RRB- risk/NN and/CC a/DT training/NN algorithm/NN that/WDT generalizes/VBZ this/DT paradigm/NN to/IN an/DT ensemble/NN of/IN hyperplanes/NNS that/WDT can/MD form/VB arbitrary/JJ complex/NN ,/, piecewise/RB linear/JJ boundaries/NNS ./.
To/TO extract/VB good/JJ features/NNS ,/, we/PRP combine/VBP LHM/NNP model/NN with/IN CNN/NNP via/IN transfer/NN learning/NN ./.
To/TO solve/VB multi-class/NN problem/NN we/PRP map/VBP pre-trained/JJ category/NN -/HYPH specific/JJ LHM/NNP classifiers/NNS to/IN a/DT multi-class/JJ neural/JJ network/NN and/CC adjust/VB the/DT weights/NNS with/IN very/RB fast/JJ tuning/NN ./.
LHM/NNP classifier/NN enables/VBZ the/DT use/NN of/IN unlabeled/JJ data/NNS in/IN its/PRP$ training/NN and/CC the/DT mapping/NN allows/VBZ for/IN multi-class/JJ inference/NN ,/, resulting/VBG in/IN a/DT classifier/NN that/WDT performs/VBZ better/JJR than/IN alternatives/NNS when/WRB trained/VBN on/IN a/DT small/JJ number/NN of/IN training/NN samples/NNS ./.
