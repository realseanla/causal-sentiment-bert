This/DT paper/NN presents/VBZ the/DT development/NN of/IN several/JJ models/NNS of/IN a/DT deep/JJ convolutional/JJ auto/NN -/HYPH encoder/NN in/IN the/DT Caffe/NNP deep/JJ learning/NN framework/NN and/CC their/PRP$ experimental/JJ evaluation/NN on/IN the/DT example/NN of/IN MNIST/NN dataset/NN ./.
We/PRP have/VBP created/VBN five/CD models/NNS of/IN a/DT convolutional/JJ auto/NN -/HYPH encoder/NN which/WDT differ/VBP architecturally/RB by/IN the/DT presence/NN or/CC absence/NN of/IN pooling/VBG and/CC unpooling/VBG layers/NNS in/IN the/DT auto/NN -/HYPH encoder/NN 's/POS encoder/NN and/CC decoder/NN parts/NNS ./.
Our/PRP$ results/NNS show/VBP that/IN the/DT developed/VBN models/NNS provide/VBP very/RB good/JJ results/NNS in/IN dimensionality/NN reduction/NN and/CC unsupervised/JJ clustering/NN tasks/NNS ,/, and/CC small/JJ classification/NN errors/NNS when/WRB we/PRP used/VBD the/DT learned/VBN internal/JJ code/NN as/IN an/DT input/NN of/IN a/DT supervised/JJ linear/JJ classifier/NN and/CC multi-layer/JJ perceptron/NN ./.
The/DT best/JJS results/NNS were/VBD provided/VBN by/IN a/DT model/NN where/WRB the/DT encoder/NN part/NN contains/VBZ convolutional/JJ and/CC pooling/VBG layers/NNS ,/, followed/VBN by/IN an/DT analogous/JJ decoder/NN part/NN with/IN deconvolution/NN and/CC unpooling/JJ layers/NNS without/IN the/DT use/NN of/IN switch/NN variables/NNS in/IN the/DT decoder/JJR part/NN ./.
The/DT paper/NN also/RB discusses/VBZ practical/JJ details/NNS of/IN the/DT creation/NN of/IN a/DT deep/JJ convolutional/JJ auto/NN -/HYPH encoder/NN in/IN the/DT very/RB popular/JJ Caffe/NNP deep/JJ learning/NN framework/NN ./.
We/PRP believe/VBP that/IN our/PRP$ approach/NN and/CC results/NNS presented/VBN in/IN this/DT paper/NN could/MD help/VB other/JJ researchers/NNS to/TO build/VB efficient/JJ deep/JJ neural/JJ network/NN architectures/NNS in/IN the/DT future/NN ./.
