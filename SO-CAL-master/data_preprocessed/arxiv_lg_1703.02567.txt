We/PRP study/VBP the/DT online/JJ learning/NN problem/NN of/IN a/DT bidder/NN who/WP participates/VBZ in/IN repeated/VBN auctions/NNS ./.
With/IN the/DT goal/NN of/IN maximizing/VBG his/PRP$ total/JJ T/NN -/HYPH period/NN payoff/NN ,/, the/DT bidder/NN wants/VBZ to/TO determine/VB the/DT optimal/JJ allocation/NN of/IN his/PRP$ fixed/JJ budget/NN among/IN his/PRP$ bids/NNS for/IN $/$ K$/CD different/JJ goods/NNS at/IN each/DT period/NN ./.
As/IN a/DT bidding/NN strategy/NN ,/, we/PRP propose/VBP a/DT polynomial/JJ time/NN algorithm/NN ,/, referred/VBN to/IN as/IN dynamic/JJ programming/NN on/IN discrete/JJ set/NN (/-LRB- DPDS/NN )/-RRB- ,/, which/WDT is/VBZ inspired/VBN by/IN the/DT dynamic/JJ programming/NN approach/NN to/IN Knapsack/NN problems/NNS ./.
We/PRP show/VBP that/IN DPDS/NNP achieves/VBZ the/DT regret/NN order/NN of/IN $/$ O/UH (/-LRB- \/SYM sqrt/NN {/-LRB- T/NN \/SYM log/NN {/-LRB- T/NN }/-RRB- }/-RRB- )/-RRB- $/$ ./.
Also/RB ,/, by/IN showing/VBG that/IN the/DT regret/NN growth/NN rate/NN is/VBZ lower/JJR bounded/VBN by/IN $/$ \/SYM Omega/NN (/-LRB- \/SYM sqrt/NN {/-LRB- T/NN }/-RRB- )/-RRB- $/$ for/IN any/DT bidding/NN strategy/NN ,/, we/PRP conclude/VBP that/IN DPDS/NNP algorithm/NN is/VBZ order/NN optimal/JJ up/RP to/IN a/DT $/$ \/CD sqrt/NN {/-LRB- \/SYM log/NN {/-LRB- T/NN }/-RRB- }/-RRB- $/$ term/NN ./.
We/PRP also/RB evaluate/VBP the/DT performance/NN of/IN DPDS/NNP empirically/RB in/IN the/DT context/NN of/IN virtual/JJ bidding/NN in/IN wholesale/JJ electricity/NN markets/NNS by/IN using/VBG historical/JJ data/NNS from/IN the/DT New/NNP York/NNP energy/NN market/NN ./.
