In/IN real/JJ supervised/JJ learning/NN scenarios/NNS ,/, it/PRP is/VBZ not/RB uncommon/JJ that/IN the/DT training/NN and/CC test/NN sample/NN follow/VBP different/JJ probability/NN distributions/NNS ,/, thus/RB rendering/VBG the/DT necessity/NN to/TO correct/VB the/DT sampling/NN bias/NN ./.
Focusing/VBG on/IN a/DT particular/JJ covariate/NN shift/NN problem/NN ,/, we/PRP derive/VBP high/JJ probability/NN confidence/NN bounds/NNS for/IN the/DT kernel/NN mean/VB matching/VBG (/-LRB- KMM/NNP )/-RRB- estimator/NN ,/, whose/WP$ convergence/NN rate/NN turns/VBZ out/RP to/TO depend/VB on/IN some/DT regularity/NN measure/NN of/IN the/DT regression/NN function/NN and/CC also/RB on/IN some/DT capacity/NN measure/NN of/IN the/DT kernel/NN ./.
By/IN comparing/VBG KMM/NNP with/IN the/DT natural/JJ plug/NN -/HYPH in/IN estimator/NN ,/, we/PRP establish/VBP the/DT superiority/NN of/IN the/DT former/JJ hence/RB provide/VBP concrete/JJ evidence/NN //HYPH understanding/NN to/IN the/DT effectiveness/NN of/IN KMM/NNP under/IN covariate/NN shift/NN ./.
