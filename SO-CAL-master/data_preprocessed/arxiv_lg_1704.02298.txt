Recently/RB ,/, deep/JJ learning/NN methods/NNS have/VBP been/VBN shown/VBN to/TO improve/VB the/DT performance/NN of/IN recommender/NN systems/NNS over/IN traditional/JJ methods/NNS ,/, especially/RB when/WRB review/NN text/NN is/VBZ available/JJ ./.
For/IN example/NN ,/, a/DT recent/JJ model/NN ,/, DeepCoNN/NNP ,/, uses/VBZ neural/JJ nets/NNS to/TO learn/VB one/CD latent/NN representation/NN for/IN the/DT text/NN of/IN all/DT reviews/NNS written/VBN by/IN a/DT target/NN user/NN ,/, and/CC a/DT second/JJ latent/NN representation/NN for/IN the/DT text/NN of/IN all/DT reviews/NNS for/IN a/DT target/NN item/NN ,/, and/CC then/RB combines/VBZ these/DT latent/JJ representations/NNS to/TO obtain/VB state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN performance/NN on/IN recommendation/NN tasks/NNS ./.
We/PRP show/VBP that/IN (/-LRB- unsurprisingly/RB )/-RRB- much/RB of/IN the/DT predictive/JJ value/NN of/IN review/NN text/NN comes/VBZ from/IN reviews/NNS of/IN the/DT target/NN user/NN for/IN the/DT target/NN item/NN ./.
We/PRP then/RB introduce/VB a/DT way/NN in/IN which/WDT this/DT information/NN can/MD be/VB used/VBN in/IN recommendation/NN ,/, even/RB when/WRB the/DT target/NN user/NN 's/POS review/NN for/IN the/DT target/NN item/NN is/VBZ not/RB available/JJ ./.
Our/PRP$ model/NN ,/, called/VBN TransNets/NNP ,/, extends/VBZ the/DT DeepCoNN/NNP model/NN by/IN introducing/VBG an/DT additional/JJ latent/JJ layer/NN representing/VBG the/DT target/NN user/NN -/HYPH target/NN item/NN pair/NN ./.
We/PRP then/RB regularize/VBP this/DT layer/NN ,/, at/IN training/NN time/NN ,/, to/TO be/VB similar/JJ to/IN another/DT latent/NN representation/NN of/IN the/DT target/NN user/NN 's/POS review/NN of/IN the/DT target/NN item/NN ./.
We/PRP show/VBP that/IN TransNets/NNPS and/CC extensions/NNS of/IN it/PRP improve/VB substantially/RB over/IN the/DT previous/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN ./.
