In/IN this/DT paper/NN we/PRP investigate/VBP the/DT computational/JJ complexity/NN of/IN learning/VBG the/DT graph/NN structure/NN underlying/VBG a/DT discrete/JJ undirected/JJ graphical/JJ model/NN from/IN i.i.d./NN samples/NNS ./.
We/PRP first/RB observe/VBP that/IN the/DT notoriously/RB difficult/JJ problem/NN of/IN learning/VBG parities/NNS with/IN noise/NN can/MD be/VB captured/VBN as/IN a/DT special/JJ case/NN of/IN learning/VBG graphical/JJ models/NNS ./.
This/DT leads/VBZ to/IN an/DT unconditional/JJ computational/JJ lower/JJR bound/VBN of/IN $/$ \/SYM Omega/NN (/-LRB- p/NN ^/SYM {/-LRB- d/NN //HYPH 2/CD }/-RRB- )/-RRB- $/$ for/IN learning/VBG general/JJ graphical/JJ models/NNS on/IN $/$ p/NN $/$ nodes/NNS of/IN maximum/JJ degree/NN $/$ d/LS $/$ ,/, for/IN the/DT class/NN of/IN so/RB -/HYPH called/VBN statistical/JJ algorithms/NNS recently/RB introduced/VBN by/IN Feldman/NNP et/FW al/FW (/-LRB- 2013/CD )/-RRB- ./.
The/DT lower/JJR bound/JJ suggests/VBZ that/IN the/DT $/$ O/UH (/-LRB- p/NN ^/SYM d/NN )/-RRB- $/$ runtime/CD required/VBN to/TO exhaustively/RB search/VB over/IN neighborhoods/NNS can/MD not/RB be/VB significantly/RB improved/VBN without/IN restricting/VBG the/DT class/NN of/IN models/NNS ./.
