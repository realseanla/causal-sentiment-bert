We/PRP develop/VBP a/DT sequential/JJ low/JJ -/HYPH complexity/NN inference/NN procedure/NN for/IN the/DT Infinite/JJ Gaussian/NNP Mixture/NNP Model/NNP (/-LRB- IGMM/NNP )/-RRB- for/IN the/DT general/JJ case/NN of/IN an/DT unknown/JJ mean/NN and/CC covariance/NN ./.
The/DT observations/NNS are/VBP sequentially/RB allocated/VBN to/IN classes/NNS based/VBN on/IN a/DT sequential/JJ maximum/NN a-posterior/NN (/-LRB- MAP/NN )/-RRB- criterion/NN ./.
We/PRP present/VBP an/DT easily/RB computed/VBN ,/, closed/VBD form/NN for/IN the/DT conditional/JJ likelihood/NN ,/, in/IN which/WDT the/DT parameters/NNS can/MD be/VB recursively/RB updated/VBN as/IN a/DT function/NN of/IN the/DT streaming/NN data/NNS ./.
We/PRP propose/VBP a/DT novel/JJ adaptive/JJ design/NN for/IN the/DT Dirichlet/NNP process/NN concentration/NN parameter/NN at/IN each/DT iteration/NN ,/, and/CC prove/VB ,/, under/IN a/DT simplified/JJ model/NN ,/, that/IN the/DT sequence/NN of/IN concentration/NN parameters/NNS is/VBZ asymptotically/RB well/RB -/HYPH behaved/VBN ./.
We/PRP sketch/VBP an/DT equivalence/NN between/IN the/DT steady/JJ -/HYPH state/NN performance/NN of/IN the/DT algorithm/NN and/CC Gaussian/JJ classification/NN ./.
The/DT methodology/NN is/VBZ applied/VBN to/IN the/DT problem/NN of/IN adaptive/JJ modulation/NN recognition/NN and/CC obviates/VBZ the/DT need/NN for/IN storing/VBG a/DT large/JJ modulation/NN library/NN required/VBN for/IN traditional/JJ modulation/NN recognition/NN ./.
We/PRP also/RB numerically/RB evaluate/VB the/DT bit/NN error/NN rate/NN performance/NN (/-LRB- BER/NN )/-RRB- of/IN the/DT DPMM/NNP -/HYPH trained/VBN classifier/NN when/WRB used/VBN as/IN a/DT demodulator/NN and/CC show/VBP that/IN there/EX is/VBZ critical/JJ signal/NN -/HYPH to/IN -/HYPH noise/NN ratio/NN (/-LRB- SNR/NN )/-RRB- that/WDT characterizes/VBZ whether/IN successful/JJ decoding/NN is/VBZ possible/JJ ./.
