UCT/NNP ,/, a/DT state/NN -/HYPH of/IN -/HYPH the/DT art/NN algorithm/NN for/IN Monte/NNP Carlo/NNP tree/NN search/NN (/-LRB- MCTS/NNP )/-RRB- in/IN games/NNS and/CC Markov/NNP decision/NN processes/NNS ,/, is/VBZ based/VBN on/IN UCB/NNP ,/, a/DT sampling/NN policy/NN for/IN the/DT Multi-armed/JJ Bandit/NN problem/NN (/-LRB- MAB/NN )/-RRB- that/WDT minimizes/VBZ the/DT cumulative/JJ regret/NN ./.
However/RB ,/, search/NN differs/VBZ from/IN MAB/NNP in/IN that/DT in/IN MCTS/NNP it/PRP is/VBZ usually/RB only/RB the/DT final/JJ "/`` arm/NN pull/VBP "/`` (/-LRB- the/DT actual/JJ move/NN selection/NN )/-RRB- that/WDT collects/VBZ a/DT reward/NN ,/, rather/RB than/IN all/DT "/`` arm/NN pulls/VBZ "/'' ./.
Therefore/RB ,/, it/PRP makes/VBZ more/JJR sense/NN to/TO minimize/VB the/DT simple/JJ regret/NN ,/, as/IN opposed/VBN to/IN the/DT cumulative/JJ regret/NN ./.
We/PRP begin/VBP by/IN introducing/VBG policies/NNS for/IN multi-armed/JJ bandits/NNS with/IN lower/JJR finite/NN -/HYPH time/NN and/CC asymptotic/JJ simple/JJ regret/NN than/IN UCB/NNP ,/, using/VBG it/PRP to/TO develop/VB a/DT two/CD -/HYPH stage/NN scheme/NN (/-LRB- SR/NNP CR/NNP )/-RRB- for/IN MCTS/NNP which/WDT outperforms/VBZ UCT/NNP empirically/RB ./.
