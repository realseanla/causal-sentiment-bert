The/DT restricted/JJ Boltzmann/NNP machine/NN (/-LRB- RBM/NNP )/-RRB- is/VBZ a/DT flexible/JJ tool/NN for/IN modeling/VBG complex/JJ data/NNS ,/, however/RB there/RB have/VBP been/VBN significant/JJ computational/JJ difficulties/NNS in/IN using/VBG RBMs/NNS to/TO model/VB high/JJ -/HYPH dimensional/JJ multinomial/JJ observations/NNS ./.
In/IN natural/JJ language/NN processing/NN applications/NNS ,/, words/NNS are/VBP naturally/RB modeled/VBN by/IN K/NN -/HYPH ary/NN discrete/JJ distributions/NNS ,/, where/WRB K/NN is/VBZ determined/VBN by/IN the/DT vocabulary/NN size/NN and/CC can/MD easily/RB be/VB in/IN the/DT hundred/CD thousands/NNS ./.
The/DT conventional/JJ approach/NN to/IN training/NN RBMs/NNS on/IN word/NN observations/NNS is/VBZ limited/JJ because/IN it/PRP requires/VBZ sampling/VBG the/DT states/NNS of/IN K/NN -/HYPH way/NN softmax/JJ visible/JJ units/NNS during/IN block/NN Gibbs/NNP updates/NNS ,/, an/DT operation/NN that/WDT takes/VBZ time/NN linear/JJ in/IN K/NN ./.
In/IN this/DT work/NN ,/, we/PRP address/VBP this/DT issue/NN by/IN employing/VBG a/DT more/RBR general/JJ class/NN of/IN Markov/NNP chain/NN Monte/NNP Carlo/NNP operators/NNS on/IN the/DT visible/JJ units/NNS ,/, yielding/VBG updates/NNS with/IN computational/JJ complexity/NN independent/JJ of/IN K/NN ./.
We/PRP demonstrate/VBP the/DT success/NN of/IN our/PRP$ approach/NN by/IN training/VBG RBMs/NNS on/IN hundreds/NNS of/IN millions/NNS of/IN word/NN n/NN -/HYPH grams/NNS using/VBG larger/JJR vocabularies/NNS than/IN previously/RB feasible/JJ with/IN RBMs/NNS and/CC using/VBG the/DT learned/VBN features/NNS to/TO improve/VB performance/NN on/IN chunking/VBG and/CC sentiment/NN classification/NN tasks/NNS ,/, achieving/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN results/NNS on/IN the/DT latter/JJ ./.
