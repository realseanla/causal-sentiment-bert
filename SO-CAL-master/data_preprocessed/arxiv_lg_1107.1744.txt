This/DT paper/NN addresses/VBZ the/DT problem/NN of/IN minimizing/VBG a/DT convex/NN ,/, Lipschitz/NNP function/VBP $/$ f/LS $/$ over/IN a/DT convex/NN ,/, compact/JJ set/NN $/$ \/CD xset/VBN $/$ under/IN a/DT stochastic/JJ bandit/NN feedback/NN model/NN ./.
In/IN this/DT model/NN ,/, the/DT algorithm/NN is/VBZ allowed/VBN to/TO observed/VBN noisy/JJ realizations/NNS of/IN the/DT function/NN value/NN $/$ f/LS (/-LRB- x/SYM )/-RRB- $/$ at/IN any/DT query/NN point/NN $/$ x/SYM \/SYM in/IN \/SYM xset/FW $/$ ./.
The/DT quantity/NN of/IN interest/NN is/VBZ regret/NN of/IN the/DT algorithm/NN ,/, which/WDT is/VBZ the/DT sum/NN of/IN the/DT function/NN values/NNS at/IN algorithm/NN 's/POS query/NN points/VBZ minus/CC the/DT optimal/JJ function/NN value/NN ./.
We/PRP demonstrate/VBP a/DT generalization/NN of/IN the/DT ellipsoid/JJ algorithm/NN that/WDT incurs/VBZ $/$ \/CD otil/NN (/-LRB- \/SYM poly/NN (/-LRB- d/NN )/-RRB- \/SYM sqrt/NN {/-LRB- T/NN }/-RRB- )/-RRB- $/$ regret/NN ./.
Since/IN any/DT algorithm/NN has/VBZ regret/NN at/IN least/JJS $/$ \/SYM Omega/NN (/-LRB- \/SYM sqrt/NN {/-LRB- T/NN }/-RRB- )/-RRB- $/$ on/IN this/DT problem/NN ,/, our/PRP$ algorithm/NN is/VBZ optimal/JJ in/IN terms/NNS of/IN the/DT scaling/NN with/IN $/$ T$/CD ./.
