The/DT encoder/NN -/HYPH decoder/NN framework/NN for/IN neural/JJ machine/NN translation/NN (/-LRB- NMT/NN )/-RRB- has/VBZ been/VBN shown/VBN effective/JJ in/IN large/JJ data/NNS scenarios/NNS ,/, but/CC is/VBZ much/RB less/JJR effective/JJ for/IN low/JJ -/HYPH resource/NN languages/NNS ./.
We/PRP present/VBP a/DT transfer/NN learning/NN method/NN that/WDT significantly/RB improves/VBZ Bleu/NN scores/NNS across/IN a/DT range/NN of/IN low/JJ -/HYPH resource/NN languages/NNS ./.
Our/PRP$ key/JJ idea/NN is/VBZ to/TO first/RB train/VB a/DT high/JJ -/HYPH resource/NN language/NN pair/NN (/-LRB- the/DT parent/NN model/NN )/-RRB- ,/, then/RB transfer/VB some/DT of/IN the/DT learned/VBN parameters/NNS to/IN the/DT low/JJ -/HYPH resource/NN pair/NN (/-LRB- the/DT child/NN model/NN )/-RRB- to/IN initialize/VB and/CC constrain/VB training/NN ./.
Using/VBG our/PRP$ transfer/NN learning/NN method/NN we/PRP improve/VBP baseline/NN NMT/NN models/NNS by/IN an/DT average/NN of/IN 5.6/CD Bleu/NN on/IN four/CD low/JJ -/HYPH resource/NN language/NN pairs/NNS ./.
Ensembling/NNP and/CC unknown/JJ word/NN replacement/NN add/VB another/DT 2/CD Bleu/NNP which/WDT brings/VBZ the/DT NMT/NN performance/NN on/IN low/JJ -/HYPH resource/NN machine/NN translation/NN close/NN to/IN a/DT strong/JJ syntax/NN based/VBN machine/NN translation/NN (/-LRB- SBMT/NN )/-RRB- system/NN ,/, exceeding/VBG its/PRP$ performance/NN on/IN one/CD language/NN pair/NN ./.
Additionally/RB ,/, using/VBG the/DT transfer/NN learning/NN model/NN for/IN re-scoring/NN ,/, we/PRP can/MD improve/VB the/DT SBMT/NN system/NN by/IN an/DT average/NN of/IN 1.3/CD Bleu/NNP ,/, improving/VBG the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN on/IN low/JJ -/HYPH resource/NN machine/NN translation/NN ./.
