Neural/JJ machine/NN translation/NN ,/, a/DT recently/RB proposed/VBN approach/NN to/IN machine/NN translation/NN based/VBN purely/RB on/IN neural/JJ networks/NNS ,/, has/VBZ shown/VBN promising/JJ results/NNS compared/VBN to/IN the/DT existing/VBG approaches/NNS such/JJ as/IN phrase/NN -/HYPH based/VBN statistical/JJ machine/NN translation/NN ./.
Despite/IN its/PRP$ recent/JJ success/NN ,/, neural/JJ machine/NN translation/NN has/VBZ its/PRP$ limitation/NN in/IN handling/VBG a/DT larger/JJR vocabulary/NN ,/, as/IN training/NN complexity/NN as/RB well/RB as/IN decoding/NN complexity/NN increase/NN proportionally/RB to/IN the/DT number/NN of/IN target/NN words/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT method/NN that/WDT allows/VBZ us/PRP to/TO use/VB a/DT very/RB large/JJ target/NN vocabulary/NN without/IN increasing/VBG training/NN complexity/NN ,/, based/VBN on/IN importance/NN sampling/NN ./.
We/PRP show/VBP that/IN decoding/NN can/MD be/VB efficiently/RB done/VBN even/RB with/IN the/DT model/NN having/VBG a/DT very/RB large/JJ target/NN vocabulary/NN by/IN selecting/VBG only/RB a/DT small/JJ subset/NN of/IN the/DT whole/JJ target/NN vocabulary/NN ./.
The/DT models/NNS trained/VBN by/IN the/DT proposed/VBN approach/NN are/VBP empirically/RB found/VBN to/TO outperform/VB the/DT baseline/NN models/NNS with/IN a/DT small/JJ vocabulary/NN as/RB well/RB as/IN the/DT LSTM/NNP -/HYPH based/VBN neural/JJ machine/NN translation/NN models/NNS ./.
Furthermore/RB ,/, when/WRB we/PRP use/VBP the/DT ensemble/NN of/IN a/DT few/JJ models/NNS with/IN very/RB large/JJ target/NN vocabularies/NNS ,/, we/PRP achieve/VBP the/DT state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN translation/NN performance/NN (/-LRB- measured/VBN by/IN BLEU/NN )/-RRB- on/IN the/DT English/NNP -/HYPH &gt;/SYM German/JJ translation/NN and/CC almost/RB as/RB high/JJ performance/NN as/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN English/NNP -/HYPH &gt;/SYM French/JJ translation/NN system/NN ./.
