Imitation/NN learning/NN has/VBZ traditionally/RB been/VBN applied/VBN to/TO learn/VB a/DT single/JJ task/NN from/IN demonstrations/NNS thereof/RB ./.
The/DT requirement/NN of/IN structured/JJ and/CC isolated/JJ demonstrations/NNS limits/VBZ the/DT scalability/NN of/IN imitation/NN learning/NN approaches/VBZ as/IN they/PRP are/VBP difficult/JJ to/TO apply/VB to/IN real/JJ -/HYPH world/NN scenarios/NNS ,/, where/WRB robots/NNS have/VBP to/TO be/VB able/JJ to/TO execute/VB a/DT multitude/NN of/IN tasks/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT multi-modal/JJ imitation/NN learning/VBG framework/NN that/WDT is/VBZ able/JJ to/TO segment/NN and/CC imitate/VBP skills/NNS from/IN unlabelled/JJ and/CC unstructured/JJ demonstrations/NNS by/IN learning/VBG skill/NN segmentation/NN and/CC imitation/NN learning/NN jointly/RB ./.
The/DT extensive/JJ simulation/NN results/NNS indicate/VBP that/IN our/PRP$ method/NN can/MD efficiently/RB separate/VB the/DT demonstrations/NNS into/IN individual/JJ skills/NNS and/CC learn/VB to/TO imitate/VB them/PRP using/VBG a/DT single/JJ multi-modal/JJ policy/NN ./.
The/DT video/NN of/IN our/PRP$ experiments/NNS is/VBZ available/JJ at/IN
