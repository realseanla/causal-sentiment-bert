Convolutional/JJ Neural/JJ Networks/NNS spread/VBP through/IN computer/NN vision/NN like/IN a/DT wildfire/NN ,/, impacting/VBG almost/RB all/DT visual/JJ tasks/NNS imaginable/JJ ./.
Despite/IN this/DT ,/, few/JJ researchers/NNS dare/VBP to/TO train/VB their/PRP$ models/NNS from/IN scratch/NN ./.
Most/JJS work/NN builds/VBZ on/IN one/CD of/IN a/DT handful/NN of/IN ImageNet/NNP pre-trained/JJ models/NNS ,/, and/CC fine/JJ -/HYPH tunes/NNS or/CC adapts/VBZ these/DT for/IN specific/JJ tasks/NNS ./.
This/DT is/VBZ in/IN large/JJ part/NN due/IN to/IN the/DT difficulty/NN of/IN properly/RB initializing/VBG these/DT networks/NNS from/IN scratch/NN ./.
A/DT small/JJ miscalibration/NN of/IN the/DT initial/JJ weights/NNS leads/VBZ to/IN vanishing/VBG or/CC exploding/VBG gradients/NNS ,/, as/RB well/RB as/IN poor/JJ convergence/NN properties/NNS ./.
In/IN this/DT work/NN we/PRP present/VBP a/DT fast/JJ and/CC simple/JJ data/NNS -/HYPH dependent/JJ initialization/NN procedure/NN ,/, that/WDT sets/VBZ the/DT weights/NNS of/IN a/DT network/NN such/JJ that/IN all/DT units/NNS in/IN the/DT network/NN train/NN at/IN roughly/RB the/DT same/JJ rate/NN ,/, avoiding/VBG vanishing/VBG or/CC exploding/VBG gradients/NNS ./.
Our/PRP$ initialization/NN matches/VBZ the/DT current/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN unsupervised/JJ or/CC self/NN -/HYPH supervised/JJ pre-training/JJ methods/NNS on/IN standard/JJ computer/NN vision/NN tasks/NNS ,/, such/JJ as/IN image/NN classification/NN and/CC object/NN detection/NN ,/, while/IN being/VBG roughly/RB three/CD orders/NNS of/IN magnitude/NN faster/RBR ./.
When/WRB combined/VBN with/IN pre-training/JJ methods/NNS ,/, our/PRP$ initialization/NN significantly/RB outperforms/VBZ prior/JJ work/NN ,/, narrowing/VBG the/DT gap/NN between/IN supervised/JJ and/CC unsupervised/JJ pre-training/NN ./.
