We/PRP present/VBP Deep/JJ Voice/NNP ,/, a/DT production/NN -/HYPH quality/NN text/NN -/HYPH to/IN -/HYPH speech/NN system/NN constructed/VBN entirely/RB from/IN deep/JJ neural/JJ networks/NNS ./.
Deep/JJ Voice/NNP lays/VBZ the/DT groundwork/NN for/IN truly/RB end/NN -/HYPH to/IN -/HYPH end/NN neural/JJ speech/NN synthesis/NN ./.
The/DT system/NN comprises/VBZ five/CD major/JJ building/NN blocks/NNS :/: a/DT segmentation/NN model/NN for/IN locating/VBG phoneme/NN boundaries/NNS ,/, a/DT grapheme/NN -/HYPH to/IN -/HYPH phoneme/NN conversion/NN model/NN ,/, a/DT phoneme/NN duration/NN prediction/NN model/NN ,/, a/DT fundamental/JJ frequency/NN prediction/NN model/NN ,/, and/CC an/DT audio/JJ synthesis/NN model/NN ./.
For/IN the/DT segmentation/NN model/NN ,/, we/PRP propose/VBP a/DT novel/JJ way/NN of/IN performing/VBG phoneme/NN boundary/NN detection/NN with/IN deep/JJ neural/JJ networks/NNS using/VBG connectionist/NN temporal/JJ classification/NN (/-LRB- CTC/NN )/-RRB- loss/NN ./.
For/IN the/DT audio/NN synthesis/NN model/NN ,/, we/PRP implement/VBP a/DT variant/NN of/IN WaveNet/NNP that/WDT requires/VBZ fewer/JJR parameters/NNS and/CC trains/NNS faster/RBR than/IN the/DT original/JJ ./.
By/IN using/VBG a/DT neural/JJ network/NN for/IN each/DT component/NN ,/, our/PRP$ system/NN is/VBZ simpler/JJR and/CC more/JJR flexible/JJ than/IN traditional/JJ text/NN -/HYPH to/IN -/HYPH speech/NN systems/NNS ,/, where/WRB each/DT component/NN requires/VBZ laborious/JJ feature/NN engineering/NN and/CC extensive/JJ domain/NN expertise/NN ./.
Finally/RB ,/, we/PRP show/VBP that/IN inference/NN with/IN our/PRP$ system/NN can/MD be/VB performed/VBN faster/RBR than/IN real/JJ time/NN and/CC describe/VB optimized/VBN WaveNet/NNP inference/NN kernels/NNS on/IN both/DT CPU/NN and/CC GPU/NN that/WDT achieve/VBP up/RP to/IN 400x/CD speedups/NNS over/IN existing/VBG implementations/NNS ./.
