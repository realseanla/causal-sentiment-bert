In/IN multi-task/VB learning/VBG several/JJ related/JJ tasks/NNS are/VBP considered/VBN simultaneously/RB ,/, with/IN the/DT hope/NN that/IN by/IN an/DT appropriate/JJ sharing/NN of/IN information/NN across/IN tasks/NNS ,/, each/DT task/NN may/MD benefit/VB from/IN the/DT others/NNS ./.
In/IN the/DT context/NN of/IN learning/VBG linear/JJ functions/NNS for/IN supervised/JJ classification/NN or/CC regression/NN ,/, this/DT can/MD be/VB achieved/VBN by/IN including/VBG a/FW priori/FW information/NN about/IN the/DT weight/NN vectors/NNS associated/VBN with/IN the/DT tasks/NNS ,/, and/CC how/WRB they/PRP are/VBP expected/VBN to/TO be/VB related/VBN to/IN each/DT other/JJ ./.
In/IN this/DT paper/NN ,/, we/PRP assume/VBP that/IN tasks/NNS are/VBP clustered/VBN into/IN groups/NNS ,/, which/WDT are/VBP unknown/JJ beforehand/RB ,/, and/CC that/IN tasks/NNS within/IN a/DT group/NN have/VBP similar/JJ weight/NN vectors/NNS ./.
We/PRP design/VBP a/DT new/JJ spectral/JJ norm/NN that/WDT encodes/VBZ this/DT a/FW priori/FW assumption/NN ,/, without/IN the/DT prior/JJ knowledge/NN of/IN the/DT partition/NN of/IN tasks/NNS into/IN groups/NNS ,/, resulting/VBG in/IN a/DT new/JJ convex/NN optimization/NN formulation/NN for/IN multi-task/VB learning/NN ./.
We/PRP show/VBP in/IN simulations/NNS on/IN synthetic/JJ examples/NNS and/CC on/IN the/DT IEDB/NNP MHC/NN -/: I/PRP binding/VBG dataset/NN ,/, that/IN our/PRP$ approach/NN outperforms/VBZ well/RB -/HYPH known/VBN convex/NN methods/NNS for/IN multi-task/VB learning/NN ,/, as/RB well/RB as/IN related/VBN non/AFX convex/NN methods/NNS dedicated/VBN to/IN the/DT same/JJ problem/NN ./.
