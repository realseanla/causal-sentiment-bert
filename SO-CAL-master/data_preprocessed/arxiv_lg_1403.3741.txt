Any/DT learning/NN algorithm/NN over/IN Markov/NNP decision/NN processes/NNS (/-LRB- MDPs/NNS )/-RRB- will/MD have/VB worst/JJS -/HYPH case/NN regret/NN $/$ \/SYM Omega/NN (/-LRB- \/SYM sqrt/NN {/-LRB- SAT/NN }/-RRB- )/-RRB- $/$ where/WRB $/$ T$/CD is/VBZ the/DT elapsed/VBN time/NN and/CC $/$ S$/CD and/CC $/$ A$/$ are/VBP the/DT cardinalities/NNS of/IN the/DT state/NN and/CC action/NN spaces/NNS ./.
In/IN many/JJ settings/NNS of/IN interest/NN $/$ S$/CD and/CC $/$ A$/$ may/MD be/VB so/RB huge/JJ that/IN it/PRP is/VBZ impossible/JJ to/TO guarantee/VB good/JJ performance/NN for/IN an/DT arbitrary/JJ MDP/NNP on/IN any/DT practical/JJ timeframe/NN $/$ T$/CD ./.
We/PRP show/VBP that/IN ,/, if/IN we/PRP know/VBP the/DT true/JJ system/NN can/MD be/VB represented/VBN as/IN a/DT \/SYM emph/NN {/-LRB- factored/VBD }/-RRB- MDP/NNP ,/, we/PRP can/MD obtain/VB regret/NN bounds/NNS which/WDT scale/VBP polynomially/RB in/IN the/DT number/NN of/IN \/SYM emph/NN {/-LRB- parameters/NNS }/-RRB- of/IN the/DT MDP/NNP ,/, which/WDT may/MD be/VB exponentially/RB smaller/JJR than/IN $/$ S$/CD or/CC $/$ A$/$ ./.
Assuming/VBG an/DT algorithm/NN for/IN approximate/JJ planning/NN and/CC knowledge/NN of/IN the/DT graphical/JJ structure/NN of/IN the/DT underlying/VBG MDP/NNP ,/, we/PRP demonstrate/VBP that/IN posterior/JJ sampling/NN reinforcement/NN learning/NN (/-LRB- PSRL/NNP )/-RRB- and/CC an/DT algorithm/NN based/VBN upon/IN optimism/NN in/IN the/DT face/NN of/IN uncertainty/NN (/-LRB- UCRL/NN -/HYPH Factored/VBN )/-RRB- both/CC satisfy/VBP near/IN -/HYPH optimal/JJ regret/NN bounds/NNS ./.
