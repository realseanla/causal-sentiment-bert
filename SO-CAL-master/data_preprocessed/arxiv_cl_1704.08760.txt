We/PRP present/VBP an/DT approach/NN to/TO rapidly/RB and/CC easily/RB build/VB natural/JJ language/NN interfaces/VBZ to/IN databases/NNS for/IN new/JJ domains/NNS ,/, whose/WP$ performance/NN improves/VBZ over/IN time/NN based/VBN on/IN user/NN feedback/NN ,/, and/CC requires/VBZ minimal/JJ intervention/NN ./.
To/TO achieve/VB this/DT ,/, we/PRP adapt/VBP neural/JJ sequence/NN models/NNS to/TO map/VB utterances/NNS directly/RB to/IN SQL/NN with/IN its/PRP$ full/JJ expressivity/NN ,/, bypassing/VBG any/DT intermediate/JJ meaning/NN representations/NNS ./.
These/DT models/NNS are/VBP immediately/RB deployed/VBN online/RB to/TO solicit/VB feedback/NN from/IN real/JJ users/NNS to/TO flag/VB incorrect/JJ queries/NNS ./.
Finally/RB ,/, the/DT popularity/NN of/IN SQL/NN facilitates/VBZ gathering/VBG annotations/NNS for/IN incorrect/JJ predictions/NNS using/VBG the/DT crowd/NN ,/, which/WDT is/VBZ directly/RB used/VBN to/TO improve/VB our/PRP$ models/NNS ./.
This/DT complete/JJ feedback/NN loop/NN ,/, without/IN intermediate/JJ representations/NNS or/CC database/NN specific/JJ engineering/NN ,/, opens/VBZ up/RP new/JJ ways/NNS of/IN building/VBG high/JJ quality/NN semantic/JJ parsers/NNS ./.
Experiments/NNS suggest/VBP that/IN this/DT approach/NN can/MD be/VB deployed/VBN quickly/RB for/IN any/DT new/JJ target/NN domain/NN ,/, as/IN we/PRP show/VBP by/IN learning/VBG a/DT semantic/JJ parser/NN for/IN an/DT online/JJ academic/JJ database/NN from/IN scratch/NN ./.
