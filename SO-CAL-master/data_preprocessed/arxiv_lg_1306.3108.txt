Learning/VBG an/DT appropriate/JJ (/-LRB- dis/FW )/-RRB- similarity/NN function/NN from/IN the/DT available/JJ data/NNS is/VBZ a/DT central/JJ problem/NN in/IN machine/NN learning/NN ,/, since/IN the/DT success/NN of/IN many/JJ machine/NN learning/VBG algorithms/NNS critically/RB depends/VBZ on/IN the/DT choice/NN of/IN a/DT similarity/NN function/NN to/TO compare/VB examples/NNS ./.
Despite/IN many/JJ approaches/NNS for/IN similarity/NN metric/JJ learning/NN have/VBP been/VBN proposed/VBN ,/, there/EX is/VBZ little/JJ theoretical/JJ study/NN on/IN the/DT links/NNS between/IN similarity/NN metric/JJ learning/NN and/CC the/DT classification/NN performance/NN of/IN the/DT result/NN classifier/NN ./.
In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT regularized/VBN similarity/NN learning/NN formulation/NN associated/VBN with/IN general/JJ matrix/NN -/HYPH norms/NNS ,/, and/CC establish/VB their/PRP$ generalization/NN bounds/NNS ./.
We/PRP show/VBP that/IN the/DT generalization/NN error/NN of/IN the/DT resulting/VBG linear/JJ separator/NN can/MD be/VB bounded/VBN by/IN the/DT derived/VBN generalization/NN bound/VBN of/IN similarity/NN learning/NN ./.
This/DT shows/VBZ that/IN a/DT good/JJ generalization/NN of/IN the/DT learnt/VBN similarity/NN function/NN guarantees/VBZ a/DT good/JJ classification/NN of/IN the/DT resulting/VBG linear/JJ classifier/NN ./.
Our/PRP$ results/NNS extend/VBP and/CC improve/VBP those/DT obtained/VBN by/IN Bellet/NNP at/IN al./FW ./.
Due/IN to/IN the/DT techniques/NNS dependent/JJ on/IN the/DT notion/NN of/IN uniform/JJ stability/NN ,/, the/DT bound/JJ obtained/VBN there/RB holds/VBZ true/JJ only/RB for/IN the/DT Frobenius/NNP matrix/NN -/HYPH norm/NN regularization/NN ,/, which/WDT has/VBZ a/DT strong/JJ dependence/NN on/IN the/DT dimensionality/NN of/IN the/DT input/NN space/NN ./.
Our/PRP$ techniques/NNS using/VBG the/DT Rademacher/NNP complexity/NN and/CC its/PRP$ related/JJ Khinchin/NN -/HYPH type/NN inequality/NN ,/, in/IN the/DT cases/NNS of/IN sparse/JJ $/NN L/NN ^/SYM 1/CD $/$ -/HYPH norm/NN and/CC mixed/JJ $/$ (/-LRB- 2,1/CD )/-RRB- $/$ -/HYPH norm/NN regularization/NN ,/, enables/VBZ us/PRP to/TO obtain/VB bounds/NNS that/WDT have/VBP a/DT mild/JJ dependence/NN on/IN the/DT input/NN dimensionality/NN ./.
