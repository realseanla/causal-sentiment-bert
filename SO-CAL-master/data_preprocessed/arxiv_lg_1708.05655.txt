In/IN this/DT paper/NN ,/, we/PRP propose/VBP a/DT new/JJ multi-objective/JJ contextual/JJ multi-armed/JJ bandit/NN problem/NN with/IN two/CD objectives/NNS ,/, where/WRB one/CD of/IN the/DT objectives/NNS dominates/VBZ the/DT other/JJ objective/NN ./.
Unlike/IN single/JJ -/HYPH objective/JJ bandit/NN problems/NNS in/IN which/WDT the/DT learner/NN obtains/VBZ a/DT random/JJ scalar/JJ reward/NN for/IN each/DT arm/NN it/PRP selects/VBZ ,/, in/IN the/DT proposed/VBN problem/NN ,/, the/DT learner/NN obtains/VBZ a/DT random/JJ reward/NN vector/NN ,/, where/WRB each/DT component/NN of/IN the/DT reward/NN vector/NN corresponds/VBZ to/IN one/CD of/IN the/DT objectives/NNS and/CC the/DT distribution/NN of/IN the/DT reward/NN depends/VBZ on/IN the/DT context/NN that/WDT is/VBZ provided/VBN to/IN the/DT learner/NN at/IN the/DT beginning/NN of/IN each/DT round/NN ./.
We/PRP call/VBP this/DT problem/NN contextual/JJ multi-armed/JJ bandit/NN with/IN a/DT dominant/JJ objective/NN (/-LRB- CMAB/NN -/HYPH DO/VB )/-RRB- ./.
In/IN CMAB/NN -/HYPH DO/VB ,/, the/DT goal/NN of/IN the/DT learner/NN is/VBZ to/TO maximize/VB its/PRP$ total/JJ reward/NN in/IN the/DT non-dominant/JJ objective/NN while/IN ensuring/VBG that/IN it/PRP maximizes/VBZ its/PRP$ total/JJ reward/NN in/IN the/DT dominant/JJ objective/NN ./.
In/IN this/DT case/NN ,/, the/DT optimal/JJ arm/NN given/VBN a/DT context/NN is/VBZ the/DT one/NN that/WDT maximizes/VBZ the/DT expected/VBN reward/NN in/IN the/DT non-dominant/JJ objective/NN among/IN all/DT arms/NNS that/WDT maximize/VBP the/DT expected/VBN reward/NN in/IN the/DT dominant/JJ objective/NN ./.
First/RB ,/, we/PRP show/VBP that/IN the/DT optimal/JJ arm/NN lies/VBZ in/IN the/DT Pareto/NNP front/NN ./.
Then/RB ,/, we/PRP propose/VBP the/DT multi-objective/JJ contextual/JJ multi-armed/JJ bandit/NN algorithm/NN (/-LRB- MOC/NN -/HYPH MAB/NN )/-RRB- ,/, and/CC define/VB two/CD performance/NN measures/NNS :/: the/DT 2/CD -/HYPH dimensional/JJ (/-LRB- 2D/NN )/-RRB- regret/NN and/CC the/DT Pareto/NNP regret/NN ./.
We/PRP show/VBP that/IN both/CC the/DT 2D/NN regret/NN and/CC the/DT Pareto/NNP regret/NN of/IN MOC/NN -/HYPH MAB/NN are/VBP sublinear/NN in/IN the/DT number/NN of/IN rounds/NNS ./.
We/PRP also/RB compare/VBP the/DT performance/NN of/IN the/DT proposed/VBN algorithm/NN with/IN other/JJ state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN methods/NNS in/IN synthetic/JJ and/CC real/JJ -/HYPH world/NN datasets/NNS ./.
The/DT proposed/VBN model/NN and/CC the/DT algorithm/NN have/VBP a/DT wide/JJ range/NN of/IN real/JJ -/HYPH world/NN applications/NNS that/WDT involve/VBP multiple/JJ and/CC possibly/RB conflicting/VBG objectives/NNS ranging/VBG from/IN wireless/JJ communication/NN to/IN medical/JJ diagnosis/NN and/CC recommender/NN systems/NNS ./.
