We/PRP propose/VBP a/DT new/JJ learning/NN method/NN for/IN heterogeneous/JJ domain/NN adaptation/NN (/-LRB- HDA/NN )/-RRB- ,/, in/IN which/WDT the/DT data/NNS from/IN the/DT source/NN domain/NN and/CC the/DT target/NN domain/NN are/VBP represented/VBN by/IN heterogeneous/JJ features/NNS with/IN different/JJ dimensions/NNS ./.
Using/VBG two/CD different/JJ projection/NN matrices/NNS ,/, we/PRP first/RB transform/VB the/DT data/NNS from/IN two/CD domains/NNS into/IN a/DT common/JJ subspace/NN in/IN order/NN to/TO measure/VB the/DT similarity/NN between/IN the/DT data/NNS from/IN two/CD domains/NNS ./.
We/PRP then/RB propose/VB two/CD new/JJ feature/NN mapping/VBG functions/NNS to/TO augment/VB the/DT transformed/VBN data/NNS with/IN their/PRP$ original/JJ features/NNS and/CC zeros/NNS ./.
The/DT existing/VBG learning/NN methods/NNS (/-LRB- e.g./FW ,/, SVM/NN and/CC SVR/NN )/-RRB- can/MD be/VB readily/RB incorporated/VBN with/IN our/PRP$ newly/RB proposed/VBN augmented/VBN feature/NN representations/NNS to/TO effectively/RB utilize/VB the/DT data/NNS from/IN both/DT domains/NNS for/IN HDA/NNP ./.
Using/VBG the/DT hinge/NN loss/NN function/NN in/IN SVM/NNP as/IN an/DT example/NN ,/, we/PRP introduce/VBP the/DT detailed/JJ objective/NN function/NN in/IN our/PRP$ method/NN called/VBN Heterogeneous/NNP Feature/NN Augmentation/NN (/-LRB- HFA/NN )/-RRB- for/IN a/DT linear/JJ case/NN and/CC also/RB describe/VB its/PRP$ kernelization/NN in/IN order/NN to/TO efficiently/RB cope/VB with/IN the/DT data/NNS with/IN very/RB high/JJ dimensions/NNS ./.
Moreover/RB ,/, we/PRP also/RB develop/VBP an/DT alternating/VBG optimization/NN algorithm/NN to/IN effectively/RB solve/VB the/DT nontrivial/JJ optimization/NN problem/NN in/IN our/PRP$ HFA/NN method/NN ./.
Comprehensive/JJ experiments/NNS on/IN two/CD benchmark/NN datasets/NNS clearly/RB demonstrate/VBP that/IN HFA/NN outperforms/VBZ the/DT existing/VBG HDA/NN methods/NNS ./.
