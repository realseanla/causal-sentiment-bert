Many/JJ real/JJ -/HYPH world/NN tasks/NNS involve/VBP multiple/JJ agents/NNS with/IN partial/JJ observability/NN and/CC limited/JJ communication/NN ./.
Learning/NN is/VBZ challenging/VBG in/IN these/DT settings/NNS due/IN to/IN local/JJ viewpoints/NNS of/IN agents/NNS ,/, which/WDT perceive/VBP the/DT world/NN as/IN non-stationary/JJ due/JJ to/IN concurrently/RB -/HYPH exploring/VBG teammates/NNS ./.
Approaches/NNS that/WDT learn/VBP specialized/JJ policies/NNS for/IN individual/JJ tasks/NNS face/VBP major/JJ problems/NNS when/WRB applied/VBN to/IN the/DT real/JJ world/NN :/: not/RB only/RB do/VBP agents/NNS have/VBP to/TO learn/VB and/CC store/VB a/DT distinct/JJ policy/NN for/IN each/DT task/NN ,/, but/CC in/IN practice/NN the/DT identity/NN of/IN the/DT task/NN is/VBZ often/RB non-observable/JJ ,/, making/VBG these/DT algorithms/NNS inapplicable/JJ ./.
This/DT paper/NN formalizes/VBZ and/CC addresses/VBZ the/DT problem/NN of/IN multi-task/VB multi-agent/JJ reinforcement/NN learning/VBG under/IN partial/JJ observability/NN ./.
We/PRP introduce/VBP a/DT decentralized/JJ single/JJ -/HYPH task/NN learning/NN approach/NN that/WDT is/VBZ robust/JJ to/IN concurrent/JJ interactions/NNS of/IN teammates/NNS ,/, and/CC present/VB an/DT approach/NN for/IN distilling/VBG single/JJ -/HYPH task/NN policies/NNS into/IN a/DT unified/JJ policy/NN that/WDT performs/VBZ well/RB across/IN multiple/JJ related/JJ tasks/NNS ,/, without/IN explicit/JJ provision/NN of/IN task/NN identity/NN ./.
