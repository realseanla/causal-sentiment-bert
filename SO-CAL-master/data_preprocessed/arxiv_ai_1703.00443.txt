This/DT paper/NN presents/VBZ OptNet/NNP ,/, a/DT network/NN architecture/NN that/WDT integrates/VBZ optimization/NN problems/NNS (/-LRB- here/RB ,/, specifically/RB in/IN the/DT form/NN of/IN quadratic/JJ programs/NNS )/-RRB- as/IN individual/JJ layers/NNS in/IN larger/JJR end/NN -/HYPH to/IN -/HYPH end/NN trainable/JJ deep/JJ networks/NNS ./.
These/DT layers/NNS allow/VBP complex/JJ dependencies/NNS between/IN the/DT hidden/JJ states/NNS to/TO be/VB captured/VBN that/IN traditional/JJ convolutional/JJ and/CC fully/RB -/HYPH connected/VBN layers/NNS are/VBP not/RB able/JJ to/TO capture/VB ./.
In/IN this/DT paper/NN ,/, we/PRP develop/VBP the/DT foundations/NNS for/IN such/PDT an/DT architecture/NN :/: we/PRP derive/VBP the/DT equations/NNS to/TO perform/VB exact/JJ differentiation/NN through/IN these/DT layers/NNS and/CC with/IN respect/NN to/IN layer/NN parameters/NNS ;/: we/PRP develop/VBP a/DT highly/RB efficient/JJ solver/NN for/IN these/DT layers/NNS that/WDT exploits/NNS fast/VBP GPU/NNP -/HYPH based/VBN batch/NN solves/VBZ within/IN a/DT primal/JJ -/HYPH dual/JJ interior/NN point/NN method/NN ,/, and/CC which/WDT provides/VBZ backpropagation/NN gradients/NNS with/IN virtually/RB no/DT additional/JJ cost/NN on/IN top/NN of/IN the/DT solve/VB ;/: and/CC we/PRP highlight/VBP the/DT application/NN of/IN these/DT approaches/NNS in/IN several/JJ problems/NNS ./.
In/IN one/CD particularly/RB standout/NN example/NN ,/, we/PRP show/VBP that/IN the/DT method/NN is/VBZ capable/JJ of/IN learning/VBG to/TO play/VB Sudoku/NNP given/VBN just/RB input/NN and/CC output/NN games/NNS ,/, with/IN no/DT a/FW priori/FW information/NN about/IN the/DT rules/NNS of/IN the/DT game/NN ;/: this/DT task/NN is/VBZ virtually/RB impossible/JJ for/IN other/JJ neural/JJ network/NN architectures/NNS that/WDT we/PRP have/VBP experimented/VBN with/IN ,/, and/CC highlights/VBZ the/DT representation/NN capabilities/NNS of/IN our/PRP$ approach/NN ./.
