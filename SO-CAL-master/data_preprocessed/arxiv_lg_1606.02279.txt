We/PRP propose/VBP a/DT novel/JJ semi-supervised/VBN structured/VBN out/IN -/HYPH put/VBN prediction/NN method/NN based/VBN on/IN local/JJ linear/JJ regression/NN in/IN this/DT paper/NN ./.
The/DT existing/VBG semi-supervise/JJ structured/JJ output/NN prediction/NN methods/NNS learn/VBP a/DT global/JJ predictor/NN for/IN all/PDT the/DT data/NNS points/NNS in/IN a/DT data/NN set/NN ,/, which/WDT ignores/VBZ the/DT differences/NNS of/IN local/JJ distributions/NNS of/IN the/DT data/NNS set/NN ,/, and/CC the/DT effects/NNS to/IN the/DT structured/JJ output/NN prediction/NN ./.
To/TO solve/VB this/DT problem/NN ,/, we/PRP propose/VBP to/TO learn/VB the/DT missing/VBG structured/JJ outputs/NNS and/CC local/JJ predictors/NNS for/IN neighborhoods/NNS of/IN different/JJ data/NNS points/NNS jointly/RB ./.
Using/VBG the/DT local/JJ linear/JJ regression/NN strategy/NN ,/, in/IN the/DT neighborhood/NN of/IN each/DT data/NN point/NN ,/, we/PRP propose/VBP to/TO learn/VB a/DT local/JJ linear/JJ predictor/NN by/IN minimizing/VBG both/CC the/DT complexity/NN of/IN the/DT predictor/NN and/CC the/DT upper/JJ bound/VBN of/IN the/DT structured/JJ prediction/NN loss/NN ./.
The/DT minimization/NN problem/NN is/VBZ solved/VBN by/IN sub-gradient/JJ descent/NN algorithms/NNS ./.
We/PRP conduct/VBP experiments/NNS over/IN two/CD benchmark/NN data/NNS sets/NNS ,/, and/CC the/DT results/NNS show/VBP the/DT advantages/NNS of/IN the/DT proposed/JJ method/NN ./.
