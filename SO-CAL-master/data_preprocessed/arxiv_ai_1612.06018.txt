When/WRB an/DT agent/NN can/MD not/RB represent/VB a/DT perfectly/RB accurate/JJ model/NN of/IN its/PRP$ environment/NN 's/POS dynamics/NNS ,/, model/NN -/HYPH based/VBN reinforcement/NN learning/NN (/-LRB- MBRL/NN )/-RRB- can/MD fail/VB catastrophically/RB ./.
Planning/NN involves/VBZ composing/VBG the/DT predictions/NNS of/IN the/DT model/NN ;/: when/WRB flawed/JJ predictions/NNS are/VBP composed/VBN ,/, even/RB minor/JJ errors/NNS can/MD compound/VB and/CC render/VB the/DT model/NN useless/JJ for/IN planning/NN ./.
Hallucinated/NNP Replay/NNP (/-LRB- Talvitie/NNP 2014/CD )/-RRB- trains/VBZ the/DT model/NN to/TO "/`` correct/VB "/'' itself/PRP when/WRB it/PRP produces/VBZ errors/NNS ,/, substantially/RB improving/VBG MBRL/NN with/IN flawed/JJ models/NNS ./.
This/DT paper/NN theoretically/RB analyzes/VBZ this/DT approach/NN ,/, illuminates/VBZ settings/NNS in/IN which/WDT it/PRP is/VBZ likely/JJ to/TO be/VB effective/JJ or/CC ineffective/JJ ,/, and/CC presents/VBZ a/DT novel/JJ error/NN bound/VBN ,/, showing/VBG that/IN a/DT model/NN 's/POS ability/NN to/TO self/NN -/HYPH correct/JJ is/VBZ more/RBR tightly/RB related/VBN to/IN MBRL/NNP performance/NN than/IN one/CD -/HYPH step/NN prediction/NN error/NN ./.
These/DT results/NNS inspire/VBP an/DT MBRL/NN algorithm/NN for/IN deterministic/JJ MDPs/NNS with/IN performance/NN guarantees/NNS that/WDT are/VBP robust/JJ to/IN model/NN class/NN limitations/NNS ./.
