This/DT paper/NN addresses/VBZ the/DT problem/NN of/IN active/JJ learning/NN of/IN a/DT multi-output/NN Gaussian/JJ process/NN (/-LRB- MOGP/NN )/-RRB- model/NN representing/VBG multiple/JJ types/NNS of/IN coexisting/VBG correlated/VBN environmental/JJ phenomena/NN ./.
In/IN contrast/NN to/IN existing/VBG works/NNS ,/, our/PRP$ active/JJ learning/NN problem/NN involves/VBZ selecting/VBG not/RB just/RB the/DT most/RBS informative/JJ sampling/NN locations/NNS to/TO be/VB observed/VBN but/CC also/RB the/DT types/NNS of/IN measurements/NNS at/IN each/DT selected/VBN location/NN for/IN minimizing/VBG the/DT predictive/JJ uncertainty/NN (/-LRB- i.e./FW ,/, posterior/JJ joint/JJ entropy/NN )/-RRB- of/IN a/DT target/NN phenomenon/NN of/IN interest/NN given/VBN a/DT sampling/NN budget/NN ./.
Unfortunately/RB ,/, such/PDT an/DT entropy/NN criterion/NN scales/NNS poorly/RB in/IN the/DT numbers/NNS of/IN candidate/NN sampling/NN locations/NNS and/CC selected/VBN observations/NNS when/WRB optimized/VBN ./.
To/TO resolve/VB this/DT issue/NN ,/, we/PRP first/RB exploit/VB a/DT structure/NN common/JJ to/IN sparse/JJ MOGP/NN models/NNS for/IN deriving/VBG a/DT novel/JJ active/JJ learning/NN criterion/NN ./.
Then/RB ,/, we/PRP exploit/VBP a/DT relaxed/JJ form/NN of/IN submodularity/NN property/NN of/IN our/PRP$ new/JJ criterion/NN for/IN devising/VBG a/DT polynomial/JJ -/HYPH time/NN approximation/NN algorithm/NN that/WDT guarantees/VBZ a/DT constant/JJ -/HYPH factor/NN approximation/NN of/IN that/DT achieved/VBN by/IN the/DT optimal/JJ set/NN of/IN selected/VBN observations/NNS ./.
Empirical/JJ evaluation/NN on/IN real/JJ -/HYPH world/NN datasets/NNS shows/VBZ that/IN our/PRP$ proposed/VBN approach/NN outperforms/VBZ existing/VBG algorithms/NNS for/IN active/JJ learning/NN of/IN MOGP/NN and/CC single/JJ -/HYPH output/NN GP/NNP models/NNS ./.
