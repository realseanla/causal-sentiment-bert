We/PRP propose/VBP a/DT new/JJ method/NN for/IN training/NN computationally/RB efficient/JJ and/CC compact/JJ convolutional/JJ neural/JJ networks/NNS (/-LRB- CNNs/NNS )/-RRB- using/VBG a/DT novel/JJ sparse/JJ connection/NN structure/NN that/WDT resembles/VBZ a/DT tree/NN root/NN ./.
Our/PRP$ sparse/JJ connection/NN structure/NN facilitates/VBZ a/DT significant/JJ reduction/NN in/IN computational/JJ cost/NN and/CC number/NN of/IN parameters/NNS of/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN deep/JJ CNNs/NNPS without/IN compromising/VBG accuracy/NN ./.
We/PRP validate/VBP our/PRP$ approach/NN by/IN using/VBG it/PRP to/TO train/VB more/RBR efficient/JJ variants/NNS of/IN state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN CNN/NNP architectures/NNS ,/, evaluated/VBN on/IN the/DT CIFAR10/NN and/CC ILSVRC/NN datasets/NNS ./.
Our/PRP$ results/NNS show/VBP similar/JJ or/CC higher/JJR accuracy/NN than/IN the/DT baseline/NN architectures/NNS with/IN much/RB less/RBR compute/VB ,/, as/IN measured/VBN by/IN CPU/NN and/CC GPU/NN timings/NNS ./.
For/IN example/NN ,/, for/IN ResNet/NNP 50/CD ,/, our/PRP$ model/NN has/VBZ 40/CD percent/NN fewer/JJR parameters/NNS ,/, 45/CD percent/NN fewer/JJR floating/VBG point/NN operations/NNS ,/, and/CC is/VBZ 31/CD percent/NN (/-LRB- 12/CD percent/NN )/-RRB- faster/RBR on/IN a/DT CPU/NN (/-LRB- GPU/NN )/-RRB- ./.
For/IN the/DT deeper/JJR ResNet/NNP 200/CD our/PRP$ model/NN has/VBZ 25/CD percent/NN fewer/JJR floating/VBG point/NN operations/NNS and/CC 44/CD percent/NN fewer/JJR parameters/NNS ,/, while/IN maintaining/VBG state/NN -/HYPH of/IN -/HYPH the/DT -/HYPH art/NN accuracy/NN ./.
For/IN GoogLeNet/NNP ,/, our/PRP$ model/NN has/VBZ 7/CD percent/NN fewer/JJR parameters/NNS and/CC is/VBZ 21/CD percent/NN (/-LRB- 16/CD percent/NN )/-RRB- faster/RBR on/IN a/DT CPU/NN (/-LRB- GPU/NN )/-RRB- ./.
