Reinforcement/NN learning/NN (/-LRB- RL/NN )/-RRB- is/VBZ a/DT general/JJ and/CC well/RB -/HYPH known/JJ method/NN that/WDT a/DT robot/NN can/MD use/VB to/TO learn/VB an/DT optimal/JJ control/NN policy/NN to/TO solve/VB a/DT particular/JJ task/NN ./.
We/PRP would/MD like/VB to/TO build/VB a/DT versatile/JJ robot/NN that/WDT can/MD learn/VB multiple/JJ tasks/NNS ,/, but/CC using/VBG RL/NN for/IN each/DT of/IN them/PRP would/MD be/VB prohibitively/RB expensive/JJ in/IN terms/NNS of/IN both/DT time/NN and/CC wear/VB -/HYPH and/CC -/HYPH tear/NN on/IN the/DT robot/NN ./.
To/TO remedy/VB this/DT problem/NN ,/, we/PRP use/VBP the/DT Policy/NN Gradient/NN Efficient/JJ Lifelong/JJ Learning/NN Algorithm/NN (/-LRB- PG/NN -/HYPH ELLA/NN )/-RRB- ,/, an/DT online/NN multi-task/VB RL/NN algorithm/NN that/WDT enables/VBZ the/DT robot/NN to/TO efficiently/RB learn/VB multiple/JJ consecutive/JJ tasks/NNS by/IN sharing/VBG knowledge/NN between/IN these/DT tasks/NNS to/TO accelerate/VB learning/NN and/CC improve/VB performance/NN ./.
We/PRP implemented/VBD and/CC evaluated/VBD three/CD RL/NN methods/NNS --/: Q/NN -/HYPH learning/NN ,/, policy/NN gradient/NN RL/NN ,/, and/CC PG/NN -/HYPH ELLA/NN --/: on/IN a/DT ground/NN robot/NN whose/WP$ task/NN is/VBZ to/TO find/VB a/DT target/NN object/NN in/IN an/DT environment/NN under/IN different/JJ surface/NN conditions/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP discuss/VBP our/PRP$ implementations/NNS as/RB well/RB as/IN present/JJ an/DT empirical/JJ analysis/NN of/IN their/PRP$ learning/NN performance/NN ./.
