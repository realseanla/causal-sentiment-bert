Recent/JJ progress/NN in/IN randomized/JJ motion/NN planners/NNS has/VBZ led/VBN to/IN the/DT development/NN of/IN a/DT new/JJ class/NN of/IN sampling/NN -/HYPH based/VBN algorithms/NNS that/WDT provide/VBP asymptotic/JJ optimality/NN guarantees/NNS ,/, notably/RB the/DT RRT/NNP */NFP and/CC the/DT PRM/NNP */NFP algorithms/NNS ./.
Careful/JJ analysis/NN reveals/VBZ that/IN the/DT so/RB -/HYPH called/VBN "/`` rewiring/VBG "/'' step/NN in/IN these/DT algorithms/NNS can/MD be/VB interpreted/VBN as/IN a/DT local/JJ policy/NN iteration/NN (/-LRB- PI/NN )/-RRB- step/NN (/-LRB- i.e./FW ,/, a/DT local/JJ policy/NN evaluation/NN step/NN followed/VBN by/IN a/DT local/JJ policy/NN improvement/NN step/NN )/-RRB- so/IN that/IN asymptotically/RB ,/, as/IN the/DT number/NN of/IN samples/NNS tend/VBP to/TO infinity/NN ,/, both/CC algorithms/NNS converge/VBP to/IN the/DT optimal/JJ path/NN almost/RB surely/RB (/-LRB- with/IN probability/NN 1/CD )/-RRB- ./.
Policy/NN iteration/NN ,/, along/IN with/IN value/NN iteration/NN (/-LRB- VI/NN )/-RRB- are/VBP common/JJ methods/NNS for/IN solving/VBG dynamic/JJ programming/NN (/-LRB- DP/NN )/-RRB- problems/NNS ./.
Based/VBN on/IN this/DT observation/NN ,/, recently/RB ,/, the/DT RRT$/NNP ^/SYM {/-LRB- \/SYM #/NN }/-RRB- $/$ algorithm/NN has/VBZ been/VBN proposed/VBN ,/, which/WDT performs/VBZ ,/, during/IN each/DT iteration/NN ,/, Bellman/NNP updates/NNS (/-LRB- aka/RB "/`` backups/NNS "/'' )/-RRB- on/IN those/DT vertices/NNS of/IN the/DT graph/NN that/WDT have/VBP the/DT potential/NN of/IN being/VBG part/NN of/IN the/DT optimal/JJ path/NN (/-LRB- i.e./FW ,/, the/DT "/`` promising/JJ "/'' vertices/NNS )/-RRB- ./.
The/DT RRT$/NNP ^/SYM {/-LRB- \/SYM #/NN }/-RRB- $/$ algorithm/NN thus/RB utilizes/VBZ dynamic/JJ programming/NN ideas/NNS and/CC implements/VBZ them/PRP incrementally/RB on/IN randomly/RB generated/VBN graphs/NNS to/TO obtain/VB high/JJ quality/NN solutions/NNS ./.
In/IN this/DT work/NN ,/, and/CC based/VBN on/IN this/DT key/JJ insight/NN ,/, we/PRP explore/VBP a/DT different/JJ class/NN of/IN dynamic/JJ programming/NN algorithms/NNS for/IN solving/VBG shortest/JJS -/HYPH path/NN problems/NNS on/IN random/JJ graphs/NNS generated/VBN by/IN iterative/JJ sampling/NN methods/NNS ./.
These/DT class/NN of/IN algorithms/NNS utilize/VBP policy/NN iteration/NN instead/RB of/IN value/NN iteration/NN ,/, and/CC thus/RB are/VBP better/RBR suited/JJ for/IN massive/JJ parallelization/NN ./.
Contrary/JJ to/IN the/DT RRT/NNP */NFP algorithm/NN ,/, the/DT policy/NN improvement/NN during/IN the/DT rewiring/VBG step/NN is/VBZ not/RB performed/VBN only/RB locally/RB but/CC rather/RB on/IN a/DT set/NN of/IN vertices/NNS that/WDT are/VBP classified/VBN as/IN "/`` promising/VBG "/'' during/IN the/DT current/JJ iteration/NN ./.
This/DT tends/VBZ to/TO speed/VB -/HYPH up/RP the/DT whole/JJ process/NN ./.
The/DT resulting/VBG algorithm/NN ,/, aptly/RB named/VBN Policy/NNP Iteration/NNP -/HYPH RRT$/NNP ^/SYM {/-LRB- \/SYM #/NN }/-RRB- $/$ (/-LRB- PI/NN -/HYPH RRT$/NN ^/SYM {/-LRB- \/SYM #/NN }/-RRB- $/$ )/-RRB- is/VBZ the/DT first/JJ of/IN a/DT new/JJ class/NN of/IN DP/NN -/HYPH inspired/VBN algorithms/NNS for/IN randomized/JJ motion/NN planning/NN that/WDT utilize/VBP PI/NN methods/NNS ./.
