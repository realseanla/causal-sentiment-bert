Poker/NNP is/VBZ a/DT family/NN of/IN card/NN games/NNS that/WDT includes/VBZ many/JJ variations/NNS ./.
We/PRP hypothesize/VBP that/IN most/JJS poker/NN games/NNS can/MD be/VB solved/VBN as/IN a/DT pattern/NN matching/VBG problem/NN ,/, and/CC propose/VB creating/VBG a/DT strong/JJ poker/NN playing/VBG system/NN based/VBN on/IN a/DT unified/JJ poker/NN representation/NN ./.
Our/PRP$ poker/NN player/NN learns/VBZ through/IN iterative/JJ self/NN -/HYPH play/NN ,/, and/CC improves/VBZ its/PRP$ understanding/NN of/IN the/DT game/NN by/IN training/VBG on/IN the/DT results/NNS of/IN its/PRP$ previous/JJ actions/NNS without/IN sophisticated/JJ domain/NN knowledge/NN ./.
We/PRP evaluate/VBP our/PRP$ system/NN on/IN three/CD poker/NN games/NNS :/: single/JJ player/NN video/NN poker/NN ,/, two/CD -/HYPH player/NN Limit/NNP Texas/NNP Hold/VB 'em/PRP ,/, and/CC finally/RB two/CD -/HYPH player/NN 2/CD -/HYPH 7/CD triple/JJ draw/NN poker/NN ./.
We/PRP show/VBP that/IN our/PRP$ model/NN can/MD quickly/RB learn/VB patterns/NNS in/IN these/DT very/RB different/JJ poker/NN games/NNS while/IN it/PRP improves/VBZ from/IN zero/CD knowledge/NN to/IN a/DT competitive/JJ player/NN against/IN human/JJ experts/NNS ./.
