This/DT work/NN builds/VBZ upon/IN previous/JJ efforts/NNS in/IN online/JJ incremental/JJ learning/NN ,/, namely/RB the/DT Incremental/NNP Gaussian/NNP Mixture/NNP Network/NNP (/-LRB- IGMN/NNP )/-RRB- ./.
The/DT IGMN/NNP is/VBZ capable/JJ of/IN learning/VBG from/IN data/NNS streams/NNS in/IN a/DT single/JJ -/HYPH pass/NN by/IN improving/VBG its/PRP$ model/NN after/IN analyzing/VBG each/DT data/NN point/NN and/CC discarding/VBG it/PRP thereafter/RB ./.
Nevertheless/RB ,/, it/PRP suffers/VBZ from/IN the/DT scalability/NN point/NN -/HYPH of/IN -/HYPH view/NN ,/, due/IN to/IN its/PRP$ asymptotic/JJ time/NN complexity/NN of/IN $/$ \/CD operatorname/NN {/-LRB- O/NN }/-RRB- \/SYM bigl/NN (/-LRB- NKD/NN ^/SYM 3/CD \/SYM bigr/NN )/-RRB- $/$ for/IN $/$ N$/CD data/NNS points/NNS ,/, $/$ K$/CD Gaussian/JJ components/NNS and/CC $/$ D$/CD dimensions/NNS ,/, rendering/VBG it/PRP inadequate/JJ for/IN high/JJ -/HYPH dimensional/JJ data/NNS ./.
In/IN this/DT paper/NN ,/, we/PRP manage/VBP to/TO reduce/VB this/DT complexity/NN to/IN $/$ \/CD operatorname/NN {/-LRB- O/NN }/-RRB- \/SYM bigl/NN (/-LRB- NKD/NN ^/SYM 2/CD \/SYM bigr/NN )/-RRB- $/$ by/IN deriving/VBG formulas/NNS for/IN working/VBG directly/RB with/IN precision/NN matrices/NNS instead/RB of/IN covariance/NN matrices/NNS ./.
The/DT final/JJ result/NN is/VBZ a/DT much/JJ faster/RBR and/CC scalable/JJ algorithm/NN which/WDT can/MD be/VB applied/VBN to/IN high/JJ dimensional/JJ tasks/NNS ./.
This/DT is/VBZ confirmed/VBN by/IN applying/VBG the/DT modified/VBN algorithm/NN to/IN high/JJ -/HYPH dimensional/JJ classification/NN datasets/NNS ./.
