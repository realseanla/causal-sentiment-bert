There/EX is/VBZ an/DT obvious/JJ need/NN for/IN improving/VBG the/DT performance/NN and/CC accuracy/NN of/IN a/DT Bayesian/JJ network/NN as/IN new/JJ data/NNS is/VBZ observed/VBN ./.
Because/IN of/IN errors/NNS in/IN model/NN construction/NN and/CC changes/NNS in/IN the/DT dynamics/NNS of/IN the/DT domains/NNS ,/, we/PRP can/MD not/RB afford/VB to/TO ignore/VB the/DT information/NN in/IN new/JJ data/NNS ./.
While/IN sequential/JJ update/NN of/IN parameters/NNS for/IN a/DT fixed/JJ structure/NN can/MD be/VB accomplished/VBN using/VBG standard/JJ techniques/NNS ,/, sequential/JJ update/NN of/IN network/NN structure/NN is/VBZ still/RB an/DT open/JJ problem/NN ./.
In/IN this/DT paper/NN ,/, we/PRP investigate/VBP sequential/JJ update/NN of/IN Bayesian/JJ networks/NNS were/VBD both/DT parameters/NNS and/CC structure/NN are/VBP expected/VBN to/TO change/VB ./.
We/PRP introduce/VBP a/DT new/JJ approach/NN that/WDT allows/VBZ for/IN the/DT flexible/JJ manipulation/NN of/IN the/DT tradeoff/NN between/IN the/DT quality/NN of/IN the/DT learned/VBN networks/NNS and/CC the/DT amount/NN of/IN information/NN that/WDT is/VBZ maintained/VBN about/IN past/JJ observations/NNS ./.
We/PRP formally/RB describe/VBP our/PRP$ approach/NN including/VBG the/DT necessary/JJ modifications/NNS to/IN the/DT scoring/NN functions/VBZ for/IN learning/VBG Bayesian/JJ networks/NNS ,/, evaluate/VB its/PRP$ effectiveness/NN through/IN an/DT empirical/JJ study/NN ,/, and/CC extend/VB it/PRP to/IN the/DT case/NN of/IN missing/VBG data/NNS ./.
