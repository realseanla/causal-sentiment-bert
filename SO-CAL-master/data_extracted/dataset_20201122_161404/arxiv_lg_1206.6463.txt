Local Linear embedding (LLE) is a popular dimension reduction method.
In this paper, we first show LLE with nonnegative constraint is equivalent to the widely used Laplacian embedding.
We further propose to iterate the two steps in LLE repeatedly to improve the results.
Thirdly, we relax the kNN constraint of LLE and present a sparse similarity learning algorithm.
The final Iterative LLE combines these three improvements.
Extensive experiment results show that iterative LLE algorithm significantly improve both classification and clustering results.
