Compared with automatic speech recognition (ASR), the human auditory system is more adept at handling noise-adverse situations, including environmental noise and channel distortion.
To mimic this adeptness, auditory models have been widely incorporated in ASR systems to improve their robustness.
This paper proposes a novel auditory model which incorporates psychoacoustics and otoacoustic emissions (OAEs) into ASR.
In particular, we successfully implement the frequency-dependent property of psychoacoustic models and effectively improve resulting system performance.
We also present a novel double-transform spectrum-analysis technique, which can qualitatively predict ASR performance for different noise types.
Detailed theoretical analysis is provided to show the effectiveness of the proposed algorithm.
Experiments are carried out on the AURORA2 database and show that the word recognition rate using our proposed feature extraction method is significantly increased over the baseline.
Given models trained with clean speech, our proposed method achieves up to 85.39 percent word recognition accuracy on noisy data.
