Random Forest (RF) is a powerful supervised learner and has been popularly used in many applications such as bioinformatics.
In this work I propose a new and enhanced RF called the guided random forest (GRF) for high-dimensional classification and feature selection.
Similar to a feature selection method called guided regularized random forest (GRRF), GRF is built using the importance scores from an ordinary RF.
The trees in GRRF are built sequentially, are highly correlated (which deteriorates accuracy performance as a classifier) and do not allow for parallel computing, while the trees in GRF are built independently and can be implemented in a distributed computing framework.
Experiments on 10 high-dimensional gene data sets show that, with a fixed parameter value (without tuning the parameter), GRF outperforms RF on 8 data sets and 7 of them have significant differences at the 0.05 level.
GRF uses, on average, only tens of features in the model, while RF uses thousands of features.
Therefore, both accuracy and interpretability are significantly improved.
I also found that, as a classifier, GRF outperforms GRRF on all the data sets and 7 of them have significant differences at the 0.05 level.
The computational complexity of GRF is only about twice as much as an ordinary RF.
GRF can be used in "RRF" v1.4, a package that also includes the regularized random forest methods.
