Recently, deep learning (DL) methods have been introduced very successfully into human activity recognition (HAR) scenarios in ubiquitous and wearable computing.
Especially the prospect of overcoming the need for manual feature design combined with superior classification capabilities render deep neural networks very attractive for real-life HAR application.
Even though DL-based approaches now outperform the state-of-the-art in a number of recognitions tasks of the field, yet substantial challenges remain.
Most prominently, issues with real-life datasets, typically including imbalanced datasets and problematic data quality, still limit the effectiveness of activity recognition using wearables.
In this paper we tackle such challenges through Ensembles of deep Long Short Term Memory (LSTM) networks.
We have developed modified training procedures for LSTM networks and combine sets of diverse LSTM learners into classifier collectives.
We demonstrate, both formally and empirically, that Ensembles of deep LSTM learners outperform the individual LSTM networks.
Through an extensive experimental evaluation on three standard benchmarks (Opportunity, PAMAP2, Skoda) we demonstrate the excellent recognition capabilities of our approach and its potential for real-life applications of human activity recognition.
