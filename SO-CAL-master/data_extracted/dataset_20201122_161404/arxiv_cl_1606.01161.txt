Various treebanks have been released for dependency parsing.
Despite that treebanks may belong to different languages or have different annotation schemes, they contain syntactic knowledge that is potential to benefit each other.
This paper presents an universal framework for exploiting these multi-typed treebanks to improve parsing with deep multi-task learning.
We consider two kinds of treebanks as source: the multilingual universal treebanks and the monolingual heterogeneous treebanks.
Multiple treebanks are trained jointly and interacted with multi-level parameter sharing.
Experiments on several benchmark datasets in various languages demonstrate that our approach can make effective use of arbitrary source treebanks to improve target parsing models.
