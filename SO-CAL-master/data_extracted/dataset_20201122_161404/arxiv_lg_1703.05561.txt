Machine learning is increasingly used in security-critical applications, such as autonomous driving, face recognition and malware detection.
Most learning methods, however, have not been designed with security in mind and thus are vulnerable to different types of attacks.
This problem has motivated the research field of adversarial machine learning that is concerned with attacking and defending learning methods.
Concurrently, a different line of research has tackled a very similar problem: In digital watermarking information are embedded in a signal in the presence of an adversary.
As a consequence, this research field has also extensively studied techniques for attacking and defending watermarking methods.
