This paper presents a computationally efficient machine-learned method for natural language response suggestion.
Feed-forward neural networks using n-gram embedding features encode messages into vectors which are optimized to give message-response pairs a high dot-product value.
An optimized search finds response suggestions.
The method is evaluated in a large-scale commercial e-mail application, Inbox by Gmail.
Compared to a sequence-to-sequence approach, the new system achieves the same quality at a small fraction of the computational requirements and latency.
