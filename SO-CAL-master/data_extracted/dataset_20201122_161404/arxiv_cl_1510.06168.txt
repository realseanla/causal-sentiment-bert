Bidirectional Long Short-Term Memory Recurrent Neural Network (BLSTM-RNN) has been shown to be very effective for tagging sequential data, e.g.
speech utterances or handwritten documents.
While word embedding has been demoed as a powerful representation for characterizing the statistical properties of natural language.
In this study, we propose to use BLSTM-RNN with word embedding for part-of-speech (POS) tagging task.
When tested on Penn Treebank WSJ test set, a state-of-the-art performance of 97.40 tagging accuracy is achieved.
Without using morphological features, this approach can also achieve a good performance comparable with the Stanford POS tagger.
