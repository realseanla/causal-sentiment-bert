In this paper, we propose a novel training procedure for image captioning models based on policy gradient methods.
This allows us to directly optimize for the metrics of interest, rather than just maximizing likelihood of human generated captions.
We show that by optimizing for standard metrics such as BLEU, CIDEr, METEOR and ROUGE, we can develop a system that improve on the metrics and ranks first on the MSCOCO image captioning leader board, even though our CNN-RNN model is much simpler than state of the art models.
We further show that by also optimizing for the recently introduced SPICE metric, which measures semantic quality of captions, we can produce a system that significantly outperforms other methods as measured by human evaluation.
Finally, we show how we can leverage extra sources of information, such as pre-trained image tagging models, to further improve quality
