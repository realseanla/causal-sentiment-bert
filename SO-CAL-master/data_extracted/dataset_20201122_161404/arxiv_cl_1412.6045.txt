Distributed representations of words have boosted the performance of many Natural Language Processing tasks.
However, usually only one representation per word is obtained, not acknowledging the fact that some words have multiple meanings.
This has a negative effect on the individual word representations and the language model as a whole.
In this paper we present a simple model that enables recent techniques for building word vectors to represent distinct senses of polysemic words.
In our assessment of this model we show that it is able to effectively discriminate between words' senses and to do so in a computationally efficient manner.
