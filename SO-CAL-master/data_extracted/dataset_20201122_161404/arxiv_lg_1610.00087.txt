Learning acoustic models directly from the raw waveform data with minimal processing is challenging.
Current waveform-based models have generally used very few (~2) convolutional layers, which might be insufficient for building high-level discriminative features.
In this work, we propose very deep convolutional neural networks (CNNs) that directly use time-domain waveforms as inputs.
Our CNNs, with up to 34 weight layers, are efficient to optimize over very long sequences (e.g., vector of size 32000), necessary for processing acoustic waveforms.
This is achieved through batch normalization, residual learning, and a careful design of down-sampling in the initial layers.
Our networks are fully convolutional, without the use of fully connected layers and dropout, to maximize representation learning.
We use a large receptive field in the first convolutional layer to mimic bandpass filters, but very small receptive fields subsequently to control the model capacity.
We demonstrate the performance gains with the deeper models.
Our evaluation shows that the CNN with 18 weight layers outperform the CNN with 3 weight layers by over 15 percent in absolute accuracy for an environmental sound recognition task and matches the performance of models using log-mel features.
