Many current Internet services rely on inferences from models trained on user data.
Commonly, both the training and inference tasks are carried out using cloud resources fed by personal data collected at scale from users.
Holding and using such large collections of personal data in the cloud creates privacy risks to the data subjects, but is currently required for users to benefit from such services.
We explore how to provide for model training and inference in a system where computation is moved to the data in preference to moving data to the cloud, obviating many current privacy risks.
Specifically, we take an initial model learnt from a small set of users and retrain it locally using data from a single user.
We evaluate on two tasks: one supervised learning task, using a neural network to recognise users' current activity from accelerometer traces; and one unsupervised learning task, identifying topics in a large set of documents.
In both cases the accuracy is improved.
We also demonstrate the feasibility of our approach by presenting a performance evaluation on a representative resource-constrained device (a Raspberry Pi).
