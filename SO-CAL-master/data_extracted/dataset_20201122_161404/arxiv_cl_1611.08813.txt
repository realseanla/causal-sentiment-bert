Prepositions are very common and very ambiguous, and understanding their sense is critical for understanding the meaning of the sentence.
Supervised corpora for the preposition-sense disambiguation task are small, suggesting a semi-supervised approach to the task.
We show that signals from unannotated multilingual data can be used to improve supervised preposition-sense disambiguation.
Our approach pre-trains an LSTM encoder for predicting the translation of a preposition, and then incorporates the pre-trained encoder as a component in a supervised classification system, and fine-tunes it for the task.
The multilingual signals consistently improve results on two preposition-sense datasets.
