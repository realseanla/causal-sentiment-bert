One essential task in information extraction from the medical corpus is drug name recognition.
Compared with text sources come from other domains, the medical text is special and has unique characteristics.
In addition, the medical text mining poses more challenges, e.g., more unstructured text, the fast growing of new terms addition, a wide range of name variation for the same drug.
The mining is even more challenging due to the lack of labeled dataset sources and external knowledge, as well as multiple token representations for a single drug name that is more common in the real application setting.
Although many approaches have been proposed to overwhelm the task, some problems remained with poor F-score performance (less than 0.75).
This paper presents a new treatment in data representation techniques to overcome some of those challenges.
We propose three data representation techniques based on the characteristics of word distribution and word similarities as a result of word embedding training.
The first technique is evaluated with the standard NN model, i.e., MLP (Multi-Layer Perceptrons).
The second technique involves two deep network classifiers, i.e., DBN (Deep Belief Networks), and SAE (Stacked Denoising Encoders).
The third technique represents the sentence as a sequence that is evaluated with a recurrent NN model, i.e., LSTM (Long Short Term Memory).
In extracting the drug name entities, the third technique gives the best F-score performance compared to the state of the art, with its average F-score being 0.8645.
