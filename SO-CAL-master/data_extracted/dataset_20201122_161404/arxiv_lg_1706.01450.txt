We propose a generative machine comprehension model that learns jointly to ask and answer questions based on documents.
The proposed model uses a sequence-to-sequence framework that encodes the document and generates a question (answer) given an answer (question).
Significant improvement in model performance is observed empirically on the SQuAD corpus, confirming our hypothesis that the model benefits from jointly learning to perform both tasks.
We believe the joint model's novelty offers a new perspective on machine comprehension beyond architectural engineering, and serves as a first step towards autonomous information seeking.
