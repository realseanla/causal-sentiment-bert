We introduce T-LESS, a new public dataset for estimating the 6D pose, i.e.
translation and rotation, of texture-less rigid objects.
The dataset features thirty industry-relevant objects with no significant texture and no discriminative color or reflectance properties.
The objects exhibit symmetries and mutual similarities in shape and/or size.
Compared to other datasets, a unique property is that some of the objects are parts of others.
The dataset includes training and test images that were captured with three synchronized sensors, specifically a structured-light and a time-of-flight RGB-D sensor and a high-resolution RGB camera.
There are approximately 39K training and 10K test images from each sensor.
Additionally, two types of 3D models are provided for each object, i.e.
a manually created CAD model and a semi-automatically reconstructed one.
Training images depict individual objects against a black background.
Test images originate from twenty test scenes having varying complexity, which increases from simple scenes with several isolated objects to very challenging ones with multiple instances of several objects and with a high amount of clutter and occlusion.
The images were captured from a systematically sampled view sphere around the object/scene, and are annotated with accurate ground truth 6D poses of all modeled objects.
Initial evaluation results indicate that the state of the art in 6D object pose estimation has ample room for improvement, especially in difficult cases with significant occlusion.
The T-LESS dataset is available online at cmp.felk.cvut.cz/t-less.
