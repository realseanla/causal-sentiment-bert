Many algorithms and applications involve repeatedly solving variations of the same inference problem; for example we may want to introduce new evidence to the model or perform updates to conditional dependencies.
The goal of adaptive inference is to take advantage of what is preserved in the model and perform inference more rapidly than from scratch.
In this paper, we describe techniques for adaptive inference on general graphs that support marginal computation and updates to the conditional probabilities and dependencies in logarithmic time.
We give experimental results for an implementation of our algorithm, and demonstrate its potential performance benefit in the study of protein structure.
