In this work, we are interested in structure learning for a set of spatially distributed dynamical systems, where individual subsystems are coupled via latent variables and observed through a filter.
We represent this model as a directed acyclic graph (DAG) that characterises the unidirectional coupling between subsystems.
Standard approaches to structure learning are not applicable in this framework due to the hidden variables, however we can exploit the properties of certain dynamical systems to formulate exact methods based on state space reconstruction.
We approach the problem by using reconstruction theorems to analytically derive a tractable expression for the KL-divergence of a candidate DAG from the observed dataset.
We show this measure can be decomposed as a function of two information-theoretic measures, transfer entropy and stochastic interaction.
We then present two mathematically robust scoring functions based on transfer entropy and statistical independence tests.
These results support the previously held conjecture that transfer entropy can be used to infer effective connectivity in complex networks.
