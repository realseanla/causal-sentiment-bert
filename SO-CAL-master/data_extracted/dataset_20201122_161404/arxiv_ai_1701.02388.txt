We present a position paper advocating the notion that Stoic philosophy and ethics can inform the development of ethical A.I.
systems.
This is in sharp contrast to most work on building ethical A.I., which has focused on Utilitarian or Deontological ethical theories.
We relate ethical A.I.
to several core Stoic notions, including the dichotomy of control, the four cardinal virtues, the ideal Sage, Stoic practices, and Stoic perspectives on emotion or affect.
More generally, we put forward an ethical view of A.I.
that focuses more on internal states of the artificial agent rather than on external actions of the agent.
We provide examples relating to near-term A.I.
systems as well as hypothetical superintelligent agents.
