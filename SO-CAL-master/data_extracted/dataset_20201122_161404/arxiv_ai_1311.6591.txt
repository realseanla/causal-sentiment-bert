Lifted inference algorithms exploit symmetries in probabilistic models to speed up inference.
They show impressive performance when calculating unconditional probabilities in relational models, but often resort to non-lifted inference when computing conditional probabilities.
The reason is that conditioning on evidence breaks many of the model's symmetries, which can preempt standard lifting techniques.
Recent theoretical results show, for example, that conditioning on evidence which corresponds to binary relations is #P-hard, suggesting that no lifting is to be expected in the worst case.
In this paper, we balance this negative result by identifying the Boolean rank of the evidence as a key parameter for characterizing the complexity of conditioning in lifted inference.
In particular, we show that conditioning on binary evidence with bounded Boolean rank is efficient.
This opens up the possibility of approximating evidence by a low-rank Boolean matrix factorization, which we investigate both theoretically and empirically.
