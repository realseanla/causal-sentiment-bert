Recent work on end-to-end neural network-based architectures for machine translation has shown promising results for English-French and English-German translation.
Unlike these language pairs, however, in the majority of scenarios, there is a lack of high quality parallel corpora.
In this work, we focus on applying neural machine translation to challenging/low-resource languages such as Chinese and Turkish.
In particular, we investigate how to leverage abundant monolingual data for these low-resource translation tasks.
Without the use of external alignment tools, we obtained up to a $1.96$ BLEU score improvement with our proposed method compared to the previous best result in Turkish-to-English translation on the IWLST 2014 dataset.
On Chinese-to-English translation by using the OpenMT 2015 dataset, we were able to obtain up to a $1.59$ BLEU score improvement over phrase-based and hierarchical phrase-based baselines.
