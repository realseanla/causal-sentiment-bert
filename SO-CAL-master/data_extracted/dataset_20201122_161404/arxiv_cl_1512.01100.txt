Target-dependent sentiment classification remains a challenge: modeling the semantic relatedness of a target with its context words in a sentence.
Different context words have different influences on determining the sentiment polarity of a sentence towards the target.
Therefore, it is desirable to integrate the connections between target word and context words when building a learning system.
In this paper, we develop two target dependent long short-term memory (LSTM) models, where target information is automatically taken into account.
We evaluate our methods on a benchmark dataset from Twitter.
Empirical results show that modeling sentence representation with standard LSTM does not perform well.
Incorporating target information into LSTM can significantly boost the classification accuracy.
The target-dependent LSTM models achieve state-of-the-art performances without using syntactic parser or external sentiment lexicons.
