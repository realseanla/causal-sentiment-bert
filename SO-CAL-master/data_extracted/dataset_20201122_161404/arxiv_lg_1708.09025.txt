In this paper, we present hierarchical relationbased latent Dirichlet allocation (hrLDA), a data-driven hierarchical topic model for extracting terminological ontologies from a large number of heterogeneous documents.
In contrast to traditional topic models, hrLDA relies on noun phrases instead of unigrams, considers syntax and document structures, and enriches topic hierarchies with topic relations.
Through a series of experiments, we demonstrate the superiority of hrLDA over existing topic models, especially for building hierarchies.
Furthermore, we illustrate the robustness of hrLDA in the settings of noisy data sets, which are likely to occur in many practical scenarios.
Our ontology evaluation results show that ontologies extracted from hrLDA are very competitive with the ontologies created by domain experts.
