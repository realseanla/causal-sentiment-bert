In this paper we describe a deep network architecture that maps visual input to control actions for a robotic planar reaching task with 100 percent reliability in real-world trials.
Our network is trained in simulation and fine-tuned with a limited number of real-world images.
The policy search is guided by a kinematics-based controller (K-GPS), which works more effectively and efficiently than $\varepsilon$-Greedy.
A critical insight in our system is the need to introduce a bottleneck in the network between the perception and control networks, and to initially train these networks independently.
