For complex segmentation tasks, fully automatic systems are inherently limited in their achievable accuracy for extracting relevant objects.
Especially in cases where only few data sets need to be processed for a highly accurate result, semi-automatic segmentation techniques exhibit a clear benefit for the user.
One area of application is medical image processing during an intervention for a single patient.
We propose a learning-based cooperative segmentation approach which includes the computing entity as well as the user into the task.
Our system builds upon a state-of-the-art fully convolutional artificial neural network (FCN) as well as an active user model for training.
During the segmentation process, a user of the trained system can iteratively add additional hints in form of pictorial scribbles as seed points into the FCN system to achieve an interactive and precise segmentation result.
The segmentation quality of interactive FCNs is evaluated.
Iterative FCN approaches can yield superior results compared to networks without the user input channel component, due to a consistent improvement in segmentation quality after each interaction.
