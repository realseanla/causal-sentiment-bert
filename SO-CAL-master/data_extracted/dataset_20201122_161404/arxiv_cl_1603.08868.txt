Corpora and web texts can become a rich language learning resource if we have a means of assessing whether they are linguistically appropriate for learners at a given proficiency level.
In this paper, we aim at addressing this issue by presenting the first approach for predicting linguistic complexity for Swedish second language learning material on a 5-point scale.
After showing that the traditional Swedish readability measure, L\"asbarhetsindex (LIX), is not suitable for this task, we propose a supervised machine learning model, based on a range of linguistic features, that can reliably classify texts according to their difficulty level.
Our model obtained an accuracy of 81.3 percent and an F-score of 0.8, which is comparable to the state of the art in English and is considerably higher than previously reported results for other languages.
We further studied the utility of our features with single sentences instead of full texts since sentences are a common linguistic unit in language learning exercises.
We trained a separate model on sentence-level data with five classes, which yielded 63.4 percent accuracy.
Although this is lower than the document level performance, we achieved an adjacent accuracy of 92 percent.
Furthermore, we found that using a combination of different features, compared to using lexical features alone, resulted in 7 percent improvement in classification accuracy at the sentence level, whereas at the document level, lexical features were more dominant.
Our models are intended for use in a freely accessible web-based language learning platform for the automatic generation of exercises.
