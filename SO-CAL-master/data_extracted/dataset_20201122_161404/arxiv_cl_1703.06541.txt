Ensemble methods using multiple classifiers have proven to be the most successful approach for the task of Native Language Identification (NLI), achieving the current state of the art.
However, a systematic examination of ensemble methods for NLI has yet to be conducted.
Additionally, deeper ensemble architectures such as classifier stacking have not been closely evaluated.
We present a set of experiments using three ensemble-based models, testing each with multiple configurations and algorithms.
This includes a rigorous application of meta-classification models for NLI, achieving state-of-the-art results on three datasets from different languages.
We also present the first use of statistical significance testing for comparing NLI systems, showing that our results are significantly better than the previous state of the art.
We make available a collection of test set predictions to facilitate future statistical tests.
