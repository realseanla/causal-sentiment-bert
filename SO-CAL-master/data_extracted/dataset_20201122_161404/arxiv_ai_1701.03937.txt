Much of work in semantic web relying on Wikipedia as the main source of knowledge often work on static snapshots of the dataset.
The full history of Wikipedia revisions, while contains much more useful information, is still difficult to access due to its exceptional volume.
To enable further research on this collection, we developed a tool, named Hedera, that efficiently extracts semantic information from Wikipedia revision history datasets.
Hedera exploits Map-Reduce paradigm to achieve rapid extraction, it is able to handle one entire Wikipedia articles revision history within a day in a medium-scale cluster, and supports flexible data structures for various kinds of semantic web study.
