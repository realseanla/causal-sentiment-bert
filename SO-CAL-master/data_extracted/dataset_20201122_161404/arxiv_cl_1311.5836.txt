Since long, research on machine translation has been ongoing.
Still, we do not get good translations from MT engines so developed.
Manual ranking of these outputs tends to be very time consuming and expensive.
Identifying which one is better or worse than the others is a very taxing task.
In this paper, we show an approach which can provide automatic ranks to MT outputs (translations) taken from different MT Engines and which is based on N-gram approximations.
We provide a solution where no human intervention is required for ranking systems.
Further we also show the evaluations of our results which show equivalent results as that of human ranking.
