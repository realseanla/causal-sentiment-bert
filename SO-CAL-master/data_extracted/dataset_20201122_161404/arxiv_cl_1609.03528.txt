We describe Microsoft's conversational speech recognition system, in which we combine recent developments in neural-network-based acoustic and language modeling to advance the state of the art on the Switchboard recognition task.
Inspired by machine learning ensemble techniques, the system uses a range of convolutional and recurrent neural networks.
I-vector modeling and lattice-free MMI training provide significant gains for all acoustic model architectures.
Language model rescoring with multiple forward and backward running RNNLMs, and word posterior-based system combination provide a 20 percent boost.
The best single system uses a ResNet architecture acoustic model with RNNLM rescoring, and achieves a word error rate of 6.9 percent on the NIST 2000 Switchboard task.
The combined system has an error rate of 6.3 percent, representing an improvement over previously reported results on this benchmark task.
