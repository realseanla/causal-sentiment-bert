In this work, we present a novel neural network based architecture for inducing compositional crosslingual word representations.
Unlike previously proposed methods, our method fulfills the following three criteria; it constrains the word-level representations to be compositional, it is capable of leveraging both bilingual and monolingual data, and it is scalable to large vocabularies and large quantities of data.
The key component of our approach is what we refer to as a monolingual inclusion criterion, that exploits the observation that phrases are more closely semantically related to their sub-phrases than to other randomly sampled phrases.
We evaluate our method on a well-established crosslingual document classification task and achieve results that are either comparable, or greatly improve upon previous state-of-the-art methods.
Concretely, our method reaches a level of 91.5 percent and 84.0 percent accuracy for the English to German and German to English sub-tasks respectively.
The latter being an absolute improvement upon the previous state of the art by 7.3 percent points of accuracy and an improvement of 31.3 percent in error reduction.
