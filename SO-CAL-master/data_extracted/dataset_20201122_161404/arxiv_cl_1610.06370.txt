Assisted text input techniques can save time and effort and improve text quality.
In this paper, we investigate how grounded and conditional extensions to standard neural language models can bring improvements in the tasks of word prediction and completion.
These extensions incorporate a structured knowledge base and numerical values from the text into the context used to predict the next word.
Our automated evaluation on a clinical dataset shows extended models significantly outperform standard models.
Our best system uses both conditioning and grounding, because of their orthogonal benefits.
For word prediction with a list of 5 suggestions, it improves recall from 25.03 percent to 71.28 percent and for word completion it improves keystroke savings from 34.35 percent to 44.81 percent, where theoretical bound for this dataset is 58.78 percent.
We also perform a qualitative investigation of how models with lower perplexity occasionally fare better at the tasks.
We found that at test time numbers have more influence on the document level than on individual word probabilities.
