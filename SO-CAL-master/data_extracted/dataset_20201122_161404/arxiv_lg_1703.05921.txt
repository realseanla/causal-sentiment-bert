Obtaining models that capture imaging markers relevant for disease progression and treatment monitoring is challenging.
Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection.
High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches.
Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers.
We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space.
Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution.
Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.
