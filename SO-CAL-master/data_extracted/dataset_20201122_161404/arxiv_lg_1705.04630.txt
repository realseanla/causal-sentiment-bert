We consider the task of forecasting an infinite sequence of future observation based on some number of past observations, where the probability measure generating the observations is "suspected" to satisfy one or more of a set of incomplete models, i.e.
convex sets in the space of probability measures.
This setting is in some sense intermediate between the realizable setting where the probability measure comes from some known set of probability measures (which can be addressed using e.g.
Bayesian inference) and the unrealizable setting where the probability measure is completely arbitrary.
We demonstrate a method of forecasting which guarantees that, whenever the true probability measure satisfies an incomplete model in a given countable set, the forecast converges to the same incomplete model in the (appropriately normalized) Kantorovich-Rubinstein metric.
This is analogous to merging of opinions for Bayesian inference, except that convergence in the Kantorovich-Rubinstein metric is weaker than convergence in total variation.
