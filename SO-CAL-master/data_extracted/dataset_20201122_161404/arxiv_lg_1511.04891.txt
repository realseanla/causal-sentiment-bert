How to build a machine learning method that can continuously gain structured visual knowledge by learning structured facts?
Our goal in this paper is to address this question by proposing a problem setting, where training data comes as structured facts in images with different types including (1) objects(e.g., &lt; boy &gt;), (2) attributes (e.g., &lt; boy,tall &gt;), (3) actions (e.g., &lt; boy, playing &gt;), (4) interactions (e.g., &lt; boy, riding, a horse &gt;).
Each structured fact has a semantic language view (e.g., &lt; boy, playing &gt;) and a visual view (an image with this fact).
A human is able to efficiently gain visual knowledge by learning facts in a never ending process, and as we believe in a structured way (e.g., understanding "playing" is the action part of &lt; boy, playing &gt;, and hence can generalize to recognize &lt; girl, playing &gt; if just learn &lt; girl &gt; additionally).
Inspired by human visual perception, we propose a model that is (1) able to learn a representation, we name as wild-card, which covers different types of structured facts, (2) could flexibly get fed with structured fact language-visual view pairs in a never ending way to gain more structured knowledge, (3) could generalize to unseen facts, and (4) allows retrieval of both the fact language view given the visual view (i.e., image) and vice versa.
We also propose a novel method to generate hundreds of thousands of structured fact pairs from image caption data, which are necessary to train our model and can be useful for other applications.
