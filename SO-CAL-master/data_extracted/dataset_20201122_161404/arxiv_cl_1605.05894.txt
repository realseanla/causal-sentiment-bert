Microblogging platforms such as Twitter provide active communication channels during mass convergence and emergency events such as earthquakes, typhoons.
During the sudden onset of a crisis situation, affected people post useful information on Twitter that can be used for situational awareness and other humanitarian disaster response efforts, if processed timely and effectively.
Processing social media information pose multiple challenges such as parsing noisy, brief and informal messages, learning information categories from the incoming stream of messages and classifying them into different classes among others.
One of the basic necessities of many of these tasks is the availability of data, in particular human-annotated data.
In this paper, we present human-annotated Twitter corpora collected during 19 different crises that took place between 2013 and 2015.
To demonstrate the utility of the annotations, we train machine learning classifiers.
Moreover, we publish first largest word2vec word embeddings trained on 52 million crisis-related tweets.
To deal with tweets language issues, we present human-annotated normalized lexical resources for different lexical variations.
