In this paper, we extend neural Turing machine (NTM) into a dynamic neural Turing machine (D-NTM) by introducing a trainable memory addressing scheme.
This scheme maintains for each memory cell two separate vectors, content and address vectors.
This allows the D-NTM to learn a wide variety of location-based addressing strategies including both linear and nonlinear ones.
We implement the D-NTM with both soft, differentiable and hard, non-differentiable read/write mechanisms.
We investigate the mechanisms and effects for learning to read and write to a memory through experiments on Facebook bAbI tasks using both a feedforward and GRU-controller.
The D-NTM is evaluated on a set of the Facebook bAbI tasks and shown to outperform NTM and LSTM baselines.
