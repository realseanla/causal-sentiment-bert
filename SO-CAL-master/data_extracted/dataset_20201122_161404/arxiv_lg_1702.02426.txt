Domain adaptation is important in sentiment analysis as sentiment-indicating words vary between domains.
Recently, multi-domain adaptation has become more pervasive, but existing approaches train on all available source domains including dissimilar ones.
However, the selection of appropriate training data is as important as the choice of algorithm.
We undertake -- to our knowledge for the first time -- an extensive study of domain similarity metrics in the context of sentiment analysis and propose novel representations, metrics, and a new scope for data selection.
We evaluate the proposed methods on two large-scale multi-domain adaptation settings on tweets and reviews and demonstrate that they consistently outperform strong random and balanced baselines, while our proposed selection strategy outperforms instance-level selection and yields the best score on a large reviews corpus.
