Latent state space models are one of the most fundamental and widely used tools for modeling dynamical systems.
Traditional Maximum Likelihood Estimation (MLE) based approaches aim to maximize the likelihood objective, which is non-convex due to latent states.
While non-convex optimization methods like EM can learn models that locally optimize the likelihood objective, using the locally optimal model for an inference task such as Bayesian filtering usually does not have performance guarantees.
In this work, we propose a method that considers the inference procedure on the dynamical system as a composition of predictors.
Instead of optimizing a given parametrization of latent states, we learn predictors for inference in predictive belief space, where we can use sufficient features of observations for supervision of our learning algorithm.
We further show that our algorithm, the Predictive State Inference Machine, has theoretical performance guarantees on the inference task.
Empirical verification across several of dynamical system benchmarks ranging from a simulated helicopter to recorded telemetry traces from a robot showcase the abilities of training Inference Machines.
