Agents of general intelligence deployed in real-world scenarios must adapt to ever-changing environmental conditions.
While such adaptive agents may leverage engineered knowledge, they will require the capacity to construct and evaluate knowledge themselves from their own experience in a bottom-up, constructivist fashion.
This position paper builds on the idea of encoding knowledge as temporally extended predictions through the use of general value functions.
Prior work has focused on learning predictions about externally derived signals about a task or environment (e.g.
battery level, joint position).
Here we advocate that the agent should also predict internally generated signals regarding its own learning process - for example, an agent's confidence in its learned predictions.
Finally, we suggest how such information would be beneficial in creating an introspective agent that is able to learn to make good decisions in a complex, changing world.
