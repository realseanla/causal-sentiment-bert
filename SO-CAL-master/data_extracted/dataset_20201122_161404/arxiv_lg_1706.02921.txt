We present an end-to-end system for musical key estimation, based on a convolutional neural network.
The proposed system not only out-performs existing key estimation methods proposed in the academic literature; it is also capable of learning a unified model for diverse musical genres that performs comparably to existing systems specialised for specific genres.
Our experiments confirm that different genres do differ in their interpretation of tonality, and thus a system tuned e.g.
for pop music performs subpar on pieces of electronic music.
They also reveal that such cross-genre setups evoke specific types of error (predicting the relative or parallel minor).
However, using the data-driven approach proposed in this paper, we can train models that deal with multiple musical styles adequately, and without major losses in accuracy.
