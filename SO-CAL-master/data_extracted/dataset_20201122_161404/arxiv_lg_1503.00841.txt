Prior knowledge has been shown very useful to address many natural language processing tasks.
Many approaches have been proposed to formalise a variety of knowledge, however, whether the proposed approach is robust or sensitive to the knowledge supplied to the model has rarely been discussed.
In this paper, we propose three regularization terms on top of generalized expectation criteria, and conduct extensive experiments to justify the robustness of the proposed methods.
Experimental results demonstrate that our proposed methods obtain remarkable improvements and are much more robust than baselines.
