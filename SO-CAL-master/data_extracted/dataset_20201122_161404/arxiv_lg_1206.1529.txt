The past decade has seen the rise of $\ell_1$-relaxation methods to promote sparsity for better interpretability and generalization of learning results.
However, there are several important learning applications, such as Markowitz portolio selection and sparse mixture density estimation, that feature simplex constraints, which disallow the application of the standard $\ell_1$-penalty.
In this setting, we show how to efficiently obtain sparse projections onto the positive and general simplex with sparsity constraints.
We provide an exact sparse projector for the positive simplex constraints, and derive a novel approach with online optimality and approximation guarantees for sparse projections onto the general simplex constraints.
Even for small sized problems, this new approach is three orders of magnitude faster than the alternative, state-of-the-art branch-and-bound based CPLEX solver with no sacrifice in solution quality.
We also empirically demonstrate that our projectors provide substantial benefits in portfolio selection and density estimation.
