This paper aims to accelerate the test-time computation of convolutional neural networks (CNNs), especially very deep CNNs that have substantially impacted the computer vision community.
Unlike existing methods that are designed for approximating linear filters or linear responses, our method takes the nonlinear units into account.
We develop an effective solution to the resulting nonlinear optimization problem without the need of stochastic gradient descent (SGD).
More importantly, while current methods mainly focus on optimizing one or two layers, our nonlinear method enables an asymmetric reconstruction that reduces the rapidly accumulated error when multiple (e.g., &gt;=10) layers are approximated.
For the widely used very deep VGG-16 model, our method achieves a whole-model speedup of 4x with merely a 0.3 percent increase of top-5 error in ImageNet classification.
Our 4x accelerated VGG-16 model also shows a graceful accuracy degradation for object detection when plugged into the latest Fast R-CNN detector.
