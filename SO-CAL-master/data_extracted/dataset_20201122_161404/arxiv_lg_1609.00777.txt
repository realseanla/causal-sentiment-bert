This paper proposes \emph{KB-InfoBot}---a dialogue agent that provides users with an entity from a knowledge base (KB) by interactively asking for its attributes.
All components of the KB-InfoBot are trained in an end-to-end fashion using reinforcement learning.
Goal-oriented dialogue systems typically need to interact with an external database to access real-world knowledge (e.g.
movies playing in a city).
Previous systems achieved this by issuing a symbolic query to the database and adding retrieved results to the dialogue state.
However, such symbolic operations break the differentiability of the system and prevent end-to-end training of neural dialogue agents.
In this paper, we address this limitation by replacing symbolic queries with an induced "soft" posterior distribution over the KB that indicates which entities the user is interested in.
We also provide a modified version of the episodic REINFORCE algorithm, which allows the KB-InfoBot to explore and learn both the policy for selecting dialogue acts and the posterior over the KB for retrieving the correct entities.
Experimental results show that the end-to-end trained KB-InfoBot outperforms competitive rule-based baselines, as well as agents which are not end-to-end trainable.
