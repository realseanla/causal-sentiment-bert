We show a tight bound on the number of adaptively chosen statistical queries that a computationally efficient algorithm can answer accurately given $n$ samples from an unknown distribution.
A statistical query asks for the expectation of a predicate over the underlying distribution, and an answer to a statistical query is accurate if it is "close" to the correct expectation over the distribution.
This question was recently considered by Dwork et al., who showed that $\tilde{\Omega}(n^2)$ queries can be answer efficiently, and also by Hardt and Ullman, who showed that answering $\tilde{O}(n^3)$ queries is computationally hard.
We close the gap between the two bounds by proving a new, nearly-optimal hardness result.
Specifically, we show that, under a standard hardness assumption, there is no computationally efficient algorithm that given $n$ samples from an unknown distribution can give valid answers to $O(n^2)$ adaptively chosen statistical queries.
An implication of our results is that computationally efficient algorithms for answering arbitrary, adaptively chosen statistical queries may as well be differentially private.
We obtain our results via an optimal construction of a new combinatorial object that we call an interactive fingerprinting code, which may be of independent interest.
