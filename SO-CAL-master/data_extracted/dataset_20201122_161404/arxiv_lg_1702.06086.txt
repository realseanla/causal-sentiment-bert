Label distribution learning (LDL) is a general learning framework, which assigns a distribution over a set of labels to an instance rather than a single label or multiple labels.
Current LDL methods have either restricted assumptions on the expression form of the label distribution or limitations in representation learning.
This paper presents label distribution learning forests (LDLFs) - a novel label distribution learning algorithm based on differentiable decision trees, which have several advantages: 1) Decision trees have the potential to model any general form of label distributions by the mixture of leaf node predictions.
2) The learning of differentiable decision trees can be combined with representation learning, e.g., to learn deep features in an end-to-end manner.
We define a distribution-based loss function for forests, enabling all the trees to be learned jointly, and show that an update function for leaf node predictions, which guarantees a strict decrease of the loss function, can be derived by variational bounding.
The effectiveness of the proposed LDLFs is verified on two LDL problems, including age estimation and crowd opinion prediction on movies, showing significant improvements to the state-of-the-art LDL methods.
