We construct optimal estimation algorithms over distributed networks for state estimation in the mean-square error (MSE) sense.
Here, we have a distributed collection of agents with processing and cooperation capabilities.
These agents continually observe a noisy version of a desired state of the nature through a linear model and seek to learn this state by interacting with each other.
Although this problem has attracted significant attention and extensively been studied in several different fields including machine learning theory to signal processing, all the well-known strategies achieve suboptimal learning performance in the MSE sense.
To this end, we provide algorithms that achieve distributed minimum MSE (MMSE) performance over an arbitrary network topology based on the aggregation of information at each agent.
This approach differs from the diffusion of information across network, i.e., exchange of local estimates per time instance.
Importantly, we show that exchange of local estimates is sufficient only over the certain network topologies.
By inspecting these network structures, we also propose strategies that achieve the distributed MMSE performance also through the diffusion of information such that we can substantially reduce the communication load while achieving the best possible MSE performance.
For practical implementations we provide approaches to reduce the complexity of the algorithms through the time-windowing of the observations.
Finally, in the numerical examples, we demonstrate the superior performance of the introduced algorithms in the MSE sense due to optimal estimation.
