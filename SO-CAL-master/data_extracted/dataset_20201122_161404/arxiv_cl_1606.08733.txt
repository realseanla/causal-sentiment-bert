This paper discusses models for dialogue state tracking using recurrent neural networks (RNN).
We present experiments on the standard dialogue state tracking (DST) dataset, DSTC2 [6].
On the one hand, RNN models became state of the art in DST, on the other hand, most state-of-the-art models are only turn-based and require dataset-specific preprocessing (e.g.
DSTC2-specific) in order to achieve state-of-the-art results.
We implemented two architectures which can be used in incremental settings and require almost no preprocessing.
We compare their performance to the benchmarks on DSTC2 and discuss their properties.
With only trivial preprocessing, the performance of our models is close to the state-of-the-art results.
