We present an alternative methodology for the analysis of algorithms, based on the concept of expected discounted reward.
This methodology naturally handles algorithms that do not always terminate, so it can (theoretically) be used with partial algorithms for undecidable problems, such as those found in artificial general intelligence (AGI) and automated theorem proving.
We mention new approaches to self-improving AGI and logical uncertainty enabled by this methodology.
