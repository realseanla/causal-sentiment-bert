The problem of "approximating the crowd" is that of estimating the crowd's majority opinion by querying only a subset of it.
Algorithms that approximate the crowd can intelligently stretch a limited budget for a crowdsourcing task.
We present an algorithm, "CrowdSense," that works in an online fashion to dynamically sample subsets of labelers based on an exploration/exploitation criterion.
The algorithm produces a weighted combination of a subset of the labelers' votes that approximates the crowd's opinion.
