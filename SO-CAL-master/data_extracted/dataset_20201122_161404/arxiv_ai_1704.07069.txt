Agent modelling involves considering how other agents will behave, in order to influence your own actions.
In this paper, we explore the use of agent modelling in the hidden-information, collaborative card game Hanabi.
We implement a number of rule-based agents, both from the literature and of our own devising, in addition to an Information Set Monte Carlo Tree Search (IS-MCTS) agent.
We observe poor results from IS-MCTS, so construct a new, predictor version that uses a model of the agents with which it is paired.
We observe a significant improvement in game-playing strength from this agent in comparison to IS-MCTS, resulting from its consideration of what the other agents in a game would do.
In addition, we create a flawed rule-based agent to highlight the predictor's capabilities with such an agent.
