We consider incorporating topic information as prior knowledge into the sequence to sequence (Seq2Seq) network structure with attention mechanism for response generation in chatbots.
To this end, we propose a topic augmented joint attention based Seq2Seq (TAJA-Seq2Seq) model.
In TAJA-Seq2Seq, information from input posts and information from topics related to the posts are simultaneously embedded into vector spaces by a content encoder and a topic encoder respectively.
The two kinds of information interact with each other and help calibrate weights of each other in the joint attention mechanism in TAJA2Seq2Seq, and jointly determine the generation of responses in decoding.
The model simulates how people behave in conversation and can generate well-focused and informative responses with the help of topic information.
Empirical study on large scale human judged generation results show that our model outperforms Seq2Seq with attention on both response quality and diversity.
