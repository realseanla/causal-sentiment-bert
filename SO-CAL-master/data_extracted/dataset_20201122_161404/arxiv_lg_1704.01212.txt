Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science.
Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature.
These models learn a message passing algorithm and aggregation function to compute a function of their entire input graph.
At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach.
In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework.
Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark, results we believe are strong enough to justify retiring this benchmark.
