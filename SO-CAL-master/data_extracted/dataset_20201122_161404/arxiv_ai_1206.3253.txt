In addressing the challenge of exponential scaling with the number of agents we adopt a cluster-based representation to approximately solve asymmetric games of very many players.
A cluster groups together agents with a similar "strategic view" of the game.
We learn the clustered approximation from data consisting of strategy profiles and payoffs, which may be obtained from observations of play or access to a simulator.
Using our clustering we construct a reduced "twins" game in which each cluster is associated with two players of the reduced game.
This allows our representation to be individually- responsive because we align the interests of every individual agent with the strategy of its cluster.
Our approach provides agents with higher payoffs and lower regret on average than model-free methods as well as previous cluster-based methods, and requires only few observations for learning to be successful.
The "twins" approach is shown to be an important component of providing these low regret approximations.
